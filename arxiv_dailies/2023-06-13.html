<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <script>
        var papers = [{"id": "2306.06157", "date": "Sat, 10 Jun 2023 23:50:02 GMT", "title": "Fault Localization for Framework Conversions of Image Recognition Models\n", "authors": ["Nikolaos Louloudakis", "Perry Gibson", "Jos\\'e Cano", "and Ajitha Rajan\n"], "categories": ["cs.CV", "cs.LG", "cs.SE", "cs.SY", "eess.SY\nComments:", "5", "pages,", "3", "figures,", "1", "table\n"], "abstract": "When deploying Deep Neural Networks (DNNs), developers often convert models from one deep learning framework to another (e.g., TensorFlow to PyTorch). However, this process is error-prone and can impact target model accuracy. To identify the extent of such impact, we perform and briefly present a differential analysis against three DNNs used for image recognition (MobileNetV2, ResNet101, and InceptionV3), converted across four well-known deep learning frameworks (PyTorch, Keras, TensorFlow (TF), and TFLite), which revealed numerous model crashes and output label discrepancies of up to 100%. To mitigate such errors, we present a novel approach towards fault localization and repair of buggy deep learning framework conversions, focusing on pre-trained image recognition models. Our technique consists of four primary stages of analysis: 1) conversion tools, 2) model parameters, 3) model hyperparameters, and 4) graph representation. In addition, we propose a number of strategies towards fault repair of the faults detected. We implement our technique on top of Apache TVM deep learning compiler, and we test it by conducting a preliminary fault localization analysis for the conversion of InceptionV3, from TF to TFLite. Our approach detected that the tf2onnx tool used in the conversion process introduced precision errors to model weights for convolutional layers in particular, which negatively affected the model accuracy. We then repaired the target model by replacing the affected weights with those from source model.", "link": "https://arxiv.org/abs/2306.06157"}, {"id": "2306.06208", "date": "Mon, 5 Jun 2023 23:07:01 GMT", "title": "A Differential Testing Framework to Evaluate Image Recognition Model\n\u00a0Robustness\n", "authors": ["Nikolaos Louloudakis", "Perry Gibson", "Jos\\'e Cano", "and Ajitha Rajan\n"], "categories": ["cs.CV", "cs.LG", "cs.SE", "cs.SY", "eess.SY\nComments:", "12", "pages,", "10", "figures,", "2", "tables.", "arXiv", "admin", "note:", "text", "overlap", "with\n\u00a0arXiv:2211.00471\n"], "abstract": "Image recognition tasks typically use deep learning and require enormous processing power, thus relying on hardware accelerators like GPUs and TPUs for fast, timely processing. Failure in real-time image recognition tasks can occur due to sub-optimal mapping on hardware accelerators during model deployment, which may lead to timing uncertainty and erroneous behavior. Mapping on hardware accelerators is done through multiple software components like deep learning frameworks, compilers, device libraries, that we refer to as the computational environment. Owing to the increased use of image recognition tasks in safety-critical applications like autonomous driving and medical imaging, it is imperative to assess their robustness to changes in the computational environment, as the impact of parameters like deep learning frameworks, compiler optimizations, and hardware devices on model performance and correctness is not well understood. In this paper we present a differential testing framework, which allows deep learning model variant generation, execution, differential analysis and testing for a number of computational environment parameters. Using our framework, we conduct an empirical study of robustness analysis of three popular image recognition models using the ImageNet dataset, assessing the impact of changing deep learning frameworks, compiler optimizations, and hardware devices. We report the impact in terms of misclassifications and inference time differences across different settings. In total, we observed up to 72% output label differences across deep learning frameworks, and up to 82% unexpected performance degradation in terms of inference time, when applying compiler optimizations. Using the analysis tools in our framework, we also perform fault analysis to understand the reasons for the observed differences.", "link": "https://arxiv.org/abs/2306.06208"}, {"id": "2306.06254", "date": "Fri, 9 Jun 2023 20:52:44 GMT", "title": "Understanding the Benefits of Image Augmentations\n", "authors": ["Matthew Iceland", "Christopher Kanan\n"], "categories": ["cs.CV", "cs.LG", "eess.IV\n"], "abstract": "Image Augmentations are widely used to reduce overfitting in neural networks. However, the explainability of their benefits largely remains a mystery. We study which layers of residual neural networks (ResNets) are most affected by augmentations using Centered Kernel Alignment (CKA). We do so by analyzing models of varying widths and depths, as well as whether their weights are initialized randomly or through transfer learning. We find that the pattern of how the layers are affected depends on the model's depth, and that networks trained with augmentation that use information from two images affect the learned weights significantly more than augmentations that operate on a single image. Deeper layers of ResNets initialized with ImageNet-1K weights and fine-tuned receive more impact from the augmentations than early layers. Understanding the effects of image augmentations on CNNs will have a variety of applications, such as determining how far back one needs to fine-tune a network and which layers should be frozen when implementing layer freezing algorithms.", "link": "https://arxiv.org/abs/2306.06254"}, {"id": "2306.07186", "date": "Mon, 12 Jun 2023 15:37:18 GMT", "title": "CD-CTFM: A Lightweight CNN-Transformer Network for Remote Sensing Cloud\n\u00a0Detection Fusing Multiscale Features\n", "authors": ["Wenxuan Ge", "Xubing Yang", "Li Zhang\n"], "categories": ["cs.CV", "cs.LG", "eess.IV\n"], "abstract": "Clouds in remote sensing images inevitably affect information extraction, which hinder the following analysis of satellite images. Hence, cloud detection is a necessary preprocessing procedure. However, the existing methods have numerous calculations and parameters. In this letter, a lightweight CNN-Transformer network, CD-CTFM, is proposed to solve the problem. CD-CTFM is based on encoder-decoder architecture and incorporates the attention mechanism. In the decoder part, we utilize a lightweight network combing CNN and Transformer as backbone, which is conducive to extract local and global features simultaneously. Moreover, a lightweight feature pyramid module is designed to fuse multiscale features with contextual information. In the decoder part, we integrate a lightweight channel-spatial attention module into each skip connection between encoder and decoder, extracting low-level features while suppressing irrelevant information without introducing many parameters. Finally, the proposed model is evaluated on two cloud datasets, 38-Cloud and MODIS. The results demonstrate that CD-CTFM achieves comparable accuracy as the state-of-art methods. At the same time, CD-CTFM outperforms state-of-art methods in terms of efficiency.", "link": "https://arxiv.org/abs/2306.07186"}, {"id": "2306.06110", "date": "Fri, 26 May 2023 09:33:12 GMT", "title": "Surrogate Modeling of Car Drag Coefficient with Depth and Normal\n\u00a0Renderings\n", "authors": ["Binyang Song", "Chenyang Yuan", "Frank Permenter", "Nikos Arechiga", "Faez\n\u00a0Ahmed\n"], "categories": ["cs.LG", "cs.CE", "cs.CV\n"], "abstract": "Generative AI models have made significant progress in automating the creation of 3D shapes, which has the potential to transform car design. In engineering design and optimization, evaluating engineering metrics is crucial. To make generative models performance-aware and enable them to create high-performing designs, surrogate modeling of these metrics is necessary. However, the currently used representations of three-dimensional (3D) shapes either require extensive computational resources to learn or suffer from significant information loss, which impairs their effectiveness in surrogate modeling. To address this issue, we propose a new two-dimensional (2D) representation of 3D shapes. We develop a surrogate drag model based on this representation to verify its effectiveness in predicting 3D car drag. We construct a diverse dataset of 9,070 high-quality 3D car meshes labeled by drag coefficients computed from computational fluid dynamics (CFD) simulations to train our model. Our experiments demonstrate that our model can accurately and efficiently evaluate drag coefficients with an $R^2$ value above 0.84 for various car categories. Moreover, the proposed representation method can be generalized to many other product categories beyond cars. Our model is implemented using deep neural networks, making it compatible with recent AI image generation tools (such as Stable Diffusion) and a significant step towards the automatic generation of drag-optimized car designs. We have made the dataset and code publicly available at https://decode.mit.edu/projects/dragprediction/.", "link": "https://arxiv.org/abs/2306.06110"}, {"id": "2306.06118", "date": "Mon, 5 Jun 2023 08:20:46 GMT", "title": "Estimation of River Water Surface Elevation Using UAV Photogrammetry and\n\u00a0Machine Learning\n", "authors": ["Rados{\\l}aw Szostak", "Marcin Pietro\\'n", "Przemys{\\l}aw Wachniew,\n\u00a0Miros{\\l}aw Zimnoch", "Pawe{\\l} \\'Cwi\\k{a}ka{\\l}a\n"], "categories": ["cs.LG", "cs.CV", "eess.IV\nComments:", "Manuscript", "submitted", "to", "Measurement", "journal", "(ISSN", "0263-2241)\n"], "abstract": "Unmanned aerial vehicle (UAV) photogrammetry allows for the creation of orthophotos and digital surface models (DSMs) of a terrain. However, DSMs of water bodies mapped with this technique reveal water surface distortions, preventing the use of photogrammetric data for accurate determination of water surface elevation (WSE). Firstly, we propose a new solution in which a convolutional neural network (CNN) is used as a WSE estimator from photogrammetric DSMs and orthophotos. Second, we improved the previously known \"water-edge\" method by filtering the outliers using a forward-backwards exponential weighted moving average. Further improvement in these two methods was achieved by performing a linear regression of the WSE values against chainage. The solutions estimate the uncertainty of the predictions. This is the first approach in which DL was used for this task. A brand new machine learning data set has been created. It was collected on a small lowland river in winter and summer conditions. It consists of 322 samples, each corresponding to a 10 by 10 meter area of the river channel and adjacent land. Each data set sample contains orthophoto and DSM arrays as input, along with a single ground-truth WSE value as output. The data set was supplemented with data collected by other researchers that compared the state-of-the-art methods for determining WSE using an UAV. The results of the DL solution were verified using k-fold cross-validation method. This provided an in-depth examination of the model's ability to perform on previously unseen data. The WSE RMSEs differ for each k-fold cross-validation subset and range from 1.7 cm up to 17.2 cm. The RMSE results of the improved \"water-edge\" method are at least six times lower than the RMSE results achieved by the conventional \"water-edge\" method. The results obtained by new methods are predominantly outperforming existing ones.", "link": "https://arxiv.org/abs/2306.06118"}, {"id": "2306.06134", "date": "Thu, 8 Jun 2023 19:58:30 GMT", "title": "Sound Explanation for Trustworthy Machine Learning\n", "authors": ["Kai Jia", "Pasapol Saowakon", "Limor Appelbaum", "Martin Rinard\n"], "categories": ["cs.LG", "cs.AI\n"], "abstract": "We take a formal approach to the explainability problem of machine learning systems. We argue against the practice of interpreting black-box models via attributing scores to input components due to inherently conflicting goals of attribution-based interpretation. We prove that no attribution algorithm satisfies specificity, additivity, completeness, and baseline invariance. We then formalize the concept, sound explanation, that has been informally adopted in prior work. A sound explanation entails providing sufficient information to causally explain the predictions made by a system. Finally, we present the application of feature selection as a sound explanation for cancer prediction models to cultivate trust among clinicians.", "link": "https://arxiv.org/abs/2306.06134"}, {"id": "2306.06135", "date": "Fri, 9 Jun 2023 01:37:32 GMT", "title": "Safety and Fairness for Content Moderation in Generative Models\n", "authors": ["Susan Hao", "Piyush Kumar", "Sarah Laszlo", "Shivani Poddar", "Bhaktipriya\n\u00a0Radharapu", "Renee Shelby\n"], "categories": ["cs.LG", "cs.AI\nComments:", "CVPR", "Workshop", "Paper\n"], "abstract": "With significant advances in generative AI, new technologies are rapidly being deployed with generative components. Generative models are typically trained on large datasets, resulting in model behaviors that can mimic the worst of the content in the training data. Responsible deployment of generative technologies requires content moderation strategies, such as safety input and output filters. Here, we provide a theoretical framework for conceptualizing responsible content moderation of text-to-image generative technologies, including a demonstration of how to empirically measure the constructs we enumerate. We define and distinguish the concepts of safety, fairness, and metric equity, and enumerate example harms that can come in each domain. We then provide a demonstration of how the defined harms can be quantified. We conclude with a summary of how the style of harms quantification we demonstrate enables data-driven content moderation decisions.", "link": "https://arxiv.org/abs/2306.06135"}, {"id": "2306.06146", "date": "Fri, 9 Jun 2023 10:52:49 GMT", "title": "Hidden Classification Layers: a study on Data Hidden Representations\n\u00a0with a Higher Degree of Linear Separability between the Classes\n", "authors": ["Andrea Apicella", "Francesco Isgr\\`o", "Roberto Prevete\n"], "categories": ["cs.LG", "cs.AI\nComments:", "Paper", "submitted", "for", "peer-review\n"], "abstract": "In the context of classification problems, Deep Learning (DL) approaches represent state of art. Many DL approaches are based on variations of standard multi-layer feed-forward neural networks. These are also referred to as deep networks. The basic idea is that each hidden neural layer accomplishes a data transformation which is expected to make the data representation \"somewhat more linearly separable\" than the previous one to obtain a final data representation which is as linearly separable as possible. However, determining the appropriate neural network parameters that can perform these transformations is a critical problem. In this paper, we investigate the impact on deep network classifier performances of a training approach favouring solutions where data representations at the hidden layers have a higher degree of linear separability between the classes with respect to standard methods. To this aim, we propose a neural network architecture which induces an error function involving the outputs of all the network layers. Although similar approaches have already been partially discussed in the past literature, here we propose a new architecture with a novel error function and an extensive experimental analysis. This experimental analysis was made in the context of image classification tasks considering four widely used datasets. The results show that our approach improves the accuracy on the test set in all the considered cases.", "link": "https://arxiv.org/abs/2306.06146"}, {"id": "2306.06148", "date": "Fri, 9 Jun 2023 12:08:34 GMT", "title": "Artificial intelligence and radiation protection. A game changer or an\n\u00a0update?\n", "authors": ["Sylvain Andresz (CEPN)", "A Z\\'ephir", "Jeremy Bez (IRSN/PSN-RES/SNC/LN),\n\u00a0Maxime Karst", "J. Danieli (SPRA)\n"], "categories": ["cs.LG", "cs.AI\nJournal-ref:", "Radioprotection,", "2022,", "57", "(2),", "pp.157-164\nDOI:", "10.1051/radiopro/2022004\n"], "abstract": "Artificial intelligence (AI) is regarded as one of the most disruptive technology of the century and with countless applications. What does it mean for radiation protection? This article describes the fundamentals of machine learning (ML) based methods and presents the inaugural applications in different fields of radiation protection. It is foreseen that the usage of AI will increase in radiation protection. Consequently, this article explores some of the benefits and also the potential barriers and questions, including ethical ones, that can come out. The article proposes that collaboration between radiation protection professionals and data scientist experts can accelerate and guide the development of the algorithms for effective scientific and technological outcomes.", "link": "https://arxiv.org/abs/2306.06148"}, {"id": "2306.06152", "date": "Fri, 9 Jun 2023 13:51:33 GMT", "title": "EfficientBioAI: Making Bioimaging AI Models Efficient in Energy, Latency\n\u00a0and Representation\n", "authors": ["Yu Zhou", "Justin Sonneck", "Sweta Banerjee", "Stefanie D\\\"orr", "Anika\n\u00a0Gr\\\"uneboom", "Kristina Lorenz", "Jianxu Chen\n"], "categories": ["cs.LG", "cs.AI\nComments:", "17", "pages,", "6", "figures\n"], "abstract": "Artificial intelligence (AI) has been widely used in bioimage image analysis nowadays, but the efficiency of AI models, like the energy consumption and latency is not ignorable due to the growing model size and complexity, as well as the fast-growing analysis needs in modern biomedical studies. Like we can compress large images for efficient storage and sharing, we can also compress the AI models for efficient applications and deployment. In this work, we present EfficientBioAI, a plug-and-play toolbox that can compress given bioimaging AI models for them to run with significantly reduced energy cost and inference time on both CPU and GPU, without compromise on accuracy. In some cases, the prediction accuracy could even increase after compression, since the compression procedure could remove redundant information in the model representation and therefore reduce over-fitting. From four different bioimage analysis applications, we observed around 2-5 times speed-up during inference and 30-80$\\%$ saving in energy. Cutting the runtime of large scale bioimage analysis from days to hours or getting a two-minutes bioimaging AI model inference done in near real-time will open new doors for method development and biomedical discoveries. We hope our toolbox will facilitate resource-constrained bioimaging AI and accelerate large-scale AI-based quantitative biological studies in an eco-friendly way, as well as stimulate further research on the efficiency of bioimaging AI.", "link": "https://arxiv.org/abs/2306.06152"}, {"id": "2306.06154", "date": "Fri, 9 Jun 2023 14:49:20 GMT", "title": "HypLL: The Hyperbolic Learning Library\n", "authors": ["Max van Spengler", "Philipp Wirth", "Pascal Mettes\n"], "categories": ["cs.LG", "cs.AI\n"], "abstract": "Deep learning in hyperbolic space is quickly gaining traction in the fields of machine learning, multimedia, and computer vision. Deep networks commonly operate in Euclidean space, implicitly assuming that data lies on regular grids. Recent advances have shown that hyperbolic geometry provides a viable alternative foundation for deep learning, especially when data is hierarchical in nature and when working with few embedding dimensions. Currently however, no accessible open-source library exists to build hyperbolic network modules akin to well-known deep learning libraries. We present HypLL, the Hyperbolic Learning Library to bring the progress on hyperbolic deep learning together. HypLL is built on top of PyTorch, with an emphasis in its design for easy-of-use, in order to attract a broad audience towards this new and open-ended research direction. The code is available at: https://github.com/maxvanspengler/hyperbolic_learning_library. The compressed archive is available at: https://doi.org/10.21942/uva.23385506.v4", "link": "https://arxiv.org/abs/2306.06154"}, {"id": "2306.06155", "date": "Fri, 9 Jun 2023 15:38:25 GMT", "title": "Intensity Profile Projection: A Framework for Continuous-Time\n\u00a0Representation Learning for Dynamic Networks\n", "authors": ["Alexander Modell", "Ian Gallagher", "Emma Ceccherini", "Nick Whiteley and\n\u00a0Patrick Rubin-Delanchy\n"], "categories": ["cs.LG", "stat.ME", "stat.ML\nComments:", "36", "pages,", "8", "figures\nMSC-class:", "62H12", "(primary),", "62H30", "(secondary)\n"], "abstract": "We present a new algorithmic framework, Intensity Profile Projection, for learning continuous-time representations of the nodes of a dynamic network, characterised by a node set and a collection of instantaneous interaction events which occur in continuous time. Our framework consists of three stages: estimating the intensity functions underlying the interactions between pairs of nodes, e.g. via kernel smoothing; learning a projection which minimises a notion of intensity reconstruction error; and inductively constructing evolving node representations via the learned projection. We show that our representations preserve the underlying structure of the network, and are temporally coherent, meaning that node representations can be meaningfully compared at different points in time. We develop estimation theory which elucidates the role of smoothing as a bias-variance trade-off, and shows how we can reduce smoothing as the signal-to-noise ratio increases on account of the algorithm `borrowing strength' across the network.", "link": "https://arxiv.org/abs/2306.06155"}, {"id": "2306.06174", "date": "Fri, 9 Jun 2023 18:01:14 GMT", "title": "Active-Learning-Driven Surrogate Modeling for Efficient Simulation of\n\u00a0Parametric Nonlinear Systems\n", "authors": ["Harshit Kapadia", "Lihong Feng", "Peter Benner\n"], "categories": ["cs.LG", "cs.CE", "cs.NA", "math.DS", "math.NA", "physics.flu-dyn\nComments:", "31", "pages,", "24", "figures,", "1", "table;", "Under", "review\n"], "abstract": "When repeated evaluations for varying parameter configurations of a high-fidelity physical model are required, surrogate modeling techniques based on model order reduction are desired. In absence of the governing equations describing the dynamics, we need to construct the parametric reduced-order surrogate model in a non-intrusive fashion. In this setting, the usual residual-based error estimate for optimal parameter sampling associated with the reduced basis method is not directly available. Our work provides a non-intrusive optimality criterion to efficiently populate the parameter snapshots, thereby, enabling us to effectively construct a parametric surrogate model. We consider separate parameter-specific proper orthogonal decomposition (POD) subspaces and propose an active-learning-driven surrogate model using kernel-based shallow neural networks, abbreviated as ActLearn-POD-KSNN surrogate model. To demonstrate the validity of our proposed ideas, we present numerical experiments using two physical models, namely Burgers' equation and shallow water equations. Both the models have mixed -- convective and diffusive -- effects within their respective parameter domains, with each of them dominating in certain regions. The proposed ActLearn-POD-KSNN surrogate model efficiently predicts the solution at new parameter locations, even for a setting with multiple interacting shock profiles.", "link": "https://arxiv.org/abs/2306.06174"}, {"id": "2306.06179", "date": "Fri, 9 Jun 2023 18:07:06 GMT", "title": "Hidden symmetries of ReLU networks\n", "authors": ["J. Elisenda Grigsby and Kathryn Lindsey and David Rolnick\n"], "categories": ["cs.LG", "math.CO", "math.GT\nComments:", "27", "pages,", "11", "figures,", "ICML", "2023\nMSC-class:", "57R70,", "57Q99,", "52B70,", "52C35\nACM-class:", "I.2.6\n"], "abstract": "The parameter space for any fixed architecture of feedforward ReLU neural networks serves as a proxy during training for the associated class of functions - but how faithful is this representation? It is known that many different parameter settings can determine the same function. Moreover, the degree of this redundancy is inhomogeneous: for some networks, the only symmetries are permutation of neurons in a layer and positive scaling of parameters at a neuron, while other networks admit additional hidden symmetries. In this work, we prove that, for any network architecture where no layer is narrower than the input, there exist parameter settings with no hidden symmetries. We also describe a number of mechanisms through which hidden symmetries can arise, and empirically approximate the functional dimension of different network architectures at initialization. These experiments indicate that the probability that a network has no hidden symmetries decreases towards 0 as depth increases, while increasing towards 1 as width and input dimension increase.", "link": "https://arxiv.org/abs/2306.06179"}, {"id": "2306.06184", "date": "Fri, 9 Jun 2023 18:21:04 GMT", "title": "A Unified Model and Dimension for Interactive Estimation\n", "authors": ["Nataly Brukhim", "Miroslav Dudik", "Aldo Pacchiano", "Robert Schapire\n"], "categories": ["cs.LG", "stat.ML\n"], "abstract": "We study an abstract framework for interactive learning called interactive estimation in which the goal is to estimate a target from its \"similarity'' to points queried by the learner. We introduce a combinatorial measure called dissimilarity dimension which largely captures learnability in our model. We present a simple, general, and broadly-applicable algorithm, for which we obtain both regret and PAC generalization bounds that are polynomial in the new dimension. We show that our framework subsumes and thereby unifies two classic learning models: statistical-query learning and structured bandits. We also delineate how the dissimilarity dimension is related to well-known parameters for both frameworks, in some cases yielding significantly improved analyses.", "link": "https://arxiv.org/abs/2306.06184"}, {"id": "2306.06191", "date": "Fri, 9 Jun 2023 18:43:26 GMT", "title": "Open Data on GitHub: Unlocking the Potential of AI\n", "authors": ["Anthony Cintron Roman", "Kevin Xu", "Arfon Smith", "Jehu Torres Vega", "Caleb\n\u00a0Robinson", "Juan M Lavista Ferres\n"], "categories": ["cs.LG", "cs.IR\nComments:", "In", "submission", "to", "NeurIPS", "2023", "Track", "Datasets", "and", "Benchmarks\n"], "abstract": "GitHub is the world's largest platform for collaborative software development, with over 100 million users. GitHub is also used extensively for open data collaboration, hosting more than 800 million open data files, totaling 142 terabytes of data. This study highlights the potential of open data on GitHub and demonstrates how it can accelerate AI research. We analyze the existing landscape of open data on GitHub and the patterns of how users share datasets. Our findings show that GitHub is one of the largest hosts of open data in the world and has experienced an accelerated growth of open data assets over the past four years. By examining the open data landscape on GitHub, we aim to empower users and organizations to leverage existing open datasets and improve their discoverability -- ultimately contributing to the ongoing AI revolution to help address complex societal issues. We release the three datasets that we have collected to support this analysis as open datasets at https://github.com/github/open-data-on-github.", "link": "https://arxiv.org/abs/2306.06191"}, {"id": "2306.06203", "date": "Fri, 9 Jun 2023 19:10:51 GMT", "title": "FLSL: Feature-level Self-supervised Learning\n", "authors": ["Qing Su", "Anton Netchaev", "Hai Li", "and Shihao Ji\n"], "categories": ["cs.LG", "cs.CV\n"], "abstract": "Current self-supervised learning (SSL) methods (e.g., SimCLR, DINO, VICReg, MOCOv3) target primarily on representations at instance level and do not generalize well to dense prediction tasks, such as object detection and segmentation. Towards aligning SSL with dense predictions, this paper demonstrates for the first time the underlying mean-shift clustering process of Vision Transformers (ViT), which aligns well with natural image semantics (e.g., a world of objects and stuffs). By employing transformer for joint embedding and clustering, we propose a two-level feature clustering SSL method, coined Feature-Level Self-supervised Learning (FLSL). We present the formal definition of the FLSL problem and construct the objectives from the mean-shift and k-means perspectives. We show that FLSL promotes remarkable semantic cluster representations and learns an embedding scheme amenable to intra-view and inter-view feature clustering. Experiments show that FLSL yields significant improvements in dense prediction tasks, achieving 44.9 (+2.8)% AP and 46.5% AP in object detection, as well as 40.8 (+2.3)% AP and 42.1% AP in instance segmentation on MS-COCO, using Mask R-CNN with ViT-S/16 and ViT-S/8 as backbone, respectively. FLSL consistently outperforms existing SSL methods across additional benchmarks, including UAV object detection on UAVDT, and video instance segmentation on DAVIS 2017. We conclude by presenting visualization and various ablation studies to better 20 understand the success of FLSL.", "link": "https://arxiv.org/abs/2306.06203"}, {"id": "2306.06213", "date": "Fri, 9 Jun 2023 19:27:24 GMT", "title": "Robust Twin Parametric Margin Support Vector Machine for Multiclass\n\u00a0Classification\n", "authors": ["Renato De Leone", "Francesca Maggioni and Andrea Spinelli\n"], "categories": ["cs.LG", "math.OC\n"], "abstract": "In this paper we present a Twin Parametric-Margin Support Vector Machine (TPMSVM) model to tackle the problem of multiclass classification. In the spirit of one-versus-all paradigm, for each class we construct a classifier by solving a TPMSVM-type model. Once all classifiers have been determined, they are combined into an aggregate decision function. We consider the cases of both linear and nonlinear kernel-induced classifiers. In addition, we robustify the proposed approach through robust optimization techniques. Indeed, in real-world applications observations are subject to measurement errors and noise, affecting the quality of the solutions. Consequently, data uncertainties need to be included within the model in order to prevent low accuracies in the classification process. Preliminary computational experiments on real-world datasets show the good performance of the proposed approach.", "link": "https://arxiv.org/abs/2306.06213"}, {"id": "2306.06247", "date": "Fri, 9 Jun 2023 20:43:19 GMT", "title": "Online Learning with Set-Valued Feedback\n", "authors": ["Vinod Raman", "Unique Subedi", "Ambuj Tewari\n"], "categories": ["cs.LG", "stat.ML\nComments:", "19", "pages\n"], "abstract": "We study a variant of online multiclass classification where the learner predicts a single label but receives a \\textit{set of labels} as feedback. In this model, the learner is penalized for not outputting a label contained in the revealed set. We show that unlike online multiclass learning with single-label feedback, deterministic and randomized online learnability are \\textit{not equivalent} even in the realizable setting with set-valued feedback. Accordingly, we give two new combinatorial dimensions, named the Set Littlestone and Measure Shattering dimension, that tightly characterize deterministic and randomized online learnability respectively in the realizable setting. In addition, we show that the Measure Shattering dimension tightly characterizes online learnability in the agnostic setting. Finally, we show that practical learning settings like online multilabel ranking and online multilabel classification are specific instances of our general online learning framework.", "link": "https://arxiv.org/abs/2306.06247"}, {"id": "2306.06252", "date": "Fri, 9 Jun 2023 20:46:55 GMT", "title": "Feature Programming for Multivariate Time Series Prediction\n", "authors": ["Alex Reneau", "Jerry Yao-Chieh Hu", "Chenwei Xu", "Weijian Li", "Ammar Gilani,\n\u00a0Han Liu\n"], "categories": ["cs.LG", "stat.ML\nComments:", "21", "pages,", "accepted", "to", "ICML2023.", "Code", "is", "available", "at\n\u00a0https://github.com/SirAlex900/FeatureProgramming\n"], "abstract": "We introduce the concept of programmable feature engineering for time series modeling and propose a feature programming framework. This framework generates large amounts of predictive features for noisy multivariate time series while allowing users to incorporate their inductive bias with minimal effort. The key motivation of our framework is to view any multivariate time series as a cumulative sum of fine-grained trajectory increments, with each increment governed by a novel spin-gas dynamical Ising model. This fine-grained perspective motivates the development of a parsimonious set of operators that summarize multivariate time series in an abstract fashion, serving as the foundation for large-scale automated feature engineering. Numerically, we validate the efficacy of our method on several synthetic and real-world noisy time series datasets.", "link": "https://arxiv.org/abs/2306.06252"}, {"id": "2306.06253", "date": "Fri, 9 Jun 2023 20:52:16 GMT", "title": "Decision Stacks: Flexible Reinforcement Learning via Modular Generative\n\u00a0Models\n", "authors": ["Siyan Zhao and Aditya Grover\n"], "categories": ["cs.LG", "cs.AI\n"], "abstract": "Reinforcement learning presents an attractive paradigm to reason about several distinct aspects of sequential decision making, such as specifying complex goals, planning future observations and actions, and critiquing their utilities. However, the combined integration of these capabilities poses competing algorithmic challenges in retaining maximal expressivity while allowing for flexibility in modeling choices for efficient learning and inference. We present Decision Stacks, a generative framework that decomposes goal-conditioned policy agents into 3 generative modules. These modules simulate the temporal evolution of observations, rewards, and actions via independent generative models that can be learned in parallel via teacher forcing. Our framework guarantees both expressivity and flexibility in designing individual modules to account for key factors such as architectural bias, optimization objective and dynamics, transferrability across domains, and inference speed. Our empirical results demonstrate the effectiveness of Decision Stacks for offline policy optimization for several MDP and POMDP environments, outperforming existing methods and enabling flexible generative decision making.", "link": "https://arxiv.org/abs/2306.06253"}, {"id": "2306.06265", "date": "Fri, 9 Jun 2023 21:26:57 GMT", "title": "Near-optimal Conservative Exploration in Reinforcement Learning under\n\u00a0Episode-wise Constraints\n", "authors": ["Donghao Li", "Ruiquan Huang", "Cong Shen", "Jing Yang\n"], "categories": ["cs.LG", "stat.ML\nComments:", "Accepted", "by", "ICML2023\n"], "abstract": "This paper investigates conservative exploration in reinforcement learning where the performance of the learning agent is guaranteed to be above a certain threshold throughout the learning process. It focuses on the tabular episodic Markov Decision Process (MDP) setting that has finite states and actions. With the knowledge of an existing safe baseline policy, an algorithm termed as StepMix is proposed to balance the exploitation and exploration while ensuring that the conservative constraint is never violated in each episode with high probability. StepMix features a unique design of a mixture policy that adaptively and smoothly interpolates between the baseline policy and the optimistic policy. Theoretical analysis shows that StepMix achieves near-optimal regret order as in the constraint-free setting, indicating that obeying the stringent episode-wise conservative constraint does not compromise the learning performance. Besides, a randomization-based EpsMix algorithm is also proposed and shown to achieve the same performance as StepMix. The algorithm design and theoretical analysis are further extended to the setting where the baseline policy is not given a priori but must be learned from an offline dataset, and it is proved that similar conservative guarantee and regret can be achieved if the offline dataset is sufficiently large. Experiment results corroborate the theoretical analysis and demonstrate the effectiveness of the proposed conservative exploration strategies.", "link": "https://arxiv.org/abs/2306.06265"}, {"id": "2306.06327", "date": "Sat, 10 Jun 2023 00:55:38 GMT", "title": "Any-dimensional equivariant neural networks\n", "authors": ["Eitan Levin and Mateo D\\'iaz\n"], "categories": ["cs.LG", "math.RT", "stat.ML\nComments:", "18", "pages,", "2", "figures\n"], "abstract": "Traditional supervised learning aims to learn an unknown mapping by fitting a function to a set of input-output pairs with a fixed dimension. The fitted function is then defined on inputs of the same dimension. However, in many settings, the unknown mapping takes inputs in any dimension; examples include graph parameters defined on graphs of any size and physics quantities defined on an arbitrary number of particles. We leverage a newly-discovered phenomenon in algebraic topology, called representation stability, to define equivariant neural networks that can be trained with data in a fixed dimension and then extended to accept inputs in any dimension. Our approach is user-friendly, requiring only the network architecture and the groups for equivariance, and can be combined with any training procedure. We provide a simple open-source implementation of our methods and offer preliminary numerical experiments.", "link": "https://arxiv.org/abs/2306.06327"}, {"id": "2306.06335", "date": "Sat, 10 Jun 2023 02:33:34 GMT", "title": "How to Learn and Generalize From Three Minutes of Data:\n\u00a0Physics-Constrained and Uncertainty-Aware Neural Stochastic Differential\n\u00a0Equations\n", "authors": ["Franck Djeumou and Cyrus Neary and Ufuk Topcu\n"], "categories": ["cs.LG", "cs.RO", "cs.SY", "eess.SY\nComments:", "Initial", "submission", "to", "CoRL", "2023\n"], "abstract": "We present a framework and algorithms to learn controlled dynamics models using neural stochastic differential equations (SDEs) -- SDEs whose drift and diffusion terms are both parametrized by neural networks. We construct the drift term to leverage a priori physics knowledge as inductive bias, and we design the diffusion term to represent a distance-aware estimate of the uncertainty in the learned model's predictions -- it matches the system's underlying stochasticity when evaluated on states near those from the training dataset, and it predicts highly stochastic dynamics when evaluated on states beyond the training regime. The proposed neural SDEs can be evaluated quickly enough for use in model predictive control algorithms, or they can be used as simulators for model-based reinforcement learning. Furthermore, they make accurate predictions over long time horizons, even when trained on small datasets that cover limited regions of the state space. We demonstrate these capabilities through experiments on simulated robotic systems, as well as by using them to model and control a hexacopter's flight dynamics: A neural SDE trained using only three minutes of manually collected flight data results in a model-based control policy that accurately tracks aggressive trajectories that push the hexacopter's velocity and Euler angles to nearly double the maximum values observed in the training dataset.", "link": "https://arxiv.org/abs/2306.06335"}, {"id": "2306.06375", "date": "Sat, 10 Jun 2023 07:54:20 GMT", "title": "Optimized Gradient Tracking for Decentralized Online Learning\n", "authors": ["Shivangi Dubey Sharma (1) and Ketan Rajawat (1)", "((1) Indian Institute\n\u00a0of Technology Kanpur)\n"], "categories": ["cs.LG", "eess.SP", "math.OC\nComments:", "30", "pages,", "6", "Figures\n"], "abstract": "This work considers the problem of decentralized online learning, where the goal is to track the optimum of the sum of time-varying functions, distributed across several nodes in a network. The local availability of the functions and their gradients necessitates coordination and consensus among the nodes. We put forth the Generalized Gradient Tracking (GGT) framework that unifies a number of existing approaches, including the state-of-the-art ones. The performance of the proposed GGT algorithm is theoretically analyzed using a novel semidefinite programming-based analysis that yields the desired regret bounds under very general conditions and without requiring the gradient boundedness assumption. The results are applicable to the special cases of GGT, which include various state-of-the-art algorithms as well as new dynamic versions of various classical decentralized algorithms. To further minimize the regret, we consider a condensed version of GGT with only four free parameters. A procedure for offline tuning of these parameters using only the problem parameters is also detailed. The resulting optimized GGT (oGGT) algorithm not only achieves improved dynamic regret bounds, but also outperforms all state-of-the-art algorithms on both synthetic and real-world datasets.", "link": "https://arxiv.org/abs/2306.06375"}, {"id": "2306.06380", "date": "Sat, 10 Jun 2023 08:35:00 GMT", "title": "D2Match: Leveraging Deep Learning and Degeneracy for Subgraph Matching\n", "authors": ["Xuanzhou Liu", "Lin Zhang", "Jiaqi Sun", "Yujiu Yang", "Haiqin Yang\n"], "categories": ["cs.LG", "cs.AI\nComments:", "Accepted", "by", "icml2023\n"], "abstract": "Subgraph matching is a fundamental building block for graph-based applications and is challenging due to its high-order combinatorial nature. Existing studies usually tackle it by combinatorial optimization or learning-based methods. However, they suffer from exponential computational costs or searching the matching without theoretical guarantees. In this paper, we develop D2Match by leveraging the efficiency of Deep learning and Degeneracy for subgraph matching. More specifically, we first prove that subgraph matching can degenerate to subtree matching, and subsequently is equivalent to finding a perfect matching on a bipartite graph. We can then yield an implementation of linear time complexity by the built-in tree-structured aggregation mechanism on graph neural networks. Moreover, circle structures and node attributes can be easily incorporated in D2Match to boost the matching performance. Finally, we conduct extensive experiments to show the superior performance of our D2Match and confirm that our D2Match indeed exploits the subtrees and differs from existing GNNs-based subgraph matching methods that depend on memorizing the data distribution divergence", "link": "https://arxiv.org/abs/2306.06380"}, {"id": "2306.06399", "date": "Sat, 10 Jun 2023 09:52:01 GMT", "title": "Personalized Graph Federated Learning with Differential Privacy\n", "authors": ["Francois Gauthier", "Vinay Chakravarthi Gogineni", "Stefan Werner,\n\u00a0Yih-Fang Huang", "Anthony Kuh\n"], "categories": ["cs.LG", "stat.ML\n"], "abstract": "This paper presents a personalized graph federated learning (PGFL) framework in which distributedly connected servers and their respective edge devices collaboratively learn device or cluster-specific models while maintaining the privacy of every individual device. The proposed approach exploits similarities among different models to provide a more relevant experience for each device, even in situations with diverse data distributions and disproportionate datasets. Furthermore, to ensure a secure and efficient approach to collaborative personalized learning, we study a variant of the PGFL implementation that utilizes differential privacy, specifically zero-concentrated differential privacy, where a noise sequence perturbs model exchanges. Our mathematical analysis shows that the proposed privacy-preserving PGFL algorithm converges to the optimal cluster-specific solution for each cluster in linear time. It also shows that exploiting similarities among clusters leads to an alternative output whose distance to the original solution is bounded, and that this bound can be adjusted by modifying the algorithm's hyperparameters. Further, our analysis shows that the algorithm ensures local differential privacy for all clients in terms of zero-concentrated differential privacy. Finally, the performance of the proposed PGFL algorithm is examined by performing numerical experiments in the context of regression and classification using synthetic data and the MNIST dataset.", "link": "https://arxiv.org/abs/2306.06399"}, {"id": "2306.06446", "date": "Sat, 10 Jun 2023 13:53:41 GMT", "title": "ShiftAddViT: Mixture of Multiplication Primitives Towards Efficient\n\u00a0Vision Transformer\n", "authors": ["Haoran You", "Huihong Shi", "Yipin Guo", "Yingyan (Celine) Lin\n"], "categories": ["cs.LG", "cs.AI\nComments:", "Preprint\n"], "abstract": "Vision Transformers (ViTs) have shown impressive performance and have become a unified backbone for multiple vision tasks. But both attention and multi-layer perceptions (MLPs) in ViTs are not efficient enough due to dense multiplications, resulting in costly training and inference. To this end, we propose to reparameterize the pre-trained ViT with a mixture of multiplication primitives, e.g., bitwise shifts and additions, towards a new type of multiplication-reduced model, dubbed $\\textbf{ShiftAddViT}$, which aims for end-to-end inference speedups on GPUs without the need of training from scratch. Specifically, all $\\texttt{MatMuls}$ among queries, keys, and values are reparameterized by additive kernels, after mapping queries and keys to binary codes in Hamming space. The remaining MLPs or linear layers are then reparameterized by shift kernels. We utilize TVM to implement and optimize those customized kernels for practical hardware deployment on GPUs. We find that such a reparameterization on (quadratic or linear) attention maintains model accuracy, while inevitably leading to accuracy drops when being applied to MLPs. To marry the best of both worlds, we further propose a new mixture of experts (MoE) framework to reparameterize MLPs by taking multiplication or its primitives as experts, e.g., multiplication and shift, and designing a new latency-aware load-balancing loss. Such a loss helps to train a generic router for assigning a dynamic amount of input tokens to different experts according to their latency. In principle, the faster experts run, the larger amount of input tokens are assigned. Extensive experiments consistently validate the effectiveness of our proposed ShiftAddViT, achieving up to $\\textbf{5.18$\\times$}$ latency reductions on GPUs and $\\textbf{42.9%}$ energy savings, while maintaining comparable accuracy as original or efficient ViTs.", "link": "https://arxiv.org/abs/2306.06446"}, {"id": "2306.06482", "date": "Sat, 10 Jun 2023 16:41:18 GMT", "title": "TensorNet: Cartesian Tensor Representations for Efficient Learning of\n\u00a0Molecular Potentials\n", "authors": ["Guillem Simeon", "Gianni de Fabritiis\n"], "categories": ["cs.LG", "physics.chem-ph", "physics.comp-ph\n"], "abstract": "The development of efficient machine learning models for molecular systems representation is becoming crucial in scientific research. We introduce TensorNet, an innovative $\\mathrm{O}(3)$-equivariant message-passing neural network architecture that leverages Cartesian tensor representations. By using Cartesian tensor atomic embeddings, feature mixing is simplified through matrix product operations. Furthermore, the cost-effective decomposition of these tensors into rotation group irreducible representations allows for the separate processing of scalars, vectors, and tensors when necessary. Compared to higher-rank spherical tensor models, TensorNet demonstrates state-of-the-art performance with significantly fewer parameters. For small molecule potential energies, this can be achieved even with a single interaction layer. As a result of all these properties, the model's computational cost is substantially decreased. Moreover, the accurate prediction of vector and tensor molecular quantities on top of potential energies and forces is possible. In summary, TensorNet's framework opens up a new space for the design of state-of-the-art equivariant models.", "link": "https://arxiv.org/abs/2306.06482"}, {"id": "2306.06510", "date": "Sat, 10 Jun 2023 19:04:03 GMT", "title": "Partial Identifiability for Domain Adaptation\n", "authors": ["Lingjing Kong", "Shaoan Xie", "Weiran Yao", "Yujia Zheng", "Guangyi Chen,\n\u00a0Petar Stojanov", "Victor Akinwande", "Kun Zhang\n"], "categories": ["cs.LG", "stat.ML\nComments:", "ICML", "2022\n"], "abstract": "Unsupervised domain adaptation is critical to many real-world applications where label information is unavailable in the target domain. In general, without further assumptions, the joint distribution of the features and the label is not identifiable in the target domain. To address this issue, we rely on the property of minimal changes of causal mechanisms across domains to minimize unnecessary influences of distribution shifts. To encode this property, we first formulate the data-generating process using a latent variable model with two partitioned latent subspaces: invariant components whose distributions stay the same across domains and sparse changing components that vary across domains. We further constrain the domain shift to have a restrictive influence on the changing components. Under mild conditions, we show that the latent variables are partially identifiable, from which it follows that the joint distribution of data and labels in the target domain is also identifiable. Given the theoretical insights, we propose a practical domain adaptation framework called iMSDA. Extensive experimental results reveal that iMSDA outperforms state-of-the-art domain adaptation algorithms on benchmark datasets, demonstrating the effectiveness of our framework.", "link": "https://arxiv.org/abs/2306.06510"}, {"id": "2306.06522", "date": "Sat, 10 Jun 2023 21:17:42 GMT", "title": "TS-MoCo: Time-Series Momentum Contrast for Self-Supervised Physiological\n\u00a0Representation Learning\n", "authors": ["Philipp Hallgarten", "David Bethge", "Ozan \\\"Ozdenizci", "Tobias\n\u00a0Grosse-Puppendahl", "Enkelejda Kasneci\n"], "categories": ["cs.LG", "cs.HC", "eess.SP\nComments:", "31ST", "EUROPEAN", "SIGNAL", "PROCESSING", "CONFERENCE", "(EUSIPCO)\n"], "abstract": "Limited availability of labeled physiological data often prohibits the use of powerful supervised deep learning models in the biomedical machine intelligence domain. We approach this problem and propose a novel encoding framework that relies on self-supervised learning with momentum contrast to learn representations from multivariate time-series of various physiological domains without needing labels. Our model uses a transformer architecture that can be easily adapted to classification problems by optimizing a linear output classification layer. We experimentally evaluate our framework using two publicly available physiological datasets from different domains, i.e., human activity recognition from embedded inertial sensory and emotion recognition from electroencephalography. We show that our self-supervised learning approach can indeed learn discriminative features which can be exploited in downstream classification tasks. Our work enables the development of domain-agnostic intelligent systems that can effectively analyze multivariate time-series data from physiological domains.", "link": "https://arxiv.org/abs/2306.06522"}, {"id": "2306.06523", "date": "Sat, 10 Jun 2023 21:18:31 GMT", "title": "Finding Hamiltonian cycles with graph neural networks\n", "authors": ["Filip Bosni\\'c", "Mile \\v{S}iki\\'c\n"], "categories": ["cs.LG", "cs.SI\nComments:", "6", "pages,", "5", "figures\nACM-class:", "I.2.8\n"], "abstract": "We train a small message-passing graph neural network to predict Hamiltonian cycles on Erd\\H{o}s-R\\'enyi random graphs in a critical regime. It outperforms existing hand-crafted heuristics after about 2.5 hours of training on a single GPU. Our findings encourage an alternative approach to solving computationally demanding (NP-hard) problems arising in practice. Instead of devising a heuristic by hand, one can train it end-to-end using a neural network. This has several advantages. Firstly, it is relatively quick and requires little problem-specific knowledge. Secondly, the network can adjust to the distribution of training samples, improving the performance on the most relevant problem instances. The model is trained using supervised learning on artificially created problem instances; this training procedure does not use an existing solver to produce the supervised signal. Finally, the model generalizes well to larger graph sizes and retains reasonable performance even on graphs eight times the original size.", "link": "https://arxiv.org/abs/2306.06523"}, {"id": "2306.06534", "date": "Sat, 10 Jun 2023 22:24:42 GMT", "title": "K-Tensors: Clustering Positive Semi-Definite Matrices\n", "authors": ["Hanchao Zhang", "Thaddeus Tarpey\n"], "categories": ["cs.LG", "stat.ME\nComments:", "10", "pages,", "2", "figures\n"], "abstract": "This paper introduces a novel self-consistency clustering algorithm (K-Tensors) designed for positive-semidefinite matrices based on their eigenstructures. As positive semi-definite matrices can be represented as ellipses or ellipsoids in $\\Re^p$, $p \\ge 2$, it is critical to maintain their structural information to perform effective clustering. However, traditional clustering algorithms often vectorize the matrices, resulting in a loss of essential structural information. To address this issue, we propose a distance metric that is specifically based on the structural information of positive semi-definite matrices. This distance metric enables the clustering algorithm to consider the differences between positive semi-definite matrices and their projection onto the common space spanned by a set of positive semi-definite matrices. This innovative approach to clustering positive semi-definite matrices has broad applications in several domains, including financial and biomedical research, such as analyzing functional connectivity data. By maintaining the structural information of positive semi-definite matrices, our proposed algorithm promises to cluster the positive semi-definite matrices in a more meaningful way, thereby facilitating deeper insights into the underlying data in various applications.", "link": "https://arxiv.org/abs/2306.06534"}, {"id": "2306.06545", "date": "Sun, 11 Jun 2023 00:06:57 GMT", "title": "A Probabilistic Framework for Modular Continual Learning\n", "authors": ["Lazar Valkov", "Akash Srivastava", "Swarat Chaudhuri", "Charles Sutton\n"], "categories": ["cs.LG", "stat.ML\n"], "abstract": "Modular approaches, which use a different composition of modules for each problem and avoid forgetting by design, have been shown to be a promising direction in continual learning (CL). However, searching through the large, discrete space of possible module compositions is a challenge because evaluating a composition's performance requires a round of neural network training. To address this challenge, we develop a modular CL framework, called PICLE, that accelerates search by using a probabilistic model to cheaply compute the fitness of each composition. The model combines prior knowledge about good module compositions with dataset-specific information. Its use is complemented by splitting up the search space into subsets, such as perceptual and latent subsets. We show that PICLE is the first modular CL algorithm to achieve different types of transfer while scaling to large search spaces. We evaluate it on two benchmark suites designed to capture different desiderata of CL techniques. On these benchmarks, PICLE offers significantly better performance than state-of-the-art CL baselines.", "link": "https://arxiv.org/abs/2306.06545"}, {"id": "2306.06547", "date": "Sun, 11 Jun 2023 00:22:44 GMT", "title": "Local-to-global Perspectives on Graph Neural Networks\n", "authors": ["Chen Cai\n"], "categories": ["cs.LG", "stat.ML\nComments:", "arXiv", "admin", "note:", "substantial", "text", "overlap", "with", "arXiv:2201.10129,\n\u00a0arXiv:2301.11956,", "arXiv:2102.01350\n"], "abstract": "We present a local-to-global perspective on graph neural networks (GNN), which are categorized as local Message Passing Neural Networks (MPNN) and global Graph Transformer. We present three pieces of work: 1) study the convergence property of a type of global GNN, Invariant Graph Networks, 2) connect the local MPNN and global Graph Transformer, and 3) use local MPNN for graph coarsening, a common subroutine used in global modeling.", "link": "https://arxiv.org/abs/2306.06547"}, {"id": "2306.06559", "date": "Sun, 11 Jun 2023 02:08:59 GMT", "title": "Straggler-Resilient Decentralized Learning via Adaptive Asynchronous\n\u00a0Updates\n", "authors": ["Guojun Xiong", "Gang Yan", "Shiqiang Wang", "Jian Li\n"], "categories": ["cs.LG", "cs.DC\nComments:", "32", "pages\n"], "abstract": "With the increasing demand for large-scale training of machine learning models, fully decentralized optimization methods have recently been advocated as alternatives to the popular parameter server framework. In this paradigm, each worker maintains a local estimate of the optimal parameter vector, and iteratively updates it by waiting and averaging all estimates obtained from its neighbors, and then corrects it on the basis of its local dataset. However, the synchronization phase is sensitive to stragglers. An efficient way to mitigate this effect is to consider asynchronous updates, where each worker computes stochastic gradients and communicates with other workers at its own pace. Unfortunately, fully asynchronous updates suffer from staleness of the stragglers' parameters. To address these limitations, we propose a fully decentralized algorithm DSGD-AAU with adaptive asynchronous updates via adaptively determining the number of neighbor workers for each worker to communicate with. We show that DSGD-AAU achieves a linear speedup for convergence (i.e., convergence performance increases linearly with respect to the number of workers). Experimental results on a suite of datasets and deep neural network models are provided to verify our theoretical results.", "link": "https://arxiv.org/abs/2306.06559"}, {"id": "2306.06569", "date": "Sun, 11 Jun 2023 03:02:10 GMT", "title": "Policy Regularization with Dataset Constraint for Offline Reinforcement\n\u00a0Learning\n", "authors": ["Yuhang Ran", "Yi-Chen Li", "Fuxiang Zhang", "Zongzhang Zhang", "Yang Yu\n"], "categories": ["cs.LG", "cs.AI\nComments:", "Accepted", "to", "ICML", "2023\n"], "abstract": "We consider the problem of learning the best possible policy from a fixed dataset, known as offline Reinforcement Learning (RL). A common taxonomy of existing offline RL works is policy regularization, which typically constrains the learned policy by distribution or support of the behavior policy. However, distribution and support constraints are overly conservative since they both force the policy to choose similar actions as the behavior policy when considering particular states. It will limit the learned policy's performance, especially when the behavior policy is sub-optimal. In this paper, we find that regularizing the policy towards the nearest state-action pair can be more effective and thus propose Policy Regularization with Dataset Constraint (PRDC). When updating the policy in a given state, PRDC searches the entire dataset for the nearest state-action sample and then restricts the policy with the action of this sample. Unlike previous works, PRDC can guide the policy with proper behaviors from the dataset, allowing it to choose actions that do not appear in the dataset along with the given state. It is a softer constraint but still keeps enough conservatism from out-of-distribution actions. Empirical evidence and theoretical analysis show that PRDC can alleviate offline RL's fundamentally challenging value overestimation issue with a bounded performance gap. Moreover, on a set of locomotion and navigation tasks, PRDC achieves state-of-the-art performance compared with existing methods. Code is available at https://github.com/LAMDA-RL/PRDC", "link": "https://arxiv.org/abs/2306.06569"}, {"id": "2306.06591", "date": "Sun, 11 Jun 2023 04:58:47 GMT", "title": "Blocked Cross-Validation: A Precise and Efficient Method for\n\u00a0Hyperparameter Tuning\n", "authors": ["Giovanni Maria Merola\n"], "categories": ["cs.LG", "stat.ME\nComments:", "28", "pages,", "7", "figures\nMSC-class:", "62-00\nACM-class:", "G.3\n"], "abstract": "Hyperparameter tuning plays a crucial role in optimizing the performance of predictive learners. Cross--validation (CV) is a widely adopted technique for estimating the error of different hyperparameter settings. Repeated cross-validation (RCV) has been commonly employed to reduce the variability of CV errors. In this paper, we introduce a novel approach called blocked cross-validation (BCV), where the repetitions are blocked with respect to both CV partition and the random behavior of the learner. Theoretical analysis and empirical experiments demonstrate that BCV provides more precise error estimates compared to RCV, even with a significantly reduced number of runs. We present extensive examples using real--world data sets to showcase the effectiveness and efficiency of BCV in hyperparameter tuning. Our results indicate that BCV outperforms RCV in hyperparameter tuning, achieving greater precision with fewer computations.", "link": "https://arxiv.org/abs/2306.06591"}, {"id": "2306.06599", "date": "Sun, 11 Jun 2023 06:27:06 GMT", "title": "Variational Imbalanced Regression\n", "authors": ["Ziyan Wang", "Hao Wang\n"], "categories": ["cs.LG", "stat.ML\n"], "abstract": "Existing regression models tend to fall short in both accuracy and uncertainty estimation when the label distribution is imbalanced. In this paper, we propose a probabilistic deep learning model, dubbed variational imbalanced regression (VIR), which not only performs well in imbalanced regression but naturally produces reasonable uncertainty estimation as a byproduct. Different from typical variational autoencoders assuming I.I.D. representations (a data point's representation is not directly affected by other data points), our VIR borrows data with similar regression labels to compute the latent representation's variational distribution; furthermore, different from deterministic regression models producing point estimates, VIR predicts the entire normal-inverse-gamma distributions and modulates the associated conjugate distributions to impose probabilistic reweighting on the imbalanced data, thereby providing better uncertainty estimation. Experiments in several real-world datasets show that our VIR can outperform state-of-the-art imbalanced regression models in terms of both accuracy and uncertainty estimation.", "link": "https://arxiv.org/abs/2306.06599"}, {"id": "2306.06611", "date": "Sun, 11 Jun 2023 07:28:35 GMT", "title": "Learning the Positions in CountSketch\n", "authors": ["Yi Li", "Honghao Lin", "Simin Liu", "Ali Vakilian", "David P. Woodruff\n"], "categories": ["cs.LG", "cs.DS\nComments:", "Merging", "of", "arXiv:2007.09890", "and", "arXiv:2102.12317", "with", "additional\n\u00a0results.", "Published", "as", "a", "conference", "paper", "at", "ICLR", "2023\n"], "abstract": "We consider sketching algorithms which first compress data by multiplication with a random sketch matrix, and then apply the sketch to quickly solve an optimization problem, e.g., low-rank approximation and regression. In the learning-based sketching paradigm proposed by~\\cite{indyk2019learning}, the sketch matrix is found by choosing a random sparse matrix, e.g., CountSketch, and then the values of its non-zero entries are updated by running gradient descent on a training data set. Despite the growing body of work on this paradigm, a noticeable omission is that the locations of the non-zero entries of previous algorithms were fixed, and only their values were learned. In this work, we propose the first learning-based algorithms that also optimize the locations of the non-zero entries. Our first proposed algorithm is based on a greedy algorithm. However, one drawback of the greedy algorithm is its slower training time. We fix this issue and propose approaches for learning a sketching matrix for both low-rank approximation and Hessian approximation for second order optimization. The latter is helpful for a range of constrained optimization problems, such as LASSO and matrix estimation with a nuclear norm constraint. Both approaches achieve good accuracy with a fast running time. Moreover, our experiments suggest that our algorithm can still reduce the error significantly even if we only have a very limited number of training matrices.", "link": "https://arxiv.org/abs/2306.06611"}, {"id": "2306.06613", "date": "Sun, 11 Jun 2023 07:46:22 GMT", "title": "Parameter-free version of Adaptive Gradient Methods for Strongly-Convex\n\u00a0Functions\n", "authors": ["Deepak Gouda", "Hassan Naveed", "Salil Kamath\n"], "categories": ["cs.LG", "math.OC\n"], "abstract": "The optimal learning rate for adaptive gradient methods applied to {\\lambda}-strongly convex functions relies on the parameters {\\lambda} and learning rate {\\eta}. In this paper, we adapt a universal algorithm along the lines of Metagrad, to get rid of this dependence on {\\lambda} and {\\eta}. The main idea is to concurrently run multiple experts and combine their predictions to a master algorithm. This master enjoys O(d log T) regret bounds.", "link": "https://arxiv.org/abs/2306.06613"}, {"id": "2306.06626", "date": "Sun, 11 Jun 2023 08:54:12 GMT", "title": "On Kinetic Optimal Probability Paths for Generative Models\n", "authors": ["Neta Shaul", "Ricky T. Q. Chen", "Maximilian Nickel", "Matt Le", "Yaron Lipman\n"], "categories": ["cs.LG", "stat.ML\n"], "abstract": "Recent successful generative models are trained by fitting a neural network to an a-priori defined tractable probability density path taking noise to training examples. In this paper we investigate the space of Gaussian probability paths, which includes diffusion paths as an instance, and look for an optimal member in some useful sense. In particular, minimizing the Kinetic Energy (KE) of a path is known to make particles' trajectories simple, hence easier to sample, and empirically improve performance in terms of likelihood of unseen data and sample generation quality. We investigate Kinetic Optimal (KO) Gaussian paths and offer the following observations: (i) We show the KE takes a simplified form on the space of Gaussian paths, where the data is incorporated only through a single, one dimensional scalar function, called the \\emph{data separation function}. (ii) We characterize the KO solutions with a one dimensional ODE. (iii) We approximate data-dependent KO paths by approximating the data separation function and minimizing the KE. (iv) We prove that the data separation function converges to $1$ in the general case of arbitrary normalized dataset consisting of $n$ samples in $d$ dimension as $n/\\sqrt{d}\\rightarrow 0$. A consequence of this result is that the Conditional Optimal Transport (Cond-OT) path becomes \\emph{kinetic optimal} as $n/\\sqrt{d}\\rightarrow 0$. We further support this theory with empirical experiments on ImageNet.", "link": "https://arxiv.org/abs/2306.06626"}, {"id": "2306.06642", "date": "Sun, 11 Jun 2023 10:32:44 GMT", "title": "Well-Calibrated Probabilistic Predictive Maintenance using Venn-Abers\n", "authors": ["Ulf Johansson", "Tuwe L\\\"ofstr\\\"om", "and Cecilia S\\\"onstr\\\"od\n"], "categories": ["cs.LG", "cs.AI\n"], "abstract": "When using machine learning for fault detection, a common problem is the fact that most data sets are very unbalanced, with the minority class (a fault) being the interesting one. In this paper, we investigate the usage of Venn-Abers predictors, looking specifically at the effect on the minority class predictions. A key property of Venn-Abers predictors is that they output well-calibrated probability intervals. In the experiments, we apply Venn-Abers calibration to decision trees, random forests and XGBoost models, showing how both overconfident and underconfident models are corrected. In addition, the benefit of using the valid probability intervals produced by Venn-Abers for decision support is demonstrated. When using techniques producing opaque underlying models, e.g., random forest and XGBoost, each prediction will consist of not only the label, but also a valid probability interval, where the width is an indication of the confidence in the estimate. Adding Venn-Abers on top of a decision tree allows inspection and analysis of the model, to understand both the underlying relationship, and finding out in which parts of feature space that the model is accurate and/or confident.", "link": "https://arxiv.org/abs/2306.06642"}, {"id": "2306.06712", "date": "Sun, 11 Jun 2023 16:02:14 GMT", "title": "Neural Architecture Design and Robustness: A Dataset\n", "authors": ["Steffen Jung", "Jovita Lukasik", "Margret Keuper\n"], "categories": ["cs.LG", "cs.CV\nComments:", "ICLR", "2023;", "project", "page:", "http://robustness.vision/\n"], "abstract": "Deep learning models have proven to be successful in a wide range of machine learning tasks. Yet, they are often highly sensitive to perturbations on the input data which can lead to incorrect decisions with high confidence, hampering their deployment for practical use-cases. Thus, finding architectures that are (more) robust against perturbations has received much attention in recent years. Just like the search for well-performing architectures in terms of clean accuracy, this usually involves a tedious trial-and-error process with one additional challenge: the evaluation of a network's robustness is significantly more expensive than its evaluation for clean accuracy. Thus, the aim of this paper is to facilitate better streamlined research on architectural design choices with respect to their impact on robustness as well as, for example, the evaluation of surrogate measures for robustness. We therefore borrow one of the most commonly considered search spaces for neural architecture search for image classification, NAS-Bench-201, which contains a manageable size of 6466 non-isomorphic network designs. We evaluate all these networks on a range of common adversarial attacks and corruption types and introduce a database on neural architecture design and robustness evaluations. We further present three exemplary use cases of this dataset, in which we (i) benchmark robustness measurements based on Jacobian and Hessian matrices for their robustness predictability, (ii) perform neural architecture search on robust accuracies, and (iii) provide an initial analysis of how architectural design choices affect robustness. We find that carefully crafting the topology of a network can have substantial impact on its robustness, where networks with the same parameter count range in mean adversarial robust accuracy from 20%-41%. Code and data is available at http://robustness.vision/.", "link": "https://arxiv.org/abs/2306.06712"}, {"id": "2306.06715", "date": "Sun, 11 Jun 2023 16:30:57 GMT", "title": "FedDec: Peer-to-peer Aided Federated Learning\n", "authors": ["Marina Costantini", "Giovanni Neglia", "and Thrasyvoulos Spyropoulos\n"], "categories": ["cs.LG", "math.OC\nComments:", "14", "pages,", "6", "figures", "in", "png", "or", "pdf", "format\n"], "abstract": "Federated learning (FL) has enabled training machine learning models exploiting the data of multiple agents without compromising privacy. However, FL is known to be vulnerable to data heterogeneity, partial device participation, and infrequent communication with the server, which are nonetheless three distinctive characteristics of this framework. While much of the recent literature has tackled these weaknesses using different tools, only a few works have explored the possibility of exploiting inter-agent communication to improve FL's performance. In this work, we present FedDec, an algorithm that interleaves peer-to-peer communication and parameter averaging (similar to decentralized learning in networks) between the local gradient updates of FL. We analyze the convergence of FedDec under the assumptions of non-iid data distribution, partial device participation, and smooth and strongly convex costs, and show that inter-agent communication alleviates the negative impact of infrequent communication rounds with the server by reducing the dependence on the number of local updates $H$ from $O(H^2)$ to $O(H)$. Furthermore, our analysis reveals that the term improved in the bound is multiplied by a constant that depends on the spectrum of the inter-agent communication graph, and that vanishes quickly the more connected the network is. We confirm the predictions of our theory in numerical simulations, where we show that FedDec converges faster than FedAvg, and that the gains are greater as either $H$ or the connectivity of the network increase.", "link": "https://arxiv.org/abs/2306.06715"}, {"id": "2306.06772", "date": "Sun, 11 Jun 2023 20:56:21 GMT", "title": "Between-Sample Relationship in Learning Tabular Data Using Graph and\n\u00a0Attention Networks\n", "authors": ["Shourav B. Rabbani and Manar D. Samad\n"], "categories": ["cs.LG", "cs.AI\nComments:", "Accepted", "to", "the", "19th", "Int.", "Conf.", "on", "Data", "Science,", "Las", "Vegas,", "NV\n"], "abstract": "Traditional machine learning assumes samples in tabular data to be independent and identically distributed (i.i.d). This assumption may miss useful information within and between sample relationships in representation learning. This paper relaxes the i.i.d assumption to learn tabular data representations by incorporating between-sample relationships for the first time using graph neural networks (GNN). We investigate our hypothesis using several GNNs and state-of-the-art (SOTA) deep attention models to learn the between-sample relationship on ten tabular data sets by comparing them to traditional machine learning methods. GNN methods show the best performance on tabular data with large feature-to-sample ratios. Our results reveal that attention-based GNN methods outperform traditional machine learning on five data sets and SOTA deep tabular learning methods on three data sets. Between-sample learning via GNN and deep attention methods yield the best classification accuracy on seven of the ten data sets. This suggests that the i.i.d assumption may not always hold for most tabular data sets.", "link": "https://arxiv.org/abs/2306.06772"}, {"id": "2306.06788", "date": "Sun, 11 Jun 2023 22:04:28 GMT", "title": "Graph Mixup with Soft Alignments\n", "authors": ["Hongyi Ling", "Zhimeng Jiang", "Meng Liu", "Shuiwang Ji", "Na Zou\n"], "categories": ["cs.LG", "cs.AI\n"], "abstract": "We study graph data augmentation by mixup, which has been used successfully on images. A key operation of mixup is to compute a convex combination of a pair of inputs. This operation is straightforward for grid-like data, such as images, but challenging for graph data. The key difficulty lies in the fact that different graphs typically have different numbers of nodes, and thus there lacks a node-level correspondence between graphs. In this work, we propose S-Mixup, a simple yet effective mixup method for graph classification by soft alignments. Specifically, given a pair of graphs, we explicitly obtain node-level correspondence via computing a soft assignment matrix to match the nodes between two graphs. Based on the soft assignments, we transform the adjacency and node feature matrices of one graph, so that the transformed graph is aligned with the other graph. In this way, any pair of graphs can be mixed directly to generate an augmented graph. We conduct systematic experiments to show that S-Mixup can improve the performance and generalization of graph neural networks (GNNs) on various graph classification tasks. In addition, we show that S-Mixup can increase the robustness of GNNs against noisy labels.", "link": "https://arxiv.org/abs/2306.06788"}, {"id": "2306.06849", "date": "Mon, 12 Jun 2023 03:47:43 GMT", "title": "Mitigating Transformer Overconfidence via Lipschitz Regularization\n", "authors": ["Wenqian Ye", "Yunsheng Ma", "Xu Cao", "Kun Tang\n"], "categories": ["cs.LG", "cs.CV\n"], "abstract": "Though Transformers have achieved promising results in many computer vision tasks, they tend to be over-confident in predictions, as the standard Dot Product Self-Attention (DPSA) can barely preserve distance for the unbounded input domain. In this work, we fill this gap by proposing a novel Lipschitz Regularized Transformer (LRFormer). Specifically, we present a new similarity function with the distance within Banach Space to ensure the Lipschitzness and also regularize the term by a contractive Lipschitz Bound. The proposed method is analyzed with a theoretical guarantee, providing a rigorous basis for its effectiveness and reliability. Extensive experiments conducted on standard vision benchmarks demonstrate that our method outperforms the state-of-the-art single forward pass approaches in prediction, calibration, and uncertainty estimation.", "link": "https://arxiv.org/abs/2306.06849"}, {"id": "2306.06866", "date": "Mon, 12 Jun 2023 04:46:44 GMT", "title": "Generating Synthetic Datasets by Interpolating along Generalized\n\u00a0Geodesics\n", "authors": ["Jiaojiao Fan and David Alvarez-Melis\n"], "categories": ["cs.LG", "cs.AI\nJournal-ref:", "Conference", "on", "Uncertainty", "in", "Artificial", "Intelligence", "(UAI)", "2023\n"], "abstract": "Data for pretraining machine learning models often consists of collections of heterogeneous datasets. Although training on their union is reasonable in agnostic settings, it might be suboptimal when the target domain -- where the model will ultimately be used -- is known in advance. In that case, one would ideally pretrain only on the dataset(s) most similar to the target one. Instead of limiting this choice to those datasets already present in the pretraining collection, here we explore extending this search to all datasets that can be synthesized as `combinations' of them. We define such combinations as multi-dataset interpolations, formalized through the notion of generalized geodesics from optimal transport (OT) theory. We compute these geodesics using a recent notion of distance between labeled datasets, and derive alternative interpolation schemes based on it: using either barycentric projections or optimal transport maps, the latter computed using recent neural OT methods. These methods are scalable, efficient, and -- notably -- can be used to interpolate even between datasets with distinct and unrelated label sets. Through various experiments in transfer learning in computer vision, we demonstrate this is a promising new approach for targeted on-demand dataset synthesis.", "link": "https://arxiv.org/abs/2306.06866"}, {"id": "2306.06894", "date": "Mon, 12 Jun 2023 06:52:04 GMT", "title": "A Generalized Unbiased Risk Estimator for Learning with Augmented\n\u00a0Classes\n", "authors": ["Senlin Shu", "Shuo He", "Haobo Wang", "Hongxin Wei", "Tao Xiang", "Lei Feng\n"], "categories": ["cs.LG", "cs.CV\nComments:", "Accepted", "by", "AAAI", "2023,", "17", "pages,", "4", "tables,", "4", "figures\n"], "abstract": "In contrast to the standard learning paradigm where all classes can be observed in training data, learning with augmented classes (LAC) tackles the problem where augmented classes unobserved in the training data may emerge in the test phase. Previous research showed that given unlabeled data, an unbiased risk estimator (URE) can be derived, which can be minimized for LAC with theoretical guarantees. However, this URE is only restricted to the specific type of one-versus-rest loss functions for multi-class classification, making it not flexible enough when the loss needs to be changed with the dataset in practice. In this paper, we propose a generalized URE that can be equipped with arbitrary loss functions while maintaining the theoretical guarantees, given unlabeled data for LAC. To alleviate the issue of negative empirical risk commonly encountered by previous studies, we further propose a novel risk-penalty regularization term. Experiments demonstrate the effectiveness of our proposed method.", "link": "https://arxiv.org/abs/2306.06894"}, {"id": "2306.06895", "date": "Mon, 12 Jun 2023 07:00:37 GMT", "title": "MPPN: Multi-Resolution Periodic Pattern Network For Long-Term Time\n\u00a0Series Forecasting\n", "authors": ["Xing Wang", "Zhendong Wang", "Kexin Yang", "Junlan Feng", "Zhiyan Song", "Chao\n\u00a0Deng", "Lin zhu\n"], "categories": ["cs.LG", "stat.ML\nComments:", "21", "pages\n"], "abstract": "Long-term time series forecasting plays an important role in various real-world scenarios. Recent deep learning methods for long-term series forecasting tend to capture the intricate patterns of time series by decomposition-based or sampling-based methods. However, most of the extracted patterns may include unpredictable noise and lack good interpretability. Moreover, the multivariate series forecasting methods usually ignore the individual characteristics of each variate, which may affecting the prediction accuracy. To capture the intrinsic patterns of time series, we propose a novel deep learning network architecture, named Multi-resolution Periodic Pattern Network (MPPN), for long-term series forecasting. We first construct context-aware multi-resolution semantic units of time series and employ multi-periodic pattern mining to capture the key patterns of time series. Then, we propose a channel adaptive module to capture the perceptions of multivariate towards different patterns. In addition, we present an entropy-based method for evaluating the predictability of time series and providing an upper bound on the prediction accuracy before forecasting. Our experimental evaluation on nine real-world benchmarks demonstrated that MPPN significantly outperforms the state-of-the-art Transformer-based, decomposition-based and sampling-based methods for long-term series forecasting.", "link": "https://arxiv.org/abs/2306.06895"}, {"id": "2306.06904", "date": "Mon, 12 Jun 2023 07:18:13 GMT", "title": "Differentiable Multi-Fidelity Fusion: Efficient Learning of Physics\n\u00a0Simulations with Neural Architecture Search and Transfer Learning\n", "authors": ["Yuwen Deng", "Wang Kang", "Wei W. Xing\n"], "categories": ["cs.LG", "cs.AI\n"], "abstract": "With rapid progress in deep learning, neural networks have been widely used in scientific research and engineering applications as surrogate models. Despite the great success of neural networks in fitting complex systems, two major challenges still remain: i) the lack of generalization on different problems/datasets, and ii) the demand for large amounts of simulation data that are computationally expensive. To resolve these challenges, we propose the differentiable \\mf (DMF) model, which leverages neural architecture search (NAS) to automatically search the suitable model architecture for different problems, and transfer learning to transfer the learned knowledge from low-fidelity (fast but inaccurate) data to high-fidelity (slow but accurate) model. Novel and latest machine learning techniques such as hyperparameters search and alternate learning are used to improve the efficiency and robustness of DMF. As a result, DMF can efficiently learn the physics simulations with only a few high-fidelity training samples, and outperform the state-of-the-art methods with a significant margin (with up to 58$\\%$ improvement in RMSE) based on a variety of synthetic and practical benchmark problems.", "link": "https://arxiv.org/abs/2306.06904"}, {"id": "2306.06923", "date": "Mon, 12 Jun 2023 07:50:53 GMT", "title": "On the Viability of using LLMs for SW/HW Co-Design: An Example in\n\u00a0Designing CiM DNN Accelerators\n", "authors": ["Zheyu Yan", "Yifan Qin", "Xiaobo Sharon Hu", "Yiyu Shi\n"], "categories": ["cs.LG", "cs.AR\n"], "abstract": "Deep Neural Networks (DNNs) have demonstrated impressive performance across a wide range of tasks. However, deploying DNNs on edge devices poses significant challenges due to stringent power and computational budgets. An effective solution to this issue is software-hardware (SW-HW) co-design, which allows for the tailored creation of DNN models and hardware architectures that optimally utilize available resources. However, SW-HW co-design traditionally suffers from slow optimization speeds because their optimizers do not make use of heuristic knowledge, also known as the ``cold start'' problem. In this study, we present a novel approach that leverages Large Language Models (LLMs) to address this issue. By utilizing the abundant knowledge of pre-trained LLMs in the co-design optimization process, we effectively bypass the cold start problem, substantially accelerating the design process. The proposed method achieves a significant speedup of 25x. This advancement paves the way for the rapid and efficient deployment of DNNs on edge devices.", "link": "https://arxiv.org/abs/2306.06923"}, {"id": "2306.06931", "date": "Mon, 12 Jun 2023 08:11:06 GMT", "title": "Evolving Semantic Prototype Improves Generative Zero-Shot Learning\n", "authors": ["Shiming Chen", "Wenjin Hou", "Ziming Hong", "Xiaohan Ding", "Yibing Song,\n\u00a0Xinge You", "Tongliang Liu", "Kun Zhang\n"], "categories": ["cs.LG", "cs.CV\nComments:", "Accepted", "to", "ICML'23\n"], "abstract": "In zero-shot learning (ZSL), generative methods synthesize class-related sample features based on predefined semantic prototypes. They advance the ZSL performance by synthesizing unseen class sample features for better training the classifier. We observe that each class's predefined semantic prototype (also referred to as semantic embedding or condition) does not accurately match its real semantic prototype. So the synthesized visual sample features do not faithfully represent the real sample features, limiting the classifier training and existing ZSL performance. In this paper, we formulate this mismatch phenomenon as the visual-semantic domain shift problem. We propose a dynamic semantic prototype evolving (DSP) method to align the empirically predefined semantic prototypes and the real prototypes for class-related feature synthesis. The alignment is learned by refining sample features and semantic prototypes in a unified framework and making the synthesized visual sample features approach real sample features. After alignment, synthesized sample features from unseen classes are closer to the real sample features and benefit DSP to improve existing generative ZSL methods by 8.5\\%, 8.0\\%, and 9.7\\% on the standard CUB, SUN AWA2 datasets, the significant performance improvement indicates that evolving semantic prototype explores a virgin field in ZSL.", "link": "https://arxiv.org/abs/2306.06931"}, {"id": "2306.06968", "date": "Mon, 12 Jun 2023 08:53:41 GMT", "title": "Can Forward Gradient Match Backpropagation?\n", "authors": ["Louis Fournier (MLIA)", "St\\'ephane Rivaud (MLIA)", "Eugene Belilovsky\n\u00a0(MILA)", "Michael Eickenberg", "Edouard Oyallon (MLIA)\n"], "categories": ["cs.LG", "cs.CV", "cs.NE", "stat.ML\nJournal-ref:", "Fortieth", "International", "Conference", "on", "Machine", "Learning,", "Jul", "2023,\n\u00a0Honolulu", "(Hawaii),", "USA,", "United", "States\n"], "abstract": "Forward Gradients - the idea of using directional derivatives in forward differentiation mode - have recently been shown to be utilizable for neural network training while avoiding problems generally associated with backpropagation gradient computation, such as locking and memorization requirements. The cost is the requirement to guess the step direction, which is hard in high dimensions. While current solutions rely on weighted averages over isotropic guess vector distributions, we propose to strongly bias our gradient guesses in directions that are much more promising, such as feedback obtained from small, local auxiliary networks. For a standard computer vision neural network, we conduct a rigorous study systematically covering a variety of combinations of gradient targets and gradient guesses, including those previously presented in the literature. We find that using gradients obtained from a local loss as a candidate direction drastically improves on random noise in Forward Gradient methods.", "link": "https://arxiv.org/abs/2306.06968"}, {"id": "2306.06994", "date": "Mon, 12 Jun 2023 09:42:16 GMT", "title": "Correlated Time Series Self-Supervised Representation Learning via\n\u00a0Spatiotemporal Bootstrapping\n", "authors": ["Luxuan Wang", "Lei Bai", "Ziyue Li", "Rui Zhao", "Fugee Tsung\n"], "categories": ["cs.LG", "cs.AI\nComments:", "Accepted", "to", "IEEE", "CASE", "2023\n"], "abstract": "Correlated time series analysis plays an important role in many real-world industries. Learning an efficient representation of this large-scale data for further downstream tasks is necessary but challenging. In this paper, we propose a time-step-level representation learning framework for individual instances via bootstrapped spatiotemporal representation prediction. We evaluated the effectiveness and flexibility of our representation learning framework on correlated time series forecasting and cold-start transferring the forecasting model to new instances with limited data. A linear regression model trained on top of the learned representations demonstrates our model performs best in most cases. Especially compared to representation learning models, we reduce the RMSE, MAE, and MAPE by 37%, 49%, and 48% on the PeMS-BAY dataset, respectively. Furthermore, in real-world metro passenger flow data, our framework demonstrates the ability to transfer to infer future information of new cold-start instances, with gains of 15%, 19%, and 18%. The source code will be released under the GitHub https://github.com/bonaldli/Spatiotemporal-TS-Representation-Learning", "link": "https://arxiv.org/abs/2306.06994"}, {"id": "2306.07001", "date": "Mon, 12 Jun 2023 10:10:57 GMT", "title": "Cancellation-Free Regret Bounds for Lagrangian Approaches in Constrained\n\u00a0Markov Decision Processes\n", "authors": ["Adrian M\\\"uller", "Pragnya Alatur", "Giorgia Ramponi", "Niao He\n"], "categories": ["cs.LG", "stat.ML\n"], "abstract": "Constrained Markov Decision Processes (CMDPs) are one of the common ways to model safe reinforcement learning problems, where the safety objectives are modeled by constraint functions. Lagrangian-based dual or primal-dual algorithms provide efficient methods for learning in CMDPs. For these algorithms, the currently known regret bounds in the finite-horizon setting allow for a \\textit{cancellation of errors}; that is, one can compensate for a constraint violation in one episode with a strict constraint satisfaction in another episode. However, in practical applications, we do not consider such a behavior safe. In this paper, we overcome this weakness by proposing a novel model-based dual algorithm \\textsc{OptAug-CMDP} for tabular finite-horizon CMDPs. Our algorithm is motivated by the augmented Lagrangian method and can be performed efficiently. We show that during $K$ episodes of exploring the CMDP, our algorithm obtains a regret of $\\tilde{O}(\\sqrt{K})$ for both the objective and the constraint violation. Unlike existing Lagrangian approaches, our algorithm achieves this regret without the need for the cancellation of errors.", "link": "https://arxiv.org/abs/2306.07001"}, {"id": "2306.07019", "date": "Mon, 12 Jun 2023 10:46:31 GMT", "title": "Dynamic Causal Graph Convolutional Network for Traffic Prediction\n", "authors": ["Junpeng Lin", "Ziyue Li", "Zhishuai Li", "Lei Bai", "Rui Zhao", "Chen Zhang\n"], "categories": ["cs.LG", "eess.SP\nComments:", "Accepted", "to", "IEEE", "CASE", "2023\n"], "abstract": "Modeling complex spatiotemporal dependencies in correlated traffic series is essential for traffic prediction. While recent works have shown improved prediction performance by using neural networks to extract spatiotemporal correlations, their effectiveness depends on the quality of the graph structures used to represent the spatial topology of the traffic network. In this work, we propose a novel approach for traffic prediction that embeds time-varying dynamic Bayesian network to capture the fine spatiotemporal topology of traffic data. We then use graph convolutional networks to generate traffic forecasts. To enable our method to efficiently model nonlinear traffic propagation patterns, we develop a deep learning-based module as a hyper-network to generate stepwise dynamic causal graphs. Our experimental results on a real traffic dataset demonstrate the superior prediction performance of the proposed method.", "link": "https://arxiv.org/abs/2306.07019"}, {"id": "2306.07024", "date": "Mon, 12 Jun 2023 10:53:50 GMT", "title": "DRCFS: Doubly Robust Causal Feature Selection\n", "authors": ["Francesco Quinzan", "Ashkan Soleymani", "Patrik Jaillet", "Cristian R.\n\u00a0Rojas", "Stefan Bauer\n"], "categories": ["cs.LG", "stat.ME\n"], "abstract": "Knowing the features of a complex system that are highly relevant to a particular target variable is of fundamental interest in many areas of science. Existing approaches are often limited to linear settings, sometimes lack guarantees, and in most cases, do not scale to the problem at hand, in particular to images. We propose DRCFS, a doubly robust feature selection method for identifying the causal features even in nonlinear and high dimensional settings. We provide theoretical guarantees, illustrate necessary conditions for our assumptions, and perform extensive experiments across a wide range of simulated and semi-synthetic datasets. DRCFS significantly outperforms existing state-of-the-art methods, selecting robust features even in challenging highly non-linear and high-dimensional problems.", "link": "https://arxiv.org/abs/2306.07024"}, {"id": "2306.07032", "date": "Mon, 12 Jun 2023 11:24:48 GMT", "title": "Mitigating Prior Errors in Causal Structure Learning: Towards LLM driven\n\u00a0Prior Knowledge\n", "authors": ["Lyuzhou Chen", "Taiyu Ban", "Xiangyu Wang", "Derui Lyu", "Huanhuan Chen\n"], "categories": ["cs.LG", "cs.AI\nComments:", "14", "pages,", "4", "figures\n"], "abstract": "Causal structure learning, a prominent technique for encoding cause and effect relationships among variables, through Bayesian Networks (BNs). Merely recovering causal structures from real-world observed data lacks precision, while the development of Large Language Models (LLM) is opening a new frontier of causality. LLM presents strong capability in discovering causal relationships between variables with the \"text\" inputs defining the investigated variables, leading to a potential new hierarchy and new ladder of causality. We aim an critical issue in the emerging topic of LLM based causal structure learning, to tackle erroneous prior causal statements from LLM, which is seldom considered in the current context of expert dominating prior resources. As a pioneer attempt, we propose a BN learning strategy resilient to prior errors without need of human intervention. Focusing on the edge-level prior, we classify the possible prior errors into three types: order-consistent, order-reversed, and irrelevant, and provide their theoretical impact on the Structural Hamming Distance (SHD) under the presumption of sufficient data. Intriguingly, we discover and prove that only the order-reversed error contributes to an increase in a unique acyclic closed structure, defined as a \"quasi-circle\". Leveraging this insight, a post-hoc strategy is employed to identify the order-reversed prior error by its impact on the increment of \"quasi-circles\". Through empirical evaluation on both real and synthetic datasets, we demonstrate our strategy's robustness against prior errors. Specifically, we highlight its substantial ability to resist order-reversed errors while maintaining the majority of correct prior knowledge.", "link": "https://arxiv.org/abs/2306.07032"}, {"id": "2306.07060", "date": "Mon, 12 Jun 2023 12:14:57 GMT", "title": "Prediction Algorithms Achieving Bayesian Decision Theoretical Optimality\n\u00a0Based on Decision Trees as Data Observation Processes\n", "authors": ["Yuta Nakahara", "Shota Saito", "Naoki Ichijo", "Koki Kazama", "Toshiyasu\n\u00a0Matsushima\n"], "categories": ["cs.LG", "stat.ML\n"], "abstract": "In the field of decision trees, most previous studies have difficulty ensuring the statistical optimality of a prediction of new data and suffer from overfitting because trees are usually used only to represent prediction functions to be constructed from given data. In contrast, some studies, including this paper, used the trees to represent stochastic data observation processes behind given data. Moreover, they derived the statistically optimal prediction, which is robust against overfitting, based on the Bayesian decision theory by assuming a prior distribution for the trees. However, these studies still have a problem in computing this Bayes optimal prediction because it involves an infeasible summation for all division patterns of a feature space, which is represented by the trees and some parameters. In particular, an open problem is a summation with respect to combinations of division axes, i.e., the assignment of features to inner nodes of the tree. We solve this by a Markov chain Monte Carlo method, whose step size is adaptively tuned according to a posterior distribution for the trees.", "link": "https://arxiv.org/abs/2306.07060"}, {"id": "2306.07071", "date": "Mon, 12 Jun 2023 12:35:16 GMT", "title": "Budgeted Multi-Armed Bandits with Asymmetric Confidence Intervals\n", "authors": ["Marco Heyden", "Vadim Arzamasov", "Edouard Fouch\\'e", "Klemens B\\\"ohm\n"], "categories": ["cs.LG", "stat.ML\nMSC-class:", "68T37,", "68T05", "(Primary)", "68W27,", "68Q32", "(Secondary)\nACM-class:", "I.2.6;", "H.4.2;", "G.3\n"], "abstract": "We study the stochastic Budgeted Multi-Armed Bandit (MAB) problem, where a player chooses from $K$ arms with unknown expected rewards and costs. The goal is to maximize the total reward under a budget constraint. A player thus seeks to choose the arm with the highest reward-cost ratio as often as possible. Current state-of-the-art policies for this problem have several issues, which we illustrate. To overcome them, we propose a new upper confidence bound (UCB) sampling policy, $\\omega$-UCB, that uses asymmetric confidence intervals. These intervals scale with the distance between the sample mean and the bounds of a random variable, yielding a more accurate and tight estimation of the reward-cost ratio compared to our competitors. We show that our approach has logarithmic regret and consistently outperforms existing policies in synthetic and real settings.", "link": "https://arxiv.org/abs/2306.07071"}, {"id": "2306.07077", "date": "Mon, 12 Jun 2023 12:43:27 GMT", "title": "Latent Dynamical Implicit Diffusion Processes\n", "authors": ["Mohammad R. Rezaei\n"], "categories": ["cs.LG", "stat.ML\n"], "abstract": "Latent dynamical models are commonly used to learn the distribution of a latent dynamical process that represents a sequence of noisy data samples. However, producing samples from such models with high fidelity is challenging due to the complexity and variability of latent and observation dynamics. Recent advances in diffusion-based generative models, such as DDPM and NCSN, have shown promising alternatives to state-of-the-art latent generative models, such as Neural ODEs, RNNs, and Normalizing flow networks, for generating high-quality sequential samples from a prior distribution. However, their application in modeling sequential data with latent dynamical models is yet to be explored. Here, we propose a novel latent variable model named latent dynamical implicit diffusion processes (LDIDPs), which utilizes implicit diffusion processes to sample from dynamical latent processes and generate sequential observation samples accordingly. We tested LDIDPs on synthetic and simulated neural decoding problems. We demonstrate that LDIDPs can accurately learn the dynamics over latent dimensions. Furthermore, the implicit sampling method allows for the computationally efficient generation of high-quality sequential data samples from the latent and observation spaces.", "link": "https://arxiv.org/abs/2306.07077"}, {"id": "2306.07098", "date": "Mon, 12 Jun 2023 13:22:06 GMT", "title": "Efficiently Learning the Graph for Semi-supervised Learning\n", "authors": ["Dravyansh Sharma", "Maxwell Jones\n"], "categories": ["cs.LG", "cs.AI\nComments:", "29", "pages,", "9", "figures\n"], "abstract": "Computational efficiency is a major bottleneck in using classic graph-based approaches for semi-supervised learning on datasets with a large number of unlabeled examples. Known techniques to improve efficiency typically involve an approximation of the graph regularization objective, but suffer two major drawbacks - first the graph is assumed to be known or constructed with heuristic hyperparameter values, second they do not provide a principled approximation guarantee for learning over the full unlabeled dataset. Building on recent work on learning graphs for semi-supervised learning from multiple datasets for problems from the same domain, and leveraging techniques for fast approximations for solving linear systems in the graph Laplacian matrix, we propose algorithms that overcome both the above limitations. We show a formal separation in the learning-theoretic complexity of sparse and dense graph families. We further show how to approximately learn the best graphs from the sparse families efficiently using the conjugate gradient method. Our approach can also be used to learn the graph efficiently online with sub-linear regret, under mild smoothness assumptions. Our online learning results are stated generally, and may be useful for approximate and efficient parameter tuning in other problems. We implement our approach and demonstrate significant ($\\sim$10-100x) speedups over prior work on semi-supervised learning with learned graphs on benchmark datasets.", "link": "https://arxiv.org/abs/2306.07098"}, {"id": "2306.07104", "date": "Mon, 12 Jun 2023 13:27:55 GMT", "title": "Unveiling the Hessian's Connection to the Decision Boundary\n", "authors": ["Mahalakshmi Sabanayagam", "Freya Behrens", "Urte Adomaityte", "Anna Dawid\n"], "categories": ["cs.LG", "cond-mat.dis-nn", "stat.ML\nComments:", "14", "pages,", "6", "figures", "+", "18-page", "appendices", "with", "19", "figures.", "Any\n\u00a0feedback", "is", "very", "welcome!", "Code", "is", "available", "at\n\u00a0https://github.com/Shmoo137/Hessian-and-Decision-Boundary\n"], "abstract": "Understanding the properties of well-generalizing minima is at the heart of deep learning research. On the one hand, the generalization of neural networks has been connected to the decision boundary complexity, which is hard to study in the high-dimensional input space. Conversely, the flatness of a minimum has become a controversial proxy for generalization. In this work, we provide the missing link between the two approaches and show that the Hessian top eigenvectors characterize the decision boundary learned by the neural network. Notably, the number of outliers in the Hessian spectrum is proportional to the complexity of the decision boundary. Based on this finding, we provide a new and straightforward approach to studying the complexity of a high-dimensional decision boundary; show that this connection naturally inspires a new generalization measure; and finally, we develop a novel margin estimation technique which, in combination with the generalization measure, precisely identifies minima with simple wide-margin boundaries. Overall, this analysis establishes the connection between the Hessian and the decision boundary and provides a new method to identify minima with simple wide-margin decision boundaries.", "link": "https://arxiv.org/abs/2306.07104"}, {"id": "2306.07125", "date": "Mon, 12 Jun 2023 14:01:30 GMT", "title": "On the Dynamics of Learning Time-Aware Behavior with Recurrent Neural\n\u00a0Networks\n", "authors": ["Peter DelMastro", "Rushiv Arora", "Edward Rietman", "Hava T. Siegelmann\n"], "categories": ["cs.LG", "cs.NE\nComments:", "Main", "paper:", "11", "pages,", "8", "figures.", "Supplemental", "Material:", "6", "pages,", "5\n\u00a0figures,", "1", "table\n"], "abstract": "Recurrent Neural Networks (RNNs) have shown great success in modeling time-dependent patterns, but there is limited research on their learned representations of latent temporal features and the emergence of these representations during training. To address this gap, we use timed automata (TA) to introduce a family of supervised learning tasks modeling behavior dependent on hidden temporal variables whose complexity is directly controllable. Building upon past studies from the perspective of dynamical systems, we train RNNs to emulate temporal flipflops, a new collection of TA that emphasizes the need for time-awareness over long-term memory. We find that these RNNs learn in phases: they quickly perfect any time-independent behavior, but they initially struggle to discover the hidden time-dependent features. In the case of periodic \"time-of-day\" aware automata, we show that the RNNs learn to switch between periodic orbits that encode time modulo the period of the transition rules. We subsequently apply fixed point stability analysis to monitor changes in the RNN dynamics during training, and we observe that the learning phases are separated by a bifurcation from which the periodic behavior emerges. In this way, we demonstrate how dynamical systems theory can provide insights into not only the learned representations of these models, but also the dynamics of the learning process itself. We argue that this style of analysis may provide insights into the training pathologies of recurrent architectures in contexts outside of time-awareness.", "link": "https://arxiv.org/abs/2306.07125"}, {"id": "2306.07163", "date": "Mon, 12 Jun 2023 14:50:21 GMT", "title": "General Transformation for Consistent Online Approximation Algorithms\n", "authors": ["Jing Dong", "Yuichi Yoshida\n"], "categories": ["cs.LG", "stat.ML\n"], "abstract": "We introduce a transformation framework that can be utilized to develop online algorithms with low $\\epsilon$-approximate regret in the random-order model from offline approximation algorithms. We first give a general reduction theorem that transforms an offline approximation algorithm with low average sensitivity to an online algorithm with low $\\epsilon$-approximate regret. We then demonstrate that offline approximation algorithms can be transformed into a low-sensitivity version using a coreset construction method. To showcase the versatility of our approach, we apply it to various problems, including online $(k,z)$-clustering, online matrix approximation, and online regression, and successfully achieve polylogarithmic $\\epsilon$-approximate regret for each problem. Moreover, we show that in all three cases, our algorithm also enjoys low inconsistency, which may be desired in some online applications.", "link": "https://arxiv.org/abs/2306.07163"}, {"id": "2306.07171", "date": "Mon, 12 Jun 2023 15:09:13 GMT", "title": "Shapley Value on Probabilistic Classifiers\n", "authors": ["Xiang Li and Haocheng Xia and Jinfei Liu\n"], "categories": ["cs.LG", "cs.DB\n"], "abstract": "Data valuation has become an increasingly significant discipline in data science due to the economic value of data. In the context of machine learning (ML), data valuation methods aim to equitably measure the contribution of each data point to the utility of an ML model. One prevalent method is Shapley value, which helps identify data points that are beneficial or detrimental to an ML model. However, traditional Shapley-based data valuation methods may not effectively distinguish between beneficial and detrimental training data points for probabilistic classifiers. In this paper, we propose Probabilistic Shapley (P-Shapley) value by constructing a probability-wise utility function that leverages the predicted class probabilities of probabilistic classifiers rather than binarized prediction results in the traditional Shapley value. We also offer several activation functions for confidence calibration to effectively quantify the marginal contribution of each data point to the probabilistic classifiers. Extensive experiments on four real-world datasets demonstrate the effectiveness of our proposed P-Shapley value in evaluating the importance of data for building a high-usability and trustworthy ML model.", "link": "https://arxiv.org/abs/2306.07171"}, {"id": "2306.07176", "date": "Mon, 12 Jun 2023 15:15:00 GMT", "title": "Unbalanced Optimal Transport meets Sliced-Wasserstein\n", "authors": ["Thibault S\\'ejourn\\'e", "Cl\\'ement Bonet", "Kilian Fatras", "Kimia Nadjahi,\n\u00a0Nicolas Courty\n"], "categories": ["cs.LG", "math.OC\n"], "abstract": "Optimal transport (OT) has emerged as a powerful framework to compare probability measures, a fundamental task in many statistical and machine learning problems. Substantial advances have been made over the last decade in designing OT variants which are either computationally and statistically more efficient, or more robust to the measures and datasets to compare. Among them, sliced OT distances have been extensively used to mitigate optimal transport's cubic algorithmic complexity and curse of dimensionality. In parallel, unbalanced OT was designed to allow comparisons of more general positive measures, while being more robust to outliers. In this paper, we propose to combine these two concepts, namely slicing and unbalanced OT, to develop a general framework for efficiently comparing positive measures. We propose two new loss functions based on the idea of slicing unbalanced OT, and study their induced topology and statistical properties. We then develop a fast Frank-Wolfe-type algorithm to compute these loss functions, and show that the resulting methodology is modular as it encompasses and extends prior related work. We finally conduct an empirical analysis of our loss functions and methodology on both synthetic and real datasets, to illustrate their relevance and applicability.", "link": "https://arxiv.org/abs/2306.07176"}, {"id": "2306.07179", "date": "Mon, 12 Jun 2023 15:21:02 GMT", "title": "Benchmarking Neural Network Training Algorithms\n", "authors": ["George E. Dahl", "Frank Schneider", "Zachary Nado", "Naman Agarwal,\n\u00a0Chandramouli Shama Sastry", "Philipp Hennig", "Sourabh Medapati", "Runa\n\u00a0Eschenhagen", "Priya Kasimbeg", "Daniel Suo", "Juhan Bae", "Justin Gilmer", "Abel L.\n\u00a0Peirson", "Bilal Khan", "Rohan Anil", "Mike Rabbat", "Shankar Krishnan", "Daniel\n\u00a0Snider", "Ehsan Amid", "Kongtao Chen", "Chris J. Maddison", "Rakshith Vasudev", "Michal\n\u00a0Badura", "Ankush Garg", "Peter Mattson\n"], "categories": ["cs.LG", "stat.ML\nComments:", "102", "pages,", "8", "figures,", "41", "tables\n"], "abstract": "Training algorithms, broadly construed, are an essential part of every deep learning pipeline. Training algorithm improvements that speed up training across a wide variety of workloads (e.g., better update rules, tuning protocols, learning rate schedules, or data selection schemes) could save time, save computational resources, and lead to better, more accurate, models. Unfortunately, as a community, we are currently unable to reliably identify training algorithm improvements, or even determine the state-of-the-art training algorithm. In this work, using concrete experiments, we argue that real progress in speeding up training requires new benchmarks that resolve three basic challenges faced by empirical comparisons of training algorithms: (1) how to decide when training is complete and precisely measure training time, (2) how to handle the sensitivity of measurements to exact workload details, and (3) how to fairly compare algorithms that require hyperparameter tuning. In order to address these challenges, we introduce a new, competitive, time-to-result benchmark using multiple workloads running on fixed hardware, the AlgoPerf: Training Algorithms benchmark. Our benchmark includes a set of workload variants that make it possible to detect benchmark submissions that are more robust to workload changes than current widely-used methods. Finally, we evaluate baseline submissions constructed using various optimizers that represent current practice, as well as other optimizers that have recently received attention in the literature. These baseline results collectively demonstrate the feasibility of our benchmark, show that non-trivial gaps between methods exist, and set a provisional state-of-the-art for future benchmark submissions to try and surpass.", "link": "https://arxiv.org/abs/2306.07179"}, {"id": "2306.07188", "date": "Mon, 12 Jun 2023 15:44:58 GMT", "title": "Fair Learning to Rank with Distribution-free Risk Control\n", "authors": ["Ruocheng Guo", "Jean-Fran\\c{c}ois Ton", "Yang Liu\n"], "categories": ["cs.LG", "cs.CY", "cs.IR\nComments:", "12", "pages,", "4", "figures\n"], "abstract": "Learning to Rank (LTR) methods are vital in online economies, affecting users and item providers. Fairness in LTR models is crucial to allocate exposure proportionally to item relevance. The deterministic ranking model can lead to unfair exposure distribution when items with the same relevance receive slightly different scores. Stochastic LTR models, incorporating the Plackett-Luce (PL) model, address fairness issues but have limitations in computational cost and performance guarantees. To overcome these limitations, we propose FairLTR-RC, a novel post-hoc model-agnostic method. FairLTR-RC leverages a pretrained scoring function to create a stochastic LTR model, eliminating the need for expensive training. Furthermore, FairLTR-RC provides finite-sample guarantees on a user-specified utility using distribution-free risk control framework. By additionally incorporating the Thresholded PL (TPL) model, we are able to achieve an effective trade-off between utility and fairness. Experimental results on several benchmark datasets demonstrate that FairLTR-RC significantly improves fairness in widely-used deterministic LTR models while guaranteeing a specified level of utility.", "link": "https://arxiv.org/abs/2306.07188"}, {"id": "2306.07218", "date": "Mon, 12 Jun 2023 16:24:01 GMT", "title": "A Protocol for Continual Explanation of SHAP\n", "authors": ["Andrea Cossu", "Francesco Spinnato", "Riccardo Guidotti", "Davide Bacciu\n"], "categories": ["cs.LG", "cs.AI\nComments:", "ESANN", "2023,", "6", "pages\n"], "abstract": "Continual Learning trains models on a stream of data, with the aim of learning new information without forgetting previous knowledge. Given the dynamic nature of such environments, explaining the predictions of these models can be challenging. We study the behavior of SHAP values explanations in Continual Learning and propose an evaluation protocol to robustly assess the change of explanations in Class-Incremental scenarios. We observed that, while Replay strategies enforce the stability of SHAP values in feedforward/convolutional models, they are not able to do the same with fully-trained recurrent models. We show that alternative recurrent approaches, like randomized recurrent models, are more effective in keeping the explanations stable over time.", "link": "https://arxiv.org/abs/2306.07218"}, {"id": "2306.07221", "date": "Mon, 12 Jun 2023 16:28:11 GMT", "title": "Convergence of mean-field Langevin dynamics: Time and space\n\u00a0discretization, stochastic gradient, and variance reduction\n", "authors": ["Taiji Suzuki and Denny Wu and Atsushi Nitanda\n"], "categories": ["cs.LG", "stat.ML\nComments:", "37", "pages\n"], "abstract": "The mean-field Langevin dynamics (MFLD) is a nonlinear generalization of the Langevin dynamics that incorporates a distribution-dependent drift, and it naturally arises from the optimization of two-layer neural networks via (noisy) gradient descent. Recent works have shown that MFLD globally minimizes an entropy-regularized convex functional in the space of measures. However, all prior analyses assumed the infinite-particle or continuous-time limit, and cannot handle stochastic gradient updates. We provide an general framework to prove a uniform-in-time propagation of chaos for MFLD that takes into account the errors due to finite-particle approximation, time-discretization, and stochastic gradient approximation. To demonstrate the wide applicability of this framework, we establish quantitative convergence rate guarantees to the regularized global optimal solution under (i) a wide range of learning problems such as neural network in the mean-field regime and MMD minimization, and (ii) different gradient estimators including SGD and SVRG. Despite the generality of our results, we achieve an improved convergence rate in both the SGD and SVRG settings when specialized to the standard Langevin dynamics.", "link": "https://arxiv.org/abs/2306.07221"}, {"id": "2306.07255", "date": "Mon, 12 Jun 2023 17:25:12 GMT", "title": "Conditional Matrix Flows for Gaussian Graphical Models\n", "authors": ["Marcello Massimo Negri", "F. Arend Torres and Volker Roth\n"], "categories": ["cs.LG", "stat.ML\n"], "abstract": "Studying conditional independence structure among many variables with few observations is a challenging task. Gaussian Graphical Models (GGMs) tackle this problem by encouraging sparsity in the precision matrix through an $l_p$ regularization with $p\\leq1$. However, since the objective is highly non-convex for sub-$l_1$ pseudo-norms, most approaches rely on the $l_1$ norm. In this case frequentist approaches allow to elegantly compute the solution path as a function of the shrinkage parameter $\\lambda$. Instead of optimizing the penalized likelihood, the Bayesian formulation introduces a Laplace prior on the precision matrix. However, posterior inference for different $\\lambda$ values requires repeated runs of expensive Gibbs samplers. We propose a very general framework for variational inference in GGMs that unifies the benefits of frequentist and Bayesian frameworks. Specifically, we propose to approximate the posterior with a matrix-variate Normalizing Flow defined on the space of symmetric positive definite matrices. As a key improvement on previous work, we train a continuum of sparse regression models jointly for all regularization parameters $\\lambda$ and all $l_p$ norms, including non-convex sub-$l_1$ pseudo-norms. This is achieved by conditioning the flow on $p>0$ and on the shrinkage parameter $\\lambda$. We have then access with one model to (i) the evolution of the posterior for any $\\lambda$ and for any $l_p$ (pseudo-) norms, (ii) the marginal log-likelihood for model selection, and (iii) we can recover the frequentist solution paths as the MAP, which is obtained through simulated annealing.", "link": "https://arxiv.org/abs/2306.07255"}, {"id": "2306.07261", "date": "Mon, 12 Jun 2023 17:44:15 GMT", "title": "Unprocessing Seven Years of Algorithmic Fairness\n", "authors": ["Andr\\'e F. Cruz", "Moritz Hardt\n"], "categories": ["cs.LG", "cs.CY\n"], "abstract": "Seven years ago, researchers proposed a postprocessing method to equalize the error rates of a model across different demographic groups. The work launched hundreds of papers purporting to improve over the postprocessing baseline. We empirically evaluate these claims through thousands of model evaluations on several tabular datasets. We find that the fairness-accuracy Pareto frontier achieved by postprocessing contains all other methods we were feasibly able to evaluate. In doing so, we address two common methodological errors that have confounded previous observations. One relates to the comparison of methods with different unconstrained base models. The other concerns methods achieving different levels of constraint relaxation. At the heart of our study is a simple idea we call unprocessing that roughly corresponds to the inverse of postprocessing. Unprocessing allows for a direct comparison of methods using different underlying models and levels of relaxation. Interpreting our findings, we recall a widely overlooked theoretical argument, present seven years ago, that accurately predicted what we observe.", "link": "https://arxiv.org/abs/2306.07261"}, {"id": "2306.07266", "date": "Mon, 12 Jun 2023 17:52:39 GMT", "title": "Operator Learning with Neural Fields: Tackling PDEs on General\n\u00a0Geometries\n", "authors": ["Louis Serrano", "Lise Le Boudec", "Armand Kassa\\\"i Koupa\\\"i", "Thomas X\n\u00a0Wang", "Yuan Yin", "Jean-No\\\"el Vittaut", "Patrick Gallinari\n"], "categories": ["cs.LG", "cs.AI\n"], "abstract": "Machine learning approaches for solving partial differential equations require learning mappings between function spaces. While convolutional or graph neural networks are constrained to discretized functions, neural operators present a promising milestone toward mapping functions directly. Despite impressive results they still face challenges with respect to the domain geometry and typically rely on some form of discretization. In order to alleviate such limitations, we present CORAL, a new method that leverages coordinate-based networks for solving PDEs on general geometries. CORAL is designed to remove constraints on the input mesh, making it applicable to any spatial sampling and geometry. Its ability extends to diverse problem domains, including PDE solving, spatio-temporal forecasting, and inverse problems like geometric design. CORAL demonstrates robust performance across multiple resolutions and performs well in both convex and non-convex domains, surpassing or performing on par with state-of-the-art models.", "link": "https://arxiv.org/abs/2306.07266"}, {"id": "2306.07273", "date": "Mon, 12 Jun 2023 17:57:05 GMT", "title": "Gaussian Membership Inference Privacy\n", "authors": ["Tobias Leemann", "Martin Pawelczyk", "Gjergji Kasneci\n"], "categories": ["cs.LG", "cs.CR", "stat.ML\nComments:", "The", "first", "two", "authors", "contributed", "equally\n"], "abstract": "We propose a new privacy notion called $f$-Membership Inference Privacy ($f$-MIP), which explicitly considers the capabilities of realistic adversaries under the membership inference attack threat model. By doing so $f$-MIP offers interpretable privacy guarantees and improved utility (e.g., better classification accuracy). Our novel theoretical analysis of likelihood ratio-based membership inference attacks on noisy stochastic gradient descent (SGD) results in a parametric family of $f$-MIP guarantees that we refer to as $\\mu$-Gaussian Membership Inference Privacy ($\\mu$-GMIP). Our analysis additionally yields an analytical membership inference attack that offers distinct advantages over previous approaches. First, unlike existing methods, our attack does not require training hundreds of shadow models to approximate the likelihood ratio. Second, our analytical attack enables straightforward auditing of our privacy notion $f$-MIP. Finally, our analysis emphasizes the importance of various factors, such as hyperparameters (e.g., batch size, number of model parameters) and data specific characteristics in controlling an attacker's success in reliably inferring a given point's membership to the training set. We demonstrate the effectiveness of our method on models trained across vision and tabular datasets.", "link": "https://arxiv.org/abs/2306.07273"}, {"id": "2306.07284", "date": "Mon, 12 Jun 2023 17:59:50 GMT", "title": "No Free Lunch: The Hazards of Over-Expressive Representations in Anomaly\n\u00a0Detection\n", "authors": ["Tal Reiss", "Niv Cohen", "Yedid Hoshen\n"], "categories": ["cs.LG", "cs.CV\n"], "abstract": "Anomaly detection methods, powered by deep learning, have recently been making significant progress, mostly due to improved representations. It is tempting to hypothesize that anomaly detection can improve indefinitely by increasing the scale of our networks, making their representations more expressive. In this paper, we provide theoretical and empirical evidence to the contrary. In fact, we empirically show cases where very expressive representations fail to detect even simple anomalies when evaluated beyond the well-studied object-centric datasets. To investigate this phenomenon, we begin by introducing a novel theoretical toy model for anomaly detection performance. The model uncovers a fundamental trade-off between representation sufficiency and over-expressivity. It provides evidence for a no-free-lunch theorem in anomaly detection stating that increasing representation expressivity will eventually result in performance degradation. Instead, guidance must be provided to focus the representation on the attributes relevant to the anomalies of interest. We conduct an extensive empirical investigation demonstrating that state-of-the-art representations often suffer from over-expressivity, failing to detect many types of anomalies. Our investigation demonstrates how this over-expressivity impairs image anomaly detection in practical settings. We conclude with future directions for mitigating this issue.", "link": "https://arxiv.org/abs/2306.07284"}, {"id": "2306.06236", "date": "Fri, 9 Jun 2023 20:12:02 GMT", "title": "iPLAN: Intent-Aware Planning in Heterogeneous Traffic via Distributed\n\u00a0Multi-Agent Reinforcement Learning\n", "authors": ["Xiyang Wu", "Rohan Chandra", "Tianrui Guan", "Amrit Singh Bedi", "Dinesh\n\u00a0Manocha\n"], "categories": ["cs.MA", "cs.LG", "cs.RO\n"], "abstract": "Navigating safely and efficiently in dense and heterogeneous traffic scenarios is challenging for autonomous vehicles (AVs) due to their inability to infer the behaviors or intentions of nearby drivers. In this work, we propose a distributed multi-agent reinforcement learning (MARL) algorithm with trajectory and intent prediction in dense and heterogeneous traffic scenarios. Our approach for intent-aware planning, iPLAN, allows agents to infer nearby drivers' intents solely from their local observations. We model two distinct incentives for agents' strategies: Behavioral incentives for agents' long-term planning based on their driving behavior or personality; Instant incentives for agents' short-term planning for collision avoidance based on the current traffic state. We design a two-stream inference module that allows agents to infer their opponents' incentives and incorporate their inferred information into decision-making. We perform experiments on two simulation environments, Non-Cooperative Navigation and Heterogeneous Highway. In Heterogeneous Highway, results show that, compared with centralized MARL baselines such as QMIX and MAPPO, our method yields a 4.0% and 35.7% higher episodic reward in mild and chaotic traffic, with 48.1% higher success rate and 80.6% longer survival time in chaotic traffic. We also compare with a decentralized baseline IPPO and demonstrate a higher episodic reward of 9.2% and 10.3% in mild traffic and chaotic traffic, 25.3% higher success rate, and 13.7% longer survival time.", "link": "https://arxiv.org/abs/2306.06236"}, {"id": "2306.07129", "date": "Mon, 12 Jun 2023 14:07:53 GMT", "title": "Collaborative Robotic Biopsy with Trajectory Guidance and Needle Tip\n\u00a0Force Feedback\n", "authors": ["Robin Mieling", "Maximilian Neidhardt", "Sarah Latus", "Carolin Stapper,\n\u00a0Stefan Gerlach", "Inga Kniep", "Axel Heinemann", "Benjamin Ondruschka and Alexander\n\u00a0Schlaefer\n"], "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY\nComments:", "Presented", "at", "ICRA", "2023\n"], "abstract": "The diagnostic value of biopsies is highly dependent on the placement of needles. Robotic trajectory guidance has been shown to improve needle positioning, but feedback for real-time navigation is limited. Haptic display of needle tip forces can provide rich feedback for needle navigation by enabling localization of tissue structures along the insertion path. We present a collaborative robotic biopsy system that combines trajectory guidance with kinesthetic feedback to assist the physician in needle placement. The robot aligns the needle while the insertion is performed in collaboration with a medical expert who controls the needle position on site. We present a needle design that senses forces at the needle tip based on optical coherence tomography and machine learning for real-time data processing. Our robotic setup allows operators to sense deep tissue interfaces independent of frictional forces to improve needle placement relative to a desired target structure. We first evaluate needle tip force sensing in ex-vivo tissue in a phantom study. We characterize the tip forces during insertions with constant velocity and demonstrate the ability to detect tissue interfaces in a collaborative user study. Participants are able to detect 91% of ex-vivo tissue interfaces based on needle tip force feedback alone. Finally, we demonstrate that even smaller, deep target structures can be accurately sampled by performing post-mortem in situ biopsies of the pancreas.", "link": "https://arxiv.org/abs/2306.07129"}, {"id": "2306.06330", "date": "Sat, 10 Jun 2023 01:59:38 GMT", "title": "Autonomous Drifting with 3 Minutes of Data via Learned Tire Models\n", "authors": ["Franck Djeumou and Jonathan Y.M. Goh and Ufuk Topcu and Avinash\n\u00a0Balachandran\n"], "categories": ["eess.SY", "cs.LG", "cs.SY\nComments:", "Final", "Submission", "at", "ICRA", "2023\n"], "abstract": "Near the limits of adhesion, the forces generated by a tire are nonlinear and intricately coupled. Efficient and accurate modelling in this region could improve safety, especially in emergency situations where high forces are required. To this end, we propose a novel family of tire force models based on neural ordinary differential equations and a neural-ExpTanh parameterization. These models are designed to satisfy physically insightful assumptions while also having sufficient fidelity to capture higher-order effects directly from vehicle state measurements. They are used as drop-in replacements for an analytical brush tire model in an existing nonlinear model predictive control framework. Experiments with a customized Toyota Supra show that scarce amounts of driving data -- less than three minutes -- is sufficient to achieve high-performance autonomous drifting on various trajectories with speeds up to 45mph. Comparisons with the benchmark model show a $4 \\times$ improvement in tracking performance, smoother control inputs, and faster and more consistent computation time.", "link": "https://arxiv.org/abs/2306.06330"}, {"id": "2306.06408", "date": "Sat, 10 Jun 2023 10:42:49 GMT", "title": "Fast light-field 3D microscopy with out-of-distribution detection and\n\u00a0adaptation through Conditional Normalizing Flows\n", "authors": ["Josu\\'e Page Vizca\\'ino", "Panagiotis Symvoulidis", "Zeguan Wang", "Jonas\n\u00a0Jelten", "Paolo Favaro", "Edward S. Boyden", "Tobias Lasser\n"], "categories": ["eess.IV", "cs.CV", "cs.LG", "q-bio.NC\n"], "abstract": "Real-time 3D fluorescence microscopy is crucial for the spatiotemporal analysis of live organisms, such as neural activity monitoring. The eXtended field-of-view light field microscope (XLFM), also known as Fourier light field microscope, is a straightforward, single snapshot solution to achieve this. The XLFM acquires spatial-angular information in a single camera exposure. In a subsequent step, a 3D volume can be algorithmically reconstructed, making it exceptionally well-suited for real-time 3D acquisition and potential analysis. Unfortunately, traditional reconstruction methods (like deconvolution) require lengthy processing times (0.0220 Hz), hampering the speed advantages of the XLFM. Neural network architectures can overcome the speed constraints at the expense of lacking certainty metrics, which renders them untrustworthy for the biomedical realm. This work proposes a novel architecture to perform fast 3D reconstructions of live immobilized zebrafish neural activity based on a conditional normalizing flow. It reconstructs volumes at 8 Hz spanning 512x512x96 voxels, and it can be trained in under two hours due to the small dataset requirements (10 image-volume pairs). Furthermore, normalizing flows allow for exact Likelihood computation, enabling distribution monitoring, followed by out-of-distribution detection and retraining of the system when a novel sample is detected. We evaluate the proposed method on a cross-validation approach involving multiple in-distribution samples (genetically identical zebrafish) and various out-of-distribution ones.", "link": "https://arxiv.org/abs/2306.06408"}, {"id": "2306.06491", "date": "Sat, 10 Jun 2023 17:14:41 GMT", "title": "Online learning for X-ray, CT or MRI\n", "authors": ["Mosabbir Bhuiyan", "MD Abdullah Al Nasim", "Sarwar Saif", "Dr. Kishor Datta\n\u00a0Gupta", "Md Jahangir Alam", "Sajedul Talukder\n"], "categories": ["eess.IV", "cs.CV", "cs.LG", "physics.med-ph\nComments:", "14", "pages,", "17", "figures,", "1", "table;", "Acceptance", "of", "the", "chapter", "for", "the\n\u00a0Springer", "book", "\"Data-driven", "approaches", "to", "medical", "imaging\"\n"], "abstract": "Medical imaging plays an important role in the medical sector in identifying diseases. X-ray, computed tomography (CT) scans, and magnetic resonance imaging (MRI) are a few examples of medical imaging. Most of the time, these imaging techniques are utilized to examine and diagnose diseases. Medical professionals identify the problem after analyzing the images. However, manual identification can be challenging because the human eye is not always able to recognize complex patterns in an image. Because of this, it is difficult for any professional to recognize a disease with rapidity and accuracy. In recent years, medical professionals have started adopting Computer-Aided Diagnosis (CAD) systems to evaluate medical images. This system can analyze the image and detect the disease very precisely and quickly. However, this system has certain drawbacks in that it needs to be processed before analysis. Medical research is already entered a new era of research which is called Artificial Intelligence (AI). AI can automatically find complex patterns from an image and identify diseases. Methods for medical imaging that uses AI techniques will be covered in this chapter.", "link": "https://arxiv.org/abs/2306.06491"}, {"id": "1810.04510", "date": "Wed, 10 Oct 2018 13:23:36 GMT", "title": "Machine learning plasma-surface interface for coupling sputtering and\n\u00a0gas-phase transport simulations\n", "authors": ["Florian Kr\\\"uger", "Tobias Gergs", "Jan Trieschmann\n"], "categories": ["physics.plasm-ph", "cs.LG", "physics.comp-ph\nDOI:", "10.1088/1361-6595/ab0246\n"], "abstract": "Thin film processing by means of sputter deposition inherently depends on the interaction of energetic particles with a target surface and the subsequent particle transport. The length and time scales of the underlying physical phenomena span orders of magnitudes. A theoretical description which bridges all time and length scales is not practically possible. Advantage can be taken particularly from the well-separated time scales of the fundamental surface and plasma processes. Initially, surface properties may be calculated from a surface model and stored for a number of representative cases. Subsequently, the surface data may be provided to gas-phase transport simulations via appropriate model interfaces (e.g., analytic expressions or look-up tables) and utilized to define insertion boundary conditions. During run-time evaluation, however, the maintained surface data may prove to be not sufficient. In this case, missing data may be obtained by interpolation (common), extrapolation (inaccurate), or be supplied on-demand by the surface model (computationally inefficient). In this work, a potential alternative is established based on machine learning techniques using artificial neural networks. As a proof of concept, a multilayer perceptron network is trained and verified with sputtered particle distributions obtained from transport of ions in matter based simulations for Ar projectiles bombarding a Ti-Al composite. It is demonstrated that the trained network is able to predict the sputtered particle distributions for unknown, arbitrarily shaped incident ion energy distributions. It is consequently argued that the trained network may be readily used as a machine learning based model interface (e.g., by quasi-continuously sampling the desired sputtered particle distributions from the network), which is sufficiently accurate also in scenarios which have not been previously trained.", "link": "https://arxiv.org/abs/1810.04510"}, {"id": "2109.01406", "date": "Fri, 3 Sep 2021 09:51:32 GMT", "title": "An efficient plasma-surface interaction surrogate model for sputtering\n\u00a0processes based on autoencoder neural networks\n", "authors": ["Tobias Gergs", "Borislav Borislavov", "and Jan Trieschmann\n"], "categories": ["physics.comp-ph", "cs.LG", "physics.plasm-ph\nDOI:", "10.1116/6.0001485\n"], "abstract": "Simulations of thin film sputter deposition require the separation of the plasma and material transport in the gas-phase from the growth/sputtering processes at the bounding surfaces. Interface models based on analytic expressions or look-up tables inherently restrict this complex interaction to a bare minimum. A machine learning model has recently been shown to overcome this remedy for Ar ions bombarding a Ti-Al composite target. However, the chosen network structure (i.e., a multilayer perceptron) provides approximately 4 million degrees of freedom, which bears the risk of overfitting the relevant dynamics and complicating the model to an unreliable extend. This work proposes a conceptually more sophisticated but parameterwise simplified regression artificial neural network for an extended scenario, considering a variable instead of a single fixed Ti-Al stoichiometry. A convolutional $\\beta$-variational autoencoder is trained to reduce the high-dimensional energy-angular distribution of sputtered particles to a latent space representation of only two components. In addition to a primary decoder which is trained to reconstruct the input energy-angular distribution, a secondary decoder is employed to reconstruct the mean energy of incident Ar ions as well as the present Ti-Al composition. The mutual latent space is hence conditioned on these quantities. The trained primary decoder of the variational autoencoder network is subsequently transferred to a regression network, for which only the mapping to the particular latent space has to be learned. While obtaining a competitive performance, the number of degrees of freedom is drastically reduced to 15,111 and 486 parameters for the primary decoder and the remaining regression network, respectively. The underlying methodology is general and can easily be extended to more complex physical descriptions with a minimal amount of data required.", "link": "https://arxiv.org/abs/2109.01406"}, {"id": "2211.04796", "date": "Wed, 9 Nov 2022 10:44:03 GMT", "title": "Physics-separating artificial neural networks for predicting initial\n\u00a0stages of Al sputtering and thin film deposition in Ar plasma discharges\n", "authors": ["Tobias Gergs", "Thomas Mussenbrock", "Jan Trieschmann\n"], "categories": ["cond-mat.mtrl-sci", "cs.LG", "physics.plasm-ph\nDOI:", "10.1088/1361-6463/acb6a4\n"], "abstract": "Simulations of Al thin film sputter depositions rely on accurate plasma and surface interaction models. Establishing the latter commonly requires a higher level of abstraction and means to dismiss the fundamental atomic fidelity. Previous works on sputtering processes addressed this issue by establishing machine learning surrogate models, which include a basic surface state (i.e., stoichiometry) as static input. In this work, an evolving surface state and defect structure are introduced to jointly describe sputtering and growth with physics-separating artificial neural networks. The data describing the plasma-surface interactions stem from hybrid reactive molecular dynamics/time-stamped force bias Monte Carlo simulations of Al neutrals and Ar$^+$ ions impinging onto Al(001) surfaces. It is demonstrated that the fundamental processes are comprehensively described by taking the surface state as well as defect structure into account. Hence, a machine learning plasma-surface interaction surrogate model is established that resolves the inherent kinetics with high physical fidelity. The resulting model is not restricted to input from modeling and simulation, but may similarly be applied to experimental input data.", "link": "https://arxiv.org/abs/2211.04796"}, {"id": "2301.03524", "date": "Mon, 9 Jan 2023 17:20:32 GMT", "title": "Physics-separating artificial neural networks for predicting sputtering\n\u00a0and thin film deposition of AlN in Ar/N$_2$ discharges on experimental\n\u00a0timescales\n", "authors": ["Tobias Gergs", "Thomas Mussenbrock", "Jan Trieschmann\n"], "categories": ["cond-mat.mtrl-sci", "cs.LG", "physics.plasm-ph\nDOI:", "10.1088/1361-6463/acc07e\n"], "abstract": "Understanding and modeling plasma-surface interactions frame a multi-scale as well as multi-physics problem. Scale-bridging machine learning surface surrogate models have been demonstrated to perceive the fundamental atomic fidelity for the physical vapor deposition of pure metals. However, the immense computational cost of the data-generating simulations render a practical application with predictions on relevant timescales impracticable. This issue is resolved in this work for the sputter deposition of AlN in Ar/N$_2$ discharges by developing a scheme that populates the parameter spaces effectively. Hybrid reactive molecular dynamics / time-stamped force-bias Monte Carlo simulations of randomized plasma-surface interactions / diffusion processes are used to setup a physics-separating artificial neural network. The application of this generic machine learning model to a specific experimental reference case study enables the systematic analysis of the particle flux emission as well as underlying system state (e.g., composition, mass density, stress, point defect structure) evolution within process times of up to 45 minutes.", "link": "https://arxiv.org/abs/2301.03524"}, {"id": "2306.06125", "date": "Thu, 8 Jun 2023 06:15:17 GMT", "title": "Joint Channel Estimation and Feedback with Masked Token Transformers in\n\u00a0Massive MIMO Systems\n", "authors": ["Mingming Zhao", "Lin Liu", "Lifu Liu", "Qi Tian\n"], "categories": ["cs.IT", "cs.LG", "math.IT\nComments:", "9", "pages,", "8", "figures\n"], "abstract": "When the base station has downlink channel status information (CSI), the huge potential of large-scale multiple input multiple output (MIMO) in frequency division duplex (FDD) mode can be fully exploited. In this paper, we propose a deep-learning-based joint channel estimation and feedback framework to realize channel estimation and feedback in massive MIMO systems. Specifically, we use traditional channel design rather than end-to-end methods. Our model contains two networks. The first network is a channel estimation network, which adopts a double loss design, and can accurately estimate the full channel information while removing channel noises. The second network is a compression and feedback network. Inspired by the masked token transformer, we propose a learnable mask token method to obtain excellent estimation and compression performance. The extensive simulation results and ablation studies show that our method outperforms state-of-the-art channel estimation and feedback methods in both separate and joint tasks.", "link": "https://arxiv.org/abs/2306.06125"}, {"id": "2306.06144", "date": "Fri, 9 Jun 2023 09:10:28 GMT", "title": "Bayesian Calibration of MEMS Accelerometers\n", "authors": ["Oliver D\\\"urr", "Po-Yu Fan", "and Zong-Xian Yin\n"], "categories": ["eess.SP", "cs.LG", "stat.AP\nComments:", "Accepted", "in", "IEEE", "Sensors\nDOI:", "10.1109/JSEN.2023.3272907\n"], "abstract": "This study aims to investigate the utilization of Bayesian techniques for the calibration of micro-electro-mechanical systems (MEMS) accelerometers. These devices have garnered substantial interest in various practical applications and typically require calibration through error-correcting functions. The parameters of these error-correcting functions are determined during a calibration process. However, due to various sources of noise, these parameters cannot be determined with precision, making it desirable to incorporate uncertainty in the calibration models. Bayesian modeling offers a natural and complete way of reflecting uncertainty by treating the model parameters as variables rather than fixed values. Additionally, Bayesian modeling enables the incorporation of prior knowledge, making it an ideal choice for calibration. Nevertheless, it is infrequently used in sensor calibration. This study introduces Bayesian methods for the calibration of MEMS accelerometer data in a straightforward manner using recent advances in probabilistic programming.", "link": "https://arxiv.org/abs/2306.06144"}, {"id": "2306.06283", "date": "Fri, 9 Jun 2023 22:22:02 GMT", "title": "14 Examples of How LLMs Can Transform Materials Science and Chemistry: A\n\u00a0Reflection on a Large Language Model Hackathon\n", "authors": ["Kevin Maik Jablonka", "Qianxiang Ai", "Alexander Al-Feghali", "Shruti\n\u00a0Badhwar", "Joshua D. Bocarsly Andres M Bran", "Stefan Bringuier", "L. Catherine\n\u00a0Brinson", "Kamal Choudhary", "Defne Circi", "Sam Cox", "Wibe A. de Jong", "Matthew L.\n\u00a0Evans", "Nicolas Gastellu", "Jerome Genzling", "Mar\\'ia Victoria Gil", "Ankur K.\n\u00a0Gupta", "Zhi Hong", "Alishba Imran", "Sabine Kruschwitz", "Anne Labarre", "Jakub\n\u00a0L\\'ala", "Tao Liu", "Steven Ma", "Sauradeep Majumdar", "Garrett W. Merz", "Nicolas\n\u00a0Moitessier", "Elias Moubarak", "Beatriz Mouri\\~no", "Brenden Pelkie", "Michael\n\u00a0Pieler", "Mayk Caldas Ramos", "Bojana Rankovi\\'c", "Samuel G. Rodriques", "Jacob N.\n\u00a0Sanders", "Philippe Schwaller", "Marcus Schwarting", "Jiale Shi", "Berend Smit", "Ben\n\u00a0E. Smith", "Joren Van Heck", "Christoph V\\\"olker", "Logan Ward", "Sean Warren,\n\u00a0Benjamin Weiser", "Sylvester Zhang", "Xiaoqi Zhang", "Ghezal Ahmad Zia", "Aristana\n\u00a0Scourtas", "KJ Schmidt", "Ian Foster", "Andrew D. White", "Ben Blaiszik\n"], "categories": ["cond-mat.mtrl-sci", "cs.LG", "physics.chem-ph\n"], "abstract": "Chemistry and materials science are complex. Recently, there have been great successes in addressing this complexity using data-driven or computational techniques. Yet, the necessity of input structured in very specific forms and the fact that there is an ever-growing number of tools creates usability and accessibility challenges. Coupled with the reality that much data in these disciplines is unstructured, the effectiveness of these tools is limited. Motivated by recent works that indicated that large language models (LLMs) might help address some of these issues, we organized a hackathon event on the applications of LLMs in chemistry, materials science, and beyond. This article chronicles the projects built as part of this hackathon. Participants employed LLMs for various applications, including predicting properties of molecules and materials, designing novel interfaces for tools, extracting knowledge from unstructured data, and developing new educational applications. The diverse topics and the fact that working prototypes could be generated in less than two days highlight that LLMs will profoundly impact the future of our fields. The rich collection of ideas and projects also indicates that the applications of LLMs are not limited to materials science and chemistry but offer potential benefits to a wide range of scientific disciplines.", "link": "https://arxiv.org/abs/2306.06283"}, {"id": "2306.06291", "date": "Fri, 9 Jun 2023 22:48:13 GMT", "title": "Optimal Heterogeneous Collaborative Linear Regression and Contextual\n\u00a0Bandits\n", "authors": ["Xinmeng Huang", "Kan Xu", "Donghwan Lee", "Hamed Hassani", "Hamsa Bastani,\n\u00a0Edgar Dobriban\n"], "categories": ["stat.ML", "cs.LG", "stat.ME\n"], "abstract": "Large and complex datasets are often collected from several, possibly heterogeneous sources. Collaborative learning methods improve efficiency by leveraging commonalities across datasets while accounting for possible differences among them. Here we study collaborative linear regression and contextual bandits, where each instance's associated parameters are equal to a global parameter plus a sparse instance-specific term. We propose a novel two-stage estimator called MOLAR that leverages this structure by first constructing an entry-wise median of the instances' linear regression estimates, and then shrinking the instance-specific estimates towards the median. MOLAR improves the dependence of the estimation error on the data dimension, compared to independent least squares estimates. We then apply MOLAR to develop methods for sparsely heterogeneous collaborative contextual bandits, which lead to improved regret guarantees compared to independent bandit methods. We further show that our methods are minimax optimal by providing a number of lower bounds. Finally, we support the efficiency of our methods by performing experiments on both synthetic data and the PISA dataset on student educational outcomes from heterogeneous countries.", "link": "https://arxiv.org/abs/2306.06291"}, {"id": "2306.06340", "date": "Sat, 10 Jun 2023 04:23:08 GMT", "title": "ECGBERT: Understanding Hidden Language of ECGs with Self-Supervised\n\u00a0Representation Learning\n", "authors": ["Seokmin Choi", "Sajad Mousavi", "Phillip Si", "Haben G. Yhdego", "Fatemeh\n\u00a0Khadem", "Fatemeh Afghah\n"], "categories": ["eess.SP", "cs.LG", "q-bio.QM\n"], "abstract": "In the medical field, current ECG signal analysis approaches rely on supervised deep neural networks trained for specific tasks that require substantial amounts of labeled data. However, our paper introduces ECGBERT, a self-supervised representation learning approach that unlocks the underlying language of ECGs. By unsupervised pre-training of the model, we mitigate challenges posed by the lack of well-labeled and curated medical data. ECGBERT, inspired by advances in the area of natural language processing and large language models, can be fine-tuned with minimal additional layers for various ECG-based problems. Through four tasks, including Atrial Fibrillation arrhythmia detection, heartbeat classification, sleep apnea detection, and user authentication, we demonstrate ECGBERT's potential to achieve state-of-the-art results on a wide variety of tasks.", "link": "https://arxiv.org/abs/2306.06340"}, {"id": "2306.06403", "date": "Sat, 10 Jun 2023 10:10:55 GMT", "title": "Bayesian Inverse Contextual Reasoning for Heterogeneous Semantics-Native\n\u00a0Communication\n", "authors": ["Hyowoon Seo", "Yoonseong Kang", "Mehdi Bennis", "Wan Choi\n"], "categories": ["cs.IT", "cs.LG", "math.IT\nComments:", "14", "pages,", "7", "figures,", "submitted", "for", "possible", "publication\n"], "abstract": "This work deals with the heterogeneous semantic-native communication (SNC) problem. When agents do not share the same communication context, the effectiveness of contextual reasoning (CR) is compromised calling for agents to infer other agents' context. This article proposes a novel framework for solving the inverse problem of CR in SNC using two Bayesian inference methods, namely: Bayesian inverse CR (iCR) and Bayesian inverse linearized CR (iLCR). The first proposed Bayesian iCR method utilizes Markov Chain Monte Carlo (MCMC) sampling to infer the agent's context while being computationally expensive. To address this issue, a Bayesian iLCR method is leveraged which obtains a linearized CR (LCR) model by training a linear neural network. Experimental results show that the Bayesian iLCR method requires less computation and achieves higher inference accuracy compared to Bayesian iCR. Additionally, heterogeneous SNC based on the context obtained through the Bayesian iLCR method shows better communication effectiveness than that of Bayesian iCR. Overall, this work provides valuable insights and methods to improve the effectiveness of SNC in situations where agents have different contexts.", "link": "https://arxiv.org/abs/2306.06403"}, {"id": "2306.06546", "date": "Sun, 11 Jun 2023 00:13:00 GMT", "title": "High-Fidelity Audio Compression with Improved RVQGAN\n", "authors": ["Rithesh Kumar", "Prem Seetharaman", "Alejandro Luebs", "Ishaan Kumar", "Kundan\n\u00a0Kumar\n"], "categories": ["cs.SD", "cs.LG", "eess.AS\n"], "abstract": "Language models have been successfully used to model natural signals, such as images, speech, and music. A key component of these models is a high quality neural compression model that can compress high-dimensional natural signals into lower dimensional discrete tokens. To that end, we introduce a high-fidelity universal neural audio compression algorithm that achieves ~90x compression of 44.1 KHz audio into tokens at just 8kbps bandwidth. We achieve this by combining advances in high-fidelity audio generation with better vector quantization techniques from the image domain, along with improved adversarial and reconstruction losses. We compress all domains (speech, environment, music, etc.) with a single universal model, making it widely applicable to generative modeling of all audio. We compare with competing audio compression algorithms, and find our method outperforms them significantly. We provide thorough ablations for every design choice, as well as open-source code and trained model weights. We hope our work can lay the foundation for the next generation of high-fidelity audio modeling.", "link": "https://arxiv.org/abs/2306.06546"}, {"id": "2306.06574", "date": "Sun, 11 Jun 2023 03:43:39 GMT", "title": "Learnable Digital Twin for Efficient Wireless Network Evaluation\n", "authors": ["Boning Li", "Timofey Efimov", "Abhishek Kumar", "Jose Cortes", "Gunjan Verma,\n\u00a0Ananthram Swami", "Santiago Segarra\n"], "categories": ["cs.NI", "cs.LG", "cs.SY", "eess.SY\n"], "abstract": "Network digital twins (NDTs) facilitate the estimation of key performance indicators (KPIs) before physically implementing a network, thereby enabling efficient optimization of the network configuration. In this paper, we propose a learning-based NDT for network simulators. The proposed method offers a holistic representation of information flow in a wireless network by integrating node, edge, and path embeddings. Through this approach, the model is trained to map the network configuration to KPIs in a single forward pass. Hence, it offers a more efficient alternative to traditional simulation-based methods, thus allowing for rapid experimentation and optimization. Our proposed method has been extensively tested through comprehensive experimentation in various scenarios, including wired and wireless networks. Results show that it outperforms baseline learning models in terms of accuracy and robustness. Moreover, our approach achieves comparable performance to simulators but with significantly higher computational efficiency.", "link": "https://arxiv.org/abs/2306.06574"}, {"id": "2306.06581", "date": "Sun, 11 Jun 2023 04:03:22 GMT", "title": "Importance Sparsification for Sinkhorn Algorithm\n", "authors": ["Mengyu Li", "Jun Yu", "Tao Li", "Cheng Meng\n"], "categories": ["stat.ML", "cs.DS", "cs.LG", "math.OC\nComments:", "Accepted", "by", "Journal", "of", "Machine", "Learning", "Research\n"], "abstract": "Sinkhorn algorithm has been used pervasively to approximate the solution to optimal transport (OT) and unbalanced optimal transport (UOT) problems. However, its practical application is limited due to the high computational complexity. To alleviate the computational burden, we propose a novel importance sparsification method, called Spar-Sink, to efficiently approximate entropy-regularized OT and UOT solutions. Specifically, our method employs natural upper bounds for unknown optimal transport plans to establish effective sampling probabilities, and constructs a sparse kernel matrix to accelerate Sinkhorn iterations, reducing the computational cost of each iteration from $O(n^2)$ to $\\widetilde{O}(n)$ for a sample of size $n$. Theoretically, we show the proposed estimators for the regularized OT and UOT problems are consistent under mild regularity conditions. Experiments on various synthetic data demonstrate Spar-Sink outperforms mainstream competitors in terms of both estimation error and speed. A real-world echocardiogram data analysis shows Spar-Sink can effectively estimate and visualize cardiac cycles, from which one can identify heart failure and arrhythmia. To evaluate the numerical accuracy of cardiac cycle prediction, we consider the task of predicting the end-systole time point using the end-diastole one. Results show Spar-Sink performs as well as the classical Sinkhorn algorithm, requiring significantly less computational time.", "link": "https://arxiv.org/abs/2306.06581"}, {"id": "2306.06603", "date": "Sun, 11 Jun 2023 06:40:51 GMT", "title": "Task-Oriented Integrated Sensing, Computation and Communication for\n\u00a0Wireless Edge AI\n", "authors": ["Hong Xing", "Guangxu Zhu", "Dongzhu Liu", "Haifeng Wen", "Kaibin Huang", "and\n\u00a0Kaishun Wu\n"], "categories": ["cs.IT", "cs.LG", "eess.SP", "math.IT\nComments:", "18", "pages,", "6", "figures,", "submitted", "for", "possible", "journal", "publication\n"], "abstract": "With the advent of emerging IoT applications such as autonomous driving, digital-twin and metaverse etc. featuring massive data sensing, analyzing and inference as well critical latency in beyond 5G (B5G) networks, edge artificial intelligence (AI) has been proposed to provide high-performance computation of a conventional cloud down to the network edge. Recently, convergence of wireless sensing, computation and communication (SC${}^2$) for specific edge AI tasks, has aroused paradigm shift by enabling (partial) sharing of the radio-frequency (RF) transceivers and information processing pipelines among these three fundamental functionalities of IoT. However, most existing design frameworks separate these designs incurring unnecessary signaling overhead and waste of energy, and it is therefore of paramount importance to advance fully integrated sensing, computation and communication (ISCC) to achieve ultra-reliable and low-latency edge intelligence acquisition. In this article, we provide an overview of principles of enabling ISCC technologies followed by two concrete use cases of edge AI tasks demonstrating the advantage of task-oriented ISCC, and pointed out some practical challenges in edge AI design with advanced ISCC solutions.", "link": "https://arxiv.org/abs/2306.06603"}, {"id": "2306.06698", "date": "Sun, 11 Jun 2023 15:04:12 GMT", "title": "On the Confidence Intervals in Bioequivalence Studies\n", "authors": ["Kexuan Li", "Susie Sinks", "Peng Sun", "Lingli Yang\n"], "categories": ["stat.ME", "cs.LG", "stat.ML", "stat.OT\n"], "abstract": "A bioequivalence study is a type of clinical trial designed to compare the biological equivalence of two different formulations of a drug. Such studies are typically conducted in controlled clinical settings with human subjects, who are randomly assigned to receive two formulations. The two formulations are then compared with respect to their pharmacokinetic profiles, which encompass the absorption, distribution, metabolism, and elimination of the drug. Under the guidance from Food and Drug Administration (FDA), for a size-$\\alpha$ bioequivalence test, the standard approach is to construct a $100(1-2\\alpha)\\%$ confidence interval and verify if the confidence interval falls with the critical region. In this work, we clarify that $100(1-2\\alpha)\\%$ confidence interval approach for bioequivalence testing yields a size-$\\alpha$ test only when the two one-sided tests in TOST are ``equal-tailed''. Furthermore, a $100(1-\\alpha)\\%$ confidence interval approach is also discussed in the bioequivalence study.", "link": "https://arxiv.org/abs/2306.06698"}, {"id": "2306.06727", "date": "Sun, 11 Jun 2023 17:17:48 GMT", "title": "A Normalized Bottleneck Distance on Persistence Diagrams and Homology\n\u00a0Preservation under Dimension Reduction\n", "authors": ["Bala Krishnamoorthy and Nathan H. May\n"], "categories": ["cs.CG", "cs.LG", "math.AT\nComments:", "19", "pages,", "2", "figures\n"], "abstract": "Persistence diagrams are used as signatures of point cloud data assumed to be sampled from manifolds, and represent their topology in a compact fashion. Further, two given clouds of points can be compared by directly comparing their persistence diagrams using the bottleneck distance, d_B. But one potential drawback of this pipeline is that point clouds sampled from topologically similar manifolds can have arbitrarily large d_B values when there is a large degree of scaling between them. This situation is typical in dimension reduction frameworks that are also aiming to preserve topology. We define a new scale-invariant distance between persistence diagrams termed normalized bottleneck distance, d_N, and study its properties. In defining d_N, we also develop a broader framework called metric decomposition for comparing finite metric spaces of equal cardinality with a bijection. We utilize metric decomposition to prove a stability result for d_N by deriving an explicit bound on the distortion of the associated bijective map. We then study two popular dimension reduction techniques, Johnson-Lindenstrauss (JL) projections and metric multidimensional scaling (mMDS), and a third class of general biLipschitz mappings. We provide new bounds on how well these dimension reduction techniques preserve homology with respect to d_N. For a JL map f that transforms input X to f(X), we show that d_N(dgm(X),dgm(f(X)) < e, where dgm(X) is the Vietoris-Rips persistence diagram of X, and 0 < e < 1 is the tolerance up to which pairwise distances are preserved by f. For mMDS, we present new bounds for both d_B and d_N between persistence diagrams of X and its projection in terms of the eigenvalues of the covariance matrix. And for k-biLipschitz maps, we show that d_N is bounded by the product of (k^2-1)/k and the ratio of diameters of X and f(X).", "link": "https://arxiv.org/abs/2306.06727"}, {"id": "2306.06743", "date": "Sun, 11 Jun 2023 18:41:23 GMT", "title": "Comparing machine learning models for tau triggers\n", "authors": ["Maayan Yaary (1 and 2)", "Uriel Barron (1)", "Luis Pascual Dom\\'inguez\n\u00a0(1)", "Boping Chen (1)", "Liron Barak (1)", "Erez Etzion (1)", "Raja Giryes (2) ((1)\n\u00a0Raymond and Beverly Sackler School of Physics and Astronomy", "Tel Aviv\n\u00a0University", "Tel Aviv", "Israel (2) School of Electrical Engineering", "Tel Aviv\n\u00a0University", "Tel Aviv", "Israel)\n"], "categories": ["hep-ex", "cs.LG", "physics.ins-det\nComments:", "Submitted", "to", "JHEP\n"], "abstract": "This paper introduces novel supervised learning techniques for real-time selection (triggering) of hadronically decaying tau leptons in proton-proton colliders. By implementing classic machine learning decision trees and advanced deep learning models, such as Multi-Layer Perceptron or residual NN, visible improvements in performance compared to standard tau triggers are observed. We show how such an implementation may lower the current energy thresholds, thus contributing to increasing the sensitivity of searches for new phenomena in proton-proton collisions classified by low-energy tau leptons.", "link": "https://arxiv.org/abs/2306.06743"}, {"id": "2306.06792", "date": "Sun, 11 Jun 2023 22:14:21 GMT", "title": "A Neural Network Implementation for Free Energy Principle\n", "authors": ["Jingwei Liu\n"], "categories": ["cs.NE", "cs.LG", "q-bio.NC\nComments:", "12", "pages,", "3", "figures,", "submitted", "to", "the", "4th", "international", "workshop", "on\n\u00a0active", "inference\nMSC-class:", "I.2.3,", "F.4.1\n"], "abstract": "The free energy principle (FEP), as an encompassing framework and a unified brain theory, has been widely applied to account for various problems in fields such as cognitive science, neuroscience, social interaction, and hermeneutics. As a computational model deeply rooted in math and statistics, FEP posits an optimization problem based on variational Bayes, which is solved either by dynamic programming or expectation maximization in practice. However, there seems to be a bottleneck in extending the FEP to machine learning and implementing such models with neural networks. This paper gives a preliminary attempt at bridging FEP and machine learning, via a classical neural network model, the Helmholtz machine. As a variational machine learning model, the Helmholtz machine is optimized by minimizing its free energy, the same objective as FEP. Although the Helmholtz machine is not temporal, it gives an ideal parallel to the vanilla FEP and the hierarchical model of the brain, under which the active inference and predictive coding could be formulated coherently. Besides a detailed theoretical discussion, the paper also presents a preliminary experiment to validate the hypothesis. By fine-tuning the trained neural network through active inference, the model performance is promoted to accuracy above 99\\%. In the meantime, the data distribution is continuously deformed to a salience that conforms to the model representation, as a result of active sampling.", "link": "https://arxiv.org/abs/2306.06792"}, {"id": "2306.06819", "date": "Mon, 12 Jun 2023 01:55:53 GMT", "title": "Multimodal Audio-textual Architecture for Robust Spoken Language\n\u00a0Understanding\n", "authors": ["Anderson R. Avila", "Mehdi Rezagholizadeh", "Chao Xing\n"], "categories": ["cs.CL", "cs.LG", "eess.AS\n"], "abstract": "Recent voice assistants are usually based on the cascade spoken language understanding (SLU) solution, which consists of an automatic speech recognition (ASR) engine and a natural language understanding (NLU) system. Because such approach relies on the ASR output, it often suffers from the so-called ASR error propagation. In this work, we investigate impacts of this ASR error propagation on state-of-the-art NLU systems based on pre-trained language models (PLM), such as BERT and RoBERTa. Moreover, a multimodal language understanding (MLU) module is proposed to mitigate SLU performance degradation caused by errors present in the ASR transcript. The MLU benefits from self-supervised features learned from both audio and text modalities, specifically Wav2Vec for speech and Bert/RoBERTa for language. Our MLU combines an encoder network to embed the audio signal and a text encoder to process text transcripts followed by a late fusion layer to fuse audio and text logits. We found that the proposed MLU showed to be robust towards poor quality ASR transcripts, while the performance of BERT and RoBERTa are severely compromised. Our model is evaluated on five tasks from three SLU datasets and robustness is tested using ASR transcripts from three ASR engines. Results show that the proposed approach effectively mitigates the ASR error propagation problem, surpassing the PLM models' performance across all datasets for the academic ASR engine.", "link": "https://arxiv.org/abs/2306.06819"}, {"id": "2306.06954", "date": "Mon, 12 Jun 2023 08:37:36 GMT", "title": "Multi-View Frequency-Attention Alternative to CNN Frontends for\n\u00a0Automatic Speech Recognition\n", "authors": ["Belen Alastruey", "Lukas Drude", "Jahn Heymann", "Simon Wiesler\n"], "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD\n"], "abstract": "Convolutional frontends are a typical choice for Transformer-based automatic speech recognition to preprocess the spectrogram, reduce its sequence length, and combine local information in time and frequency similarly. However, the width and height of an audio spectrogram denote different information, e.g., due to reverberation as well as the articulatory system, the time axis has a clear left-to-right dependency. On the contrary, vowels and consonants demonstrate very different patterns and occupy almost disjoint frequency ranges. Therefore, we hypothesize, global attention over frequencies is beneficial over local convolution. We obtain 2.4 % relative word error rate reduction (rWERR) on a production scale Conformer transducer replacing its convolutional neural network frontend by the proposed F-Attention module on Alexa traffic. To demonstrate generalizability, we validate this on public LibriSpeech data with a long short term memory-based listen attend and spell architecture obtaining 4.6 % rWERR and demonstrate robustness to (simulated) noisy conditions.", "link": "https://arxiv.org/abs/2306.06954"}, {"id": "2306.06979", "date": "Mon, 12 Jun 2023 09:21:34 GMT", "title": "A Weakly Supervised Approach to Emotion-change Prediction and Improved\n\u00a0Mood Inference\n", "authors": ["Soujanya Narayana", "Ibrahim Radwan", "Ravikiran Parameshwara", "Iman\n\u00a0Abbasnejad", "Akshay Asthana", "Ramanathan Subramanian", "Roland Goecke\n"], "categories": ["cs.HC", "cs.LG", "cs.MM\nComments:", "9", "pages,", "3", "figures,", "6", "tables\n"], "abstract": "Whilst a majority of affective computing research focuses on inferring emotions, examining mood or understanding the \\textit{mood-emotion interplay} has received significantly less attention. Building on prior work, we (a) deduce and incorporate emotion-change ($\\Delta$) information for inferring mood, without resorting to annotated labels, and (b) attempt mood prediction for long duration video clips, in alignment with the characterisation of mood. We generate the emotion-change ($\\Delta$) labels via metric learning from a pre-trained Siamese Network, and use these in addition to mood labels for mood classification. Experiments evaluating \\textit{unimodal} (training only using mood labels) vs \\textit{multimodal} (training using mood plus $\\Delta$ labels) models show that mood prediction benefits from the incorporation of emotion-change information, emphasising the importance of modelling the mood-emotion interplay for effective mood inference.", "link": "https://arxiv.org/abs/2306.06979"}, {"id": "2306.07056", "date": "Mon, 12 Jun 2023 12:05:54 GMT", "title": "Kernel Random Projection Depth for Outlier Detection\n", "authors": ["Akira Tamamori\n"], "categories": ["stat.ML", "cs.LG", "stat.AP", "stat.ME\nComments:", "submitted", "to", "APSIPA", "ASC", "2023\n"], "abstract": "This paper proposes an extension of Random Projection Depth (RPD) to cope with multiple modalities and non-convexity on data clouds. In the framework of the proposed method, the RPD is computed in a reproducing kernel Hilbert space. With the help of kernel principal component analysis, we expect that the proposed method can cope with the above multiple modalities and non-convexity. The experimental results demonstrate that the proposed method outperforms RPD and is comparable to other existing detection models on benchmark datasets regarding Area Under the Curves (AUCs) of Receiver Operating Characteristic (ROC).", "link": "https://arxiv.org/abs/2306.07056"}, {"id": "2306.07158", "date": "Mon, 12 Jun 2023 14:44:22 GMT", "title": "Riemannian Laplace approximations for Bayesian neural networks\n", "authors": ["Federico Bergamin", "Pablo Moreno-Mu\\~noz", "S{\\o}ren Hauberg", "Georgios\n\u00a0Arvanitidis\n"], "categories": ["stat.ML", "cs.LG", "stat.ME\nComments:", "28", "pages,", "12", "figures.", "Under", "submission\n"], "abstract": "Bayesian neural networks often approximate the weight-posterior with a Gaussian distribution. However, practical posteriors are often, even locally, highly non-Gaussian, and empirical performance deteriorates. We propose a simple parametric approximate posterior that adapts to the shape of the true posterior through a Riemannian metric that is determined by the log-posterior gradient. We develop a Riemannian Laplace approximation where samples naturally fall into weight-regions with low negative log-posterior. We show that these samples can be drawn by solving a system of ordinary differential equations, which can be done efficiently by leveraging the structure of the Riemannian metric and automatic differentiation. Empirically, we demonstrate that our approach consistently improves over the conventional Laplace approximation across tasks. We further show that, unlike the conventional Laplace approximation, our method is not overly sensitive to the choice of prior, which alleviates a practical pitfall of current approaches.", "link": "https://arxiv.org/abs/2306.07158"}, {"id": "2306.07187", "date": "Mon, 12 Jun 2023 15:40:31 GMT", "title": "Video-to-Music Recommendation using Temporal Alignment of Segments\n", "authors": ["Laure Pr\\'etet", "Ga\\\"el Richard", "Cl\\'ement Souchier", "Geoffroy Peeters\n"], "categories": ["cs.MM", "cs.IR", "cs.LG", "cs.SD", "eess.AS\nJournal-ref:", "IEEE", "Transactions", "on", "Multimedia,", "18", "February", "2022\nDOI:", "10.1109/TMM.2022.3152598\n"], "abstract": "We study cross-modal recommendation of music tracks to be used as soundtracks for videos. This problem is known as the music supervision task. We build on a self-supervised system that learns a content association between music and video. In addition to the adequacy of content, adequacy of structure is crucial in music supervision to obtain relevant recommendations. We propose a novel approach to significantly improve the system's performance using structure-aware recommendation. The core idea is to consider not only the full audio-video clips, but rather shorter segments for training and inference. We find that using semantic segments and ranking the tracks according to sequence alignment costs significantly improves the results. We investigate the impact of different ranking metrics and segmentation methods.", "link": "https://arxiv.org/abs/2306.07187"}, {"id": "2306.07235", "date": "Mon, 12 Jun 2023 16:53:38 GMT", "title": "Deep Gaussian Mixture Ensembles\n", "authors": ["Yousef El-Laham", "Niccol\\`o Dalmasso", "Elizabeth Fons", "Svitlana\n\u00a0Vyetrenko\n"], "categories": ["stat.ML", "cs.LG", "stat.ME\nComments:", "Accepted", "at", "Uncertainty", "in", "Artificial", "Intelligence", "(UAI)", "2023\n\u00a0Conference,", "7", "figures,", "11", "tables\n"], "abstract": "This work introduces a novel probabilistic deep learning technique called deep Gaussian mixture ensembles (DGMEs), which enables accurate quantification of both epistemic and aleatoric uncertainty. By assuming the data generating process follows that of a Gaussian mixture, DGMEs are capable of approximating complex probability distributions, such as heavy-tailed or multimodal distributions. Our contributions include the derivation of an expectation-maximization (EM) algorithm used for learning the model parameters, which results in an upper-bound on the log-likelihood of training data over that of standard deep ensembles. Additionally, the proposed EM training procedure allows for learning of mixture weights, which is not commonly done in ensembles. Our experimental results demonstrate that DGMEs outperform state-of-the-art uncertainty quantifying deep learning models in handling complex predictive densities.", "link": "https://arxiv.org/abs/2306.07235"}, {"id": "2306.06130", "date": "Thu, 8 Jun 2023 11:14:51 GMT", "title": "Towards Understanding the Interplay of Generative Artificial\n\u00a0Intelligence and the Internet\n", "authors": ["Gonzalo Mart\\'inez", "Lauren Watson", "Pedro Reviriego", "Jos\\'e Alberto\n\u00a0Hern\\'andez", "Marc Juarez", "Rik Sarkar\n"], "categories": ["cs.AI", "cs.CV", "cs.LG\n"], "abstract": "The rapid adoption of generative Artificial Intelligence (AI) tools that can generate realistic images or text, such as DALL-E, MidJourney, or ChatGPT, have put the societal impacts of these technologies at the center of public debate. These tools are possible due to the massive amount of data (text and images) that is publicly available through the Internet. At the same time, these generative AI tools become content creators that are already contributing to the data that is available to train future models. Therefore, future versions of generative AI tools will be trained with a mix of human-created and AI-generated content, causing a potential feedback loop between generative AI and public data repositories. This interaction raises many questions: how will future versions of generative AI tools behave when trained on a mixture of real and AI generated data? Will they evolve and improve with the new data sets or on the contrary will they degrade? Will evolution introduce biases or reduce diversity in subsequent generations of generative AI tools? What are the societal implications of the possible degradation of these models? Can we mitigate the effects of this feedback loop? In this document, we explore the effect of this interaction and report some initial results using simple diffusion models trained with various image datasets. Our results show that the quality and diversity of the generated images can degrade over time suggesting that incorporating AI-created data can have undesired effects on future versions of generative models.", "link": "https://arxiv.org/abs/2306.06130"}, {"id": "2306.06499", "date": "Sat, 10 Jun 2023 18:05:16 GMT", "title": "Defining and Explorting the Intelligence Space\n", "authors": ["Paul S. Rosenbloom\n"], "categories": ["cs.AI", "cs.LG\nComments:", "May", "ultimately", "appear", "as", "a", "journal", "article", "and/or", "a", "book", "chapter\n"], "abstract": "Intelligence is a difficult concept to define, despite many attempts at doing so. Rather than trying to settle on a single definition, this article introduces a broad perspective on what intelligence is, by laying out a cascade of definitions that induces both a nested hierarchy of three levels of intelligence and a wider-ranging space that is built around them and approximations to them. Within this intelligence space, regions are identified that correspond to both natural -- most particularly, human -- intelligence and artificial intelligence (AI), along with the crossover notion of humanlike intelligence. These definitions are then exploited in early explorations of four more advanced, and likely more controversial, topics: the singularity, generative AI, ethics, and intellectual property.", "link": "https://arxiv.org/abs/2306.06499"}, {"id": "2306.06770", "date": "Sun, 11 Jun 2023 20:50:14 GMT", "title": "Improving Knowledge Extraction from LLMs for Robotic Task Learning\n\u00a0through Agent Analysis\n", "authors": ["James R. Kirk Robert E. Wray Peter Lindes\n"], "categories": ["cs.AI", "cs.HC", "cs.RO\nComments:", "8", "pages,", "8", "figures,", "1", "table,", "bibliography,", "appendix", "(30", "pages", "total)\nACM-class:", "I.2.6;", "I.2.7\n"], "abstract": "Large language models (LLMs) offer significant promise as a knowledge source for robotic task learning. Prompt engineering has been shown to be effective for eliciting knowledge from an LLM but alone is insufficient for acquiring relevant, situationally grounded knowledge for an embodied robotic agent learning novel tasks. We describe a cognitive-agent approach that extends and complements prompt engineering, mitigating its limitations, and thus enabling a robot to acquire new task knowledge matched to its native language capabilities, embodiment, environment, and user preferences. The approach is to increase the response space of LLMs and deploy general strategies, embedded within the autonomous robot, to evaluate, repair, and select among candidate responses produced by the LLM. We describe the approach and experiments that show how a robot, by retrieving and evaluating a breadth of responses from the LLM, can achieve >75% task completion in one-shot learning without user oversight. The approach achieves 100% task completion when human oversight (such as indication of preference) is provided, while greatly reducing how much human oversight is needed.", "link": "https://arxiv.org/abs/2306.06770"}, {"id": "2306.06924", "date": "Mon, 12 Jun 2023 07:55:18 GMT", "title": "TASRA: A Taxonomy and Analysis of Societal-Scale Risks from AI\n", "authors": ["Andrew Critch and Stuart Russell\n"], "categories": ["cs.AI", "cs.CR", "cs.CY", "cs.LG\nMSC-class:", "68T01\nACM-class:", "I.2.0\n"], "abstract": "While several recent works have identified societal-scale and extinction-level risks to humanity arising from artificial intelligence, few have attempted an {\\em exhaustive taxonomy} of such risks. Many exhaustive taxonomies are possible, and some are useful -- particularly if they reveal new risks or practical approaches to safety. This paper explores a taxonomy based on accountability: whose actions lead to the risk, are the actors unified, and are they deliberate? We also provide stories to illustrate how the various risk types could each play out, including risks arising from unanticipated interactions of many AI systems, as well as risks from deliberate misuse, for which combined technical and policy solutions are indicated.", "link": "https://arxiv.org/abs/2306.06924"}, {"id": "2306.07012", "date": "Mon, 12 Jun 2023 10:31:16 GMT", "title": "Generating Language Corrections for Teaching Physical Control Tasks\n", "authors": ["Megha Srivastava", "Noah Goodman", "Dorsa Sadigh\n"], "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.RO\nComments:", "International", "Conference", "on", "Machine", "Learning", "(ICML)", "2023,", "9", "pages\n"], "abstract": "AI assistance continues to help advance applications in education, from language learning to intelligent tutoring systems, yet current methods for providing students feedback are still quite limited. Most automatic feedback systems either provide binary correctness feedback, which may not help a student understand how to improve, or require hand-coding feedback templates, which may not generalize to new domains. This can be particularly challenging for physical control tasks, where the rich diversity in student behavior and specialized domains make it challenging to leverage general-purpose assistive tools for providing feedback. We design and build CORGI, a model trained to generate language corrections for physical control tasks, such as learning to ride a bike. CORGI takes in as input a pair of student and expert trajectories, and then generates natural language corrections to help the student improve. We collect and train CORGI over data from three diverse physical control tasks (drawing, steering, and joint movement). Through both automatic and human evaluations, we show that CORGI can (i) generate valid feedback for novel student trajectories, (ii) outperform baselines on domains with novel control dynamics, and (iii) improve student learning in an interactive drawing task.", "link": "https://arxiv.org/abs/2306.07012"}, {"id": "2306.06189", "date": "Fri, 9 Jun 2023 18:41:37 GMT", "title": "FasterViT: Fast Vision Transformers with Hierarchical Attention\n", "authors": ["Ali Hatamizadeh", "Greg Heinrich", "Hongxu Yin", "Andrew Tao", "Jose M.\n\u00a0Alvarez", "Jan Kautz", "Pavlo Molchanov\n"], "categories": ["cs.CV", "cs.AI", "cs.LG\nComments:", "Tech", "report\n"], "abstract": "We design a new family of hybrid CNN-ViT neural networks, named FasterViT, with a focus on high image throughput for computer vision (CV) applications. FasterViT combines the benefits of fast local representation learning in CNNs and global modeling properties in ViT. Our newly introduced Hierarchical Attention (HAT) approach decomposes global self-attention with quadratic complexity into a multi-level attention with reduced computational costs. We benefit from efficient window-based self-attention. Each window has access to dedicated carrier tokens that participate in local and global representation learning. At a high level, global self-attentions enable the efficient cross-window communication at lower costs. FasterViT achieves a SOTA Pareto-front in terms of accuracy \\vs image throughput. We have extensively validated its effectiveness on various CV tasks including classification, object detection and segmentation. We also show that HAT can be used as a plug-and-play module for existing networks and enhance them. We further demonstrate significantly faster and more accurate performance than competitive counterparts for images with high resolution. Code is available at https://github.com/NVlabs/FasterViT.", "link": "https://arxiv.org/abs/2306.06189"}, {"id": "2306.06269", "date": "Fri, 9 Jun 2023 21:42:29 GMT", "title": "DeepLCZChange: A Remote Sensing Deep Learning Model Architecture for\n\u00a0Urban Climate Resilience\n", "authors": ["Wenlu Sun", "Yao Sun", "Chenying Liu", "Conrad M Albrecht\n"], "categories": ["cs.CV", "cs.AI", "cs.LG\nComments:", "accepted", "for", "publication", "in", "2023", "IGARSS", "conference\n"], "abstract": "Urban land use structures impact local climate conditions of metropolitan areas. To shed light on the mechanism of local climate wrt. urban land use, we present a novel, data-driven deep learning architecture and pipeline, DeepLCZChange, to correlate airborne LiDAR data statistics with the Landsat 8 satellite's surface temperature product. A proof-of-concept numerical experiment utilizes corresponding remote sensing data for the city of New York to verify the cooling effect of urban forests.", "link": "https://arxiv.org/abs/2306.06269"}, {"id": "2306.06300", "date": "Fri, 9 Jun 2023 23:28:33 GMT", "title": "NERFBK: A High-Quality Benchmark for NERF-Based 3D Reconstruction\n", "authors": ["Ali Karami", "Simone Rigon", "Gabriele Mazzacca", "Ziyang Yan", "Fabio\n\u00a0Remondino\n"], "categories": ["cs.CV", "cs.AI", "cs.GR\nComments:", "9", "pages,", "6", "figures,", "1", "table,", "conference\n"], "abstract": "This paper introduces a new real and synthetic dataset called NeRFBK specifically designed for testing and comparing NeRF-based 3D reconstruction algorithms. High-quality 3D reconstruction has significant potential in various fields, and advancements in image-based algorithms make it essential to evaluate new advanced techniques. However, gathering diverse data with precise ground truth is challenging and may not encompass all relevant applications. The NeRFBK dataset addresses this issue by providing multi-scale, indoor and outdoor datasets with high-resolution images and videos and camera parameters for testing and comparing NeRF-based algorithms. This paper presents the design and creation of the NeRFBK benchmark, various examples and application scenarios, and highlights its potential for advancing the field of 3D reconstruction.", "link": "https://arxiv.org/abs/2306.06300"}, {"id": "2306.06362", "date": "Sat, 10 Jun 2023 06:46:32 GMT", "title": "Aria Digital Twin: A New Benchmark Dataset for Egocentric 3D Machine\n\u00a0Perception\n", "authors": ["Xiaqing Pan", "Nicholas Charron", "Yongqian Yang", "Scott Peters", "Thomas\n\u00a0Whelan", "Chen Kong", "Omkar Parkhi", "Richard Newcombe", "Carl (Yuheng) Ren\n"], "categories": ["cs.CV", "cs.AI", "cs.LG\n"], "abstract": "We introduce the Aria Digital Twin (ADT) - an egocentric dataset captured using Aria glasses with extensive object, environment, and human level ground truth. This ADT release contains 200 sequences of real-world activities conducted by Aria wearers in two real indoor scenes with 398 object instances (324 stationary and 74 dynamic). Each sequence consists of: a) raw data of two monochrome camera streams, one RGB camera stream, two IMU streams; b) complete sensor calibration; c) ground truth data including continuous 6-degree-of-freedom (6DoF) poses of the Aria devices, object 6DoF poses, 3D eye gaze vectors, 3D human poses, 2D image segmentations, image depth maps; and d) photo-realistic synthetic renderings. To the best of our knowledge, there is no existing egocentric dataset with a level of accuracy, photo-realism and comprehensiveness comparable to ADT. By contributing ADT to the research community, our mission is to set a new standard for evaluation in the egocentric machine perception domain, which includes very challenging research problems such as 3D object detection and tracking, scene reconstruction and understanding, sim-to-real learning, human pose prediction - while also inspiring new machine perception tasks for augmented reality (AR) applications. To kick start exploration of the ADT research use cases, we evaluated several existing state-of-the-art methods for object detection, segmentation and image translation tasks that demonstrate the usefulness of ADT as a benchmarking dataset.", "link": "https://arxiv.org/abs/2306.06362"}, {"id": "2306.06553", "date": "Sun, 11 Jun 2023 00:58:38 GMT", "title": "Hinting Pipeline and Multivariate Regression CNN for Maize Kernel\n\u00a0Counting on the Ear\n", "authors": ["Felipe Ara\\'ujo", "Igor Gadelha", "Rodrigo Tsukahara", "Luiz Pita", "Filipe\n\u00a0Costa", "Igor Vaz", "Andreza Santos and Guilherme F\\^olego\n"], "categories": ["cs.CV", "cs.AI", "cs.LG\n"], "abstract": "Maize is a highly nutritional cereal widely used for human and animal consumption and also as raw material by the biofuels industries. This highlights the importance of precisely quantifying the corn grain productivity in season, helping the commercialization process, operationalization, and critical decision-making. Considering the manual labor cost of counting maize kernels, we propose in this work a novel preprocessing pipeline named hinting that guides the attention of the model to the center of the corn kernels and enables a deep learning model to deliver better performance, given a picture of one side of the corn ear. Also, we propose a multivariate CNN regressor that outperforms single regression results. Experiments indicated that the proposed approach excels the current manual estimates, obtaining MAE of 34.4 and R2 of 0.74 against 35.38 and 0.72 for the manual estimate, respectively.", "link": "https://arxiv.org/abs/2306.06553"}, {"id": "2306.06638", "date": "Sun, 11 Jun 2023 09:52:03 GMT", "title": "Face0: Instantaneously Conditioning a Text-to-Image Model on a Face\n", "authors": ["Dani Valevski", "Danny Wasserman", "Yossi Matias", "Yaniv Leviathan\n"], "categories": ["cs.CV", "cs.AI", "cs.GR", "cs.LG\n"], "abstract": "We present Face0, a novel way to instantaneously condition a text-to-image generation model on a face, in sample time, without any optimization procedures such as fine-tuning or inversions. We augment a dataset of annotated images with embeddings of the included faces and train an image generation model, on the augmented dataset. Once trained, our system is practically identical at inference time to the underlying base model, and is therefore able to generate images, given a user-supplied face image and a prompt, in just a couple of seconds. Our method achieves pleasing results, is remarkably simple, extremely fast, and equips the underlying model with new capabilities, like controlling the generated images both via text or via direct manipulation of the input face embeddings. In addition, when using a fixed random vector instead of a face embedding from a user supplied image, our method essentially solves the problem of consistent character generation across images. Finally, while requiring further research, we hope that our method, which decouples the model's textual biases from its biases on faces, might be a step towards some mitigation of biases in future text-to-image models.", "link": "https://arxiv.org/abs/2306.06638"}, {"id": "2306.06767", "date": "Sun, 11 Jun 2023 20:39:13 GMT", "title": "The Impact of ChatGPT and LLMs on Medical Imaging Stakeholders:\n\u00a0Perspectives and Use Cases\n", "authors": ["Jiancheng Yang", "Hongwei Bran Li", "Donglai Wei\n"], "categories": ["cs.CV", "cs.AI", "cs.LG\n"], "abstract": "This study investigates the transformative potential of Large Language Models (LLMs), such as OpenAI ChatGPT, in medical imaging. With the aid of public data, these models, which possess remarkable language understanding and generation capabilities, are augmenting the interpretive skills of radiologists, enhancing patient-physician communication, and streamlining clinical workflows. The paper introduces an analytic framework for presenting the complex interactions between LLMs and the broader ecosystem of medical imaging stakeholders, including businesses, insurance entities, governments, research institutions, and hospitals (nicknamed BIGR-H). Through detailed analyses, illustrative use cases, and discussions on the broader implications and future directions, this perspective seeks to raise discussion in strategic planning and decision-making in the era of AI-enabled healthcare.", "link": "https://arxiv.org/abs/2306.06767"}, {"id": "2306.06991", "date": "Mon, 12 Jun 2023 09:38:04 GMT", "title": "Fast Diffusion Model\n", "authors": ["Zike Wu", "Pan Zhou", "Kenji Kawaguchi", "Hanwang Zhang\n"], "categories": ["cs.CV", "cs.AI", "cs.LG\n"], "abstract": "Despite their success in real data synthesis, diffusion models (DMs) often suffer from slow and costly training and sampling issues, limiting their broader applications. To mitigate this, we propose a Fast Diffusion Model (FDM) which improves the diffusion process of DMs from a stochastic optimization perspective to speed up both training and sampling. Specifically, we first find that the diffusion process of DMs accords with the stochastic optimization process of stochastic gradient descent (SGD) on a stochastic time-variant problem. Note that momentum SGD uses both the current gradient and an extra momentum, achieving more stable and faster convergence. We are inspired to introduce momentum into the diffusion process to accelerate both training and sampling. However, this comes with the challenge of deriving the noise perturbation kernel from the momentum-based diffusion process. To this end, we frame the momentum-based process as a Damped Oscillation system whose critically damped state -- the kernel solution -- avoids oscillation and thus has a faster convergence speed of the diffusion process. Empirical results show that our FDM can be applied to several popular DM frameworks, e.g. VP, VE, and EDM, and reduces their training cost by about 50% with comparable image synthesis performance on CIFAR-10, FFHQ, and AFHQv2 datasets. Moreover, FDM decreases their sampling steps by about $3\\times$ to achieve similar performance under the same deterministic samplers. The code is available at https://github.com/sail-sg/FDM.", "link": "https://arxiv.org/abs/2306.06991"}, {"id": "2306.07027", "date": "Mon, 12 Jun 2023 11:04:11 GMT", "title": "Rotational augmentation techniques: a new perspective on ensemble\n\u00a0learning for image classification\n", "authors": ["Unai Mu\\~noz-Aseguinolaza", "Basilio Sierra and Naiara Aginako\n"], "categories": ["cs.CV", "cs.AI", "cs.LG\nComments:", "15", "pages,", "5", "figures", "and", "5", "tables\n"], "abstract": "The popularity of data augmentation techniques in machine learning has increased in recent years, as they enable the creation of new samples from existing datasets. Rotational augmentation, in particular, has shown great promise by revolving images and utilising them as additional data points for training. This research study introduces a new approach to enhance the performance of classification methods where the testing sets were generated employing transformations on every image from the original dataset. Subsequently, ensemble-based systems were implemented to determine the most reliable outcome in each subset acquired from the augmentation phase to get a final prediction for every original image. The findings of this study suggest that rotational augmentation techniques can significantly improve the accuracy of standard classification models; and the selection of a voting scheme can considerably impact the model's performance. Overall, the study found that using an ensemble-based voting system produced more accurate results than simple voting.", "link": "https://arxiv.org/abs/2306.07027"}, {"id": "2306.07178", "date": "Mon, 12 Jun 2023 15:19:13 GMT", "title": "Frequency-Based Vulnerability Analysis of Deep Learning Models against\n\u00a0Image Corruptions\n", "authors": ["Harshitha Machiraju", "Michael H. Herzog", "Pascal Frossard\n"], "categories": ["cs.CV", "cs.AI", "cs.CR", "cs.LG\nComments:", "Code:", "https://github.com/code-Assasin/MUFIACode\n"], "abstract": "Deep learning models often face challenges when handling real-world image corruptions. In response, researchers have developed image corruption datasets to evaluate the performance of deep neural networks in handling such corruptions. However, these datasets have a significant limitation: they do not account for all corruptions encountered in real-life scenarios. To address this gap, we present MUFIA (Multiplicative Filter Attack), an algorithm designed to identify the specific types of corruptions that can cause models to fail. Our algorithm identifies the combination of image frequency components that render a model susceptible to misclassification while preserving the semantic similarity to the original image. We find that even state-of-the-art models trained to be robust against known common corruptions struggle against the low visibility-based corruptions crafted by MUFIA. This highlights the need for more comprehensive approaches to enhance model robustness against a wider range of real-world image corruptions.", "link": "https://arxiv.org/abs/2306.07178"}, {"id": "2306.07197", "date": "Mon, 12 Jun 2023 15:54:52 GMT", "title": "AROID: Improving Adversarial Robustness through Online Instance-wise\n\u00a0Data Augmentation\n", "authors": ["Lin Li", "Jianing Qiu", "Michael Spratling\n"], "categories": ["cs.CV", "cs.AI", "cs.LG\nComments:", "in", "submission\n"], "abstract": "Deep neural networks are vulnerable to adversarial examples. Adversarial training (AT) is an effective defense against adversarial examples. However, AT is prone to overfitting which degrades robustness substantially. Recently, data augmentation (DA) was shown to be effective in mitigating robust overfitting if appropriately designed and optimized for AT. This work proposes a new method to automatically learn online, instance-wise, DA policies to improve robust generalization for AT. A novel policy learning objective, consisting of Vulnerability, Affinity and Diversity, is proposed and shown to be sufficiently effective and efficient to be practical for automatic DA generation during AT. This allows our method to efficiently explore a large search space for a more effective DA policy and evolve the policy as training progresses. Empirically, our method is shown to outperform or match all competitive DA methods across various model architectures (CNNs and ViTs) and datasets (CIFAR10, SVHN and Imagenette). Our DA policy reinforced vanilla AT to surpass several state-of-the-art AT methods (with baseline DA) in terms of both accuracy and robustness. It can also be combined with those advanced AT methods to produce a further boost in robustness.", "link": "https://arxiv.org/abs/2306.07197"}, {"id": "2306.07207", "date": "Mon, 12 Jun 2023 16:11:10 GMT", "title": "Valley: Video Assistant with Large Language model Enhanced abilitY\n", "authors": ["Ruipu Luo", "Ziwang Zhao", "Min Yang", "Junwei Dong", "Minghui Qiu", "Pengcheng\n\u00a0Lu", "Tao Wang", "Zhongyu Wei\n"], "categories": ["cs.CV", "cs.AI", "cs.CL\n"], "abstract": "Recently, several multi-modal models have been developed for joint image and language understanding, which have demonstrated impressive chat abilities by utilizing advanced large language models (LLMs). The process of developing such models is straightforward yet effective. It involves pre-training an adaptation module to align the semantics of the vision encoder and language model, followed by fine-tuning on the instruction-following data. However, despite the success of this pipeline in image and language understanding, its effectiveness in joint video and language understanding has not been widely explored. In this paper, we aim to develop a novel multi-modal foundation model capable of perceiving video, image, and language within a general framework. To achieve this goal, we introduce Valley: Video Assistant with Large Language model Enhanced ability. Specifically, our proposed Valley model is designed with a simple projection module that bridges video, image, and language modalities, and is further unified with a multi-lingual LLM. We also collect multi-source vision-text pairs and adopt a spatio-temporal pooling strategy to obtain a unified vision encoding of video and image input for pre-training. Furthermore, we generate multi-task instruction-following video data, including multi-shot captions, long video descriptions, action recognition, causal relationship inference, etc. To obtain the instruction-following data, we design diverse rounds of task-oriented conversations between humans and videos, facilitated by ChatGPT. Qualitative examples demonstrate that our proposed model has the potential to function as a highly effective multilingual video assistant that can make complex video understanding scenarios easy. Code, data, and models will be available at https://github.com/RupertLuo/Valley.", "link": "https://arxiv.org/abs/2306.07207"}, {"id": "2306.07280", "date": "Mon, 12 Jun 2023 17:59:23 GMT", "title": "Controlling Text-to-Image Diffusion by Orthogonal Finetuning\n", "authors": ["Zeju Qiu", "Weiyang Liu", "Haiwen Feng", "Yuxuan Xue", "Yao Feng", "Zhen Liu,\n\u00a0Dan Zhang", "Adrian Weller", "Bernhard Sch\\\"olkopf\n"], "categories": ["cs.CV", "cs.AI", "cs.GR", "cs.LG\nComments:", "Technical", "Report", "(40", "pages,", "32", "figures,", "project", "page:\n\u00a0https://oft.wyliu.com/)\n"], "abstract": "Large text-to-image diffusion models have impressive capabilities in generating photorealistic images from text prompts. How to effectively guide or control these powerful models to perform different downstream tasks becomes an important open problem. To tackle this challenge, we introduce a principled finetuning method -- Orthogonal Finetuning (OFT), for adapting text-to-image diffusion models to downstream tasks. Unlike existing methods, OFT can provably preserve hyperspherical energy which characterizes the pairwise neuron relationship on the unit hypersphere. We find that this property is crucial for preserving the semantic generation ability of text-to-image diffusion models. To improve finetuning stability, we further propose Constrained Orthogonal Finetuning (COFT) which imposes an additional radius constraint to the hypersphere. Specifically, we consider two important finetuning text-to-image tasks: subject-driven generation where the goal is to generate subject-specific images given a few images of a subject and a text prompt, and controllable generation where the goal is to enable the model to take in additional control signals. We empirically show that our OFT framework outperforms existing methods in generation quality and convergence speed.", "link": "https://arxiv.org/abs/2306.07280"}, {"id": "2306.06192", "date": "Fri, 9 Jun 2023 18:45:15 GMT", "title": "Ada-NAV: Adaptive Trajectory-Based Sample Efficient Policy Learning for\n\u00a0Robotic Navigation\n", "authors": ["Bhrij Patel", "Kasun Weerakoon", "Wesley A. Suttle", "Alec Koppel", "Brian M.\n\u00a0Sadler", "Amrit Singh Bedi and Dinesh Manocha\n"], "categories": ["cs.RO", "cs.AI", "cs.LG\nComments:", "14", "pages,", "7", "figures,", "2", "tables\n"], "abstract": "Reinforcement learning methods, while effective for learning robotic navigation strategies, are known to be highly sample inefficient. This sample inefficiency comes in part from not suitably balancing the explore-exploit dilemma, especially in the presence of non-stationarity, during policy optimization. To incorporate a balance of exploration-exploitation for sample efficiency, we propose Ada-NAV, an adaptive trajectory length scheme where the length grows as a policy's randomness, represented by its Shannon or differential entropy, decreases. Our adaptive trajectory length scheme emphasizes exploration at the beginning of training due to more frequent gradient updates and emphasizes exploitation later on with longer trajectories. In gridworld, simulated robotic environments, and real-world robotic experiments, we demonstrate the merits of the approach over constant and randomly sampled trajectory lengths in terms of performance and sample efficiency. For a fixed sample budget, Ada-NAV results in an 18% increase in navigation success rate, a 20-38% decrease in the navigation path length, and 9.32% decrease in the elevation cost compared to the policies obtained by the other methods. We also demonstrate that Ada-NAV can be transferred and integrated into a Clearpath Husky robot without significant performance degradation.", "link": "https://arxiv.org/abs/2306.06192"}, {"id": "2306.06344", "date": "Sat, 10 Jun 2023 05:20:30 GMT", "title": "Language-Guided Traffic Simulation via Scene-Level Diffusion\n", "authors": ["Ziyuan Zhong", "Davis Rempe", "Yuxiao Chen", "Boris Ivanovic", "Yulong Cao,\n\u00a0Danfei Xu", "Marco Pavone", "Baishakhi Ray\n"], "categories": ["cs.RO", "cs.AI", "cs.LG\n"], "abstract": "Realistic and controllable traffic simulation is a core capability that is necessary to accelerate autonomous vehicle (AV) development. However, current approaches for controlling learning-based traffic models require significant domain expertise and are difficult for practitioners to use. To remedy this, we present CTG++, a scene-level conditional diffusion model that can be guided by language instructions. Developing this requires tackling two challenges: the need for a realistic and controllable traffic model backbone, and an effective method to interface with a traffic model using language. To address these challenges, we first propose a scene-level diffusion model equipped with a spatio-temporal transformer backbone, which generates realistic and controllable traffic. We then harness a large language model (LLM) to convert a user's query into a loss function, guiding the diffusion model towards query-compliant generation. Through comprehensive evaluation, we demonstrate the effectiveness of our proposed method in generating realistic, query-compliant traffic simulations.", "link": "https://arxiv.org/abs/2306.06344"}, {"id": "2306.06527", "date": "Sat, 10 Jun 2023 21:49:08 GMT", "title": "Contribution \\`a l'Optimisation d'un Comportement Collectif pour un\n\u00a0Groupe de Robots Autonomes\n", "authors": ["Amine Bendahmane\n"], "categories": ["cs.RO", "cs.AI", "cs.MA\nComments:", "PhD", "Thesis", "(French", "version)\nDOI:", "10.13140/RG.2.2.34066.63684\n"], "abstract": "This thesis studies the domain of collective robotics, and more particularly the optimization problems of multirobot systems in the context of exploration, path planning and coordination. It includes two contributions. The first one is the use of the Butterfly Optimization Algorithm (BOA) to solve the Unknown Area Exploration problem with energy constraints in dynamic environments. This algorithm was never used for solving robotics problems before, as far as we know. We proposed a new version of this algorithm called xBOA based on the crossover operator to improve the diversity of the candidate solutions and speed up the convergence of the algorithm. The second contribution is the development of a new simulation framework for benchmarking dynamic incremental problems in robotics such as exploration tasks. The framework is made in such a manner to be generic to quickly compare different metaheuristics with minimum modifications, and to adapt easily to single and multi-robot scenarios. Also, it provides researchers with tools to automate their experiments and generate visuals, which will allow them to focus on more important tasks such as modeling new algorithms. We conducted a series of experiments that showed promising results and allowed us to validate our approach and model.", "link": "https://arxiv.org/abs/2306.06527"}, {"id": "2306.06543", "date": "Sat, 10 Jun 2023 23:53:28 GMT", "title": "MANER: Multi-Agent Neural Rearrangement Planning of Objects in Cluttered\n\u00a0Environments\n", "authors": ["Vivek Gupta", "Praphpreet Dhir", "Jeegn Dani", "Ahmed H. Qureshi\n"], "categories": ["cs.RO", "cs.AI", "cs.LG\nComments:", "The", "videos", "and", "supplementary", "material", "are", "available", "at\n\u00a0https://sites.google.com/view/maner-supplementary\n"], "abstract": "Object rearrangement is a fundamental problem in robotics with various practical applications ranging from managing warehouses to cleaning and organizing home kitchens. While existing research has primarily focused on single-agent solutions, real-world scenarios often require multiple robots to work together on rearrangement tasks. This paper proposes a comprehensive learning-based framework for multi-agent object rearrangement planning, addressing the challenges of task sequencing and path planning in complex environments. The proposed method iteratively selects objects, determines their relocation regions, and pairs them with available robots under kinematic feasibility and task reachability for execution to achieve the target arrangement. Our experiments on a diverse range of environments demonstrate the effectiveness and robustness of the proposed framework. Furthermore, results indicate improved performance in terms of traversal time and success rate compared to baseline approaches.", "link": "https://arxiv.org/abs/2306.06543"}, {"id": "2306.06799", "date": "Sun, 11 Jun 2023 22:52:08 GMT", "title": "On the Efficacy of 3D Point Cloud Reinforcement Learning\n", "authors": ["Zhan Ling", "Yunchao Yao", "Xuanlin Li", "Hao Su\n"], "categories": ["cs.RO", "cs.AI", "cs.LG\n"], "abstract": "Recent studies on visual reinforcement learning (visual RL) have explored the use of 3D visual representations. However, none of these work has systematically compared the efficacy of 3D representations with 2D representations across different tasks, nor have they analyzed 3D representations from the perspective of agent-object / object-object relationship reasoning. In this work, we seek answers to the question of when and how do 3D neural networks that learn features in the 3D-native space provide a beneficial inductive bias for visual RL. We specifically focus on 3D point clouds, one of the most common forms of 3D representations. We systematically investigate design choices for 3D point cloud RL, leading to the development of a robust algorithm for various robotic manipulation and control tasks. Furthermore, through comparisons between 2D image vs 3D point cloud RL methods on both minimalist synthetic tasks and complex robotic manipulation tasks, we find that 3D point cloud RL can significantly outperform the 2D counterpart when agent-object / object-object relationship encoding is a key factor.", "link": "https://arxiv.org/abs/2306.06799"}, {"id": "2306.06969", "date": "Mon, 12 Jun 2023 08:57:15 GMT", "title": "Viewpoint Generation using Feature-Based Constrained Spaces for Robot\n\u00a0Vision Systems\n", "authors": ["Alejandro Maga\\~na", "Jonas Dirr", "Philipp Bauer", "Gunther Reinhart\n"], "categories": ["cs.RO", "cs.AI", "cs.CV\n"], "abstract": "The efficient computation of viewpoints under consideration of various system and process constraints is a common challenge that any robot vision system is confronted with when trying to execute a vision task. Although fundamental research has provided solid and sound solutions for tackling this problem, a holistic framework that poses its formal description, considers the heterogeneity of robot vision systems, and offers an integrated solution remains unaddressed. Hence, this publication outlines the generation of viewpoints as a geometrical problem and introduces a generalized theoretical framework based on Feature-Based Constrained Spaces ($\\mathcal{C}$-spaces) as the backbone for solving it. A $\\mathcal{C}$-space can be understood as the topological space that a viewpoint constraint spans, where the sensor can be positioned for acquiring a feature while fulfilling the regarded constraint. The present study demonstrates that many viewpoint constraints can be efficiently formulated as $\\mathcal{C}$-spaces providing geometric, deterministic, and closed solutions. The introduced $\\mathcal{C}$-spaces are characterized based on generic domain and viewpoint constraints models to ease the transferability of the present framework to different applications and robot vision systems. The effectiveness and efficiency of the concepts introduced are verified on a simulation-based scenario and validated on a real robot vision system comprising two different sensors.", "link": "https://arxiv.org/abs/2306.06969"}, {"id": "2306.07142", "date": "Mon, 12 Jun 2023 14:26:12 GMT", "title": "Evolving Testing Scenario Generation Method and Intelligence Evaluation\n\u00a0Framework for Automated Vehicles\n", "authors": ["Yining Ma", "Wei Jiang", "Lingtong Zhang", "Junyi Chen", "Hong Wang", "Chen Lv,\n\u00a0Xuesong Wang", "Lu Xiong\n"], "categories": ["eess.SY", "cs.AI", "cs.MA", "cs.RO", "cs.SY\nComments:", "18", "pages,17", "figures\n"], "abstract": "Interaction between the background vehicles (BVs) and automated vehicles (AVs) in scenario-based testing plays a critical role in evaluating the intelligence of the AVs. Current testing scenarios typically employ predefined or scripted BVs, which inadequately reflect the complexity of human-like social behaviors in real-world driving scenarios, and also lack a systematic metric for evaluating the comprehensive intelligence of AVs. Therefore, this paper proposes an evolving scenario generation method that utilizes deep reinforcement learning (DRL) to create human-like BVs for testing and intelligence evaluation of AVs. Firstly, a class of driver models with human-like competitive, cooperative, and mutual driving motivations is designed. Then, utilizing an improved \"level-k\" training procedure, the three distinct driver models acquire game-based interactive driving policies. And these models are assigned to BVs for generating evolving scenarios in which all BVs can interact continuously and evolve diverse contents. Next, a framework including safety, driving efficiency, and interaction utility are presented to evaluate and quantify the intelligence performance of 3 systems under test (SUTs), indicating the effectiveness of the evolving scenario for intelligence testing. Finally, the complexity and fidelity of the proposed evolving testing scenario are validated. The results demonstrate that the proposed evolving scenario exhibits the highest level of complexity compared to other baseline scenarios and has more than 85% similarity to naturalistic driving data. This highlights the potential of the proposed method to facilitate the development and evaluation of high-level AVs in a realistic and challenging environment.", "link": "https://arxiv.org/abs/2306.07142"}, {"id": "2306.06109", "date": "Fri, 26 May 2023 04:13:31 GMT", "title": "Learning to Quantize Vulnerability Patterns and Match to Locate\n\u00a0Statement-Level Vulnerabilities\n", "authors": ["Michael Fu", "Trung Le", "Van Nguyen", "Chakkrit Tantithamthavorn", "Dinh\n\u00a0Phung\n"], "categories": ["cs.CR", "cs.AI", "cs.LG\n"], "abstract": "Deep learning (DL) models have become increasingly popular in identifying software vulnerabilities. Prior studies found that vulnerabilities across different vulnerable programs may exhibit similar vulnerable scopes, implicitly forming discernible vulnerability patterns that can be learned by DL models through supervised training. However, vulnerable scopes still manifest in various spatial locations and formats within a program, posing challenges for models to accurately identify vulnerable statements. Despite this challenge, state-of-the-art vulnerability detection approaches fail to exploit the vulnerability patterns that arise in vulnerable programs. To take full advantage of vulnerability patterns and unleash the ability of DL models, we propose a novel vulnerability-matching approach in this paper, drawing inspiration from program analysis tools that locate vulnerabilities based on pre-defined patterns. Specifically, a vulnerability codebook is learned, which consists of quantized vectors representing various vulnerability patterns. During inference, the codebook is iterated to match all learned patterns and predict the presence of potential vulnerabilities within a given program. Our approach was extensively evaluated on a real-world dataset comprising more than 188,000 C/C++ functions. The evaluation results show that our approach achieves an F1-score of 94% (6% higher than the previous best) and 82% (19% higher than the previous best) for function and statement-level vulnerability identification, respectively. These substantial enhancements highlight the effectiveness of our approach to identifying vulnerabilities. The training code and pre-trained models are available at https://github.com/optimatch/optimatch.", "link": "https://arxiv.org/abs/2306.06109"}, {"id": "2306.06123", "date": "Tue, 6 Jun 2023 09:53:39 GMT", "title": "Adversarial Attacks and Defenses in Explainable Artificial Intelligence:\n\u00a0A Survey\n", "authors": ["Hubert Baniecki and Przemyslaw Biecek\n"], "categories": ["cs.CR", "cs.AI", "cs.CV", "cs.LG\nComments:", "To", "be", "presented", "at", "the", "IJCAI", "2023", "Workshop", "on", "XAI\n"], "abstract": "Explainable artificial intelligence (XAI) methods are portrayed as a remedy for debugging and trusting statistical and deep learning models, as well as interpreting their predictions. However, recent advances in adversarial machine learning highlight the limitations and vulnerabilities of state-of-the-art explanations, putting their security and trustworthiness into question. The possibility of manipulating, fooling or fairwashing evidence of the model's reasoning has detrimental consequences when applied in high-stakes decision-making and knowledge discovery. This concise survey of over 50 papers summarizes research concerning adversarial attacks on explanations of machine learning models, as well as fairness metrics. We discuss how to defend against attacks and design robust interpretation methods. We contribute a list of existing insecurities in XAI and outline the emerging research directions in adversarial XAI (AdvXAI).", "link": "https://arxiv.org/abs/2306.06123"}, {"id": "2306.06233", "date": "Fri, 9 Jun 2023 20:08:46 GMT", "title": "Boosting GUI Prototyping with Diffusion Models\n", "authors": ["Jialiang Wei", "Anne-Lise Courbis", "Thomas Lambolais", "Binbin Xu", "Pierre\n\u00a0Louis Bernard", "G\\'erard Dray\n"], "categories": ["cs.SE", "cs.AI", "cs.CV\nComments:", "Accepted", "for", "The", "31st", "IEEE", "International", "Requirements", "Engineering\n\u00a0Conference", "2023,", "RE@Next!", "track\n"], "abstract": "GUI (graphical user interface) prototyping is a widely-used technique in requirements engineering for gathering and refining requirements, reducing development risks and increasing stakeholder engagement. However, GUI prototyping can be a time-consuming and costly process. In recent years, deep learning models such as Stable Diffusion have emerged as a powerful text-to-image tool capable of generating detailed images based on text prompts. In this paper, we propose UI-Diffuser, an approach that leverages Stable Diffusion to generate mobile UIs through simple textual descriptions and UI components. Preliminary results show that UI-Diffuser provides an efficient and cost-effective way to generate mobile GUI designs while reducing the need for extensive prototyping efforts. This approach has the potential to significantly improve the speed and efficiency of GUI prototyping in requirements engineering.", "link": "https://arxiv.org/abs/2306.06233"}, {"id": "2306.06284", "date": "Fri, 9 Jun 2023 22:24:05 GMT", "title": "Everybody Compose: Deep Beats To Music\n", "authors": ["Conghao Shen", "Violet Z. Yao", "Yixin Liu\n"], "categories": ["cs.SD", "cs.AI", "cs.MM", "eess.AS\nComments:", "Accepted", "MMSys", "'23\nJournal-ref:", "Proceedings", "of", "the", "14th", "Conference", "on", "ACM", "Multimedia", "Systems\n\u00a0(2023)\nDOI:", "10.1145/3587819.3592542\n"], "abstract": "This project presents a deep learning approach to generate monophonic melodies based on input beats, allowing even amateurs to create their own music compositions. Three effective methods - LSTM with Full Attention, LSTM with Local Attention, and Transformer with Relative Position Representation - are proposed for this novel task, providing great variation, harmony, and structure in the generated music. This project allows anyone to compose their own music by tapping their keyboards or ``recoloring'' beat sequences from existing works.", "link": "https://arxiv.org/abs/2306.06284"}, {"id": "2306.06521", "date": "Sat, 10 Jun 2023 21:09:16 GMT", "title": "Universal Language Modelling agent\n", "authors": ["Anees Aslam\n"], "categories": ["cs.CL", "cs.AI", "cs.LG\n"], "abstract": "Large Language Models are designed to understand complex Human Language. Yet, Understanding of animal language has long intrigued researchers striving to bridge the communication gap between humans and other species. This research paper introduces a novel approach that draws inspiration from the linguistic concepts found in the Quran, a revealed Holy Arabic scripture dating back 1400 years. By exploring the linguistic structure of the Quran, specifically the components of ism, fil, and harf, we aim to unlock the underlying intentions and meanings embedded within animal conversations using audio data. To unravel the intricate complexities of animal language, we employ word embedding techniques to analyze each distinct frequency component. This methodology enables the identification of potential correlations and the extraction of meaningful insights from the data. Furthermore, we leverage a bioacoustics model to generate audio, which serves as a valuable resource for training natural language processing (NLP) techniques. This Paper aims to find the intention* behind animal language rather than having each word translation.", "link": "https://arxiv.org/abs/2306.06521"}, {"id": "2306.06651", "date": "Sun, 11 Jun 2023 11:16:27 GMT", "title": "Predicting Software Performance with Divide-and-Learn\n", "authors": ["Jingzhi Gong", "Tao Chen\n"], "categories": ["cs.SE", "cs.AI", "cs.PF\nComments:", "This", "paper", "has", "been", "accepted", "by", "The", "ACM", "Joint", "European", "Software\n\u00a0Engineering", "Conference", "and", "Symposium", "on", "the", "Foundations", "of", "Software\n\u00a0Engineering", "(ESEC/FSE),", "2023\n"], "abstract": "Predicting the performance of highly configurable software systems is the foundation for performance testing and quality assurance. To that end, recent work has been relying on machine/deep learning to model software performance. However, a crucial yet unaddressed challenge is how to cater for the sparsity inherited from the configuration landscape: the influence of configuration options (features) and the distribution of data samples are highly sparse. In this paper, we propose an approach based on the concept of 'divide-and-learn', dubbed $DaL$. The basic idea is that, to handle sample sparsity, we divide the samples from the configuration landscape into distant divisions, for each of which we build a regularized Deep Neural Network as the local model to deal with the feature sparsity. A newly given configuration would then be assigned to the right model of division for the final prediction. Experiment results from eight real-world systems and five sets of training data reveal that, compared with the state-of-the-art approaches, $DaL$ performs no worse than the best counterpart on 33 out of 40 cases (within which 26 cases are significantly better) with up to $1.94\\times$ improvement on accuracy; requires fewer samples to reach the same/better accuracy; and producing acceptable training overhead. Practically, $DaL$ also considerably improves different global models when using them as the underlying local models, which further strengthens its flexibility. To promote open science, all the data, code, and supplementary figures of this work can be accessed at our repository: https://github.com/ideas-labo/DaL.", "link": "https://arxiv.org/abs/2306.06651"}, {"id": "2306.06672", "date": "Sun, 11 Jun 2023 12:53:46 GMT", "title": "Reducing Barriers to Self-Supervised Learning: HuBERT Pre-training with\n\u00a0Academic Compute\n", "authors": ["William Chen", "Xuankai Chang", "Yifan Peng", "Zhaoheng Ni", "Soumi Maiti,\n\u00a0Shinji Watanabe\n"], "categories": ["cs.CL", "cs.AI", "eess.AS\nComments:", "Accepted", "at", "INTERSPEECH", "2023\n"], "abstract": "Self-supervised learning (SSL) has led to great strides in speech processing. However, the resources needed to train these models has become prohibitively large as they continue to scale. Currently, only a few groups with substantial resources are capable of creating SSL models, which harms reproducibility. In this work, we optimize HuBERT SSL to fit in academic constraints. We reproduce HuBERT independently from the original implementation, with no performance loss. Our code and training optimizations make SSL feasible with only 8 GPUs, instead of the 32 used in the original work. We also explore a semi-supervised route, using an ASR model to skip the first pre-training iteration. Within one iteration of pre-training, our models improve over HuBERT on several tasks. Furthermore, our HuBERT Large variant requires only 8 GPUs, achieving similar performance to the original trained on 128. As our contribution to the community, all models, configurations, and code are made open-source in ESPnet.", "link": "https://arxiv.org/abs/2306.06672"}, {"id": "2306.06686", "date": "Sun, 11 Jun 2023 14:01:15 GMT", "title": "UAV Trajectory and Multi-User Beamforming Optimization for Clustered\n\u00a0Users Against Passive Eavesdropping Attacks With Unknown CSI\n", "authors": ["Aly Sabri Abdalla", "Ali Behfarnia", "and Vuk Marojevic\n"], "categories": ["cs.IT", "cs.AI", "cs.CR", "eess.SP", "math.IT\nComments:", "This", "paper", "has", "been", "accepted", "for", "publication", "in", "the", "IEEE", "Transactions\n\u00a0on", "Vehicular", "Technology\n"], "abstract": "This paper tackles the fundamental passive eavesdropping problem in modern wireless communications in which the location and the channel state information (CSI) of the attackers are unknown. In this regard, we propose deploying an unmanned aerial vehicle (UAV) that serves as a mobile aerial relay (AR) to help ground base station (GBS) support a subset of vulnerable users. More precisely, our solution (1) clusters the single-antenna users in two groups to be either served by the GBS directly or via the AR, (2) employs optimal multi-user beamforming to the directly served users, and (3) optimizes the AR's 3D position, its multi-user beamforming matrix and transmit powers by combining closed-form solutions with machine learning techniques. Specifically, we design a plain beamforming and power optimization combined with a deep reinforcement learning (DRL) algorithm for an AR to optimize its trajectory for the security maximization of the served users. Numerical results show that the multi-user multiple input, single output (MU-MISO) system split between a GBS and an AR with optimized transmission parameters without knowledge of the eavesdropping channels achieves high secrecy capacities that scale well with increasing the number of users.", "link": "https://arxiv.org/abs/2306.06686"}, {"id": "2306.06755", "date": "Sun, 11 Jun 2023 19:47:52 GMT", "title": "Attention, Compilation, and Solver-based Symbolic Analysis are All You\n\u00a0Need\n", "authors": ["Prithwish Jana", "Piyush Jha", "Haoyang Ju", "Gautham Kishore", "Aryan Mahajan\n\u00a0and Vijay Ganesh\n"], "categories": ["cs.PL", "cs.AI", "cs.SE\nACM-class:", "I.2.7;", "I.2.5;", "D.2\n"], "abstract": "In this paper we present a Java-to-Python (J2P) and Python-to-Java (P2J) back-to-back code translation method, and associated tool called CoTran, based on large language models (LLMs). Our method leverages the attention mechanism of LLMs, compilation, and symbolic execution-based test generation for equivalence testing between the input and output programs. More precisely, we modify the typical LLM training loop to incorporate compiler and symbolic execution loss. Via extensive experiments comparing CoTran with 10 other transpilers and LLM-based translation tools over a benchmark of more than 57,000 Java-Python equivalent pairs, we show that CoTran outperforms them on relevant metrics such as compilation and runtime equivalence accuracy. For example, our tool gets 97.43% compilation accuracy and 49.66% runtime equivalence accuracy for J2P translation, whereas the nearest competing tool only gets 96.44% and 6.8% respectively.", "link": "https://arxiv.org/abs/2306.06755"}, {"id": "2306.06812", "date": "Mon, 12 Jun 2023 01:06:22 GMT", "title": "Particularity\n", "authors": ["Lee Spector", "Li Ding", "Ryan Boldi\n"], "categories": ["cs.NE", "cs.AI", "cs.LG\nComments:", "Genetic", "Programming", "Theory", "and", "Practice", "XX\nACM-class:", "I.2.2;", "I.2.6\n"], "abstract": "We describe a design principle for adaptive systems under which adaptation is driven by particular challenges that the environment poses, as opposed to average or otherwise aggregated measures of performance over many challenges. We trace the development of this \"particularity\" approach from the use of lexicase selection in genetic programming to \"particularist\" approaches to other forms of machine learning and to the design of adaptive systems more generally.", "link": "https://arxiv.org/abs/2306.06812"}, {"id": "2306.06814", "date": "Mon, 12 Jun 2023 01:21:41 GMT", "title": "HiddenSinger: High-Quality Singing Voice Synthesis via Neural Audio\n\u00a0Codec and Latent Diffusion Models\n", "authors": ["Ji-Sang Hwang", "Sang-Hoon Lee", "and Seong-Whan Lee\n"], "categories": ["eess.AS", "cs.AI", "cs.SD", "eess.SP\nComments:", "11", "pages,", "5", "figures,", "5", "tables,", "under", "review\n"], "abstract": "Recently, denoising diffusion models have demonstrated remarkable performance among generative models in various domains. However, in the speech domain, the application of diffusion models for synthesizing time-varying audio faces limitations in terms of complexity and controllability, as speech synthesis requires very high-dimensional samples with long-term acoustic features. To alleviate the challenges posed by model complexity in singing voice synthesis, we propose HiddenSinger, a high-quality singing voice synthesis system using a neural audio codec and latent diffusion models. To ensure high-fidelity audio, we introduce an audio autoencoder that can encode audio into an audio codec as a compressed representation and reconstruct the high-fidelity audio from the low-dimensional compressed latent vector. Subsequently, we use the latent diffusion models to sample a latent representation from a musical score. In addition, our proposed model is extended to an unsupervised singing voice learning framework, HiddenSinger-U, to train the model using an unlabeled singing voice dataset. Experimental results demonstrate that our model outperforms previous models in terms of audio quality. Furthermore, the HiddenSinger-U can synthesize high-quality singing voices of speakers trained solely on unlabeled data.", "link": "https://arxiv.org/abs/2306.06814"}, {"id": "2306.06826", "date": "Mon, 12 Jun 2023 02:26:00 GMT", "title": "When Do Annotator Demographics Matter? Measuring the Influence of\n\u00a0Annotator Demographics with the POPQUORN Dataset\n", "authors": ["Jiaxin Pei and David Jurgens\n"], "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC", "cs.LG\n"], "abstract": "Annotators are not fungible. Their demographics, life experiences, and backgrounds all contribute to how they label data. However, NLP has only recently considered how annotator identity might influence their decisions. Here, we present POPQUORN (the POtato-Prolific dataset for QUestion-Answering, Offensiveness, text Rewriting, and politeness rating with demographic Nuance). POPQUORN contains 45,000 annotations from 1,484 annotators, drawn from a representative sample regarding sex, age, and race as the US population. Through a series of analyses, we show that annotators' background plays a significant role in their judgments. Further, our work shows that backgrounds not previously considered in NLP (e.g., education), are meaningful and should be considered. Our study suggests that understanding the background of annotators and collecting labels from a demographically balanced pool of crowd workers is important to reduce the bias of datasets. The dataset, annotator background, and annotation interface are available at https://github.com/Jiaxin-Pei/potato-prolific-dataset .", "link": "https://arxiv.org/abs/2306.06826"}, {"id": "2306.07061", "date": "Mon, 12 Jun 2023 12:24:47 GMT", "title": "Deep Model Compression Also Helps Models Capture Ambiguity\n", "authors": ["Hancheol Park", "Jong C. Park\n"], "categories": ["cs.CL", "cs.AI", "cs.LG\nComments:", "ACL", "2023\n"], "abstract": "Natural language understanding (NLU) tasks face a non-trivial amount of ambiguous samples where veracity of their labels is debatable among annotators. NLU models should thus account for such ambiguity, but they approximate the human opinion distributions quite poorly and tend to produce over-confident predictions. To address this problem, we must consider how to exactly capture the degree of relationship between each sample and its candidate classes. In this work, we propose a novel method with deep model compression and show how such relationship can be accounted for. We see that more reasonably represented relationships can be discovered in the lower layers and that validation accuracies are converging at these layers, which naturally leads to layer pruning. We also see that distilling the relationship knowledge from a lower layer helps models produce better distribution. Experimental results demonstrate that our method makes substantial improvement on quantifying ambiguity without gold distribution labels. As positive side-effects, our method is found to reduce the model size significantly and improve latency, both attractive aspects of NLU products.", "link": "https://arxiv.org/abs/2306.07061"}, {"id": "2306.07075", "date": "Mon, 12 Jun 2023 12:40:48 GMT", "title": "Large Language Models as Tax Attorneys: A Case Study in Legal\n\u00a0Capabilities Emergence\n", "authors": ["John J. Nay", "David Karamardian", "Sarah B. Lawsky", "Wenting Tao", "Meghana\n\u00a0Bhat", "Raghav Jain", "Aaron Travis Lee", "Jonathan H. Choi", "Jungo Kasai\n"], "categories": ["cs.CL", "cs.AI", "cs.CY\n"], "abstract": "Better understanding of Large Language Models' (LLMs) legal analysis abilities can contribute to improving the efficiency of legal services, governing artificial intelligence, and leveraging LLMs to identify inconsistencies in law. This paper explores LLM capabilities in applying tax law. We choose this area of law because it has a structure that allows us to set up automated validation pipelines across thousands of examples, requires logical reasoning and maths skills, and enables us to test LLM capabilities in a manner relevant to real-world economic lives of citizens and companies. Our experiments demonstrate emerging legal understanding capabilities, with improved performance in each subsequent OpenAI model release. We experiment with retrieving and utilising the relevant legal authority to assess the impact of providing additional legal context to LLMs. Few-shot prompting, presenting examples of question-answer pairs, is also found to significantly enhance the performance of the most advanced model, GPT-4. The findings indicate that LLMs, particularly when combined with prompting enhancements and the correct legal texts, can perform at high levels of accuracy but not yet at expert tax lawyer levels. As LLMs continue to advance, their ability to reason about law autonomously could have significant implications for the legal profession and AI governance.", "link": "https://arxiv.org/abs/2306.07075"}, {"id": "2306.07089", "date": "Mon, 12 Jun 2023 13:01:50 GMT", "title": "Topology Repairing of Disconnected Pulmonary Airways and Vessels:\n\u00a0Baselines and a Dataset\n", "authors": ["Ziqiao Weng", "Jiancheng Yang", "Dongnan Liu", "Weidong Cai\n"], "categories": ["eess.IV", "cs.AI", "cs.CV\nComments:", "MICCAI", "2023", "Early", "Accepted\n"], "abstract": "Accurate segmentation of pulmonary airways and vessels is crucial for the diagnosis and treatment of pulmonary diseases. However, current deep learning approaches suffer from disconnectivity issues that hinder their clinical usefulness. To address this challenge, we propose a post-processing approach that leverages a data-driven method to repair the topology of disconnected pulmonary tubular structures. Our approach formulates the problem as a keypoint detection task, where a neural network is trained to predict keypoints that can bridge disconnected components. We use a training data synthesis pipeline that generates disconnected data from complete pulmonary structures. Moreover, the new Pulmonary Tree Repairing (PTR) dataset is publicly available, which comprises 800 complete 3D models of pulmonary airways, arteries, and veins, as well as the synthetic disconnected data. Our code and data are available at https://github.com/M3DV/pulmonary-tree-repairing.", "link": "https://arxiv.org/abs/2306.07089"}, {"id": "2306.07111", "date": "Mon, 12 Jun 2023 13:39:54 GMT", "title": "Linear Classifier: An Often-Forgotten Baseline for Text Classification\n", "authors": ["Yu-Chen Lin", "Si-An Chen", "Jie-Jyun Liu", "and Chih-Jen Lin\n"], "categories": ["cs.CL", "cs.AI", "cs.LG\nComments:", "Accepted", "by", "ACL", "2023\n"], "abstract": "Large-scale pre-trained language models such as BERT are popular solutions for text classification. Due to the superior performance of these advanced methods, nowadays, people often directly train them for a few epochs and deploy the obtained model. In this opinion paper, we point out that this way may only sometimes get satisfactory results. We argue the importance of running a simple baseline like linear classifiers on bag-of-words features along with advanced methods. First, for many text data, linear methods show competitive performance, high efficiency, and robustness. Second, advanced models such as BERT may only achieve the best results if properly applied. Simple baselines help to confirm whether the results of advanced models are acceptable. Our experimental results fully support these points.", "link": "https://arxiv.org/abs/2306.07111"}, {"id": "2306.07117", "date": "Mon, 12 Jun 2023 13:52:01 GMT", "title": "Language of Bargaining\n", "authors": ["Mourad Heddaya", "Solomon Dworkin", "Chenhao Tan", "Rob Voigt", "Alexander\n\u00a0Zentefis\n"], "categories": ["cs.CL", "cs.AI", "cs.CY\nComments:", "ACL", "2023", "Main", "Conference\n"], "abstract": "Leveraging an established exercise in negotiation education, we build a novel dataset for studying how the use of language shapes bilateral bargaining. Our dataset extends existing work in two ways: 1) we recruit participants via behavioral labs instead of crowdsourcing platforms and allow participants to negotiate through audio, enabling more naturalistic interactions; 2) we add a control setting where participants negotiate only through alternating, written numeric offers.Despite the two contrasting forms of communication, we find that the average agreed prices of the two treatments are identical. But when subjects can talk, fewer offers are exchanged, negotiations finish faster, the likelihood of reaching agreement rises, and the variance of prices at which subjects agree drops substantially. We further propose a taxonomy of speech acts in negotiation and enrich the dataset with annotated speech acts. We set up prediction tasks to predict negotiation success and find that being reactive to the arguments of the other party is advantageous over driving the negotiation.", "link": "https://arxiv.org/abs/2306.07117"}, {"id": "2306.07209", "date": "Mon, 12 Jun 2023 16:12:56 GMT", "title": "Data-Copilot: Bridging Billions of Data and Humans with Autonomous\n\u00a0Workflow\n", "authors": ["Wenqi Zhang", "Yongliang Shen", "Weiming Lu", "Yueting Zhuang\n"], "categories": ["cs.CL", "cs.AI", "cs.CE\n"], "abstract": "Various industries such as finance, meteorology, and energy generate vast amounts of heterogeneous data every day. There is a natural demand for humans to manage, process, and display data efficiently. However, it necessitates labor-intensive efforts and a high level of expertise for these data-related tasks. Considering that large language models (LLMs) have showcased promising capabilities in semantic understanding and reasoning, we advocate that the deployment of LLMs could autonomously manage and process massive amounts of data while displaying and interacting in a human-friendly manner. Based on this belief, we propose Data-Copilot, an LLM-based system that connects numerous data sources on one end and caters to diverse human demands on the other end. Acting like an experienced expert, Data-Copilot autonomously transforms raw data into visualization results that best match the user's intent. Specifically, Data-Copilot autonomously designs versatile interfaces (tools) for data management, processing, prediction, and visualization. In real-time response, it automatically deploys a concise workflow by invoking corresponding interfaces step by step for the user's request. The interface design and deployment processes are fully controlled by Data-Copilot itself, without human assistance. Besides, we create a Data-Copilot demo that links abundant data from different domains (stock, fund, company, economics, and live news) and accurately respond to diverse requests, serving as a reliable AI assistant.", "link": "https://arxiv.org/abs/2306.07209"}, {"id": "2306.07220", "date": "Mon, 12 Jun 2023 16:26:38 GMT", "title": "Strokes2Surface: Recovering Curve Networks From 4D Architectural Design\n\u00a0Sketches\n", "authors": ["S. Rasoulzadeh", "M. Wimmer", "and I. Kovacic\n"], "categories": ["cs.GR", "cs.AI", "cs.LG\nComments:", "14", "pages,", "16", "figures\nACM-class:", "I.2;", "I.3\n"], "abstract": "We present Strokes2Surface, an offline geometry-reconstruction pipeline built upon a 4D Sketching Interface, MR.Sketch, targeted at architectural design. The pipeline recovers a curve network from designer-drawn strokes, thus bridging between concept design and digital modeling stages in architectural design. The input to our pipeline consists of 3D strokes' polyline vertices and their corresponding timestamps (as of the fourth dimension), along with additional geometric and stylus-related recorded properties. Inspired by sketch consolidation and sketch-based modeling methods, our pipeline leverages such data and combines three Machine Learning (ML) models; a classifier and two clustering models. In particular, based on observations of practices designers typically employ in architectural design sketches, we solve a binary classification problem to recognize whether a stroke depicts a boundary and edge or is used to fill in the enclosing areas and faces of the intended architectural object. Followed by the two clustering models, strokes of each type are further parsed into groups, each representing either a single edge or a single face. Next, groups representing edges are approximated with B-spline curves, followed by a topology-recovering process identifying and fixing desired connectivities between the curves forming a well-connected curve network. Next, groups representing the faces are employed to detect the cycles bounding patches in the curve network, resulting in the final surface mesh geometry of the architectural object. We confirm the usability of Strokes2Surface via a user study and further validate and compare our results against a range of reconstructions computed using alternative methods. We also introduce our manually labeled dataset of 4D architectural design sketches for further use in the community.", "link": "https://arxiv.org/abs/2306.07220"}, {"id": "2306.06360", "date": "Sat, 10 Jun 2023 06:39:28 GMT", "title": "3D reconstruction using Structure for Motion\n", "authors": ["Kshitij Karnawat", "Hritvik Choudhari", "Abhimanyu Saxena", "Mudit Singal,\n\u00a0Raajith Gadam\n"], "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO\nComments:", "Implementation", "code", "can", "be", "found", "at\n\u00a0https://github.com/KshitijKarnawat/Structure-from-Motion\nMSC-class:", "65D19\n"], "abstract": "We are working towards 3D reconstruction of indoor spaces using a pair of HDR cameras in a stereo vision configuration mounted on an indoor mobile floor robot that captures various textures and spatial features as 2D images and this data is simultaneously utilized as a feed to our algorithm which will allow us to visualize the depth map.", "link": "https://arxiv.org/abs/2306.06360"}, {"id": "2306.06136", "date": "Fri, 9 Jun 2023 02:26:28 GMT", "title": "Robustness Testing for Multi-Agent Reinforcement Learning: State\n\u00a0Perturbations on Critical Agents\n", "authors": ["Ziyuan Zhou and Guanjun Liu\n"], "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.MA\n"], "abstract": "Multi-Agent Reinforcement Learning (MARL) has been widely applied in many fields such as smart traffic and unmanned aerial vehicles. However, most MARL algorithms are vulnerable to adversarial perturbations on agent states. Robustness testing for a trained model is an essential step for confirming the trustworthiness of the model against unexpected perturbations. This work proposes a novel Robustness Testing framework for MARL that attacks states of Critical Agents (RTCA). The RTCA has two innovations: 1) a Differential Evolution (DE) based method to select critical agents as victims and to advise the worst-case joint actions on them; and 2) a team cooperation policy evaluation method employed as the objective function for the optimization of DE. Then, adversarial state perturbations of the critical agents are generated based on the worst-case joint actions. This is the first robustness testing framework with varying victim agents. RTCA demonstrates outstanding performance in terms of the number of victim agents and destroying cooperation policies.", "link": "https://arxiv.org/abs/2306.06136"}, {"id": "2306.06139", "date": "Fri, 9 Jun 2023 07:00:00 GMT", "title": "WePaMaDM-Outlier Detection: Weighted Outlier Detection using Pattern\n\u00a0Approaches for Mass Data Mining\n", "authors": ["Ravindrakumar Purohit", "Jai Prakash Verma", "Rachna Jain", "Madhuri Bhavsar\n"], "categories": ["cs.LG", "cs.AI", "cs.CV\n"], "abstract": "Weighted Outlier Detection is a method for identifying unusual or anomalous data points in a dataset, which can be caused by various factors like human error, fraud, or equipment malfunctions. Detecting outliers can reveal vital information about system faults, fraudulent activities, and patterns in the data, assisting experts in addressing the root causes of these anomalies. However,creating a model of normal data patterns to identify outliers can be challenging due to the nature of input data, labeled data availability, and specific requirements of the problem. This article proposed the WePaMaDM-Outlier Detection with distinct mass data mining domain, demonstrating that such techniques are domain-dependent and usually developed for specific problem formulations. Nevertheless, similar domains can adapt solutions with modifications. This work also investigates the significance of data modeling in outlier detection techniques in surveillance, fault detection, and trend analysis, also referred to as novelty detection, a semisupervised task where the algorithm learns to recognize abnormality while being taught the normal class.", "link": "https://arxiv.org/abs/2306.06139"}, {"id": "2306.06193", "date": "Fri, 9 Jun 2023 18:45:43 GMT", "title": "Consistent Explanations in the Face of Model Indeterminacy via\n\u00a0Ensembling\n", "authors": ["Dan Ley", "Leonard Tang", "Matthew Nazari", "Hongjin Lin", "Suraj Srinivas,\n\u00a0Himabindu Lakkaraju\n"], "categories": ["cs.LG", "cs.AI", "cs.CY\n"], "abstract": "This work addresses the challenge of providing consistent explanations for predictive models in the presence of model indeterminacy, which arises due to the existence of multiple (nearly) equally well-performing models for a given dataset and task. Despite their similar performance, such models often exhibit inconsistent or even contradictory explanations for their predictions, posing challenges to end users who rely on these models to make critical decisions. Recognizing this issue, we introduce ensemble methods as an approach to enhance the consistency of the explanations provided in these scenarios. Leveraging insights from recent work on neural network loss landscapes and mode connectivity, we devise ensemble strategies to efficiently explore the $\\textit{underspecification set}$ -- the set of models with performance variations resulting solely from changes in the random seed during training. Experiments on five benchmark financial datasets reveal that ensembling can yield significant improvements when it comes to explanation similarity, and demonstrate the potential of existing ensemble methods to explore the underspecification set efficiently. Our findings highlight the importance of considering model indeterminacy when interpreting explanations and showcase the effectiveness of ensembles in enhancing the reliability of explanations in machine learning.", "link": "https://arxiv.org/abs/2306.06193"}, {"id": "2306.06196", "date": "Fri, 9 Jun 2023 18:53:25 GMT", "title": "ElectroCardioGuard: Preventing Patient Misidentification in\n\u00a0Electrocardiogram Databases through Neural Networks\n", "authors": ["Michal Sej\\'ak", "Jakub Sido", "David \\v{Z}ahour\n"], "categories": ["cs.LG", "cs.AI", "eess.SP\nComments:", "22", "pages,", "4", "figures,", "6", "tables\n"], "abstract": "Electrocardiograms (ECGs) are commonly used by cardiologists to detect heart-related pathological conditions. Reliable collections of ECGs are crucial for precise diagnosis. However, in clinical practice, the assignment of captured ECG recordings to incorrect patients can occur inadvertently. In collaboration with a clinical and research facility which recognized this challenge and reached out to us, we present a study that addresses this issue. In this work, we propose a small and efficient neural-network based model for determining whether two ECGs originate from the same patient. Our model demonstrates great generalization capabilities and achieves state-of-the-art performance in gallery-probe patient identification on PTB-XL while utilizing 760x fewer parameters. Furthermore, we present a technique leveraging our model for detection of recording-assignment mistakes, showcasing its applicability in a realistic scenario. Finally, we evaluate our model on a newly collected ECG dataset specifically curated for this study, and make it public for the research community.", "link": "https://arxiv.org/abs/2306.06196"}, {"id": "2306.06202", "date": "Fri, 9 Jun 2023 19:10:16 GMT", "title": "NeuroGraph: Benchmarks for Graph Machine Learning in Brain Connectomics\n", "authors": ["Anwar Said", "Roza G. Bayrak", "Tyler Derr", "Mudassir Shabbir", "Daniel\n\u00a0Moyer", "Catie Chang", "Xenofon Koutsoukos\n"], "categories": ["cs.LG", "cs.AI", "q-bio.NC\n"], "abstract": "Machine learning provides a valuable tool for analyzing high-dimensional functional neuroimaging data, and is proving effective in predicting various neurological conditions, psychiatric disorders, and cognitive patterns. In functional Magnetic Resonance Imaging (MRI) research, interactions between brain regions are commonly modeled using graph-based representations. The potency of graph machine learning methods has been established across myriad domains, marking a transformative step in data interpretation and predictive modeling. Yet, despite their promise, the transposition of these techniques to the neuroimaging domain remains surprisingly under-explored due to the expansive preprocessing pipeline and large parameter search space for graph-based datasets construction. In this paper, we introduce NeuroGraph, a collection of graph-based neuroimaging datasets that span multiple categories of behavioral and cognitive traits. We delve deeply into the dataset generation search space by crafting 35 datasets within both static and dynamic contexts, running in excess of 15 baseline methods for benchmarking. Additionally, we provide generic frameworks for learning on dynamic as well as static graphs. Our extensive experiments lead to several key observations. Notably, using correlation vectors as node features, incorporating larger number of regions of interest, and employing sparser graphs lead to improved performance. To foster further advancements in graph-based data driven Neuroimaging, we offer a comprehensive open source Python package that includes the datasets, baseline implementations, model training, and standard evaluation. The package is publicly accessible at https://anwar-said.github.io/anwarsaid/neurograph.html .", "link": "https://arxiv.org/abs/2306.06202"}, {"id": "2306.06238", "date": "Fri, 9 Jun 2023 20:18:05 GMT", "title": "Understanding the Effect of the Long Tail on Neural Network Compression\n", "authors": ["Harvey Dam", "Vinu Joseph", "Aditya Bhaskara", "Ganesh Gopalakrishna", "Saurav\n\u00a0Muralidharan", "Michael Garland\n"], "categories": ["cs.LG", "cs.AI", "cs.CV\n"], "abstract": "Network compression is now a mature sub-field of neural network research: over the last decade, significant progress has been made towards reducing the size of models and speeding up inference, while maintaining the classification accuracy. However, many works have observed that focusing on just the overall accuracy can be misguided. E.g., it has been shown that mismatches between the full and compressed models can be biased towards under-represented classes. This raises the important research question, \\emph{can we achieve network compression while maintaining ``semantic equivalence'' with the original network?} In this work, we study this question in the context of the ``long tail'' phenomenon in computer vision datasets observed by Feldman, et al. They argue that \\emph{memorization} of certain inputs (appropriately defined) is essential to achieving good generalization. As compression limits the capacity of a network (and hence also its ability to memorize), we study the question: are mismatches between the full and compressed models correlated with the memorized training data? We present positive evidence in this direction for image classification tasks, by considering different base architectures and compression schemes.", "link": "https://arxiv.org/abs/2306.06238"}, {"id": "2306.06251", "date": "Fri, 9 Jun 2023 20:46:31 GMT", "title": "Design Principles for Generalization and Scalability of AI in\n\u00a0Communication Systems\n", "authors": ["Pablo Soldati", "Euhanna Ghadimi", "Burak Demirel", "Yu Wang", "Raimundas\n\u00a0Gaigalas and Mathias Sintorn\n"], "categories": ["cs.LG", "cs.AI", "cs.NI\n"], "abstract": "Artificial intelligence (AI) has emerged as a powerful tool for addressing complex and dynamic tasks in communication systems, where traditional rule-based algorithms often struggle. However, most AI applications to networking tasks are designed and trained for specific, limited conditions, hindering the algorithms from learning and adapting to generic situations, such as those met across radio access networks (RAN). This paper proposes design principles for sustainable and scalable AI integration in communication systems, focusing on creating AI algorithms that can generalize across network environments, intents, and control tasks. This approach enables a limited number of AI-driven RAN functions to tackle larger problems, improve system performance, and simplify lifecycle management. To achieve sustainability and automation, we introduce a scalable learning architecture that supports all deployed AI applications in the system. This architecture separates centralized learning functionalities from distributed actuation and inference functions, enabling efficient data collection and management, computational and storage resources optimization, and cost reduction. We illustrate these concepts by designing a generalized link adaptation algorithm, demonstrating the benefits of our proposed approach.", "link": "https://arxiv.org/abs/2306.06251"}, {"id": "2306.06503", "date": "Sat, 10 Jun 2023 18:41:50 GMT", "title": "Preserving privacy in domain transfer of medical AI models comes at no\n\u00a0performance costs: The integral role of differential privacy\n", "authors": ["Soroosh Tayebi Arasteh", "Mahshad Lotfinia", "Teresa Nolte", "Marwin Saehn,\n\u00a0Peter Isfort", "Christiane Kuhl", "Sven Nebelung", "Georgios Kaissis", "Daniel Truhn\n"], "categories": ["cs.LG", "cs.AI", "cs.CR", "eess.IV\n"], "abstract": "Developing robust and effective artificial intelligence (AI) models in medicine requires access to large amounts of patient data. The use of AI models solely trained on large multi-institutional datasets can help with this, yet the imperative to ensure data privacy remains, particularly as membership inference risks breaching patient confidentiality. As a proposed remedy, we advocate for the integration of differential privacy (DP). We specifically investigate the performance of models trained with DP as compared to models trained without DP on data from institutions that the model had not seen during its training (i.e., external validation) - the situation that is reflective of the clinical use of AI models. By leveraging more than 590,000 chest radiographs from five institutions, we evaluated the efficacy of DP-enhanced domain transfer (DP-DT) in diagnosing cardiomegaly, pleural effusion, pneumonia, atelectasis, and in identifying healthy subjects. We juxtaposed DP-DT with non-DP-DT and examined diagnostic accuracy and demographic fairness using the area under the receiver operating characteristic curve (AUC) as the main metric, as well as accuracy, sensitivity, and specificity. Our results show that DP-DT, even with exceptionally high privacy levels (epsilon around 1), performs comparably to non-DP-DT (P>0.119 across all domains). Furthermore, DP-DT led to marginal AUC differences - less than 1% - for nearly all subgroups, relative to non-DP-DT. Despite consistent evidence suggesting that DP models induce significant performance degradation for on-domain applications, we show that off-domain performance is almost not affected. Therefore, we ardently advocate for the adoption of DP in training diagnostic medical AI models, given its minimal impact on performance.", "link": "https://arxiv.org/abs/2306.06503"}, {"id": "2306.06506", "date": "Sat, 10 Jun 2023 18:54:15 GMT", "title": "Calculating and Visualizing Counterfactual Feature Importance Values\n", "authors": ["Bjorge Meulemeester", "Raphael Mazzine Barbosa De Oliveira", "David\n\u00a0Martens\n"], "categories": ["cs.LG", "cs.AI", "cs.HC\n"], "abstract": "Despite the success of complex machine learning algorithms, mostly justified by an outstanding performance in prediction tasks, their inherent opaque nature still represents a challenge to their responsible application. Counterfactual explanations surged as one potential solution to explain individual decision results. However, two major drawbacks directly impact their usability: (1) the isonomic view of feature changes, in which it is not possible to observe \\textit{how much} each modified feature influences the prediction, and (2) the lack of graphical resources to visualize the counterfactual explanation. We introduce Counterfactual Feature (change) Importance (CFI) values as a solution: a way of assigning an importance value to each feature change in a given counterfactual explanation. To calculate these values, we propose two potential CFI methods. One is simple, fast, and has a greedy nature. The other, coined CounterShapley, provides a way to calculate Shapley values between the factual-counterfactual pair. Using these importance values, we additionally introduce three chart types to visualize the counterfactual explanations: (a) the Greedy chart, which shows a greedy sequential path for prediction score increase up to predicted class change, (b) the CounterShapley chart, depicting its respective score in a simple and one-dimensional chart, and finally (c) the Constellation chart, which shows all possible combinations of feature changes, and their impact on the model's prediction score. For each of our proposed CFI methods and visualization schemes, we show how they can provide more information on counterfactual explanations. Finally, an open-source implementation is offered, compatible with any counterfactual explanation generator algorithm. Code repository at: https://github.com/ADMAntwerp/CounterPlots", "link": "https://arxiv.org/abs/2306.06506"}, {"id": "2306.06528", "date": "Sat, 10 Jun 2023 21:53:39 GMT", "title": "Pus$\\mathbb{H}$: Concurrent Probabilistic Programming with Function\n\u00a0Spaces\n", "authors": ["Daniel Huang", "Christian Cama\\~no", "Jonathan Tsegaye\n"], "categories": ["cs.LG", "cs.AI", "cs.PL\nComments:", "preprint\n"], "abstract": "We introduce a prototype probabilistic programming language (PPL) called Pus$\\mathbb{H}$ for performing Bayesian inference on function spaces with a focus on Bayesian deep learning (BDL). We describe the core abstraction of Pus$\\mathbb{H}$ based on particles that links models, specified as neural networks (NNs), with inference, specified as procedures on particles using a programming model inspired by message passing. Finally, we test Pus$\\mathbb{H}$ on a variety of models and datasets used in scientific machine learning (SciML), a domain with natural function space inference problems, and we evaluate scaling of Pus$\\mathbb{H}$ on single-node multi-GPU devices. Thus we explore the combination of probabilistic programming, NNs, and concurrency in the context of Bayesian inference on function spaces. The code can be found at https://github.com/lbai-lab/PusH.", "link": "https://arxiv.org/abs/2306.06528"}, {"id": "2306.06777", "date": "Sun, 11 Jun 2023 21:14:29 GMT", "title": "Improving the Validitity of Decision Trees as Explanations\n", "authors": ["Jiri Nemecek and Tomas Pevny and Jakub Marecek\n"], "categories": ["cs.LG", "cs.AI", "math.OC\n"], "abstract": "In classification and forecasting with tabular data, one often utilizes tree-based models. This can be competitive with deep neural networks on tabular data [cf. Grinsztajn et al., NeurIPS 2022, arXiv:2207.08815] and, under some conditions, explainable. The explainability depends on the depth of the tree and the accuracy in each leaf of the tree. Here, we train a low-depth tree with the objective of minimising the maximum misclassification error across each leaf node, and then ``suspend'' further tree-based models (e.g., trees of unlimited depth) from each leaf of the low-depth tree. The low-depth tree is easily explainable, while the overall statistical performance of the combined low-depth and suspended tree-based models improves upon decision trees of unlimited depth trained using classical methods (e.g., CART) and is comparable to state-of-the-art methods (e.g., well-tuned XGBoost).", "link": "https://arxiv.org/abs/2306.06777"}, {"id": "2306.06778", "date": "Sun, 11 Jun 2023 21:18:40 GMT", "title": "Approximation Algorithms for Fair Range Clustering\n", "authors": ["S\\`edjro S. Hotegni and Sepideh Mahabadi and Ali Vakilian\n"], "categories": ["cs.LG", "cs.AI", "cs.DS\nComments:", "ICML", "2023\n"], "abstract": "This paper studies the fair range clustering problem in which the data points are from different demographic groups and the goal is to pick $k$ centers with the minimum clustering cost such that each group is at least minimally represented in the centers set and no group dominates the centers set. More precisely, given a set of $n$ points in a metric space $(P,d)$ where each point belongs to one of the $\\ell$ different demographics (i.e., $P = P_1 \\uplus P_2 \\uplus \\cdots \\uplus P_\\ell$) and a set of $\\ell$ intervals $[\\alpha_1, \\beta_1], \\cdots, [\\alpha_\\ell, \\beta_\\ell]$ on desired number of centers from each group, the goal is to pick a set of $k$ centers $C$ with minimum $\\ell_p$-clustering cost (i.e., $(\\sum_{v\\in P} d(v,C)^p)^{1/p}$) such that for each group $i\\in \\ell$, $|C\\cap P_i| \\in [\\alpha_i, \\beta_i]$. In particular, the fair range $\\ell_p$-clustering captures fair range $k$-center, $k$-median and $k$-means as its special cases. In this work, we provide an $O(1)$-approximation algorithm for the fair range $\\ell_p$-clustering that picks at most $k+2\\ell$ centers and may only violate the upper bound of each demographic group by at most an additive term of $2$.", "link": "https://arxiv.org/abs/2306.06778"}, {"id": "2306.06836", "date": "Mon, 12 Jun 2023 02:56:09 GMT", "title": "Tackling Heavy-Tailed Rewards in Reinforcement Learning with Function\n\u00a0Approximation: Minimax Optimal and Instance-Dependent Regret Bounds\n", "authors": ["Jiayi Huang", "Han Zhong", "Liwei Wang", "Lin F. Yang\n"], "categories": ["cs.LG", "cs.AI", "stat.ML\n"], "abstract": "While numerous works have focused on devising efficient algorithms for reinforcement learning (RL) with uniformly bounded rewards, it remains an open question whether sample or time-efficient algorithms for RL with large state-action space exist when the rewards are \\emph{heavy-tailed}, i.e., with only finite $(1+\\epsilon)$-th moments for some $\\epsilon\\in(0,1]$. In this work, we address the challenge of such rewards in RL with linear function approximation. We first design an algorithm, \\textsc{Heavy-OFUL}, for heavy-tailed linear bandits, achieving an \\emph{instance-dependent} $T$-round regret of $\\tilde{O}\\big(d T^{\\frac{1-\\epsilon}{2(1+\\epsilon)}} \\sqrt{\\sum_{t=1}^T \\nu_t^2} + d T^{\\frac{1-\\epsilon}{2(1+\\epsilon)}}\\big)$, the \\emph{first} of this kind. Here, $d$ is the feature dimension, and $\\nu_t^{1+\\epsilon}$ is the $(1+\\epsilon)$-th central moment of the reward at the $t$-th round. We further show the above bound is minimax optimal when applied to the worst-case instances in stochastic and deterministic linear bandits. We then extend this algorithm to the RL settings with linear function approximation. Our algorithm, termed as \\textsc{Heavy-LSVI-UCB}, achieves the \\emph{first} computationally efficient \\emph{instance-dependent} $K$-episode regret of $\\tilde{O}(d \\sqrt{H \\mathcal{U}^*} K^\\frac{1}{1+\\epsilon} + d \\sqrt{H \\mathcal{V}^* K})$. Here, $H$ is length of the episode, and $\\mathcal{U}^*, \\mathcal{V}^*$ are instance-dependent quantities scaling with the central moment of reward and value functions, respectively. We also provide a matching minimax lower bound $\\Omega(d H K^{\\frac{1}{1+\\epsilon}} + d \\sqrt{H^3 K})$ to demonstrate the optimality of our algorithm in the worst case. Our result is achieved via a novel robust self-normalized concentration inequality that may be of independent interest in handling heavy-tailed noise in general online regression problems.", "link": "https://arxiv.org/abs/2306.06836"}, {"id": "2306.06865", "date": "Mon, 12 Jun 2023 04:46:01 GMT", "title": "Deep denoising autoencoder-based non-invasive blood flow detection for\n\u00a0arteriovenous fistula\n", "authors": ["Li-Chin Chen", "Yi-Heng Lin", "Li-Ning Peng", "Feng-Ming Wang", "Yu-Hsin Chen,\n\u00a0Po-Hsun Huang", "Shang-Feng Yang", "Yu Tsao\n"], "categories": ["cs.LG", "cs.AI", "eess.SP\n"], "abstract": "Clinical guidelines underscore the importance of regularly monitoring and surveilling arteriovenous fistula (AVF) access in hemodialysis patients to promptly detect any dysfunction. Although phono-angiography/sound analysis overcomes the limitations of standardized AVF stenosis diagnosis tool, prior studies have depended on conventional feature extraction methods, restricting their applicability in diverse contexts. In contrast, representation learning captures fundamental underlying factors that can be readily transferred across different contexts. We propose an approach based on deep denoising autoencoders (DAEs) that perform dimensionality reduction and reconstruction tasks using the waveform obtained through one-level discrete wavelet transform, utilizing representation learning. Our results demonstrate that the latent representation generated by the DAE surpasses expectations with an accuracy of 0.93. The incorporation of noise-mixing and the utilization of a noise-to-clean scheme effectively enhance the discriminative capabilities of the latent representation. Moreover, when employed to identify patient-specific characteristics, the latent representation exhibited performance by surpassing an accuracy of 0.92. Appropriate light-weighted methods can restore the detection performance of the excessively reduced dimensionality version and enable operation on less computational devices. Our findings suggest that representation learning is a more feasible approach for extracting auscultation features in AVF, leading to improved generalization and applicability across multiple tasks. The manipulation of latent representations holds immense potential for future advancements. Further investigations in this area are promising and warrant continued exploration.", "link": "https://arxiv.org/abs/2306.06865"}, {"id": "2306.06871", "date": "Mon, 12 Jun 2023 05:10:10 GMT", "title": "Ensemble-based Offline-to-Online Reinforcement Learning: From\n\u00a0Pessimistic Learning to Optimistic Exploration\n", "authors": ["Kai Zhao", "Yi Ma", "Jinyi Liu", "Yan Zheng", "Zhaopeng Meng\n"], "categories": ["cs.LG", "cs.AI", "cs.RO\n"], "abstract": "Offline reinforcement learning (RL) is a learning paradigm where an agent learns from a fixed dataset of experience. However, learning solely from a static dataset can limit the performance due to the lack of exploration. To overcome it, offline-to-online RL combines offline pre-training with online fine-tuning, which enables the agent to further refine its policy by interacting with the environment in real-time. Despite its benefits, existing offline-to-online RL methods suffer from performance degradation and slow improvement during the online phase. To tackle these challenges, we propose a novel framework called Ensemble-based Offline-to-Online (E2O) RL. By increasing the number of Q-networks, we seamlessly bridge offline pre-training and online fine-tuning without degrading performance. Moreover, to expedite online performance enhancement, we appropriately loosen the pessimism of Q-value estimation and incorporate ensemble-based exploration mechanisms into our framework. Experimental results demonstrate that E2O can substantially improve the training stability, learning efficiency, and final performance of existing offline RL methods during online fine-tuning on a range of locomotion and navigation tasks, significantly outperforming existing offline-to-online RL methods.", "link": "https://arxiv.org/abs/2306.06871"}, {"id": "2306.06909", "date": "Mon, 12 Jun 2023 07:27:31 GMT", "title": "Graph Agent Network: Empowering Nodes with Decentralized Communications\n\u00a0Capabilities for Adversarial Resilience\n", "authors": ["Ao Liu", "Wenshan Li", "Tao Li", "Beibei Li", "Hanyuan Huang", "Guangquan Xu,\n\u00a0Pan Zhou\n"], "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.NE\n"], "abstract": "End-to-end training with global optimization have popularized graph neural networks (GNNs) for node classification, yet inadvertently introduced vulnerabilities to adversarial edge-perturbing attacks. Adversaries can exploit the inherent opened interfaces of GNNs' input and output, perturbing critical edges and thus manipulating the classification results. Current defenses, due to their persistent utilization of global-optimization-based end-to-end training schemes, inherently encapsulate the vulnerabilities of GNNs. This is specifically evidenced in their inability to defend against targeted secondary attacks. In this paper, we propose the Graph Agent Network (GAgN) to address the aforementioned vulnerabilities of GNNs. GAgN is a graph-structured agent network in which each node is designed as an 1-hop-view agent. Through the decentralized interactions between agents, they can learn to infer global perceptions to perform tasks including inferring embeddings, degrees and neighbor relationships for given nodes. This empowers nodes to filtering adversarial edges while carrying out classification tasks. Furthermore, agents' limited view prevents malicious messages from propagating globally in GAgN, thereby resisting global-optimization-based secondary attacks. We prove that single-hidden-layer multilayer perceptrons (MLPs) are theoretically sufficient to achieve these functionalities. Experimental results show that GAgN effectively implements all its intended capabilities and, compared to state-of-the-art defenses, achieves optimal classification accuracy on the perturbed datasets.", "link": "https://arxiv.org/abs/2306.06909"}, {"id": "2306.06913", "date": "Mon, 12 Jun 2023 07:34:21 GMT", "title": "Network Robustness Learning via Graph Transformer\n", "authors": ["Yu Zhang", "Jia Li", "Jie Ding", "Xiang Li\n"], "categories": ["cs.LG", "cs.AI", "cs.CR\nComments:", "14", "pages,", "7", "figures\n"], "abstract": "Learning and analysis of network robustness, including controllability robustness and connectivity robustness, is critical for various networked systems against attacks. Traditionally, network robustness is determined by attack simulations, which is very time-consuming and even incapable for large-scale networks. Network Robustness Learning, which is dedicated to learning network robustness with high precision and high speed, provides a powerful tool to analyze network robustness by replacing simulations. In this paper, a novel versatile and unified robustness learning approach via graph transformer (NRL-GT) is proposed, which accomplishes the task of controllability robustness learning and connectivity robustness learning from multiple aspects including robustness curve learning, overall robustness learning, and synthetic network classification. Numerous experiments show that: 1) NRL-GT is a unified learning framework for controllability robustness and connectivity robustness, demonstrating a strong generalization ability to ensure high precision when training and test sets are distributed differently; 2) Compared to the cutting-edge methods, NRL-GT can simultaneously perform network robustness learning from multiple aspects and obtains superior results in less time. NRL-GT is also able to deal with complex networks of different size with low learning error and high efficiency; 3) It is worth mentioning that the backbone of NRL-GT can serve as a transferable feature learning module for complex networks of different size and different downstream tasks.", "link": "https://arxiv.org/abs/2306.06913"}, {"id": "2306.07059", "date": "Mon, 12 Jun 2023 12:13:06 GMT", "title": "A Distribution Optimization Framework for Confidence Bounds of Risk\n\u00a0Measures\n", "authors": ["Hao Liang", "Zhi-quan Luo\n"], "categories": ["cs.LG", "cs.AI", "stat.ML\n"], "abstract": "We present a distribution optimization framework that significantly improves confidence bounds for various risk measures compared to previous methods. Our framework encompasses popular risk measures such as the entropic risk measure, conditional value at risk (CVaR), spectral risk measure, distortion risk measure, equivalent certainty, and rank-dependent expected utility, which are well established in risk-sensitive decision-making literature. To achieve this, we introduce two estimation schemes based on concentration bounds derived from the empirical distribution, specifically using either the Wasserstein distance or the supremum distance. Unlike traditional approaches that add or subtract a confidence radius from the empirical risk measures, our proposed schemes evaluate a specific transformation of the empirical distribution based on the distance. Consequently, our confidence bounds consistently yield tighter results compared to previous methods. We further verify the efficacy of the proposed framework by providing tighter problem-dependent regret bound for the CVaR bandit.", "link": "https://arxiv.org/abs/2306.07059"}, {"id": "2306.07106", "date": "Mon, 12 Jun 2023 13:31:58 GMT", "title": "Adversarial Constrained Bidding via Minimax Regret Optimization with\n\u00a0Causality-Aware Reinforcement Learning\n", "authors": ["Haozhe Wang", "Chao Du", "Panyan Fang", "Li He", "Liang Wang", "Bo Zheng\n"], "categories": ["cs.LG", "cs.AI", "cs.GT", "cs.IR\nComments:", "Accepted", "by", "SIGKDD2023\nDOI:", "10.1145/3580305.3599254\n"], "abstract": "The proliferation of the Internet has led to the emergence of online advertising, driven by the mechanics of online auctions. In these repeated auctions, software agents participate on behalf of aggregated advertisers to optimize for their long-term utility. To fulfill the diverse demands, bidding strategies are employed to optimize advertising objectives subject to different spending constraints. Existing approaches on constrained bidding typically rely on i.i.d. train and test conditions, which contradicts the adversarial nature of online ad markets where different parties possess potentially conflicting objectives. In this regard, we explore the problem of constrained bidding in adversarial bidding environments, which assumes no knowledge about the adversarial factors. Instead of relying on the i.i.d. assumption, our insight is to align the train distribution of environments with the potential test distribution meanwhile minimizing policy regret. Based on this insight, we propose a practical Minimax Regret Optimization (MiRO) approach that interleaves between a teacher finding adversarial environments for tutoring and a learner meta-learning its policy over the given distribution of environments. In addition, we pioneer to incorporate expert demonstrations for learning bidding strategies. Through a causality-aware policy design, we improve upon MiRO by distilling knowledge from the experts. Extensive experiments on both industrial data and synthetic data show that our method, MiRO with Causality-aware reinforcement Learning (MiROCL), outperforms prior methods by over 30%.", "link": "https://arxiv.org/abs/2306.07106"}, {"id": "2306.07124", "date": "Mon, 12 Jun 2023 13:59:48 GMT", "title": "Diverse Projection Ensembles for Distributional Reinforcement Learning\n", "authors": ["Moritz A. Zanger", "Wendelin B\\\"ohmer", "Matthijs T. J. Spaan\n"], "categories": ["cs.LG", "cs.AI", "stat.ML\nComments:", "21", "pages,", "7", "figures,", "submitted", "to", "NeurIPS", "2023\n"], "abstract": "In contrast to classical reinforcement learning, distributional reinforcement learning algorithms aim to learn the distribution of returns rather than their expected value. Since the nature of the return distribution is generally unknown a priori or arbitrarily complex, a common approach finds approximations within a set of representable, parametric distributions. Typically, this involves a projection of the unconstrained distribution onto the set of simplified distributions. We argue that this projection step entails a strong inductive bias when coupled with neural networks and gradient descent, thereby profoundly impacting the generalization behavior of learned models. In order to facilitate reliable uncertainty estimation through diversity, this work studies the combination of several different projections and representations in a distributional ensemble. We establish theoretical properties of such projection ensembles and derive an algorithm that uses ensemble disagreement, measured by the average $1$-Wasserstein distance, as a bonus for deep exploration. We evaluate our algorithm on the behavior suite benchmark and find that diverse projection ensembles lead to significant performance improvements over existing methods on a wide variety of tasks with the most pronounced gains in directed exploration problems.", "link": "https://arxiv.org/abs/2306.07124"}, {"id": "2306.07215", "date": "Mon, 12 Jun 2023 16:20:36 GMT", "title": "Efficient Quantization-aware Training with Adaptive Coreset Selection\n", "authors": ["Xijie Huang", "Zechun Liu", "Shih-Yang Liu", "Kwang-Ting Cheng\n"], "categories": ["cs.LG", "cs.AI", "cs.CV\nComments:", "Code:", "https://github.com/HuangOwen/QAT-ACS\n"], "abstract": "The expanding model size and computation of deep neural networks (DNNs) have increased the demand for efficient model deployment methods. Quantization-aware training (QAT) is a representative model compression method to leverage redundancy in weights and activations. However, most existing QAT methods require end-to-end training on the entire dataset, which suffers from long training time and high energy costs. Coreset selection, aiming to improve data efficiency utilizing the redundancy of training data, has also been widely used for efficient training. In this work, we propose a new angle through the coreset selection to improve the training efficiency of quantization-aware training. Based on the characteristics of QAT, we propose two metrics: error vector score and disagreement score, to quantify the importance of each sample during training. Guided by these two metrics of importance, we proposed a quantization-aware adaptive coreset selection (ACS) method to select the data for the current training epoch. We evaluate our method on various networks (ResNet-18, MobileNetV2), datasets(CIFAR-100, ImageNet-1K), and under different quantization settings. Compared with previous coreset selection methods, our method significantly improves QAT performance with different dataset fractions. Our method can achieve an accuracy of 68.39% of 4-bit quantized ResNet-18 on the ImageNet-1K dataset with only a 10% subset, which has an absolute gain of 4.24% compared to the baseline.", "link": "https://arxiv.org/abs/2306.07215"}, {"id": "2306.06117", "date": "Thu, 1 Jun 2023 20:35:06 GMT", "title": "Strengths and Weaknesses of 3D Pose Estimation and Inertial Motion\n\u00a0Capture System for Movement Therapy\n", "authors": ["Shawan Mohammed", "Hannah Siebers", "Ted Preu{\\ss}\n"], "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG", "eess.SP\n"], "abstract": "3D pose estimation offers the opportunity for fast, non-invasive, and accurate motion analysis. This is of special interest also for clinical use. Currently, motion capture systems are used, as they offer robust and precise data acquisition, which is essential in the case of clinical applications. In this study, we investigate the accuracy of the state-of-the-art 3D position estimation approach MeTrabs, compared to the established inertial sensor system MTw Awinda for specific motion exercises. The study uses and provides an evaluation dataset of parallel recordings from 10 subjects during various movement therapy exercises. The information from the Awinda system and the frames for monocular pose estimation are synchronized. For the comparison, clinically relevant parameters for joint angles of ankle, knee, back, and elbow flexion-extension were estimated and evaluated using mean, median, and maximum deviation between the calculated joint angles for the different exercises, camera positions, and clothing items. The results of the analysis indicate that the mean and median deviations can be kept below 5{\\deg} for some of the studied angles. These joints could be considered for medical applications even considering the maximum deviations of 15{\\deg}. However, caution should be applied to certain particularly problematic joints. In particular, elbow flexions, which showed high maximum deviations of up to 50{\\deg} in our analysis. Furthermore, the type of exercise plays a crucial role in the reliable and safe application of the 3D position estimation method. For example, all joint angles showed a significant deterioration in performance during exercises near the ground.", "link": "https://arxiv.org/abs/2306.06117"}, {"id": "2306.06124", "date": "Thu, 8 Jun 2023 04:41:34 GMT", "title": "Unsupervised clustering of disturbances in power systems via deep\n\u00a0convolutional autoencoders\n", "authors": ["Md Maidul Islam", "Md Omar Faruque", "Joshua Butterfield", "Gaurav Singh,\n\u00a0Thomas A. Cooke\n"], "categories": ["eess.SP", "cs.AI", "cs.LG", "cs.SY\n"], "abstract": "Power quality (PQ) events are recorded by PQ meters whenever anomalous events are detected on the power grid. Using neural networks with machine learning can aid in accurately classifying the recorded waveforms and help power system engineers diagnose and rectify the root causes of problems. However, many of the waveforms captured during a disturbance in the power system need to be labeled for supervised learning, leaving a large number of data recordings for engineers to process manually or go unseen. This paper presents an autoencoder and K-means clustering-based unsupervised technique that can be used to cluster PQ events into categories like sag, interruption, transients, normal, and harmonic distortion to enable filtering of anomalous waveforms from recurring or normal waveforms. The method is demonstrated using three-phase, field-obtained voltage waveforms recorded in a distribution grid. First, a convolutional autoencoder compresses the input signals into a set of lower feature dimensions which, after further processing, is passed to the K-means algorithm to identify data clusters. Using a small, labeled dataset, numerical labels are then assigned to events based on a cosine similarity analysis. Finally, the study analyzes the clusters using the t-distributed stochastic neighbor embedding (t-SNE) visualization tool, demonstrating that the technique can help investigate a large number of captured events in a quick manner.", "link": "https://arxiv.org/abs/2306.06124"}, {"id": "2306.06748", "date": "Sun, 11 Jun 2023 19:12:30 GMT", "title": "Moving beyond simulation: data-driven quantitative photoacoustic imaging\n\u00a0using tissue-mimicking phantoms\n", "authors": ["Janek Gr\\\"ohl", "Thomas R. Else", "Lina Hacker", "Ellie V. Bunce", "Paul W.\n\u00a0Sweeney", "Sarah E. Bohndiek\n"], "categories": ["eess.IV", "cs.AI", "cs.LG", "physics.med-ph\nComments:", "20", "pages,", "14", "figures\n"], "abstract": "Accurate measurement of optical absorption coefficients from photoacoustic imaging (PAI) data would enable direct mapping of molecular concentrations, providing vital clinical insight. The ill-posed nature of the problem of absorption coefficient recovery has prohibited PAI from achieving this goal in living systems due to the domain gap between simulation and experiment. To bridge this gap, we introduce a collection of experimentally well-characterised imaging phantoms and their digital twins. This first-of-a-kind phantom data set enables supervised training of a U-Net on experimental data for pixel-wise estimation of absorption coefficients. We show that training on simulated data results in artefacts and biases in the estimates, reinforcing the existence of a domain gap between simulation and experiment. Training on experimentally acquired data, however, yielded more accurate and robust estimates of optical absorption coefficients. We compare the results to fluence correction with a Monte Carlo model from reference optical properties of the materials, which yields a quantification error of approximately 20%. Application of the trained U-Nets to a blood flow phantom demonstrated spectral biases when training on simulated data, while application to a mouse model highlighted the ability of both learning-based approaches to recover the depth-dependent loss of signal intensity. We demonstrate that training on experimental phantoms can restore the correlation of signal amplitudes measured in depth. While the absolute quantification error remains high and further improvements are needed, our results highlight the promise of deep learning to advance quantitative PAI.", "link": "https://arxiv.org/abs/2306.06748"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.link + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

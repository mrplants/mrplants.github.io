<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2307.02574", "Date": "Wed, 05 Jul 2023 18:16:30 ", "Title": "Semi-supervised Learning from Street-View Images and OpenStreetMap for Automatic Building Height Estimation", "Authors": ["Hao Li", "Zhendong Yuan", "Gabriel Dax", "Gefei Kong", "Hongchao Fan", "Alexander Zipf", "Martin Werner"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted for GIScience 2023"]}, "abstract": "Accurate building height estimation is key to the automatic derivation of 3D city models from emerging big geospatial data, including Volunteered Geographical Information (VGI). However, an automatic solution for large-scale building height estimation based on low-cost VGI data is currently missing. The fast development of VGI data platforms, especially OpenStreetMap (OSM) and crowdsourced street-view images (SVI), offers a stimulating opportunity to fill this research gap. In this work, we propose a semi-supervised learning (SSL) method of automatically estimating building height from Mapillary SVI and OSM data to generate low-cost and open-source 3D city modeling in LoD1. The proposed method consists of three parts: first, we propose an SSL schema with the option of setting a different ratio of \"pseudo label\" during the supervised regression; second, we extract multi-level morphometric features from OSM data (i.e., buildings and streets) for the purposed of inferring building height; last, we design a building floor estimation workflow with a pre-trained facade object detection network to generate \"pseudo label\" from SVI and assign it to the corresponding OSM building footprint. In a case study, we validate the proposed SSL method in the city of Heidelberg, Germany and evaluate the model performance against the reference data of building heights. Based on three different regression models, namely Random Forest (RF), Support Vector Machine (SVM), and Convolutional Neural Network (CNN), the SSL method leads to a clear performance boosting in estimating building heights with a Mean Absolute Error (MAE) around 2.1 meters, which is competitive to state-of-the-art approaches. The preliminary result is promising and motivates our future work in scaling up the proposed method based on low-cost VGI data, with possibilities in even regions and areas with diverse data quality and availability.", "url": "https://arxiv.org/abs/2307.02574"}, {"metadata": {"arXiv": "2307.02828", "Date": "Thu, 06 Jul 2023 07:52:42 ", "Title": "Sampling-based Fast Gradient Rescaling Method for Highly Transferable Adversarial Attacks", "Authors": ["Xu Han", "Anmin Liu", "Chenxuan Yao", "Yanbo Fan", "Kun He"], "Categories": "cs.CV cs.CR cs.LG", "Comments": ["10 pages", "6 figures", "7 tables. arXiv admin note: substantial text overlap with arXiv:2204.02887"]}, "abstract": "Deep neural networks are known to be vulnerable to adversarial examples crafted by adding human-imperceptible perturbations to the benign input. After achieving nearly 100% attack success rates in white-box setting, more focus is shifted to black-box attacks, of which the transferability of adversarial examples has gained significant attention. In either case, the common gradient-based methods generally use the sign function to generate perturbations on the gradient update, that offers a roughly correct direction and has gained great success. But little work pays attention to its possible limitation. In this work, we observe that the deviation between the original gradient and the generated noise may lead to inaccurate gradient update estimation and suboptimal solutions for adversarial transferability. To this end, we propose a Sampling-based Fast Gradient Rescaling Method (S-FGRM). Specifically, we use data rescaling to substitute the sign function without extra computational cost. We further propose a Depth First Sampling method to eliminate the fluctuation of rescaling and stabilize the gradient update. Our method could be used in any gradient-based attacks and is extensible to be integrated with various input transformation or ensemble methods to further improve the adversarial transferability. Extensive experiments on the standard ImageNet dataset show that our method could significantly boost the transferability of gradient-based attacks and outperform the state-of-the-art baselines.", "url": "https://arxiv.org/abs/2307.02828"}, {"metadata": {"arXiv": "2307.03108", "Date": "Thu, 06 Jul 2023 16:27:39 ", "Title": "How to Detect Unauthorized Data Usages in Text-to-image Diffusion Models", "Authors": ["Zhenting Wang", "Chen Chen", "Yuchen Liu", "Lingjuan Lyu", "Dimitris Metaxas", "Shiqing Ma"], "Categories": "cs.CV cs.CR cs.LG"}, "abstract": "Recent text-to-image diffusion models have shown surprising performance in generating high-quality images. However, concerns have arisen regarding the unauthorized usage of data during the training process. One example is when a model trainer collects a set of images created by a particular artist and attempts to train a model capable of generating similar images without obtaining permission from the artist. To address this issue, it becomes crucial to detect unauthorized data usage. In this paper, we propose a method for detecting such unauthorized data usage by planting injected memorization into the text-to-image diffusion models trained on the protected dataset. Specifically, we modify the protected image dataset by adding unique contents on the images such as stealthy image wrapping functions that are imperceptible to human vision but can be captured and memorized by diffusion models. By analyzing whether the model has memorization for the injected content (i.e., whether the generated images are processed by the chosen post-processing function), we can detect models that had illegally utilized the unauthorized data. Our experiments conducted on Stable Diffusion and LoRA model demonstrate the effectiveness of the proposed method in detecting unauthorized data usages.", "url": "https://arxiv.org/abs/2307.03108"}, {"metadata": {"arXiv": "2307.03132", "Date": "Thu, 06 Jul 2023 16:59:52 ", "Title": "T-MARS: Improving Visual Representations by Circumventing Text Feature Learning", "Authors": ["Pratyush Maini", "Sachin Goyal", "Zachary C. Lipton", "J. Zico Kolter", "Aditi Raghunathan"], "Categories": "cs.CV cs.CL cs.LG"}, "abstract": "Large web-sourced multimodal datasets have powered a slew of new methods for learning general-purpose visual representations, advancing the state of the art in computer vision and revolutionizing zero- and few-shot recognition. One crucial decision facing practitioners is how, if at all, to curate these ever-larger datasets. For example, the creators of the LAION-5B dataset chose to retain only image-caption pairs whose CLIP similarity score exceeded a designated threshold. In this paper, we propose a new state-of-the-art data filtering approach motivated by our observation that nearly 40% of LAION's images contain text that overlaps significantly with the caption. Intuitively, such data could be wasteful as it incentivizes models to perform optical character recognition rather than learning visual features. However, naively removing all such data could also be wasteful, as it throws away images that contain visual features (in addition to overlapping text). Our simple and scalable approach, T-MARS (Text Masking and Re-Scoring), filters out only those pairs where the text dominates the remaining visual features -- by first masking out the text and then filtering out those with a low CLIP similarity score of the masked image. Experimentally, T-MARS outperforms the top-ranked method on the \"medium scale\" of DataComp (a data filtering benchmark) by a margin of 6.5% on ImageNet and 4.7% on VTAB. Additionally, our systematic evaluation on various data pool sizes from 2M to 64M shows that the accuracy gains enjoyed by T-MARS linearly increase as data and compute are scaled exponentially. Code is available at https://github.com/locuslab/T-MARS.", "url": "https://arxiv.org/abs/2307.03132"}, {"metadata": {"arXiv": "2307.03157", "Date": "Thu, 06 Jul 2023 17:32:38 ", "Title": "Can Domain Adaptation Improve Accuracy and Fairness of Skin Lesion Classification?", "Authors": ["Janet Wang", "Yunbei Zhang", "Zhengming Ding", "Jihun Hamm"], "Categories": "cs.CV cs.CY cs.LG"}, "abstract": "Deep learning-based diagnostic system has demonstrated potential in classifying skin cancer conditions when labeled training example are abundant. However, skin lesion analysis often suffers from a scarcity of labeled data, hindering the development of an accurate and reliable diagnostic system. In this work, we leverage multiple skin lesion datasets and investigate the feasibility of various unsupervised domain adaptation (UDA) methods in binary and multi-class skin lesion classification. In particular, we assess three UDA training schemes: single-, combined-, and multi-source. Our experiment results show that UDA is effective in binary classification, with further improvement being observed when imbalance is mitigated. In multi-class task, its performance is less prominent, and imbalance problem again needs to be addressed to achieve above-baseline accuracy. Through our quantitative analysis, we find that the test error of multi-class tasks is strongly correlated with label shift, and feature-level UDA methods have limitations when handling imbalanced datasets. Finally, our study reveals that UDA can effectively reduce bias against minority groups and promote fairness, even without the explicit use of fairness-focused techniques.", "url": "https://arxiv.org/abs/2307.03157"}, {"metadata": {"arXiv": "2307.03190", "Date": "Thu, 06 Jul 2023 17:59:31 ", "Title": "Synthesizing Artistic Cinemagraphs from Text", "Authors": ["Aniruddha Mahapatra", "Aliaksandr Siarohin", "Hsin-Ying Lee", "Sergey Tulyakov", "Jun-Yan Zhu"], "Categories": "cs.CV cs.GR cs.LG"}, "abstract": "We introduce Artistic Cinemagraph, a fully automated method for creating cinemagraphs from text descriptions - an especially challenging task when prompts feature imaginary elements and artistic styles, given the complexity of interpreting the semantics and motions of these images. Existing single-image animation methods fall short on artistic inputs, and recent text-based video methods frequently introduce temporal inconsistencies, struggling to keep certain regions static. To address these challenges, we propose an idea of synthesizing image twins from a single text prompt - a pair of an artistic image and its pixel-aligned corresponding natural-looking twin. While the artistic image depicts the style and appearance detailed in our text prompt, the realistic counterpart greatly simplifies layout and motion analysis. Leveraging existing natural image and video datasets, we can accurately segment the realistic image and predict plausible motion given the semantic information. The predicted motion can then be transferred to the artistic image to create the final cinemagraph. Our method outperforms existing approaches in creating cinemagraphs for natural landscapes as well as artistic and other-worldly scenes, as validated by automated metrics and user studies. Finally, we demonstrate two extensions: animating existing paintings and controlling motion directions using text.", "url": "https://arxiv.org/abs/2307.03190"}, {"metadata": {"arXiv": "2307.02497", "Date": "Tue, 04 Jul 2023 08:27:52 ", "Title": "Multi-gauge Hydrological Variational Data Assimilation: Regionalization Learning with Spatial Gradients using Multilayer Perceptron and Bayesian-Guided Multivariate Regression", "Authors": ["Ngo Nghi Truyen Huynh", "Pierre-Andr\\'e Garambois", "Fran\\c{c}ois Colleoni", "Benjamin Renard", "H\\'el\\`ene Roux (IMFT)"], "Categories": "cs.LG", "Journal-ref": "Colloque SHF 2023 - Pr{\\'e}vision des crues et des inondations, Nov 2023, Toulouse, France"}, "abstract": "Tackling the difficult problem of estimating spatially distributed hydrological parameters, especially for floods on ungauged watercourses, this contribution presents a novel seamless regionalization technique for learning complex regional transfer functions designed for high-resolution hydrological models. The transfer functions rely on: (i) a multilayer perceptron enabling a seamless flow of gradient computation to employ machine learning optimization algorithms, or (ii) a multivariate regression mapping optimized by variational data assimilation algorithms and guided by Bayesian estimation, addressing the equifinality issue of feasible solutions. The approach involves incorporating the inferable regionalization mappings into a differentiable hydrological model and optimizing a cost function computed on multi-gauge data with accurate adjoint-based spatially distributed gradients.", "url": "https://arxiv.org/abs/2307.02497"}, {"metadata": {"arXiv": "2307.02509", "Date": "Wed, 05 Jul 2023 09:46:52 ", "Title": "Wasserstein Auto-Encoders of Merge Trees (and Persistence Diagrams)", "Authors": ["Mahieu Pont", "Julien Tierny"], "Categories": "cs.LG cs.CG cs.CV cs.GR", "Comments": ["arXiv admin note: text overlap with arXiv:2207.10960"]}, "abstract": "This paper presents a computational framework for the Wasserstein auto-encoding of merge trees (MT-WAE), a novel extension of the classical auto-encoder neural network architecture to the Wasserstein metric space of merge trees. In contrast to traditional auto-encoders which operate on vectorized data, our formulation explicitly manipulates merge trees on their associated metric space at each layer of the network, resulting in superior accuracy and interpretability. Our novel neural network approach can be interpreted as a non-linear generalization of previous linear attempts [65] at merge tree encoding. It also trivially extends to persistence diagrams. Extensive experiments on public ensembles demonstrate the efficiency of our algorithms, with MT-WAE computations in the orders of minutes on average. We show the utility of our contributions in two applications adapted from previous work on merge tree encoding [65]. First, we apply MT-WAE to data reduction and reliably compress merge trees by concisely representing them with their coordinates in the final layer of our auto-encoder. Second, we document an application to dimensionality reduction, by exploiting the latent space of our auto-encoder, for the visual analysis of ensemble data. We illustrate the versatility of our framework by introducing two penalty terms, to help preserve in the latent space both the Wasserstein distances between merge trees, as well as their clusters. In both applications, quantitative experiments assess the relevance of our framework. Finally, we provide a C++ implementation that can be used for reproducibility.", "url": "https://arxiv.org/abs/2307.02509"}, {"metadata": {"arXiv": "2307.02572", "Date": "Wed, 05 Jul 2023 18:14:38 ", "Title": "Conditional Korhunen-Lo\\'{e}ve regression model with Basis Adaptation for high-dimensional problems: uncertainty quantification and inverse modeling", "Authors": ["Yu-Hong Yeung", "Ramakrishna Tipireddy", "David A. Barajas-Solano", "Alexandre M. Tartakovsky"], "Categories": "cs.LG math.AP physics.flu-dyn physics.geo-ph", "Comments": ["29 pages", "4 figures", "5 tables"]}, "abstract": "We propose a methodology for improving the accuracy of surrogate models of the observable response of physical systems as a function of the systems' spatially heterogeneous parameter fields with applications to uncertainty quantification and parameter estimation in high-dimensional problems. Practitioners often formulate finite-dimensional representations of spatially heterogeneous parameter fields using truncated unconditional Karhunen-Lo\\'{e}ve expansions (KLEs) for a certain choice of unconditional covariance kernel and construct surrogate models of the observable response with respect to the random variables in the KLE. When direct measurements of the parameter fields are available, we propose improving the accuracy of these surrogate models by representing the parameter fields via conditional Karhunen-Lo\\'{e}ve expansions (CKLEs). CKLEs are constructed by conditioning the covariance kernel of the unconditional expansion on the direct measurements via Gaussian process regression and then truncating the corresponding KLE. We apply the proposed methodology to constructing surrogate models via the Basis Adaptation (BA) method of the stationary hydraulic head response, measured at spatially discrete observation locations, of a groundwater flow model of the Hanford Site, as a function of the 1,000-dimensional representation of the model's log-transmissivity field. We find that BA surrogate models of the hydraulic head based on CKLEs are more accurate than BA surrogate models based on unconditional expansions for forward uncertainty quantification tasks. Furthermore, we find that inverse estimates of the hydraulic transmissivity field computed using CKLE-based BA surrogate models are more accurate than those computed using unconditional BA surrogate models.", "url": "https://arxiv.org/abs/2307.02572"}, {"metadata": {"arXiv": "2307.02575", "Date": "Wed, 05 Jul 2023 18:17:23 ", "Title": "How accurate are existing land cover maps for agriculture in Sub-Saharan Africa?", "Authors": ["Hannah Kerner", "Catherine Nakalembe", "Adam Yang", "Ivan Zvonkov", "Ryan McWeeny", "Gabriel Tseng", "Inbal Becker-Reshef"], "Categories": "cs.LG cs.CY", "Comments": ["Under review for Nature Scientific Data"]}, "abstract": "Satellite Earth observations (EO) can provide affordable and timely information for assessing crop conditions and food production. Such monitoring systems are essential in Africa, where there is high food insecurity and sparse agricultural statistics. EO-based monitoring systems require accurate cropland maps to provide information about croplands, but there is a lack of data to determine which of the many available land cover maps most accurately identify cropland in African countries. This study provides a quantitative evaluation and intercomparison of 11 publicly available land cover maps to assess their suitability for cropland classification and EO-based agriculture monitoring in Africa using statistically rigorous reference datasets from 8 countries. We hope the results of this study will help users determine the most suitable map for their needs and encourage future work to focus on resolving inconsistencies between maps and improving accuracy in low-accuracy regions.", "url": "https://arxiv.org/abs/2307.02575"}, {"metadata": {"arXiv": "2307.02578", "Date": "Wed, 05 Jul 2023 18:23:13 ", "Title": "Multimodal Temporal Fusion Transformers Are Good Product Demand Forecasters", "Authors": ["Maarten Sukel", "Stevan Rudinac", "Marcel Worring"], "Categories": "cs.LG"}, "abstract": "Multimodal demand forecasting aims at predicting product demand utilizing visual, textual, and contextual information. This paper proposes a method for multimodal product demand forecasting using convolutional, graph-based, and transformer-based architectures. Traditional approaches to demand forecasting rely on historical demand, product categories, and additional contextual information such as seasonality and events. However, these approaches have several shortcomings, such as the cold start problem making it difficult to predict product demand until sufficient historical data is available for a particular product, and their inability to properly deal with category dynamics. By incorporating multimodal information, such as product images and textual descriptions, our architecture aims to address the shortcomings of traditional approaches and outperform them. The experiments conducted on a large real-world dataset show that the proposed approach effectively predicts demand for a wide range of products. The multimodal pipeline presented in this work enhances the accuracy and reliability of the predictions, demonstrating the potential of leveraging multimodal information in product demand forecasting.", "url": "https://arxiv.org/abs/2307.02578"}, {"metadata": {"arXiv": "2307.02598", "Date": "Wed, 05 Jul 2023 18:48:20 ", "Title": "Additive Decoders for Latent Variables Identification and Cartesian-Product Extrapolation", "Authors": ["S\\'ebastien Lachapelle", "Divyat Mahajan", "Ioannis Mitliagkas", "Simon Lacoste-Julien"], "Categories": "cs.LG stat.ML", "Comments": ["35 pages"], "ACM-class": "I.2.6; I.5.1"}, "abstract": "We tackle the problems of latent variables identification and \"out-of-support\" image generation in representation learning. We show that both are possible for a class of decoders that we call additive, which are reminiscent of decoders used for object-centric representation learning (OCRL) and well suited for images that can be decomposed as a sum of object-specific images. We provide conditions under which exactly solving the reconstruction problem using an additive decoder is guaranteed to identify the blocks of latent variables up to permutation and block-wise invertible transformations. This guarantee relies only on very weak assumptions about the distribution of the latent factors, which might present statistical dependencies and have an almost arbitrarily shaped support. Our result provides a new setting where nonlinear independent component analysis (ICA) is possible and adds to our theoretical understanding of OCRL methods. We also show theoretically that additive decoders can generate novel images by recombining observed factors of variations in novel ways, an ability we refer to as Cartesian-product extrapolation. We show empirically that additivity is crucial for both identifiability and extrapolation on simulated data.", "url": "https://arxiv.org/abs/2307.02598"}, {"metadata": {"arXiv": "2307.02623", "Date": "Wed, 05 Jul 2023 19:53:38 ", "Title": "FLuID: Mitigating Stragglers in Federated Learning using Invariant Dropout", "Authors": ["Irene Wang", "Prashant J. Nair", "Divya Mahajan"], "Categories": "cs.LG cs.DC"}, "abstract": "Federated Learning (FL) allows machine learning models to train locally on individual mobile devices, synchronizing model updates via a shared server. This approach safeguards user privacy; however, it also generates a heterogeneous training environment due to the varying performance capabilities across devices. As a result, straggler devices with lower performance often dictate the overall training time in FL. In this work, we aim to alleviate this performance bottleneck due to stragglers by dynamically balancing the training load across the system. We introduce Invariant Dropout, a method that extracts a sub-model based on the weight update threshold, thereby minimizing potential impacts on accuracy. Building on this dropout technique, we develop an adaptive training framework, Federated Learning using Invariant Dropout (FLuID). FLuID offers a lightweight sub-model extraction to regulate computational intensity, thereby reducing the load on straggler devices without affecting model quality. Our method leverages neuron updates from non-straggler devices to construct a tailored sub-model for each straggler based on client performance profiling. Furthermore, FLuID can dynamically adapt to changes in stragglers as runtime conditions shift. We evaluate FLuID using five real-world mobile clients. The evaluations show that Invariant Dropout maintains baseline model efficiency while alleviating the performance bottleneck of stragglers through a dynamic, runtime approach.", "url": "https://arxiv.org/abs/2307.02623"}, {"metadata": {"arXiv": "2307.02632", "Date": "Wed, 05 Jul 2023 20:04:26 ", "Title": "Stability of Q-Learning Through Design and Optimism", "Authors": ["Sean Meyn"], "Categories": "cs.LG cs.SY eess.SY math.OC", "Comments": ["Companion paper to the INFORMS APS inaugural Applied Probability Trust Plenary Lecture", "presented in Nancy France", "June 2023. Slides available online", "Online", "DOI 10.13140/RG.2.2.24897.33127"], "MSC-class": "68T05, 93E35, 62L20, 93E20"}, "abstract": "Q-learning has become an important part of the reinforcement learning toolkit since its introduction in the dissertation of Chris Watkins in the 1980s. The purpose of this paper is in part a tutorial on stochastic approximation and Q-learning, providing details regarding the INFORMS APS inaugural Applied Probability Trust Plenary Lecture, presented in Nancy France, June 2023. The paper also presents new approaches to ensure stability and potentially accelerated convergence for these algorithms, and stochastic approximation in other settings. Two contributions are entirely new: 1. Stability of Q-learning with linear function approximation has been an open topic for research for over three decades. It is shown that with appropriate optimistic training in the form of a modified Gibbs policy, there exists a solution to the projected Bellman equation, and the algorithm is stable (in terms of bounded parameter estimates). Convergence remains one of many open topics for research. 2. The new Zap Zero algorithm is designed to approximate the Newton-Raphson flow without matrix inversion. It is stable and convergent under mild assumptions on the mean flow vector field for the algorithm, and compatible statistical assumption on an underlying Markov chain. The algorithm is a general approach to stochastic approximation which in particular applies to Q-learning with \"oblivious\" training even with non-linear function approximation.", "url": "https://arxiv.org/abs/2307.02632"}, {"metadata": {"arXiv": "2307.02672", "Date": "Wed, 05 Jul 2023 22:04:38 ", "Title": "GIT: Detecting Uncertainty, Out-Of-Distribution and Adversarial Samples using Gradients and Invariance Transformations", "Authors": ["Julia Lust and Alexandru P. Condurache"], "Categories": "cs.LG cs.CV", "Comments": ["Accepted at IJCNN 2023"], "Journal-ref": "IJCNN 2023"}, "abstract": "Deep neural networks tend to make overconfident predictions and often require additional detectors for misclassifications, particularly for safety-critical applications. Existing detection methods usually only focus on adversarial attacks or out-of-distribution samples as reasons for false predictions. However, generalization errors occur due to diverse reasons often related to poorly learning relevant invariances. We therefore propose GIT, a holistic approach for the detection of generalization errors that combines the usage of gradient information and invariance transformations. The invariance transformations are designed to shift misclassified samples back into the generalization area of the neural network, while the gradient information measures the contradiction between the initial prediction and the corresponding inherent computations of the neural network using the transformed sample. Our experiments demonstrate the superior performance of GIT compared to the state-of-the-art on a variety of network architectures, problem setups and perturbation types.", "url": "https://arxiv.org/abs/2307.02672"}, {"metadata": {"arXiv": "2307.02693", "Date": "Wed, 05 Jul 2023 23:51:05 ", "Title": "Kernels, Data & Physics", "Authors": ["Francesco Cagnetta", "Deborah Oliveira", "Mahalakshmi Sabanayagam", "Nikolaos Tsilivis", "Julia Kempe"], "Categories": "cs.LG stat.ML", "Comments": ["These are notes from the lecture of Julia Kempe given at the summer school \"Statistical Physics \\& Machine Learning\"", "that took place in Les Houches School of Physics in France from 4th to 29th July 2022"]}, "abstract": "Lecture notes from the course given by Professor Julia Kempe at the summer school \"Statistical physics of Machine Learning\" in Les Houches. The notes discuss the so-called NTK approach to problems in machine learning, which consists of gaining an understanding of generally unsolvable problems by finding a tractable kernel formulation. The notes are mainly focused on practical applications such as data distillation and adversarial robustness, examples of inductive bias are also discussed.", "url": "https://arxiv.org/abs/2307.02693"}, {"metadata": {"arXiv": "2307.02707", "Date": "Thu, 06 Jul 2023 01:05:34 ", "Title": "Towards Symmetry-Aware Generation of Periodic Materials", "Authors": ["Youzhi Luo", "Chengkai Liu", "Shuiwang Ji"], "Categories": "cs.LG cond-mat.mtrl-sci"}, "abstract": "We consider the problem of generating periodic materials with deep models. While symmetry-aware molecule generation has been studied extensively, periodic materials possess different symmetries, which have not been completely captured by existing methods. In this work, we propose SyMat, a novel material generation approach that can capture physical symmetries of periodic material structures. SyMat generates atom types and lattices of materials through generating atom type sets, lattice lengths and lattice angles with a variational auto-encoder model. In addition, SyMat employs a score-based diffusion model to generate atom coordinates of materials, in which a novel symmetry-aware probabilistic model is used in the coordinate diffusion process. We show that SyMat is theoretically invariant to all symmetry transformations on materials and demonstrate that SyMat achieves promising performance on random generation and property optimization tasks.", "url": "https://arxiv.org/abs/2307.02707"}, {"metadata": {"arXiv": "2307.02712", "Date": "Thu, 06 Jul 2023 01:26:01 ", "Title": "Multi-Similarity Contrastive Learning", "Authors": ["Emily Mu", "John Guttag", "Maggie Makar"], "Categories": "cs.LG"}, "abstract": "Given a similarity metric, contrastive methods learn a representation in which examples that are similar are pushed together and examples that are dissimilar are pulled apart. Contrastive learning techniques have been utilized extensively to learn representations for tasks ranging from image classification to caption generation. However, existing contrastive learning approaches can fail to generalize because they do not take into account the possibility of different similarity relations. In this paper, we propose a novel multi-similarity contrastive loss (MSCon), that learns generalizable embeddings by jointly utilizing supervision from multiple metrics of similarity. Our method automatically learns contrastive similarity weightings based on the uncertainty in the corresponding similarity, down-weighting uncertain tasks and leading to better out-of-domain generalization to new tasks. We show empirically that networks trained with MSCon outperform state-of-the-art baselines on in-domain and out-of-domain settings.", "url": "https://arxiv.org/abs/2307.02712"}, {"metadata": {"arXiv": "2307.02719", "Date": "Thu, 06 Jul 2023 01:57:37 ", "Title": "Understanding Uncertainty Sampling", "Authors": ["Shang Liu", "Xiaocheng Li"], "Categories": "cs.LG stat.ML"}, "abstract": "Uncertainty sampling is a prevalent active learning algorithm that queries sequentially the annotations of data samples which the current prediction model is uncertain about. However, the usage of uncertainty sampling has been largely heuristic: (i) There is no consensus on the proper definition of \"uncertainty\" for a specific task under a specific loss; (ii) There is no theoretical guarantee that prescribes a standard protocol to implement the algorithm, for example, how to handle the sequentially arrived annotated data under the framework of optimization algorithms such as stochastic gradient descent. In this work, we systematically examine uncertainty sampling algorithms under both stream-based and pool-based active learning. We propose a notion of equivalent loss which depends on the used uncertainty measure and the original loss function and establish that an uncertainty sampling algorithm essentially optimizes against such an equivalent loss. The perspective verifies the properness of existing uncertainty measures from two aspects: surrogate property and loss convexity. Furthermore, we propose a new notion for designing uncertainty measures called \\textit{loss as uncertainty}. The idea is to use the conditional expected loss given the features as the uncertainty measure. Such an uncertainty measure has nice analytical properties and generality to cover both classification and regression problems, which enable us to provide the first generalization bound for uncertainty sampling algorithms under both stream-based and pool-based settings, in the full generality of the underlying model and problem. Lastly, we establish connections between certain variants of the uncertainty sampling algorithms with risk-sensitive objectives and distributional robustness, which can partly explain the advantage of uncertainty sampling algorithms when the sample size is small.", "url": "https://arxiv.org/abs/2307.02719"}, {"metadata": {"arXiv": "2307.02732", "Date": "Thu, 06 Jul 2023 02:31:38 ", "Title": "Evaluating the Evaluators: Are Current Few-Shot Learning Benchmarks Fit for Purpose?", "Authors": ["Lu\\'isa Shimabucoro", "Timothy Hospedales", "Henry Gouk"], "Categories": "cs.LG stat.ML", "Comments": ["Accepted at the ICML 2023 workshop on Data-centric Machine Learning"]}, "abstract": "Numerous benchmarks for Few-Shot Learning have been proposed in the last decade. However all of these benchmarks focus on performance averaged over many tasks, and the question of how to reliably evaluate and tune models trained for individual tasks in this regime has not been addressed. This paper presents the first investigation into task-level evaluation -- a fundamental step when deploying a model. We measure the accuracy of performance estimators in the few-shot setting, consider strategies for model selection, and examine the reasons for the failure of evaluators usually thought of as being robust. We conclude that cross-validation with a low number of folds is the best choice for directly estimating the performance of a model, whereas using bootstrapping or cross validation with a large number of folds is better for model selection purposes. Overall, we find that existing benchmarks for few-shot learning are not designed in such a way that one can get a reliable picture of how effectively methods can be used on individual tasks.", "url": "https://arxiv.org/abs/2307.02732"}, {"metadata": {"arXiv": "2307.02764", "Date": "Thu, 06 Jul 2023 04:13:57 ", "Title": "When Does Confidence-Based Cascade Deferral Suffice?", "Authors": ["Wittawat Jitkrittum", "Neha Gupta", "Aditya Krishna Menon", "Harikrishna Narasimhan", "Ankit Singh Rawat", "Sanjiv Kumar"], "Categories": "cs.LG stat.ML"}, "abstract": "Cascades are a classical strategy to enable inference cost to vary adaptively across samples, wherein a sequence of classifiers are invoked in turn. A deferral rule determines whether to invoke the next classifier in the sequence, or to terminate prediction. One simple deferral rule employs the confidence of the current classifier, e.g., based on the maximum predicted softmax probability. Despite being oblivious to the structure of the cascade -- e.g., not modelling the errors of downstream models -- such confidence-based deferral often works remarkably well in practice. In this paper, we seek to better understand the conditions under which confidence-based deferral may fail, and when alternate deferral strategies can perform better. We first present a theoretical characterisation of the optimal deferral rule, which precisely characterises settings under which confidence-based deferral may suffer. We then study post-hoc deferral mechanisms, and demonstrate they can significantly improve upon confidence-based deferral in settings where (i) downstream models are specialists that only work well on a subset of inputs, (ii) samples are subject to label noise, and (iii) there is distribution shift between the train and test set.", "url": "https://arxiv.org/abs/2307.02764"}, {"metadata": {"arXiv": "2307.02804", "Date": "Thu, 06 Jul 2023 06:39:27 ", "Title": "OLR-WA Online Regression with Weighted Average", "Authors": ["Mohammad Abu-Shaira and Greg Speegle"], "Categories": "cs.LG"}, "abstract": "Machine Learning requires a large amount of training data in order to build accurate models. Sometimes the data arrives over time, requiring significant storage space and recalculating the model to account for the new data. On-line learning addresses these issues by incrementally modifying the model as data is encountered, and then discarding the data. In this study we introduce a new online linear regression approach. Our approach combines newly arriving data with a previously existing model to create a new model. The introduced model, named OLR-WA (OnLine Regression with Weighted Average) uses user-defined weights to provide flexibility in the face of changing data to bias the results in favor of old or new data. We have conducted 2-D and 3-D experiments comparing OLR-WA to a static model using the entire data set. The results show that for consistent data, OLR-WA and the static batch model perform similarly and for varying data, the user can set the OLR-WA to adapt more quickly or to resist change.", "url": "https://arxiv.org/abs/2307.02804"}, {"metadata": {"arXiv": "2307.02813", "Date": "Thu, 06 Jul 2023 07:18:22 ", "Title": "CPDG: A Contrastive Pre-Training Method for Dynamic Graph Neural Networks", "Authors": ["Yuanchen Bei", "Hao Xu", "Sheng Zhou", "Huixuan Chi", "Mengdi Zhang", "Zhao Li", "Jiajun Bu"], "Categories": "cs.LG cs.SI", "Comments": ["12 pages", "6 figures"]}, "abstract": "Dynamic graph data mining has gained popularity in recent years due to the rich information contained in dynamic graphs and their widespread use in the real world. Despite the advances in dynamic graph neural networks (DGNNs), the rich information and diverse downstream tasks have posed significant difficulties for the practical application of DGNNs in industrial scenarios. To this end, in this paper, we propose to address them by pre-training and present the Contrastive Pre-Training Method for Dynamic Graph Neural Networks (CPDG). CPDG tackles the challenges of pre-training for DGNNs, including generalization and long-short term modeling capability, through a flexible structural-temporal subgraph sampler along with structural-temporal contrastive pre-training schemes. Extensive experiments conducted on both large-scale research and industrial dynamic graph datasets show that CPDG outperforms existing methods in dynamic graph pre-training for various downstream tasks under three transfer settings.", "url": "https://arxiv.org/abs/2307.02813"}, {"metadata": {"arXiv": "2307.02829", "Date": "Thu, 06 Jul 2023 07:52:50 ", "Title": "Policy Contrastive Imitation Learning", "Authors": ["Jialei Huang", "Zhaoheng Yin", "Yingdong Hu", "Yang Gao"], "Categories": "cs.LG cs.RO"}, "abstract": "Adversarial imitation learning (AIL) is a popular method that has recently achieved much success. However, the performance of AIL is still unsatisfactory on the more challenging tasks. We find that one of the major reasons is due to the low quality of AIL discriminator representation. Since the AIL discriminator is trained via binary classification that does not necessarily discriminate the policy from the expert in a meaningful way, the resulting reward might not be meaningful either. We propose a new method called Policy Contrastive Imitation Learning (PCIL) to resolve this issue. PCIL learns a contrastive representation space by anchoring on different policies and generates a smooth cosine-similarity-based reward. Our proposed representation learning objective can be viewed as a stronger version of the AIL objective and provide a more meaningful comparison between the agent and the policy. From a theoretical perspective, we show the validity of our method using the apprenticeship learning framework. Furthermore, our empirical evaluation on the DeepMind Control suite demonstrates that PCIL can achieve state-of-the-art performance. Finally, qualitative results suggest that PCIL builds a smoother and more meaningful representation space for imitation learning.", "url": "https://arxiv.org/abs/2307.02829"}, {"metadata": {"arXiv": "2307.02842", "Date": "Thu, 06 Jul 2023 08:14:54 ", "Title": "Provably Efficient Iterated CVaR Reinforcement Learning with Function Approximation", "Authors": ["Yu Chen", "Yihan Du", "Pihe Hu", "Siwei Wang", "Desheng Wu", "Longbo Huang"], "Categories": "cs.LG", "Comments": ["27 pages", "3 figures"]}, "abstract": "Risk-sensitive reinforcement learning (RL) aims to optimize policies that balance the expected reward and risk. In this paper, we investigate a novel risk-sensitive RL formulation with an Iterated Conditional Value-at-Risk (CVaR) objective under linear and general function approximations. This new formulation, named ICVaR-RL with function approximation, provides a principled way to guarantee safety at each decision step. For ICVaR-RL with linear function approximation, we propose a computationally efficient algorithm ICVaR-L, which achieves an $\\widetilde{O}(\\sqrt{\\alpha^{-(H+1)}(d^2H^4+dH^6)K})$ regret, where $\\alpha$ is the risk level, $d$ is the dimension of state-action features, $H$ is the length of each episode, and $K$ is the number of episodes. We also establish a matching lower bound $\\Omega(\\sqrt{\\alpha^{-(H-1)}d^2K})$ to validate the optimality of ICVaR-L with respect to $d$ and $K$. For ICVaR-RL with general function approximation, we propose algorithm ICVaR-G, which achieves an $\\widetilde{O}(\\sqrt{\\alpha^{-(H+1)}DH^4K})$ regret, where $D$ is a dimensional parameter that depends on the eluder dimension and covering number. Furthermore, our analysis provides several novel techniques for risk-sensitive RL, including an efficient approximation of the CVaR operator, a new ridge regression with CVaR-adapted features, and a refined elliptical potential lemma.", "url": "https://arxiv.org/abs/2307.02842"}, {"metadata": {"arXiv": "2307.02884", "Date": "Thu, 06 Jul 2023 09:39:01 ", "Title": "Sample-Efficient Learning of POMDPs with Multiple Observations In Hindsight", "Authors": ["Jiacheng Guo", "Minshuo Chen", "Huan Wang", "Caiming Xiong", "Mengdi Wang", "Yu Bai"], "Categories": "cs.LG stat.ML"}, "abstract": "This paper studies the sample-efficiency of learning in Partially Observable Markov Decision Processes (POMDPs), a challenging problem in reinforcement learning that is known to be exponentially hard in the worst-case. Motivated by real-world settings such as loading in game playing, we propose an enhanced feedback model called ``multiple observations in hindsight'', where after each episode of interaction with the POMDP, the learner may collect multiple additional observations emitted from the encountered latent states, but may not observe the latent states themselves. We show that sample-efficient learning under this feedback model is possible for two new subclasses of POMDPs: \\emph{multi-observation revealing POMDPs} and \\emph{distinguishable POMDPs}. Both subclasses generalize and substantially relax \\emph{revealing POMDPs} -- a widely studied subclass for which sample-efficient learning is possible under standard trajectory feedback. Notably, distinguishable POMDPs only require the emission distributions from different latent states to be \\emph{different} instead of \\emph{linearly independent} as required in revealing POMDPs.", "url": "https://arxiv.org/abs/2307.02884"}, {"metadata": {"arXiv": "2307.02894", "Date": "Thu, 06 Jul 2023 09:57:48 ", "Title": "Free Bits: Latency Optimization of Mixed-Precision Quantized Neural Networks on the Edge", "Authors": ["Georg Rutishauser", "Francesco Conti", "Luca Benini"], "Categories": "cs.LG", "Comments": ["Accepted for publication at the 2023 IEEE International Conference of Artificial Intelligence Circuits and Systems (AICAS '23)"]}, "abstract": "Mixed-precision quantization, where a deep neural network's layers are quantized to different precisions, offers the opportunity to optimize the trade-offs between model size, latency, and statistical accuracy beyond what can be achieved with homogeneous-bit-width quantization. To navigate the intractable search space of mixed-precision configurations for a given network, this paper proposes a hybrid search methodology. It consists of a hardware-agnostic differentiable search algorithm followed by a hardware-aware heuristic optimization to find mixed-precision configurations latency-optimized for a specific hardware target. We evaluate our algorithm on MobileNetV1 and MobileNetV2 and deploy the resulting networks on a family of multi-core RISC-V microcontroller platforms with different hardware characteristics. We achieve up to 28.6% reduction of end-to-end latency compared to an 8-bit model at a negligible accuracy drop from a full-precision baseline on the 1000-class ImageNet dataset. We demonstrate speedups relative to an 8-bit baseline, even on systems with no hardware support for sub-byte arithmetic at negligible accuracy drop. Furthermore, we show the superiority of our approach with respect to differentiable search targeting reduced binary operation counts as a proxy for latency.", "url": "https://arxiv.org/abs/2307.02894"}, {"metadata": {"arXiv": "2307.02906", "Date": "Thu, 06 Jul 2023 10:38:14 ", "Title": "A Real-time Human Pose Estimation Approach for Optimal Sensor Placement in Sensor-based Human Activity Recognition", "Authors": ["Orhan Konak", "Alexander Wischmann", "Robin van de Water", "Bert Arnrich"], "Categories": "cs.LG cs.CV eess.SP"}, "abstract": "Sensor-based Human Activity Recognition facilitates unobtrusive monitoring of human movements. However, determining the most effective sensor placement for optimal classification performance remains challenging. This paper introduces a novel methodology to resolve this issue, using real-time 2D pose estimations derived from video recordings of target activities. The derived skeleton data provides a unique strategy for identifying the optimal sensor location. We validate our approach through a feasibility study, applying inertial sensors to monitor 13 different activities across ten subjects. Our findings indicate that the vision-based method for sensor placement offers comparable results to the conventional deep learning approach, demonstrating its efficacy. This research significantly advances the field of Human Activity Recognition by providing a lightweight, on-device solution for determining the optimal sensor placement, thereby enhancing data anonymization and supporting a multimodal classification approach.", "url": "https://arxiv.org/abs/2307.02906"}, {"metadata": {"arXiv": "2307.02932", "Date": "Thu, 06 Jul 2023 11:43:22 ", "Title": "When No-Rejection Learning is Optimal for Regression with Rejection", "Authors": ["Xiaocheng Li", "Shang Liu", "Chunlin Sun", "Hanzhao Wang"], "Categories": "cs.LG"}, "abstract": "Learning with rejection is a prototypical model for studying the interaction between humans and AI on prediction tasks. The model has two components, a predictor and a rejector. Upon the arrival of a sample, the rejector first decides whether to accept it; if accepted, the predictor fulfills the prediction task, and if rejected, the prediction will be deferred to humans. The learning problem requires learning a predictor and a rejector simultaneously. This changes the structure of the conventional loss function and often results in non-convexity and inconsistency issues. For the classification with rejection problem, several works develop surrogate losses for the jointly learning with provable consistency guarantees; in parallel, there has been less work for the regression counterpart. We study the regression with rejection (RwR) problem and investigate the no-rejection learning strategy which treats the RwR problem as a standard regression task to learn the predictor. We establish that the suboptimality of the no-rejection learning strategy observed in the literature can be mitigated by enlarging the function class of the predictor. Then we introduce the truncated loss to single out the learning for the predictor and we show that a consistent surrogate property can be established for the predictor individually in an easier way than for the predictor and the rejector jointly. Our findings advocate for a two-step learning procedure that first uses all the data to learn the predictor and then calibrates the prediction loss for the rejector. It is better aligned with the common intuition that more data samples will lead to a better predictor and it calls for more efforts on a better design of calibration algorithms for learning the rejector. While our discussions mainly focus on the regression problem, the theoretical results and insights generalize to the classification problem as well.", "url": "https://arxiv.org/abs/2307.02932"}, {"metadata": {"arXiv": "2307.02973", "Date": "Thu, 06 Jul 2023 13:18:44 ", "Title": "Pruning vs Quantization: Which is Better?", "Authors": ["Andrey Kuzmin", "Markus Nagel", "Mart van Baalen", "Arash Behboodi", "Tijmen Blankevoort"], "Categories": "cs.LG"}, "abstract": "Neural network pruning and quantization techniques are almost as old as neural networks themselves. However, to date only ad-hoc comparisons between the two have been published. In this paper, we set out to answer the question on which is better: neural network quantization or pruning? By answering this question, we hope to inform design decisions made on neural network hardware going forward. We provide an extensive comparison between the two techniques for compressing deep neural networks. First, we give an analytical comparison of expected quantization and pruning error for general data distributions. Then, we provide lower bounds for the per-layer pruning and quantization error in trained networks, and compare these to empirical error after optimization. Finally, we provide an extensive experimental comparison for training 8 large-scale models on 3 tasks. Our results show that in most cases quantization outperforms pruning. Only in some scenarios with very high compression ratio, pruning might be beneficial from an accuracy standpoint.", "url": "https://arxiv.org/abs/2307.02973"}, {"metadata": {"arXiv": "2307.02975", "Date": "Thu, 06 Jul 2023 13:19:27 ", "Title": "Transfer Learning for the Efficient Detection of COVID-19 from Smartphone Audio Data", "Authors": ["Mattia Giovanni Campana", "Franca Delmastro", "Elena Pagani"], "Categories": "cs.LG", "Journal-ref": "Pervasive and Mobile Computing, Volume 89, 2023", "DOI": "10.1016/j.pmcj.2023.101754"}, "abstract": "Disease detection from smartphone data represents an open research challenge in mobile health (m-health) systems. COVID-19 and its respiratory symptoms are an important case study in this area and their early detection is a potential real instrument to counteract the pandemic situation. The efficacy of this solution mainly depends on the performances of AI algorithms applied to the collected data and their possible implementation directly on the users' mobile devices. Considering these issues, and the limited amount of available data, in this paper we present the experimental evaluation of 3 different deep learning models, compared also with hand-crafted features, and of two main approaches of transfer learning in the considered scenario: both feature extraction and fine-tuning. Specifically, we considered VGGish, YAMNET, and L\\textsuperscript{3}-Net (including 12 different configurations) evaluated through user-independent experiments on 4 different datasets (13,447 samples in total). Results clearly show the advantages of L\\textsuperscript{3}-Net in all the experimental settings as it overcomes the other solutions by 12.3\\% in terms of Precision-Recall AUC as features extractor, and by 10\\% when the model is fine-tuned. Moreover, we note that to fine-tune only the fully-connected layers of the pre-trained models generally leads to worse performances, with an average drop of 6.6\\% with respect to feature extraction. %highlighting the need for further investigations. Finally, we evaluate the memory footprints of the different models for their possible applications on commercial mobile devices.", "url": "https://arxiv.org/abs/2307.02975"}, {"metadata": {"arXiv": "2307.02991", "Date": "Thu, 06 Jul 2023 13:44:29 ", "Title": "ContainerGym: A Real-World Reinforcement Learning Benchmark for Resource Allocation", "Authors": ["Abhijeet Pendyala", "Justin Dettmer", "Tobias Glasmachers", "Asma Atamna"], "Categories": "cs.LG"}, "abstract": "We present ContainerGym, a benchmark for reinforcement learning inspired by a real-world industrial resource allocation task. The proposed benchmark encodes a range of challenges commonly encountered in real-world sequential decision making problems, such as uncertainty. It can be configured to instantiate problems of varying degrees of difficulty, e.g., in terms of variable dimensionality. Our benchmark differs from other reinforcement learning benchmarks, including the ones aiming to encode real-world difficulties, in that it is directly derived from a real-world industrial problem, which underwent minimal simplification and streamlining. It is sufficiently versatile to evaluate reinforcement learning algorithms on any real-world problem that fits our resource allocation framework. We provide results of standard baseline methods. Going beyond the usual training reward curves, our results and the statistical tools used to interpret them allow to highlight interesting limitations of well-known deep reinforcement learning algorithms, namely PPO, TRPO and DQN.", "url": "https://arxiv.org/abs/2307.02991"}, {"metadata": {"arXiv": "2307.03003", "Date": "Thu, 06 Jul 2023 14:06:23 ", "Title": "Improving the Efficiency of Human-in-the-Loop Systems: Adding Artificial to Human Experts", "Authors": ["Johannes Jakubik", "Daniel Weber", "Patrick Hemmer", "Michael V\\\"ossing", "Gerhard Satzger"], "Categories": "cs.LG", "Comments": ["Accepted at International Conference on Wirtschaftsinformatik", "2023"]}, "abstract": "Information systems increasingly leverage artificial intelligence (AI) and machine learning (ML) to generate value from vast amounts of data. However, ML models are imperfect and can generate incorrect classifications. Hence, human-in-the-loop (HITL) extensions to ML models add a human review for instances that are difficult to classify. This study argues that continuously relying on human experts to handle difficult model classifications leads to a strong increase in human effort, which strains limited resources. To address this issue, we propose a hybrid system that creates artificial experts that learn to classify data instances from unknown classes previously reviewed by human experts. Our hybrid system assesses which artificial expert is suitable for classifying an instance from an unknown class and automatically assigns it. Over time, this reduces human effort and increases the efficiency of the system. Our experiments demonstrate that our approach outperforms traditional HITL systems for several benchmarks on image classification.", "url": "https://arxiv.org/abs/2307.03003"}, {"metadata": {"arXiv": "2307.03027", "Date": "Thu, 06 Jul 2023 14:44:07 ", "Title": "Improving Retrieval-Augmented Large Language Models via Data Importance Learning", "Authors": ["Xiaozhong Lyu", "Stefan Grafberger", "Samantha Biegel", "Shaopeng Wei", "Meng Cao", "Sebastian Schelter", "Ce Zhang"], "Categories": "cs.LG cs.CL cs.IR"}, "abstract": "Retrieval augmentation enables large language models to take advantage of external knowledge, for example on tasks like question answering and data imputation. However, the performance of such retrieval-augmented models is limited by the data quality of their underlying retrieval corpus. In this paper, we propose an algorithm based on multilinear extension for evaluating the data importance of retrieved data points. There are exponentially many terms in the multilinear extension, and one key contribution of this paper is a polynomial time algorithm that computes exactly, given a retrieval-augmented model with an additive utility function and a validation set, the data importance of data points in the retrieval corpus using the multilinear extension of the model's utility function. We further proposed an even more efficient ({\\epsilon}, {\\delta})-approximation algorithm. Our experimental results illustrate that we can enhance the performance of large language models by only pruning or reweighting the retrieval corpus, without requiring further training. For some tasks, this even allows a small model (e.g., GPT-JT), augmented with a search engine API, to outperform GPT-3.5 (without retrieval augmentation). Moreover, we show that weights based on multilinear extension can be computed efficiently in practice (e.g., in less than ten minutes for a corpus with 100 million elements).", "url": "https://arxiv.org/abs/2307.03027"}, {"metadata": {"arXiv": "2307.03048", "Date": "Thu, 06 Jul 2023 15:14:23 ", "Title": "Origin-Destination Travel Time Oracle for Map-based Services", "Authors": ["Yan Lin", "Huaiyu Wan", "Jilin Hu", "Shengnan Guo", "Bin Yang", "Youfang Lin", "Christian S. Jensen"], "Categories": "cs.LG", "Comments": ["15 pages", "12 figures", "accepted by SIGMOD International Conference on Management of Data 2024"]}, "abstract": "Given an origin (O), a destination (D), and a departure time (T), an Origin-Destination (OD) travel time oracle~(ODT-Oracle) returns an estimate of the time it takes to travel from O to D when departing at T. ODT-Oracles serve important purposes in map-based services. To enable the construction of such oracles, we provide a travel-time estimation (TTE) solution that leverages historical trajectories to estimate time-varying travel times for OD pairs. The problem is complicated by the fact that multiple historical trajectories with different travel times may connect an OD pair, while trajectories may vary from one another. To solve the problem, it is crucial to remove outlier trajectories when doing travel time estimation for future queries. We propose a novel, two-stage framework called Diffusion-based Origin-destination Travel Time Estimation (DOT), that solves the problem. First, DOT employs a conditioned Pixelated Trajectories (PiT) denoiser that enables building a diffusion-based PiT inference process by learning correlations between OD pairs and historical trajectories. Specifically, given an OD pair and a departure time, we aim to infer a PiT. Next, DOT encompasses a Masked Vision Transformer~(MViT) that effectively and efficiently estimates a travel time based on the inferred PiT. We report on extensive experiments on two real-world datasets that offer evidence that DOT is capable of outperforming baseline methods in terms of accuracy, scalability, and explainability.", "url": "https://arxiv.org/abs/2307.03048"}, {"metadata": {"arXiv": "2307.03068", "Date": "Thu, 06 Jul 2023 15:35:14 ", "Title": "A Hybrid End-to-End Spatio-Temporal Attention Neural Network with Graph-Smooth Signals for EEG Emotion Recognition", "Authors": ["Shadi Sartipi and Mastaneh Torkamani-Azar and Mujdat Cetin"], "Categories": "cs.LG eess.SP"}, "abstract": "Recently, physiological data such as electroencephalography (EEG) signals have attracted significant attention in affective computing. In this context, the main goal is to design an automated model that can assess emotional states. Lately, deep neural networks have shown promising performance in emotion recognition tasks. However, designing a deep architecture that can extract practical information from raw data is still a challenge. Here, we introduce a deep neural network that acquires interpretable physiological representations by a hybrid structure of spatio-temporal encoding and recurrent attention network blocks. Furthermore, a preprocessing step is applied to the raw data using graph signal processing tools to perform graph smoothing in the spatial domain. We demonstrate that our proposed architecture exceeds state-of-the-art results for emotion classification on the publicly available DEAP dataset. To explore the generality of the learned model, we also evaluate the performance of our architecture towards transfer learning (TL) by transferring the model parameters from a specific source to other target domains. Using DEAP as the source dataset, we demonstrate the effectiveness of our model in performing cross-modality TL and improving emotion classification accuracy on DREAMER and the Emotional English Word (EEWD) datasets, which involve EEG-based emotion classification tasks with different stimuli.", "url": "https://arxiv.org/abs/2307.03068"}, {"metadata": {"arXiv": "2307.03077", "Date": "Thu, 06 Jul 2023 15:45:35 ", "Title": "Learning Disentangled Representations in Signed Directed Graphs without Social Assumptions", "Authors": ["Geonwoo Ko and Jinhong Jung"], "Categories": "cs.LG cs.SI", "Comments": ["26 pages", "11 figures"]}, "abstract": "Signed graphs are complex systems that represent trust relationships or preferences in various domains. Learning node representations in such graphs is crucial for many mining tasks. Although real-world signed relationships can be influenced by multiple latent factors, most existing methods often oversimplify the modeling of signed relationships by relying on social theories and treating them as simplistic factors. This limits their expressiveness and their ability to capture the diverse factors that shape these relationships. In this paper, we propose DINES, a novel method for learning disentangled node representations in signed directed graphs without social assumptions. We adopt a disentangled framework that separates each embedding into distinct factors, allowing for capturing multiple latent factors. We also explore lightweight graph convolutions that focus solely on sign and direction, without depending on social theories. Additionally, we propose a decoder that effectively classifies an edge's sign by considering correlations between the factors. To further enhance disentanglement, we jointly train a self-supervised factor discriminator with our encoder and decoder. Throughout extensive experiments on real-world signed directed graphs, we show that DINES effectively learns disentangled node representations, and significantly outperforms its competitors in the sign prediction task.", "url": "https://arxiv.org/abs/2307.03077"}, {"metadata": {"arXiv": "2307.03093", "Date": "Thu, 06 Jul 2023 16:08:47 ", "Title": "Beyond Intuition, a Framework for Applying GPs to Real-World Data", "Authors": ["Kenza Tazi", "Jihao Andreas Lin", "Ross Viljoen", "Alex Gardner", "Ti John", "Hong Ge", "Richard E. Turner"], "Categories": "cs.LG stat.ML", "Comments": ["Accepted at the 1st ICML Workshop on Structured Probabilistic Inference and Generative Modelling (2023)"]}, "abstract": "Gaussian Processes (GPs) offer an attractive method for regression over small, structured and correlated datasets. However, their deployment is hindered by computational costs and limited guidelines on how to apply GPs beyond simple low-dimensional datasets. We propose a framework to identify the suitability of GPs to a given problem and how to set up a robust and well-specified GP model. The guidelines formalise the decisions of experienced GP practitioners, with an emphasis on kernel design and options for computational scalability. The framework is then applied to a case study of glacier elevation change yielding more accurate results at test time.", "url": "https://arxiv.org/abs/2307.03093"}, {"metadata": {"arXiv": "2307.03133", "Date": "Thu, 06 Jul 2023 16:59:53 ", "Title": "Benchmarking Test-Time Adaptation against Distribution Shifts in Image Classification", "Authors": ["Yongcan Yu", "Lijun Sheng", "Ran He", "Jian Liang"], "Categories": "cs.LG cs.CV"}, "abstract": "Test-time adaptation (TTA) is a technique aimed at enhancing the generalization performance of models by leveraging unlabeled samples solely during prediction. Given the need for robustness in neural network systems when faced with distribution shifts, numerous TTA methods have recently been proposed. However, evaluating these methods is often done under different settings, such as varying distribution shifts, backbones, and designing scenarios, leading to a lack of consistent and fair benchmarks to validate their effectiveness. To address this issue, we present a benchmark that systematically evaluates 13 prominent TTA methods and their variants on five widely used image classification datasets: CIFAR-10-C, CIFAR-100-C, ImageNet-C, DomainNet, and Office-Home. These methods encompass a wide range of adaptation scenarios (e.g. online adaptation v.s. offline adaptation, instance adaptation v.s. batch adaptation v.s. domain adaptation). Furthermore, we explore the compatibility of different TTA methods with diverse network backbones. To implement this benchmark, we have developed a unified framework in PyTorch, which allows for consistent evaluation and comparison of the TTA methods across the different datasets and network architectures. By establishing this benchmark, we aim to provide researchers and practitioners with a reliable means of assessing and comparing the effectiveness of TTA methods in improving model robustness and generalization performance. Our code is available at https://github.com/yuyongcan/Benchmark-TTA.", "url": "https://arxiv.org/abs/2307.03133"}, {"metadata": {"arXiv": "2307.03186", "Date": "Thu, 06 Jul 2023 17:58:40 ", "Title": "TGRL: An Algorithm for Teacher Guided Reinforcement Learning", "Authors": ["Idan Shenfeld", "Zhang-Wei Hong", "Aviv Tamar", "Pulkit Agrawal"], "Categories": "cs.LG", "Journal-ref": "ICML 2023"}, "abstract": "Learning from rewards (i.e., reinforcement learning or RL) and learning to imitate a teacher (i.e., teacher-student learning) are two established approaches for solving sequential decision-making problems. To combine the benefits of these different forms of learning, it is common to train a policy to maximize a combination of reinforcement and teacher-student learning objectives. However, without a principled method to balance these objectives, prior work used heuristics and problem-specific hyperparameter searches to balance the two objectives. We present a $\\textit{principled}$ approach, along with an approximate implementation for $\\textit{dynamically}$ and $\\textit{automatically}$ balancing when to follow the teacher and when to use rewards. The main idea is to adjust the importance of teacher supervision by comparing the agent's performance to the counterfactual scenario of the agent learning without teacher supervision and only from rewards. If using teacher supervision improves performance, the importance of teacher supervision is increased and otherwise it is decreased. Our method, $\\textit{Teacher Guided Reinforcement Learning}$ (TGRL), outperforms strong baselines across diverse domains without hyper-parameter tuning.", "url": "https://arxiv.org/abs/2307.03186"}, {"metadata": {"arXiv": "2307.02641", "Date": "Wed, 05 Jul 2023 20:16:57 ", "Title": "Active Class Selection for Few-Shot Class-Incremental Learning", "Authors": ["Christopher McClurg", "Ali Ayub", "Harsh Tyagi", "Sarah M. Rajtmajer", "and Alan R. Wagner"], "Categories": "cs.RO cs.CV cs.LG", "Comments": ["Accepted at the Conference on Lifelong Learning Agents (CoLLAs)", "2023"]}, "abstract": "For real-world applications, robots will need to continually learn in their environments through limited interactions with their users. Toward this, previous works in few-shot class incremental learning (FSCIL) and active class selection (ACS) have achieved promising results but were tested in constrained setups. Therefore, in this paper, we combine ideas from FSCIL and ACS to develop a novel framework that can allow an autonomous agent to continually learn new objects by asking its users to label only a few of the most informative objects in the environment. To this end, we build on a state-of-the-art (SOTA) FSCIL model and extend it with techniques from ACS literature. We term this model Few-shot Incremental Active class SeleCtiOn (FIASco). We further integrate a potential field-based navigation technique with our model to develop a complete framework that can allow an agent to process and reason on its sensory data through the FIASco model, navigate towards the most informative object in the environment, gather data about the object through its sensors and incrementally update the FIASco model. Experimental results on a simulated agent and a real robot show the significance of our approach for long-term real-world robotics applications.", "url": "https://arxiv.org/abs/2307.02641"}, {"metadata": {"arXiv": "2307.02889", "Date": "Thu, 06 Jul 2023 09:48:51 ", "Title": "Learning to Solve Tasks with Exploring Prior Behaviours", "Authors": ["Ruiqi Zhu", "Siyuan Li", "Tianhong Dai", "Chongjie Zhang", "Oya Celiktutan"], "Categories": "cs.RO cs.LG"}, "abstract": "Demonstrations are widely used in Deep Reinforcement Learning (DRL) for facilitating solving tasks with sparse rewards. However, the tasks in real-world scenarios can often have varied initial conditions from the demonstration, which would require additional prior behaviours. For example, consider we are given the demonstration for the task of \\emph{picking up an object from an open drawer}, but the drawer is closed in the training. Without acquiring the prior behaviours of opening the drawer, the robot is unlikely to solve the task. To address this, in this paper we propose an Intrinsic Rewards Driven Example-based Control \\textbf{(IRDEC)}. Our method can endow agents with the ability to explore and acquire the required prior behaviours and then connect to the task-specific behaviours in the demonstration to solve sparse-reward tasks without requiring additional demonstration of the prior behaviours. The performance of our method outperforms other baselines on three navigation tasks and one robotic manipulation task with sparse rewards. Codes are available at https://github.com/Ricky-Zhu/IRDEC.", "url": "https://arxiv.org/abs/2307.02889"}, {"metadata": {"arXiv": "2307.02637", "Date": "Wed, 05 Jul 2023 20:13:01 ", "Title": "Surge Routing: Event-informed Multiagent Reinforcement Learning for Autonomous Rideshare", "Authors": ["Daniel Garces and Stephanie Gil"], "Categories": "cs.AI cs.MA cs.RO", "Comments": ["11 pages", "8 figures", "2 tables", "under review"]}, "abstract": "Large events such as conferences, concerts and sports games, often cause surges in demand for ride services that are not captured in average demand patterns, posing unique challenges for routing algorithms. We propose a learning framework for an autonomous fleet of taxis that scrapes event data from the internet to predict and adapt to surges in demand and generates cooperative routing and pickup policies that service a higher number of requests than other routing protocols. We achieve this through a combination of (i) an event processing framework that scrapes the internet for event information and generates dense vector representations that can be used as input features for a neural network that predicts demand; (ii) a two neural network system that predicts hourly demand over the entire map, using these dense vector representations; (iii) a probabilistic approach that leverages locale occupancy schedules to map publicly available demand data over sectors to discretized street intersections; and finally, (iv) a scalable model-based reinforcement learning framework that uses the predicted demand over intersections to anticipate surges and route taxis using one-agent-at-a-time rollout with limited sampling certainty equivalence. We learn routing and pickup policies using real NYC ride share data for 2022 and information for more than 2000 events across 300 unique venues in Manhattan. We test our approach with a fleet of 100 taxis on a map with 38 different sectors (2235 street intersections). Our experimental results demonstrate that our method obtains routing policies that service $6$ more requests on average per minute (around $360$ more requests per hour) than other model-based RL frameworks and other classical algorithms in operations research when dealing with surge demand conditions.", "url": "https://arxiv.org/abs/2307.02637"}, {"metadata": {"arXiv": "2307.02709", "Date": "Thu, 06 Jul 2023 01:17:29 ", "Title": "Validation of the Practicability of Logical Assessment Formula for Evaluations with Inaccurate Ground-Truth Labels", "Authors": ["Yongquan Yang and Hong Bu"], "Categories": "cs.AI", "Comments": ["arXiv admin note: substantial text overlap with arXiv:2110.11567"]}, "abstract": "Logical assessment formula (LAF) is a new theory proposed for evaluations with inaccurate ground-truth labels (IAGTLs) to assess the predictive models for various artificial intelligence applications. However, the practicability of LAF for evaluations with IAGTLs has not yet been validated in real-world practice. In this paper, to address this issue, we applied LAF to tumour segmentation for breast cancer (TSfBC) in medical histopathology whole slide image analysis (MHWSIA). Experimental results and analysis show the validity of LAF for evaluations with IAGTLs in the case of TSfBC and reflect the potentials of LAF applied to MHWSIA.", "url": "https://arxiv.org/abs/2307.02709"}, {"metadata": {"arXiv": "2307.02738", "Date": "Thu, 06 Jul 2023 02:51:54 ", "Title": "RecallM: An Architecture for Temporal Context Understanding and Question Answering", "Authors": ["Brandon Kynoch", "Hugo Latapie"], "Categories": "cs.AI cs.CL cs.SC", "Comments": ["10 pages", "4 figures Our code is publicly available online at: https://github.com/cisco-open/DeepVision/tree/main/recallm"]}, "abstract": "The ideal long-term memory mechanism for Large Language Model (LLM) based chatbots, would lay the foundation for continual learning, complex reasoning and allow sequential and temporal dependencies to be learnt. Creating this type of memory mechanism is an extremely challenging problem. In this paper we explore different methods of achieving the effect of long-term memory. We propose a new architecture focused on creating adaptable and updatable long-term memory for AGI systems. We demonstrate through various experiments the benefits of the RecallM architecture, particularly the improved temporal understanding it provides.", "url": "https://arxiv.org/abs/2307.02738"}, {"metadata": {"arXiv": "2307.03171", "Date": "Thu, 06 Jul 2023 17:52:29 ", "Title": "LEO: Learning Efficient Orderings for Multiobjective Binary Decision Diagrams", "Authors": ["Rahul Patel", "Elias B. Khalil"], "Categories": "cs.AI"}, "abstract": "Approaches based on Binary decision diagrams (BDDs) have recently achieved state-of-the-art results for multiobjective integer programming problems. The variable ordering used in constructing BDDs can have a significant impact on their size and on the quality of bounds derived from relaxed or restricted BDDs for single-objective optimization problems. We first showcase a similar impact of variable ordering on the Pareto frontier (PF) enumeration time for the multiobjective knapsack problem, suggesting the need for deriving variable ordering methods that improve the scalability of the multiobjective BDD approach. To that end, we derive a novel parameter configuration space based on variable scoring functions which are linear in a small set of interpretable and easy-to-compute variable features. We show how the configuration space can be efficiently explored using black-box optimization, circumventing the curse of dimensionality (in the number of variables and objectives), and finding good orderings that reduce the PF enumeration time. However, black-box optimization approaches incur a computational overhead that outweighs the reduction in time due to good variable ordering. To alleviate this issue, we propose LEO, a supervised learning approach for finding efficient variable orderings that reduce the enumeration time. Experiments on benchmark sets from the knapsack problem with 3-7 objectives and up to 80 variables show that LEO is ~30-300% and ~10-200% faster at PF enumeration than common ordering strategies and algorithm configuration. Our code and instances are available at https://github.com/khalil-research/leo.", "url": "https://arxiv.org/abs/2307.03171"}, {"metadata": {"arXiv": "2307.02489", "Date": "Tue, 13 Jun 2023 19:17:58 ", "Title": "Visual Question Answering (VQA) on Images with Superimposed Text", "Authors": ["Venkat Kodali and Daniel Berleant"], "Categories": "cs.CV cs.AI", "Comments": ["To appear in: Proc. of the Future Technologies Conference (FTC) 2023", "Nov. 2-3", "San Francisco", "pub. by Springer Nature"], "ACM-class": "I.2.10; J.3"}, "abstract": "Superimposed text annotations have been under-investigated, yet are ubiquitous, useful and important, especially in medical images. Medical images also highlight the challenges posed by low resolution, noise and superimposed textual meta-information. Therefor we probed the impact of superimposing text onto medical images on VQA. Our results revealed that this textual meta-information can be added without severely degrading key measures of VQA performance. Our findings are significant because they validate the practice of superimposing text on images, even for medical images subjected to the VQA task using AI techniques. The work helps advance understanding of VQA in general and, in particular, in the domain of healthcare and medicine.", "url": "https://arxiv.org/abs/2307.02489"}, {"metadata": {"arXiv": "2307.02495", "Date": "Tue, 04 Jul 2023 07:49:31 ", "Title": "Anomaly detection in image or latent space of patch-based auto-encoders for industrial image analysis", "Authors": ["Nicolas Pinon (MYRIAD)", "Robin Trombetta (MYRIAD)", "Carole Lartizien (MYRIAD)"], "Categories": "cs.CV cs.AI eess.SP", "Comments": ["in French language. GRETSI 2023 : XXIX{\\`e}me Colloque Francophone de Traitement du Signal et des Images", "Aug 2023", "Grenoble", "France"]}, "abstract": "We study several methods for detecting anomalies in color images, constructed on patch-based auto-encoders. Wecompare the performance of three types of methods based, first, on the error between the original image and its reconstruction,second, on the support estimation of the normal image distribution in the latent space, and third, on the error between the originalimage and a restored version of the reconstructed image. These methods are evaluated on the industrial image database MVTecADand compared to two competitive state-of-the-art methods.", "url": "https://arxiv.org/abs/2307.02495"}, {"metadata": {"arXiv": "2307.02730", "Date": "Thu, 06 Jul 2023 02:30:56 ", "Title": "Fine-grained Action Analysis: A Multi-modality and Multi-task Dataset of Figure Skating", "Authors": ["Sheng-Lan Liu", "Yu-Ning Ding", "Si-Fan Zhang", "Wen-Yue Chen", "Ning Zhou", "Hao Liu", "Gui-Hong Lao"], "Categories": "cs.CV cs.AI"}, "abstract": "The fine-grained action analysis of the existing action datasets is challenged by insufficient action categories, low fine granularities, limited modalities, and tasks. In this paper, we propose a Multi-modality and Multi-task dataset of Figure Skating (MMFS) which was collected from the World Figure Skating Championships. MMFS, which possesses action recognition and action quality assessment, captures RGB, skeleton, and is collected the score of actions from 11671 clips with 256 categories including spatial and temporal labels. The key contributions of our dataset fall into three aspects as follows. (1) Independently spatial and temporal categories are first proposed to further explore fine-grained action recognition and quality assessment. (2) MMFS first introduces the skeleton modality for complex fine-grained action quality assessment. (3) Our multi-modality and multi-task dataset encourage more action analysis models. To benchmark our dataset, we adopt RGB-based and skeleton-based baseline methods for action recognition and action quality assessment.", "url": "https://arxiv.org/abs/2307.02730"}, {"metadata": {"arXiv": "2307.02770", "Date": "Thu, 06 Jul 2023 04:45:14 ", "Title": "Censored Sampling of Diffusion Models Using 3 Minutes of Human Feedback", "Authors": ["TaeHo Yoon", "Kibeom Myoung", "Keon Lee", "Jaewoong Cho", "Albert No", "Ernest K. Ryu"], "Categories": "cs.CV cs.AI"}, "abstract": "Diffusion models have recently shown remarkable success in high-quality image generation. Sometimes, however, a pre-trained diffusion model exhibits partial misalignment in the sense that the model can generate good images, but it sometimes outputs undesirable images. If so, we simply need to prevent the generation of the bad images, and we call this task censoring. In this work, we present censored generation with a pre-trained diffusion model using a reward model trained on minimal human feedback. We show that censoring can be accomplished with extreme human feedback efficiency and that labels generated with a mere few minutes of human feedback are sufficient. Code available at: https://github.com/tetrzim/diffusion-human-feedback.", "url": "https://arxiv.org/abs/2307.02770"}, {"metadata": {"arXiv": "2307.02798", "Date": "Thu, 06 Jul 2023 06:13:22 ", "Title": "Semi-supervised Domain Adaptive Medical Image Segmentation through Consistency Regularized Disentangled Contrastive Learning", "Authors": ["Hritam Basak", "Zhaozheng Yin"], "Categories": "cs.CV cs.AI", "Comments": ["Paper accepted at MICCAI 2023"]}, "abstract": "Although unsupervised domain adaptation (UDA) is a promising direction to alleviate domain shift, they fall short of their supervised counterparts. In this work, we investigate relatively less explored semi-supervised domain adaptation (SSDA) for medical image segmentation, where access to a few labeled target samples can improve the adaptation performance substantially. Specifically, we propose a two-stage training process. First, an encoder is pre-trained in a self-learning paradigm using a novel domain-content disentangled contrastive learning (CL) along with a pixel-level feature consistency constraint. The proposed CL enforces the encoder to learn discriminative content-specific but domain-invariant semantics on a global scale from the source and target images, whereas consistency regularization enforces the mining of local pixel-level information by maintaining spatial sensitivity. This pre-trained encoder, along with a decoder, is further fine-tuned for the downstream task, (i.e. pixel-level segmentation) using a semi-supervised setting. Furthermore, we experimentally validate that our proposed method can easily be extended for UDA settings, adding to the superiority of the proposed strategy. Upon evaluation on two domain adaptive image segmentation tasks, our proposed method outperforms the SoTA methods, both in SSDA and UDA settings. Code is available at https://github.com/hritam-98/GFDA-disentangled", "url": "https://arxiv.org/abs/2307.02798"}, {"metadata": {"arXiv": "2307.02971", "Date": "Thu, 06 Jul 2023 13:17:55 ", "Title": "On the Cultural Gap in Text-to-Image Generation", "Authors": ["Bingshuai Liu", "Longyue Wang", "Chenyang Lyu", "Yong Zhang", "Jinsong Su", "Shuming Shi", "Zhaopeng Tu"], "Categories": "cs.CV cs.AI cs.CL", "Comments": ["Equal contribution: Bingshuai Liu and Longyue Wang. Work done while Bingshuai Liu and Chengyang Lyu were interning at Tencent AI Lab. Zhaopeng Tu is the corresponding author"]}, "abstract": "One challenge in text-to-image (T2I) generation is the inadvertent reflection of culture gaps present in the training data, which signifies the disparity in generated image quality when the cultural elements of the input text are rarely collected in the training set. Although various T2I models have shown impressive but arbitrary examples, there is no benchmark to systematically evaluate a T2I model's ability to generate cross-cultural images. To bridge the gap, we propose a Challenging Cross-Cultural (C3) benchmark with comprehensive evaluation criteria, which can assess how well-suited a model is to a target culture. By analyzing the flawed images generated by the Stable Diffusion model on the C3 benchmark, we find that the model often fails to generate certain cultural objects. Accordingly, we propose a novel multi-modal metric that considers object-text alignment to filter the fine-tuning data in the target culture, which is used to fine-tune a T2I model to improve cross-cultural generation. Experimental results show that our multi-modal metric provides stronger data selection performance on the C3 benchmark than existing metrics, in which the object-text alignment is crucial. We release the benchmark, data, code, and generated images to facilitate future research on culturally diverse T2I generation (https://github.com/longyuewangdcu/C3-Bench).", "url": "https://arxiv.org/abs/2307.02971"}, {"metadata": {"arXiv": "2307.03007", "Date": "Thu, 06 Jul 2023 14:13:11 ", "Title": "Self-supervised Optimization of Hand Pose Estimation using Anatomical Features and Iterative Learning", "Authors": ["Christian Jauch", "Timo Leitritz", "Marco F. Huber"], "Categories": "cs.CV cs.AI", "Comments": ["Manuscript accepted at IEEE SMC 2023"]}, "abstract": "Manual assembly workers face increasing complexity in their work. Human-centered assistance systems could help, but object recognition as an enabling technology hinders sophisticated human-centered design of these systems. At the same time, activity recognition based on hand poses suffers from poor pose estimation in complex usage scenarios, such as wearing gloves. This paper presents a self-supervised pipeline for adapting hand pose estimation to specific use cases with minimal human interaction. This enables cheap and robust hand posebased activity recognition. The pipeline consists of a general machine learning model for hand pose estimation trained on a generalized dataset, spatial and temporal filtering to account for anatomical constraints of the hand, and a retraining step to improve the model. Different parameter combinations are evaluated on a publicly available and annotated dataset. The best parameter and model combination is then applied to unlabelled videos from a manual assembly scenario. The effectiveness of the pipeline is demonstrated by training an activity recognition as a downstream task in the manual assembly scenario.", "url": "https://arxiv.org/abs/2307.03007"}, {"metadata": {"arXiv": "2307.03039", "Date": "Thu, 06 Jul 2023 15:04:18 ", "Title": "Art Authentication with Vision Transformers", "Authors": ["Ludovica Schaerf", "Carina Popovici", "Eric Postma"], "Categories": "cs.CV cs.AI"}, "abstract": "In recent years, Transformers, initially developed for language, have been successfully applied to visual tasks. Vision Transformers have been shown to push the state-of-the-art in a wide range of tasks, including image classification, object detection, and semantic segmentation. While ample research has shown promising results in art attribution and art authentication tasks using Convolutional Neural Networks, this paper examines if the superiority of Vision Transformers extends to art authentication, improving, thus, the reliability of computer-based authentication of artworks. Using a carefully compiled dataset of authentic paintings by Vincent van Gogh and two contrast datasets, we compare the art authentication performances of Swin Transformers with those of EfficientNet. Using a standard contrast set containing imitations and proxies (works by painters with styles closely related to van Gogh), we find that EfficientNet achieves the best performance overall. With a contrast set that only consists of imitations, we find the Swin Transformer to be superior to EfficientNet by achieving an authentication accuracy of over 85%. These results lead us to conclude that Vision Transformers represent a strong and promising contender in art authentication, particularly in enhancing the computer-based ability to detect artistic imitations.", "url": "https://arxiv.org/abs/2307.03039"}, {"metadata": {"arXiv": "2307.02691", "Date": "Wed, 05 Jul 2023 23:36:33 ", "Title": "SACHA: Soft Actor-Critic with Heuristic-Based Attention for Partially Observable Multi-Agent Path Finding", "Authors": ["Qiushi Lin", "Hang Ma"], "Categories": "cs.RO cs.AI cs.MA", "Comments": ["Accepted to IEEE Robotics and Automation Letters (RA-L)"], "DOI": "10.1109/LRA.2023.3292004"}, "abstract": "Multi-Agent Path Finding (MAPF) is a crucial component for many large-scale robotic systems, where agents must plan their collision-free paths to their given goal positions. Recently, multi-agent reinforcement learning has been introduced to solve the partially observable variant of MAPF by learning a decentralized single-agent policy in a centralized fashion based on each agent's partial observation. However, existing learning-based methods are ineffective in achieving complex multi-agent cooperation, especially in congested environments, due to the non-stationarity of this setting. To tackle this challenge, we propose a multi-agent actor-critic method called Soft Actor-Critic with Heuristic-Based Attention (SACHA), which employs novel heuristic-based attention mechanisms for both the actors and critics to encourage cooperation among agents. SACHA learns a neural network for each agent to selectively pay attention to the shortest path heuristic guidance from multiple agents within its field of view, thereby allowing for more scalable learning of cooperation. SACHA also extends the existing multi-agent actor-critic framework by introducing a novel critic centered on each agent to approximate $Q$-values. Compared to existing methods that use a fully observable critic, our agent-centered multi-agent actor-critic method results in more impartial credit assignment and better generalizability of the learned policy to MAPF instances with varying numbers of agents and types of environments. We also implement SACHA(C), which embeds a communication module in the agent's policy network to enable information exchange among agents. We evaluate both SACHA and SACHA(C) on a variety of MAPF instances and demonstrate decent improvements over several state-of-the-art learning-based MAPF methods with respect to success rate and solution quality.", "url": "https://arxiv.org/abs/2307.02691"}, {"metadata": {"arXiv": "2307.03015", "Date": "Thu, 06 Jul 2023 14:24:17 ", "Title": "Sequential Neural Barriers for Scalable Dynamic Obstacle Avoidance", "Authors": ["Hongzhan Yu", "Chiaki Hirayama", "Chenning Yu", "Sylvia Herbert", "Sicun Gao"], "Categories": "cs.RO cs.AI", "Comments": ["To be published in IROS 2023"]}, "abstract": "There are two major challenges for scaling up robot navigation around dynamic obstacles: the complex interaction dynamics of the obstacles can be hard to model analytically, and the complexity of planning and control grows exponentially in the number of obstacles. Data-driven and learning-based methods are thus particularly valuable in this context. However, data-driven methods are sensitive to distribution drift, making it hard to train and generalize learned models across different obstacle densities. We propose a novel method for compositional learning of Sequential Neural Control Barrier models (SNCBFs) to achieve scalability. Our approach exploits an important observation: the spatial interaction patterns of multiple dynamic obstacles can be decomposed and predicted through temporal sequences of states for each obstacle. Through decomposition, we can generalize control policies trained only with a small number of obstacles, to environments where the obstacle density can be 100x higher. We demonstrate the benefits of the proposed methods in improving dynamic collision avoidance in comparison with existing methods including potential fields, end-to-end reinforcement learning, and model-predictive control. We also perform hardware experiments and show the practical effectiveness of the approach in the supplementary video.", "url": "https://arxiv.org/abs/2307.03015"}, {"metadata": {"arXiv": "2307.03067", "Date": "Thu, 06 Jul 2023 15:35:02 ", "Title": "DeepOnto: A Python Package for Ontology Engineering with Deep Learning", "Authors": ["Yuan He", "Jiaoyan Chen", "Hang Dong", "Ian Horrocks", "Carlo Allocca", "Taehun Kim", "Brahmananda Sapkota"], "Categories": "cs.AI cs.CL cs.LG cs.LO", "Comments": ["under review at Semantic Web Journal"]}, "abstract": "Applying deep learning techniques, particularly language models (LMs), in ontology engineering has raised widespread attention. However, deep learning frameworks like PyTorch and Tensorflow are predominantly developed for Python programming, while widely-used ontology APIs, such as the OWL API and Jena, are primarily Java-based. To facilitate seamless integration of these frameworks and APIs, we present Deeponto, a Python package designed for ontology engineering. The package encompasses a core ontology processing module founded on the widely-recognised and reliable OWL API, encapsulating its fundamental features in a more \"Pythonic\" manner and extending its capabilities to include other essential components including reasoning, verbalisation, normalisation, projection, and more. Building on this module, Deeponto offers a suite of tools, resources, and algorithms that support various ontology engineering tasks, such as ontology alignment and completion, by harnessing deep learning methodologies, primarily pre-trained LMs. In this paper, we also demonstrate the practical utility of Deeponto through two use-cases: the Digital Health Coaching in Samsung Research UK and the Bio-ML track of the Ontology Alignment Evaluation Initiative (OAEI).", "url": "https://arxiv.org/abs/2307.03067"}, {"metadata": {"arXiv": "2307.03119", "Date": "Thu, 06 Jul 2023 16:45:40 ", "Title": "Learning Multi-Agent Intention-Aware Communication for Optimal Multi-Order Execution in Finance", "Authors": ["Yuchen Fang", "Zhenggang Tang", "Kan Ren", "Weiqing Liu", "Li Zhao", "Jiang Bian", "Dongsheng Li", "Weinan Zhang", "Yong Yu", "Tie-Yan Liu"], "Categories": "cs.AI cs.LG cs.MA", "Comments": ["Accepted in KDD 2023; The website is at https://seqml.github.io/marl4fin"], "DOI": "10.1145/3580305.3599856"}, "abstract": "Order execution is a fundamental task in quantitative finance, aiming at finishing acquisition or liquidation for a number of trading orders of the specific assets. Recent advance in model-free reinforcement learning (RL) provides a data-driven solution to the order execution problem. However, the existing works always optimize execution for an individual order, overlooking the practice that multiple orders are specified to execute simultaneously, resulting in suboptimality and bias. In this paper, we first present a multi-agent RL (MARL) method for multi-order execution considering practical constraints. Specifically, we treat every agent as an individual operator to trade one specific order, while keeping communicating with each other and collaborating for maximizing the overall profits. Nevertheless, the existing MARL algorithms often incorporate communication among agents by exchanging only the information of their partial observations, which is inefficient in complicated financial market. To improve collaboration, we then propose a learnable multi-round communication protocol, for the agents communicating the intended actions with each other and refining accordingly. It is optimized through a novel action value attribution method which is provably consistent with the original learning objective yet more efficient. The experiments on the data from two real-world markets have illustrated superior performance with significantly better collaboration effectiveness achieved by our method.", "url": "https://arxiv.org/abs/2307.03119"}, {"metadata": {"arXiv": "2307.02791", "Date": "Thu, 06 Jul 2023 06:06:47 ", "Title": "The Role of Subgroup Separability in Group-Fair Medical Image Classification", "Authors": ["Charles Jones", "M\\'elanie Roschewitz", "Ben Glocker"], "Categories": "cs.CV cs.AI cs.CY cs.LG", "Comments": ["Accepted at MICCAI 2023. Code available under https://github.com/biomedia-mira/subgroup-separability"]}, "abstract": "We investigate performance disparities in deep classifiers. We find that the ability of classifiers to separate individuals into subgroups varies substantially across medical imaging modalities and protected characteristics; crucially, we show that this property is predictive of algorithmic bias. Through theoretical analysis and extensive empirical evaluation, we find a relationship between subgroup separability, subgroup disparities, and performance degradation when models are trained on data with systematic bias such as underdiagnosis. Our findings shed new light on the question of how models become biased, providing important insights for the development of fair medical imaging AI.", "url": "https://arxiv.org/abs/2307.02791"}, {"metadata": {"arXiv": "2307.03135", "Date": "Thu, 06 Jul 2023 17:05:26 ", "Title": "Distilling Large Vision-Language Model with Out-of-Distribution Generalizability", "Authors": ["Xuanlin Li", "Yunhao Fang", "Minghua Liu", "Zhan Ling", "Zhuowen Tu", "Hao Su"], "Categories": "cs.CV cs.AI cs.CL cs.LG"}, "abstract": "Large vision-language models have achieved outstanding performance, but their size and computational requirements make their deployment on resource-constrained devices and time-sensitive tasks impractical. Model distillation, the process of creating smaller, faster models that maintain the performance of larger models, is a promising direction towards the solution. This paper investigates the distillation of visual representations in large teacher vision-language models into lightweight student models using a small- or mid-scale dataset. Notably, this study focuses on open-vocabulary out-of-distribution (OOD) generalization, a challenging problem that has been overlooked in previous model distillation literature. We propose two principles from vision and language modality perspectives to enhance student's OOD generalization: (1) by better imitating teacher's visual representation space, and carefully promoting better coherence in vision-language alignment with the teacher; (2) by enriching the teacher's language representations with informative and finegrained semantic attributes to effectively distinguish between different labels. We propose several metrics and conduct extensive experiments to investigate their techniques. The results demonstrate significant improvements in zero-shot and few-shot student performance on open-vocabulary out-of-distribution classification, highlighting the effectiveness of our proposed approaches. Our code will be released at https://github.com/xuanlinli17/large_vlm_distillation_ood", "url": "https://arxiv.org/abs/2307.03135"}, {"metadata": {"arXiv": "2307.02491", "Date": "Tue, 04 Jul 2023 02:45:59 ", "Title": "TablEye: Seeing small Tables through the Lens of Images", "Authors": ["Seung-eon Lee and Sang-Chul Lee"], "Categories": "cs.LG cs.AI"}, "abstract": "The exploration of few-shot tabular learning becomes imperative. Tabular data is a versatile representation that captures diverse information, yet it is not exempt from limitations, property of data and model size. Labeling extensive tabular data can be challenging, and it may not be feasible to capture every important feature. Few-shot tabular learning, however, remains relatively unexplored, primarily due to scarcity of shared information among independent datasets and the inherent ambiguity in defining boundaries within tabular data. To the best of our knowledge, no meaningful and unrestricted few-shot tabular learning techniques have been developed without imposing constraints on the dataset. In this paper, we propose an innovative framework called TablEye, which aims to overcome the limit of forming prior knowledge for tabular data by adopting domain transformation. It facilitates domain transformation by generating tabular images, which effectively conserve the intrinsic semantics of the original tabular data. This approach harnesses rigorously tested few-shot learning algorithms and embedding functions to acquire and apply prior knowledge. Leveraging shared data domains allows us to utilize this prior knowledge, originally learned from the image domain. Specifically, TablEye demonstrated a superior performance by outstripping the TabLLM in a 4-shot task with a maximum 0.11 AUC and a STUNT in a 1- shot setting, where it led on average by 3.17% accuracy.", "url": "https://arxiv.org/abs/2307.02491"}, {"metadata": {"arXiv": "2307.02493", "Date": "Tue, 04 Jul 2023 05:56:44 ", "Title": "FREEDOM: Target Label & Source Data & Domain Information-Free Multi-Source Domain Adaptation for Unsupervised Personalization", "Authors": ["Eunju Yang", "Gyusang Cho", "Chan-Hyun Youn"], "Categories": "cs.LG cs.AI"}, "abstract": "From a service perspective, Multi-Source Domain Adaptation (MSDA) is a promising scenario to adapt a deployed model to a client's dataset. It can provide adaptation without a target label and support the case where a source dataset is constructed from multiple domains. However, it is impractical, wherein its training heavily relies on prior domain information of the multi-source dataset -- how many domains exist and the domain label of each data sample. Moreover, MSDA requires both source and target datasets simultaneously (physically), causing storage limitations on the client device or data privacy issues by transferring client data to a server. For a more practical scenario of model adaptation from a service provider's point of view, we relax these constraints and present a novel problem scenario of Three-Free Domain Adaptation, namely TFDA, where 1) target labels, 2) source dataset, and mostly 3) source domain information (domain labels + the number of domains) are unavailable. Under the problem scenario, we propose a practical adaptation framework called FREEDOM. It leverages the power of the generative model, disentangling data into class and style aspects, where the style is defined as the class-independent information from the source data and designed with a nonparametric Bayesian approach. In the adaptation stage, FREEDOM aims to match the source class distribution with the target's under the philosophy that class distribution is consistent even if the style is different; after then, only part of the classification model is deployed as a personalized network. As a result, FREEDOM achieves state-of-the-art or comparable performance even without domain information, with reduced final model size on the target side, independent of the number of source domains.", "url": "https://arxiv.org/abs/2307.02493"}, {"metadata": {"arXiv": "2307.02507", "Date": "Wed, 05 Jul 2023 03:47:28 ", "Title": "STS-CCL: Spatial-Temporal Synchronous Contextual Contrastive Learning for Urban Traffic Forecasting", "Authors": ["Lincan Li", "Kaixiang Yang", "Fengji Luo", "Jichao Bi"], "Categories": "cs.LG cs.AI", "Comments": ["11pages", "6 figures"]}, "abstract": "Efficiently capturing the complex spatiotemporal representations from large-scale unlabeled traffic data remains to be a challenging task. In considering of the dilemma, this work employs the advanced contrastive learning and proposes a novel Spatial-Temporal Synchronous Contextual Contrastive Learning (STS-CCL) model. First, we elaborate the basic and strong augmentation methods for spatiotemporal graph data, which not only perturb the data in terms of graph structure and temporal characteristics, but also employ a learning-based dynamic graph view generator for adaptive augmentation. Second, we introduce a Spatial-Temporal Synchronous Contrastive Module (STS-CM) to simultaneously capture the decent spatial-temporal dependencies and realize graph-level contrasting. To further discriminate node individuals in negative filtering, a Semantic Contextual Contrastive method is designed based on semantic features and spatial heterogeneity, achieving node-level contrastive learning along with negative filtering. Finally, we present a hard mutual-view contrastive training scheme and extend the classic contrastive loss to an integrated objective function, yielding better performance. Extensive experiments and evaluations demonstrate that building a predictor upon STS-CCL contrastive learning model gains superior performance than existing traffic forecasting benchmarks. The proposed STS-CCL is highly suitable for large datasets with only a few labeled data and other spatiotemporal tasks with data scarcity issue.", "url": "https://arxiv.org/abs/2307.02507"}, {"metadata": {"arXiv": "2307.02511", "Date": "Wed, 05 Jul 2023 10:07:50 ", "Title": "Diffusion Models for Computational Design at the Example of Floor Plans", "Authors": ["Joern Ploennigs", "Markus Berger"], "Categories": "cs.LG cs.AI"}, "abstract": "AI Image generators based on diffusion models are widely discussed recently for their capability to create images from simple text prompts. But, for practical use in civil engineering they need to be able to create specific construction plans for given constraints. Within this paper we explore the capabilities of those diffusion-based AI generators for computational design at the example of floor plans and identify their current limitation. We explain how the diffusion-models work and propose new diffusion models with improved semantic encoding. In several experiments we show that we can improve validity of generated floor plans from 6% to 90% and query performance for different examples. We identify short comings and derive future research challenges of those models and discuss the need to combine diffusion models with building information modelling. With this we provide key insights into the current state and future directions for diffusion models in civil engineering.", "url": "https://arxiv.org/abs/2307.02511"}, {"metadata": {"arXiv": "2307.02516", "Date": "Wed, 05 Jul 2023 14:28:46 ", "Title": "Exploring new ways: Enforcing representational dissimilarity to learn new features and reduce error consistency", "Authors": ["Tassilo Wald and Constantin Ulrich and Fabian Isensee and David Zimmerer and Gregor Koehler and Michael Baumgartner and Klaus H. Maier-Hein"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["The Second Workshop on Spurious Correlations", "Invariance and Stability at ICML 2023"]}, "abstract": "Independently trained machine learning models tend to learn similar features. Given an ensemble of independently trained models, this results in correlated predictions and common failure modes. Previous attempts focusing on decorrelation of output predictions or logits yielded mixed results, particularly due to their reduction in model accuracy caused by conflicting optimization objectives. In this paper, we propose the novel idea of utilizing methods of the representational similarity field to promote dissimilarity during training instead of measuring similarity of trained models. To this end, we promote intermediate representations to be dissimilar at different depths between architectures, with the goal of learning robust ensembles with disjoint failure modes. We show that highly dissimilar intermediate representations result in less correlated output predictions and slightly lower error consistency, resulting in higher ensemble accuracy. With this, we shine first light on the connection between intermediate representations and their impact on the output predictions.", "url": "https://arxiv.org/abs/2307.02516"}, {"metadata": {"arXiv": "2307.02588", "Date": "Wed, 05 Jul 2023 18:34:22 ", "Title": "TransformerG2G: Adaptive time-stepping for learning temporal graph embeddings using transformers", "Authors": ["Alan John Varghese", "Aniruddha Bora", "Mengjia Xu", "George Em Karniadakis"], "Categories": "cs.LG cs.AI math.DS", "Comments": ["16 pages", "8 figures"]}, "abstract": "Dynamic graph embedding has emerged as a very effective technique for addressing diverse temporal graph analytic tasks (i.e., link prediction, node classification, recommender systems, anomaly detection, and graph generation) in various applications. Such temporal graphs exhibit heterogeneous transient dynamics, varying time intervals, and highly evolving node features throughout their evolution. Hence, incorporating long-range dependencies from the historical graph context plays a crucial role in accurately learning their temporal dynamics. In this paper, we develop a graph embedding model with uncertainty quantification, TransformerG2G, by exploiting the advanced transformer encoder to first learn intermediate node representations from its current state ($t$) and previous context (over timestamps [$t-1, t-l$], $l$ is the length of context). Moreover, we employ two projection layers to generate lower-dimensional multivariate Gaussian distributions as each node's latent embedding at timestamp $t$. We consider diverse benchmarks with varying levels of ``novelty\" as measured by the TEA plots. Our experiments demonstrate that the proposed TransformerG2G model outperforms conventional multi-step methods and our prior work (DynG2G) in terms of both link prediction accuracy and computational efficiency, especially for high degree of novelty. Furthermore, the learned time-dependent attention weights across multiple graph snapshots reveal the development of an automatic adaptive time stepping enabled by the transformer. Importantly, by examining the attention weights, we can uncover temporal dependencies, identify influential elements, and gain insights into the complex interactions within the graph structure. For example, we identified a strong correlation between attention weights and node degree at the various stages of the graph topology evolution.", "url": "https://arxiv.org/abs/2307.02588"}, {"metadata": {"arXiv": "2307.02620", "Date": "Wed, 05 Jul 2023 19:48:03 ", "Title": "Dynamic Observation Policies in Observation Cost-Sensitive Reinforcement Learning", "Authors": ["Colin Bellinger", "Mark Crowley", "Isaac Tamblyn"], "Categories": "cs.LG cs.AI", "MSC-class": "68T01", "ACM-class": "I.2.0"}, "abstract": "Reinforcement learning (RL) has been shown to learn sophisticated control policies for complex tasks including games, robotics, heating and cooling systems and text generation. The action-perception cycle in RL, however, generally assumes that a measurement of the state of the environment is available at each time step without a cost. In applications such as deep-sea and planetary robot exploration, materials design and medicine, however, there can be a high cost associated with measuring, or even approximating, the state of the environment. In this paper, we survey the recently growing literature that adopts the perspective that an RL agent might not need, or even want, a costly measurement at each time step. Within this context, we propose the Deep Dynamic Multi-Step Observationless Agent (DMSOA), contrast it with the literature and empirically evaluate it on OpenAI gym and Atari Pong environments. Our results, show that DMSOA learns a better policy with fewer decision steps and measurements than the considered alternative from the literature.", "url": "https://arxiv.org/abs/2307.02620"}, {"metadata": {"arXiv": "2307.02631", "Date": "Wed, 05 Jul 2023 20:04:13 ", "Title": "An explainable model to support the decision about the therapy protocol for AML", "Authors": ["Jade M. Almeida", "Giovanna A. Castro", "Jo\\~ao A. Machado-Neto", "Tiago A. Almeida"], "Categories": "cs.LG cs.AI", "Comments": ["Preprint of the paper accepted at the 12th Brazilian Conference on Intelligent Systems (BRACIS'2023)"]}, "abstract": "Acute Myeloid Leukemia (AML) is one of the most aggressive types of hematological neoplasm. To support the specialists' decision about the appropriate therapy, patients with AML receive a prognostic of outcomes according to their cytogenetic and molecular characteristics, often divided into three risk categories: favorable, intermediate, and adverse. However, the current risk classification has known problems, such as the heterogeneity between patients of the same risk group and no clear definition of the intermediate risk category. Moreover, as most patients with AML receive an intermediate-risk classification, specialists often demand other tests and analyses, leading to delayed treatment and worsening of the patient's clinical condition. This paper presents the data analysis and an explainable machine-learning model to support the decision about the most appropriate therapy protocol according to the patient's survival prediction. In addition to the prediction model being explainable, the results obtained are promising and indicate that it is possible to use it to support the specialists' decisions safely. Most importantly, the findings offered in this study have the potential to open new avenues of research toward better treatments and prognostic markers.", "url": "https://arxiv.org/abs/2307.02631"}, {"metadata": {"arXiv": "2307.02694", "Date": "Wed, 05 Jul 2023 23:53:55 ", "Title": "Loss Functions and Metrics in Deep Learning. A Review", "Authors": ["Juan Terven", "Diana M. Cordova-Esparza", "Alfonzo Ramirez-Pedraza", "Edgar A. Chavez-Urbiola"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["53 pages", "5 figures", "7 tables", "86 equations"], "ACM-class": "I.4.0"}, "abstract": "One of the essential components of deep learning is the choice of the loss function and performance metrics used to train and evaluate models. This paper reviews the most prevalent loss functions and performance measurements in deep learning. We examine the benefits and limits of each technique and illustrate their application to various deep-learning problems. Our review aims to give a comprehensive picture of the different loss functions and performance indicators used in the most common deep learning tasks and help practitioners choose the best method for their specific task.", "url": "https://arxiv.org/abs/2307.02694"}, {"metadata": {"arXiv": "2307.02728", "Date": "Thu, 06 Jul 2023 02:27:05 ", "Title": "Hierarchical Empowerment: Towards Tractable Empowerment-Based Skill-Learning", "Authors": ["Andrew Levy", "Sreehari Rammohan", "Alessandro Allievi", "Scott Niekum", "George Konidaris"], "Categories": "cs.LG cs.AI cs.RO"}, "abstract": "General purpose agents will require large repertoires of skills. Empowerment -- the maximum mutual information between skills and the states -- provides a pathway for learning large collections of distinct skills, but mutual information is difficult to optimize. We introduce a new framework, Hierarchical Empowerment, that makes computing empowerment more tractable by integrating concepts from Goal-Conditioned Hierarchical Reinforcement Learning. Our framework makes two specific contributions. First, we introduce a new variational lower bound on mutual information that can be used to compute empowerment over short horizons. Second, we introduce a hierarchical architecture for computing empowerment over exponentially longer time scales. We verify the contributions of the framework in a series of simulated robotics tasks. In a popular ant navigation domain, our four level agents are able to learn skills that cover a surface area over two orders of magnitude larger than prior work.", "url": "https://arxiv.org/abs/2307.02728"}, {"metadata": {"arXiv": "2307.02752", "Date": "Thu, 06 Jul 2023 03:22:19 ", "Title": "Offline Reinforcement Learning with Imbalanced Datasets", "Authors": ["Li Jiang", "Sijie Chen", "Jielin Qiu", "Haoran Xu", "Wai Kin Chan", "Zhao Ding"], "Categories": "cs.LG cs.AI", "Journal-ref": "ICML 2023, workshop on Data-centric Machine Learning Research"}, "abstract": "The prevalent use of benchmarks in current offline reinforcement learning (RL) research has led to a neglect of the imbalance of real-world dataset distributions in the development of models. The real-world offline RL dataset is often imbalanced over the state space due to the challenge of exploration or safety considerations. In this paper, we specify properties of imbalanced datasets in offline RL, where the state coverage follows a power law distribution characterized by skewed policies. Theoretically and empirically, we show that typically offline RL methods based on distributional constraints, such as conservative Q-learning (CQL), are ineffective in extracting policies under the imbalanced dataset. Inspired by natural intelligence, we propose a novel offline RL method that utilizes the augmentation of CQL with a retrieval process to recall past related experiences, effectively alleviating the challenges posed by imbalanced datasets. We evaluate our method on several tasks in the context of imbalanced datasets with varying levels of imbalance, utilizing the variant of D4RL. Empirical results demonstrate the superiority of our method over other baselines.", "url": "https://arxiv.org/abs/2307.02752"}, {"metadata": {"arXiv": "2307.02891", "Date": "Thu, 06 Jul 2023 09:53:56 ", "Title": "BaBE: Enhancing Fairness via Estimation of Latent Explaining Variables", "Authors": ["Ruta Binkyte", "Daniele Gorla", "Catuscia Palamidessi"], "Categories": "cs.LG cs.AI cs.CY"}, "abstract": "We consider the problem of unfair discrimination between two groups and propose a pre-processing method to achieve fairness. Corrective methods like statistical parity usually lead to bad accuracy and do not really achieve fairness in situations where there is a correlation between the sensitive attribute S and the legitimate attribute E (explanatory variable) that should determine the decision. To overcome these drawbacks, other notions of fairness have been proposed, in particular, conditional statistical parity and equal opportunity. However, E is often not directly observable in the data, i.e., it is a latent variable. We may observe some other variable Z representing E, but the problem is that Z may also be affected by S, hence Z itself can be biased. To deal with this problem, we propose BaBE (Bayesian Bias Elimination), an approach based on a combination of Bayes inference and the Expectation-Maximization method, to estimate the most likely value of E for a given Z for each group. The decision can then be based directly on the estimated E. We show, by experiments on synthetic and real data sets, that our approach provides a good level of fairness as well as high accuracy.", "url": "https://arxiv.org/abs/2307.02891"}, {"metadata": {"arXiv": "2307.02984", "Date": "Thu, 06 Jul 2023 13:35:48 ", "Title": "A Privacy-Preserving Walk in the Latent Space of Generative Models for Medical Applications", "Authors": ["Matteo Pennisi", "Federica Proietto Salanitri", "Giovanni Bellitto", "Simone Palazzo", "Ulas Bagci", "Concetto Spampinato"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["Accepted at MICCAI 2023"]}, "abstract": "Generative Adversarial Networks (GANs) have demonstrated their ability to generate synthetic samples that match a target distribution. However, from a privacy perspective, using GANs as a proxy for data sharing is not a safe solution, as they tend to embed near-duplicates of real samples in the latent space. Recent works, inspired by k-anonymity principles, address this issue through sample aggregation in the latent space, with the drawback of reducing the dataset by a factor of k. Our work aims to mitigate this problem by proposing a latent space navigation strategy able to generate diverse synthetic samples that may support effective training of deep models, while addressing privacy concerns in a principled way. Our approach leverages an auxiliary identity classifier as a guide to non-linearly walk between points in the latent space, minimizing the risk of collision with near-duplicates of real samples. We empirically demonstrate that, given any random pair of points in the latent space, our walking strategy is safer than linear interpolation. We then test our path-finding strategy combined to k-same methods and demonstrate, on two benchmarks for tuberculosis and diabetic retinopathy classification, that training a model using samples generated by our approach mitigate drops in performance, while keeping privacy preservation.", "url": "https://arxiv.org/abs/2307.02984"}, {"metadata": {"arXiv": "2307.03056", "Date": "Thu, 06 Jul 2023 15:19:53 ", "Title": "Generalizing Backpropagation for Gradient-Based Interpretability", "Authors": ["Kevin Du", "Lucas Torroba Hennigen", "Niklas Stoehr", "Alexander Warstadt", "Ryan Cotterell"], "Categories": "cs.LG cs.AI", "Comments": ["Long paper accepted at ACL 2023"]}, "abstract": "Many popular feature-attribution methods for interpreting deep neural networks rely on computing the gradients of a model's output with respect to its inputs. While these methods can indicate which input features may be important for the model's prediction, they reveal little about the inner workings of the model itself. In this paper, we observe that the gradient computation of a model is a special case of a more general formulation using semirings. This observation allows us to generalize the backpropagation algorithm to efficiently compute other interpretable statistics about the gradient graph of a neural network, such as the highest-weighted path and entropy. We implement this generalized algorithm, evaluate it on synthetic datasets to better understand the statistics it computes, and apply it to study BERT's behavior on the subject-verb number agreement task (SVA). With this method, we (a) validate that the amount of gradient flow through a component of a model reflects its importance to a prediction and (b) for SVA, identify which pathways of the self-attention mechanism are most important.", "url": "https://arxiv.org/abs/2307.03056"}, {"metadata": {"arXiv": "2307.03084", "Date": "Wed, 05 Jul 2023 16:30:14 ", "Title": "OpenDelta: A Plug-and-play Library for Parameter-efficient Adaptation of Pre-trained Models", "Authors": ["Shengding Hu", "Ning Ding", "Weilin Zhao", "Xingtai Lv", "Zhen Zhang", "Zhiyuan Liu", "Maosong Sun"], "Categories": "cs.LG cs.AI cs.CL", "Comments": ["Accepted to ACL 2023 Demo track"]}, "abstract": "The scale of large pre-trained models (PTMs) poses significant challenges in adapting to downstream tasks due to the high optimization overhead and storage costs associated with full-parameter fine-tuning. To address this, many studies explore parameter-efficient tuning methods, also framed as \"delta tuning\", which updates only a small subset of parameters, known as \"delta modules\", while keeping the backbone model's parameters fixed. However, the practicality and flexibility of delta tuning have been limited due to existing implementations that directly modify the code of the backbone PTMs and hard-code specific delta tuning methods for each PTM. In this paper, we present OpenDelta, an open-source library that overcomes these limitations by providing a plug-and-play implementation of various delta tuning methods. Our novel techniques eliminate the need to modify the backbone PTMs' code, making OpenDelta compatible with different, even novel PTMs. OpenDelta is designed to be simple, modular, and extensible, providing a comprehensive platform for researchers and practitioners to adapt large PTMs efficiently.", "url": "https://arxiv.org/abs/2307.03084"}, {"metadata": {"arXiv": "2307.03175", "Date": "Thu, 06 Jul 2023 17:55:28 ", "Title": "Push Past Green: Learning to Look Behind Plant Foliage by Moving It", "Authors": ["Xiaoyu Zhang", "Saurabh Gupta"], "Categories": "cs.RO cs.AI cs.CV cs.LG", "Comments": ["for project website with video", "see https://sites.google.com/view/pushpastgreen/"]}, "abstract": "Autonomous agriculture applications (e.g., inspection, phenotyping, plucking fruits) require manipulating the plant foliage to look behind the leaves and the branches. Partial visibility, extreme clutter, thin structures, and unknown geometry and dynamics for plants make such manipulation challenging. We tackle these challenges through data-driven methods. We use self-supervision to train SRPNet, a neural network that predicts what space is revealed on execution of a candidate action on a given plant. We use SRPNet with the cross-entropy method to predict actions that are effective at revealing space beneath plant foliage. Furthermore, as SRPNet does not just predict how much space is revealed but also where it is revealed, we can execute a sequence of actions that incrementally reveal more and more space beneath the plant foliage. We experiment with a synthetic (vines) and a real plant (Dracaena) on a physical test-bed across 5 settings including 2 settings that test generalization to novel plant configurations. Our experiments reveal the effectiveness of our overall method, PPG, over a competitive hand-crafted exploration method, and the effectiveness of SRPNet over a hand-crafted dynamics model and relevant ablations.", "url": "https://arxiv.org/abs/2307.03175"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

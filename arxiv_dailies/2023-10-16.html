<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2310.08645", "Date": "Thu, 12 Oct 2023 18:10:36 ", "Title": "Defect Analysis of 3D Printed Cylinder Object Using Transfer Learning Approaches", "Authors": ["Md Manjurul Ahsan", "Shivakumar Raman and Zahed Siddique"], "Categories": "cs.CV cs.LG"}, "abstract": "Additive manufacturing (AM) is gaining attention across various industries like healthcare, aerospace, and automotive. However, identifying defects early in the AM process can reduce production costs and improve productivity - a key challenge. This study explored the effectiveness of machine learning (ML) approaches, specifically transfer learning (TL) models, for defect detection in 3D-printed cylinders. Images of cylinders were analyzed using models including VGG16, VGG19, ResNet50, ResNet101, InceptionResNetV2, and MobileNetV2. Performance was compared across two datasets using accuracy, precision, recall, and F1-score metrics. In the first study, VGG16, InceptionResNetV2, and MobileNetV2 achieved perfect scores. In contrast, ResNet50 had the lowest performance, with an average F1-score of 0.32. Similarly, in the second study, MobileNetV2 correctly classified all instances, while ResNet50 struggled with more false positives and fewer true positives, resulting in an F1-score of 0.75. Overall, the findings suggest certain TL models like MobileNetV2 can deliver high accuracy for AM defect classification, although performance varies across algorithms. The results provide insights into model optimization and integration needs for reliable automated defect analysis during 3D printing. By identifying the top-performing TL techniques, this study aims to enhance AM product quality through robust image-based monitoring and inspection.", "url": "https://arxiv.org/abs/2310.08645"}, {"metadata": {"arXiv": "2310.08854", "Date": "Fri, 13 Oct 2023 04:48:32 ", "Title": "Rank-DETR for High Quality Object Detection", "Authors": ["Yifan Pu", "Weicong Liang", "Yiduo Hao", "Yuhui Yuan", "Yukang Yang", "Chao Zhang", "Han Hu", "Gao Huang"], "Categories": "cs.CV cs.LG", "Comments": ["NeurIPS 2023"]}, "abstract": "Modern detection transformers (DETRs) use a set of object queries to predict a list of bounding boxes, sort them by their classification confidence scores, and select the top-ranked predictions as the final detection results for the given input image. A highly performant object detector requires accurate ranking for the bounding box predictions. For DETR-based detectors, the top-ranked bounding boxes suffer from less accurate localization quality due to the misalignment between classification scores and localization accuracy, thus impeding the construction of high-quality detectors. In this work, we introduce a simple and highly performant DETR-based object detector by proposing a series of rank-oriented designs, combinedly called Rank-DETR. Our key contributions include: (i) a rank-oriented architecture design that can prompt positive predictions and suppress the negative ones to ensure lower false positive rates, as well as (ii) a rank-oriented loss function and matching cost design that prioritizes predictions of more accurate localization accuracy during ranking to boost the AP under high IoU thresholds. We apply our method to improve the recent SOTA methods (e.g., H-DETR and DINO-DETR) and report strong COCO object detection results when using different backbones such as ResNet-$50$, Swin-T, and Swin-L, demonstrating the effectiveness of our approach. Code is available at \\url{https://github.com/LeapLabTHU/Rank-DETR}.", "url": "https://arxiv.org/abs/2310.08854"}, {"metadata": {"arXiv": "2310.09236", "Date": "Fri, 13 Oct 2023 16:40:29 ", "Title": "Time CNN and Graph Convolution Network for Epileptic Spike Detection in MEG Data", "Authors": ["Pauline Mouches", "Thibaut Dejean", "Julien Jung", "Romain Bouet", "Carole Lartizien", "Romain Quentin"], "Categories": "cs.CV cs.LG", "Comments": ["This work has been submitted to IEEE ISBI 2024 for possible publication"]}, "abstract": "Magnetoencephalography (MEG) recordings of patients with epilepsy exhibit spikes, a typical biomarker of the pathology. Detecting those spikes allows accurate localization of brain regions triggering seizures. Spike detection is often performed manually. However, it is a burdensome and error prone task due to the complexity of MEG data. To address this problem, we propose a 1D temporal convolutional neural network (Time CNN) coupled with a graph convolutional network (GCN) to classify short time frames of MEG recording as containing a spike or not. Compared to other recent approaches, our models have fewer parameters to train and we propose to use a GCN to account for MEG sensors spatial relationships. Our models produce clinically relevant results and outperform deep learning-based state-of-the-art methods reaching a classification f1-score of 76.7% on a balanced dataset and of 25.5% on a realistic, highly imbalanced dataset, for the spike class.", "url": "https://arxiv.org/abs/2310.09236"}, {"metadata": {"arXiv": "2310.09247", "Date": "Fri, 13 Oct 2023 16:53:25 ", "Title": "Hypernymy Understanding Evaluation of Text-to-Image Models via WordNet Hierarchy", "Authors": ["Anton Baryshnikov", "Max Ryabinin"], "Categories": "cs.CV cs.CL cs.LG"}, "abstract": "Text-to-image synthesis has recently attracted widespread attention due to rapidly improving quality and numerous practical applications. However, the language understanding capabilities of text-to-image models are still poorly understood, which makes it difficult to reason about prompt formulations that a given model would understand well. In this work, we measure the capability of popular text-to-image models to understand $\\textit{hypernymy}$, or the \"is-a\" relation between words. We design two automatic metrics based on the WordNet semantic hierarchy and existing image classifiers pretrained on ImageNet. These metrics both enable broad quantitative comparison of linguistic capabilities for text-to-image models and offer a way of finding fine-grained qualitative differences, such as words that are unknown to models and thus are difficult for them to draw. We comprehensively evaluate popular text-to-image models, including GLIDE, Latent Diffusion, and Stable Diffusion, showing how our metrics can provide a better understanding of the individual strengths and weaknesses of these models.", "url": "https://arxiv.org/abs/2310.09247"}, {"metadata": {"arXiv": "2310.08792", "Date": "Fri, 13 Oct 2023 00:34:12 ", "Title": "Incentive Mechanism Design for Distributed Ensemble Learning", "Authors": ["Chao Huang", "Pengchao Han", "Jianwei Huang"], "Categories": "cs.GT cs.LG", "Comments": ["Accepted to IEEE GLOBECOM 2023"]}, "abstract": "Distributed ensemble learning (DEL) involves training multiple models at distributed learners, and then combining their predictions to improve performance. Existing related studies focus on DEL algorithm design and optimization but ignore the important issue of incentives, without which self-interested learners may be unwilling to participate in DEL. We aim to fill this gap by presenting a first study on the incentive mechanism design for DEL. Our proposed mechanism specifies both the amount of training data and reward for learners with heterogeneous computation and communication costs. One design challenge is to have an accurate understanding regarding how learners' diversity (in terms of training data) affects the ensemble accuracy. To this end, we decompose the ensemble accuracy into a diversity-precision tradeoff to guide the mechanism design. Another challenge is that the mechanism design involves solving a mixed-integer program with a large search space. To this end, we propose an alternating algorithm that iteratively updates each learner's training data size and reward. We prove that under mild conditions, the algorithm converges. Numerical results using MNIST dataset show an interesting result: our proposed mechanism may prefer a lower level of learner diversity to achieve a higher ensemble accuracy.", "url": "https://arxiv.org/abs/2310.08792"}, {"metadata": {"arXiv": "2310.08620", "Date": "Thu, 12 Oct 2023 17:05:51 ", "Title": "Divorce Prediction with Machine Learning: Insights and LIME Interpretability", "Authors": ["Md Manjurul Ahsan"], "Categories": "cs.LG"}, "abstract": "Divorce is one of the most common social issues in developed countries like in the United States. Almost 50% of the recent marriages turn into an involuntary divorce or separation. While it is evident that people vary to a different extent, and even over time, an incident like Divorce does not interrupt the individual's daily activities; still, Divorce has a severe effect on the individual's mental health, and personal life. Within the scope of this research, the divorce prediction was carried out by evaluating a dataset named by the 'divorce predictor dataset' to correctly classify between married and Divorce people using six different machine learning algorithms- Logistic Regression (LR), Linear Discriminant Analysis (LDA), K-Nearest Neighbors (KNN), Classification and Regression Trees (CART), Gaussian Na\\\"ive Bayes (NB), and, Support Vector Machines (SVM). Preliminary computational results show that algorithms such as SVM, KNN, and LDA, can perform that task with an accuracy of 98.57%. This work's additional novel contribution is the detailed and comprehensive explanation of prediction probabilities using Local Interpretable Model-Agnostic Explanations (LIME). Utilizing LIME to analyze test results illustrates the possibility of differentiating between divorced and married couples. Finally, we have developed a divorce predictor app considering ten most important features that potentially affect couples in making decisions in their divorce, such tools can be used by any one in order to identify their relationship condition.", "url": "https://arxiv.org/abs/2310.08620"}, {"metadata": {"arXiv": "2310.08661", "Date": "Thu, 12 Oct 2023 18:39:24 ", "Title": "Counting and Algorithmic Generalization with Transformers", "Authors": ["Simon Ouellette", "Rolf Pfister", "Hansueli Jud"], "Categories": "cs.LG", "Comments": ["10 pages", "9 figures", "submitted to AAAI 2024"]}, "abstract": "Algorithmic generalization in machine learning refers to the ability to learn the underlying algorithm that generates data in a way that generalizes out-of-distribution. This is generally considered a difficult task for most machine learning algorithms. Here, we analyze algorithmic generalization when counting is required, either implicitly or explicitly. We show that standard Transformers are based on architectural decisions that hinder out-of-distribution performance for such tasks. In particular, we discuss the consequences of using layer normalization and of normalizing the attention weights via softmax. With ablation of the problematic operations, we demonstrate that a modified transformer can exhibit a good algorithmic generalization performance on counting while using a very lightweight architecture.", "url": "https://arxiv.org/abs/2310.08661"}, {"metadata": {"arXiv": "2310.08670", "Date": "Thu, 12 Oct 2023 19:07:58 ", "Title": "Every Parameter Matters: Ensuring the Convergence of Federated Learning with Dynamic Heterogeneous Models Reduction", "Authors": ["Hanhan Zhou", "Tian Lan", "Guru Venkataramani and Wenbo Ding"], "Categories": "cs.LG cs.DC", "Comments": ["Accepted at NeurIPS 2023. arXiv admin note: text overlap with arXiv:2201.11803"]}, "abstract": "Cross-device Federated Learning (FL) faces significant challenges where low-end clients that could potentially make unique contributions are excluded from training large models due to their resource bottlenecks. Recent research efforts have focused on model-heterogeneous FL, by extracting reduced-size models from the global model and applying them to local clients accordingly. Despite the empirical success, general theoretical guarantees of convergence on this method remain an open question. In this paper, we present a unifying framework for heterogeneous FL algorithms with online model extraction and provide a general convergence analysis. In particular, we prove that under certain sufficient conditions and for both IID and non-IID data, these algorithms converge to a stationary point of standard FL for general smooth cost functions. Moreover, we illuminate two key factors impacting its convergence: model-extraction noise and minimum coverage index, advocating a joint design of local model extraction for efficient heterogeneous FL.", "url": "https://arxiv.org/abs/2310.08670"}, {"metadata": {"arXiv": "2310.08685", "Date": "Thu, 12 Oct 2023 19:44:20 ", "Title": "Kernel-Elastic Autoencoder for Molecular Design", "Authors": ["Haote Li", "Yu Shee", "Brandon Allen", "Federica Maschietto", "Victor Batista"], "Categories": "cs.LG"}, "abstract": "We introduce the Kernel-Elastic Autoencoder (KAE), a self-supervised generative model based on the transformer architecture with enhanced performance for molecular design. KAE is formulated based on two novel loss functions: modified maximum mean discrepancy and weighted reconstruction. KAE addresses the long-standing challenge of achieving valid generation and accurate reconstruction at the same time. KAE achieves remarkable diversity in molecule generation while maintaining near-perfect reconstructions on the independent testing dataset, surpassing previous molecule-generating models. KAE enables conditional generation and allows for decoding based on beam search resulting in state-of-the-art performance in constrained optimizations. Furthermore, KAE can generate molecules conditional to favorable binding affinities in docking applications as confirmed by AutoDock Vina and Glide scores, outperforming all existing candidates from the training dataset. Beyond molecular design, we anticipate KAE could be applied to solve problems by generation in a wide range of applications.", "url": "https://arxiv.org/abs/2310.08685"}, {"metadata": {"arXiv": "2310.08708", "Date": "Thu, 12 Oct 2023 20:44:41 ", "Title": "Polynomial Time Cryptanalytic Extraction of Neural Network Models", "Authors": ["Adi Shamir", "Isaac Canales-Martinez", "Anna Hambitzer", "Jorge Chavez-Saab", "Francisco Rodrigez-Henriquez", "and Nitin Satpute"], "Categories": "cs.LG cs.CR"}, "abstract": "Billions of dollars and countless GPU hours are currently spent on training Deep Neural Networks (DNNs) for a variety of tasks. Thus, it is essential to determine the difficulty of extracting all the parameters of such neural networks when given access to their black-box implementations. Many versions of this problem have been studied over the last 30 years, and the best current attack on ReLU-based deep neural networks was presented at Crypto 2020 by Carlini, Jagielski, and Mironov. It resembles a differential chosen plaintext attack on a cryptosystem, which has a secret key embedded in its black-box implementation and requires a polynomial number of queries but an exponential amount of time (as a function of the number of neurons). In this paper, we improve this attack by developing several new techniques that enable us to extract with arbitrarily high precision all the real-valued parameters of a ReLU-based DNN using a polynomial number of queries and a polynomial amount of time. We demonstrate its practical efficiency by applying it to a full-sized neural network for classifying the CIFAR10 dataset, which has 3072 inputs, 8 hidden layers with 256 neurons each, and over million neuronal parameters. An attack following the approach by Carlini et al. requires an exhaustive search over 2 to the power 256 possibilities. Our attack replaces this with our new techniques, which require only 30 minutes on a 256-core computer.", "url": "https://arxiv.org/abs/2310.08708"}, {"metadata": {"arXiv": "2310.08725", "Date": "Thu, 12 Oct 2023 21:19:47 ", "Title": "Heterophily-Based Graph Neural Network for Imbalanced Classification", "Authors": ["Zirui Liang", "Yuntao Li", "Tianjin Huang", "Akrati Saxena", "Yulong Pei", "Mykola Pechenizkiy"], "Categories": "cs.LG", "Comments": ["Accepted by Twelfth International Conference on Complex Networks & Their Applications"]}, "abstract": "Graph neural networks (GNNs) have shown promise in addressing graph-related problems, including node classification. However, conventional GNNs assume an even distribution of data across classes, which is often not the case in real-world scenarios, where certain classes are severely underrepresented. This leads to suboptimal performance of standard GNNs on imbalanced graphs. In this paper, we introduce a unique approach that tackles imbalanced classification on graphs by considering graph heterophily. We investigate the intricate relationship between class imbalance and graph heterophily, revealing that minority classes not only exhibit a scarcity of samples but also manifest lower levels of homophily, facilitating the propagation of erroneous information among neighboring nodes. Drawing upon this insight, we propose an efficient method, called Fast Im-GBK, which integrates an imbalance classification strategy with heterophily-aware GNNs to effectively address the class imbalance problem while significantly reducing training time. Our experiments on real-world graphs demonstrate our model's superiority in classification performance and efficiency for node classification tasks compared to existing baselines.", "url": "https://arxiv.org/abs/2310.08725"}, {"metadata": {"arXiv": "2310.08732", "Date": "Thu, 12 Oct 2023 21:39:16 ", "Title": "Provably Robust Cost-Sensitive Learning via Randomized Smoothing", "Authors": ["Yuan Xin", "Michael Backes", "Xiao Zhang"], "Categories": "cs.LG cs.CR", "Comments": ["18 pages", "7 tables", "4 figures"]}, "abstract": "We focus on learning adversarially robust classifiers under a cost-sensitive scenario, where the potential harm of different classwise adversarial transformations is encoded in a binary cost matrix. Existing methods are either empirical that cannot certify robustness or suffer from inherent scalability issues. In this work, we study whether randomized smoothing, a more scalable robustness certification framework, can be leveraged to certify cost-sensitive robustness. Built upon a notion of cost-sensitive certified radius, we show how to adapt the standard randomized smoothing certification pipeline to produce tight robustness guarantees for any cost matrix. In addition, with fine-grained certified radius optimization schemes specifically designed for different data subgroups, we propose an algorithm to train smoothed classifiers that are optimized for cost-sensitive robustness. Extensive experiments on image benchmarks and a real-world medical dataset demonstrate the superiority of our method in achieving significantly improved performance of certified cost-sensitive robustness while having a negligible impact on overall accuracy.", "url": "https://arxiv.org/abs/2310.08732"}, {"metadata": {"arXiv": "2310.08738", "Date": "Thu, 12 Oct 2023 21:51:25 ", "Title": "Splicing Up Your Predictions with RNA Contrastive Learning", "Authors": ["Philip Fradkin", "Ruian Shi", "Bo Wang", "Brendan Frey", "Leo J. Lee"], "Categories": "cs.LG q-bio.GN"}, "abstract": "In the face of rapidly accumulating genomic data, our understanding of the RNA regulatory code remains incomplete. Recent self-supervised methods in other domains have demonstrated the ability to learn rules underlying the data-generating process such as sentence structure in language. Inspired by this, we extend contrastive learning techniques to genomic data by utilizing functional similarities between sequences generated through alternative splicing and gene duplication. Our novel dataset and contrastive objective enable the learning of generalized RNA isoform representations. We validate their utility on downstream tasks such as RNA half-life and mean ribosome load prediction. Our pre-training strategy yields competitive results using linear probing on both tasks, along with up to a two-fold increase in Pearson correlation in low-data conditions. Importantly, our exploration of the learned latent space reveals that our contrastive objective yields semantically meaningful representations, underscoring its potential as a valuable initialization technique for RNA property prediction.", "url": "https://arxiv.org/abs/2310.08738"}, {"metadata": {"arXiv": "2310.08746", "Date": "Thu, 12 Oct 2023 22:19:36 ", "Title": "Robustness to Multi-Modal Environment Uncertainty in MARL using Curriculum Learning", "Authors": ["Aakriti Agrawal", "Rohith Aralikatti", "Yanchao Sun", "Furong Huang"], "Categories": "cs.LG"}, "abstract": "Multi-agent reinforcement learning (MARL) plays a pivotal role in tackling real-world challenges. However, the seamless transition of trained policies from simulations to real-world requires it to be robust to various environmental uncertainties. Existing works focus on finding Nash Equilibrium or the optimal policy under uncertainty in one environment variable (i.e. action, state or reward). This is because a multi-agent system itself is highly complex and unstationary. However, in real-world situation uncertainty can occur in multiple environment variables simultaneously. This work is the first to formulate the generalised problem of robustness to multi-modal environment uncertainty in MARL. To this end, we propose a general robust training approach for multi-modal uncertainty based on curriculum learning techniques. We handle two distinct environmental uncertainty simultaneously and present extensive results across both cooperative and competitive MARL environments, demonstrating that our approach achieves state-of-the-art levels of robustness.", "url": "https://arxiv.org/abs/2310.08746"}, {"metadata": {"arXiv": "2310.08750", "Date": "Thu, 12 Oct 2023 22:30:15 ", "Title": "Search-Adaptor: Text Embedding Customization for Information Retrieval", "Authors": ["Jinsung Yoon", "Sercan O Arik", "Yanfei Chen", "Tomas Pfister"], "Categories": "cs.LG", "Comments": ["9 pages", "2 figures"]}, "abstract": "Text embeddings extracted by pre-trained Large Language Models (LLMs) have significant potential to improve information retrieval and search. Beyond the zero-shot setup in which they are being conventionally used, being able to take advantage of the information from the relevant query-corpus paired data has the power to further boost the LLM capabilities. In this paper, we propose a novel method, Search-Adaptor, for customizing LLMs for information retrieval in an efficient and robust way. Search-Adaptor modifies the original text embedding generated by pre-trained LLMs, and can be integrated with any LLM, including those only available via APIs. On multiple real-world English and multilingual retrieval datasets, we show consistent and significant performance benefits for Search-Adaptor -- e.g., more than 5.2% improvements over the Google Embedding APIs in nDCG@10 averaged over 13 BEIR datasets.", "url": "https://arxiv.org/abs/2310.08750"}, {"metadata": {"arXiv": "2310.08754", "Date": "Thu, 12 Oct 2023 22:44:19 ", "Title": "Tokenizer Choice For LLM Training: Negligible or Crucial?", "Authors": ["Mehdi Ali", "Michael Fromm", "Klaudia Thellmann", "Richard Rutmann", "Max L\\\"ubbering", "Johannes Leveling", "Katrin Klug", "Jan Ebert", "Niclas Doll", "Jasper Schulze Buschhoff", "Charvi Jain", "Alexander Arno Weber", "Lena Jurkschat", "Hammam Abdelwahab", "Chelsea John", "Pedro Ortiz Suarez", "Malte Ostendorff", "Samuel Weinbach", "Rafet Sifa", "Stefan Kesselheim", "Nicolas Flores-Herr"], "Categories": "cs.LG"}, "abstract": "The recent success of LLMs has been predominantly driven by curating the training dataset composition, scaling of model architectures and dataset sizes and advancements in pretraining objectives, leaving tokenizer influence as a blind spot. Shedding light on this underexplored area, we conduct a comprehensive study on the influence of tokenizer choice on LLM downstream performance by training 24 mono- and multilingual LLMs at a 2.6B parameter scale, ablating different tokenizer algorithms and parameterizations. Our studies highlight that the tokenizer choice can significantly impact the model's downstream performance, training and inference costs. In particular, we find that the common tokenizer evaluation metrics fertility and parity are not always predictive of model downstream performance, rendering these metrics a questionable choice for tokenizer evaluation. Furthermore, we show that multilingual tokenizers trained on the five most frequent European languages require vocabulary size increases of factor three in comparison to English. While English-only tokenizers have been applied to the training of multi-lingual LLMs in the past, we find that this approach results in a severe downstream performance degradation and additional training costs of up to 68%, due to an inefficient tokenization vocabulary.", "url": "https://arxiv.org/abs/2310.08754"}, {"metadata": {"arXiv": "2310.08757", "Date": "Thu, 12 Oct 2023 22:52:29 ", "Title": "Detection and prediction of clopidogrel treatment failures using longitudinal structured electronic health records", "Authors": ["Samuel Kim", "In Gu Sean Lee", "Mijeong Irene Ban", "Jane Chiang"], "Categories": "cs.LG"}, "abstract": "We propose machine learning algorithms to automatically detect and predict clopidogrel treatment failure using longitudinal structured electronic health records (EHR). By drawing analogies between natural language and structured EHR, we introduce various machine learning algorithms used in natural language processing (NLP) applications to build models for treatment failure detection and prediction. In this regard, we generated a cohort of patients with clopidogrel prescriptions from UK Biobank and annotated if the patients had treatment failure events within one year of the first clopidogrel prescription; out of 502,527 patients, 1,824 patients were identified as treatment failure cases, and 6,859 patients were considered as control cases. From the dataset, we gathered diagnoses, prescriptions, and procedure records together per patient and organized them into visits with the same date to build models. The models were built for two different tasks, i.e., detection and prediction, and the experimental results showed that time series models outperform bag-of-words approaches in both tasks. In particular, a Transformer-based model, namely BERT, could reach 0.928 AUC in detection tasks and 0.729 AUC in prediction tasks. BERT also showed competence over other time series models when there is not enough training data, because it leverages the pre-training procedure using large unlabeled data.", "url": "https://arxiv.org/abs/2310.08757"}, {"metadata": {"arXiv": "2310.08759", "Date": "Thu, 12 Oct 2023 22:56:53 ", "Title": "Question Answering for Electronic Health Records: A Scoping Review of datasets and models", "Authors": ["Jayetri Bardhan", "Kirk Roberts", "Daisy Zhe Wang"], "Categories": "cs.LG cs.IR", "Comments": ["5 tables", "6 figures"]}, "abstract": "Question Answering (QA) systems on patient-related data can assist both clinicians and patients. They can, for example, assist clinicians in decision-making and enable patients to have a better understanding of their medical history. Significant amounts of patient data are stored in Electronic Health Records (EHRs), making EHR QA an important research area. In EHR QA, the answer is obtained from the medical record of the patient. Because of the differences in data format and modality, this differs greatly from other medical QA tasks that employ medical websites or scientific papers to retrieve answers, making it critical to research EHR question answering. This study aimed to provide a methodological review of existing works on QA over EHRs. We searched for articles from January 1st, 2005 to September 30th, 2023 in four digital sources including Google Scholar, ACL Anthology, ACM Digital Library, and PubMed to collect relevant publications on EHR QA. 4111 papers were identified for our study, and after screening based on our inclusion criteria, we obtained a total of 47 papers for further study. Out of the 47 papers, 25 papers were about EHR QA datasets, and 37 papers were about EHR QA models. It was observed that QA on EHRs is relatively new and unexplored. Most of the works are fairly recent. Also, it was observed that emrQA is by far the most popular EHR QA dataset, both in terms of citations and usage in other papers. Furthermore, we identified the different models used in EHR QA along with the evaluation metrics used for these models.", "url": "https://arxiv.org/abs/2310.08759"}, {"metadata": {"arXiv": "2310.08775", "Date": "Thu, 12 Oct 2023 23:47:22 ", "Title": "When Machine Learning Models Leak: An Exploration of Synthetic Training Data", "Authors": ["Manel Slokom and Peter-Paul de Wolf and Martha Larson"], "Categories": "cs.LG"}, "abstract": "We investigate an attack on a machine learning model that predicts whether a person or household will relocate in the next two years, i.e., a propensity-to-move classifier. The attack assumes that the attacker can query the model to obtain predictions and that the marginal distribution of the data on which the model was trained is publicly available. The attack also assumes that the attacker has obtained the values of non-sensitive attributes for a certain number of target individuals. The objective of the attack is to infer the values of sensitive attributes for these target individuals. We explore how replacing the original data with synthetic data when training the model impacts how successfully the attacker can infer sensitive attributes.\\footnote{Original paper published at PSD 2022. The paper was subsequently updated.}", "url": "https://arxiv.org/abs/2310.08775"}, {"metadata": {"arXiv": "2310.08793", "Date": "Fri, 13 Oct 2023 00:46:12 ", "Title": "Analysis of Weather and Time Features in Machine Learning-aided ERCOT Load Forecasting", "Authors": ["Jonathan Yang", "Mingjian Tuo", "Jin Lu", "Xingpeng Li"], "Categories": "cs.LG cs.SY eess.SY"}, "abstract": "Accurate load forecasting is critical for efficient and reliable operations of the electric power system. A large part of electricity consumption is affected by weather conditions, making weather information an important determinant of electricity usage. Personal appliances and industry equipment also contribute significantly to electricity demand with temporal patterns, making time a useful factor to consider in load forecasting. This work develops several machine learning (ML) models that take various time and weather information as part of the input features to predict the short-term system-wide total load. Ablation studies were also performed to investigate and compare the impacts of different weather factors on the prediction accuracy. Actual load and historical weather data for the same region were processed and then used to train the ML models. It is interesting to observe that using all available features, each of which may be correlated to the load, is unlikely to achieve the best forecasting performance; features with redundancy may even decrease the inference capabilities of ML models. This indicates the importance of feature selection for ML models. Overall, case studies demonstrated the effectiveness of ML models trained with different weather and time input features for ERCOT load forecasting.", "url": "https://arxiv.org/abs/2310.08793"}, {"metadata": {"arXiv": "2310.08833", "Date": "Fri, 13 Oct 2023 03:08:59 ", "Title": "Optimal Sample Complexity for Average Reward Markov Decision Processes", "Authors": ["Shengbo Wang", "Jose Blanchet", "and Peter Glynn"], "Categories": "cs.LG math.OC stat.ML"}, "abstract": "We settle the sample complexity of policy learning for the maximization of the long run average reward associated with a uniformly ergodic Markov decision process (MDP), assuming a generative model. In this context, the existing literature provides a sample complexity upper bound of $\\widetilde O(|S||A|t_{\\text{mix}}^2 \\epsilon^{-2})$ and a lower bound of $\\Omega(|S||A|t_{\\text{mix}} \\epsilon^{-2})$. In these expressions, $|S|$ and $|A|$ denote the cardinalities of the state and action spaces respectively, $t_{\\text{mix}}$ serves as a uniform upper limit for the total variation mixing times, and $\\epsilon$ signifies the error tolerance. Therefore, a notable gap of $t_{\\text{mix}}$ still remains to be bridged. Our primary contribution is to establish an estimator for the optimal policy of average reward MDPs with a sample complexity of $\\widetilde O(|S||A|t_{\\text{mix}}\\epsilon^{-2})$, effectively reaching the lower bound in the literature. This is achieved by combining algorithmic ideas in Jin and Sidford (2021) with those of Li et al. (2020).", "url": "https://arxiv.org/abs/2310.08833"}, {"metadata": {"arXiv": "2310.08847", "Date": "Fri, 13 Oct 2023 04:14:51 ", "Title": "On the Over-Memorization During Natural, Robust and Catastrophic Overfitting", "Authors": ["Runqi Lin", "Chaojian Yu", "Bo Han", "Tongliang Liu"], "Categories": "cs.LG"}, "abstract": "Overfitting negatively impacts the generalization ability of deep neural networks (DNNs) in both natural and adversarial training. Existing methods struggle to consistently address different types of overfitting, typically designing strategies that focus separately on either natural or adversarial patterns. In this work, we adopt a unified perspective by solely focusing on natural patterns to explore different types of overfitting. Specifically, we examine the memorization effect in DNNs and reveal a shared behaviour termed over-memorization, which impairs their generalization capacity. This behaviour manifests as DNNs suddenly becoming high-confidence in predicting certain training patterns and retaining a persistent memory for them. Furthermore, when DNNs over-memorize an adversarial pattern, they tend to simultaneously exhibit high-confidence prediction for the corresponding natural pattern. These findings motivate us to holistically mitigate different types of overfitting by hindering the DNNs from over-memorization natural patterns. To this end, we propose a general framework, Distraction Over-Memorization (DOM), which explicitly prevents over-memorization by either removing or augmenting the high-confidence natural patterns. Extensive experiments demonstrate the effectiveness of our proposed method in mitigating overfitting across various training paradigms.", "url": "https://arxiv.org/abs/2310.08847"}, {"metadata": {"arXiv": "2310.08848", "Date": "Fri, 13 Oct 2023 04:22:21 ", "Title": "Semi-Supervised End-To-End Contrastive Learning For Time Series Classification", "Authors": ["Huili Cai", "Xiang Zhang and Xiaofeng Liu"], "Categories": "cs.LG", "Comments": ["Submitted to NeurIPS 2023"]}, "abstract": "Time series classification is a critical task in various domains, such as finance, healthcare, and sensor data analysis. Unsupervised contrastive learning has garnered significant interest in learning effective representations from time series data with limited labels. The prevalent approach in existing contrastive learning methods consists of two separate stages: pre-training the encoder on unlabeled datasets and fine-tuning the well-trained model on a small-scale labeled dataset. However, such two-stage approaches suffer from several shortcomings, such as the inability of unsupervised pre-training contrastive loss to directly affect downstream fine-tuning classifiers, and the lack of exploiting the classification loss which is guided by valuable ground truth. In this paper, we propose an end-to-end model called SLOTS (Semi-supervised Learning fOr Time clasSification). SLOTS receives semi-labeled datasets, comprising a large number of unlabeled samples and a small proportion of labeled samples, and maps them to an embedding space through an encoder. We calculate not only the unsupervised contrastive loss but also measure the supervised contrastive loss on the samples with ground truth. The learned embeddings are fed into a classifier, and the classification loss is calculated using the available true labels. The unsupervised, supervised contrastive losses and classification loss are jointly used to optimize the encoder and classifier. We evaluate SLOTS by comparing it with ten state-of-the-art methods across five datasets. The results demonstrate that SLOTS is a simple yet effective framework. When compared to the two-stage framework, our end-to-end SLOTS utilizes the same input data, consumes a similar computational cost, but delivers significantly improved performance. We release code and datasets at https://anonymous.4open.science/r/SLOTS-242E.", "url": "https://arxiv.org/abs/2310.08848"}, {"metadata": {"arXiv": "2310.08855", "Date": "Fri, 13 Oct 2023 04:50:40 ", "Title": "Overcoming Recency Bias of Normalization Statistics in Continual Learning: Balance and Adaptation", "Authors": ["Yilin Lyu", "Liyuan Wang", "Xingxing Zhang", "Zicheng Sun", "Hang Su", "Jun Zhu", "Liping Jing"], "Categories": "cs.LG", "Comments": ["Accepted by NeurIPS 2023"]}, "abstract": "Continual learning entails learning a sequence of tasks and balancing their knowledge appropriately. With limited access to old training samples, much of the current work in deep neural networks has focused on overcoming catastrophic forgetting of old tasks in gradient-based optimization. However, the normalization layers provide an exception, as they are updated interdependently by the gradient and statistics of currently observed training samples, which require specialized strategies to mitigate recency bias. In this work, we focus on the most popular Batch Normalization (BN) and provide an in-depth theoretical analysis of its sub-optimality in continual learning. Our analysis demonstrates the dilemma between balance and adaptation of BN statistics for incremental tasks, which potentially affects training stability and generalization. Targeting on these particular challenges, we propose Adaptive Balance of BN (AdaB$^2$N), which incorporates appropriately a Bayesian-based strategy to adapt task-wise contributions and a modified momentum to balance BN statistics, corresponding to the training and testing stages. By implementing BN in a continual learning fashion, our approach achieves significant performance gains across a wide range of benchmarks, particularly for the challenging yet realistic online scenarios (e.g., up to 7.68%, 6.86% and 4.26% on Split CIFAR-10, Split CIFAR-100 and Split Mini-ImageNet, respectively). Our code is available at https://github.com/lvyilin/AdaB2N.", "url": "https://arxiv.org/abs/2310.08855"}, {"metadata": {"arXiv": "2310.08863", "Date": "Fri, 13 Oct 2023 05:12:48 ", "Title": "In-Context Learning for Few-Shot Molecular Property Prediction", "Authors": ["Christopher Fifty", "Jure Leskovec", "Sebastian Thrun"], "Categories": "cs.LG"}, "abstract": "In-context learning has become an important approach for few-shot learning in Large Language Models because of its ability to rapidly adapt to new tasks without fine-tuning model parameters. However, it is restricted to applications in natural language and inapplicable to other domains. In this paper, we adapt the concepts underpinning in-context learning to develop a new algorithm for few-shot molecular property prediction. Our approach learns to predict molecular properties from a context of (molecule, property measurement) pairs and rapidly adapts to new properties without fine-tuning. On the FS-Mol and BACE molecular property prediction benchmarks, we find this method surpasses the performance of recent meta-learning algorithms at small support sizes and is competitive with the best methods at large support sizes.", "url": "https://arxiv.org/abs/2310.08863"}, {"metadata": {"arXiv": "2310.08867", "Date": "Fri, 13 Oct 2023 05:35:13 ", "Title": "A Survey of Methods for Handling Disk Data Imbalance", "Authors": ["Shuangshuang Yuan", "Peng Wu", "Yuehui Chen and Qiang Li"], "Categories": "cs.LG stat.ME"}, "abstract": "Class imbalance exists in many classification problems, and since the data is designed for accuracy, imbalance in data classes can lead to classification challenges with a few classes having higher misclassification costs. The Backblaze dataset, a widely used dataset related to hard discs, has a small amount of failure data and a large amount of health data, which exhibits a serious class imbalance. This paper provides a comprehensive overview of research in the field of imbalanced data classification. The discussion is organized into three main aspects: data-level methods, algorithmic-level methods, and hybrid methods. For each type of method, we summarize and analyze the existing problems, algorithmic ideas, strengths, and weaknesses. Additionally, the challenges of unbalanced data classification are discussed, along with strategies to address them. It is convenient for researchers to choose the appropriate method according to their needs.", "url": "https://arxiv.org/abs/2310.08867"}, {"metadata": {"arXiv": "2310.08876", "Date": "Fri, 13 Oct 2023 06:03:07 ", "Title": "Gesture Recognition for FMCW Radar on the Edge", "Authors": ["Maximilian Strobel", "Stephan Schoenfeldt", "Jonas Daugalas"], "Categories": "cs.LG eess.SP", "Comments": ["4 pages", "5 figures", "submitted to 2024 IEEE Topical Conference on Wireless Sensors and Sensor Networks (WiSNeT)"]}, "abstract": "This paper introduces a lightweight gesture recognition system based on 60 GHz frequency modulated continuous wave (FMCW) radar. We show that gestures can be characterized efficiently by a set of five features, and propose a slim radar processing algorithm to extract these features. In contrast to previous approaches, we avoid heavy 2D processing, i.e. range-Doppler imaging, and perform instead an early target detection - this allows us to port the system to fully embedded platforms with tight constraints on memory, compute and power consumption. A recurrent neural network (RNN) based architecture exploits these features to jointly detect and classify five different gestures. The proposed system recognizes gestures with an F1 score of 98.4% on our hold-out test dataset, it runs on an Arm Cortex-M4 microcontroller requiring less than 280 kB of flash memory, 120 kB of RAM, and consuming 75 mW of power.", "url": "https://arxiv.org/abs/2310.08876"}, {"metadata": {"arXiv": "2310.08891", "Date": "Fri, 13 Oct 2023 06:53:02 ", "Title": "EHI: End-to-end Learning of Hierarchical Index for Efficient Dense Retrieval", "Authors": ["Ramnath Kumar and Anshul Mittal and Nilesh Gupta and Aditya Kusupati and Inderjit Dhillon and Prateek Jain"], "Categories": "cs.LG cs.IR"}, "abstract": "Dense embedding-based retrieval is now the industry standard for semantic search and ranking problems, like obtaining relevant web documents for a given query. Such techniques use a two-stage process: (a) contrastive learning to train a dual encoder to embed both the query and documents and (b) approximate nearest neighbor search (ANNS) for finding similar documents for a given query. These two stages are disjoint; the learned embeddings might be ill-suited for the ANNS method and vice-versa, leading to suboptimal performance. In this work, we propose End-to-end Hierarchical Indexing -- EHI -- that jointly learns both the embeddings and the ANNS structure to optimize retrieval performance. EHI uses a standard dual encoder model for embedding queries and documents while learning an inverted file index (IVF) style tree structure for efficient ANNS. To ensure stable and efficient learning of discrete tree-based ANNS structure, EHI introduces the notion of dense path embedding that captures the position of a query/document in the tree. We demonstrate the effectiveness of EHI on several benchmarks, including de-facto industry standard MS MARCO (Dev set and TREC DL19) datasets. For example, with the same compute budget, EHI outperforms state-of-the-art (SOTA) in by 0.6% (MRR@10) on MS MARCO dev set and by 4.2% (nDCG@10) on TREC DL19 benchmarks.", "url": "https://arxiv.org/abs/2310.08891"}, {"metadata": {"arXiv": "2310.08910", "Date": "Fri, 13 Oct 2023 07:31:04 ", "Title": "Scalarization for Multi-Task and Multi-Domain Learning at Scale", "Authors": ["Amelie Royer", "Tijmen Blankevoort", "Babak Ehteshami Bejnordi"], "Categories": "cs.LG cs.CV", "Comments": ["NeurIPS 2023; https://openreview.net/forum?id=TSuq3debnD"]}, "abstract": "Training a single model on multiple input domains and/or output tasks allows for compressing information from multiple sources into a unified backbone hence improves model efficiency. It also enables potential positive knowledge transfer across tasks/domains, leading to improved accuracy and data-efficient training. However, optimizing such networks is a challenge, in particular due to discrepancies between the different tasks or domains: Despite several hypotheses and solutions proposed over the years, recent work has shown that uniform scalarization training, i.e., simply minimizing the average of the task losses, yields on-par performance with more costly SotA optimization methods. This raises the issue of how well we understand the training dynamics of multi-task and multi-domain networks. In this work, we first devise a large-scale unified analysis of multi-domain and multi-task learning to better understand the dynamics of scalarization across varied task/domain combinations and model sizes. Following these insights, we then propose to leverage population-based training to efficiently search for the optimal scalarization weights when dealing with a large number of tasks or domains.", "url": "https://arxiv.org/abs/2310.08910"}, {"metadata": {"arXiv": "2310.08922", "Date": "Fri, 13 Oct 2023 07:47:44 ", "Title": "LLaMA Rider: Spurring Large Language Models to Explore the Open World", "Authors": ["Yicheng Feng", "Yuxuan Wang", "Jiazheng Liu", "Sipeng Zheng", "and Zongqing Lu"], "Categories": "cs.LG", "Comments": ["18 pages"]}, "abstract": "Recently, various studies have leveraged Large Language Models (LLMs) to help decision-making and planning in environments, and try to align the LLMs' knowledge with the world conditions. Nonetheless, the capacity of LLMs to continuously acquire environmental knowledge and adapt in an open world remains uncertain. In this paper, we propose an approach to spur LLMs to explore the open world, gather experiences, and learn to improve their task-solving capabilities. In this approach, a multi-round feedback-revision mechanism is utilized to encourage LLMs to actively select appropriate revision actions guided by feedback information from the environment. This facilitates exploration and enhances the model's performance. Besides, we integrate sub-task relabeling to assist LLMs in maintaining consistency in sub-task planning and help the model learn the combinatorial nature between tasks, enabling it to complete a wider range of tasks through training based on the acquired exploration experiences. By evaluation in Minecraft, an open-ended sandbox world, we demonstrate that our approach LLaMA-Rider enhances the efficiency of the LLM in exploring the environment, and effectively improves the LLM's ability to accomplish more tasks through fine-tuning with merely 1.3k instances of collected data, showing minimal training costs compared to the baseline using reinforcement learning.", "url": "https://arxiv.org/abs/2310.08922"}, {"metadata": {"arXiv": "2310.08961", "Date": "Fri, 13 Oct 2023 09:11:35 ", "Title": "PAGE: Equilibrate Personalization and Generalization in Federated Learning", "Authors": ["Qian Chen", "Zilong Wang", "Jiaqi Hu", "Haonan Yan", "Jianying Zhou", "Xiaodong Lin"], "Categories": "cs.LG"}, "abstract": "Federated learning (FL) is becoming a major driving force behind machine learning as a service, where customers (clients) collaboratively benefit from shared local updates under the orchestration of the service provider (server). Representing clients' current demands and the server's future demand, local model personalization and global model generalization are separately investigated, as the ill-effects of data heterogeneity enforce the community to focus on one over the other. However, these two seemingly competing goals are of equal importance rather than black and white issues, and should be achieved simultaneously. In this paper, we propose the first algorithm to balance personalization and generalization on top of game theory, dubbed PAGE, which reshapes FL as a co-opetition game between clients and the server. To explore the equilibrium, PAGE further formulates the game as Markov decision processes, and leverages the reinforcement learning algorithm, which simplifies the solving complexity. Extensive experiments on four widespread datasets show that PAGE outperforms state-of-the-art FL baselines in terms of global and local prediction accuracy simultaneously, and the accuracy can be improved by up to 35.20% and 39.91%, respectively. In addition, biased variants of PAGE imply promising adaptiveness to demand shifts in practice.", "url": "https://arxiv.org/abs/2310.08961"}, {"metadata": {"arXiv": "2310.09000", "Date": "Fri, 13 Oct 2023 10:37:46 ", "Title": "Measuring the Stability of Process Outcome Predictions in Online Settings", "Authors": ["Suhwan Lee", "Marco Comuzzi", "Xixi Lu", "Hajo A. Reijers"], "Categories": "cs.LG cs.DB", "Comments": ["8 pages", "3 figures", "Proceedings of the 5th International Conference on Process Mining (ICPM 2023)"]}, "abstract": "Predictive Process Monitoring aims to forecast the future progress of process instances using historical event data. As predictive process monitoring is increasingly applied in online settings to enable timely interventions, evaluating the performance of the underlying models becomes crucial for ensuring their consistency and reliability over time. This is especially important in high risk business scenarios where incorrect predictions may have severe consequences. However, predictive models are currently usually evaluated using a single, aggregated value or a time-series visualization, which makes it challenging to assess their performance and, specifically, their stability over time. This paper proposes an evaluation framework for assessing the stability of models for online predictive process monitoring. The framework introduces four performance meta-measures: the frequency of significant performance drops, the magnitude of such drops, the recovery rate, and the volatility of performance. To validate this framework, we applied it to two artificial and two real-world event logs. The results demonstrate that these meta-measures facilitate the comparison and selection of predictive models for different risk-taking scenarios. Such insights are of particular value to enhance decision-making in dynamic business environments.", "url": "https://arxiv.org/abs/2310.09000"}, {"metadata": {"arXiv": "2310.09002", "Date": "Fri, 13 Oct 2023 10:48:28 ", "Title": "Federated Meta-Learning for Few-Shot Fault Diagnosis with Representation Encoding", "Authors": ["Jixuan Cui", "Jun Li", "Zhen Mei", "Kang Wei", "Sha Wei", "Ming Ding", "Wen Chen", "Song Guo"], "Categories": "cs.LG"}, "abstract": "Deep learning-based fault diagnosis (FD) approaches require a large amount of training data, which are difficult to obtain since they are located across different entities. Federated learning (FL) enables multiple clients to collaboratively train a shared model with data privacy guaranteed. However, the domain discrepancy and data scarcity problems among clients deteriorate the performance of the global FL model. To tackle these issues, we propose a novel framework called representation encoding-based federated meta-learning (REFML) for few-shot FD. First, a novel training strategy based on representation encoding and meta-learning is developed. It harnesses the inherent heterogeneity among training clients, effectively transforming it into an advantage for out-of-distribution generalization on unseen working conditions or equipment types. Additionally, an adaptive interpolation method that calculates the optimal combination of local and global models as the initialization of local training is proposed. This helps to further utilize local information to mitigate the negative effects of domain discrepancy. As a result, high diagnostic accuracy can be achieved on unseen working conditions or equipment types with limited training data. Compared with the state-of-the-art methods, such as FedProx, the proposed REFML framework achieves an increase in accuracy by 2.17%-6.50% when tested on unseen working conditions of the same equipment type and 13.44%-18.33% when tested on totally unseen equipment types, respectively.", "url": "https://arxiv.org/abs/2310.09002"}, {"metadata": {"arXiv": "2310.09031", "Date": "Fri, 13 Oct 2023 11:47:41 ", "Title": "MINDE: Mutual Information Neural Diffusion Estimation", "Authors": ["Giulio Franzese", "Mustapha Bounoua", "Pietro Michiardi"], "Categories": "cs.LG stat.ML"}, "abstract": "In this work we present a new method for the estimation of Mutual Information (MI) between random variables. Our approach is based on an original interpretation of the Girsanov theorem, which allows us to use score-based diffusion models to estimate the Kullback Leibler divergence between two densities as a difference between their score functions. As a by-product, our method also enables the estimation of the entropy of random variables. Armed with such building blocks, we present a general recipe to measure MI, which unfolds in two directions: one uses conditional diffusion process, whereas the other uses joint diffusion processes that allow simultaneous modelling of two random variables. Our results, which derive from a thorough experimental protocol over all the variants of our approach, indicate that our method is more accurate than the main alternatives from the literature, especially for challenging distributions. Furthermore, our methods pass MI self-consistency tests, including data processing and additivity under independence, which instead are a pain-point of existing methods.", "url": "https://arxiv.org/abs/2310.09031"}, {"metadata": {"arXiv": "2310.09071", "Date": "Fri, 13 Oct 2023 12:45:52 ", "Title": "Online Relocating and Matching of Ride-Hailing Services: A Model-Based Modular Approach", "Authors": ["Chang Gao", "Xi Lin", "Fang He", "Xindi Tang"], "Categories": "cs.LG cs.SY eess.SY"}, "abstract": "This study proposes an innovative model-based modular approach (MMA) to dynamically optimize order matching and vehicle relocation in a ride-hailing platform. MMA utilizes a two-layer and modular modeling structure. The upper layer determines the spatial transfer patterns of vehicle flow within the system to maximize the total revenue of the current and future stages. With the guidance provided by the upper layer, the lower layer performs rapid vehicle-to-order matching and vehicle relocation. MMA is interpretable, and equipped with the customized and polynomial-time algorithm, which, as an online order-matching and vehicle-relocation algorithm, can scale past thousands of vehicles. We theoretically prove that the proposed algorithm can achieve the global optimum in stylized networks, while the numerical experiments based on both the toy network and realistic dataset demonstrate that MMA is capable of achieving superior systematic performance compared to batch matching and reinforcement-learning based methods. Moreover, its modular and lightweight modeling structure further enables it to achieve a high level of robustness against demand variation while maintaining a relatively low computational cost.", "url": "https://arxiv.org/abs/2310.09071"}, {"metadata": {"arXiv": "2310.09118", "Date": "Fri, 13 Oct 2023 14:03:01 ", "Title": "DSG: An End-to-End Document Structure Generator", "Authors": ["Johannes Rausch and Gentiana Rashiti and Maxim Gusev and Ce Zhang and Stefan Feuerriegel"], "Categories": "cs.LG cs.CV", "Comments": ["Accepted at ICDM 2023"]}, "abstract": "Information in industry, research, and the public sector is widely stored as rendered documents (e.g., PDF files, scans). Hence, to enable downstream tasks, systems are needed that map rendered documents onto a structured hierarchical format. However, existing systems for this task are limited by heuristics and are not end-to-end trainable. In this work, we introduce the Document Structure Generator (DSG), a novel system for document parsing that is fully end-to-end trainable. DSG combines a deep neural network for parsing (i) entities in documents (e.g., figures, text blocks, headers, etc.) and (ii) relations that capture the sequence and nested structure between entities. Unlike existing systems that rely on heuristics, our DSG is trained end-to-end, making it effective and flexible for real-world applications. We further contribute a new, large-scale dataset called E-Periodica comprising real-world magazines with complex document structures for evaluation. Our results demonstrate that our DSG outperforms commercial OCR tools and, on top of that, achieves state-of-the-art performance. To the best of our knowledge, our DSG system is the first end-to-end trainable system for hierarchical document parsing.", "url": "https://arxiv.org/abs/2310.09118"}, {"metadata": {"arXiv": "2310.09127", "Date": "Fri, 13 Oct 2023 14:15:54 ", "Title": "On Generalization Bounds for Projective Clustering", "Authors": ["Maria Sofia Bucarelli", "Matilde Fjelds{\\o} Larsen", "Chris Schwiegelshohn", "Mads Bech Toftrup"], "Categories": "cs.LG"}, "abstract": "Given a set of points, clustering consists of finding a partition of a point set into $k$ clusters such that the center to which a point is assigned is as close as possible. Most commonly, centers are points themselves, which leads to the famous $k$-median and $k$-means objectives. One may also choose centers to be $j$ dimensional subspaces, which gives rise to subspace clustering. In this paper, we consider learning bounds for these problems. That is, given a set of $n$ samples $P$ drawn independently from some unknown, but fixed distribution $\\mathcal{D}$, how quickly does a solution computed on $P$ converge to the optimal clustering of $\\mathcal{D}$? We give several near optimal results. In particular, For center-based objectives, we show a convergence rate of $\\tilde{O}\\left(\\sqrt{{k}/{n}}\\right)$. This matches the known optimal bounds of [Fefferman, Mitter, and Narayanan, Journal of the Mathematical Society 2016] and [Bartlett, Linder, and Lugosi, IEEE Trans. Inf. Theory 1998] for $k$-means and extends it to other important objectives such as $k$-median. For subspace clustering with $j$-dimensional subspaces, we show a convergence rate of $\\tilde{O}\\left(\\sqrt{\\frac{kj^2}{n}}\\right)$. These are the first provable bounds for most of these problems. For the specific case of projective clustering, which generalizes $k$-means, we show a convergence rate of $\\Omega\\left(\\sqrt{\\frac{kj}{n}}\\right)$ is necessary, thereby proving that the bounds from [Fefferman, Mitter, and Narayanan, Journal of the Mathematical Society 2016] are essentially optimal.", "url": "https://arxiv.org/abs/2310.09127"}, {"metadata": {"arXiv": "2310.09129", "Date": "Fri, 13 Oct 2023 14:17:25 ", "Title": "Computing Marginal and Conditional Divergences between Decomposable Models with Applications", "Authors": ["Loong Kuan Lee", "Geoffrey I. Webb", "Daniel F. Schmidt", "Nico Piatkowski"], "Categories": "cs.LG", "Comments": ["10 pages", "8 figures", "Accepted at the IEEE International Conference on Data Mining (ICDM) 2023"]}, "abstract": "The ability to compute the exact divergence between two high-dimensional distributions is useful in many applications but doing so naively is intractable. Computing the alpha-beta divergence -- a family of divergences that includes the Kullback-Leibler divergence and Hellinger distance -- between the joint distribution of two decomposable models, i.e chordal Markov networks, can be done in time exponential in the treewidth of these models. However, reducing the dissimilarity between two high-dimensional objects to a single scalar value can be uninformative. Furthermore, in applications such as supervised learning, the divergence over a conditional distribution might be of more interest. Therefore, we propose an approach to compute the exact alpha-beta divergence between any marginal or conditional distribution of two decomposable models. Doing so tractably is non-trivial as we need to decompose the divergence between these distributions and therefore, require a decomposition over the marginal and conditional distributions of these models. Consequently, we provide such a decomposition and also extend existing work to compute the marginal and conditional alpha-beta divergence between these decompositions. We then show how our method can be used to analyze distributional changes by first applying it to a benchmark image dataset. Finally, based on our framework, we propose a novel way to quantify the error in contemporary superconducting quantum computers. Code for all experiments is available at: https://lklee.dev/pub/2023-icdm/code", "url": "https://arxiv.org/abs/2310.09129"}, {"metadata": {"arXiv": "2310.09144", "Date": "Fri, 13 Oct 2023 14:35:59 ", "Title": "Goodhart's Law in Reinforcement Learning", "Authors": ["Jacek Karwowski", "Oliver Hayman", "Xingjian Bai", "Klaus Kiendlhofer", "Charlie Griffin", "Joar Skalse"], "Categories": "cs.LG"}, "abstract": "Implementing a reward function that perfectly captures a complex task in the real world is impractical. As a result, it is often appropriate to think of the reward function as a proxy for the true objective rather than as its definition. We study this phenomenon through the lens of Goodhart's law, which predicts that increasing optimisation of an imperfect proxy beyond some critical point decreases performance on the true objective. First, we propose a way to quantify the magnitude of this effect and show empirically that optimising an imperfect proxy reward often leads to the behaviour predicted by Goodhart's law for a wide range of environments and reward functions. We then provide a geometric explanation for why Goodhart's law occurs in Markov decision processes. We use these theoretical insights to propose an optimal early stopping method that provably avoids the aforementioned pitfall and derive theoretical regret bounds for this method. Moreover, we derive a training method that maximises worst-case reward, for the setting where there is uncertainty about the true reward function. Finally, we evaluate our early stopping method experimentally. Our results support a foundation for a theoretically-principled study of reinforcement learning under reward misspecification.", "url": "https://arxiv.org/abs/2310.09144"}, {"metadata": {"arXiv": "2310.09163", "Date": "Fri, 13 Oct 2023 14:56:38 ", "Title": "Jointly-Learned Exit and Inference for a Dynamic Neural Network : JEI-DNN", "Authors": ["Florence Regol", "Joud Chataoui", "Mark Coates"], "Categories": "cs.LG"}, "abstract": "Large pretrained models, coupled with fine-tuning, are slowly becoming established as the dominant architecture in machine learning. Even though these models offer impressive performance, their practical application is often limited by the prohibitive amount of resources required for every inference. Early-exiting dynamic neural networks (EDNN) circumvent this issue by allowing a model to make some of its predictions from intermediate layers (i.e., early-exit). Training an EDNN architecture is challenging as it consists of two intertwined components: the gating mechanism (GM) that controls early-exiting decisions and the intermediate inference modules (IMs) that perform inference from intermediate representations. As a result, most existing approaches rely on thresholding confidence metrics for the gating mechanism and strive to improve the underlying backbone network and the inference modules. Although successful, this approach has two fundamental shortcomings: 1) the GMs and the IMs are decoupled during training, leading to a train-test mismatch; and 2) the thresholding gating mechanism introduces a positive bias into the predictive probabilities, making it difficult to readily extract uncertainty information. We propose a novel architecture that connects these two modules. This leads to significant performance improvements on classification datasets and enables better uncertainty characterization capabilities.", "url": "https://arxiv.org/abs/2310.09163"}, {"metadata": {"arXiv": "2310.09194", "Date": "Fri, 13 Oct 2023 15:40:55 ", "Title": "Variational autoencoder with weighted samples for high-dimensional non-parametric adaptive importance sampling", "Authors": ["Julien Demange-Chryst", "Fran\\c{c}ois Bachoc", "J\\'er\\^ome Morio", "Timoth\\'e Krauth"], "Categories": "cs.LG math.ST stat.TH", "Comments": ["20 pages", "5 figures"]}, "abstract": "Probability density function estimation with weighted samples is the main foundation of all adaptive importance sampling algorithms. Classically, a target distribution is approximated either by a non-parametric model or within a parametric family. However, these models suffer from the curse of dimensionality or from their lack of flexibility. In this contribution, we suggest to use as the approximating model a distribution parameterised by a variational autoencoder. We extend the existing framework to the case of weighted samples by introducing a new objective function. The flexibility of the obtained family of distributions makes it as expressive as a non-parametric model, and despite the very high number of parameters to estimate, this family is much more efficient in high dimension than the classical Gaussian or Gaussian mixture families. Moreover, in order to add flexibility to the model and to be able to learn multimodal distributions, we consider a learnable prior distribution for the variational autoencoder latent variables. We also introduce a new pre-training procedure for the variational autoencoder to find good starting weights of the neural networks to prevent as much as possible the posterior collapse phenomenon to happen. At last, we explicit how the resulting distribution can be combined with importance sampling, and we exploit the proposed procedure in existing adaptive importance sampling algorithms to draw points from a target distribution and to estimate a rare event probability in high dimension on two multimodal problems.", "url": "https://arxiv.org/abs/2310.09194"}, {"metadata": {"arXiv": "2310.09202", "Date": "Fri, 13 Oct 2023 15:48:12 ", "Title": "Graph Condensation via Eigenbasis Matching", "Authors": ["Yang Liu", "Deyu Bo", "Chuan Shi"], "Categories": "cs.LG", "Comments": ["Under Review"]}, "abstract": "The increasing amount of graph data places requirements on the efficiency and scalability of graph neural networks (GNNs), despite their effectiveness in various graph-related applications. Recently, the emerging graph condensation (GC) sheds light on reducing the computational cost of GNNs from a data perspective. It aims to replace the real large graph with a significantly smaller synthetic graph so that GNNs trained on both graphs exhibit comparable performance. However, our empirical investigation reveals that existing GC methods suffer from poor generalization, i.e., different GNNs trained on the same synthetic graph have obvious performance gaps. What factors hinder the generalization of GC and how can we mitigate it? To answer this question, we commence with a detailed analysis and observe that GNNs will inject spectrum bias into the synthetic graph, resulting in a distribution shift. To tackle this issue, we propose eigenbasis matching for spectrum-free graph condensation, named GCEM, which has two key steps: First, GCEM matches the eigenbasis of the real and synthetic graphs, rather than the graph structure, which eliminates the spectrum bias of GNNs. Subsequently, GCEM leverages the spectrum of the real graph and the synthetic eigenbasis to construct the synthetic graph, thereby preserving the essential structural information. We theoretically demonstrate that the synthetic graph generated by GCEM maintains the spectral similarity, i.e., total variation, of the real graph. Extensive experiments conducted on five graph datasets verify that GCEM not only achieves state-of-the-art performance over baselines but also significantly narrows the performance gaps between different GNNs.", "url": "https://arxiv.org/abs/2310.09202"}, {"metadata": {"arXiv": "2310.09210", "Date": "Fri, 13 Oct 2023 16:04:06 ", "Title": "Regularization-Based Methods for Ordinal Quantification", "Authors": ["Mirko Bunse", "Alejandro Moreo", "Fabrizio Sebastiani", "Martin Senz"], "Categories": "cs.LG", "Comments": ["45 pages"]}, "abstract": "Quantification, i.e., the task of training predictors of the class prevalence values in sets of unlabeled data items, has received increased attention in recent years. However, most quantification research has concentrated on developing algorithms for binary and multiclass problems in which the classes are not ordered. Here, we study the ordinal case, i.e., the case in which a total order is defined on the set of n>2 classes. We give three main contributions to this field. First, we create and make available two datasets for ordinal quantification (OQ) research that overcome the inadequacies of the previously available ones. Second, we experimentally compare the most important OQ algorithms proposed in the literature so far. To this end, we bring together algorithms proposed by authors from very different research fields, such as data mining and astrophysics, who were unaware of each others' developments. Third, we propose a novel class of regularized OQ algorithms, which outperforms existing algorithms in our experiments. The key to this gain in performance is that our regularization prevents ordinally implausible estimates, assuming that ordinal distributions tend to be smooth in practice. We informally verify this assumption for several real-world applications.", "url": "https://arxiv.org/abs/2310.09210"}, {"metadata": {"arXiv": "2310.09213", "Date": "Fri, 13 Oct 2023 16:07:31 ", "Title": "Unseen Image Synthesis with Diffusion Models", "Authors": ["Ye Zhu", "Yu Wu", "Zhiwei Deng", "Olga Russakovsky and Yan Yan"], "Categories": "cs.LG cs.CV", "Comments": ["28 pages including appendices"]}, "abstract": "While the current trend in the generative field is scaling up towards larger models and more training data for generalized domain representations, we go the opposite direction in this work by synthesizing unseen domain images without additional training. We do so via latent sampling and geometric optimization using pre-trained and frozen Denoising Diffusion Probabilistic Models (DDPMs) on single-domain datasets. Our key observation is that DDPMs pre-trained even just on single-domain images are already equipped with sufficient representation abilities to reconstruct arbitrary images from the inverted latent encoding following bi-directional deterministic diffusion and denoising trajectories. This motivates us to investigate the statistical and geometric behaviors of the Out-Of-Distribution (OOD) samples from unseen image domains in the latent spaces along the denoising chain. Notably, we theoretically and empirically show that the inverted OOD samples also establish Gaussians that are distinguishable from the original In-Domain (ID) samples in the intermediate latent spaces, which allows us to sample from them directly. Geometrical domain-specific and model-dependent information of the unseen subspace (e.g., sample-wise distance and angles) is used to further optimize the sampled OOD latent encodings from the estimated Gaussian prior. We conduct extensive analysis and experiments using pre-trained diffusion models (DDPM, iDDPM) on different datasets (AFHQ, CelebA-HQ, LSUN-Church, and LSUN-Bedroom), proving the effectiveness of this novel perspective to explore and re-think the diffusion models' data synthesis generalization ability.", "url": "https://arxiv.org/abs/2310.09213"}, {"metadata": {"arXiv": "2310.09229", "Date": "Fri, 13 Oct 2023 16:31:51 ", "Title": "Insuring Smiles: Predicting routine dental coverage using Spark ML", "Authors": ["Aishwarya Gupta", "Rahul S. Bhogale", "Priyanka Thota", "Prathushkumar Dathuri", "Jongwook Woo"], "Categories": "cs.LG cs.DC", "Comments": ["4 pages", "13 figures", "5 tables"]}, "abstract": "Finding suitable health insurance coverage can be challenging for individuals and small enterprises in the USA. The Health Insurance Exchange Public Use Files (Exchange PUFs) dataset provided by CMS offers valuable information on health and dental policies [1]. In this paper, we leverage machine learning algorithms to predict if a health insurance plan covers routine dental services for adults. By analyzing plan type, region, deductibles, out-of-pocket maximums, and copayments, we employ Logistic Regression, Decision Tree, Random Forest, Gradient Boost, Factorization Model and Support Vector Machine algorithms. Our goal is to provide a clinical strategy for individuals and families to select the most suitable insurance plan based on income and expenses.", "url": "https://arxiv.org/abs/2310.09229"}, {"metadata": {"arXiv": "2310.09259", "Date": "Fri, 13 Oct 2023 17:15:05 ", "Title": "Towards End-to-end 4-Bit Inference on Generative Large Language Models", "Authors": ["Saleh Ashkboos", "Ilia Markov", "Elias Frantar", "Tingxuan Zhong", "Xincheng Wang", "Jie Ren", "Torsten Hoefler", "Dan Alistarh"], "Categories": "cs.LG", "Comments": ["9 pages"]}, "abstract": "We show that the majority of the inference computations for large generative models such as LLaMA and OPT can be performed with both weights and activations being cast to 4 bits, in a way that leads to practical speedups while at the same time maintaining good accuracy. We achieve this via a hybrid quantization strategy called QUIK, which compresses most of the weights and activations to 4-bit, while keeping some outlier weights and activations in higher-precision. Crucially, our scheme is designed with computational efficiency in mind: we provide GPU kernels with highly-efficient layer-wise runtimes, which lead to practical end-to-end throughput improvements of up to 3.1x relative to FP16 execution. Code and models are provided at https://github.com/IST-DASLab/QUIK.", "url": "https://arxiv.org/abs/2310.09259"}, {"metadata": {"arXiv": "2310.09277", "Date": "Fri, 13 Oct 2023 17:39:35 ", "Title": "A Hybrid Approach for Depression Classification: Random Forest-ANN Ensemble on Motor Activity Signals", "Authors": ["Anket Patil", "Dhairya Shah", "Abhishek Shah", "Mokshit Gala"], "Categories": "cs.LG", "Comments": ["8 pages"], "MSC-class": "68T05"}, "abstract": "Regarding the rising number of people suffering from mental health illnesses in today's society, the importance of mental health cannot be overstated. Wearable sensors, which are increasingly widely available, provide a potential way to track and comprehend mental health issues. These gadgets not only monitor everyday activities but also continuously record vital signs like heart rate, perhaps providing information on a person's mental state. Recent research has used these sensors in conjunction with machine learning methods to identify patterns relating to different mental health conditions, highlighting the immense potential of this data beyond simple activity monitoring. In this research, we present a novel algorithm called the Hybrid Random forest - Neural network that has been tailored to evaluate sensor data from depressed patients. Our method has a noteworthy accuracy of 80\\% when evaluated on a special dataset that included both unipolar and bipolar depressive patients as well as healthy controls. The findings highlight the algorithm's potential for reliably determining a person's depression condition using sensor data, making a substantial contribution to the area of mental health diagnostics.", "url": "https://arxiv.org/abs/2310.09277"}, {"metadata": {"arXiv": "2310.09278", "Date": "Fri, 13 Oct 2023 17:40:39 ", "Title": "Disentangled Latent Spaces Facilitate Data-Driven Auxiliary Learning", "Authors": ["Geri Skenderi", "Luigi Capogrosso", "Andrea Toaiari", "Matteo Denitto", "Franco Fummi", "Simone Melzi", "Marco Cristani"], "Categories": "cs.LG", "Comments": ["Under review in Pattern Recognition Letters"]}, "abstract": "In deep learning, auxiliary objectives are often used to facilitate learning in situations where data is scarce, or the principal task is extremely complex. This idea is primarily inspired by the improved generalization capability induced by solving multiple tasks simultaneously, which leads to a more robust shared representation. Nevertheless, finding optimal auxiliary tasks that give rise to the desired improvement is a crucial problem that often requires hand-crafted solutions or expensive meta-learning approaches. In this paper, we propose a novel framework, dubbed Detaux, whereby a weakly supervised disentanglement procedure is used to discover new unrelated classification tasks and the associated labels that can be exploited with the principal task in any Multi-Task Learning (MTL) model. The disentanglement procedure works at a representation level, isolating a subspace related to the principal task, plus an arbitrary number of orthogonal subspaces. In the most disentangled subspaces, through a clustering procedure, we generate the additional classification tasks, and the associated labels become their representatives. Subsequently, the original data, the labels associated with the principal task, and the newly discovered ones can be fed into any MTL framework. Extensive validation on both synthetic and real data, along with various ablation studies, demonstrate promising results, revealing the potential in what has been, so far, an unexplored connection between learning disentangled representations and MTL. The code will be made publicly available upon acceptance.", "url": "https://arxiv.org/abs/2310.09278"}, {"metadata": {"arXiv": "2310.08710", "Date": "Thu, 12 Oct 2023 20:49:15 ", "Title": "Waymax: An Accelerated, Data-Driven Simulator for Large-Scale Autonomous Driving Research", "Authors": ["Cole Gulino", "Justin Fu", "Wenjie Luo", "George Tucker", "Eli Bronstein", "Yiren Lu", "Jean Harb", "Xinlei Pan", "Yan Wang", "Xiangyu Chen", "John D. Co-Reyes", "Rishabh Agarwal", "Rebecca Roelofs", "Yao Lu", "Nico Montali", "Paul Mougin", "Zoey Yang", "Brandyn White", "Aleksandra Faust", "Rowan McAllister", "Dragomir Anguelov", "Benjamin Sapp"], "Categories": "cs.RO cs.LG"}, "abstract": "Simulation is an essential tool to develop and benchmark autonomous vehicle planning software in a safe and cost-effective manner. However, realistic simulation requires accurate modeling of nuanced and complex multi-agent interactive behaviors. To address these challenges, we introduce Waymax, a new data-driven simulator for autonomous driving in multi-agent scenes, designed for large-scale simulation and testing. Waymax uses publicly-released, real-world driving data (e.g., the Waymo Open Motion Dataset) to initialize or play back a diverse set of multi-agent simulated scenarios. It runs entirely on hardware accelerators such as TPUs/GPUs and supports in-graph simulation for training, making it suitable for modern large-scale, distributed machine learning workflows. To support online training and evaluation, Waymax includes several learned and hard-coded behavior models that allow for realistic interaction within simulation. To supplement Waymax, we benchmark a suite of popular imitation and reinforcement learning algorithms with ablation studies on different design decisions, where we highlight the effectiveness of routes as guidance for planning agents and the ability of RL to overfit against simulated agents.", "url": "https://arxiv.org/abs/2310.08710"}, {"metadata": {"arXiv": "2310.08617", "Date": "Thu, 12 Oct 2023 16:00:16 ", "Title": "The Impact of Explanations on Fairness in Human-AI Decision-Making: Protected vs Proxy Features", "Authors": ["Navita Goyal", "Connor Baumler", "Tin Nguyen", "and Hal Daum\\'e III"], "Categories": "cs.AI cs.HC"}, "abstract": "AI systems have been known to amplify biases in real world data. Explanations may help human-AI teams address these biases for fairer decision-making. Typically, explanations focus on salient input features. If a model is biased against some protected group, explanations may include features that demonstrate this bias, but when biases are realized through proxy features, the relationship between this proxy feature and the protected one may be less clear to a human. In this work, we study the effect of the presence of protected and proxy features on participants' perception of model fairness and their ability to improve demographic parity over an AI alone. Further, we examine how different treatments -- explanations, model bias disclosure and proxy correlation disclosure -- affect fairness perception and parity. We find that explanations help people detect direct biases but not indirect biases. Additionally, regardless of bias type, explanations tend to increase agreement with model biases. Disclosures can help mitigate this effect for indirect biases, improving both unfairness recognition and the decision-making fairness. We hope that our findings can help guide further research into advancing explanations in support of fair human-AI decision-making.", "url": "https://arxiv.org/abs/2310.08617"}, {"metadata": {"arXiv": "2310.08737", "Date": "Thu, 12 Oct 2023 21:50:53 ", "Title": "Real-Time Event Detection with Random Forests and Temporal Convolutional Networks for More Sustainable Petroleum Industry", "Authors": ["Yuanwei Qu", "Baifan Zhou", "Arild Waaler", "David Cameron"], "Categories": "cs.AI", "Comments": ["Paper accepted at PRICAI 2023 AI-Impact Track"]}, "abstract": "The petroleum industry is crucial for modern society, but the production process is complex and risky. During the production, accidents or failures, resulting from undesired production events, can cause severe environmental and economic damage. Previous studies have investigated machine learning (ML) methods for undesired event detection. However, the prediction of event probability in real-time was insufficiently addressed, which is essential since it is important to undertake early intervention when an event is expected to happen. This paper proposes two ML approaches, random forests and temporal convolutional networks, to detect undesired events in real-time. Results show that our approaches can effectively classify event types and predict the probability of their appearance, addressing the challenges uncovered in previous studies and providing a more effective solution for failure event management during the production.", "url": "https://arxiv.org/abs/2310.08737"}, {"metadata": {"arXiv": "2310.08773", "Date": "Thu, 12 Oct 2023 23:39:28 ", "Title": "Examining the Potential and Pitfalls of ChatGPT in Science and Engineering Problem-Solving", "Authors": ["Karen D. Wang", "Eric Burkholder", "Carl Wieman", "Shima Salehi", "Nick Haber"], "Categories": "cs.AI cs.CE", "Comments": ["12 pages", "2 figures"]}, "abstract": "The study explores the capabilities of OpenAI's ChatGPT in solving different types of physics problems. ChatGPT (with GPT-4) was queried to solve a total of 40 problems from a college-level engineering physics course. These problems ranged from well-specified problems, where all data required for solving the problem was provided, to under-specified, real-world problems where not all necessary data were given. Our findings show that ChatGPT could successfully solve 62.5\\% of the well-specified problems, but its accuracy drops to 8.3\\% for under-specified problems. Analysis of the model's incorrect solutions revealed three distinct failure modes: 1) failure to construct accurate models of the physical world, 2) failure to make reasonable assumptions about missing data, and 3) calculation errors. The study offers implications for how to leverage LLM-augmented instructional materials to enhance STEM education. The insights also contribute to the broader discourse on AI's strengths and limitations, serving both educators aiming to leverage the technology and researchers investigating human-AI collaboration frameworks for problem-solving and decision-making.", "url": "https://arxiv.org/abs/2310.08773"}, {"metadata": {"arXiv": "2310.08803", "Date": "Fri, 13 Oct 2023 01:21:55 ", "Title": "Advancing Perception in Artificial Intelligence through Principles of Cognitive Science", "Authors": ["Palaash Agrawal", "Cheston Tan and Heena Rathore"], "Categories": "cs.AI", "Comments": ["Summary: a detailed review of the current state of perception models through the lens of cognitive AI"]}, "abstract": "Although artificial intelligence (AI) has achieved many feats at a rapid pace, there still exist open problems and fundamental shortcomings related to performance and resource efficiency. Since AI researchers benchmark a significant proportion of performance standards through human intelligence, cognitive sciences-inspired AI is a promising domain of research. Studying cognitive science can provide a fresh perspective to building fundamental blocks in AI research, which can lead to improved performance and efficiency. In this review paper, we focus on the cognitive functions of perception, which is the process of taking signals from one's surroundings as input, and processing them to understand the environment. Particularly, we study and compare its various processes through the lens of both cognitive sciences and AI. Through this study, we review all current major theories from various sub-disciplines of cognitive science (specifically neuroscience, psychology and linguistics), and draw parallels with theories and techniques from current practices in AI. We, hence, present a detailed collection of methods in AI for researchers to build AI systems inspired by cognitive science. Further, through the process of reviewing the state of cognitive-inspired AI, we point out many gaps in the current state of AI (with respect to the performance of the human brain), and hence present potential directions for researchers to develop better perception systems in AI.", "url": "https://arxiv.org/abs/2310.08803"}, {"metadata": {"arXiv": "2310.08841", "Date": "Fri, 13 Oct 2023 03:39:15 ", "Title": "Leveraging Optimal Transport for Enhanced Offline Reinforcement Learning in Surgical Robotic Environments", "Authors": ["Maryam Zare", "Parham M. Kebria", "Abbas Khosravi"], "Categories": "cs.AI cs.RO stat.ML", "Comments": ["Preprint"]}, "abstract": "Most Reinforcement Learning (RL) methods are traditionally studied in an active learning setting, where agents directly interact with their environments, observe action outcomes, and learn through trial and error. However, allowing partially trained agents to interact with real physical systems poses significant challenges, including high costs, safety risks, and the need for constant supervision. Offline RL addresses these cost and safety concerns by leveraging existing datasets and reducing the need for resource-intensive real-time interactions. Nevertheless, a substantial challenge lies in the demand for these datasets to be meticulously annotated with rewards. In this paper, we introduce Optimal Transport Reward (OTR) labelling, an innovative algorithm designed to assign rewards to offline trajectories, using a small number of high-quality expert demonstrations. The core principle of OTR involves employing Optimal Transport (OT) to calculate an optimal alignment between an unlabeled trajectory from the dataset and an expert demonstration. This alignment yields a similarity measure that is effectively interpreted as a reward signal. An offline RL algorithm can then utilize these reward signals to learn a policy. This approach circumvents the need for handcrafted rewards, unlocking the potential to harness vast datasets for policy learning. Leveraging the SurRoL simulation platform tailored for surgical robot learning, we generate datasets and employ them to train policies using the OTR algorithm. By demonstrating the efficacy of OTR in a different domain, we emphasize its versatility and its potential to expedite RL deployment across a wide range of fields.", "url": "https://arxiv.org/abs/2310.08841"}, {"metadata": {"arXiv": "2310.08842", "Date": "Fri, 13 Oct 2023 03:56:38 ", "Title": "A Case-Based Persistent Memory for a Large Language Model", "Authors": ["Ian Watson"], "Categories": "cs.AI", "Comments": ["8 pages", "1 figure"], "ACM-class": "I.2.0"}, "abstract": "Case-based reasoning (CBR) as a methodology for problem-solving can use any appropriate computational technique. This position paper argues that CBR researchers have somewhat overlooked recent developments in deep learning and large language models (LLMs). The underlying technical developments that have enabled the recent breakthroughs in AI have strong synergies with CBR and could be used to provide a persistent memory for LLMs to make progress towards Artificial General Intelligence.", "url": "https://arxiv.org/abs/2310.08842"}, {"metadata": {"arXiv": "2310.08849", "Date": "Fri, 13 Oct 2023 04:25:30 ", "Title": "Path To Gain Functional Transparency In Artificial Intelligence With Meaningful Explainability", "Authors": ["Md. Tanzib Hosain", "Mehedi Hasan Anik", "Sadman Rafi", "Rana Tabassum", "Khaleque Insia", "Md. Mehrab Siddiky"], "Categories": "cs.AI", "Comments": ["Hosain", "M. T. ", "Anik", "M. H. ", "Rafi", "S. ", "Tabassum", "R. ", "Insia", "K. & S{\\i}dd{\\i}ky", "M. M. (). Path To Gain Functional Transparency In Artificial Intelligence With Meaningful Explainability . Journal of Metaverse ", "3 (2) ", "166-180 . DOI: 10.57019/jmv.1306685"], "DOI": "10.57019/jmv.1306685"}, "abstract": "Artificial Intelligence (AI) is rapidly integrating into various aspects of our daily lives, influencing decision-making processes in areas such as targeted advertising and matchmaking algorithms. As AI systems become increasingly sophisticated, ensuring their transparency and explainability becomes crucial. Functional transparency is a fundamental aspect of algorithmic decision-making systems, allowing stakeholders to comprehend the inner workings of these systems and enabling them to evaluate their fairness and accuracy. However, achieving functional transparency poses significant challenges that need to be addressed. In this paper, we propose a design for user-centered compliant-by-design transparency in transparent systems. We emphasize that the development of transparent and explainable AI systems is a complex and multidisciplinary endeavor, necessitating collaboration among researchers from diverse fields such as computer science, artificial intelligence, ethics, law, and social science. By providing a comprehensive understanding of the challenges associated with transparency in AI systems and proposing a user-centered design framework, we aim to facilitate the development of AI systems that are accountable, trustworthy, and aligned with societal values.", "url": "https://arxiv.org/abs/2310.08849"}, {"metadata": {"arXiv": "2310.08915", "Date": "Fri, 13 Oct 2023 07:38:52 ", "Title": "Dynamic Sparse No Training: Training-Free Fine-tuning for Sparse LLMs", "Authors": ["Yuxin Zhang", "Lirui Zhao", "Mingbao Lin", "Yunyun Sun", "Yiwu Yao", "Xingjia Han", "Jared Tanner", "Shiwei Liu", "Rongrong Ji"], "Categories": "cs.AI"}, "abstract": "The ever-increasing large language models (LLMs), though opening a potential path for the upcoming artificial general intelligence, sadly drops a daunting obstacle on the way towards their on-device deployment. As one of the most well-established pre-LLMs approaches in reducing model complexity, network pruning appears to lag behind in the era of LLMs, due mostly to its costly fine-tuning (or re-training) necessity under the massive volumes of model parameter and training data. To close this industry-academia gap, we introduce Dynamic Sparse No Training (DSnoT), a training-free fine-tuning approach that slightly updates sparse LLMs without the expensive backpropagation and any weight updates. Inspired by the Dynamic Sparse Training, DSnoT minimizes the reconstruction error between the dense and sparse LLMs, in the fashion of performing iterative weight pruning-and-growing on top of sparse LLMs. To accomplish this purpose, DSnoT particularly takes into account the anticipated reduction in reconstruction error for pruning and growing, as well as the variance w.r.t. different input data for growing each weight. This practice can be executed efficiently in linear time since its obviates the need of backpropagation for fine-tuning LLMs. Extensive experiments on LLaMA-V1/V2, Vicuna, and OPT across various benchmarks demonstrate the effectiveness of DSnoT in enhancing the performance of sparse LLMs, especially at high sparsity levels. For instance, DSnoT is able to outperform the state-of-the-art Wanda by 26.79 perplexity at 70% sparsity with LLaMA-7B. Our paper offers fresh insights into how to fine-tune sparse LLMs in an efficient training-free manner and open new venues to scale the great potential of sparsity to LLMs. Codes are available at https://github.com/zxyxmu/DSnoT.", "url": "https://arxiv.org/abs/2310.08915"}, {"metadata": {"arXiv": "2310.08949", "Date": "Fri, 13 Oct 2023 08:38:56 ", "Title": "Making Multimodal Generation Easier: When Diffusion Models Meet LLMs", "Authors": ["Xiangyu Zhao", "Bo Liu", "Qijiong Liu", "Guangyuan Shi", "Xiao-Ming Wu"], "Categories": "cs.AI cs.CL cs.CV"}, "abstract": "We present EasyGen, an efficient model designed to enhance multimodal understanding and generation by harnessing the capabilities of diffusion models and large language models (LLMs). Unlike existing multimodal models that predominately depend on encoders like CLIP or ImageBind and need ample amounts of training data to bridge the gap between modalities, EasyGen is built upon a bidirectional conditional diffusion model named BiDiffuser, which promotes more efficient interactions between modalities. EasyGen handles image-to-text generation by integrating BiDiffuser and an LLM via a simple projection layer. Unlike most existing multimodal models that are limited to generating text responses, EasyGen can also facilitate text-to-image generation by leveraging the LLM to create textual descriptions, which can be interpreted by BiDiffuser to generate appropriate visual responses. Extensive quantitative and qualitative experiments demonstrate the effectiveness of EasyGen, whose training can be easily achieved in a lab setting. The source code is available at https://github.com/zxy556677/EasyGen.", "url": "https://arxiv.org/abs/2310.08949"}, {"metadata": {"arXiv": "2310.08977", "Date": "Fri, 13 Oct 2023 09:47:24 ", "Title": "Multi-Purpose NLP Chatbot : Design, Methodology & Conclusion", "Authors": ["Shivom Aggarwal", "Shourya Mehra", "Pritha Mitra"], "Categories": "cs.AI", "Comments": ["Multilingual ", "Voice Conversion ", "Emotion Recognition ", "Offline Service ", "Financial Advisor ", "Product Preference ", "Customer Reaction Prediction"]}, "abstract": "With a major focus on its history, difficulties, and promise, this research paper provides a thorough analysis of the chatbot technology environment as it exists today. It provides a very flexible chatbot system that makes use of reinforcement learning strategies to improve user interactions and conversational experiences. Additionally, this system makes use of sentiment analysis and natural language processing to determine user moods. The chatbot is a valuable tool across many fields thanks to its amazing characteristics, which include voice-to-voice conversation, multilingual support [12], advising skills, offline functioning, and quick help features. The complexity of chatbot technology development is also explored in this study, along with the causes that have propelled these developments and their far-reaching effects on a range of sectors. According to the study, three crucial elements are crucial: 1) Even without explicit profile information, the chatbot system is built to adeptly understand unique consumer preferences and fluctuating satisfaction levels. With the use of this capacity, user interactions are made to meet their wants and preferences. 2) Using a complex method that interlaces Multiview voice chat information, the chatbot may precisely simulate users' actual experiences. This aids in developing more genuine and interesting discussions. 3) The study presents an original method for improving the black-box deep learning models' capacity for prediction. This improvement is made possible by introducing dynamic satisfaction measurements that are theory-driven, which leads to more precise forecasts of consumer reaction.", "url": "https://arxiv.org/abs/2310.08977"}, {"metadata": {"arXiv": "2310.08982", "Date": "Fri, 13 Oct 2023 09:57:22 ", "Title": "Big data-driven prediction of airspace congestion", "Authors": ["Samet Ayhan", "\\'Italo Romani de Oliveira", "Glaucia Balvedi", "Pablo Costas", "Alexandre Leite", "Felipe C. F. de Azevedo"], "Categories": "cs.AI cs.CE cs.SY eess.SY", "Comments": ["Submitted to the 2023 IEEE/AIAA Digital Aviation Systems Conference (DASC)"]}, "abstract": "Air Navigation Service Providers (ANSP) worldwide have been making a considerable effort for the development of a better method to measure and predict aircraft counts within a particular airspace, also referred to as airspace density. An accurate measurement and prediction of airspace density is crucial for a better managed airspace, both strategically and tactically, yielding a higher level of automation and thereby reducing the air traffic controller's workload. Although the prior approaches have been able to address the problem to some extent, data management and query processing of ever-increasing vast volume of air traffic data at high rates, for various analytics purposes such as predicting aircraft counts, still remains a challenge especially when only linear prediction models are used. In this paper, we present a novel data management and prediction system that accurately predicts aircraft counts for a particular airspace sector within the National Airspace System (NAS). The incoming Traffic Flow Management (TFM) data is streaming, big, uncorrelated and noisy. In the preprocessing step, the system continuously processes the incoming raw data, reduces it to a compact size, and stores it in a NoSQL database, where it makes the data available for efficient query processing. In the prediction step, the system learns from historical trajectories and uses their segments to collect key features such as sector boundary crossings, weather parameters, and other air traffic data. The features are fed into various regression models, including linear, non-linear and ensemble models, and the best performing model is used for prediction. Evaluation on an extensive set of real track, weather, and air traffic data including boundary crossings in the U.S. verify that our system efficiently and accurately predicts aircraft counts in each airspace sector.", "url": "https://arxiv.org/abs/2310.08982"}, {"metadata": {"arXiv": "2310.08992", "Date": "Fri, 13 Oct 2023 10:17:48 ", "Title": "CodeChain: Towards Modular Code Generation Through Chain of Self-revisions with Representative Sub-modules", "Authors": ["Hung Le", "Hailin Chen", "Amrita Saha", "Akash Gokul", "Doyen Sahoo", "Shafiq Joty"], "Categories": "cs.AI cs.CL cs.PL"}, "abstract": "Large Language Models (LLMs) have already become quite proficient at solving simpler programming tasks like those in HumanEval or MBPP benchmarks. However, solving more complex and competitive programming tasks is still quite challenging for these models - possibly due to their tendency to generate solutions as monolithic code blocks instead of decomposing them into logical sub-tasks and sub-modules. On the other hand, experienced programmers instinctively write modularized code with abstraction for solving complex tasks, often reusing previously developed modules. To address this gap, we propose CodeChain, a novel framework for inference that elicits modularized code generation through a chain of self-revisions, each being guided by some representative sub-modules generated in previous iterations. Concretely, CodeChain first instructs the LLM to generate modularized codes through chain-of-thought prompting. Then it applies a chain of self-revisions by iterating the two steps: 1) extracting and clustering the generated sub-modules and selecting the cluster representatives as the more generic and re-usable implementations, and 2) augmenting the original chain-of-thought prompt with these selected module-implementations and instructing the LLM to re-generate new modularized solutions. We find that by naturally encouraging the LLM to reuse the previously developed and verified sub-modules, CodeChain can significantly boost both modularity as well as correctness of the generated solutions, achieving relative pass@1 improvements of 35% on APPS and 76% on CodeContests. It is shown to be effective on both OpenAI LLMs as well as open-sourced LLMs like WizardCoder. We also conduct comprehensive ablation studies with different methods of prompting, number of clusters, model sizes, program qualities, etc., to provide useful insights that underpin CodeChain's success.", "url": "https://arxiv.org/abs/2310.08992"}, {"metadata": {"arXiv": "2310.09049", "Date": "Fri, 13 Oct 2023 12:14:58 ", "Title": "SAI: Solving AI Tasks with Systematic Artificial Intelligence in Communication Network", "Authors": ["Lei Yao", "Yong Zhang", "Zilong Yan and Jialu Tian"], "Categories": "cs.AI"}, "abstract": "In the rapid development of artificial intelligence, solving complex AI tasks is a crucial technology in intelligent mobile networks. Despite the good performance of specialized AI models in intelligent mobile networks, they are unable to handle complicated AI tasks. To address this challenge, we propose Systematic Artificial Intelligence (SAI), which is a framework designed to solve AI tasks by leveraging Large Language Models (LLMs) and JSON-format intent-based input to connect self-designed model library and database. Specifically, we first design a multi-input component, which simultaneously integrates Large Language Models (LLMs) and JSON-format intent-based inputs to fulfill the diverse intent requirements of different users. In addition, we introduce a model library module based on model cards which employ model cards to pairwise match between different modules for model composition. Model cards contain the corresponding model's name and the required performance metrics. Then when receiving user network requirements, we execute each subtask for multiple selected model combinations and provide output based on the execution results and LLM feedback. By leveraging the language capabilities of LLMs and the abundant AI models in the model library, SAI can complete numerous complex AI tasks in the communication network, achieving impressive results in network optimization, resource allocation, and other challenging tasks.", "url": "https://arxiv.org/abs/2310.09049"}, {"metadata": {"arXiv": "2310.09130", "Date": "Fri, 13 Oct 2023 14:17:33 ", "Title": "Split-and-Denoise: Protect large language model inference with local differential privacy", "Authors": ["Peihua Mai", "Ran Yan", "Zhe Huang", "Youjia Yang", "Yan Pang"], "Categories": "cs.AI cs.CR", "Comments": ["15 pages"]}, "abstract": "Large Language Models (LLMs) shows powerful capability in natural language understanding by capturing hidden semantics in vector space. This process enriches the value of the text embeddings for various downstream tasks, thereby fostering the Embedding-as-a-Service (EaaS) business model. However, the direct transmission of text to servers poses a largely unaddressed risk of privacy leakage. To mitigate this issue, we introduce Split-N-Denoise (SnD), an innovative framework that split the model to execute the token embedding layer on the client side at minimal computational cost. This allows the client to introduce noise prior to transmitting the embeddings to the server, and subsequently receive and denoise the perturbed output embeddings for downstream tasks. Our approach is designed for the inference stage of LLMs and requires no modifications to the model parameters. Extensive experiments demonstrate SnD's effectiveness in optimizing the privacy-utility tradeoff across various LLM architectures and diverse downstream tasks. The results reveal a significant performance improvement under the same privacy budget compared to the baseline, offering clients a privacy-preserving solution for local privacy protection.", "url": "https://arxiv.org/abs/2310.09130"}, {"metadata": {"arXiv": "2310.09135", "Date": "Fri, 13 Oct 2023 14:23:33 ", "Title": "HierarchicalContrast: A Coarse-to-Fine Contrastive Learning Framework for Cross-Domain Zero-Shot Slot Filling", "Authors": ["Junwen Zhang and Yin Zhang"], "Categories": "cs.AI cs.CL", "Comments": ["EMNLP 2023"], "ACM-class": "I.2.7"}, "abstract": "In task-oriented dialogue scenarios, cross-domain zero-shot slot filling plays a vital role in leveraging source domain knowledge to learn a model with high generalization ability in unknown target domain where annotated data is unavailable. However, the existing state-of-the-art zero-shot slot filling methods have limited generalization ability in target domain, they only show effective knowledge transfer on seen slots and perform poorly on unseen slots. To alleviate this issue, we present a novel Hierarchical Contrastive Learning Framework (HiCL) for zero-shot slot filling. Specifically, we propose a coarse- to fine-grained contrastive learning based on Gaussian-distributed embedding to learn the generalized deep semantic relations between utterance-tokens, by optimizing inter- and intra-token distribution distance. This encourages HiCL to generalize to the slot types unseen at training phase. Furthermore, we present a new iterative label set semantics inference method to unbiasedly and separately evaluate the performance of unseen slot types which entangled with their counterparts (i.e., seen slot types) in the previous zero-shot slot filling evaluation methods. The extensive empirical experiments on four datasets demonstrate that the proposed method achieves comparable or even better performance than the current state-of-the-art zero-shot slot filling approaches.", "url": "https://arxiv.org/abs/2310.09135"}, {"metadata": {"arXiv": "2310.09145", "Date": "Fri, 13 Oct 2023 14:36:26 ", "Title": "Lincoln AI Computing Survey (LAICS) Update", "Authors": ["Albert Reuther and Peter Michaleas and Michael Jones and Vijay Gadepally and Siddharth Samsi and Jeremy Kepner"], "Categories": "cs.AI cs.DC", "Comments": ["7 pages", "6 figures", "2023 IEEE High Performance Extreme Computing (HPEC) conference", "September 2023"], "ACM-class": "C.1.4; C.4"}, "abstract": "This paper is an update of the survey of AI accelerators and processors from past four years, which is now called the Lincoln AI Computing Survey - LAICS (pronounced \"lace\"). As in past years, this paper collects and summarizes the current commercial accelerators that have been publicly announced with peak performance and peak power consumption numbers. The performance and power values are plotted on a scatter graph, and a number of dimensions and observations from the trends on this plot are again discussed and analyzed. Market segments are highlighted on the scatter plot, and zoomed plots of each segment are also included. Finally, a brief description of each of the new accelerators that have been added in the survey this year is included.", "url": "https://arxiv.org/abs/2310.09145"}, {"metadata": {"arXiv": "2310.09158", "Date": "Fri, 13 Oct 2023 14:53:06 ", "Title": "Learning To Teach Large Language Models Logical Reasoning", "Authors": ["Meiqi Chen", "Yubo Ma", "Kaitao Song", "Yixin Cao", "Yan Zhang", "and Dongsheng Li"], "Categories": "cs.AI"}, "abstract": "Large language models (LLMs) have gained enormous attention from both academia and industry, due to their exceptional ability in language generation and extremely powerful generalization. However, current LLMs still output unreliable content in practical reasoning tasks due to their inherent issues (e.g., hallucination). To better disentangle this problem, in this paper, we conduct an in-depth investigation to systematically explore the capability of LLMs in logical reasoning. More in detail, we first investigate the deficiency of LLMs in logical reasoning on different tasks, including event relation extraction and deductive reasoning. Our study demonstrates that LLMs are not good reasoners in solving tasks with rigorous reasoning and will produce counterfactual answers, which require us to iteratively refine. Therefore, we comprehensively explore different strategies to endow LLMs with logical reasoning ability, and thus enable them to generate more logically consistent answers across different scenarios. Based on our approach, we also contribute a synthesized dataset (LLM-LR) involving multi-hop reasoning for evaluation and pre-training. Extensive quantitative and qualitative analyses on different tasks also validate the effectiveness and necessity of teaching LLMs with logic and provide insights for solving practical tasks with LLMs in future work.", "url": "https://arxiv.org/abs/2310.09158"}, {"metadata": {"arXiv": "2310.09217", "Date": "Fri, 13 Oct 2023 16:12:26 ", "Title": "Multinational AGI Consortium (MAGIC): A Proposal for International Coordination on AI", "Authors": ["Jason Hausenloy", "Andrea Miotti", "Claire Dennis"], "Categories": "cs.AI"}, "abstract": "This paper proposes a Multinational Artificial General Intelligence Consortium (MAGIC) to mitigate existential risks from advanced artificial intelligence (AI). MAGIC would be the only institution in the world permitted to develop advanced AI, enforced through a global moratorium by its signatory members on all other advanced AI development. MAGIC would be exclusive, safety-focused, highly secure, and collectively supported by member states, with benefits distributed equitably among signatories. MAGIC would allow narrow AI models to flourish while significantly reducing the possibility of misaligned, rogue, breakout, or runaway outcomes of general-purpose systems. We do not address the political feasibility of implementing a moratorium or address the specific legislative strategies and rules needed to enforce a ban on high-capacity AGI training runs. Instead, we propose one positive vision of the future, where MAGIC, as a global governance regime, can lay the groundwork for long-term, safe regulation of advanced AI.", "url": "https://arxiv.org/abs/2310.09217"}, {"metadata": {"arXiv": "2310.09237", "Date": "Fri, 13 Oct 2023 16:46:23 ", "Title": "Evaluating Machine Perception of Indigeneity: An Analysis of ChatGPT's Perceptions of Indigenous Roles in Diverse Scenarios", "Authors": ["Cecilia Delgado Solorzano", "Carlos Toxtli Hernandez"], "Categories": "cs.AI cs.HC", "Comments": ["5 pages", "3 figures"], "DOI": "10.13140/RG.2.2.30617.39520"}, "abstract": "Large Language Models (LLMs), like ChatGPT, are fundamentally tools trained on vast data, reflecting diverse societal impressions. This paper aims to investigate LLMs' self-perceived bias concerning indigeneity when simulating scenarios of indigenous people performing various roles. Through generating and analyzing multiple scenarios, this work offers a unique perspective on how technology perceives and potentially amplifies societal biases related to indigeneity in social computing. The findings offer insights into the broader implications of indigeneity in critical computing.", "url": "https://arxiv.org/abs/2310.09237"}, {"metadata": {"arXiv": "2310.09243", "Date": "Fri, 13 Oct 2023 16:47:35 ", "Title": "Augmented Computational Design: Methodical Application of Artificial Intelligence in Generative Design", "Authors": ["Pirouz Nourian", "Shervin Azadi", "Roy Uijtendaal", "Nan Bai"], "Categories": "cs.AI cs.CE", "Comments": ["This is the author's version of the book chapter Augmented Computational Design: Methodical Application of Artificial Intelligence in Generative Design. In Artificial Intelligence in Performance-Driven Design: Theories", "Methods", "and Tools Towards Sustainability", "edited by Narjes Abbasabadi and Mehdi Ashayeri. Wiley", "2023"]}, "abstract": "This chapter presents methodological reflections on the necessity and utility of artificial intelligence in generative design. Specifically, the chapter discusses how generative design processes can be augmented by AI to deliver in terms of a few outcomes of interest or performance indicators while dealing with hundreds or thousands of small decisions. The core of the performance-based generative design paradigm is about making statistical or simulation-driven associations between these choices and consequences for mapping and navigating such a complex decision space. This chapter will discuss promising directions in Artificial Intelligence for augmenting decision-making processes in architectural design for mapping and navigating complex design spaces.", "url": "https://arxiv.org/abs/2310.09243"}, {"metadata": {"arXiv": "2310.08785", "Date": "Thu, 12 Oct 2023 15:43:12 ", "Title": "DeltaSpace: A Semantic-aligned Feature Space for Flexible Text-guided Image Editing", "Authors": ["Yueming Lyu", "Kang Zhao", "Bo Peng", "Yue Jiang", "Yingya Zhang", "Jing Dong"], "Categories": "cs.CV cs.AI", "Comments": ["17 pages. arXiv admin note: text overlap with arXiv:2303.06285"]}, "abstract": "Text-guided image editing faces significant challenges to training and inference flexibility. Much literature collects large amounts of annotated image-text pairs to train text-conditioned generative models from scratch, which is expensive and not efficient. After that, some approaches that leverage pre-trained vision-language models are put forward to avoid data collection, but they are also limited by either per text-prompt optimization or inference-time hyper-parameters tuning. To address these issues, we investigate and identify a specific space, referred to as CLIP DeltaSpace, where the CLIP visual feature difference of two images is semantically aligned with the CLIP textual feature difference of their corresponding text descriptions. Based on DeltaSpace, we propose a novel framework called DeltaEdit, which maps the CLIP visual feature differences to the latent space directions of a generative model during the training phase, and predicts the latent space directions from the CLIP textual feature differences during the inference phase. And this design endows DeltaEdit with two advantages: (1) text-free training; (2) generalization to various text prompts for zero-shot inference. Extensive experiments validate the effectiveness and versatility of DeltaEdit with different generative models, including both the GAN model and the diffusion model, in achieving flexible text-guided image editing. Code is available at https://github.com/Yueming6568/DeltaEdit.", "url": "https://arxiv.org/abs/2310.08785"}, {"metadata": {"arXiv": "2310.08888", "Date": "Fri, 13 Oct 2023 06:48:38 ", "Title": "A Hybrid Transfer Learning Assisted Decision Support System for Accurate Prediction of Alzheimer Disease", "Authors": ["Mahin Khan Mahadi", "Abdullah Abdullah", "Jamal Uddin", "Asif Newaz"], "Categories": "cs.CV cs.AI"}, "abstract": "Alzheimer's disease (AD) is the most common long-term illness in elderly people. In recent years, deep learning has become popular in the area of medical imaging and has had a lot of success there. It has become the most effective way to look at medical images. When it comes to detecting AD, the deep neural model is more accurate and effective than general machine learning. Our research contributes to the development of a more comprehensive understanding and detection of the disease by identifying four distinct classes that are predictive of AD with a high weighted accuracy of 98.91%. A unique strategy has been proposed to improve the accuracy of the imbalance dataset classification problem via the combination of ensemble averaging models and five different transfer learning models in this study. EfficientNetB0+Resnet152(effnet+res152) and InceptionV3+EfficientNetB0+Resnet50(incep+effnet+res50) models have been fine-tuned and have reached the highest weighted accuracy for multi-class AD stage classifications.", "url": "https://arxiv.org/abs/2310.08888"}, {"metadata": {"arXiv": "2310.08948", "Date": "Fri, 13 Oct 2023 08:35:02 ", "Title": "Federated Class-Incremental Learning with Prompting", "Authors": ["Jiale Liu", "Yu-Wei Zhan", "Chong-Yu Zhang", "Xin Luo", "Zhen-Duo Chen", "Yinwei Wei", "and Xin-Shun Xu"], "Categories": "cs.CV cs.AI"}, "abstract": "As Web technology continues to develop, it has become increasingly common to use data stored on different clients. At the same time, federated learning has received widespread attention due to its ability to protect data privacy when let models learn from data which is distributed across various clients. However, most existing works assume that the client's data are fixed. In real-world scenarios, such an assumption is most likely not true as data may be continuously generated and new classes may also appear. To this end, we focus on the practical and challenging federated class-incremental learning (FCIL) problem. For FCIL, the local and global models may suffer from catastrophic forgetting on old classes caused by the arrival of new classes and the data distributions of clients are non-independent and identically distributed (non-iid). In this paper, we propose a novel method called Federated Class-Incremental Learning with PrompTing (FCILPT). Given the privacy and limited memory, FCILPT does not use a rehearsal-based buffer to keep exemplars of old data. We choose to use prompts to ease the catastrophic forgetting of the old classes. Specifically, we encode the task-relevant and task-irrelevant knowledge into prompts, preserving the old and new knowledge of the local clients and solving the problem of catastrophic forgetting. We first sort the task information in the prompt pool in the local clients to align the task information on different clients before global aggregation. It ensures that the same task's knowledge are fully integrated, solving the problem of non-iid caused by the lack of classes among different clients in the same incremental task. Experiments on CIFAR-100, Mini-ImageNet, and Tiny-ImageNet demonstrate that FCILPT achieves significant accuracy improvements over the state-of-the-art methods.", "url": "https://arxiv.org/abs/2310.08948"}, {"metadata": {"arXiv": "2310.09016", "Date": "Fri, 13 Oct 2023 11:25:41 ", "Title": "A Spatial-Temporal Dual-Mode Mixed Flow Network for Panoramic Video Salient Object Detection", "Authors": ["Xiaolei Chen", "Pengcheng Zhang", "Zelong Du", "Ishfaq Ahmad"], "Categories": "cs.CV cs.AI"}, "abstract": "Salient object detection (SOD) in panoramic video is still in the initial exploration stage. The indirect application of 2D video SOD method to the detection of salient objects in panoramic video has many unmet challenges, such as low detection accuracy, high model complexity, and poor generalization performance. To overcome these hurdles, we design an Inter-Layer Attention (ILA) module, an Inter-Layer weight (ILW) module, and a Bi-Modal Attention (BMA) module. Based on these modules, we propose a Spatial-Temporal Dual-Mode Mixed Flow Network (STDMMF-Net) that exploits the spatial flow of panoramic video and the corresponding optical flow for SOD. First, the ILA module calculates the attention between adjacent level features of consecutive frames of panoramic video to improve the accuracy of extracting salient object features from the spatial flow. Then, the ILW module quantifies the salient object information contained in the features of each level to improve the fusion efficiency of the features of each level in the mixed flow. Finally, the BMA module improves the detection accuracy of STDMMF-Net. A large number of subjective and objective experimental results testify that the proposed method demonstrates better detection accuracy than the state-of-the-art (SOTA) methods. Moreover, the comprehensive performance of the proposed method is better in terms of memory required for model inference, testing time, complexity, and generalization performance.", "url": "https://arxiv.org/abs/2310.09016"}, {"metadata": {"arXiv": "2310.09114", "Date": "Fri, 13 Oct 2023 14:00:49 ", "Title": "Timestamp-supervised Wearable-based Activity Segmentation and Recognition with Contrastive Learning and Order-Preserving Optimal Transport", "Authors": ["Songpengcheng Xia", "Lei Chu", "Ling Pei", "Jiarui Yang", "Wenxian Yu", "Robert C. Qiu"], "Categories": "cs.CV cs.AI", "Comments": ["Under Review (submitted to IEEE TMC)"]}, "abstract": "Human activity recognition (HAR) with wearables is one of the serviceable technologies in ubiquitous and mobile computing applications. The sliding-window scheme is widely adopted while suffering from the multi-class windows problem. As a result, there is a growing focus on joint segmentation and recognition with deep-learning methods, aiming at simultaneously dealing with HAR and time-series segmentation issues. However, obtaining the full activity annotations of wearable data sequences is resource-intensive or time-consuming, while unsupervised methods yield poor performance. To address these challenges, we propose a novel method for joint activity segmentation and recognition with timestamp supervision, in which only a single annotated sample is needed in each activity segment. However, the limited information of sparse annotations exacerbates the gap between recognition and segmentation tasks, leading to sub-optimal model performance. Therefore, the prototypes are estimated by class-activation maps to form a sample-to-prototype contrast module for well-structured embeddings. Moreover, with the optimal transport theory, our approach generates the sample-level pseudo-labels that take advantage of unlabeled data between timestamp annotations for further performance improvement. Comprehensive experiments on four public HAR datasets demonstrate that our model trained with timestamp supervision is superior to the state-of-the-art weakly-supervised methods and achieves comparable performance to the fully-supervised approaches.", "url": "https://arxiv.org/abs/2310.09114"}, {"metadata": {"arXiv": "2310.09170", "Date": "Fri, 13 Oct 2023 15:03:21 ", "Title": "mnmDTW: An extension to Dynamic Time Warping for Camera-based Movement Error Localization", "Authors": ["Sebastian Dill and Maurice Rohr"], "Categories": "cs.CV cs.AI", "Comments": ["Poster Prague 2023 Conference", "4 pages"]}, "abstract": "In this proof of concept, we use Computer Vision (CV) methods to extract pose information out of exercise videos. We then employ a modified version of Dynamic Time Warping (DTW) to calculate the deviation from a gold standard execution of the exercise. Specifically, we calculate the distance between each body part individually to get a more precise measure for exercise accuracy. We can show that exercise mistakes are clearly visible, identifiable and localizable through this metric.", "url": "https://arxiv.org/abs/2310.09170"}, {"metadata": {"arXiv": "2310.08901", "Date": "Fri, 13 Oct 2023 07:15:32 ", "Title": "Welfare Diplomacy: Benchmarking Language Model Cooperation", "Authors": ["Gabriel Mukobi", "Hannah Erlebach", "Niklas Lauffer", "Lewis Hammond", "Alan Chan", "Jesse Clifton"], "Categories": "cs.MA cs.AI cs.CL"}, "abstract": "The growing capabilities and increasingly widespread deployment of AI systems necessitate robust benchmarks for measuring their cooperative capabilities. Unfortunately, most multi-agent benchmarks are either zero-sum or purely cooperative, providing limited opportunities for such measurements. We introduce a general-sum variant of the zero-sum board game Diplomacy -- called Welfare Diplomacy -- in which players must balance investing in military conquest and domestic welfare. We argue that Welfare Diplomacy facilitates both a clearer assessment of and stronger training incentives for cooperative capabilities. Our contributions are: (1) proposing the Welfare Diplomacy rules and implementing them via an open-source Diplomacy engine; (2) constructing baseline agents using zero-shot prompted language models; and (3) conducting experiments where we find that baselines using state-of-the-art models attain high social welfare but are exploitable. Our work aims to promote societal safety by aiding researchers in developing and assessing multi-agent AI systems. Code to evaluate Welfare Diplomacy and reproduce our experiments is available at https://github.com/mukobi/welfare-diplomacy.", "url": "https://arxiv.org/abs/2310.08901"}, {"metadata": {"arXiv": "2310.08809", "Date": "Fri, 13 Oct 2023 01:36:46 ", "Title": "DexCatch: Learning to Catch Arbitrary Objects with Dexterous Hands", "Authors": ["Fengbo Lan", "Shengjie Wang", "Yunzhe Zhang", "Haotian Xu", "Oluwatosin Oseni", "Yang Gao", "Tao Zhang"], "Categories": "cs.RO cs.AI"}, "abstract": "Achieving human-like dexterous manipulation remains a crucial area of research in robotics. Current research focuses on improving the success rate of pick-and-place tasks. Compared with pick-and-place, throw-catching behavior has the potential to increase picking speed without transporting objects to their destination. However, dynamic dexterous manipulation poses a major challenge for stable control due to a large number of dynamic contacts. In this paper, we propose a Stability-Constrained Reinforcement Learning (SCRL) algorithm to learn to catch diverse objects with dexterous hands. The SCRL algorithm outperforms baselines by a large margin, and the learned policies show strong zero-shot transfer performance on unseen objects. Remarkably, even though the object in a hand facing sideward is extremely unstable due to the lack of support from the palm, our method can still achieve a high level of success in the most challenging task. Video demonstrations of learned behaviors and the code can be found on the supplementary website.", "url": "https://arxiv.org/abs/2310.08809"}, {"metadata": {"arXiv": "2310.08830", "Date": "Fri, 13 Oct 2023 02:57:35 ", "Title": "Urban Drone Navigation: Autoencoder Learning Fusion for Aerodynamics", "Authors": ["Jiaohao Wu", "Yang Ye", "Jing Du"], "Categories": "cs.RO cs.AI", "Comments": ["47 pages"]}, "abstract": "Drones are vital for urban emergency search and rescue (SAR) due to the challenges of navigating dynamic environments with obstacles like buildings and wind. This paper presents a method that combines multi-objective reinforcement learning (MORL) with a convolutional autoencoder to improve drone navigation in urban SAR. The approach uses MORL to achieve multiple goals and the autoencoder for cost-effective wind simulations. By utilizing imagery data of urban layouts, the drone can autonomously make navigation decisions, optimize paths, and counteract wind effects without traditional sensors. Tested on a New York City model, this method enhances drone SAR operations in complex urban settings.", "url": "https://arxiv.org/abs/2310.08830"}, {"metadata": {"arXiv": "2310.09053", "Date": "Fri, 13 Oct 2023 12:22:31 ", "Title": "DATT: Deep Adaptive Trajectory Tracking for Quadrotor Control", "Authors": ["Kevin Huang", "Rwik Rana", "Alexander Spitzer", "Guanya Shi", "Byron Boots"], "Categories": "cs.RO cs.AI cs.SY eess.SY"}, "abstract": "Precise arbitrary trajectory tracking for quadrotors is challenging due to unknown nonlinear dynamics, trajectory infeasibility, and actuation limits. To tackle these challenges, we present Deep Adaptive Trajectory Tracking (DATT), a learning-based approach that can precisely track arbitrary, potentially infeasible trajectories in the presence of large disturbances in the real world. DATT builds on a novel feedforward-feedback-adaptive control structure trained in simulation using reinforcement learning. When deployed on real hardware, DATT is augmented with a disturbance estimator using L1 adaptive control in closed-loop, without any fine-tuning. DATT significantly outperforms competitive adaptive nonlinear and model predictive controllers for both feasible smooth and infeasible trajectories in unsteady wind fields, including challenging scenarios where baselines completely fail. Moreover, DATT can efficiently run online with an inference time less than 3.2 ms, less than 1/4 of the adaptive nonlinear model predictive control baseline", "url": "https://arxiv.org/abs/2310.09053"}, {"metadata": {"arXiv": "2310.09069", "Date": "Fri, 13 Oct 2023 12:42:54 ", "Title": "ImageManip: Image-based Robotic Manipulation with Affordance-guided Next View Selection", "Authors": ["Xiaoqi Li", "Yanzi Wang", "Yan Shen", "Ponomarenko Iaroslav", "Haoran Lu", "Qianxu Wang", "Boshi An", "Jiaming Liu", "Hao Dong"], "Categories": "cs.RO cs.AI"}, "abstract": "In the realm of future home-assistant robots, 3D articulated object manipulation is essential for enabling robots to interact with their environment. Many existing studies make use of 3D point clouds as the primary input for manipulation policies. However, this approach encounters challenges due to data sparsity and the significant cost associated with acquiring point cloud data, which can limit its practicality. In contrast, RGB images offer high-resolution observations using cost effective devices but lack spatial 3D geometric information. To overcome these limitations, we present a novel image-based robotic manipulation framework. This framework is designed to capture multiple perspectives of the target object and infer depth information to complement its geometry. Initially, the system employs an eye-on-hand RGB camera to capture an overall view of the target object. It predicts the initial depth map and a coarse affordance map. The affordance map indicates actionable areas on the object and serves as a constraint for selecting subsequent viewpoints. Based on the global visual prior, we adaptively identify the optimal next viewpoint for a detailed observation of the potential manipulation success area. We leverage geometric consistency to fuse the views, resulting in a refined depth map and a more precise affordance map for robot manipulation decisions. By comparing with prior works that adopt point clouds or RGB images as inputs, we demonstrate the effectiveness and practicality of our method. In the project webpage (https://sites.google.com/view/imagemanip), real world experiments further highlight the potential of our method for practical deployment.", "url": "https://arxiv.org/abs/2310.09069"}, {"metadata": {"arXiv": "2310.08731", "Date": "Thu, 12 Oct 2023 21:38:07 ", "Title": "A Simple Way to Incorporate Novelty Detection in World Models", "Authors": ["Geigh Zollicoffer", "Kenneth Eaton", "Jonathan Balloch", "Julia Kim", "Mark O. Riedl", "Robert Wright"], "Categories": "cs.AI cs.LG cs.SY eess.SY"}, "abstract": "Reinforcement learning (RL) using world models has found significant recent successes. However, when a sudden change to world mechanics or properties occurs then agent performance and reliability can dramatically decline. We refer to the sudden change in visual properties or state transitions as {\\em novelties}. Implementing novelty detection within generated world model frameworks is a crucial task for protecting the agent when deployed. In this paper, we propose straightforward bounding approaches to incorporate novelty detection into world model RL agents, by utilizing the misalignment of the world model's hallucinated states and the true observed states as an anomaly score. We first provide an ontology of novelty detection relevant to sequential decision making, then we provide effective approaches to detecting novelties in a distribution of transitions learned by an agent in a world model. Finally, we show the advantage of our work in a novel environment compared to traditional machine learning novelty detection methods as well as currently accepted RL focused novelty detection algorithms.", "url": "https://arxiv.org/abs/2310.08731"}, {"metadata": {"arXiv": "2310.09270", "Date": "Fri, 13 Oct 2023 17:35:04 ", "Title": "Retro-fallback: retrosynthetic planning in an uncertain world", "Authors": ["Austin Tripp", "Krzysztof Maziarz", "Sarah Lewis", "Marwin Segler", "Jos\\'e Miguel Hern\\'andez-Lobato"], "Categories": "cs.AI cs.LG", "Comments": ["39 pages (including appendices). Currently undergoing peer review"]}, "abstract": "Retrosynthesis is the task of proposing a series of chemical reactions to create a desired molecule from simpler, buyable molecules. While previous works have proposed algorithms to find optimal solutions for a range of metrics (e.g. shortest, lowest-cost), these works generally overlook the fact that we have imperfect knowledge of the space of possible reactions, meaning plans created by the algorithm may not work in a laboratory. In this paper we propose a novel formulation of retrosynthesis in terms of stochastic processes to account for this uncertainty. We then propose a novel greedy algorithm called retro-fallback which maximizes the probability that at least one synthesis plan can be executed in the lab. Using in-silico benchmarks we demonstrate that retro-fallback generally produces better sets of synthesis plans than the popular MCTS and retro* algorithms.", "url": "https://arxiv.org/abs/2310.09270"}, {"metadata": {"arXiv": "2310.08743", "Date": "Thu, 12 Oct 2023 22:09:53 ", "Title": "Development and Validation of a Deep Learning-Based Microsatellite Instability Predictor from Prostate Cancer Whole-Slide Images", "Authors": ["Qiyuan Hu", "Abbas A. Rizvi", "Geoffery Schau", "Kshitij Ingale", "Yoni Muller", "Rachel Baits", "Sebastian Pretzer", "A\\\"icha BenTaieb", "Abigail Gordhamer", "Roberto Nussenzveig", "Adam Cole", "Matthew O. Leavitt", "Rohan P. Joshi", "Nike Beaubier", "Martin C. Stumpe", "Kunal Nagpal"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Microsatellite instability-high (MSI-H) is a tumor agnostic biomarker for immune checkpoint inhibitor therapy. However, MSI status is not routinely tested in prostate cancer, in part due to low prevalence and assay cost. As such, prediction of MSI status from hematoxylin and eosin (H&E) stained whole-slide images (WSIs) could identify prostate cancer patients most likely to benefit from confirmatory testing and becoming eligible for immunotherapy. Prostate biopsies and surgical resections from de-identified records of consecutive prostate cancer patients referred to our institution were analyzed. Their MSI status was determined by next generation sequencing. Patients before a cutoff date were split into an algorithm development set (n=4015, MSI-H 1.8%) and a paired validation set (n=173, MSI-H 19.7%) that consisted of two serial sections from each sample, one stained and scanned internally and the other at an external site. Patients after the cutoff date formed the temporal validation set (n=1350, MSI-H 2.3%). Attention-based multiple instance learning models were trained to predict MSI-H from H&E WSIs. The MSI-H predictor achieved area under the receiver operating characteristic curve values of 0.78 (95% CI [0.69-0.86]), 0.72 (95% CI [0.63-0.81]), and 0.72 (95% CI [0.62-0.82]) on the internally prepared, externally prepared, and temporal validation sets, respectively. While MSI-H status is significantly correlated with Gleason score, the model remained predictive within each Gleason score subgroup. In summary, we developed and validated an AI-based MSI-H diagnostic model on a large real-world cohort of routine H&E slides, which effectively generalized to externally stained and scanned samples and a temporally independent validation cohort. This algorithm has the potential to direct prostate cancer patients toward immunotherapy and to identify MSI-H cases secondary to Lynch syndrome.", "url": "https://arxiv.org/abs/2310.08743"}, {"metadata": {"arXiv": "2310.09139", "Date": "Fri, 13 Oct 2023 14:27:21 ", "Title": "The Consensus Game: Language Model Generation via Equilibrium Search", "Authors": ["Athul Paul Jacob", "Yikang Shen", "Gabriele Farina and Jacob Andreas"], "Categories": "cs.GT cs.AI cs.CL cs.LG"}, "abstract": "When applied to question answering and other text generation tasks, language models (LMs) may be queried generatively (by sampling answers from their output distribution) or discriminatively (by using them to score or rank a set of candidate outputs). These procedures sometimes yield very different predictions. How do we reconcile mutually incompatible scoring procedures to obtain coherent LM predictions? We introduce a new, a training-free, game-theoretic procedure for language model decoding. Our approach casts language model decoding as a regularized imperfect-information sequential signaling game - which we term the CONSENSUS GAME - in which a GENERATOR seeks to communicate an abstract correctness parameter using natural language sentences to a DISCRIMINATOR. We develop computational procedures for finding approximate equilibria of this game, resulting in a decoding algorithm we call EQUILIBRIUM-RANKING. Applied to a large number of tasks (including reading comprehension, commonsense reasoning, mathematical problem-solving, and dialog), EQUILIBRIUM-RANKING consistently, and sometimes substantially, improves performance over existing LM decoding procedures - on multiple benchmarks, we observe that applying EQUILIBRIUM-RANKING to LLaMA-7B outperforms the much larger LLaMA-65B and PaLM-540B models. These results highlight the promise of game-theoretic tools for addressing fundamental challenges of truthfulness and consistency in LMs.", "url": "https://arxiv.org/abs/2310.09139"}, {"metadata": {"arXiv": "2310.08644", "Date": "Thu, 12 Oct 2023 18:09:33 ", "Title": "A Mass-Conserving-Perceptron for Machine Learning-Based Modeling of Geoscientific Systems", "Authors": ["Yuan-Heng Wang", "Hoshin V. Gupta"], "Categories": "cs.LG cs.AI", "Comments": ["60 pages", "7 figures", "10 figures", "and tables in supplementary materials"]}, "abstract": "Although decades of effort have been devoted to building Physical-Conceptual (PC) models for predicting the time-series evolution of geoscientific systems, recent work shows that Machine Learning (ML) based Gated Recurrent Neural Network technology can be used to develop models that are much more accurate. However, the difficulty of extracting physical understanding from ML-based models complicates their utility for enhancing scientific knowledge regarding system structure and function. Here, we propose a physically-interpretable Mass Conserving Perceptron (MCP) as a way to bridge the gap between PC-based and ML-based modeling approaches. The MCP exploits the inherent isomorphism between the directed graph structures underlying both PC models and GRNNs to explicitly represent the mass-conserving nature of physical processes while enabling the functional nature of such processes to be directly learned (in an interpretable manner) from available data using off-the-shelf ML technology. As a proof of concept, we investigate the functional expressivity (capacity) of the MCP, explore its ability to parsimoniously represent the rainfall-runoff (RR) dynamics of the Leaf River Basin, and demonstrate its utility for scientific hypothesis testing. To conclude, we discuss extensions of the concept to enable ML-based physical-conceptual representation of the coupled nature of mass-energy-information flows through geoscientific systems.", "url": "https://arxiv.org/abs/2310.08644"}, {"metadata": {"arXiv": "2310.08650", "Date": "Thu, 12 Oct 2023 18:23:06 ", "Title": "Electrical Grid Anomaly Detection via Tensor Decomposition", "Authors": ["Alexander Most", "Maksim Eren", "Nigel Lawrence", "Boian Alexandrov"], "Categories": "cs.LG cs.AI", "Comments": ["8 pages", "2 figures. In IEEE Military Communications Conference", "Artificial Intelligence for Cyber Workshop (MILCOM)", "2023"]}, "abstract": "Supervisory Control and Data Acquisition (SCADA) systems often serve as the nervous system for substations within power grids. These systems facilitate real-time monitoring, data acquisition, control of equipment, and ensure smooth and efficient operation of the substation and its connected devices. Previous work has shown that dimensionality reduction-based approaches, such as Principal Component Analysis (PCA), can be used for accurate identification of anomalies in SCADA systems. While not specifically applied to SCADA, non-negative matrix factorization (NMF) has shown strong results at detecting anomalies in wireless sensor networks. These unsupervised approaches model the normal or expected behavior and detect the unseen types of attacks or anomalies by identifying the events that deviate from the expected behavior. These approaches; however, do not model the complex and multi-dimensional interactions that are naturally present in SCADA systems. Differently, non-negative tensor decomposition is a powerful unsupervised machine learning (ML) method that can model the complex and multi-faceted activity details of SCADA events. In this work, we novelly apply the tensor decomposition method Canonical Polyadic Alternating Poisson Regression (CP-APR) with a probabilistic framework, which has previously shown state-of-the-art anomaly detection results on cyber network data, to identify anomalies in SCADA systems. We showcase that the use of statistical behavior analysis of SCADA communication with tensor decomposition improves the specificity and accuracy of identifying anomalies in electrical grid systems. In our experiments, we model real-world SCADA system data collected from the electrical grid operated by Los Alamos National Laboratory (LANL) which provides transmission and distribution service through a partnership with Los Alamos County, and detect synthetically generated anomalies.", "url": "https://arxiv.org/abs/2310.08650"}, {"metadata": {"arXiv": "2310.08653", "Date": "Thu, 12 Oct 2023 18:26:23 ", "Title": "Analyzing Textual Data for Fatality Classification in Afghanistan's Armed Conflicts: A BERT Approach", "Authors": ["Hikmatullah Mohammadi", "Ziaullah Momand", "Parwin Habibi", "Nazifa Ramaki", "Bibi Storay Fazli", "Sayed Zobair Rohany", "Iqbal Samsoor"], "Categories": "cs.LG cs.AI", "Comments": ["6 pages", "4 figures", "2 tables"]}, "abstract": "Afghanistan has witnessed many armed conflicts throughout history, especially in the past 20 years; these events have had a significant impact on human lives, including military and civilians, with potential fatalities. In this research, we aim to leverage state-of-the-art machine learning techniques to classify the outcomes of Afghanistan armed conflicts to either fatal or non-fatal based on their textual descriptions provided by the Armed Conflict Location & Event Data Project (ACLED) dataset. The dataset contains comprehensive descriptions of armed conflicts in Afghanistan that took place from August 2021 to March 2023. The proposed approach leverages the power of BERT (Bidirectional Encoder Representations from Transformers), a cutting-edge language representation model in natural language processing. The classifier utilizes the raw textual description of an event to estimate the likelihood of the event resulting in a fatality. The model achieved impressive performance on the test set with an accuracy of 98.8%, recall of 98.05%, precision of 99.6%, and an F1 score of 98.82%. These results highlight the model's robustness and indicate its potential impact in various areas such as resource allocation, policymaking, and humanitarian aid efforts in Afghanistan. The model indicates a machine learning-based text classification approach using the ACLED dataset to accurately classify fatality in Afghanistan armed conflicts, achieving robust performance with the BERT model and paving the way for future endeavors in predicting event severity in Afghanistan.", "url": "https://arxiv.org/abs/2310.08653"}, {"metadata": {"arXiv": "2310.08660", "Date": "Thu, 12 Oct 2023 18:36:36 ", "Title": "Learning RL-Policies for Joint Beamforming Without Exploration: A Batch Constrained Off-Policy Approach", "Authors": ["Heasung Kim and Sravan Ankireddy"], "Categories": "cs.LG cs.AI eess.SP", "Comments": ["10 pages", "8 figures"]}, "abstract": "In this project, we consider the problem of network parameter optimization for rate maximization. We frame this as a joint optimization problem of power control, beam forming, and interference cancellation. We consider the setting where multiple Base Stations (BSs) are communicating with multiple user equipments (UEs). Because of the exponential computational complexity of brute force search, we instead solve this non-convex optimization problem using deep reinforcement learning (RL) techniques. The modern communication systems are notorious for their difficulty in exactly modeling their behaviour. This limits us in using RL based algorithms as interaction with the environment is needed for the agent to explore and learn efficiently. Further, it is ill advised to deploy the algorithm in real world for exploration and learning because of the high cost of failure. In contrast to the previous RL-based solutions proposed, such as deep-Q network (DQN) based control, we propose taking an offline model based approach. We specifically consider discrete batch constrained deep Q-learning (BCQ) and show that performance similar to DQN can be acheived with only a fraction of the data and without the need for exploration. This results in maximizing sample efficiency and minimizing risk in the deployment of a new algorithm to commercial networks. We provide the entire resource of the project, including code and data, at the following link: https://github.com/Heasung-Kim/ safe-rl-deployment-for-5g.", "url": "https://arxiv.org/abs/2310.08660"}, {"metadata": {"arXiv": "2310.08677", "Date": "Thu, 12 Oct 2023 19:27:43 ", "Title": "GDL-DS: A Benchmark for Geometric Deep Learning under Distribution Shifts", "Authors": ["Deyu Zou", "Shikun Liu", "Siqi Miao", "Victor Fung", "Shiyu Chang", "Pan Li"], "Categories": "cs.LG cs.AI", "Comments": ["Code and data are available at https://github.com/Graph-COM/GDL_DS"]}, "abstract": "Geometric deep learning (GDL) has gained significant attention in various scientific fields, chiefly for its proficiency in modeling data with intricate geometric structures. Yet, very few works have delved into its capability of tackling the distribution shift problem, a prevalent challenge in many relevant applications. To bridge this gap, we propose GDL-DS, a comprehensive benchmark designed for evaluating the performance of GDL models in scenarios with distribution shifts. Our evaluation datasets cover diverse scientific domains from particle physics and materials science to biochemistry, and encapsulate a broad spectrum of distribution shifts including conditional, covariate, and concept shifts. Furthermore, we study three levels of information access from the out-of-distribution (OOD) testing data, including no OOD information, only OOD features without labels, and OOD features with a few labels. Overall, our benchmark results in 30 different experiment settings, and evaluates 3 GDL backbones and 11 learning algorithms in each setting. A thorough analysis of the evaluation results is provided, poised to illuminate insights for DGL researchers and domain practitioners who are to use DGL in their applications.", "url": "https://arxiv.org/abs/2310.08677"}, {"metadata": {"arXiv": "2310.08683", "Date": "Thu, 12 Oct 2023 19:42:42 ", "Title": "Virtual Augmented Reality for Atari Reinforcement Learning", "Authors": ["Christian A. Schiller"], "Categories": "cs.LG cs.AI", "Comments": ["20 pages (thereof 13 in appendix)", "4 figures", "15 tables (thereof 12 in appendix)", "12 Atari games explored"]}, "abstract": "Reinforcement Learning (RL) has achieved significant milestones in the gaming domain, most notably Google DeepMind's AlphaGo defeating human Go champion Ken Jie. This victory was also made possible through the Atari Learning Environment (ALE): The ALE has been foundational in RL research, facilitating significant RL algorithm developments such as AlphaGo and others. In current Atari video game RL research, RL agents' perceptions of its environment is based on raw pixel data from the Atari video game screen with minimal image preprocessing. Contrarily, cutting-edge ML research, external to the Atari video game RL research domain, is focusing on enhancing image perception. A notable example is Meta Research's \"Segment Anything Model\" (SAM), a foundation model capable of segmenting images without prior training (zero-shot). This paper addresses a novel methodical question: Can state-of-the-art image segmentation models such as SAM improve the performance of RL agents playing Atari video games? The results suggest that SAM can serve as a \"virtual augmented reality\" for the RL agent, boosting its Atari video game playing performance under certain conditions. Comparing RL agent performance results from raw and augmented pixel inputs provides insight into these conditions. Although this paper was limited by computational constraints, the findings show improved RL agent performance for augmented pixel inputs and can inform broader research agendas in the domain of \"virtual augmented reality for video game playing RL agents\".", "url": "https://arxiv.org/abs/2310.08683"}, {"metadata": {"arXiv": "2310.08702", "Date": "Thu, 12 Oct 2023 20:20:21 ", "Title": "ELDEN: Exploration via Local Dependencies", "Authors": ["Jiaheng Hu", "Zizhao Wang", "Peter Stone", "Roberto Martin-Martin"], "Categories": "cs.LG cs.AI cs.RO", "Comments": ["Accepted to NeurIPS 2023"]}, "abstract": "Tasks with large state space and sparse rewards present a longstanding challenge to reinforcement learning. In these tasks, an agent needs to explore the state space efficiently until it finds a reward. To deal with this problem, the community has proposed to augment the reward function with intrinsic reward, a bonus signal that encourages the agent to visit interesting states. In this work, we propose a new way of defining interesting states for environments with factored state spaces and complex chained dependencies, where an agent's actions may change the value of one entity that, in order, may affect the value of another entity. Our insight is that, in these environments, interesting states for exploration are states where the agent is uncertain whether (as opposed to how) entities such as the agent or objects have some influence on each other. We present ELDEN, Exploration via Local DepENdencies, a novel intrinsic reward that encourages the discovery of new interactions between entities. ELDEN utilizes a novel scheme -- the partial derivative of the learned dynamics to model the local dependencies between entities accurately and computationally efficiently. The uncertainty of the predicted dependencies is then used as an intrinsic reward to encourage exploration toward new interactions. We evaluate the performance of ELDEN on four different domains with complex dependencies, ranging from 2D grid worlds to 3D robotic tasks. In all domains, ELDEN correctly identifies local dependencies and learns successful policies, significantly outperforming previous state-of-the-art exploration methods.", "url": "https://arxiv.org/abs/2310.08702"}, {"metadata": {"arXiv": "2310.08716", "Date": "Thu, 12 Oct 2023 20:54:10 ", "Title": "Transformer Choice Net: A Transformer Neural Network for Choice Prediction", "Authors": ["Hanzhao Wang", "Xiaocheng Li", "Kalyan Talluri"], "Categories": "cs.LG cs.AI"}, "abstract": "Discrete-choice models, such as Multinomial Logit, Probit, or Mixed-Logit, are widely used in Marketing, Economics, and Operations Research: given a set of alternatives, the customer is modeled as choosing one of the alternatives to maximize a (latent) utility function. However, extending such models to situations where the customer chooses more than one item (such as in e-commerce shopping) has proven problematic. While one can construct reasonable models of the customer's behavior, estimating such models becomes very challenging because of the combinatorial explosion in the number of possible subsets of items. In this paper we develop a transformer neural network architecture, the Transformer Choice Net, that is suitable for predicting multiple choices. Transformer networks turn out to be especially suitable for this task as they take into account not only the features of the customer and the items but also the context, which in this case could be the assortment as well as the customer's past choices. On a range of benchmark datasets, our architecture shows uniformly superior out-of-sample prediction performance compared to the leading models in the literature, without requiring any custom modeling or tuning for each instance.", "url": "https://arxiv.org/abs/2310.08716"}, {"metadata": {"arXiv": "2310.08751", "Date": "Thu, 12 Oct 2023 22:32:00 ", "Title": "Constrained Bayesian Optimization with Adaptive Active Learning of Unknown Constraints", "Authors": ["Fengxue Zhang", "Zejie Zhu", "Yuxin Chen"], "Categories": "cs.LG cs.AI"}, "abstract": "Optimizing objectives under constraints, where both the objectives and constraints are black box functions, is a common scenario in real-world applications such as scientific experimental design, design of medical therapies, and industrial process optimization. One popular approach to handling these complex scenarios is Bayesian Optimization (BO). In terms of theoretical behavior, BO is relatively well understood in the unconstrained setting, where its principles have been well explored and validated. However, when it comes to constrained Bayesian optimization (CBO), the existing framework often relies on heuristics or approximations without the same level of theoretical guarantees. In this paper, we delve into the theoretical and practical aspects of constrained Bayesian optimization, where the objective and constraints can be independently evaluated and are subject to noise. By recognizing that both the objective and constraints can help identify high-confidence regions of interest (ROI), we propose an efficient CBO framework that intersects the ROIs identified from each aspect to determine the general ROI. The ROI, coupled with a novel acquisition function that adaptively balances the optimization of the objective and the identification of feasible regions, enables us to derive rigorous theoretical justifications for its performance. We showcase the efficiency and robustness of our proposed CBO framework through empirical evidence and discuss the fundamental challenge of deriving practical regret bounds for CBO algorithms.", "url": "https://arxiv.org/abs/2310.08751"}, {"metadata": {"arXiv": "2310.08762", "Date": "Thu, 12 Oct 2023 23:06:52 ", "Title": "Stabilizing Subject Transfer in EEG Classification with Divergence Estimation", "Authors": ["Niklas Smedemark-Margulies", "Ye Wang", "Toshiaki Koike-Akino", "Jing Liu", "Kieran Parsons", "Yunus Bicer", "Deniz Erdogmus"], "Categories": "cs.LG cs.AI cs.HC eess.SP stat.ML", "Comments": ["16 pages", "5 figures"]}, "abstract": "Classification models for electroencephalogram (EEG) data show a large decrease in performance when evaluated on unseen test sub jects. We reduce this performance decrease using new regularization techniques during model training. We propose several graphical models to describe an EEG classification task. From each model, we identify statistical relationships that should hold true in an idealized training scenario (with infinite data and a globally-optimal model) but that may not hold in practice. We design regularization penalties to enforce these relationships in two stages. First, we identify suitable proxy quantities (divergences such as Mutual Information and Wasserstein-1) that can be used to measure statistical independence and dependence relationships. Second, we provide algorithms to efficiently estimate these quantities during training using secondary neural network models. We conduct extensive computational experiments using a large benchmark EEG dataset, comparing our proposed techniques with a baseline method that uses an adversarial classifier. We find our proposed methods significantly increase balanced accuracy on test subjects and decrease overfitting. The proposed methods exhibit a larger benefit over a greater range of hyperparameters than the baseline method, with only a small computational cost at training time. These benefits are largest when used for a fixed training period, though there is still a significant benefit for a subset of hyperparameters when our techniques are used in conjunction with early stopping regularization.", "url": "https://arxiv.org/abs/2310.08762"}, {"metadata": {"arXiv": "2310.08782", "Date": "Fri, 13 Oct 2023 00:07:49 ", "Title": "Selectivity Drives Productivity: Efficient Dataset Pruning for Enhanced Transfer Learning", "Authors": ["Yihua Zhang", "Yimeng Zhang", "Aochuan Chen", "Jinghan Jia", "Jiancheng Liu", "Gaowen Liu", "Mingyi Hong", "Shiyu Chang", "Sijia Liu"], "Categories": "cs.LG cs.AI", "Comments": ["Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS 2023)"]}, "abstract": "Massive data is often considered essential for deep learning applications, but it also incurs significant computational and infrastructural costs. Therefore, dataset pruning (DP) has emerged as an effective way to improve data efficiency by identifying and removing redundant training samples without sacrificing performance. In this work, we aim to address the problem of DP for transfer learning, i.e., how to prune a source dataset for improved pretraining efficiency and lossless finetuning accuracy on downstream target tasks. To our best knowledge, the problem of DP for transfer learning remains open, as previous studies have primarily addressed DP and transfer learning as separate problems. By contrast, we establish a unified viewpoint to integrate DP with transfer learning and find that existing DP methods are not suitable for the transfer learning paradigm. We then propose two new DP methods, label mapping and feature mapping, for supervised and self-supervised pretraining settings respectively, by revisiting the DP problem through the lens of source-target domain mapping. Furthermore, we demonstrate the effectiveness of our approach on numerous transfer learning tasks. We show that source data classes can be pruned by up to 40% ~ 80% without sacrificing downstream performance, resulting in a significant 2 ~ 5 times speed-up during the pretraining stage. Besides, our proposal exhibits broad applicability and can improve other computationally intensive transfer learning techniques, such as adversarial pretraining. Codes are available at https://github.com/OPTML-Group/DP4TL.", "url": "https://arxiv.org/abs/2310.08782"}, {"metadata": {"arXiv": "2310.08790", "Date": "Fri, 13 Oct 2023 00:25:21 ", "Title": "Price of Stability in Quality-Aware Federated Learning", "Authors": ["Yizhou Yan", "Xinyu Tang", "Chao Huang", "Ming Tang"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted to IEEE GLOBECOM 2023"]}, "abstract": "Federated Learning (FL) is a distributed machine learning scheme that enables clients to train a shared global model without exchanging local data. The presence of label noise can severely degrade the FL performance, and some existing studies have focused on algorithm design for label denoising. However, they ignored the important issue that clients may not apply costly label denoising strategies due to them being self-interested and having heterogeneous valuations on the FL performance. To fill this gap, we model the clients' interactions as a novel label denoising game and characterize its equilibrium. We also analyze the price of stability, which quantifies the difference in the system performance (e.g., global model accuracy, social welfare) between the equilibrium outcome and the socially optimal solution. We prove that the equilibrium outcome always leads to a lower global model accuracy than the socially optimal solution does. We further design an efficient algorithm to compute the socially optimal solution. Numerical experiments on MNIST dataset show that the price of stability increases as the clients' data become noisier, calling for an effective incentive mechanism.", "url": "https://arxiv.org/abs/2310.08790"}, {"metadata": {"arXiv": "2310.08800", "Date": "Fri, 13 Oct 2023 01:18:41 ", "Title": "DDMT: Denoising Diffusion Mask Transformer Models for Multivariate Time Series Anomaly Detection", "Authors": ["Chaocheng Yang and Tingyin Wang and Xuanhui Yan"], "Categories": "cs.LG cs.AI", "Comments": ["16 pages", "9 figures"]}, "abstract": "Anomaly detection in multivariate time series has emerged as a crucial challenge in time series research, with significant research implications in various fields such as fraud detection, fault diagnosis, and system state estimation. Reconstruction-based models have shown promising potential in recent years for detecting anomalies in time series data. However, due to the rapid increase in data scale and dimensionality, the issues of noise and Weak Identity Mapping (WIM) during time series reconstruction have become increasingly pronounced. To address this, we introduce a novel Adaptive Dynamic Neighbor Mask (ADNM) mechanism and integrate it with the Transformer and Denoising Diffusion Model, creating a new framework for multivariate time series anomaly detection, named Denoising Diffusion Mask Transformer (DDMT). The ADNM module is introduced to mitigate information leakage between input and output features during data reconstruction, thereby alleviating the problem of WIM during reconstruction. The Denoising Diffusion Transformer (DDT) employs the Transformer as an internal neural network structure for Denoising Diffusion Model. It learns the stepwise generation process of time series data to model the probability distribution of the data, capturing normal data patterns and progressively restoring time series data by removing noise, resulting in a clear recovery of anomalies. To the best of our knowledge, this is the first model that combines Denoising Diffusion Model and the Transformer for multivariate time series anomaly detection. Experimental evaluations were conducted on five publicly available multivariate time series anomaly detection datasets. The results demonstrate that the model effectively identifies anomalies in time series data, achieving state-of-the-art performance in anomaly detection.", "url": "https://arxiv.org/abs/2310.08800"}, {"metadata": {"arXiv": "2310.08817", "Date": "Fri, 13 Oct 2023 02:06:52 ", "Title": "Exploring the relationship between response time sequence in scale answering process and severity of insomnia: a machine learning approach", "Authors": ["Zhao Su", "Rongxun Liu", "Keyin Zhou", "Xinru Wei", "Ning Wang", "Zexin Lin", "Yuanchen Xie", "Jie Wang", "Fei Wang", "Shenzhong Zhang", "Xizhe Zhang"], "Categories": "cs.LG cs.AI"}, "abstract": "Objectives: The study aims to investigate the relationship between insomnia and response time. Additionally, it aims to develop a machine learning model to predict the presence of insomnia in participants using response time data. Methods: A mobile application was designed to administer scale tests and collect response time data from 2729 participants. The relationship between symptom severity and response time was explored, and a machine learning model was developed to predict the presence of insomnia. Results: The result revealed a statistically significant difference (p<.001) in the total response time between participants with or without insomnia symptoms. A correlation was observed between the severity of specific insomnia aspects and response times at the individual questions level. The machine learning model demonstrated a high predictive accuracy of 0.743 in predicting insomnia symptoms based on response time data. Conclusions: These findings highlight the potential utility of response time data to evaluate cognitive and psychological measures, demonstrating the effectiveness of using response time as a diagnostic tool in the assessment of insomnia.", "url": "https://arxiv.org/abs/2310.08817"}, {"metadata": {"arXiv": "2310.08823", "Date": "Fri, 13 Oct 2023 02:38:35 ", "Title": "Distance-rank Aware Sequential Reward Learning for Inverse Reinforcement Learning with Sub-optimal Demonstrations", "Authors": ["Lu Li", "Yuxin Pan", "Ruobing Chen", "Jie Liu", "Zilin Wang", "Yu Liu", "Zhiheng Li"], "Categories": "cs.LG cs.AI"}, "abstract": "Inverse reinforcement learning (IRL) aims to explicitly infer an underlying reward function based on collected expert demonstrations. Considering that obtaining expert demonstrations can be costly, the focus of current IRL techniques is on learning a better-than-demonstrator policy using a reward function derived from sub-optimal demonstrations. However, existing IRL algorithms primarily tackle the challenge of trajectory ranking ambiguity when learning the reward function. They overlook the crucial role of considering the degree of difference between trajectories in terms of their returns, which is essential for further removing reward ambiguity. Additionally, it is important to note that the reward of a single transition is heavily influenced by the context information within the trajectory. To address these issues, we introduce the Distance-rank Aware Sequential Reward Learning (DRASRL) framework. Unlike existing approaches, DRASRL takes into account both the ranking of trajectories and the degrees of dissimilarity between them to collaboratively eliminate reward ambiguity when learning a sequence of contextually informed reward signals. Specifically, we leverage the distance between policies, from which the trajectories are generated, as a measure to quantify the degree of differences between traces. This distance-aware information is then used to infer embeddings in the representation space for reward learning, employing the contrastive learning technique. Meanwhile, we integrate the pairwise ranking loss function to incorporate ranking information into the latent features. Moreover, we resort to the Transformer architecture to capture the contextual dependencies within the trajectories in the latent space, leading to more accurate reward estimation. Through extensive experimentation, our DRASRL framework demonstrates significant performance improvements over previous SOTA methods.", "url": "https://arxiv.org/abs/2310.08823"}, {"metadata": {"arXiv": "2310.08866", "Date": "Fri, 13 Oct 2023 05:29:09 ", "Title": "Adaptivity and Modularity for Efficient Generalization Over Task Complexity", "Authors": ["Samira Abnar", "Omid Saremi", "Laurent Dinh", "Shantel Wilson", "Miguel Angel Bautista", "Chen Huang", "Vimal Thilak", "Etai Littwin", "Jiatao Gu", "Josh Susskind", "Samy Bengio"], "Categories": "cs.LG cs.AI"}, "abstract": "Can transformers generalize efficiently on problems that require dealing with examples with different levels of difficulty? We introduce a new task tailored to assess generalization over different complexities and present results that indicate that standard transformers face challenges in solving these tasks. These tasks are variations of pointer value retrieval previously introduced by Zhang et al. (2021). We investigate how the use of a mechanism for adaptive and modular computation in transformers facilitates the learning of tasks that demand generalization over the number of sequential computation steps (i.e., the depth of the computation graph). Based on our observations, we propose a transformer-based architecture called Hyper-UT, which combines dynamic function generation from hyper networks with adaptive depth from Universal Transformers. This model demonstrates higher accuracy and a fairer allocation of computational resources when generalizing to higher numbers of computation steps. We conclude that mechanisms for adaptive depth and modularity complement each other in improving efficient generalization concerning example complexity. Additionally, to emphasize the broad applicability of our findings, we illustrate that in a standard image recognition task, Hyper- UT's performance matches that of a ViT model but with considerably reduced computational demands (achieving over 70\\% average savings by effectively using fewer layers).", "url": "https://arxiv.org/abs/2310.08866"}, {"metadata": {"arXiv": "2310.08887", "Date": "Fri, 13 Oct 2023 06:43:11 ", "Title": "METRA: Scalable Unsupervised RL with Metric-Aware Abstraction", "Authors": ["Seohong Park", "Oleh Rybkin", "Sergey Levine"], "Categories": "cs.LG cs.AI cs.RO"}, "abstract": "Unsupervised pre-training strategies have proven to be highly effective in natural language processing and computer vision. Likewise, unsupervised reinforcement learning (RL) holds the promise of discovering a variety of potentially useful behaviors that can accelerate the learning of a wide array of downstream tasks. Previous unsupervised RL approaches have mainly focused on pure exploration and mutual information skill learning. However, despite the previous attempts, making unsupervised RL truly scalable still remains a major open challenge: pure exploration approaches might struggle in complex environments with large state spaces, where covering every possible transition is infeasible, and mutual information skill learning approaches might completely fail to explore the environment due to the lack of incentives. To make unsupervised RL scalable to complex, high-dimensional environments, we propose a novel unsupervised RL objective, which we call Metric-Aware Abstraction (METRA). Our main idea is, instead of directly covering the entire state space, to only cover a compact latent space $Z$ that is metrically connected to the state space $S$ by temporal distances. By learning to move in every direction in the latent space, METRA obtains a tractable set of diverse behaviors that approximately cover the state space, being scalable to high-dimensional environments. Through our experiments in five locomotion and manipulation environments, we demonstrate that METRA can discover a variety of useful behaviors even in complex, pixel-based environments, being the first unsupervised RL method that discovers diverse locomotion behaviors in pixel-based Quadruped and Humanoid. Our code and videos are available at https://seohong.me/projects/metra/", "url": "https://arxiv.org/abs/2310.08887"}, {"metadata": {"arXiv": "2310.08917", "Date": "Fri, 13 Oct 2023 07:40:12 ", "Title": "Relation-aware Ensemble Learning for Knowledge Graph Embedding", "Authors": ["Ling Yue", "Yongqi Zhang", "Quanming Yao", "Yong Li", "Xian Wu", "Ziheng Zhang", "Zhenxi Lin", "Yefeng Zheng"], "Categories": "cs.LG cs.AI cs.CL", "Comments": ["This short paper has been accepted by EMNLP 2023"]}, "abstract": "Knowledge graph (KG) embedding is a fundamental task in natural language processing, and various methods have been proposed to explore semantic patterns in distinctive ways. In this paper, we propose to learn an ensemble by leveraging existing methods in a relation-aware manner. However, exploring these semantics using relation-aware ensemble leads to a much larger search space than general ensemble methods. To address this issue, we propose a divide-search-combine algorithm RelEns-DSC that searches the relation-wise ensemble weights independently. This algorithm has the same computation cost as general ensemble methods but with much better performance. Experimental results on benchmark datasets demonstrate the effectiveness of the proposed method in efficiently searching relation-aware ensemble weights and achieving state-of-the-art embedding performance. The code is public at https://github.com/LARS-research/RelEns.", "url": "https://arxiv.org/abs/2310.08917"}, {"metadata": {"arXiv": "2310.08920", "Date": "Fri, 13 Oct 2023 07:44:05 ", "Title": "Embarrassingly Simple Text Watermarks", "Authors": ["Ryoma Sato", "Yuki Takezawa", "Han Bao", "Kenta Niwa", "Makoto Yamada"], "Categories": "cs.LG cs.AI cs.CR"}, "abstract": "We propose Easymark, a family of embarrassingly simple yet effective watermarks. Text watermarking is becoming increasingly important with the advent of Large Language Models (LLM). LLMs can generate texts that cannot be distinguished from human-written texts. This is a serious problem for the credibility of the text. Easymark is a simple yet effective solution to this problem. Easymark can inject a watermark without changing the meaning of the text at all while a validator can detect if a text was generated from a system that adopted Easymark or not with high credibility. Easymark is extremely easy to implement so that it only requires a few lines of code. Easymark does not require access to LLMs, so it can be implemented on the user-side when the LLM providers do not offer watermarked LLMs. In spite of its simplicity, it achieves higher detection accuracy and BLEU scores than the state-of-the-art text watermarking methods. We also prove the impossibility theorem of perfect watermarking, which is valuable in its own right. This theorem shows that no matter how sophisticated a watermark is, a malicious user could remove it from the text, which motivate us to use a simple watermark such as Easymark. We carry out experiments with LLM-generated texts and confirm that Easymark can be detected reliably without any degradation of BLEU and perplexity, and outperform state-of-the-art watermarks in terms of both quality and reliability.", "url": "https://arxiv.org/abs/2310.08920"}, {"metadata": {"arXiv": "2310.08988", "Date": "Fri, 13 Oct 2023 10:09:12 ", "Title": "Reroute Prediction Service", "Authors": ["\\'Italo Romani de Oliveira", "Samet Ayhan", "Michael Biglin", "Pablo Costas", "Euclides C. Pinto Neto"], "Categories": "cs.LG cs.AI", "Comments": ["Submitted to the 2023 IEEE/AIAA Digital Aviation Systems Conference (DASC)"]}, "abstract": "The cost of delays was estimated as 33 billion US dollars only in 2019 for the US National Airspace System, a peak value following a growth trend in past years. Aiming to address this huge inefficiency, we designed and developed a novel Data Analytics and Machine Learning system, which aims at reducing delays by proactively supporting re-routing decisions. Given a time interval up to a few days in the future, the system predicts if a reroute advisory for a certain Air Route Traffic Control Center or for a certain advisory identifier will be issued, which may impact the pertinent routes. To deliver such predictions, the system uses historical reroute data, collected from the System Wide Information Management (SWIM) data services provided by the FAA, and weather data, provided by the US National Centers for Environmental Prediction (NCEP). The data is huge in volume, and has many items streamed at high velocity, uncorrelated and noisy. The system continuously processes the incoming raw data and makes it available for the next step where an interim data store is created and adaptively maintained for efficient query processing. The resulting data is fed into an array of ML algorithms, which compete for higher accuracy. The best performing algorithm is used in the final prediction, generating the final results. Mean accuracy values higher than 90% were obtained in our experiments with this system. Our algorithm divides the area of interest in units of aggregation and uses temporal series of the aggregate measures of weather forecast parameters in each geographical unit, in order to detect correlations with reroutes and where they will most likely occur. Aiming at practical application, the system is formed by a number of microservices, which are deployed in the cloud, making the system distributed, scalable and highly available.", "url": "https://arxiv.org/abs/2310.08988"}, {"metadata": {"arXiv": "2310.09028", "Date": "Fri, 13 Oct 2023 11:40:18 ", "Title": "Subspace Adaptation Prior for Few-Shot Learning", "Authors": ["Mike Huisman", "Aske Plaat", "Jan N. van Rijn"], "Categories": "cs.LG cs.AI stat.ML", "Comments": ["Accepted at Machine Learning Journal", "Special Issue of the ECML PKDD 2023 Journal Track"]}, "abstract": "Gradient-based meta-learning techniques aim to distill useful prior knowledge from a set of training tasks such that new tasks can be learned more efficiently with gradient descent. While these methods have achieved successes in various scenarios, they commonly adapt all parameters of trainable layers when learning new tasks. This neglects potentially more efficient learning strategies for a given task distribution and may be susceptible to overfitting, especially in few-shot learning where tasks must be learned from a limited number of examples. To address these issues, we propose Subspace Adaptation Prior (SAP), a novel gradient-based meta-learning algorithm that jointly learns good initialization parameters (prior knowledge) and layer-wise parameter subspaces in the form of operation subsets that should be adaptable. In this way, SAP can learn which operation subsets to adjust with gradient descent based on the underlying task distribution, simultaneously decreasing the risk of overfitting when learning new tasks. We demonstrate that this ability is helpful as SAP yields superior or competitive performance in few-shot image classification settings (gains between 0.1% and 3.9% in accuracy). Analysis of the learned subspaces demonstrates that low-dimensional operations often yield high activation strengths, indicating that they may be important for achieving good few-shot learning performance. For reproducibility purposes, we publish all our research code publicly.", "url": "https://arxiv.org/abs/2310.09028"}, {"metadata": {"arXiv": "2310.09040", "Date": "Fri, 13 Oct 2023 12:07:36 ", "Title": "Optimal Scheduling of Electric Vehicle Charging with Deep Reinforcement Learning considering End Users Flexibility", "Authors": ["Christoforos Menos-Aikateriniadis", "Stavros Sykiotis", "Pavlos S. Georgilakis"], "Categories": "cs.LG cs.AI", "Journal-ref": "13th Mediterranean Conference on Power Generation, Transmission, Distribution and Energy Conversion (MEDPOWER 2022)", "DOI": "10.1049/icp.2023.0007"}, "abstract": "The rapid growth of decentralized energy resources and especially Electric Vehicles (EV), that are expected to increase sharply over the next decade, will put further stress on existing power distribution networks, increasing the need for higher system reliability and flexibility. In an attempt to avoid unnecessary network investments and to increase the controllability over distribution networks, network operators develop demand response (DR) programs that incentivize end users to shift their consumption in return for financial or other benefits. Artificial intelligence (AI) methods are in the research forefront for residential load scheduling applications, mainly due to their high accuracy, high computational speed and lower dependence on the physical characteristics of the models under development. The aim of this work is to identify households' EV cost-reducing charging policy under a Time-of-Use tariff scheme, with the use of Deep Reinforcement Learning, and more specifically Deep Q-Networks (DQN). A novel end users flexibility potential reward is inferred from historical data analysis, where households with solar power generation have been used to train and test the designed algorithm. The suggested DQN EV charging policy can lead to more than 20% of savings in end users electricity bills.", "url": "https://arxiv.org/abs/2310.09040"}, {"metadata": {"arXiv": "2310.09091", "Date": "Fri, 13 Oct 2023 13:22:05 ", "Title": "Insightful analysis of historical sources at scales beyond human capabilities using unsupervised Machine Learning and XAI", "Authors": ["Oliver Eberle", "Jochen B\\\"uttner", "Hassan El-Hajj", "Gr\\'egoire Montavon", "Klaus-Robert M\\\"uller", "Matteo Valleriani"], "Categories": "cs.LG cs.AI cs.CY cs.DL"}, "abstract": "Historical materials are abundant. Yet, piecing together how human knowledge has evolved and spread both diachronically and synchronically remains a challenge that can so far only be very selectively addressed. The vast volume of materials precludes comprehensive studies, given the restricted number of human specialists. However, as large amounts of historical materials are now available in digital form there is a promising opportunity for AI-assisted historical analysis. In this work, we take a pivotal step towards analyzing vast historical corpora by employing innovative machine learning (ML) techniques, enabling in-depth historical insights on a grand scale. Our study centers on the evolution of knowledge within the `Sacrobosco Collection' -- a digitized collection of 359 early modern printed editions of textbooks on astronomy used at European universities between 1472 and 1650 -- roughly 76,000 pages, many of which contain astronomic, computational tables. An ML based analysis of these tables helps to unveil important facets of the spatio-temporal evolution of knowledge and innovation in the field of mathematical astronomy in the period, as taught at European universities.", "url": "https://arxiv.org/abs/2310.09091"}, {"metadata": {"arXiv": "2310.09162", "Date": "Fri, 13 Oct 2023 14:56:38 ", "Title": "Quantum Machine Learning in Climate Change and Sustainability: a Review", "Authors": ["Amal Nammouchi", "Andreas Kassler", "Andreas Theorachis"], "Categories": "cs.LG cs.AI", "Comments": ["8 pages Accepted for publication in AAAI proceedings (AAAI Fall symposium 2023)"]}, "abstract": "Climate change and its impact on global sustainability are critical challenges, demanding innovative solutions that combine cutting-edge technologies and scientific insights. Quantum machine learning (QML) has emerged as a promising paradigm that harnesses the power of quantum computing to address complex problems in various domains including climate change and sustainability. In this work, we survey existing literature that applies quantum machine learning to solve climate change and sustainability-related problems. We review promising QML methodologies that have the potential to accelerate decarbonization including energy systems, climate data forecasting, climate monitoring, and hazardous events predictions. We discuss the challenges and current limitations of quantum machine learning approaches and provide an overview of potential opportunities and future work to leverage QML-based methods in the important area of climate change research.", "url": "https://arxiv.org/abs/2310.09162"}, {"metadata": {"arXiv": "2310.09183", "Date": "Fri, 13 Oct 2023 15:21:25 ", "Title": "PRIOR: Personalized Prior for Reactivating the Information Overlooked in Federated Learning", "Authors": ["Mingjia Shi", "Yuhao Zhou", "Kai Wang", "Huaizheng Zhang", "Shudong Huang", "Qing Ye", "Jiangcheng Lv"], "Categories": "cs.LG cs.AI cs.DC", "Comments": ["This paper is accepted by NeurIPS 2023"], "MSC-class": "68T07", "ACM-class": "I.2.11"}, "abstract": "Classical federated learning (FL) enables training machine learning models without sharing data for privacy preservation, but heterogeneous data characteristic degrades the performance of the localized model. Personalized FL (PFL) addresses this by synthesizing personalized models from a global model via training on local data. Such a global model may overlook the specific information that the clients have been sampled. In this paper, we propose a novel scheme to inject personalized prior knowledge into the global model in each client, which attempts to mitigate the introduced incomplete information problem in PFL. At the heart of our proposed approach is a framework, the PFL with Bregman Divergence (pFedBreD), decoupling the personalized prior from the local objective function regularized by Bregman divergence for greater adaptability in personalized scenarios. We also relax the mirror descent (RMD) to extract the prior explicitly to provide optional strategies. Additionally, our pFedBreD is backed up by a convergence analysis. Sufficient experiments demonstrate that our method reaches the state-of-the-art performances on 5 datasets and outperforms other methods by up to 3.5% across 8 benchmarks. Extensive analyses verify the robustness and necessity of proposed designs.", "url": "https://arxiv.org/abs/2310.09183"}, {"metadata": {"arXiv": "2310.09192", "Date": "Fri, 13 Oct 2023 15:36:48 ", "Title": "Does Graph Distillation See Like Vision Dataset Counterpart?", "Authors": ["Beining Yang", "Kai Wang", "Qingyun Sun", "Cheng Ji", "Xingcheng Fu", "Hao Tang", "Yang You", "Jianxin Li"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted by NeurIPS 2023"]}, "abstract": "Training on large-scale graphs has achieved remarkable results in graph representation learning, but its cost and storage have attracted increasing concerns. Existing graph condensation methods primarily focus on optimizing the feature matrices of condensed graphs while overlooking the impact of the structure information from the original graphs. To investigate the impact of the structure information, we conduct analysis from the spectral domain and empirically identify substantial Laplacian Energy Distribution (LED) shifts in previous works. Such shifts lead to poor performance in cross-architecture generalization and specific tasks, including anomaly detection and link prediction. In this paper, we propose a novel Structure-broadcasting Graph Dataset Distillation (SGDD) scheme for broadcasting the original structure information to the generation of the synthetic one, which explicitly prevents overlooking the original structure information. Theoretically, the synthetic graphs by SGDD are expected to have smaller LED shifts than previous works, leading to superior performance in both cross-architecture settings and specific tasks. We validate the proposed SGDD across 9 datasets and achieve state-of-the-art results on all of them: for example, on the YelpChi dataset, our approach maintains 98.6% test accuracy of training on the original graph dataset with 1,000 times saving on the scale of the graph. Moreover, we empirically evaluate there exist 17.6% ~ 31.4% reductions in LED shift crossing 9 datasets. Extensive experiments and analysis verify the effectiveness and necessity of the proposed designs. The code is available in the GitHub repository: https://github.com/RingBDStack/SGDD.", "url": "https://arxiv.org/abs/2310.09192"}, {"metadata": {"arXiv": "2310.09203", "Date": "Fri, 13 Oct 2023 15:48:24 ", "Title": "SiamAF: Learning Shared Information from ECG and PPG Signals for Robust Atrial Fibrillation Detection", "Authors": ["Zhicheng Guo", "Cheng Ding", "Duc H. Do", "Amit Shah", "Randall J. Lee", "Xiao Hu", "Cynthia Rudin"], "Categories": "cs.LG cs.AI"}, "abstract": "Atrial fibrillation (AF) is the most common type of cardiac arrhythmia. It is associated with an increased risk of stroke, heart failure, and other cardiovascular complications, but can be clinically silent. Passive AF monitoring with wearables may help reduce adverse clinical outcomes related to AF. Detecting AF in noisy wearable data poses a significant challenge, leading to the emergence of various deep learning techniques. Previous deep learning models learn from a single modality, either electrocardiogram (ECG) or photoplethysmography (PPG) signals. However, deep learning models often struggle to learn generalizable features and rely on features that are more susceptible to corruption from noise, leading to sub-optimal performances in certain scenarios, especially with low-quality signals. Given the increasing availability of ECG and PPG signal pairs from wearables and bedside monitors, we propose a new approach, SiamAF, leveraging a novel Siamese network architecture and joint learning loss function to learn shared information from both ECG and PPG signals. At inference time, the proposed model is able to predict AF from either PPG or ECG and outperforms baseline methods on three external test sets. It learns medically relevant features as a result of our novel architecture design. The proposed model also achieves comparable performance to traditional learning regimes while requiring much fewer training labels, providing a potential approach to reduce future reliance on manual labeling.", "url": "https://arxiv.org/abs/2310.09203"}, {"metadata": {"arXiv": "2310.09222", "Date": "Fri, 13 Oct 2023 16:20:20 ", "Title": "Fast & Efficient Learning of Bayesian Networks from Data: Knowledge Discovery and Causality", "Authors": ["Minn Sein", "Fu Shunkai"], "Categories": "cs.LG cs.AI", "Journal-ref": "ICDM 2023:CXAI"}, "abstract": "Structure learning is essential for Bayesian networks (BNs) as it uncovers causal relationships, and enables knowledge discovery, predictions, inferences, and decision-making under uncertainty. Two novel algorithms, FSBN and SSBN, based on the PC algorithm, employ local search strategy and conditional independence tests to learn the causal network structure from data. They incorporate d-separation to infer additional topology information, prioritize conditioning sets, and terminate the search immediately and efficiently. FSBN achieves up to 52% computation cost reduction, while SSBN surpasses it with a remarkable 72% reduction for a 200-node network. SSBN demonstrates further efficiency gains due to its intelligent strategy. Experimental studies show that both algorithms match the induction quality of the PC algorithm while significantly reducing computation costs. This enables them to offer interpretability and adaptability while reducing the computational burden, making them valuable for various applications in big data analytics.", "url": "https://arxiv.org/abs/2310.09222"}, {"metadata": {"arXiv": "2310.09250", "Date": "Fri, 13 Oct 2023 17:06:34 ", "Title": "It's an Alignment, Not a Trade-off: Revisiting Bias and Variance in Deep Models", "Authors": ["Lin Chen", "Michal Lukasik", "Wittawat Jitkrittum", "Chong You", "Sanjiv Kumar"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "Classical wisdom in machine learning holds that the generalization error can be decomposed into bias and variance, and these two terms exhibit a \\emph{trade-off}. However, in this paper, we show that for an ensemble of deep learning based classification models, bias and variance are \\emph{aligned} at a sample level, where squared bias is approximately \\emph{equal} to variance for correctly classified sample points. We present empirical evidence confirming this phenomenon in a variety of deep learning models and datasets. Moreover, we study this phenomenon from two theoretical perspectives: calibration and neural collapse. We first show theoretically that under the assumption that the models are well calibrated, we can observe the bias-variance alignment. Second, starting from the picture provided by the neural collapse theory, we show an approximate correlation between bias and variance.", "url": "https://arxiv.org/abs/2310.09250"}, {"metadata": {"arXiv": "2310.08595", "Date": "Sat, 30 Sep 2023 10:54:02 ", "Title": "Deep Reinforcement Learning for Autonomous Vehicle Intersection Navigation", "Authors": ["Badr Ben Elallid", "Hamza El Alaoui", "and Nabil Benamar"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["Accepted for publication in the 2023 International Conference on Innovation and Intelligence for Informatics", "Computing", "and Technologies (3ICT)"]}, "abstract": "In this paper, we explore the challenges associated with navigating complex T-intersections in dense traffic scenarios for autonomous vehicles (AVs). Reinforcement learning algorithms have emerged as a promising approach to address these challenges by enabling AVs to make safe and efficient decisions in real-time. Here, we address the problem of efficiently and safely navigating T-intersections using a lower-cost, single-agent approach based on the Twin Delayed Deep Deterministic Policy Gradient (TD3) reinforcement learning algorithm. We show that our TD3-based method, when trained and tested in the CARLA simulation platform, demonstrates stable convergence and improved safety performance in various traffic densities. Our results reveal that the proposed approach enables the AV to effectively navigate T-intersections, outperforming previous methods in terms of travel delays, collision minimization, and overall cost. This study contributes to the growing body of knowledge on reinforcement learning applications in autonomous driving and highlights the potential of single-agent, cost-effective methods for addressing more complex driving scenarios and advancing reinforcement learning algorithms in the future.", "url": "https://arxiv.org/abs/2310.08595"}, {"metadata": {"arXiv": "2310.08602", "Date": "Sun, 08 Oct 2023 00:32:59 ", "Title": "Safe Deep Policy Adaptation", "Authors": ["Wenli Xiao", "Tairan He", "John Dolan", "Guanya Shi"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["8 pages", "7 figures"]}, "abstract": "A critical goal of autonomy and artificial intelligence is enabling autonomous robots to rapidly adapt in dynamic and uncertain environments. Classic adaptive control and safe control provide stability and safety guarantees but are limited to specific system classes. In contrast, policy adaptation based on reinforcement learning (RL) offers versatility and generalizability but presents safety and robustness challenges. We propose SafeDPA, a novel RL and control framework that simultaneously tackles the problems of policy adaptation and safe reinforcement learning. SafeDPA jointly learns adaptive policy and dynamics models in simulation, predicts environment configurations, and fine-tunes dynamics models with few-shot real-world data. A safety filter based on the Control Barrier Function (CBF) on top of the RL policy is introduced to ensure safety during real-world deployment. We provide theoretical safety guarantees of SafeDPA and show the robustness of SafeDPA against learning errors and extra perturbations. Comprehensive experiments on (1) classic control problems (Inverted Pendulum), (2) simulation benchmarks (Safety Gym), and (3) a real-world agile robotics platform (RC Car) demonstrate great superiority of SafeDPA in both safety and task performance, over state-of-the-art baselines. Particularly, SafeDPA demonstrates notable generalizability, achieving a 300% increase in safety rate compared to the baselines, under unseen disturbances in real-world experiments.", "url": "https://arxiv.org/abs/2310.08602"}, {"metadata": {"arXiv": "2310.08836", "Date": "Fri, 13 Oct 2023 03:15:42 ", "Title": "A Framework for Few-Shot Policy Transfer through Observation Mapping and Behavior Cloning", "Authors": ["Yash Shukla", "Bharat Kesari", "Shivam Goel", "Robert Wright and Jivko Sinapov"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["Paper accepted to the IROS 2023 Conference"]}, "abstract": "Despite recent progress in Reinforcement Learning for robotics applications, many tasks remain prohibitively difficult to solve because of the expensive interaction cost. Transfer learning helps reduce the training time in the target domain by transferring knowledge learned in a source domain. Sim2Real transfer helps transfer knowledge from a simulated robotic domain to a physical target domain. Knowledge transfer reduces the time required to train a task in the physical world, where the cost of interactions is high. However, most existing approaches assume exact correspondence in the task structure and the physical properties of the two domains. This work proposes a framework for Few-Shot Policy Transfer between two domains through Observation Mapping and Behavior Cloning. We use Generative Adversarial Networks (GANs) along with a cycle-consistency loss to map the observations between the source and target domains and later use this learned mapping to clone the successful source task behavior policy to the target domain. We observe successful behavior policy transfer with limited target task interactions and in cases where the source and target task are semantically dissimilar.", "url": "https://arxiv.org/abs/2310.08836"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2309.14468", "Date": "Mon, 25 Sep 2023 19:02:40 ", "Title": "FARSEC: A Reproducible Framework for Automatic Real-Time Vehicle Speed Estimation Using Traffic Cameras", "Authors": ["Lucas Liebe", "Franz Sauerwald", "Sylwester Sawicki", "Matthias Schneider", "Leo Schuhmann", "Tolga Buz", "Paul Boes", "Ahmad Ahmadov", "Gerard de Melo"], "Categories": "cs.CV cs.LG cs.SI", "ACM-class": "I.4.9"}, "abstract": "Estimating the speed of vehicles using traffic cameras is a crucial task for traffic surveillance and management, enabling more optimal traffic flow, improved road safety, and lower environmental impact. Transportation-dependent systems, such as for navigation and logistics, have great potential to benefit from reliable speed estimation. While there is prior research in this area reporting competitive accuracy levels, their solutions lack reproducibility and robustness across different datasets. To address this, we provide a novel framework for automatic real-time vehicle speed calculation, which copes with more diverse data from publicly available traffic cameras to achieve greater robustness. Our model employs novel techniques to estimate the length of road segments via depth map prediction. Additionally, our framework is capable of handling realistic conditions such as camera movements and different video stream inputs automatically. We compare our model to three well-known models in the field using their benchmark datasets. While our model does not set a new state of the art regarding prediction performance, the results are competitive on realistic CCTV videos. At the same time, our end-to-end pipeline offers more consistent results, an easier implementation, and better compatibility. Its modular structure facilitates reproducibility and future improvements.", "url": "https://arxiv.org/abs/2309.14468"}, {"metadata": {"arXiv": "2309.14585", "Date": "Tue, 26 Sep 2023 00:15:13 ", "Title": "DifAttack: Query-Efficient Black-Box Attack via Disentangled Feature Space", "Authors": ["Liu Jun", "Zhou Jiantao", "Zeng Jiandian", "Jinyu Tian"], "Categories": "cs.CV cs.CR cs.LG"}, "abstract": "This work investigates efficient score-based black-box adversarial attacks with a high Attack Success Rate (ASR) and good generalizability. We design a novel attack method based on a Disentangled Feature space, called DifAttack, which differs significantly from the existing ones operating over the entire feature space. Specifically, DifAttack firstly disentangles an image's latent feature into an adversarial feature and a visual feature, where the former dominates the adversarial capability of an image, while the latter largely determines its visual appearance. We train an autoencoder for the disentanglement by using pairs of clean images and their Adversarial Examples (AEs) generated from available surrogate models via white-box attack methods. Eventually, DifAttack iteratively optimizes the adversarial feature according to the query feedback from the victim model until a successful AE is generated, while keeping the visual feature unaltered. In addition, due to the avoidance of using surrogate models' gradient information when optimizing AEs for black-box models, our proposed DifAttack inherently possesses better attack capability in the open-set scenario, where the training dataset of the victim model is unknown. Extensive experimental results demonstrate that our method achieves significant improvements in ASR and query efficiency simultaneously, especially in the targeted attack and open-set scenarios. The code will be available at https://github.com/csjunjun/DifAttack.git soon.", "url": "https://arxiv.org/abs/2309.14585"}, {"metadata": {"arXiv": "2309.14666", "Date": "Tue, 26 Sep 2023 04:44:40 ", "Title": "ZiCo-BC: A Bias Corrected Zero-Shot NAS for Vision Tasks", "Authors": ["Kartikeya Bhardwaj", "Hsin-Pai Cheng", "Sweta Priyadarshi", "Zhuojin Li"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted at ICCV-Workshop on Resource-Efficient Deep Learning", "2023"]}, "abstract": "Zero-Shot Neural Architecture Search (NAS) approaches propose novel training-free metrics called zero-shot proxies to substantially reduce the search time compared to the traditional training-based NAS. Despite the success on image classification, the effectiveness of zero-shot proxies is rarely evaluated on complex vision tasks such as semantic segmentation and object detection. Moreover, existing zero-shot proxies are shown to be biased towards certain model characteristics which restricts their broad applicability. In this paper, we empirically study the bias of state-of-the-art (SOTA) zero-shot proxy ZiCo across multiple vision tasks and observe that ZiCo is biased towards thinner and deeper networks, leading to sub-optimal architectures. To solve the problem, we propose a novel bias correction on ZiCo, called ZiCo-BC. Our extensive experiments across various vision tasks (image classification, object detection and semantic segmentation) show that our approach can successfully search for architectures with higher accuracy and significantly lower latency on Samsung Galaxy S10 devices.", "url": "https://arxiv.org/abs/2309.14666"}, {"metadata": {"arXiv": "2309.14670", "Date": "Tue, 26 Sep 2023 04:48:50 ", "Title": "DONNAv2 -- Lightweight Neural Architecture Search for Vision tasks", "Authors": ["Sweta Priyadarshi", "Tianyu Jiang", "Hsin-Pai Cheng", "Sendil Krishna", "Viswanath Ganapathy", "Chirag Patel"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted at ICCV-Workshop on Resource-Efficient Deep Learning", "2023"]}, "abstract": "With the growing demand for vision applications and deployment across edge devices, the development of hardware-friendly architectures that maintain performance during device deployment becomes crucial. Neural architecture search (NAS) techniques explore various approaches to discover efficient architectures for diverse learning tasks in a computationally efficient manner. In this paper, we present the next-generation neural architecture design for computationally efficient neural architecture distillation - DONNAv2 . Conventional NAS algorithms rely on a computationally extensive stage where an accuracy predictor is learned to estimate model performance within search space. This building of accuracy predictors helps them predict the performance of models that are not being finetuned. Here, we have developed an elegant approach to eliminate building the accuracy predictor and extend DONNA to a computationally efficient setting. The loss metric of individual blocks forming the network serves as the surrogate performance measure for the sampled models in the NAS search stage. To validate the performance of DONNAv2 we have performed extensive experiments involving a range of diverse vision tasks including classification, object detection, image denoising, super-resolution, and panoptic perception network (YOLOP). The hardware-in-the-loop experiments were carried out using the Samsung Galaxy S10 mobile platform. Notably, DONNAv2 reduces the computational cost of DONNA by 10x for the larger datasets. Furthermore, to improve the quality of NAS search space, DONNAv2 leverages a block knowledge distillation filter to remove blocks with high inference costs.", "url": "https://arxiv.org/abs/2309.14670"}, {"metadata": {"arXiv": "2309.14715", "Date": "Tue, 26 Sep 2023 07:16:39 ", "Title": "Explaining Deep Face Algorithms through Visualization: A Survey", "Authors": ["Thrupthi Ann John", "Vineeth N Balasubramanian", "C. V. Jawahar"], "Categories": "cs.CV cs.HC cs.LG", "ACM-class": "I.2.10; I.4.10; I.5.1", "Journal-ref": "IEEE Transactions in Biometrics, Behaviour and Identity Science (IEEE T-BIOM) 2023"}, "abstract": "Although current deep models for face tasks surpass human performance on some benchmarks, we do not understand how they work. Thus, we cannot predict how it will react to novel inputs, resulting in catastrophic failures and unwanted biases in the algorithms. Explainable AI helps bridge the gap, but currently, there are very few visualization algorithms designed for faces. This work undertakes a first-of-its-kind meta-analysis of explainability algorithms in the face domain. We explore the nuances and caveats of adapting general-purpose visualization algorithms to the face domain, illustrated by computing visualizations on popular face models. We review existing face explainability works and reveal valuable insights into the structure and hierarchy of face networks. We also determine the design considerations for practical face visualizations accessible to AI practitioners by conducting a user study on the utility of various explainability algorithms.", "url": "https://arxiv.org/abs/2309.14715"}, {"metadata": {"arXiv": "2309.14883", "Date": "Tue, 26 Sep 2023 12:29:36 ", "Title": "Locality-preserving Directions for Interpreting the Latent Space of Satellite Image GANs", "Authors": ["Georgia Kourmouli", "Nikos Kostagiolas", "Yannis Panagakis", "Mihalis A. Nicolaou"], "Categories": "cs.CV cs.LG"}, "abstract": "We present a locality-aware method for interpreting the latent space of wavelet-based Generative Adversarial Networks (GANs), that can well capture the large spatial and spectral variability that is characteristic to satellite imagery. By focusing on preserving locality, the proposed method is able to decompose the weight-space of pre-trained GANs and recover interpretable directions that correspond to high-level semantic concepts (such as urbanization, structure density, flora presence) - that can subsequently be used for guided synthesis of satellite imagery. In contrast to typically used approaches that focus on capturing the variability of the weight-space in a reduced dimensionality space (i.e., based on Principal Component Analysis, PCA), we show that preserving locality leads to vectors with different angles, that are more robust to artifacts and can better preserve class information. Via a set of quantitative and qualitative examples, we further show that the proposed approach can outperform both baseline geometric augmentations, as well as global, PCA-based approaches for data synthesis in the context of data augmentation for satellite scene classification.", "url": "https://arxiv.org/abs/2309.14883"}, {"metadata": {"arXiv": "2309.14897", "Date": "Tue, 26 Sep 2023 12:54:58 ", "Title": "FDLS: A Deep Learning Approach to Production Quality, Controllable, and Retargetable Facial Performances", "Authors": ["Wan-Duo Kurt Ma", "Muhammad Ghifary", "J.P. Lewis", "Byungkuk Choi", "Haekwang Eom"], "Categories": "cs.CV cs.GR cs.LG", "Comments": ["DigiPro '22: The Digital Production Symposium"], "DOI": "10.1145/3543664"}, "abstract": "Visual effects commonly requires both the creation of realistic synthetic humans as well as retargeting actors' performances to humanoid characters such as aliens and monsters. Achieving the expressive performances demanded in entertainment requires manipulating complex models with hundreds of parameters. Full creative control requires the freedom to make edits at any stage of the production, which prohibits the use of a fully automatic ``black box'' solution with uninterpretable parameters. On the other hand, producing realistic animation with these sophisticated models is difficult and laborious. This paper describes FDLS (Facial Deep Learning Solver), which is Weta Digital's solution to these challenges. FDLS adopts a coarse-to-fine and human-in-the-loop strategy, allowing a solved performance to be verified and edited at several stages in the solving process. To train FDLS, we first transform the raw motion-captured data into robust graph features. Secondly, based on the observation that the artists typically finalize the jaw pass animation before proceeding to finer detail, we solve for the jaw motion first and predict fine expressions with region-based networks conditioned on the jaw position. Finally, artists can optionally invoke a non-linear finetuning process on top of the FDLS solution to follow the motion-captured virtual markers as closely as possible. FDLS supports editing if needed to improve the results of the deep learning solution and it can handle small daily changes in the actor's face shape. FDLS permits reliable and production-quality performance solving with minimal training and little or no manual effort in many cases, while also allowing the solve to be guided and edited in unusual and difficult cases. The system has been under development for several years and has been used in major movies.", "url": "https://arxiv.org/abs/2309.14897"}, {"metadata": {"arXiv": "2309.14928", "Date": "Tue, 26 Sep 2023 13:35:31 ", "Title": "Noise-Tolerant Unsupervised Adapter for Vision-Language Models", "Authors": ["Eman Ali", "Dayan Guan", "Shijian Lu", "Abdulmotaleb Elsaddik"], "Categories": "cs.CV cs.LG"}, "abstract": "Recent advances in large-scale vision-language models have achieved very impressive performance in various zero-shot image classification tasks. While prior studies have demonstrated significant improvements by introducing few-shot labelled target samples, they still require labelling of target samples, which greatly degrades their scalability while handling various visual recognition tasks. We design NtUA, a Noise-tolerant Unsupervised Adapter that allows learning superior target models with few-shot unlabelled target samples. NtUA works as a key-value cache that formulates visual features and predicted pseudo-labels of the few-shot unlabelled target samples as key-value pairs. It consists of two complementary designs. The first is adaptive cache formation that combats pseudo-label noises by weighting the key-value pairs according to their prediction confidence. The second is pseudo-label rectification, which corrects both pair values (i.e., pseudo-labels) and cache weights by leveraging knowledge distillation from large-scale vision language models. Extensive experiments show that NtUA achieves superior performance consistently across multiple widely adopted benchmarks.", "url": "https://arxiv.org/abs/2309.14928"}, {"metadata": {"arXiv": "2309.14356", "Date": "Sat, 23 Sep 2023 00:16:47 ", "Title": "COCO-Counterfactuals: Automatically Constructed Counterfactual Examples for Image-Text Pairs", "Authors": ["Tiep Le and Vasudev Lal and Phillip Howard"], "Categories": "cs.LG cs.CL cs.CV", "Comments": ["Accepted to NeurIPS 2023 Datasets and Benchmarks Track"]}, "abstract": "Counterfactual examples have proven to be valuable in the field of natural language processing (NLP) for both evaluating and improving the robustness of language models to spurious correlations in datasets. Despite their demonstrated utility for NLP, multimodal counterfactual examples have been relatively unexplored due to the difficulty of creating paired image-text data with minimal counterfactual changes. To address this challenge, we introduce a scalable framework for automatic generation of counterfactual examples using text-to-image diffusion models. We use our framework to create COCO-Counterfactuals, a multimodal counterfactual dataset of paired image and text captions based on the MS-COCO dataset. We validate the quality of COCO-Counterfactuals through human evaluations and show that existing multimodal models are challenged by our counterfactual image-text pairs. Additionally, we demonstrate the usefulness of COCO-Counterfactuals for improving out-of-domain generalization of multimodal vision-language models via training data augmentation.", "url": "https://arxiv.org/abs/2309.14356"}, {"metadata": {"arXiv": "2309.14360", "Date": "Sat, 23 Sep 2023 07:09:44 ", "Title": "Domain-Guided Conditional Diffusion Model for Unsupervised Domain Adaptation", "Authors": ["Yulong Zhang", "Shuhao Chen", "Weisen Jiang", "Yu Zhang", "Jiangang Lu", "and James T. Kwok"], "Categories": "cs.LG cs.CV", "Comments": ["Work in progress"]}, "abstract": "Limited transferability hinders the performance of deep learning models when applied to new application scenarios. Recently, Unsupervised Domain Adaptation (UDA) has achieved significant progress in addressing this issue via learning domain-invariant features. However, the performance of existing UDA methods is constrained by the large domain shift and limited target domain data. To alleviate these issues, we propose DomAin-guided Conditional Diffusion Model (DACDM) to generate high-fidelity and diversity samples for the target domain. In the proposed DACDM, by introducing class information, the labels of generated samples can be controlled, and a domain classifier is further introduced in DACDM to guide the generated samples for the target domain. The generated samples help existing UDA methods transfer from the source domain to the target domain more easily, thus improving the transfer performance. Extensive experiments on various benchmarks demonstrate that DACDM brings a large improvement to the performance of existing UDA methods.", "url": "https://arxiv.org/abs/2309.14360"}, {"metadata": {"arXiv": "2309.14397", "Date": "Mon, 25 Sep 2023 15:54:03 ", "Title": "Predicting environment effects on breast cancer by implementing machine learning", "Authors": ["Muhammad Shoaib Farooq", "Mehreen Ilyas"], "Categories": "cs.LG q-bio.QM", "Comments": ["8 pages", "7 figures", "2 tables"]}, "abstract": "The biggest Breast cancer is increasingly a major factor in female fatalities, overtaking heart disease. While genetic factors are important in the growth of breast cancer, new research indicates that environmental factors also play a substantial role in its occurrence and progression. The literature on the various environmental factors that may affect breast cancer risk, incidence, and outcomes is thoroughly reviewed in this study report. The study starts by looking at how lifestyle decisions, such as eating habits, exercise routines, and alcohol consumption, may affect hormonal imbalances and inflammation, two important factors driving the development of breast cancer. Additionally, it explores the part played by environmental contaminants such pesticides, endocrine-disrupting chemicals (EDCs), and industrial emissions, all of which have been linked to a higher risk of developing breast cancer due to their interference with hormone signaling and DNA damage. Algorithms for machine learning are used to express predictions. Logistic Regression, Random Forest, KNN Algorithm, SVC and extra tree classifier. Metrics including the confusion matrix correlation coefficient, F1-score, Precision, Recall, and ROC curve were used to evaluate the models. The best accuracy among all the classifiers is Random Forest with 0.91% accuracy and ROC curve 0.901% of Logistic Regression. The accuracy of the multiple algorithms for machine learning utilized in this research was good, which is important and indicates that these techniques could serve as replacement forecasting techniques in breast cancer survival analysis, notably in the Asia region.", "url": "https://arxiv.org/abs/2309.14397"}, {"metadata": {"arXiv": "2309.14482", "Date": "Mon, 25 Sep 2023 19:29:50 ", "Title": "LogGPT: Log Anomaly Detection via GPT", "Authors": ["Xiao Han", "Shuhan Yuan", "Mohamed Trabelsi"], "Categories": "cs.LG"}, "abstract": "Detecting system anomalies based on log data is important for ensuring the security and reliability of computer systems. Recently, deep learning models have been widely used for log anomaly detection. The core idea is to model the log sequences as natural language and adopt deep sequential models, such as LSTM or Transformer, to encode the normal patterns in log sequences via language modeling. However, there is a gap between language modeling and anomaly detection as the objective of training a sequential model via a language modeling loss is not directly related to anomaly detection. To fill up the gap, we propose LogGPT, a novel framework that employs GPT for log anomaly detection. LogGPT is first trained to predict the next log entry based on the preceding sequence. To further enhance the performance of LogGPT, we propose a novel reinforcement learning strategy to finetune the model specifically for the log anomaly detection task. The experimental results on three datasets show that LogGPT significantly outperforms existing state-of-the-art approaches.", "url": "https://arxiv.org/abs/2309.14482"}, {"metadata": {"arXiv": "2309.14485", "Date": "Mon, 25 Sep 2023 19:30:44 ", "Title": "Explainable and Accurate Natural Language Understanding for Voice Assistants and Beyond", "Authors": ["Kalpa Gunaratna", "Vijay Srinivasan", "Hongxia Jin"], "Categories": "cs.LG cs.CL", "Comments": ["Accepted at CIKM 2023"]}, "abstract": "Joint intent detection and slot filling, which is also termed as joint NLU (Natural Language Understanding) is invaluable for smart voice assistants. Recent advancements in this area have been heavily focusing on improving accuracy using various techniques. Explainability is undoubtedly an important aspect for deep learning-based models including joint NLU models. Without explainability, their decisions are opaque to the outside world and hence, have tendency to lack user trust. Therefore to bridge this gap, we transform the full joint NLU model to be `inherently' explainable at granular levels without compromising on accuracy. Further, as we enable the full joint NLU model explainable, we show that our extension can be successfully used in other general classification tasks. We demonstrate this using sentiment analysis and named entity recognition.", "url": "https://arxiv.org/abs/2309.14485"}, {"metadata": {"arXiv": "2309.14495", "Date": "Mon, 25 Sep 2023 19:45:11 ", "Title": "Classifying token frequencies using angular Minkowski $p$-distance", "Authors": ["Oliver Urs Lenz", "Chris Cornelis"], "Categories": "cs.LG cs.CL", "Comments": ["Accepted for publication in the proceedings of IJCRS 2023"]}, "abstract": "Angular Minkowski $p$-distance is a dissimilarity measure that is obtained by replacing Euclidean distance in the definition of cosine dissimilarity with other Minkowski $p$-distances. Cosine dissimilarity is frequently used with datasets containing token frequencies, and angular Minkowski $p$-distance may potentially be an even better choice for certain tasks. In a case study based on the 20-newsgroups dataset, we evaluate clasification performance for classical weighted nearest neighbours, as well as fuzzy rough nearest neighbours. In addition, we analyse the relationship between the hyperparameter $p$, the dimensionality $m$ of the dataset, the number of neighbours $k$, the choice of weights and the choice of classifier. We conclude that it is possible to obtain substantially higher classification performance with angular Minkowski $p$-distance with suitable values for $p$ than with classical cosine dissimilarity.", "url": "https://arxiv.org/abs/2309.14495"}, {"metadata": {"arXiv": "2309.14502", "Date": "Mon, 25 Sep 2023 20:01:57 ", "Title": "Uncertainty Aware Deep Learning for Particle Accelerators", "Authors": ["Kishansingh Rajput and Malachi Schram and Karthik Somayaji"], "Categories": "cs.LG physics.acc-ph", "Comments": ["6 pages", "2 figures", "Neurips Physical Sciences Workshop"]}, "abstract": "Standard deep learning models for classification and regression applications are ideal for capturing complex system dynamics. However, their predictions can be arbitrarily inaccurate when the input samples are not similar to the training data. Implementation of distance aware uncertainty estimation can be used to detect these scenarios and provide a level of confidence associated with their predictions. In this paper, we present results from using Deep Gaussian Process Approximation (DGPA) methods for errant beam prediction at Spallation Neutron Source (SNS) accelerator (classification) and we provide an uncertainty aware surrogate model for the Fermi National Accelerator Lab (FNAL) Booster Accelerator Complex (regression).", "url": "https://arxiv.org/abs/2309.14502"}, {"metadata": {"arXiv": "2309.14509", "Date": "Mon, 25 Sep 2023 20:15:57 ", "Title": "DeepSpeed Ulysses: System Optimizations for Enabling Training of Extreme Long Sequence Transformer Models", "Authors": ["Sam Ade Jacobs", "Masahiro Tanaka", "Chengming Zhang", "Minjia Zhang", "Leon Song", "Samyam Rajbhandari", "Yuxiong He"], "Categories": "cs.LG cs.CL cs.DC"}, "abstract": "Computation in a typical Transformer-based large language model (LLM) can be characterized by batch size, hidden dimension, number of layers, and sequence length. Until now, system works for accelerating LLM training have focused on the first three dimensions: data parallelism for batch size, tensor parallelism for hidden size and pipeline parallelism for model depth or layers. These widely studied forms of parallelism are not targeted or optimized for long sequence Transformer models. Given practical application needs for long sequence LLM, renewed attentions are being drawn to sequence parallelism. However, existing works in sequence parallelism are constrained by memory-communication inefficiency, limiting their scalability to long sequence large models. In this work, we introduce DeepSpeed-Ulysses, a novel, portable and effective methodology for enabling highly efficient and scalable LLM training with extremely long sequence length. DeepSpeed-Ulysses at its core partitions input data along the sequence dimension and employs an efficient all-to-all collective communication for attention computation. Theoretical communication analysis shows that whereas other methods incur communication overhead as sequence length increases, DeepSpeed-Ulysses maintains constant communication volume when sequence length and compute devices are increased proportionally. Furthermore, experimental evaluations show that DeepSpeed-Ulysses trains 2.5X faster with 4X longer sequence length than the existing method SOTA baseline.", "url": "https://arxiv.org/abs/2309.14509"}, {"metadata": {"arXiv": "2309.14518", "Date": "Mon, 25 Sep 2023 20:24:36 ", "Title": "Detach-ROCKET: Sequential feature selection for time series classification with random convolutional kernels", "Authors": ["Gonzalo Uribarri", "Federico Barone", "Alessio Ansuini", "Erik Frans\\'en"], "Categories": "cs.LG", "Comments": ["13 pages", "4 figures", "1 table"]}, "abstract": "Time series classification is essential in many fields, such as medicine, finance, environmental science, and manufacturing, enabling tasks like disease diagnosis, anomaly detection, and stock price prediction. Machine learning models like Recurrent Neural Networks and InceptionTime, while successful in numerous applications, can face scalability limitations due to intensive training requirements. To address this, random convolutional kernel models such as Rocket and its derivatives have emerged, simplifying training and achieving state-of-the-art performance by utilizing a large number of randomly generated features from time series data. However, due to their random nature, most of the generated features are redundant or non-informative, adding unnecessary computational load and compromising generalization. Here, we introduce Sequential Feature Detachment (SFD) as a method to identify and prune these non-essential features. SFD uses model coefficients to estimate feature importance and, unlike previous algorithms, can handle large feature sets without the need for complex hyperparameter tuning. Testing on the UCR archive demonstrates that SFD can produce models with $10\\%$ of the original features while improving $0.2\\%$ the accuracy on the test set. We also present an end-to-end procedure for determining an optimal balance between the number of features and model accuracy, called Detach-ROCKET. When applied to the largest binary UCR dataset, Detach-ROCKET is capable of reduce model size by $98.9\\%$ and increases test accuracy by $0.6\\%$.", "url": "https://arxiv.org/abs/2309.14518"}, {"metadata": {"arXiv": "2309.14557", "Date": "Mon, 25 Sep 2023 22:03:09 ", "Title": "Disruption Detection for a Cognitive Digital Supply Chain Twin Using Hybrid Deep Learning", "Authors": ["Mahmoud Ashraf", "Amr Eltawil", "Islam Ali"], "Categories": "cs.LG cs.ET"}, "abstract": "Purpose: Recent disruptive events, such as COVID-19 and Russia-Ukraine conflict, had a significant impact of global supply chains. Digital supply chain twins have been proposed in order to provide decision makers with an effective and efficient tool to mitigate disruption impact. Methods: This paper introduces a hybrid deep learning approach for disruption detection within a cognitive digital supply chain twin framework to enhance supply chain resilience. The proposed disruption detection module utilises a deep autoencoder neural network combined with a one-class support vector machine algorithm. In addition, long-short term memory neural network models are developed to identify the disrupted echelon and predict time-to-recovery from the disruption effect. Results: The obtained information from the proposed approach will help decision-makers and supply chain practitioners make appropriate decisions aiming at minimizing negative impact of disruptive events based on real-time disruption detection data. The results demonstrate the trade-off between disruption detection model sensitivity, encountered delay in disruption detection, and false alarms. This approach has seldom been used in recent literature addressing this issue.", "url": "https://arxiv.org/abs/2309.14557"}, {"metadata": {"arXiv": "2309.14597", "Date": "Tue, 26 Sep 2023 01:03:54 ", "Title": "Policy Optimization in a Noisy Neighborhood: On Return Landscapes in Continuous Control", "Authors": ["Nate Rahn", "Pierluca D'Oro", "Harley Wiltzer", "Pierre-Luc Bacon", "Marc G. Bellemare"], "Categories": "cs.LG", "Comments": ["NeurIPS 2023 Accepted Paper"]}, "abstract": "Deep reinforcement learning agents for continuous control are known to exhibit significant instability in their performance over time. In this work, we provide a fresh perspective on these behaviors by studying the return landscape: the mapping between a policy and a return. We find that popular algorithms traverse noisy neighborhoods of this landscape, in which a single update to the policy parameters leads to a wide range of returns. By taking a distributional view of these returns, we map the landscape, characterizing failure-prone regions of policy space and revealing a hidden dimension of policy quality. We show that the landscape exhibits surprising structure by finding simple paths in parameter space which improve the stability of a policy. To conclude, we develop a distribution-aware procedure which finds such paths, navigating away from noisy neighborhoods in order to improve the robustness of a policy. Taken together, our results provide new insight into the optimization, evaluation, and design of agents.", "url": "https://arxiv.org/abs/2309.14597"}, {"metadata": {"arXiv": "2309.14601", "Date": "Tue, 26 Sep 2023 01:10:16 ", "Title": "Neuro-Visualizer: An Auto-encoder-based Loss Landscape Visualization Method", "Authors": ["Mohannad Elhamod", "Anuj Karpatne"], "Categories": "cs.LG cs.HC"}, "abstract": "In recent years, there has been a growing interest in visualizing the loss landscape of neural networks. Linear landscape visualization methods, such as principal component analysis, have become widely used as they intuitively help researchers study neural networks and their training process. However, these linear methods suffer from limitations and drawbacks due to their lack of flexibility and low fidelity at representing the high dimensional landscape. In this paper, we present a novel auto-encoder-based non-linear landscape visualization method called Neuro-Visualizer that addresses these shortcoming and provides useful insights about neural network loss landscapes. To demonstrate its potential, we run experiments on a variety of problems in two separate applications of knowledge-guided machine learning (KGML). Our findings show that Neuro-Visualizer outperforms other linear and non-linear baselines and helps corroborate, and sometime challenge, claims proposed by machine learning community. All code and data used in the experiments of this paper are available at an anonymous link https://anonymous.4open.science/r/NeuroVisualizer-FDD6", "url": "https://arxiv.org/abs/2309.14601"}, {"metadata": {"arXiv": "2309.14615", "Date": "Tue, 26 Sep 2023 02:07:26 ", "Title": "Gray-box Adversarial Attack of Deep Reinforcement Learning-based Trading Agents", "Authors": ["Foozhan Ataiefard", "Hadi Hemmati"], "Categories": "cs.LG cs.CE q-fin.TR"}, "abstract": "In recent years, deep reinforcement learning (Deep RL) has been successfully implemented as a smart agent in many systems such as complex games, self-driving cars, and chat-bots. One of the interesting use cases of Deep RL is its application as an automated stock trading agent. In general, any automated trading agent is prone to manipulations by adversaries in the trading environment. Thus studying their robustness is vital for their success in practice. However, typical mechanism to study RL robustness, which is based on white-box gradient-based adversarial sample generation techniques (like FGSM), is obsolete for this use case, since the models are protected behind secure international exchange APIs, such as NASDAQ. In this research, we demonstrate that a \"gray-box\" approach for attacking a Deep RL-based trading agent is possible by trading in the same stock market, with no extra access to the trading agent. In our proposed approach, an adversary agent uses a hybrid Deep Neural Network as its policy consisting of Convolutional layers and fully-connected layers. On average, over three simulated trading market configurations, the adversary policy proposed in this research is able to reduce the reward values by 214.17%, which results in reducing the potential profits of the baseline by 139.4%, ensemble method by 93.7%, and an automated trading software developed by our industrial partner by 85.5%, while consuming significantly less budget than the victims (427.77%, 187.16%, and 66.97%, respectively).", "url": "https://arxiv.org/abs/2309.14615"}, {"metadata": {"arXiv": "2309.14662", "Date": "Tue, 26 Sep 2023 04:36:12 ", "Title": "Tranformer-based classification of user queries for medical consultancy with respect to expert specialisation", "Authors": ["Dmitry Lyutkin", "Andrey Soloviev", "Dmitry Zhukov", "Denis Pozdnyakov", "Muhammad Shahid Iqbal Malik", "Dmitry I. Ignatov"], "Categories": "cs.LG cs.CY cs.IR", "Comments": ["16 pages", "5 figures"]}, "abstract": "The need for skilled medical support is growing in the era of digital healthcare. This research presents an innovative strategy, utilising the RuBERT model, for categorising user inquiries in the field of medical consultation with a focus on expert specialisation. By harnessing the capabilities of transformers, we fine-tuned the pre-trained RuBERT model on a varied dataset, which facilitates precise correspondence between queries and particular medical specialisms. Using a comprehensive dataset, we have demonstrated our approach's superior performance with an F1-score of over 92%, calculated through both cross-validation and the traditional split of test and train datasets. Our approach has shown excellent generalisation across medical domains such as cardiology, neurology and dermatology. This methodology provides practical benefits by directing users to appropriate specialists for prompt and targeted medical advice. It also enhances healthcare system efficiency, reduces practitioner burden, and improves patient care quality. In summary, our suggested strategy facilitates the attainment of specific medical knowledge, offering prompt and precise advice within the digital healthcare field.", "url": "https://arxiv.org/abs/2309.14662"}, {"metadata": {"arXiv": "2309.14675", "Date": "Tue, 26 Sep 2023 05:03:13 ", "Title": "FedCompass: Efficient Cross-Silo Federated Learning on Heterogeneous Client Devices using a Computing Power Aware Scheduler", "Authors": ["Zilinghan Li", "Pranshu Chaturvedi", "Shilan He", "Han Chen", "Gagandeep Singh", "Volodymyr Kindratenko", "E. A. Huerta", "Kibaek Kim", "Ravi Madduri"], "Categories": "cs.LG cs.DC"}, "abstract": "Cross-silo federated learning offers a promising solution to collaboratively train robust and generalized AI models without compromising the privacy of local datasets, e.g., healthcare, financial, as well as scientific projects that lack a centralized data facility. Nonetheless, because of the disparity of computing resources among different clients (i.e., device heterogeneity), synchronous federated learning algorithms suffer from degraded efficiency when waiting for straggler clients. Similarly, asynchronous federated learning algorithms experience degradation in the convergence rate and final model accuracy on non-identically and independently distributed (non-IID) heterogeneous datasets due to stale local models and client drift. To address these limitations in cross-silo federated learning with heterogeneous clients and data, we propose FedCompass, an innovative semi-asynchronous federated learning algorithm with a computing power aware scheduler on the server side, which adaptively assigns varying amounts of training tasks to different clients using the knowledge of the computing power of individual clients. FedCompass ensures that multiple locally trained models from clients are received almost simultaneously as a group for aggregation, effectively reducing the staleness of local models. At the same time, the overall training process remains asynchronous, eliminating prolonged waiting periods from straggler clients. Using diverse non-IID heterogeneous distributed datasets, we demonstrate that FedCompass achieves faster convergence and higher accuracy than other asynchronous algorithms while remaining more efficient than synchronous algorithms when performing federated learning on heterogeneous clients.", "url": "https://arxiv.org/abs/2309.14675"}, {"metadata": {"arXiv": "2309.14691", "Date": "Tue, 26 Sep 2023 06:06:47 ", "Title": "On the Computational Complexity and Formal Hierarchy of Second Order Recurrent Neural Networks", "Authors": ["Ankur Mali and Alexander Ororbia and Daniel Kifer and Lee Giles"], "Categories": "cs.LG cs.CC", "Comments": ["12 pages", "5 tables", "1 figure"]}, "abstract": "Artificial neural networks (ANNs) with recurrence and self-attention have been shown to be Turing-complete (TC). However, existing work has shown that these ANNs require multiple turns or unbounded computation time, even with unbounded precision in weights, in order to recognize TC grammars. However, under constraints such as fixed or bounded precision neurons and time, ANNs without memory are shown to struggle to recognize even context-free languages. In this work, we extend the theoretical foundation for the $2^{nd}$-order recurrent network ($2^{nd}$ RNN) and prove there exists a class of a $2^{nd}$ RNN that is Turing-complete with bounded time. This model is capable of directly encoding a transition table into its recurrent weights, enabling bounded time computation and is interpretable by design. We also demonstrate that $2$nd order RNNs, without memory, under bounded weights and time constraints, outperform modern-day models such as vanilla RNNs and gated recurrent units in recognizing regular grammars. We provide an upper bound and a stability analysis on the maximum number of neurons required by $2$nd order RNNs to recognize any class of regular grammar. Extensive experiments on the Tomita grammars support our findings, demonstrating the importance of tensor connections in crafting computationally efficient RNNs. Finally, we show $2^{nd}$ order RNNs are also interpretable by extraction and can extract state machines with higher success rates as compared to first-order RNNs. Our results extend the theoretical foundations of RNNs and offer promising avenues for future explainable AI research.", "url": "https://arxiv.org/abs/2309.14691"}, {"metadata": {"arXiv": "2309.14717", "Date": "Tue, 26 Sep 2023 07:22:23 ", "Title": "QA-LoRA: Quantization-Aware Low-Rank Adaptation of Large Language Models", "Authors": ["Yuhui Xu", "Lingxi Xie", "Xiaotao Gu", "Xin Chen", "Heng Chang", "Hengheng Zhang", "Zhensu Chen", "Xiaopeng Zhang", "Qi Tian"], "Categories": "cs.LG", "Comments": ["16 pages"]}, "abstract": "Recently years have witnessed a rapid development of large language models (LLMs). Despite the strong ability in many language-understanding tasks, the heavy computational burden largely restricts the application of LLMs especially when one needs to deploy them onto edge devices. In this paper, we propose a quantization-aware low-rank adaptation (QA-LoRA) algorithm. The motivation lies in the imbalanced degrees of freedom of quantization and adaptation, and the solution is to use group-wise operators which increase the degree of freedom of quantization meanwhile decreasing that of adaptation. QA-LoRA is easily implemented with a few lines of code, and it equips the original LoRA with two-fold abilities: (i) during fine-tuning, the LLM's weights are quantized (e.g., into INT4) to reduce time and memory usage; (ii) after fine-tuning, the LLM and auxiliary weights are naturally integrated into a quantized model without loss of accuracy. We apply QA-LoRA to the LLaMA and LLaMA2 model families and validate its effectiveness in different fine-tuning datasets and downstream scenarios. Code will be made available at https://github.com/yuhuixu1993/qa-lora.", "url": "https://arxiv.org/abs/2309.14717"}, {"metadata": {"arXiv": "2309.14774", "Date": "Tue, 26 Sep 2023 09:16:44 ", "Title": "BLIP-Adapter: Parameter-Efficient Transfer Learning for Mobile Screenshot Captioning", "Authors": ["Ching-Yu Chiang", "I-Hua Chang", "Shih-Wei Liao"], "Categories": "cs.LG cs.CL cs.CV cs.HC"}, "abstract": "This study aims to explore efficient tuning methods for the screenshot captioning task. Recently, image captioning has seen significant advancements, but research in captioning tasks for mobile screens remains relatively scarce. Current datasets and use cases describing user behaviors within product screenshots are notably limited. Consequently, we sought to fine-tune pre-existing models for the screenshot captioning task. However, fine-tuning large pre-trained models can be resource-intensive, requiring considerable time, computational power, and storage due to the vast number of parameters in image captioning models. To tackle this challenge, this study proposes a combination of adapter methods, which necessitates tuning only the additional modules on the model. These methods are originally designed for vision or language tasks, and our intention is to apply them to address similar challenges in screenshot captioning. By freezing the parameters of the image caption models and training only the weights associated with the methods, performance comparable to fine-tuning the entire model can be achieved, while significantly reducing the number of parameters. This study represents the first comprehensive investigation into the effectiveness of combining adapters within the context of the screenshot captioning task. Through our experiments and analyses, this study aims to provide valuable insights into the application of adapters in vision-language models and contribute to the development of efficient tuning techniques for the screenshot captioning task. Our study is available at https://github.com/RainYuGG/BLIP-Adapter", "url": "https://arxiv.org/abs/2309.14774"}, {"metadata": {"arXiv": "2309.14775", "Date": "Tue, 26 Sep 2023 09:18:55 ", "Title": "Markov Chain Mirror Descent On Data Federation", "Authors": ["Yawei Zhao"], "Categories": "cs.LG math.OC"}, "abstract": "Stochastic optimization methods such as mirror descent have wide applications due to low computational cost. Those methods have been well studied under assumption of the independent and identical distribution, and usually achieve sublinear rate of convergence. However, this assumption may be too strong and unpractical in real application scenarios. Recent researches investigate stochastic gradient descent when instances are sampled from a Markov chain. Unfortunately, few results are known for stochastic mirror descent. In the paper, we propose a new version of stochastic mirror descent termed by MarchOn in the scenario of the federated learning. Given a distributed network, the model iteratively travels from a node to one of its neighbours randomly. Furthermore, we propose a new framework to analyze MarchOn, which yields best rates of convergence for convex, strongly convex, and non-convex loss. Finally, we conduct empirical studies to evaluate the convergence of MarchOn, and validate theoretical results.", "url": "https://arxiv.org/abs/2309.14775"}, {"metadata": {"arXiv": "2309.14816", "Date": "Tue, 26 Sep 2023 10:30:45 ", "Title": "A Comparative Study of Population-Graph Construction Methods and Graph Neural Networks for Brain Age Regression", "Authors": ["Kyriaki-Margarita Bintsi", "Tamara T. Mueller", "Sophie Starck", "Vasileios Baltatzis", "Alexander Hammers", "Daniel Rueckert"], "Categories": "cs.LG cs.CV", "Comments": ["Accepted at GRAIL", "MICCAI 2023"]}, "abstract": "The difference between the chronological and biological brain age of a subject can be an important biomarker for neurodegenerative diseases, thus brain age estimation can be crucial in clinical settings. One way to incorporate multimodal information into this estimation is through population graphs, which combine various types of imaging data and capture the associations among individuals within a population. In medical imaging, population graphs have demonstrated promising results, mostly for classification tasks. In most cases, the graph structure is pre-defined and remains static during training. However, extracting population graphs is a non-trivial task and can significantly impact the performance of Graph Neural Networks (GNNs), which are sensitive to the graph structure. In this work, we highlight the importance of a meaningful graph construction and experiment with different population-graph construction methods and their effect on GNN performance on brain age estimation. We use the homophily metric and graph visualizations to gain valuable quantitative and qualitative insights on the extracted graph structures. For the experimental evaluation, we leverage the UK Biobank dataset, which offers many imaging and non-imaging phenotypes. Our results indicate that architectures highly sensitive to the graph structure, such as Graph Convolutional Network (GCN) and Graph Attention Network (GAT), struggle with low homophily graphs, while other architectures, such as GraphSage and Chebyshev, are more robust across different homophily ratios. We conclude that static graph construction approaches are potentially insufficient for the task of brain age estimation and make recommendations for alternative research directions.", "url": "https://arxiv.org/abs/2309.14816"}, {"metadata": {"arXiv": "2309.14857", "Date": "Tue, 26 Sep 2023 11:35:25 ", "Title": "Cluster Exploration using Informative Manifold Projections", "Authors": ["Stavros Gerolymatos", "Xenophon Evangelopoulos", "Vladimir Gusev and John Y. Goulermas"], "Categories": "cs.LG cs.HC"}, "abstract": "Dimensionality reduction (DR) is one of the key tools for the visual exploration of high-dimensional data and uncovering its cluster structure in two- or three-dimensional spaces. The vast majority of DR methods in the literature do not take into account any prior knowledge a practitioner may have regarding the dataset under consideration. We propose a novel method to generate informative embeddings which not only factor out the structure associated with different kinds of prior knowledge but also aim to reveal any remaining underlying structure. To achieve this, we employ a linear combination of two objectives: firstly, contrastive PCA that discounts the structure associated with the prior information, and secondly, kurtosis projection pursuit which ensures meaningful data separation in the obtained embeddings. We formulate this task as a manifold optimization problem and validate it empirically across a variety of datasets considering three distinct types of prior knowledge. Lastly, we provide an automated framework to perform iterative visual exploration of high-dimensional data.", "url": "https://arxiv.org/abs/2309.14857"}, {"metadata": {"arXiv": "2309.14880", "Date": "Tue, 26 Sep 2023 12:26:28 ", "Title": "Credit Card Fraud Detection with Subspace Learning-based One-Class Classification", "Authors": ["Zaffar Zaffar", "Fahad Sohrab", "Juho Kanniainen", "Moncef Gabbouj"], "Categories": "cs.LG", "Comments": ["6 pages", "1 figure", "2 tables. Accepted at IEEE Symposium Series on Computational Intelligence 2023"]}, "abstract": "In an increasingly digitalized commerce landscape, the proliferation of credit card fraud and the evolution of sophisticated fraudulent techniques have led to substantial financial losses. Automating credit card fraud detection is a viable way to accelerate detection, reducing response times and minimizing potential financial losses. However, addressing this challenge is complicated by the highly imbalanced nature of the datasets, where genuine transactions vastly outnumber fraudulent ones. Furthermore, the high number of dimensions within the feature set gives rise to the ``curse of dimensionality\". In this paper, we investigate subspace learning-based approaches centered on One-Class Classification (OCC) algorithms, which excel in handling imbalanced data distributions and possess the capability to anticipate and counter the transactions carried out by yet-to-be-invented fraud techniques. The study highlights the potential of subspace learning-based OCC algorithms by investigating the limitations of current fraud detection strategies and the specific challenges of credit card fraud detection. These algorithms integrate subspace learning into the data description; hence, the models transform the data into a lower-dimensional subspace optimized for OCC. Through rigorous experimentation and analysis, the study validated that the proposed approach helps tackle the curse of dimensionality and the imbalanced nature of credit card data for automatic fraud detection to mitigate financial losses caused by fraudulent activities.", "url": "https://arxiv.org/abs/2309.14880"}, {"metadata": {"arXiv": "2309.14936", "Date": "Tue, 26 Sep 2023 13:48:04 ", "Title": "Parallel Multi-Objective Hyperparameter Optimization with Uniform Normalization and Bounded Objectives", "Authors": ["Romain Egele", "Tyler Chang", "Yixuan Sun", "Venkatram Vishwanath", "Prasanna Balaprakash"], "Categories": "cs.LG cs.DC", "Comments": ["Preprint with appendices"]}, "abstract": "Machine learning (ML) methods offer a wide range of configurable hyperparameters that have a significant influence on their performance. While accuracy is a commonly used performance objective, in many settings, it is not sufficient. Optimizing the ML models with respect to multiple objectives such as accuracy, confidence, fairness, calibration, privacy, latency, and memory consumption is becoming crucial. To that end, hyperparameter optimization, the approach to systematically optimize the hyperparameters, which is already challenging for a single objective, is even more challenging for multiple objectives. In addition, the differences in objective scales, the failures, and the presence of outlier values in objectives make the problem even harder. We propose a multi-objective Bayesian optimization (MoBO) algorithm that addresses these problems through uniform objective normalization and randomized weights in scalarization. We increase the efficiency of our approach by imposing constraints on the objective to avoid exploring unnecessary configurations (e.g., insufficient accuracy). Finally, we leverage an approach to parallelize the MoBO which results in a 5x speed-up when using 16x more workers.", "url": "https://arxiv.org/abs/2309.14936"}, {"metadata": {"arXiv": "2309.14949", "Date": "Tue, 26 Sep 2023 14:06:26 ", "Title": "Towards Real-World Test-Time Adaptation: Tri-Net Self-Training with Balanced Normalization", "Authors": ["Yongyi Su", "Xun Xu", "Kui Jia"], "Categories": "cs.LG cs.CV", "Comments": ["23 pages", "7 figures and 22 tables"]}, "abstract": "Test-Time Adaptation aims to adapt source domain model to testing data at inference stage with success demonstrated in adapting to unseen corruptions. However, these attempts may fail under more challenging real-world scenarios. Existing works mainly consider real-world test-time adaptation under non-i.i.d. data stream and continual domain shift. In this work, we first complement the existing real-world TTA protocol with a globally class imbalanced testing set. We demonstrate that combining all settings together poses new challenges to existing methods. We argue the failure of state-of-the-art methods is first caused by indiscriminately adapting normalization layers to imbalanced testing data. To remedy this shortcoming, we propose a balanced batchnorm layer to swap out the regular batchnorm at inference stage. The new batchnorm layer is capable of adapting without biasing towards majority classes. We are further inspired by the success of self-training~(ST) in learning from unlabeled data and adapt ST for test-time adaptation. However, ST alone is prone to over adaption which is responsible for the poor performance under continual domain shift. Hence, we propose to improve self-training under continual domain shift by regularizing model updates with an anchored loss. The final TTA model, termed as TRIBE, is built upon a tri-net architecture with balanced batchnorm layers. We evaluate TRIBE on four datasets representing real-world TTA settings. TRIBE consistently achieves the state-of-the-art performance across multiple evaluation protocols. The code is available at \\url{https://github.com/Gorilla-Lab-SCUT/TRIBE}.", "url": "https://arxiv.org/abs/2309.14949"}, {"metadata": {"arXiv": "2309.14989", "Date": "Tue, 26 Sep 2023 15:01:21 ", "Title": "Tempo Adaption in Non-stationary Reinforcement Learning", "Authors": ["Hyunin Lee", "Yuhao Ding", "Jongmin Lee", "Ming Jin", "Javad Lavaei", "Somayeh Sojoudi"], "Categories": "cs.LG", "Comments": ["53 pages. To be published in Neural Information Processing Systems (NeurIPS)", "2023"]}, "abstract": "We first raise and tackle ``time synchronization'' issue between the agent and the environment in non-stationary reinforcement learning (RL), a crucial factor hindering its real-world applications. In reality, environmental changes occur over wall-clock time ($\\mathfrak{t}$) rather than episode progress ($k$), where wall-clock time signifies the actual elapsed time within the fixed duration $\\mathfrak{t} \\in [0, T]$. In existing works, at episode $k$, the agent rollouts a trajectory and trains a policy before transitioning to episode $k+1$. In the context of the time-desynchronized environment, however, the agent at time $\\mathfrak{t}_k$ allocates $\\Delta \\mathfrak{t}$ for trajectory generation and training, subsequently moves to the next episode at $\\mathfrak{t}_{k+1}=\\mathfrak{t}_{k}+\\Delta \\mathfrak{t}$. Despite a fixed total episode ($K$), the agent accumulates different trajectories influenced by the choice of \\textit{interaction times} ($\\mathfrak{t}_1,\\mathfrak{t}_2,...,\\mathfrak{t}_K$), significantly impacting the sub-optimality gap of policy. We propose a Proactively Synchronizing Tempo (ProST) framework that computes optimal $\\{ \\mathfrak{t}_1,\\mathfrak{t}_2,...,\\mathfrak{t}_K \\} (= \\{ \\mathfrak{t} \\}_{1:K})$. Our main contribution is that we show optimal $\\{ \\mathfrak{t} \\}_{1:K}$ trades-off between the policy training time (agent tempo) and how fast the environment changes (environment tempo). Theoretically, this work establishes an optimal $\\{ \\mathfrak{t} \\}_{1:K}$ as a function of the degree of the environment's non-stationarity while also achieving a sublinear dynamic regret. Our experimental evaluation on various high dimensional non-stationary environments shows that the ProST framework achieves a higher online return at optimal $\\{ \\mathfrak{t} \\}_{1:K}$ than the existing methods.", "url": "https://arxiv.org/abs/2309.14989"}, {"metadata": {"arXiv": "2309.15038", "Date": "Tue, 26 Sep 2023 16:12:57 ", "Title": "HPCR: Holistic Proxy-based Contrastive Replay for Online Continual Learning", "Authors": ["Huiwei Lin", "Shanshan Feng", "Baoquan Zhang", "Xutao Li", "Yew-soon Ong", "Yunming Ye"], "Categories": "cs.LG cs.CV", "Comments": ["18 pages", "11 figures"]}, "abstract": "Online continual learning (OCL) aims to continuously learn new data from a single pass over the online data stream. It generally suffers from the catastrophic forgetting issue. Existing replay-based methods effectively alleviate this issue by replaying part of old data in a proxy-based or contrastive-based replay manner. In this paper, we conduct a comprehensive analysis of these two replay manners and find they can be complementary. Inspired by this finding, we propose a novel replay-based method called proxy-based contrastive replay (PCR), which replaces anchor-to-sample pairs with anchor-to-proxy pairs in the contrastive-based loss to alleviate the phenomenon of forgetting. Based on PCR, we further develop a more advanced method named holistic proxy-based contrastive replay (HPCR), which consists of three components. The contrastive component conditionally incorporates anchor-to-sample pairs to PCR, learning more fine-grained semantic information with a large training batch. The second is a temperature component that decouples the temperature coefficient into two parts based on their impacts on the gradient and sets different values for them to learn more novel knowledge. The third is a distillation component that constrains the learning process to keep more historical knowledge. Experiments on four datasets consistently demonstrate the superiority of HPCR over various state-of-the-art methods.", "url": "https://arxiv.org/abs/2309.15038"}, {"metadata": {"arXiv": "2309.15094", "Date": "Tue, 26 Sep 2023 17:40:29 ", "Title": "Identifying Simulation Model Through Alternative Techniques for a Medical Device Assembly Process", "Authors": ["Fatemeh Kakavandi"], "Categories": "cs.LG"}, "abstract": "This scientific paper explores two distinct approaches for identifying and approximating the simulation model, particularly in the context of the snap process crucial to medical device assembly. Simulation models play a pivotal role in providing engineers with insights into industrial processes, enabling experimentation and troubleshooting before physical assembly. However, their complexity often results in time-consuming computations. To mitigate this complexity, we present two distinct methods for identifying simulation models: one utilizing Spline functions and the other harnessing Machine Learning (ML) models. Our goal is to create adaptable models that accurately represent the snap process and can accommodate diverse scenarios. Such models hold promise for enhancing process understanding and aiding in decision-making, especially when data availability is limited.", "url": "https://arxiv.org/abs/2309.15094"}, {"metadata": {"arXiv": "2309.15096", "Date": "Tue, 26 Sep 2023 17:42:52 ", "Title": "Fixing the NTK: From Neural Network Linearizations to Exact Convex Programs", "Authors": ["Rajat Vadiraj Dwaraknath", "Tolga Ergen", "Mert Pilanci"], "Categories": "cs.LG stat.ML", "Comments": ["Accepted to Neurips 2023"]}, "abstract": "Recently, theoretical analyses of deep neural networks have broadly focused on two directions: 1) Providing insight into neural network training by SGD in the limit of infinite hidden-layer width and infinitesimally small learning rate (also known as gradient flow) via the Neural Tangent Kernel (NTK), and 2) Globally optimizing the regularized training objective via cone-constrained convex reformulations of ReLU networks. The latter research direction also yielded an alternative formulation of the ReLU network, called a gated ReLU network, that is globally optimizable via efficient unconstrained convex programs. In this work, we interpret the convex program for this gated ReLU network as a Multiple Kernel Learning (MKL) model with a weighted data masking feature map and establish a connection to the NTK. Specifically, we show that for a particular choice of mask weights that do not depend on the learning targets, this kernel is equivalent to the NTK of the gated ReLU network on the training data. A consequence of this lack of dependence on the targets is that the NTK cannot perform better than the optimal MKL kernel on the training set. By using iterative reweighting, we improve the weights induced by the NTK to obtain the optimal MKL kernel which is equivalent to the solution of the exact convex reformulation of the gated ReLU network. We also provide several numerical simulations corroborating our theory. Additionally, we provide an analysis of the prediction error of the resulting optimal kernel via consistency results for the group lasso.", "url": "https://arxiv.org/abs/2309.15096"}, {"metadata": {"arXiv": "2309.15111", "Date": "Tue, 26 Sep 2023 17:57:44 ", "Title": "SGD Finds then Tunes Features in Two-Layer Neural Networks with near-Optimal Sample Complexity: A Case Study in the XOR problem", "Authors": ["Margalit Glasgow"], "Categories": "cs.LG stat.ML"}, "abstract": "In this work, we consider the optimization process of minibatch stochastic gradient descent (SGD) on a 2-layer neural network with data separated by a quadratic ground truth function. We prove that with data drawn from the $d$-dimensional Boolean hypercube labeled by the quadratic ``XOR'' function $y = -x_ix_j$, it is possible to train to a population error $o(1)$ with $d \\:\\text{polylog}(d)$ samples. Our result considers simultaneously training both layers of the two-layer-neural network with ReLU activations via standard minibatch SGD on the logistic loss. To our knowledge, this work is the first to give a sample complexity of $\\tilde{O}(d)$ for efficiently learning the XOR function on isotropic data on a standard neural network with standard training. Our main technique is showing that the network evolves in two phases: a $\\textit{signal-finding}$ phase where the network is small and many of the neurons evolve independently to find features, and a $\\textit{signal-heavy}$ phase, where SGD maintains and balances the features. We leverage the simultaneous training of the layers to show that it is sufficient for only a small fraction of the neurons to learn features, since those neurons will be amplified by the simultaneous growth of their second layer weights.", "url": "https://arxiv.org/abs/2309.15111"}, {"metadata": {"arXiv": "2309.14837", "Date": "Tue, 26 Sep 2023 11:05:37 ", "Title": "Realtime Motion Generation with Active Perception Using Attention Mechanism for Cooking Robot", "Authors": ["Namiko Saito", "Mayu Hiramoto", "Ayuna Kubo", "Kanata Suzuki", "Hiroshi Ito", "Shigeki Sugano and Tetsuya Ogata"], "Categories": "cs.RO cs.LG"}, "abstract": "To support humans in their daily lives, robots are required to autonomously learn, adapt to objects and environments, and perform the appropriate actions. We tackled on the task of cooking scrambled eggs using real ingredients, in which the robot needs to perceive the states of the egg and adjust stirring movement in real time, while the egg is heated and the state changes continuously. In previous works, handling changing objects was found to be challenging because sensory information includes dynamical, both important or noisy information, and the modality which should be focused on changes every time, making it difficult to realize both perception and motion generation in real time. We propose a predictive recurrent neural network with an attention mechanism that can weigh the sensor input, distinguishing how important and reliable each modality is, that realize quick and efficient perception and motion generation. The model is trained with learning from the demonstration, and allows the robot to acquire human-like skills. We validated the proposed technique using the robot, Dry-AIREC, and with our learning model, it could perform cooking eggs with unknown ingredients. The robot could change the method of stirring and direction depending on the status of the egg, as in the beginning it stirs in the whole pot, then subsequently, after the egg started being heated, it starts flipping and splitting motion targeting specific areas, although we did not explicitly indicate them.", "url": "https://arxiv.org/abs/2309.14837"}, {"metadata": {"arXiv": "2309.14894", "Date": "Tue, 26 Sep 2023 12:51:03 ", "Title": "Verifiable Learned Behaviors via Motion Primitive Composition: Applications to Scooping of Granular Media", "Authors": ["Andrew Benton", "Eugen Solowjow", "Prithvi Akella"], "Categories": "cs.RO cs.LG cs.SY eess.SY"}, "abstract": "A robotic behavior model that can reliably generate behaviors from natural language inputs in real time would substantially expedite the adoption of industrial robots due to enhanced system flexibility. To facilitate these efforts, we construct a framework in which learned behaviors, created by a natural language abstractor, are verifiable by construction. Leveraging recent advancements in motion primitives and probabilistic verification, we construct a natural-language behavior abstractor that generates behaviors by synthesizing a directed graph over the provided motion primitives. If these component motion primitives are constructed according to the criteria we specify, the resulting behaviors are probabilistically verifiable. We demonstrate this verifiable behavior generation capacity in both simulation on an exploration task and on hardware with a robot scooping granular media.", "url": "https://arxiv.org/abs/2309.14894"}, {"metadata": {"arXiv": "2309.14941", "Date": "Tue, 26 Sep 2023 13:53:53 ", "Title": "Learning Generative Models for Climbing Aircraft from Radar Data", "Authors": ["Nick Pepper and Marc Thomas"], "Categories": "eess.SY cs.LG cs.SY"}, "abstract": "Accurate trajectory prediction (TP) for climbing aircraft is hampered by the presence of epistemic uncertainties concerning aircraft operation, which can lead to significant misspecification between predicted and observed trajectories. This paper proposes a generative model for climbing aircraft in which the standard Base of Aircraft Data (BADA) model is enriched by a functional correction to the thrust that is learned from data. The method offers three features: predictions of the arrival time with 66.3% less error when compared to BADA; generated trajectories that are realistic when compared to test data; and a means of computing confidence bounds for minimal computational cost.", "url": "https://arxiv.org/abs/2309.14941"}, {"metadata": {"arXiv": "2309.14957", "Date": "Tue, 26 Sep 2023 14:20:09 ", "Title": "Context-Aware Generative Models for Prediction of Aircraft Ground Tracks", "Authors": ["Nick Pepper and George De Ath and Marc Thomas and Richard Everson and Tim Dodwell"], "Categories": "eess.SY cs.LG cs.SY"}, "abstract": "Trajectory prediction (TP) plays an important role in supporting the decision-making of Air Traffic Controllers (ATCOs). Traditional TP methods are deterministic and physics-based, with parameters that are calibrated using aircraft surveillance data harvested across the world. These models are, therefore, agnostic to the intentions of the pilots and ATCOs, which can have a significant effect on the observed trajectory, particularly in the lateral plane. This work proposes a generative method for lateral TP, using probabilistic machine learning to model the effect of the epistemic uncertainty arising from the unknown effect of pilot behaviour and ATCO intentions. The models are trained to be specific to a particular sector, allowing local procedures such as coordinated entry and exit points to be modelled. A dataset comprising a week's worth of aircraft surveillance data, passing through a busy sector of the United Kingdom's upper airspace, was used to train and test the models. Specifically, a piecewise linear model was used as a functional, low-dimensional representation of the ground tracks, with its control points determined by a generative model conditioned on partial context. It was found that, of the investigated models, a Bayesian Neural Network using the Laplace approximation was able to generate the most plausible trajectories in order to emulate the flow of traffic through the sector.", "url": "https://arxiv.org/abs/2309.14957"}, {"metadata": {"arXiv": "2309.14497", "Date": "Mon, 25 Sep 2023 19:49:14 ", "Title": "Interaction-Aware Decision-Making for Autonomous Vehicles in Forced Merging Scenario Leveraging Social Psychology Factors", "Authors": ["Xiao Li", "Kaiwen Liu", "H. Eric Tseng", "Anouck Girard", "Ilya Kolmanovsky"], "Categories": "cs.AI cs.RO cs.SY eess.SY"}, "abstract": "Understanding the intention of vehicles in the surrounding traffic is crucial for an autonomous vehicle to successfully accomplish its driving tasks in complex traffic scenarios such as highway forced merging. In this paper, we consider a behavioral model that incorporates both social behaviors and personal objectives of the interacting drivers. Leveraging this model, we develop a receding-horizon control-based decision-making strategy, that estimates online the other drivers' intentions using Bayesian filtering and incorporates predictions of nearby vehicles' behaviors under uncertain intentions. The effectiveness of the proposed decision-making strategy is demonstrated and evaluated based on simulation studies in comparison with a game theoretic controller and a real-world traffic dataset.", "url": "https://arxiv.org/abs/2309.14497"}, {"metadata": {"arXiv": "2309.14548", "Date": "Mon, 25 Sep 2023 21:45:30 ", "Title": "Algorithmic Collusion or Competition: the Role of Platforms' Recommender Systems", "Authors": ["Xingchen Xu", "Stephanie Lee", "Yong Tan"], "Categories": "cs.AI cs.IR econ.GN q-fin.EC", "Comments": ["33 pages", "5 figures", "4 tables"], "ACM-class": "J.4"}, "abstract": "Recent academic research has extensively examined algorithmic collusion resulting from the utilization of artificial intelligence (AI)-based dynamic pricing algorithms. Nevertheless, e-commerce platforms employ recommendation algorithms to allocate exposure to various products, and this important aspect has been largely overlooked in previous studies on algorithmic collusion. Our study bridges this important gap in the literature and examines how recommendation algorithms can determine the competitive or collusive dynamics of AI-based pricing algorithms. Specifically, two commonly deployed recommendation algorithms are examined: (i) a recommender system that aims to maximize the sellers' total profit (profit-based recommender system) and (ii) a recommender system that aims to maximize the demand for products sold on the platform (demand-based recommender system). We construct a repeated game framework that incorporates both pricing algorithms adopted by sellers and the platform's recommender system. Subsequently, we conduct experiments to observe price dynamics and ascertain the final equilibrium. Experimental results reveal that a profit-based recommender system intensifies algorithmic collusion among sellers due to its congruence with sellers' profit-maximizing objectives. Conversely, a demand-based recommender system fosters price competition among sellers and results in a lower price, owing to its misalignment with sellers' goals. Extended analyses suggest the robustness of our findings in various market scenarios. Overall, we highlight the importance of platforms' recommender systems in delineating the competitive structure of the digital marketplace, providing important insights for market participants and corresponding policymakers.", "url": "https://arxiv.org/abs/2309.14548"}, {"metadata": {"arXiv": "2309.14663", "Date": "Tue, 26 Sep 2023 04:40:52 ", "Title": "Learning Emergent Behavior in Robot Swarms with NEAT", "Authors": ["Pranav Rajbhandari", "Donald Sofge"], "Categories": "cs.AI"}, "abstract": "When researching robot swarms, many studies observe complex group behavior emerging from the individual agents' simple local actions. However, the task of learning an individual policy to produce a desired emergent behavior remains a challenging and largely unsolved problem. We present a method of training distributed robotic swarm algorithms to produce emergent behavior. Inspired by the biological evolution of emergent behavior in animals, we use an evolutionary algorithm to train a 'population' of individual behaviors to approximate a desired group behavior. We perform experiments using simulations of the Georgia Tech Miniature Autonomous Blimps (GT-MABs) aerial robotics platforms conducted in the CoppeliaSim simulator. Additionally, we test on simulations of Anki Vector robots to display our algorithm's effectiveness on various modes of actuation. We evaluate our algorithm on various tasks where a somewhat complex group behavior is required for success. These tasks include an Area Coverage task, a Surround Target task, and a Wall Climb task. We compare behaviors evolved using our algorithm against 'designed policies', which we create in order to exhibit the emergent behaviors we desire.", "url": "https://arxiv.org/abs/2309.14663"}, {"metadata": {"arXiv": "2309.14718", "Date": "Tue, 26 Sep 2023 07:23:26 ", "Title": "Optimizing delegation between human and AI collaborative agents", "Authors": ["Andrew Fuchs", "Andrea Passarella", "Marco Conti"], "Categories": "cs.AI", "Comments": ["This work has been accepted to the 'Towards Hybrid Human-Machine Learning and Decision Making (HLDM)' workshop at ECML PKDD 2023"]}, "abstract": "In the context of humans operating with artificial or autonomous agents in a hybrid team, it is essential to accurately identify when to authorize those team members to perform actions. Given past examples where humans and autonomous systems can either succeed or fail at tasks, we seek to train a delegating manager agent to make delegation decisions with respect to these potential performance deficiencies. Additionally, we cannot always expect the various agents to operate within the same underlying model of the environment. It is possible to encounter cases where the actions and transitions would vary between agents. Therefore, our framework provides a manager model which learns through observations of team performance without restricting agents to matching dynamics. Our results show our manager learns to perform delegation decisions with teams of agents operating under differing representations of the environment, significantly outperforming alternative methods to manage the team.", "url": "https://arxiv.org/abs/2309.14718"}, {"metadata": {"arXiv": "2309.14796", "Date": "Tue, 26 Sep 2023 09:48:30 ", "Title": "Forgetting-aware Linear Bias for Attentive Knowledge Tracing", "Authors": ["Yoonjin Im", "Eunseong Choi", "Heejin Kook", "Jongwuk Lee"], "Categories": "cs.AI", "Comments": ["In Proceedings of the 32nd ACM International Conference on Information and Knowledge Management (CIKM'23)", "5 pages", "3 figures", "2 tables"], "DOI": "10.1145/3583780.3615191"}, "abstract": "Knowledge Tracing (KT) aims to track proficiency based on a question-solving history, allowing us to offer a streamlined curriculum. Recent studies actively utilize attention-based mechanisms to capture the correlation between questions and combine it with the learner's characteristics for responses. However, our empirical study shows that existing attention-based KT models neglect the learner's forgetting behavior, especially as the interaction history becomes longer. This problem arises from the bias that overprioritizes the correlation of questions while inadvertently ignoring the impact of forgetting behavior. This paper proposes a simple-yet-effective solution, namely Forgetting-aware Linear Bias (FoLiBi), to reflect forgetting behavior as a linear bias. Despite its simplicity, FoLiBi is readily equipped with existing attentive KT models by effectively decomposing question correlations with forgetting behavior. FoLiBi plugged with several KT models yields a consistent improvement of up to 2.58% in AUC over state-of-the-art KT models on four benchmark datasets.", "url": "https://arxiv.org/abs/2309.14796"}, {"metadata": {"arXiv": "2309.14389", "Date": "Mon, 25 Sep 2023 07:01:16 ", "Title": "Analyzing the Efficacy of an LLM-Only Approach for Image-based Document Question Answering", "Authors": ["Nidhi Hegde", "Sujoy Paul", "Gagan Madan", "Gaurav Aggarwal"], "Categories": "cs.CV cs.AI"}, "abstract": "Recent document question answering models consist of two key components: the vision encoder, which captures layout and visual elements in images, and a Large Language Model (LLM) that helps contextualize questions to the image and supplements them with external world knowledge to generate accurate answers. However, the relative contributions of the vision encoder and the language model in these tasks remain unclear. This is especially interesting given the effectiveness of instruction-tuned LLMs, which exhibit remarkable adaptability to new tasks. To this end, we explore the following aspects in this work: (1) The efficacy of an LLM-only approach on document question answering tasks (2) strategies for serializing textual information within document images and feeding it directly to an instruction-tuned LLM, thus bypassing the need for an explicit vision encoder (3) thorough quantitative analysis on the feasibility of such an approach. Our comprehensive analysis encompasses six diverse benchmark datasets, utilizing LLMs of varying scales. Our findings reveal that a strategy exclusively reliant on the LLM yields results that are on par with or closely approach state-of-the-art performance across a range of datasets. We posit that this evaluation framework will serve as a guiding resource for selecting appropriate datasets for future research endeavors that emphasize the fundamental importance of layout and image content information.", "url": "https://arxiv.org/abs/2309.14389"}, {"metadata": {"arXiv": "2309.14478", "Date": "Mon, 25 Sep 2023 19:22:57 ", "Title": "Incorporating Ensemble and Transfer Learning For An End-To-End Auto-Colorized Image Detection Model", "Authors": ["Ahmed Samir Ragab", "Shereen Aly Taie", "Howida Youssry Abdelnaby"], "Categories": "cs.CV cs.AI", "Journal-ref": "Journal of Theoretical and Applied Information Technology 15th September 2023 -- Vol. 101. No. 17-- 2023"}, "abstract": "Image colorization is the process of colorizing grayscale images or recoloring an already-color image. This image manipulation can be used for grayscale satellite, medical and historical images making them more expressive. With the help of the increasing computation power of deep learning techniques, the colorization algorithms results are becoming more realistic in such a way that human eyes cannot differentiate between natural and colorized images. However, this poses a potential security concern, as forged or illegally manipulated images can be used illegally. There is a growing need for effective detection methods to distinguish between natural color and computer-colorized images. This paper presents a novel approach that combines the advantages of transfer and ensemble learning approaches to help reduce training time and resource requirements while proposing a model to classify natural color and computer-colorized images. The proposed model uses pre-trained branches VGG16 and Resnet50, along with Mobile Net v2 or Efficientnet feature vectors. The proposed model showed promising results, with accuracy ranging from 94.55% to 99.13% and very low Half Total Error Rate values. The proposed model outperformed existing state-of-the-art models regarding classification performance and generalization capabilities.", "url": "https://arxiv.org/abs/2309.14478"}, {"metadata": {"arXiv": "2309.14564", "Date": "Mon, 25 Sep 2023 22:24:02 ", "Title": "Generative Escher Meshes", "Authors": ["Noam Aigerman and Thibault Groueix"], "Categories": "cs.CV cs.AI cs.CG cs.GR"}, "abstract": "This paper proposes a fully-automatic, text-guided generative method for producing periodic, repeating, tile-able 2D art, such as the one seen on floors, mosaics, ceramics, and the work of M.C. Escher. In contrast to the standard concept of a seamless texture, i.e., square images that are seamless when tiled, our method generates non-square tilings which comprise solely of repeating copies of the same object. It achieves this by optimizing both geometry and color of a 2D mesh, in order to generate a non-square tile in the shape and appearance of the desired object, with close to no additional background details. We enable geometric optimization of tilings by our key technical contribution: an unconstrained, differentiable parameterization of the space of all possible tileable shapes for a given symmetry group. Namely, we prove that modifying the laplacian used in a 2D mesh-mapping technique - Orbifold Tutte Embedding - can achieve all possible tiling configurations for a chosen planar symmetry group. We thus consider both the mesh's tile-shape and its texture as optimizable parameters, rendering the textured mesh via a differentiable renderer. We leverage a trained image diffusion model to define a loss on the resulting image, thereby updating the mesh's parameters based on its appearance matching the text prompt. We show our method is able to produce plausible, appealing results, with non-trivial tiles, for a variety of different periodic tiling patterns.", "url": "https://arxiv.org/abs/2309.14564"}, {"metadata": {"arXiv": "2309.14622", "Date": "Tue, 26 Sep 2023 02:21:23 ", "Title": "Divide and Conquer in Video Anomaly Detection: A Comprehensive Review and New Approach", "Authors": ["Jian Xiao", "Tianyuan Liu", "Genlin Ji"], "Categories": "cs.CV cs.AI"}, "abstract": "Video anomaly detection is a complex task, and the principle of \"divide and conquer\" is often regarded as an effective approach to tackling intricate issues. It's noteworthy that recent methods in video anomaly detection have revealed the application of the divide and conquer philosophy (albeit with distinct perspectives from traditional usage), yielding impressive outcomes. This paper systematically reviews these literatures from six dimensions, aiming to enhance the use of the divide and conquer strategy in video anomaly detection. Furthermore, based on the insights gained from this review, a novel approach is presented, which integrates human skeletal frameworks with video data analysis techniques. This method achieves state-of-the-art performance on the ShanghaiTech dataset, surpassing all existing advanced methods.", "url": "https://arxiv.org/abs/2309.14622"}, {"metadata": {"arXiv": "2309.14660", "Date": "Tue, 26 Sep 2023 04:32:38 ", "Title": "CoFiI2P: Coarse-to-Fine Correspondences for Image-to-Point Cloud Registration", "Authors": ["Shuhao Kang", "Youqi Liao", "Jianping Li", "Fuxun Liang", "Yuhao Li", "Fangning Li", "Zhen Dong", "Bisheng Yang"], "Categories": "cs.CV cs.AI cs.RO", "Comments": ["demo video: https://youtu.be/TG2GBrJTuW4 source code: https://github.com/kang-1-2-3/CoFiI2P"]}, "abstract": "Image-to-point cloud (I2P) registration is a fundamental task in the fields of robot navigation and mobile mapping. Existing I2P registration works estimate correspondences at the point-to-pixel level, neglecting the global alignment. However, I2P matching without high-level guidance from global constraints may converge to the local optimum easily. To solve the problem, this paper proposes CoFiI2P, a novel I2P registration network that extracts correspondences in a coarse-to-fine manner for the global optimal solution. First, the image and point cloud are fed into a Siamese encoder-decoder network for hierarchical feature extraction. Then, a coarse-to-fine matching module is designed to exploit features and establish resilient feature correspondences. Specifically, in the coarse matching block, a novel I2P transformer module is employed to capture the homogeneous and heterogeneous global information from image and point cloud. With the discriminate descriptors, coarse super-point-to-super-pixel matching pairs are estimated. In the fine matching module, point-to-pixel pairs are established with the super-point-to-super-pixel correspondence supervision. Finally, based on matching pairs, the transform matrix is estimated with the EPnP-RANSAC algorithm. Extensive experiments conducted on the KITTI dataset have demonstrated that CoFiI2P achieves a relative rotation error (RRE) of 2.25 degrees and a relative translation error (RTE) of 0.61 meters. These results represent a significant improvement of 14% in RRE and 52% in RTE compared to the current state-of-the-art (SOTA) method. The demo video for the experiments is available at https://youtu.be/TG2GBrJTuW4. The source code will be public at https://github.com/kang-1-2-3/CoFiI2P.", "url": "https://arxiv.org/abs/2309.14660"}, {"metadata": {"arXiv": "2309.14793", "Date": "Tue, 26 Sep 2023 09:42:21 ", "Title": "Semantic Map Learning of Traffic Light to Lane Assignment based on Motion Data", "Authors": ["Thomas Monninger", "Andreas Weber", "Steffen Staab"], "Categories": "cs.CV cs.AI cs.RO"}, "abstract": "Understanding which traffic light controls which lane is crucial to navigate intersections safely. Autonomous vehicles commonly rely on High Definition (HD) maps that contain information about the assignment of traffic lights to lanes. The manual provisioning of this information is tedious, expensive, and not scalable. To remedy these issues, our novel approach derives the assignments from traffic light states and the corresponding motion patterns of vehicle traffic. This works in an automated way and independently of the geometric arrangement. We show the effectiveness of basic statistical approaches for this task by implementing and evaluating a pattern-based contribution method. In addition, our novel rejection method includes accompanying safety considerations by leveraging statistical hypothesis testing. Finally, we propose a dataset transformation to re-purpose available motion prediction datasets for semantic map learning. Our publicly available API for the Lyft Level 5 dataset enables researchers to develop and evaluate their own approaches.", "url": "https://arxiv.org/abs/2309.14793"}, {"metadata": {"arXiv": "2309.14950", "Date": "Tue, 26 Sep 2023 14:08:03 ", "Title": "Multi-Source Domain Adaptation for Object Detection with Prototype-based Mean-teacher", "Authors": ["Atif Belal", "Akhil Meethal", "Francisco Perdigon Romero", "Marco Pedersoli", "Eric Granger"], "Categories": "cs.CV cs.AI"}, "abstract": "Adapting visual object detectors to operational target domains is a challenging task, commonly achieved using unsupervised domain adaptation (UDA) methods. When the labeled dataset is coming from multiple source domains, treating them as separate domains and performing a multi-source domain adaptation (MSDA) improves the accuracy and robustness over mixing these source domains and performing a UDA, as observed by recent studies in MSDA. Existing MSDA methods learn domain invariant and domain-specific parameters (for each source domain) for the adaptation. However, unlike single-source UDA methods, learning domain-specific parameters makes them grow significantly proportional to the number of source domains used. This paper proposes a novel MSDA method called Prototype-based Mean-Teacher (PMT), which uses class prototypes instead of domain-specific subnets to preserve domain-specific information. These prototypes are learned using a contrastive loss, aligning the same categories across domains and separating different categories far apart. Because of the use of prototypes, the parameter size of our method does not increase significantly with the number of source domains, thus reducing memory issues and possible overfitting. Empirical studies show PMT outperforms state-of-the-art MSDA methods on several challenging object detection datasets.", "url": "https://arxiv.org/abs/2309.14950"}, {"metadata": {"arXiv": "2309.14972", "Date": "Tue, 26 Sep 2023 14:44:48 ", "Title": "Improving Unsupervised Visual Program Inference with Code Rewriting Families", "Authors": ["Aditya Ganeshan", "R. Kenny Jones and Daniel Ritchie"], "Categories": "cs.CV cs.AI cs.GR", "Comments": ["Accepted at ICCV 23 (oral). Website: https://bardofcodes.github.io/coref/"]}, "abstract": "Programs offer compactness and structure that makes them an attractive representation for visual data. We explore how code rewriting can be used to improve systems for inferring programs from visual data. We first propose Sparse Intermittent Rewrite Injection (SIRI), a framework for unsupervised bootstrapped learning. SIRI sparsely applies code rewrite operations over a dataset of training programs, injecting the improved programs back into the training set. We design a family of rewriters for visual programming domains: parameter optimization, code pruning, and code grafting. For three shape programming languages in 2D and 3D, we show that using SIRI with our family of rewriters improves performance: better reconstructions and faster convergence rates, compared with bootstrapped learning methods that do not use rewriters or use them naively. Finally, we demonstrate that our family of rewriters can be effectively used at test time to improve the output of SIRI predictions. For 2D and 3D CSG, we outperform or match the reconstruction performance of recent domain-specific neural architectures, while producing more parsimonious programs that use significantly fewer primitives.", "url": "https://arxiv.org/abs/2309.14972"}, {"metadata": {"arXiv": "2309.15018", "Date": "Tue, 26 Sep 2023 15:38:26 ", "Title": "Unidirectional brain-computer interface: Artificial neural network encoding natural images to fMRI response in the visual cortex", "Authors": ["Ruixing Liang", "Xiangyu Zhang", "Qiong Li", "Lai Wei", "Hexin Liu", "Avisha Kumar", "Kelley M. Kempski Leadingham", "Joshua Punnoose", "Leibny Paola Garcia", "Amir Manbachi"], "Categories": "cs.CV cs.AI cs.HC q-bio.NC"}, "abstract": "While significant advancements in artificial intelligence (AI) have catalyzed progress across various domains, its full potential in understanding visual perception remains underexplored. We propose an artificial neural network dubbed VISION, an acronym for \"Visual Interface System for Imaging Output of Neural activity,\" to mimic the human brain and show how it can foster neuroscientific inquiries. Using visual and contextual inputs, this multimodal model predicts the brain's functional magnetic resonance imaging (fMRI) scan response to natural images. VISION successfully predicts human hemodynamic responses as fMRI voxel values to visual inputs with an accuracy exceeding state-of-the-art performance by 45%. We further probe the trained networks to reveal representational biases in different visual areas, generate experimentally testable hypotheses, and formulate an interpretable metric to associate these hypotheses with cortical functions. With both a model and evaluation metric, the cost and time burdens associated with designing and implementing functional analysis on the visual cortex could be reduced. Our work suggests that the evolution of computational models may shed light on our fundamental understanding of the visual cortex and provide a viable approach toward reliable brain-machine interfaces.", "url": "https://arxiv.org/abs/2309.15018"}, {"metadata": {"arXiv": "2309.15110", "Date": "Tue, 26 Sep 2023 17:56:31 ", "Title": "Doduo: Learning Dense Visual Correspondence from Unsupervised Semantic-Aware Flow", "Authors": ["Zhenyu Jiang", "Hanwen Jiang", "Yuke Zhu"], "Categories": "cs.CV cs.AI cs.RO", "Comments": ["Project website: https://ut-austin-rpl.github.io/Doduo"]}, "abstract": "Dense visual correspondence plays a vital role in robotic perception. This work focuses on establishing the dense correspondence between a pair of images that captures dynamic scenes undergoing substantial transformations. We introduce Doduo to learn general dense visual correspondence from in-the-wild images and videos without ground truth supervision. Given a pair of images, it estimates the dense flow field encoding the displacement of each pixel in one image to its corresponding pixel in the other image. Doduo uses flow-based warping to acquire supervisory signals for the training. Incorporating semantic priors with self-supervised flow training, Doduo produces accurate dense correspondence robust to the dynamic changes of the scenes. Trained on an in-the-wild video dataset, Doduo illustrates superior performance on point-level correspondence estimation over existing self-supervised correspondence learning baselines. We also apply Doduo to articulation estimation and zero-shot goal-conditioned manipulation, underlining its practical applications in robotics. Code and additional visualizations are available at https://ut-austin-rpl.github.io/Doduo", "url": "https://arxiv.org/abs/2309.15110"}, {"metadata": {"arXiv": "2309.15049", "Date": "Tue, 26 Sep 2023 16:26:17 ", "Title": "When Prolog meets generative models: a new approach for managing knowledge and planning in robotic applications", "Authors": ["Enrico Saccon", "Ahmet Tikna", "Davide De Martini", "Edoardo Lamon", "Marco Roveri", "Luigi Palopoli (Department of Information Engineering and Computer Science", "Universit\\`a di Trento", "Trento", "Italy)"], "Categories": "cs.RO cs.AI", "Comments": ["7 pages", "4 figures", "submitted to ICRA 2024"]}, "abstract": "In this paper, we propose a robot oriented knowledge management system based on the use of the Prolog language. Our framework hinges on a special organisation of knowledge base that enables: 1. its efficient population from natural language texts using semi-automated procedures based on Large Language Models, 2. the bumpless generation of temporal parallel plans for multi-robot systems through a sequence of transformations, 3. the automated translation of the plan into an executable formalism (the behaviour trees). The framework is supported by a set of open source tools and is shown on a realistic application.", "url": "https://arxiv.org/abs/2309.15049"}, {"metadata": {"arXiv": "2309.14726", "Date": "Tue, 26 Sep 2023 07:36:20 ", "Title": "PLMM: Personal Large Models on Mobile Devices", "Authors": ["Yuanhao Gong"], "Categories": "cs.CV cs.AI cs.CE cs.CL cs.LG", "Comments": ["arXiv admin note: substantial text overlap with arXiv:2307.13221"]}, "abstract": "Inspired by Federated Learning, in this paper, we propose personal large models that are distilled from traditional large language models but more adaptive to local users' personal information such as education background and hobbies. We classify the large language models into three levels: the personal level, expert level and traditional level. The personal level models are adaptive to users' personal information. They encrypt the users' input and protect their privacy. The expert level models focus on merging specific knowledge such as finance, IT and art. The traditional models focus on the universal knowledge discovery and upgrading the expert models. In such classifications, the personal models directly interact with the user. For the whole system, the personal models have users' (encrypted) personal information. Moreover, such models must be small enough to be performed on personal computers or mobile devices. Finally, they also have to response in real-time for better user experience and produce high quality results. The proposed personal large models can be applied in a wide range of applications such as language and vision tasks.", "url": "https://arxiv.org/abs/2309.14726"}, {"metadata": {"arXiv": "2309.14859", "Date": "Tue, 26 Sep 2023 11:36:26 ", "Title": "Navigating Text-To-Image Customization:From LyCORIS Fine-Tuning to Model Evaluation", "Authors": ["Shin-Ying Yeh", "Yu-Guan Hsieh", "Zhidong Gao", "Bernard B W Yang", "Giyeong Oh", "Yanmin Gong"], "Categories": "cs.CV cs.AI cs.GR cs.LG", "Comments": ["77 pages", "54 figures", "6 tables"]}, "abstract": "Text-to-image generative models have garnered immense attention for their ability to produce high-fidelity images from text prompts. Among these, Stable Diffusion distinguishes itself as a leading open-source model in this fast-growing field. However, the intricacies of fine-tuning these models pose multiple challenges from new methodology integration to systematic evaluation. Addressing these issues, this paper introduces LyCORIS (Lora beYond Conventional methods, Other Rank adaptation Implementations for Stable diffusion) [https://github.com/KohakuBlueleaf/LyCORIS], an open-source library that offers a wide selection of fine-tuning methodologies for Stable Diffusion. Furthermore, we present a thorough framework for the systematic assessment of varied fine-tuning techniques. This framework employs a diverse suite of metrics and delves into multiple facets of fine-tuning, including hyperparameter adjustments and the evaluation with different prompt types across various concept categories. Through this comprehensive approach, our work provides essential insights into the nuanced effects of fine-tuning parameters, bridging the gap between state-of-the-art research and practical application.", "url": "https://arxiv.org/abs/2309.14859"}, {"metadata": {"arXiv": "2309.15091", "Date": "Tue, 26 Sep 2023 17:36:26 ", "Title": "VideoDirectorGPT: Consistent Multi-scene Video Generation via LLM-Guided Planning", "Authors": ["Han Lin", "Abhay Zala", "Jaemin Cho", "Mohit Bansal"], "Categories": "cs.CV cs.AI cs.CL cs.LG", "Comments": ["Project page: https://videodirectorgpt.github.io"]}, "abstract": "Although recent text-to-video (T2V) generation methods have seen significant advancements, most of these works focus on producing short video clips of a single event with a single background (i.e., single-scene videos). Meanwhile, recent large language models (LLMs) have demonstrated their capability in generating layouts and programs to control downstream visual modules such as image generation models. This raises an important question: can we leverage the knowledge embedded in these LLMs for temporally consistent long video generation? In this paper, we propose VideoDirectorGPT, a novel framework for consistent multi-scene video generation that uses the knowledge of LLMs for video content planning and grounded video generation. Specifically, given a single text prompt, we first ask our video planner LLM (GPT-4) to expand it into a 'video plan', which involves generating the scene descriptions, the entities with their respective layouts, the background for each scene, and consistency groupings of the entities and backgrounds. Next, guided by this output from the video planner, our video generator, Layout2Vid, has explicit control over spatial layouts and can maintain temporal consistency of entities/backgrounds across scenes, while only trained with image-level annotations. Our experiments demonstrate that VideoDirectorGPT framework substantially improves layout and movement control in both single- and multi-scene video generation and can generate multi-scene videos with visual consistency across scenes, while achieving competitive performance with SOTAs in open-domain single-scene T2V generation. We also demonstrate that our framework can dynamically control the strength for layout guidance and can also generate videos with user-provided images. We hope our framework can inspire future work on better integrating the planning ability of LLMs into consistent long video generation.", "url": "https://arxiv.org/abs/2309.15091"}, {"metadata": {"arXiv": "2309.14349", "Date": "Tue, 19 Sep 2023 03:39:12 ", "Title": "Corporate Credit Rating: A Survey", "Authors": ["Bojing Feng", "Xi Cheng", "Dan Li", "Zeyu Liu", "Wenfang Xue"], "Categories": "cs.LG cs.AI", "Comments": ["11 pages"]}, "abstract": "Corporate credit rating (CCR) plays a very important role in the process of contemporary economic and social development. How to use credit rating methods for enterprises has always been a problem worthy of discussion. Through reading and studying the relevant literature at home and abroad, this paper makes a systematic survey of CCR. This paper combs the context of the development of CCR methods from the three levels: statistical models, machine learning models and neural network models, summarizes the common databases of CCR, and deeply compares the advantages and disadvantages of the models. Finally, this paper summarizes the problems existing in the current research and prospects the future of CCR. Compared with the existing review of CCR, this paper expounds and analyzes the progress of neural network model in this field in recent years.", "url": "https://arxiv.org/abs/2309.14349"}, {"metadata": {"arXiv": "2309.14385", "Date": "Mon, 25 Sep 2023 02:46:19 ", "Title": "Sampling - Variational Auto Encoder - Ensemble: In the Quest of Explainable Artificial Intelligence", "Authors": ["Sarit Maitra", "Vivek Mishra", "Pratima Verma", "Manav Chopra", "Priyanka Nath"], "Categories": "cs.LG cs.AI", "Comments": ["8 pages", "10 figures", "IEEE conference (IEIT 2023)"]}, "abstract": "Explainable Artificial Intelligence (XAI) models have recently attracted a great deal of interest from a variety of application sectors. Despite significant developments in this area, there are still no standardized methods or approaches for understanding AI model outputs. A systematic and cohesive framework is also increasingly necessary to incorporate new techniques like discriminative and generative models to close the gap. This paper contributes to the discourse on XAI by presenting an empirical evaluation based on a novel framework: Sampling - Variational Auto Encoder (VAE) - Ensemble Anomaly Detection (SVEAD). It is a hybrid architecture where VAE combined with ensemble stacking and SHapley Additive exPlanations are used for imbalanced classification. The finding reveals that combining ensemble stacking, VAE, and SHAP can. not only lead to better model performance but also provide an easily explainable framework. This work has used SHAP combined with Permutation Importance and Individual Conditional Expectations to create a powerful interpretability of the model. The finding has an important implication in the real world, where the need for XAI is paramount to boost confidence in AI applications.", "url": "https://arxiv.org/abs/2309.14385"}, {"metadata": {"arXiv": "2309.14390", "Date": "Mon, 25 Sep 2023 08:44:32 ", "Title": "Early Churn Prediction from Large Scale User-Product Interaction Time Series", "Authors": ["Shamik Bhattacharjee", "Utkarsh Thukral", "Nilesh Patil"], "Categories": "cs.LG cs.AI", "Comments": ["12 pages", "3 tables", "8 figures", "Accepted in ICMLA"], "ACM-class": "I.2.1"}, "abstract": "User churn, characterized by customers ending their relationship with a business, has profound economic consequences across various Business-to-Customer scenarios. For numerous system-to-user actions, such as promotional discounts and retention campaigns, predicting potential churners stands as a primary objective. In volatile sectors like fantasy sports, unpredictable factors such as international sports events can influence even regular spending habits. Consequently, while transaction history and user-product interaction are valuable in predicting churn, they demand deep domain knowledge and intricate feature engineering. Additionally, feature development for churn prediction systems can be resource-intensive, particularly in production settings serving 200m+ users, where inference pipelines largely focus on feature engineering. This paper conducts an exhaustive study on predicting user churn using historical data. We aim to create a model forecasting customer churn likelihood, facilitating businesses in comprehending attrition trends and formulating effective retention plans. Our approach treats churn prediction as multivariate time series classification, demonstrating that combining user activity and deep neural networks yields remarkable results for churn prediction in complex business-to-customer contexts.", "url": "https://arxiv.org/abs/2309.14390"}, {"metadata": {"arXiv": "2309.14391", "Date": "Mon, 25 Sep 2023 09:05:36 ", "Title": "An AI Chatbot for Explaining Deep Reinforcement Learning Decisions of Service-oriented Systems", "Authors": ["Andreas Metzger", "Jone Bartel", "Jan Laufer"], "Categories": "cs.LG cs.AI cs.CL", "Comments": ["To be published at 21st Int'l Conference on Service-Oriented Computing (ICSOC 2023)", "Rome", "Italy", "November 28-December 1", "2023", "ser. LNCS", "F. Monti", "S. Rinderle-Ma", "A. Ruiz Cortes", "Z. Zheng", "M. Mecella", "Eds.", "Springer", "2023"]}, "abstract": "Deep Reinforcement Learning (Deep RL) is increasingly used to cope with the open-world assumption in service-oriented systems. Deep RL was successfully applied to problems such as dynamic service composition, job scheduling, and offloading, as well as service adaptation. While Deep RL offers many benefits, understanding the decision-making of Deep RL is challenging because its learned decision-making policy essentially appears as a black box. Yet, understanding the decision-making of Deep RL is key to help service developers perform debugging, support service providers to comply with relevant legal frameworks, and facilitate service users to build trust. We introduce Chat4XAI to facilitate the understanding of the decision-making of Deep RL by providing natural-language explanations. Compared with visual explanations, the reported benefits of natural-language explanations include better understandability for non-technical users, increased user acceptance and trust, as well as more efficient explanations. Chat4XAI leverages modern AI chatbot technology and dedicated prompt engineering. Compared to earlier work on natural-language explanations using classical software-based dialogue systems, using an AI chatbot eliminates the need for eliciting and defining potential questions and answers up-front. We prototypically realize Chat4XAI using OpenAI's ChatGPT API and evaluate the fidelity and stability of its explanations using an adaptive service exemplar.", "url": "https://arxiv.org/abs/2309.14391"}, {"metadata": {"arXiv": "2309.14395", "Date": "Mon, 25 Sep 2023 15:33:08 ", "Title": "Implicit Sensing in Traffic Optimization: Advanced Deep Reinforcement Learning Techniques", "Authors": ["Emanuel Figetakis", "Yahuza Bello", "Ahmed Refaey", "Lei Lei", "Medhat Moussa"], "Categories": "cs.LG cs.AI"}, "abstract": "A sudden roadblock on highways due to many reasons such as road maintenance, accidents, and car repair is a common situation we encounter almost daily. Autonomous Vehicles (AVs) equipped with sensors that can acquire vehicle dynamics such as speed, acceleration, and location can make intelligent decisions to change lanes before reaching a roadblock. A number of literature studies have examined car-following models and lane-changing models. However, only a few studies proposed an integrated car-following and lane-changing model, which has the potential to model practical driving maneuvers. Hence, in this paper, we present an integrated car-following and lane-changing decision-control system based on Deep Reinforcement Learning (DRL) to address this issue. Specifically, we consider a scenario where sudden construction work will be carried out along a highway. We model the scenario as a Markov Decision Process (MDP) and employ the well-known DQN algorithm to train the RL agent to make the appropriate decision accordingly (i.e., either stay in the same lane or change lanes). To overcome the delay and computational requirement of DRL algorithms, we adopt an MEC-assisted architecture where the RL agents are trained on MEC servers. We utilize the highly reputable SUMO simulator and OPENAI GYM to evaluate the performance of the proposed model under two policies; {\\epsilon}-greedy policy and Boltzmann policy. The results unequivocally demonstrate that the DQN agent trained using the {\\epsilon}-greedy policy significantly outperforms the one trained with the Boltzmann policy.", "url": "https://arxiv.org/abs/2309.14395"}, {"metadata": {"arXiv": "2309.14398", "Date": "Mon, 25 Sep 2023 16:00:06 ", "Title": "Seeing and hearing what has not been said; A multimodal client behavior classifier in Motivational Interviewing with interpretable fusion", "Authors": ["Lucie Galland", "Catherine Pelachaud and Florian Pecune"], "Categories": "cs.LG cs.AI cs.CL eess.AS", "Comments": ["9 pages", "7 figures"]}, "abstract": "Motivational Interviewing (MI) is an approach to therapy that emphasizes collaboration and encourages behavioral change. To evaluate the quality of an MI conversation, client utterances can be classified using the MISC code as either change talk, sustain talk, or follow/neutral talk. The proportion of change talk in a MI conversation is positively correlated with therapy outcomes, making accurate classification of client utterances essential. In this paper, we present a classifier that accurately distinguishes between the three MISC classes (change talk, sustain talk, and follow/neutral talk) leveraging multimodal features such as text, prosody, facial expressivity, and body expressivity. To train our model, we perform annotations on the publicly available AnnoMI dataset to collect multimodal information, including text, audio, facial expressivity, and body expressivity. Furthermore, we identify the most important modalities in the decision-making process, providing valuable insights into the interplay of different modalities during a MI conversation.", "url": "https://arxiv.org/abs/2309.14398"}, {"metadata": {"arXiv": "2309.14471", "Date": "Mon, 25 Sep 2023 19:09:54 ", "Title": "Adapting Double Q-Learning for Continuous Reinforcement Learning", "Authors": ["Arsenii Kuznetsov"], "Categories": "cs.LG cs.AI"}, "abstract": "Majority of off-policy reinforcement learning algorithms use overestimation bias control techniques. Most of these techniques rooted in heuristics, primarily addressing the consequences of overestimation rather than its fundamental origins. In this work we present a novel approach to the bias correction, similar in spirit to Double Q-Learning. We propose using a policy in form of a mixture with two components. Each policy component is maximized and assessed by separate networks, which removes any basis for the overestimation bias. Our approach shows promising near-SOTA results on a small set of MuJoCo environments.", "url": "https://arxiv.org/abs/2309.14471"}, {"metadata": {"arXiv": "2309.14496", "Date": "Mon, 25 Sep 2023 19:45:45 ", "Title": "Era Splitting", "Authors": ["Timothy DeLise"], "Categories": "cs.LG cs.AI cs.CE", "Comments": ["20 pages", "8 figures"]}, "abstract": "Real life machine learning problems exhibit distributional shifts in the data from one time to another or from on place to another. This behavior is beyond the scope of the traditional empirical risk minimization paradigm, which assumes i.i.d. distribution of data over time and across locations. The emerging field of out-of-distribution (OOD) generalization addresses this reality with new theory and algorithms which incorporate environmental, or era-wise information into the algorithms. So far, most research has been focused on linear models and/or neural networks. In this research we develop two new splitting criteria for decision trees, which allow us to apply ideas from OOD generalization research to decision tree models, including random forest and gradient-boosting decision trees. The new splitting criteria use era-wise information associated with each data point to allow tree-based models to find split points that are optimal across all disjoint eras in the data, instead of optimal over the entire data set pooled together, which is the default setting. We describe the new splitting criteria in detail and develop unique experiments to showcase the benefits of these new criteria, which improve metrics in our experiments out-of-sample. The new criteria are incorporated into the a state-of-the-art gradient boosted decision tree model in the Scikit-Learn code base, which is made freely available.", "url": "https://arxiv.org/abs/2309.14496"}, {"metadata": {"arXiv": "2309.14540", "Date": "Mon, 25 Sep 2023 21:28:52 ", "Title": "Effect of roundabout design on the behavior of road users: A case study of roundabouts with application of Unsupervised Machine Learning", "Authors": ["Tasnim M. Dwekat", "Ayda A. Almsre", "and Huthaifa I. Ashqar"], "Categories": "cs.LG cs.AI cs.CV cs.CY"}, "abstract": "This research aims to evaluate the performance of the rotors and study the behavior of the human driver in interacting with the rotors. In recent years, rotors have been increasingly used between countries due to their safety, capacity, and environmental advantages, and because they provide safe and fluid flows of vehicles for transit and integration. It turns out that roundabouts can significantly reduce speed at twisting intersections, entry speed and the resulting effect on speed depends on the rating of road users. In our research, (bus, car, truck) drivers were given special attention and their behavior was categorized into (conservative, normal, aggressive). Anticipating and recognizing driver behavior is an important challenge. Therefore, the aim of this research is to study the effect of roundabouts on these classifiers and to develop a method for predicting the behavior of road users at roundabout intersections. Safety is primarily due to two inherent features of the rotor. First, by comparing the data collected and processed in order to classify and evaluate drivers' behavior, and comparing the speeds of the drivers (bus, car and truck), the speed of motorists at crossing the roundabout was more fit than that of buses and trucks. We looked because the car is smaller and all parts of the rotor are visible to it. So drivers coming from all directions have to slow down, giving them more time to react and mitigating the consequences in the event of an accident. Second, with fewer conflicting flows (and points of conflict), drivers only need to look to their left (in right-hand traffic) for other vehicles, making their job of crossing the roundabout easier as there is less need to split attention between different directions.", "url": "https://arxiv.org/abs/2309.14540"}, {"metadata": {"arXiv": "2309.14580", "Date": "Tue, 26 Sep 2023 00:03:25 ", "Title": "CWCL: Cross-Modal Transfer with Continuously Weighted Contrastive Loss", "Authors": ["Rakshith Sharma Srinivasa", "Jaejin Cho", "Chouchang Yang", "Yashas Malur Saidutta", "Ching-Hua Lee", "Yilin Shen", "Hongxia Jin"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["Accepted to Neural Information Processing Systems (NeurIPS) 2023 conference"]}, "abstract": "This paper considers contrastive training for cross-modal 0-shot transfer wherein a pre-trained model in one modality is used for representation learning in another domain using pairwise data. The learnt models in the latter domain can then be used for a diverse set of tasks in a zero-shot way, similar to ``Contrastive Language-Image Pre-training (CLIP)'' and ``Locked-image Tuning (LiT)'' that have recently gained considerable attention. Most existing works for cross-modal representation alignment (including CLIP and LiT) use the standard contrastive training objective, which employs sets of positive and negative examples to align similar and repel dissimilar training data samples. However, similarity amongst training examples has a more continuous nature, thus calling for a more `non-binary' treatment. To address this, we propose a novel loss function called Continuously Weighted Contrastive Loss (CWCL) that employs a continuous measure of similarity. With CWCL, we seek to align the embedding space of one modality with another. Owing to the continuous nature of similarity in the proposed loss function, these models outperform existing methods for 0-shot transfer across multiple models, datasets and modalities. Particularly, we consider the modality pairs of image-text and speech-text and our models achieve 5-8% (absolute) improvement over previous state-of-the-art methods in 0-shot image classification and 20-30% (absolute) improvement in 0-shot speech-to-intent classification and keyword classification.", "url": "https://arxiv.org/abs/2309.14580"}, {"metadata": {"arXiv": "2309.14587", "Date": "Tue, 26 Sep 2023 00:26:29 ", "Title": "Joint Communication and Computation Framework for Goal-Oriented Semantic Communication with Distortion Rate Resilience", "Authors": ["Minh-Duong Nguyen", "Quang-Vinh Do", "Zhaohui Yang", "Quoc-Viet Pham", "Won-Joo Hwang"], "Categories": "cs.LG cs.AI cs.DC cs.IT eess.SP math.IT", "Comments": ["15 pages; 11 figures", "2 tables"], "MSC-class": "68T05", "ACM-class": "F.1.3"}, "abstract": "Recent research efforts on semantic communication have mostly considered accuracy as a main problem for optimizing goal-oriented communication systems. However, these approaches introduce a paradox: the accuracy of artificial intelligence (AI) tasks should naturally emerge through training rather than being dictated by network constraints. Acknowledging this dilemma, this work introduces an innovative approach that leverages the rate-distortion theory to analyze distortions induced by communication and semantic compression, thereby analyzing the learning process. Specifically, we examine the distribution shift between the original data and the distorted data, thus assessing its impact on the AI model's performance. Founding upon this analysis, we can preemptively estimate the empirical accuracy of AI tasks, making the goal-oriented semantic communication problem feasible. To achieve this objective, we present the theoretical foundation of our approach, accompanied by simulations and experiments that demonstrate its effectiveness. The experimental results indicate that our proposed method enables accurate AI task performance while adhering to network constraints, establishing it as a valuable contribution to the field of signal processing. Furthermore, this work advances research in goal-oriented semantic communication and highlights the significance of data-driven approaches in optimizing the performance of intelligent systems.", "url": "https://arxiv.org/abs/2309.14587"}, {"metadata": {"arXiv": "2309.14592", "Date": "Tue, 26 Sep 2023 00:58:36 ", "Title": "Efficient Post-training Quantization with FP8 Formats", "Authors": ["Haihao Shen", "Naveen Mellempudi", "Xin He", "Qun Gao", "Chang Wang", "and Mengni Wang"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "Recent advances in deep learning methods such as LLMs and Diffusion models have created a need for improved quantization methods that can meet the computational demands of these modern architectures while maintaining accuracy. Towards this goal, we study the advantages of FP8 data formats for post-training quantization across 75 unique network architectures covering a wide range of tasks, including machine translation, language modeling, text generation, image classification, generation, and segmentation. We examine three different FP8 representations (E5M2, E4M3, and E3M4) to study the effects of varying degrees of trade-off between dynamic range and precision on model accuracy. Based on our extensive study, we developed a quantization workflow that generalizes across different network architectures. Our empirical results show that FP8 formats outperform INT8 in multiple aspects, including workload coverage (92.64% vs. 65.87%), model accuracy and suitability for a broader range of operations. Furthermore, our findings suggest that E4M3 is better suited for NLP models, whereas E3M4 performs marginally better than E4M3 on computer vision tasks. The code is publicly available on Intel Neural Compressor: https://github.com/intel/neural-compressor.", "url": "https://arxiv.org/abs/2309.14592"}, {"metadata": {"arXiv": "2309.14610", "Date": "Tue, 26 Sep 2023 01:40:36 ", "Title": "Unsupervised Graph Deep Learning Reveals Emergent Flood Risk Profile of Urban Areas", "Authors": ["Kai Yin Ali Mostafavi"], "Categories": "cs.LG cs.AI cs.CY stat.AP", "Comments": ["24 pages"], "MSC-class": "I.2.1 Applications and Expert Systems"}, "abstract": "Urban flood risk emerges from complex and nonlinear interactions among multiple features related to flood hazard, flood exposure, and social and physical vulnerabilities, along with the complex spatial flood dependence relationships. Existing approaches for characterizing urban flood risk, however, are primarily based on flood plain maps, focusing on a limited number of features, primarily hazard and exposure features, without consideration of feature interactions or the dependence relationships among spatial areas. To address this gap, this study presents an integrated urban flood-risk rating model based on a novel unsupervised graph deep learning model (called FloodRisk-Net). FloodRisk-Net is capable of capturing spatial dependence among areas and complex and nonlinear interactions among flood hazards and urban features for specifying emergent flood risk. Using data from multiple metropolitan statistical areas (MSAs) in the United States, the model characterizes their flood risk into six distinct city-specific levels. The model is interpretable and enables feature analysis of areas within each flood-risk level, allowing for the identification of the three archetypes shaping the highest flood risk within each MSA. Flood risk is found to be spatially distributed in a hierarchical structure within each MSA, where the core city disproportionately bears the highest flood risk. Multiple cities are found to have high overall flood-risk levels and low spatial inequality, indicating limited options for balancing urban development and flood-risk reduction. Relevant flood-risk reduction strategies are discussed considering ways that the highest flood risk and uneven spatial distribution of flood risk are formed.", "url": "https://arxiv.org/abs/2309.14610"}, {"metadata": {"arXiv": "2309.14673", "Date": "Tue, 26 Sep 2023 04:59:49 ", "Title": "ALEX: Towards Effective Graph Transfer Learning with Noisy Labels", "Authors": ["Jingyang Yuan", "Xiao Luo", "Yifang Qin", "Zhengyang Mao", "Wei Ju", "Ming Zhang"], "Categories": "cs.LG cs.AI cs.IR cs.SI", "Comments": ["Accepted by the ACM International Conference on Multimedia (MM) 2023"]}, "abstract": "Graph Neural Networks (GNNs) have garnered considerable interest due to their exceptional performance in a wide range of graph machine learning tasks. Nevertheless, the majority of GNN-based approaches have been examined using well-annotated benchmark datasets, leading to suboptimal performance in real-world graph learning scenarios. To bridge this gap, the present paper investigates the problem of graph transfer learning in the presence of label noise, which transfers knowledge from a noisy source graph to an unlabeled target graph. We introduce a novel technique termed Balance Alignment and Information-aware Examination (ALEX) to address this challenge. ALEX first employs singular value decomposition to generate different views with crucial structural semantics, which help provide robust node representations using graph contrastive learning. To mitigate both label shift and domain shift, we estimate a prior distribution to build subgraphs with balanced label distributions. Building on this foundation, an adversarial domain discriminator is incorporated for the implicit domain alignment of complex multi-modal distributions. Furthermore, we project node representations into a different space, optimizing the mutual information between the projected features and labels. Subsequently, the inconsistency of similarity structures is evaluated to identify noisy samples with potential overfitting. Comprehensive experiments on various benchmark datasets substantiate the outstanding superiority of the proposed ALEX in different settings.", "url": "https://arxiv.org/abs/2309.14673"}, {"metadata": {"arXiv": "2309.14674", "Date": "Tue, 26 Sep 2023 05:01:07 ", "Title": "Leveraging Herpangina Data to Enhance Hospital-level Prediction of Hand-Foot-and-Mouth Disease Admissions Using UPTST", "Authors": ["Guoqi Yu", "Hailun Yao", "Huan Zheng and Ximing Xu"], "Categories": "cs.LG cs.AI"}, "abstract": "Outbreaks of hand-foot-and-mouth disease(HFMD) have been associated with significant morbidity and, in severe cases, mortality. Accurate forecasting of daily admissions of pediatric HFMD patients is therefore crucial for aiding the hospital in preparing for potential outbreaks and mitigating nosocomial transmissions. To address this pressing need, we propose a novel transformer-based model with a U-net shape, utilizing the patching strategy and the joint prediction strategy that capitalizes on insights from herpangina, a disease closely correlated with HFMD. This model also integrates representation learning by introducing reconstruction loss as an auxiliary loss. The results show that our U-net Patching Time Series Transformer (UPTST) model outperforms existing approaches in both long- and short-arm prediction accuracy of HFMD at hospital-level. Furthermore, the exploratory extension experiments show that the model's capabilities extend beyond prediction of infectious disease, suggesting broader applicability in various domains.", "url": "https://arxiv.org/abs/2309.14674"}, {"metadata": {"arXiv": "2309.14681", "Date": "Tue, 26 Sep 2023 05:10:08 ", "Title": "Are Human-generated Demonstrations Necessary for In-context Learning?", "Authors": ["Rui Li", "Guoyin Wang", "Jiwei Li"], "Categories": "cs.LG cs.AI", "Comments": ["Pre-print Version"]}, "abstract": "Despite the promising few-shot ability of large language models (LLMs), the standard paradigm of In-context Learning (ICL) suffers the disadvantages of susceptibility to selected demonstrations and the intricacy to generate these demonstrations. In this paper, we raise the fundamental question that whether human-generated demonstrations are necessary for ICL. To answer this question, we propose self-contemplation prompting strategy (SEC), a paradigm free from human-crafted demonstrations. The key point of SEC is that, instead of using hand-crafted examples as demonstrations in ICL, SEC asks LLMs to first create demonstrations on their own, based on which the final output is generated. SEC is a flexible framework and can be adapted to both the vanilla ICL and the chain-of-thought (CoT), but with greater ease: as the manual-generation process of both examples and rationale can be saved. Extensive experiments in arithmetic reasoning, commonsense reasoning, multi-task language understanding, and code generation benchmarks, show that SEC, which does not require hand-crafted demonstrations, significantly outperforms the zero-shot learning strategy, and achieves comparable results to ICL with hand-crafted demonstrations. This demonstrates that, for many tasks, contemporary LLMs possess a sufficient level of competence to exclusively depend on their own capacity for decision making, removing the need for external training data. Code is available at https://github.com/ruili33/SEC.", "url": "https://arxiv.org/abs/2309.14681"}, {"metadata": {"arXiv": "2309.14757", "Date": "Tue, 26 Sep 2023 08:37:21 ", "Title": "Age Minimization in Massive IoT via UAV Swarm: A Multi-agent Reinforcement Learning Approach", "Authors": ["Eslam Eldeeb", "Mohammad Shehab and Hirley Alves"], "Categories": "cs.LG cs.AI"}, "abstract": "In many massive IoT communication scenarios, the IoT devices require coverage from dynamic units that can move close to the IoT devices and reduce the uplink energy consumption. A robust solution is to deploy a large number of UAVs (UAV swarm) to provide coverage and a better line of sight (LoS) for the IoT network. However, the study of these massive IoT scenarios with a massive number of serving units leads to high dimensional problems with high complexity. In this paper, we apply multi-agent deep reinforcement learning to address the high-dimensional problem that results from deploying a swarm of UAVs to collect fresh information from IoT devices. The target is to minimize the overall age of information in the IoT network. The results reveal that both cooperative and partially cooperative multi-agent deep reinforcement learning approaches are able to outperform the high-complexity centralized deep reinforcement learning approach, which stands helpless in large-scale networks.", "url": "https://arxiv.org/abs/2309.14757"}, {"metadata": {"arXiv": "2309.14807", "Date": "Tue, 26 Sep 2023 10:05:46 ", "Title": "Evaluating Soccer Match Prediction Models: A Deep Learning Approach and Feature Optimization for Gradient-Boosted Trees", "Authors": ["Calvin Yeung", "Rory Bunker", "Rikuhei Umemoto", "Keisuke Fujii"], "Categories": "cs.LG cs.AI"}, "abstract": "Machine learning models have become increasingly popular for predicting the results of soccer matches, however, the lack of publicly-available benchmark datasets has made model evaluation challenging. The 2023 Soccer Prediction Challenge required the prediction of match results first in terms of the exact goals scored by each team, and second, in terms of the probabilities for a win, draw, and loss. The original training set of matches and features, which was provided for the competition, was augmented with additional matches that were played between 4 April and 13 April 2023, representing the period after which the training set ended, but prior to the first matches that were to be predicted (upon which the performance was evaluated). A CatBoost model was employed using pi-ratings as the features, which were initially identified as the optimal choice for calculating the win/draw/loss probabilities. Notably, deep learning models have frequently been disregarded in this particular task. Therefore, in this study, we aimed to assess the performance of a deep learning model and determine the optimal feature set for a gradient-boosted tree model. The model was trained using the most recent five years of data, and three training and validation sets were used in a hyperparameter grid search. The results from the validation sets show that our model had strong performance and stability compared to previously published models from the 2017 Soccer Prediction Challenge for win/draw/loss prediction.", "url": "https://arxiv.org/abs/2309.14807"}, {"metadata": {"arXiv": "2309.14808", "Date": "Tue, 26 Sep 2023 10:06:28 ", "Title": "Revisiting Softmax Masking for Stability in Continual Learning", "Authors": ["Hoyong Kim", "Minchan Kwon", "Kangil Kim"], "Categories": "cs.LG cs.AI"}, "abstract": "In continual learning, many classifiers use softmax function to learn confidence. However, numerous studies have pointed out its inability to accurately determine confidence distributions for outliers, often referred to as epistemic uncertainty. This inherent limitation also curtails the accurate decisions for selecting what to forget and keep in previously trained confidence distributions over continual learning process. To address the issue, we revisit the effects of masking softmax function. While this method is both simple and prevalent in literature, its implication for retaining confidence distribution during continual learning, also known as stability, has been under-investigated. In this paper, we revisit the impact of softmax masking, and introduce a methodology to utilize its confidence preservation effects. In class- and task-incremental learning benchmarks with and without memory replay, our approach significantly increases stability while maintaining sufficiently large plasticity. In the end, our methodology shows better overall performance than state-of-the-art methods, particularly in the use with zero or small memory. This lays a simple and effective foundation of strongly stable replay-based continual learning.", "url": "https://arxiv.org/abs/2309.14808"}, {"metadata": {"arXiv": "2309.14907", "Date": "Tue, 26 Sep 2023 13:09:43 ", "Title": "Label Deconvolution for Node Representation Learning on Large-scale Attributed Graphs against Learning Bias", "Authors": ["Zhihao Shi", "Jie Wang", "Fanghua Lu", "Hanzhu Chen", "Defu Lian", "Zheng Wang", "Jieping Ye", "Feng Wu"], "Categories": "cs.LG cs.AI"}, "abstract": "Node representation learning on attributed graphs -- whose nodes are associated with rich attributes (e.g., texts and protein sequences) -- plays a crucial role in many important downstream tasks. To encode the attributes and graph structures simultaneously, recent studies integrate pre-trained models with graph neural networks (GNNs), where pre-trained models serve as node encoders (NEs) to encode the attributes. As jointly training large NEs and GNNs on large-scale graphs suffers from severe scalability issues, many methods propose to train NEs and GNNs separately. Consequently, they do not take feature convolutions in GNNs into consideration in the training phase of NEs, leading to a significant learning bias from that by the joint training. To address this challenge, we propose an efficient label regularization technique, namely Label Deconvolution (LD), to alleviate the learning bias by a novel and highly scalable approximation to the inverse mapping of GNNs. The inverse mapping leads to an objective function that is equivalent to that by the joint training, while it can effectively incorporate GNNs in the training phase of NEs against the learning bias. More importantly, we show that LD converges to the optimal objective function values by thejoint training under mild assumptions. Experiments demonstrate LD significantly outperforms state-of-the-art methods on Open Graph Benchmark datasets.", "url": "https://arxiv.org/abs/2309.14907"}, {"metadata": {"arXiv": "2309.14970", "Date": "Tue, 26 Sep 2023 14:42:28 ", "Title": "Recurrent Hypernetworks are Surprisingly Strong in Meta-RL", "Authors": ["Jacob Beck", "Risto Vuorio", "Zheng Xiong", "Shimon Whiteson"], "Categories": "cs.LG cs.AI cs.RO", "Comments": ["Published at NeurIPS 2023"]}, "abstract": "Deep reinforcement learning (RL) is notoriously impractical to deploy due to sample inefficiency. Meta-RL directly addresses this sample inefficiency by learning to perform few-shot learning when a distribution of related tasks is available for meta-training. While many specialized meta-RL methods have been proposed, recent work suggests that end-to-end learning in conjunction with an off-the-shelf sequential model, such as a recurrent network, is a surprisingly strong baseline. However, such claims have been controversial due to limited supporting evidence, particularly in the face of prior work establishing precisely the opposite. In this paper, we conduct an empirical investigation. While we likewise find that a recurrent network can achieve strong performance, we demonstrate that the use of hypernetworks is crucial to maximizing their potential. Surprisingly, when combined with hypernetworks, the recurrent baselines that are far simpler than existing specialized methods actually achieve the strongest performance of all methods evaluated.", "url": "https://arxiv.org/abs/2309.14970"}, {"metadata": {"arXiv": "2309.14994", "Date": "Tue, 26 Sep 2023 15:03:05 ", "Title": "Measurement Models For Sailboats Price vs. Features And Regional Areas", "Authors": ["Jiaqi Weng", "Chunlin Feng", "Yihan Shao"], "Categories": "cs.LG cs.AI", "Comments": ["20 pages", "17 figures"]}, "abstract": "In this study, we investigated the relationship between sailboat technical specifications and their prices, as well as regional pricing influences. Utilizing a dataset encompassing characteristics like length, beam, draft, displacement, sail area, and waterline, we applied multiple machine learning models to predict sailboat prices. The gradient descent model demonstrated superior performance, producing the lowest MSE and MAE. Our analysis revealed that monohulled boats are generally more affordable than catamarans, and that certain specifications such as length, beam, displacement, and sail area directly correlate with higher prices. Interestingly, lower draft was associated with higher listing prices. We also explored regional price determinants and found that the United States tops the list in average sailboat prices, followed by Europe, Hong Kong, and the Caribbean. Contrary to our initial hypothesis, a country's GDP showed no direct correlation with sailboat prices. Utilizing a 50% cross-validation method, our models yielded consistent results across test groups. Our research offers a machine learning-enhanced perspective on sailboat pricing, aiding prospective buyers in making informed decisions.", "url": "https://arxiv.org/abs/2309.14994"}, {"metadata": {"arXiv": "2309.15039", "Date": "Tue, 26 Sep 2023 16:15:54 ", "Title": "Combining Survival Analysis and Machine Learning for Mass Cancer Risk Prediction using EHR data", "Authors": ["Petr Philonenko", "Vladimir Kokh", "Pavel Blinov"], "Categories": "cs.LG cs.AI stat.AP"}, "abstract": "Purely medical cancer screening methods are often costly, time-consuming, and weakly applicable on a large scale. Advanced Artificial Intelligence (AI) methods greatly help cancer detection but require specific or deep medical data. These aspects affect the mass implementation of cancer screening methods. For these reasons, it is a disruptive change for healthcare to apply AI methods for mass personalized assessment of the cancer risk among patients based on the existing Electronic Health Records (EHR) volume. This paper presents a novel method for mass cancer risk prediction using EHR data. Among other methods, our one stands out by the minimum data greedy policy, requiring only a history of medical service codes and diagnoses from EHR. We formulate the problem as a binary classification. This dataset contains 175 441 de-identified patients (2 861 diagnosed with cancer). As a baseline, we implement a solution based on a recurrent neural network (RNN). We propose a method that combines machine learning and survival analysis since these approaches are less computationally heavy, can be combined into an ensemble (the Survival Ensemble), and can be reproduced in most medical institutions. We test the Survival Ensemble in some studies. Firstly, we obtain a significant difference between values of the primary metric (Average Precision) with 22.8% (ROC AUC 83.7%, F1 17.8%) for the Survival Ensemble versus 15.1% (ROC AUC 84.9%, F1 21.4%) for the Baseline. Secondly, the performance of the Survival Ensemble is also confirmed during the ablation study. Thirdly, our method exceeds age baselines by a significant margin. Fourthly, in the blind retrospective out-of-time experiment, the proposed method is reliable in cancer patient detection (9 out of 100 selected). Such results exceed the estimates of medical screenings, e.g., the best Number Needed to Screen (9 out of 1000 screenings).", "url": "https://arxiv.org/abs/2309.15039"}, {"metadata": {"arXiv": "2309.15048", "Date": "Tue, 26 Sep 2023 16:25:57 ", "Title": "Class Incremental Learning via Likelihood Ratio Based Task Prediction", "Authors": ["Haowei Lin", "Yijia Shao", "Weinan Qian", "Ningxin Pan", "Yiduo Guo", "Bing Liu"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "Class incremental learning (CIL) is a challenging setting of continual learning, which learns a series of tasks sequentially. Each task consists of a set of unique classes. The key feature of CIL is that no task identifier (or task-id) is provided at test time for each test sample. Predicting the task-id for each test sample is a challenging problem. An emerging theoretically justified and effective approach is to train a task-specific model for each task in a shared network for all tasks based on a task-incremental learning (TIL) method to deal with forgetting. The model for each task in this approach is an out-of-distribution (OOD) detector rather than a conventional classifier. The OOD detector can perform both within-task (in-distribution (IND)) class prediction and OOD detection. The OOD detection capability is the key for task-id prediction during inference for each test sample. However, this paper argues that using a traditional OOD detector for task-id prediction is sub-optimal because additional information (e.g., the replay data and the learned tasks) available in CIL can be exploited to design a better and principled method for task-id prediction. We call the new method TPLR (Task-id Prediction based on Likelihood Ratio}). TPLR markedly outperforms strong CIL baselines.", "url": "https://arxiv.org/abs/2309.15048"}, {"metadata": {"arXiv": "2309.14387", "Date": "Mon, 25 Sep 2023 06:46:19 ", "Title": "Exploring Robot Morphology Spaces through Breadth-First Search and Random Query", "Authors": ["Jie Luo"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["arXiv admin note: text overlap with arXiv:2303.12594. substantial text overlap with arXiv:2309.13099"]}, "abstract": "Evolutionary robotics offers a powerful framework for designing and evolving robot morphologies, particularly in the context of modular robots. However, the role of query mechanisms during the genotype-to-phenotype mapping process has been largely overlooked. This research addresses this gap by conducting a comparative analysis of query mechanisms in the brain-body co-evolution of modular robots. Using two different query mechanisms, Breadth-First Search (BFS) and Random Query, within the context of evolving robot morphologies using CPPNs and robot controllers using tensors, and testing them in two evolutionary frameworks, Lamarckian and Darwinian systems, this study investigates their influence on evolutionary outcomes and performance. The findings demonstrate the impact of the two query mechanisms on the evolution and performance of modular robot bodies, including morphological intelligence, diversity, and morphological traits. This study suggests that BFS is both more effective and efficient in producing highly performing robots. It also reveals that initially, robot diversity was higher with BFS compared to Random Query, but in the Lamarckian system, it declines faster, converging to superior designs, while in the Darwinian system, BFS led to higher end-process diversity.", "url": "https://arxiv.org/abs/2309.14387"}, {"metadata": {"arXiv": "2309.14425", "Date": "Mon, 25 Sep 2023 18:00:03 ", "Title": "Self-Recovery Prompting: Promptable General Purpose Service Robot System with Foundation Models and Self-Recovery", "Authors": ["Mimo Shirasaka", "Tatsuya Matsushima", "Soshi Tsunashima", "Yuya Ikeda", "Aoi Horo", "So Ikoma", "Chikaha Tsuji", "Hikaru Wada", "Tsunekazu Omija", "Dai Komukai", "Yutaka Matsuo Yusuke Iwasawa"], "Categories": "cs.RO cs.AI cs.CV cs.LG cs.SY eess.SY", "Comments": ["Website: https://sites.google.com/view/srgpsr"]}, "abstract": "A general-purpose service robot (GPSR), which can execute diverse tasks in various environments, requires a system with high generalizability and adaptability to tasks and environments. In this paper, we first developed a top-level GPSR system for worldwide competition (RoboCup@Home 2023) based on multiple foundation models. This system is both generalizable to variations and adaptive by prompting each model. Then, by analyzing the performance of the developed system, we found three types of failure in more realistic GPSR application settings: insufficient information, incorrect plan generation, and plan execution failure. We then propose the self-recovery prompting pipeline, which explores the necessary information and modifies its prompts to recover from failure. We experimentally confirm that the system with the self-recovery mechanism can accomplish tasks by resolving various failure cases. Supplementary videos are available at https://sites.google.com/view/srgpsr .", "url": "https://arxiv.org/abs/2309.14425"}, {"metadata": {"arXiv": "2309.14463", "Date": "Mon, 25 Sep 2023 18:54:32 ", "Title": "DefGoalNet: Contextual Goal Learning from Demonstrations For Deformable Object Manipulation", "Authors": ["Bao Thach", "Tanner Watts", "Shing-Hei Ho", "Tucker Hermans", "Alan Kuntz"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["Submitted to IEEE Conference on Robotics and Automation (ICRA) 2024. 8 pages", "11 figures"]}, "abstract": "Shape servoing, a robotic task dedicated to controlling objects to desired goal shapes, is a promising approach to deformable object manipulation. An issue arises, however, with the reliance on the specification of a goal shape. This goal has been obtained either by a laborious domain knowledge engineering process or by manually manipulating the object into the desired shape and capturing the goal shape at that specific moment, both of which are impractical in various robotic applications. In this paper, we solve this problem by developing a novel neural network DefGoalNet, which learns deformable object goal shapes directly from a small number of human demonstrations. We demonstrate our method's effectiveness on various robotic tasks, both in simulation and on a physical robot. Notably, in the surgical retraction task, even when trained with as few as 10 demonstrations, our method achieves a median success percentage of nearly 90%. These results mark a substantial advancement in enabling shape servoing methods to bring deformable object manipulation closer to practical, real-world applications.", "url": "https://arxiv.org/abs/2309.14463"}, {"metadata": {"arXiv": "2309.14552", "Date": "Mon, 25 Sep 2023 21:51:48 ", "Title": "Tactile Estimation of Extrinsic Contact Patch for Stable Placement", "Authors": ["Kei Ota", "Devesh K. Jha", "Krishna Murthy Jatavallabhula", "Asako Kanezaki", "and Joshua B. Tenenbaum"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["Under submission"]}, "abstract": "Precise perception of contact interactions is essential for the fine-grained manipulation skills for robots. In this paper, we present the design of feedback skills for robots that must learn to stack complex-shaped objects on top of each other. To design such a system, a robot should be able to reason about the stability of placement from very gentle contact interactions. Our results demonstrate that it is possible to infer the stability of object placement based on tactile readings during contact formation between the object and its environment. In particular, we estimate the contact patch between a grasped object and its environment using force and tactile observations to estimate the stability of the object during a contact formation. The contact patch could be used to estimate the stability of the object upon the release of the grasp. The proposed method is demonstrated on various pairs of objects that are used in a very popular board game.", "url": "https://arxiv.org/abs/2309.14552"}, {"metadata": {"arXiv": "2309.14566", "Date": "Mon, 25 Sep 2023 22:30:18 ", "Title": "Integrating Higher-Order Dynamics and Roadway-Compliance into Constrained ILQR-based Trajectory Planning for Autonomous Vehicles", "Authors": ["Hanxiang Li", "Jiaqiao Zhang", "Sheng Zhu", "Dongjian Tang", "Donghao Xu"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["6 pages", "3 figures"]}, "abstract": "This paper addresses the advancements in on-road trajectory planning for Autonomous Passenger Vehicles (APV). Trajectory planning aims to produce a globally optimal route for APVs, considering various factors such as vehicle dynamics, constraints, and detected obstacles. Traditional techniques involve a combination of sampling methods followed by optimization algorithms, where the former ensures global awareness and the latter refines for local optima. Notably, the Constrained Iterative Linear Quadratic Regulator (CILQR) optimization algorithm has recently emerged, adapted for APV systems, emphasizing improved safety and comfort. However, existing implementations utilizing the vehicle bicycle kinematic model may not guarantee controllable trajectories. We augment this model by incorporating higher-order terms, including the first and second-order derivatives of curvature and longitudinal jerk. This inclusion facilitates a richer representation in our cost and constraint design. We also address roadway compliance, emphasizing adherence to lane boundaries and directions, which past work often overlooked. Lastly, we adopt a relaxed logarithmic barrier function to address the CILQR's dependency on feasible initial trajectories. The proposed methodology is then validated through simulation and real-world experiment driving scenes in real time.", "url": "https://arxiv.org/abs/2309.14566"}, {"metadata": {"arXiv": "2309.14727", "Date": "Tue, 26 Sep 2023 07:38:19 ", "Title": "Effective Multi-Agent Deep Reinforcement Learning Control with Relative Entropy Regularization", "Authors": ["Chenyang Miao", "Yunduan Cui", "Huiyun Li", "Xinyu Wu"], "Categories": "eess.SY cs.AI cs.LG cs.SY"}, "abstract": "In this paper, a novel Multi-agent Reinforcement Learning (MARL) approach, Multi-Agent Continuous Dynamic Policy Gradient (MACDPP) was proposed to tackle the issues of limited capability and sample efficiency in various scenarios controlled by multiple agents. It alleviates the inconsistency of multiple agents' policy updates by introducing the relative entropy regularization to the Centralized Training with Decentralized Execution (CTDE) framework with the Actor-Critic (AC) structure. Evaluated by multi-agent cooperation and competition tasks and traditional control tasks including OpenAI benchmarks and robot arm manipulation, MACDPP demonstrates significant superiority in learning capability and sample efficiency compared with both related multi-agent and widely implemented signal-agent baselines and therefore expands the potential of MARL in effectively learning challenging control scenarios.", "url": "https://arxiv.org/abs/2309.14727"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

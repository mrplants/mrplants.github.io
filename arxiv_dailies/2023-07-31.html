<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2307.15067", "Date": "Thu, 22 Jun 2023 06:47:56 ", "Title": "Set-Membership Inference Attacks using Data Watermarking", "Authors": ["Mike Laszkiewicz", "Denis Lukovnikov", "Johannes Lederer", "Asja Fischer"], "Categories": "cs.CV cs.CR cs.LG", "Comments": ["Preliminary work"]}, "abstract": "In this work, we propose a set-membership inference attack for generative models using deep image watermarking techniques. In particular, we demonstrate how conditional sampling from a generative model can reveal the watermark that was injected into parts of the training data. Our empirical results demonstrate that the proposed watermarking technique is a principled approach for detecting the non-consensual use of image data in training generative models.", "url": "https://arxiv.org/abs/2307.15067"}, {"metadata": {"arXiv": "2307.15098", "Date": "Thu, 27 Jul 2023 14:17:24 ", "Title": "Self-Supervised Learning for Improved Synthetic Aperture Sonar Target Recognition", "Authors": ["BW Sheffield"], "Categories": "cs.CV cs.LG eess.IV"}, "abstract": "This study explores the application of self-supervised learning (SSL) for improved target recognition in synthetic aperture sonar (SAS) imagery. The unique challenges of underwater environments make traditional computer vision techniques, which rely heavily on optical camera imagery, less effective. SAS, with its ability to generate high-resolution imagery, emerges as a preferred choice for underwater imaging. However, the voluminous high-resolution SAS data presents a significant challenge for labeling; a crucial step for training deep neural networks (DNNs). SSL, which enables models to learn features in data without the need for labels, is proposed as a potential solution to the data labeling challenge in SAS. The study evaluates the performance of two prominent SSL algorithms, MoCov2 and BYOL, against the well-regarded supervised learning model, ResNet18, for binary image classification tasks. The findings suggest that while both SSL models can outperform a fully supervised model with access to a small number of labels in a few-shot scenario, they do not exceed it when all the labels are used. The results underscore the potential of SSL as a viable alternative to traditional supervised learning, capable of maintaining task performance while reducing the time and costs associated with data labeling. The study also contributes to the growing body of evidence supporting the use of SSL in remote sensing and could stimulate further research in this area.", "url": "https://arxiv.org/abs/2307.15098"}, {"metadata": {"arXiv": "2307.15099", "Date": "Thu, 27 Jul 2023 14:54:28 ", "Title": "Clustering of illustrations by atmosphere using a combination of supervised and unsupervised learning", "Authors": ["Keisuke Kubota (Doshisha University)", "Masahiro Okuda (Doshisha University)"], "Categories": "cs.CV cs.LG", "Comments": ["5 pages", "2 figures"], "ACM-class": "I.2.6; I.4.7; I.4.8"}, "abstract": "The distribution of illustrations on social media, such as Twitter and Pixiv has increased with the growing popularity of animation, games, and animated movies. The \"atmosphere\" of illustrations plays an important role in user preferences. Classifying illustrations by atmosphere can be helpful for recommendations and searches. However, assigning clear labels to the elusive \"atmosphere\" and conventional supervised classification is not always practical. Furthermore, even images with similar colors, edges, and low-level features may not have similar atmospheres, making classification based on low-level features challenging. In this paper, this problem is solved using both supervised and unsupervised learning with pseudo-labels. The feature vectors are obtained using the supervised method with pseudo-labels that contribute to an ambiguous atmosphere. Further, clustering is performed based on these feature vectors. Experimental analyses show that our method outperforms conventional methods in human-like clustering on datasets manually classified by humans.", "url": "https://arxiv.org/abs/2307.15099"}, {"metadata": {"arXiv": "2307.15105", "Date": "Thu, 27 Jul 2023 17:48:29 ", "Title": "Detecting Morphing Attacks via Continual Incremental Training", "Authors": ["Lorenzo Pellegrini", "Guido Borghi", "Annalisa Franco", "Davide Maltoni"], "Categories": "cs.CV cs.LG", "Comments": ["Paper accepted in IJCB 2023 conference"]}, "abstract": "Scenarios in which restrictions in data transfer and storage limit the possibility to compose a single dataset -- also exploiting different data sources -- to perform a batch-based training procedure, make the development of robust models particularly challenging. We hypothesize that the recent Continual Learning (CL) paradigm may represent an effective solution to enable incremental training, even through multiple sites. Indeed, a basic assumption of CL is that once a model has been trained, old data can no longer be used in successive training iterations and in principle can be deleted. Therefore, in this paper, we investigate the performance of different Continual Learning methods in this scenario, simulating a learning model that is updated every time a new chunk of data, even of variable size, is available. Experimental results reveal that a particular CL method, namely Learning without Forgetting (LwF), is one of the best-performing algorithms. Then, we investigate its usage and parametrization in Morphing Attack Detection and Object Classification tasks, specifically with respect to the amount of new training data that became available.", "url": "https://arxiv.org/abs/2307.15105"}, {"metadata": {"arXiv": "2307.15150", "Date": "Thu, 27 Jul 2023 18:53:14 ", "Title": "R-Block: Regularized Block of Dropout for convolutional networks", "Authors": ["Liqi Wang", "Qiya Hu"], "Categories": "cs.CV cs.LG"}, "abstract": "Dropout as a regularization technique is widely used in fully connected layers while is less effective in convolutional layers. Therefore more structured forms of dropout have been proposed to regularize convolutional networks. The disadvantage of these methods is that the randomness introduced causes inconsistency between training and inference. In this paper, we apply a mutual learning training strategy for convolutional layer regularization, namely R-Block, which forces two outputs of the generated difference maximizing sub models to be consistent with each other. Concretely, R-Block minimizes the losses between the output distributions of two sub models with different drop regions for each sample in the training dataset. We design two approaches to construct such sub models. Our experiments demonstrate that R-Block achieves better performance than other existing structured dropout variants. We also demonstrate that our approaches to construct sub models outperforms others.", "url": "https://arxiv.org/abs/2307.15150"}, {"metadata": {"arXiv": "2307.15157", "Date": "Thu, 27 Jul 2023 19:11:31 ", "Title": "R-LPIPS: An Adversarially Robust Perceptual Similarity Metric", "Authors": ["Sara Ghazanfari", "Siddharth Garg", "Prashanth Krishnamurthy", "Farshad Khorrami", "Alexandre Araujo"], "Categories": "cs.CV cs.LG eess.IV"}, "abstract": "Similarity metrics have played a significant role in computer vision to capture the underlying semantics of images. In recent years, advanced similarity metrics, such as the Learned Perceptual Image Patch Similarity (LPIPS), have emerged. These metrics leverage deep features extracted from trained neural networks and have demonstrated a remarkable ability to closely align with human perception when evaluating relative image similarity. However, it is now well-known that neural networks are susceptible to adversarial examples, i.e., small perturbations invisible to humans crafted to deliberately mislead the model. Consequently, the LPIPS metric is also sensitive to such adversarial examples. This susceptibility introduces significant security concerns, especially considering the widespread adoption of LPIPS in large-scale applications. In this paper, we propose the Robust Learned Perceptual Image Patch Similarity (R-LPIPS) metric, a new metric that leverages adversarially trained deep features. Through a comprehensive set of experiments, we demonstrate the superiority of R-LPIPS compared to the classical LPIPS metric. The code is available at \\url{https://github.com/SaraGhazanfari/R-LPIPS}.", "url": "https://arxiv.org/abs/2307.15157"}, {"metadata": {"arXiv": "2307.15273", "Date": "Fri, 28 Jul 2023 02:47:34 ", "Title": "Recovering high-quality FODs from a reduced number of diffusion-weighted images using a model-driven deep learning architecture", "Authors": ["J Bartlett", "C E Davey", "L A Johnston", "and J Duan"], "Categories": "cs.CV cs.LG eess.IV", "Comments": ["10 pages", "7 figures", "This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice", "after which this version may no longer be accessible"]}, "abstract": "Fibre orientation distribution (FOD) reconstruction using deep learning has the potential to produce accurate FODs from a reduced number of diffusion-weighted images (DWIs), decreasing total imaging time. Diffusion acquisition invariant representations of the DWI signals are typically used as input to these methods to ensure that they can be applied flexibly to data with different b-vectors and b-values; however, this means the network cannot condition its output directly on the DWI signal. In this work, we propose a spherical deconvolution network, a model-driven deep learning FOD reconstruction architecture, that ensures intermediate and output FODs produced by the network are consistent with the input DWI signals. Furthermore, we implement a fixel classification penalty within our loss function, encouraging the network to produce FODs that can subsequently be segmented into the correct number of fixels and improve downstream fixel-based analysis. Our results show that the model-based deep learning architecture achieves competitive performance compared to a state-of-the-art FOD super-resolution network, FOD-Net. Moreover, we show that the fixel classification penalty can be tuned to offer improved performance with respect to metrics that rely on accurately segmented of FODs. Our code is publicly available at https://github.com/Jbartlett6/SDNet .", "url": "https://arxiv.org/abs/2307.15273"}, {"metadata": {"arXiv": "2307.15326", "Date": "Fri, 28 Jul 2023 06:04:46 ", "Title": "Staging E-Commerce Products for Online Advertising using Retrieval Assisted Image Generation", "Authors": ["Yueh-Ning Ku", "Mikhail Kuznetsov", "Shaunak Mishra and Paloma de Juan"], "Categories": "cs.CV cs.IR cs.LG", "Comments": ["Accepted for publication in AdKDD 2023"]}, "abstract": "Online ads showing e-commerce products typically rely on the product images in a catalog sent to the advertising platform by an e-commerce platform. In the broader ads industry such ads are called dynamic product ads (DPA). It is common for DPA catalogs to be in the scale of millions (corresponding to the scale of products which can be bought from the e-commerce platform). However, not all product images in the catalog may be appealing when directly re-purposed as an ad image, and this may lead to lower click-through rates (CTRs). In particular, products just placed against a solid background may not be as enticing and realistic as a product staged in a natural environment. To address such shortcomings of DPA images at scale, we propose a generative adversarial network (GAN) based approach to generate staged backgrounds for un-staged product images. Generating the entire staged background is a challenging task susceptible to hallucinations. To get around this, we introduce a simpler approach called copy-paste staging using retrieval assisted GANs. In copy paste staging, we first retrieve (from the catalog) staged products similar to the un-staged input product, and then copy-paste the background of the retrieved product in the input image. A GAN based in-painting model is used to fill the holes left after this copy-paste operation. We show the efficacy of our copy-paste staging method via offline metrics, and human evaluation. In addition, we show how our staging approach can enable animations of moving products leading to a video ad from a product image.", "url": "https://arxiv.org/abs/2307.15326"}, {"metadata": {"arXiv": "2307.15428", "Date": "Fri, 28 Jul 2023 09:26:00 ", "Title": "Implicit neural representation for change detection", "Authors": ["Peter Naylor", "Diego Di Carlo", "Arianna Traviglia", "Makoto Yamada and Marco Fiorucci"], "Categories": "cs.CV cs.LG eess.IV", "Comments": ["Main article is 10 pages + 3 pages of supplementary. Conference style paper"]}, "abstract": "Detecting changes that occurred in a pair of 3D airborne LiDAR point clouds, acquired at two different times over the same geographical area, is a challenging task because of unmatching spatial supports and acquisition system noise. Most recent attempts to detect changes on point clouds are based on supervised methods, which require large labelled data unavailable in real-world applications. To address these issues, we propose an unsupervised approach that comprises two components: Neural Field (NF) for continuous shape reconstruction and a Gaussian Mixture Model for categorising changes. NF offer a grid-agnostic representation to encode bi-temporal point clouds with unmatched spatial support that can be regularised to increase high-frequency details and reduce noise. The reconstructions at each timestamp are compared at arbitrary spatial scales, leading to a significant increase in detection capabilities. We apply our method to a benchmark dataset of simulated LiDAR point clouds for urban sprawling. The dataset offers different challenging scenarios with different resolutions, input modalities and noise levels, allowing a multi-scenario comparison of our method with the current state-of-the-art. We boast the previous methods on this dataset by a 10% margin in intersection over union metric. In addition, we apply our methods to a real-world scenario to identify illegal excavation (looting) of archaeological sites and confirm that they match findings from field experts.", "url": "https://arxiv.org/abs/2307.15428"}, {"metadata": {"arXiv": "2307.15647", "Date": "Fri, 28 Jul 2023 16:08:10 ", "Title": "Multi-layer Aggregation as a key to feature-based OOD detection", "Authors": ["Benjamin Lambert", "Florence Forbes", "Senan Doyle and Michel Dojat"], "Categories": "cs.CV cs.LG eess.IV", "Comments": ["Accepted for presentation at the Workshop on Uncertainty for Safe Utilization of Machine Learning in Medical Imaging (UNSURE) at MICCAI 2023"]}, "abstract": "Deep Learning models are easily disturbed by variations in the input images that were not observed during the training stage, resulting in unpredictable predictions. Detecting such Out-of-Distribution (OOD) images is particularly crucial in the context of medical image analysis, where the range of possible abnormalities is extremely wide. Recently, a new category of methods has emerged, based on the analysis of the intermediate features of a trained model. These methods can be divided into 2 groups: single-layer methods that consider the feature map obtained at a fixed, carefully chosen layer, and multi-layer methods that consider the ensemble of the feature maps generated by the model. While promising, a proper comparison of these algorithms is still lacking. In this work, we compared various feature-based OOD detection methods on a large spectra of OOD (20 types), representing approximately 7800 3D MRIs. Our experiments shed the light on two phenomenons. First, multi-layer methods consistently outperform single-layer approaches, which tend to have inconsistent behaviour depending on the type of anomaly. Second, the OOD detection performance highly depends on the architecture of the underlying neural network.", "url": "https://arxiv.org/abs/2307.15647"}, {"metadata": {"arXiv": "2307.15710", "Date": "Fri, 28 Jul 2023 17:59:03 ", "Title": "Semi-Supervised Object Detection in the Open World", "Authors": ["Garvita Allabadi", "Ana Lucic", "Peter Pao-Huang", "Yu-Xiong Wang and Vikram Adve"], "Categories": "cs.CV cs.LG"}, "abstract": "Existing approaches for semi-supervised object detection assume a fixed set of classes present in training and unlabeled datasets, i.e., in-distribution (ID) data. The performance of these techniques significantly degrades when these techniques are deployed in the open-world, due to the fact that the unlabeled and test data may contain objects that were not seen during training, i.e., out-of-distribution (OOD) data. The two key questions that we explore in this paper are: can we detect these OOD samples and if so, can we learn from them? With these considerations in mind, we propose the Open World Semi-supervised Detection framework (OWSSD) that effectively detects OOD data along with a semi-supervised learning pipeline that learns from both ID and OOD data. We introduce an ensemble based OOD detector consisting of lightweight auto-encoder networks trained only on ID data. Through extensive evalulation, we demonstrate that our method performs competitively against state-of-the-art OOD detection algorithms and also significantly boosts the semi-supervised learning performance in open-world scenarios.", "url": "https://arxiv.org/abs/2307.15710"}, {"metadata": {"arXiv": "2307.15084", "Date": "Wed, 26 Jul 2023 05:54:06 ", "Title": "Mathematical Modeling of BCG-based Bladder Cancer Treatment Using Socio-Demographics", "Authors": ["Elizaveta Savchenko", "Ariel Rosenfeld", "Svetlana Bunimovich-Mendrazitsky"], "Categories": "cs.LG cs.IR"}, "abstract": "Cancer is one of the most widespread diseases around the world with millions of new patients each year. Bladder cancer is one of the most prevalent types of cancer affecting all individuals alike with no obvious prototypical patient. The current standard treatment for BC follows a routine weekly Bacillus Calmette-Guerin (BCG) immunotherapy-based therapy protocol which is applied to all patients alike. The clinical outcomes associated with BCG treatment vary significantly among patients due to the biological and clinical complexity of the interaction between the immune system, treatments, and cancer cells. In this study, we take advantage of the patient's socio-demographics to offer a personalized mathematical model that describes the clinical dynamics associated with BCG-based treatment. To this end, we adopt a well-established BCG treatment model and integrate a machine learning component to temporally adjust and reconfigure key parameters within the model thus promoting its personalization. Using real clinical data, we show that our personalized model favorably compares with the original one in predicting the number of cancer cells at the end of the treatment, with 14.8% improvement, on average.", "url": "https://arxiv.org/abs/2307.15084"}, {"metadata": {"arXiv": "2307.15088", "Date": "Wed, 26 Jul 2023 20:14:23 ", "Title": "Equitable Time-Varying Pricing Tariff Design: A Joint Learning and Optimization Approach", "Authors": ["Liudong Chen and Bolun Xu"], "Categories": "cs.LG cs.SY eess.SY"}, "abstract": "Time-varying pricing tariffs incentivize consumers to shift their electricity demand and reduce costs, but may increase the energy burden for consumers with limited response capability. The utility must thus balance affordability and response incentives when designing these tariffs by considering consumers' response expectations. This paper proposes a joint learning-based identification and optimization method to design equitable time-varying tariffs. Our proposed method encodes historical prices and demand response data into a recurrent neural network (RNN) to capture high-dimensional and non-linear consumer price response behaviors. We then embed the RNN into the tariff design optimization, formulating a non-linear optimization problem with a quadratic objective. We propose a gradient-based solution method that achieves fast and scalable computation. Simulation using real-world consumer data shows that our equitable tariffs protect low-income consumers from price surges while effectively motivating consumers to reduce peak demand. The method also ensures revenue recovery for the utility company and achieves robust performance against demand response uncertainties and prediction errors.", "url": "https://arxiv.org/abs/2307.15088"}, {"metadata": {"arXiv": "2307.15154", "Date": "Thu, 27 Jul 2023 19:03:36 ", "Title": "A/B Testing and Best-arm Identification for Linear Bandits with Robustness to Non-stationarity", "Authors": ["Zhihan Xiong", "Romain Camilleri", "Maryam Fazel", "Lalit Jain", "Kevin Jamieson"], "Categories": "cs.LG stat.ML", "Comments": ["25 pages", "6 figures"]}, "abstract": "We investigate the fixed-budget best-arm identification (BAI) problem for linear bandits in a potentially non-stationary environment. Given a finite arm set $\\mathcal{X}\\subset\\mathbb{R}^d$, a fixed budget $T$, and an unpredictable sequence of parameters $\\left\\lbrace\\theta_t\\right\\rbrace_{t=1}^{T}$, an algorithm will aim to correctly identify the best arm $x^* := \\arg\\max_{x\\in\\mathcal{X}}x^\\top\\sum_{t=1}^{T}\\theta_t$ with probability as high as possible. Prior work has addressed the stationary setting where $\\theta_t = \\theta_1$ for all $t$ and demonstrated that the error probability decreases as $\\exp(-T /\\rho^*)$ for a problem-dependent constant $\\rho^*$. But in many real-world $A/B/n$ multivariate testing scenarios that motivate our work, the environment is non-stationary and an algorithm expecting a stationary setting can easily fail. For robust identification, it is well-known that if arms are chosen randomly and non-adaptively from a G-optimal design over $\\mathcal{X}$ at each time then the error probability decreases as $\\exp(-T\\Delta^2_{(1)}/d)$, where $\\Delta_{(1)} = \\min_{x \\neq x^*} (x^* - x)^\\top \\frac{1}{T}\\sum_{t=1}^T \\theta_t$. As there exist environments where $\\Delta_{(1)}^2/ d \\ll 1/ \\rho^*$, we are motivated to propose a novel algorithm $\\mathsf{P1}$-$\\mathsf{RAGE}$ that aims to obtain the best of both worlds: robustness to non-stationarity and fast rates of identification in benign settings. We characterize the error probability of $\\mathsf{P1}$-$\\mathsf{RAGE}$ and demonstrate empirically that the algorithm indeed never performs worse than G-optimal design but compares favorably to the best algorithms in the stationary setting.", "url": "https://arxiv.org/abs/2307.15154"}, {"metadata": {"arXiv": "2307.15168", "Date": "Thu, 27 Jul 2023 19:56:18 ", "Title": "PredictChain: Empowering Collaboration and Data Accessibility for AI in a Decentralized Blockchain-based Marketplace", "Authors": ["Matthew T. Pisano and Connor J. Patterson and Oshani Seneviratne"], "Categories": "cs.LG cs.DC", "Report-no": "ChainScience/2023/24"}, "abstract": "Limited access to computing resources and training data poses significant challenges for individuals and groups aiming to train and utilize predictive machine learning models. Although numerous publicly available machine learning models exist, they are often unhosted, necessitating end-users to establish their computational infrastructure. Alternatively, these models may only be accessible through paid cloud-based mechanisms, which can prove costly for general public utilization. Moreover, model and data providers require a more streamlined approach to track resource usage and capitalize on subsequent usage by others, both financially and otherwise. An effective mechanism is also lacking to contribute high-quality data for improving model performance. We propose a blockchain-based marketplace called \"PredictChain\" for predictive machine-learning models to address these issues. This marketplace enables users to upload datasets for training predictive machine learning models, request model training on previously uploaded datasets, or submit queries to trained models. Nodes within the blockchain network, equipped with available computing resources, will operate these models, offering a range of archetype machine learning models with varying characteristics, such as cost, speed, simplicity, power, and cost-effectiveness. This decentralized approach empowers users to develop improved models accessible to the public, promotes data sharing, and reduces reliance on centralized cloud providers.", "url": "https://arxiv.org/abs/2307.15168"}, {"metadata": {"arXiv": "2307.15196", "Date": "Thu, 27 Jul 2023 21:01:26 ", "Title": "The Marginal Value of Momentum for Small Learning Rate SGD", "Authors": ["Runzhe Wang", "Sadhika Malladi", "Tianhao Wang", "Kaifeng Lyu", "Zhiyuan Li"], "Categories": "cs.LG math.OC"}, "abstract": "Momentum is known to accelerate the convergence of gradient descent in strongly convex settings without stochastic gradient noise. In stochastic optimization, such as training neural networks, folklore suggests that momentum may help deep learning optimization by reducing the variance of the stochastic gradient update, but previous theoretical analyses do not find momentum to offer any provable acceleration. Theoretical results in this paper clarify the role of momentum in stochastic settings where the learning rate is small and gradient noise is the dominant source of instability, suggesting that SGD with and without momentum behave similarly in the short and long time horizons. Experiments show that momentum indeed has limited benefits for both optimization and generalization in practical training regimes where the optimal learning rate is not very large, including small- to medium-batch training from scratch on ImageNet and fine-tuning language models on downstream tasks.", "url": "https://arxiv.org/abs/2307.15196"}, {"metadata": {"arXiv": "2307.15247", "Date": "Fri, 28 Jul 2023 00:59:14 ", "Title": "Is this model reliable for everyone? Testing for strong calibration", "Authors": ["Jean Feng", "Alexej Gossmann", "Romain Pirracchio", "Nicholas Petrick", "Gene Pennello", "Berkman Sahiner"], "Categories": "cs.LG stat.ME stat.ML"}, "abstract": "In a well-calibrated risk prediction model, the average predicted probability is close to the true event rate for any given subgroup. Such models are reliable across heterogeneous populations and satisfy strong notions of algorithmic fairness. However, the task of auditing a model for strong calibration is well-known to be difficult -- particularly for machine learning (ML) algorithms -- due to the sheer number of potential subgroups. As such, common practice is to only assess calibration with respect to a few predefined subgroups. Recent developments in goodness-of-fit testing offer potential solutions but are not designed for settings with weak signal or where the poorly calibrated subgroup is small, as they either overly subdivide the data or fail to divide the data at all. We introduce a new testing procedure based on the following insight: if we can reorder observations by their expected residuals, there should be a change in the association between the predicted and observed residuals along this sequence if a poorly calibrated subgroup exists. This lets us reframe the problem of calibration testing into one of changepoint detection, for which powerful methods already exist. We begin with introducing a sample-splitting procedure where a portion of the data is used to train a suite of candidate models for predicting the residual, and the remaining data are used to perform a score-based cumulative sum (CUSUM) test. To further improve power, we then extend this adaptive CUSUM test to incorporate cross-validation, while maintaining Type I error control under minimal assumptions. Compared to existing methods, the proposed procedure consistently achieved higher power in simulation studies and more than doubled the power when auditing a mortality risk prediction model.", "url": "https://arxiv.org/abs/2307.15247"}, {"metadata": {"arXiv": "2307.15367", "Date": "Fri, 28 Jul 2023 07:34:44 ", "Title": "Toward Transparent Sequence Models with Model-Based Tree Markov Model", "Authors": ["Chan Hsu", "Wei-Chun Huang", "Jun-Ting Wu", "Chih-Yuan Li", "Yihuang Kang"], "Categories": "cs.LG cs.IR"}, "abstract": "In this study, we address the interpretability issue in complex, black-box Machine Learning models applied to sequence data. We introduce the Model-Based tree Hidden Semi-Markov Model (MOB-HSMM), an inherently interpretable model aimed at detecting high mortality risk events and discovering hidden patterns associated with the mortality risk in Intensive Care Units (ICU). This model leverages knowledge distilled from Deep Neural Networks (DNN) to enhance predictive performance while offering clear explanations. Our experimental results indicate the improved performance of Model-Based trees (MOB trees) via employing LSTM for learning sequential patterns, which are then transferred to MOB trees. Integrating MOB trees with the Hidden Semi-Markov Model (HSMM) in the MOB-HSMM enables uncovering potential and explainable sequences using available information.", "url": "https://arxiv.org/abs/2307.15367"}, {"metadata": {"arXiv": "2307.15388", "Date": "Fri, 28 Jul 2023 08:32:11 ", "Title": "Does Full Waveform Inversion Benefit from Big Data?", "Authors": ["Peng Jin", "Yinan Feng", "Shihang Feng", "Hanchen Wang", "Yinpeng Chen", "Benjamin Consolvo", "Zicheng Liu", "Youzuo Lin"], "Categories": "cs.LG eess.SP physics.geo-ph"}, "abstract": "This paper investigates the impact of big data on deep learning models for full waveform inversion (FWI). While it is well known that big data can boost the performance of deep learning models in many tasks, its effectiveness has not been validated for FWI. To address this gap, we present an empirical study that investigates how deep learning models in FWI behave when trained on OpenFWI, a collection of large-scale, multi-structural datasets published recently. Particularly, we train and evaluate the FWI models on a combination of 10 2D subsets in OpenFWI that contain 470K data pairs in total. Our experiments demonstrate that larger datasets lead to better performance and generalization of deep learning models for FWI. We further demonstrate that model capacity needs to scale in accordance with data size for optimal improvement.", "url": "https://arxiv.org/abs/2307.15388"}, {"metadata": {"arXiv": "2307.15396", "Date": "Fri, 28 Jul 2023 08:41:12 ", "Title": "Noisy Interpolation Learning with Shallow Univariate ReLU Networks", "Authors": ["Nirmit Joshi", "Gal Vardi", "Nathan Srebro"], "Categories": "cs.LG", "Comments": ["41 pages"]}, "abstract": "We study the asymptotic overfitting behavior of interpolation with minimum norm ($\\ell_2$ of the weights) two-layer ReLU networks for noisy univariate regression. We show that overfitting is tempered for the $L_1$ loss, and any $L_p$ loss for $p<2$, but catastrophic for $p\\geq 2$.", "url": "https://arxiv.org/abs/2307.15396"}, {"metadata": {"arXiv": "2307.15398", "Date": "Fri, 28 Jul 2023 08:48:32 ", "Title": "The Initial Screening Order Problem", "Authors": ["Jose M. Alvarez and Salvatore Ruggieri"], "Categories": "cs.LG cs.CY"}, "abstract": "In this paper we present the initial screening order problem, a crucial step within candidate screening. It involves a human-like screener with an objective to find the first k suitable candidates rather than the best k suitable candidates in a candidate pool given an initial screening order. The initial screening order represents the way in which the human-like screener arranges the candidate pool prior to screening. The choice of initial screening order has considerable effects on the selected set of k candidates. We prove that under an unbalanced candidate pool (e.g., having more male than female candidates), the human-like screener can suffer from uneven efforts that hinder its decision-making over the protected, under-represented group relative to the non-protected, over-represented group. Other fairness results are proven under the human-like screener. This research is based on a collaboration with a large company to better understand its hiring process for potential automation. Our main contribution is the formalization of the initial screening order problem which, we argue, opens the path for future extensions of the current works on ranking algorithms, fairness, and automation for screening procedures.", "url": "https://arxiv.org/abs/2307.15398"}, {"metadata": {"arXiv": "2307.15422", "Date": "Fri, 28 Jul 2023 09:14:41 ", "Title": "Is One Epoch All You Need For Multi-Fidelity Hyperparameter Optimization?", "Authors": ["Romain Egele", "Isabelle Guyon", "Yixuan Sun", "Prasanna Balaprakash"], "Categories": "cs.LG", "Comments": ["5 pages", "with extended appendices"]}, "abstract": "Hyperparameter optimization (HPO) is crucial for fine-tuning machine learning models but can be computationally expensive. To reduce costs, Multi-fidelity HPO (MF-HPO) leverages intermediate accuracy levels in the learning process and discards low-performing models early on. We compared various representative MF-HPO methods against a simple baseline on classical benchmark data. The baseline involved discarding all models except the Top-K after training for only one epoch, followed by further training to select the best model. Surprisingly, this baseline achieved similar results to its counterparts, while requiring an order of magnitude less computation. Upon analyzing the learning curves of the benchmark data, we observed a few dominant learning curves, which explained the success of our baseline. This suggests that researchers should (1) always use the suggested baseline in benchmarks and (2) broaden the diversity of MF-HPO benchmarks to include more complex cases.", "url": "https://arxiv.org/abs/2307.15422"}, {"metadata": {"arXiv": "2307.15424", "Date": "Fri, 28 Jul 2023 09:17:03 ", "Title": "Deep Generative Models, Synthetic Tabular Data, and Differential Privacy: An Overview and Synthesis", "Authors": ["Conor Hassan", "Robert Salomone", "Kerrie Mengersen"], "Categories": "cs.LG stat.AP stat.CO stat.ML"}, "abstract": "This article provides a comprehensive synthesis of the recent developments in synthetic data generation via deep generative models, focusing on tabular datasets. We specifically outline the importance of synthetic data generation in the context of privacy-sensitive data. Additionally, we highlight the advantages of using deep generative models over other methods and provide a detailed explanation of the underlying concepts, including unsupervised learning, neural networks, and generative models. The paper covers the challenges and considerations involved in using deep generative models for tabular datasets, such as data normalization, privacy concerns, and model evaluation. This review provides a valuable resource for researchers and practitioners interested in synthetic data generation and its applications.", "url": "https://arxiv.org/abs/2307.15424"}, {"metadata": {"arXiv": "2307.15438", "Date": "Fri, 28 Jul 2023 09:40:19 ", "Title": "Autonomous Payload Thermal Control", "Authors": ["Alejandro D. Mousist"], "Categories": "cs.LG cs.SY eess.SY"}, "abstract": "In small satellites there is less room for heat control equipment, scientific instruments, and electronic components. Furthermore, the near proximity of the electronics makes power dissipation difficult, with the risk of not being able to control the temperature appropriately, reducing component lifetime and mission performance. To address this challenge, taking advantage of the advent of increasing intelligence on board satellites, a deep reinforcement learning based framework that uses Soft Actor-Critic algorithm is proposed for learning the thermal control policy onboard. The framework is evaluated both in a naive simulated environment and in a real space edge processing computer that will be shipped in the future IMAGIN-e mission and hosted in the ISS. The experiment results show that the proposed framework is able to learn to control the payload processing power to maintain the temperature under operational ranges, complementing traditional thermal control systems.", "url": "https://arxiv.org/abs/2307.15438"}, {"metadata": {"arXiv": "2307.15466", "Date": "Fri, 28 Jul 2023 10:37:49 ", "Title": "LUCID-GAN: Conditional Generative Models to Locate Unfairness", "Authors": ["Andres Algaba", "Carmen Mazijn", "Carina Prunkl", "Jan Danckaert", "Vincent Ginis"], "Categories": "cs.LG cs.CY", "Comments": ["24 pages", "6 figures", "1st World Conference on eXplainable Artificial Intelligence"]}, "abstract": "Most group fairness notions detect unethical biases by computing statistical parity metrics on a model's output. However, this approach suffers from several shortcomings, such as philosophical disagreement, mutual incompatibility, and lack of interpretability. These shortcomings have spurred the research on complementary bias detection methods that offer additional transparency into the sources of discrimination and are agnostic towards an a priori decision on the definition of fairness and choice of protected features. A recent proposal in this direction is LUCID (Locating Unfairness through Canonical Inverse Design), where canonical sets are generated by performing gradient descent on the input space, revealing a model's desired input given a preferred output. This information about the model's mechanisms, i.e., which feature values are essential to obtain specific outputs, allows exposing potential unethical biases in its internal logic. Here, we present LUCID-GAN, which generates canonical inputs via a conditional generative model instead of gradient-based inverse design. LUCID-GAN has several benefits, including that it applies to non-differentiable models, ensures that canonical sets consist of realistic inputs, and allows to assess proxy and intersectional discrimination. We empirically evaluate LUCID-GAN on the UCI Adult and COMPAS data sets and show that it allows for detecting unethical biases in black-box models without requiring access to the training data.", "url": "https://arxiv.org/abs/2307.15466"}, {"metadata": {"arXiv": "2307.15496", "Date": "Fri, 28 Jul 2023 11:44:06 ", "Title": "From continuous-time formulations to discretization schemes: tensor trains and robust regression for BSDEs and parabolic PDEs", "Authors": ["Lorenz Richter", "Leon Sallandt", "Nikolas N\\\"usken"], "Categories": "cs.LG cs.NA math.NA math.PR stat.ML"}, "abstract": "The numerical approximation of partial differential equations (PDEs) poses formidable challenges in high dimensions since classical grid-based methods suffer from the so-called curse of dimensionality. Recent attempts rely on a combination of Monte Carlo methods and variational formulations, using neural networks for function approximation. Extending previous work (Richter et al., 2021), we argue that tensor trains provide an appealing framework for parabolic PDEs: The combination of reformulations in terms of backward stochastic differential equations and regression-type methods holds the promise of leveraging latent low-rank structures, enabling both compression and efficient computation. Emphasizing a continuous-time viewpoint, we develop iterative schemes, which differ in terms of computational efficiency and robustness. We demonstrate both theoretically and numerically that our methods can achieve a favorable trade-off between accuracy and computational efficiency. While previous methods have been either accurate or fast, we have identified a novel numerical strategy that can often combine both of these aspects.", "url": "https://arxiv.org/abs/2307.15496"}, {"metadata": {"arXiv": "2307.15503", "Date": "Fri, 28 Jul 2023 11:58:26 ", "Title": "The Applicability of Federated Learning to Official Statistics", "Authors": ["Joshua Stock", "Oliver Hauke", "Julius Wei{\\ss}mann", "Hannes Federrath"], "Categories": "cs.LG"}, "abstract": "This work investigates the potential of Federated Learning (FL) for official statistics and shows how well the performance of FL models can keep up with centralized learning methods. At the same time, its utilization can safeguard the privacy of data holders, thus facilitating access to a broader range of data and ultimately enhancing official statistics. By simulating three different use cases, important insights on the applicability of the technology are gained. The use cases are based on a medical insurance data set, a fine dust pollution data set and a mobile radio coverage data set - all of which are from domains close to official statistics. We provide a detailed analysis of the results, including a comparison of centralized and FL algorithm performances for each simulation. In all three use cases, we were able to train models via FL which reach a performance very close to the centralized model benchmarks. Our key observations and their implications for transferring the simulations into practice are summarized. We arrive at the conclusion that FL has the potential to emerge as a pivotal technology in future use cases of official statistics.", "url": "https://arxiv.org/abs/2307.15503"}, {"metadata": {"arXiv": "2307.15539", "Date": "Fri, 28 Jul 2023 13:07:42 ", "Title": "Backdoor Defense with Non-Adversarial Backdoor", "Authors": ["Min Liu", "Alberto Sangiovanni-Vincentelli", "Xiangyu Yue"], "Categories": "cs.LG cs.CR cs.CV"}, "abstract": "Deep neural networks (DNNs) are vulnerable to backdoor attack, which does not affect the network's performance on clean data but would manipulate the network behavior once a trigger pattern is added. Existing defense methods have greatly reduced attack success rate, but their prediction accuracy on clean data still lags behind a clean model by a large margin. Inspired by the stealthiness and effectiveness of backdoor attack, we propose a simple but highly effective defense framework which injects non-adversarial backdoors targeting poisoned samples. Following the general steps in backdoor attack, we detect a small set of suspected samples and then apply a poisoning strategy to them. The non-adversarial backdoor, once triggered, suppresses the attacker's backdoor on poisoned data, but has limited influence on clean data. The defense can be carried out during data preprocessing, without any modification to the standard end-to-end training pipeline. We conduct extensive experiments on multiple benchmarks with different architectures and representative attacks. Results demonstrate that our method achieves state-of-the-art defense effectiveness with by far the lowest performance drop on clean data. Considering the surprising defense ability displayed by our framework, we call for more attention to utilizing backdoor for backdoor defense. Code is available at https://github.com/damianliumin/non-adversarial_backdoor.", "url": "https://arxiv.org/abs/2307.15539"}, {"metadata": {"arXiv": "2307.15593", "Date": "Fri, 28 Jul 2023 14:52:08 ", "Title": "Robust Distortion-free Watermarks for Language Models", "Authors": ["Rohith Kuditipudi and John Thickstun and Tatsunori Hashimoto and Percy Liang"], "Categories": "cs.LG cs.CL cs.CR"}, "abstract": "We propose a methodology for planting watermarks in text from an autoregressive language model that are robust to perturbations without changing the distribution over text up to a certain maximum generation budget. We generate watermarked text by mapping a sequence of random numbers -- which we compute using a randomized watermark key -- to a sample from the language model. To detect watermarked text, any party who knows the key can align the text to the random number sequence. We instantiate our watermark methodology with two sampling schemes: inverse transform sampling and exponential minimum sampling. We apply these watermarks to three language models -- OPT-1.3B, LLaMA-7B and Alpaca-7B -- to experimentally validate their statistical power and robustness to various paraphrasing attacks. Notably, for both the OPT-1.3B and LLaMA-7B models, we find we can reliably detect watermarked text ($p \\leq 0.01$) from $35$ tokens even after corrupting between $40$-$50$\\% of the tokens via random edits (i.e., substitutions, insertions or deletions). For the Alpaca-7B model, we conduct a case study on the feasibility of watermarking responses to typical user instructions. Due to the lower entropy of the responses, detection is more difficult: around $25\\%$ of the responses -- whose median length is around $100$ tokens -- are detectable with $p \\leq 0.01$, and the watermark is also less robust to certain automated paraphrasing attacks we implement.", "url": "https://arxiv.org/abs/2307.15593"}, {"metadata": {"arXiv": "2307.15621", "Date": "Fri, 28 Jul 2023 15:29:52 ", "Title": "Shrink-Perturb Improves Architecture Mixing during Population Based Training for Neural Architecture Search", "Authors": ["Alexander Chebykin", "Arkadiy Dushatskiy", "Tanja Alderliesten", "Peter A. N. Bosman"], "Categories": "cs.LG", "Comments": ["10 pages", "7 figures. Accepted at ECAI 2023"]}, "abstract": "In this work, we show that simultaneously training and mixing neural networks is a promising way to conduct Neural Architecture Search (NAS). For hyperparameter optimization, reusing the partially trained weights allows for efficient search, as was previously demonstrated by the Population Based Training (PBT) algorithm. We propose PBT-NAS, an adaptation of PBT to NAS where architectures are improved during training by replacing poorly-performing networks in a population with the result of mixing well-performing ones and inheriting the weights using the shrink-perturb technique. After PBT-NAS terminates, the created networks can be directly used without retraining. PBT-NAS is highly parallelizable and effective: on challenging tasks (image generation and reinforcement learning) PBT-NAS achieves superior performance compared to baselines (random search and mutation-based PBT).", "url": "https://arxiv.org/abs/2307.15621"}, {"metadata": {"arXiv": "2307.15663", "Date": "Fri, 28 Jul 2023 16:48:42 ", "Title": "CoRe Optimizer: An All-in-One Solution for Machine Learning", "Authors": ["Marco Eckhoff and Markus Reiher"], "Categories": "cs.LG cond-mat.mtrl-sci physics.chem-ph physics.comp-ph", "Comments": ["10 pages", "5 figures"]}, "abstract": "The optimization algorithm and its hyperparameters can significantly affect the training speed and resulting model accuracy in machine learning applications. The wish list for an ideal optimizer includes fast and smooth convergence to low error, low computational demand, and general applicability. Our recently introduced continual resilient (CoRe) optimizer has shown superior performance compared to other state-of-the-art first-order gradient-based optimizers for training lifelong machine learning potentials. In this work we provide an extensive performance comparison of the CoRe optimizer and nine other optimization algorithms including the Adam optimizer and resilient backpropagation (RPROP) for diverse machine learning tasks. We analyze the influence of different hyperparameters and provide generally applicable values. The CoRe optimizer yields best or competitive performance in every investigated application, while only one hyperparameter needs to be changed depending on mini-batch or batch learning.", "url": "https://arxiv.org/abs/2307.15663"}, {"metadata": {"arXiv": "2307.15672", "Date": "Fri, 28 Jul 2023 17:04:06 ", "Title": "Bayesian Time-Series Classifier for Decoding Simple Visual Stimuli from Intracranial Neural Activity", "Authors": ["Navid Ziaei", "Reza Saadatifard", "Ali Yousefi", "Behzad Nazari", "Sydney S. Cash", "Angelique C. Paulk"], "Categories": "cs.LG eess.SP q-bio.NC"}, "abstract": "Understanding how external stimuli are encoded in distributed neural activity is of significant interest in clinical and basic neuroscience. To address this need, it is essential to develop analytical tools capable of handling limited data and the intrinsic stochasticity present in neural data. In this study, we propose a straightforward Bayesian time series classifier (BTsC) model that tackles these challenges whilst maintaining a high level of interpretability. We demonstrate the classification capabilities of this approach by utilizing neural data to decode colors in a visual task. The model exhibits consistent and reliable average performance of 75.55% on 4 patients' dataset, improving upon state-of-the-art machine learning techniques by about 3.0 percent. In addition to its high classification accuracy, the proposed BTsC model provides interpretable results, making the technique a valuable tool to study neural activity in various tasks and categories. The proposed solution can be applied to neural data recorded in various tasks, where there is a need for interpretable results and accurate classification accuracy.", "url": "https://arxiv.org/abs/2307.15672"}, {"metadata": {"arXiv": "2307.15677", "Date": "Fri, 28 Jul 2023 17:12:46 ", "Title": "Adversarial training for tabular data with attack propagation", "Authors": ["Tiago Leon Melo", "Jo\\~ao Bravo", "Marco O. P. Sampaio", "Paolo Romano", "Hugo Ferreira", "Jo\\~ao Tiago Ascens\\~ao", "Pedro Bizarro"], "Categories": "cs.LG cs.CR"}, "abstract": "Adversarial attacks are a major concern in security-centered applications, where malicious actors continuously try to mislead Machine Learning (ML) models into wrongly classifying fraudulent activity as legitimate, whereas system maintainers try to stop them. Adversarially training ML models that are robust against such attacks can prevent business losses and reduce the work load of system maintainers. In such applications data is often tabular and the space available for attackers to manipulate undergoes complex feature engineering transformations, to provide useful signals for model training, to a space attackers cannot access. Thus, we propose a new form of adversarial training where attacks are propagated between the two spaces in the training loop. We then test this method empirically on a real world dataset in the domain of credit card fraud detection. We show that our method can prevent about 30% performance drops under moderate attacks and is essential under very aggressive attacks, with a trade-off loss in performance under no attacks smaller than 7%.", "url": "https://arxiv.org/abs/2307.15677"}, {"metadata": {"arXiv": "2307.15679", "Date": "Fri, 28 Jul 2023 17:14:58 ", "Title": "Dynamic Analysis and an Eigen Initializer for Recurrent Neural Networks", "Authors": ["Ran Dou and Jose Principe"], "Categories": "cs.LG"}, "abstract": "In recurrent neural networks, learning long-term dependency is the main difficulty due to the vanishing and exploding gradient problem. Many researchers are dedicated to solving this issue and they proposed many algorithms. Although these algorithms have achieved great success, understanding how the information decays remains an open problem. In this paper, we study the dynamics of the hidden state in recurrent neural networks. We propose a new perspective to analyze the hidden state space based on an eigen decomposition of the weight matrix. We start the analysis by linear state space model and explain the function of preserving information in activation functions. We provide an explanation for long-term dependency based on the eigen analysis. We also point out the different behavior of eigenvalues for regression tasks and classification tasks. From the observations on well-trained recurrent neural networks, we proposed a new initialization method for recurrent neural networks, which improves consistently performance. It can be applied to vanilla-RNN, LSTM, and GRU. We test on many datasets, such as Tomita Grammars, pixel-by-pixel MNIST datasets, and machine translation datasets (Multi30k). It outperforms the Xavier initializer and kaiming initializer as well as other RNN-only initializers like IRNN and sp-RNN in several tasks.", "url": "https://arxiv.org/abs/2307.15679"}, {"metadata": {"arXiv": "2307.15690", "Date": "Fri, 28 Jul 2023 17:29:49 ", "Title": "Benchmarking Offline Reinforcement Learning on Real-Robot Hardware", "Authors": ["Nico G\\\"urtler", "Sebastian Blaes", "Pavel Kolev", "Felix Widmaier", "Manuel W\\\"uthrich", "Stefan Bauer", "Bernhard Sch\\\"olkopf and Georg Martius"], "Categories": "cs.LG cs.RO", "Comments": ["The Eleventh International Conference on Learning Representations. 2022. Published at ICLR 2023. Datasets available at https://github.com/rr-learning/trifinger_rl_datasets"]}, "abstract": "Learning policies from previously recorded data is a promising direction for real-world robotics tasks, as online learning is often infeasible. Dexterous manipulation in particular remains an open problem in its general form. The combination of offline reinforcement learning with large diverse datasets, however, has the potential to lead to a breakthrough in this challenging domain analogously to the rapid progress made in supervised learning in recent years. To coordinate the efforts of the research community toward tackling this problem, we propose a benchmark including: i) a large collection of data for offline learning from a dexterous manipulation platform on two tasks, obtained with capable RL agents trained in simulation; ii) the option to execute learned policies on a real-world robotic system and a simulation for efficient debugging. We evaluate prominent open-sourced offline reinforcement learning algorithms on the datasets and provide a reproducible experimental setup for offline reinforcement learning on real systems.", "url": "https://arxiv.org/abs/2307.15690"}, {"metadata": {"arXiv": "2307.15694", "Date": "Fri, 28 Jul 2023 17:40:58 ", "Title": "Universal Recurrent Event Memories for Streaming Data", "Authors": ["Ran Dou and Jose Principe"], "Categories": "cs.LG"}, "abstract": "In this paper, we propose a new event memory architecture (MemNet) for recurrent neural networks, which is universal for different types of time series data such as scalar, multivariate or symbolic. Unlike other external neural memory architectures, it stores key-value pairs, which separate the information for addressing and for content to improve the representation, as in the digital archetype. Moreover, the key-value pairs also avoid the compromise between memory depth and resolution that applies to memories constructed by the model state. One of the MemNet key characteristics is that it requires only linear adaptive mapping functions while implementing a nonlinear operation on the input data. MemNet architecture can be applied without modifications to scalar time series, logic operators on strings, and also to natural language processing, providing state-of-the-art results in all application domains such as the chaotic time series, the symbolic operation tasks, and the question-answering tasks (bAbI). Finally, controlled by five linear layers, MemNet requires a much smaller number of training parameters than other external memory networks as well as the transformer network. The space complexity of MemNet equals a single self-attention layer. It greatly improves the efficiency of the attention mechanism and opens the door for IoT applications.", "url": "https://arxiv.org/abs/2307.15694"}, {"metadata": {"arXiv": "2307.15175", "Date": "Thu, 27 Jul 2023 20:07:55 ", "Title": "Causative Cyberattacks on Online Learning-based Automated Demand Response Systems", "Authors": ["Samrat Acharya", "Yury Dvorkin", "Ramesh Karri"], "Categories": "eess.SY cs.CR cs.LG cs.SY", "DOI": "10.1109/TSG.2021.3067896"}, "abstract": "Power utilities are adopting Automated Demand Response (ADR) to replace the costly fuel-fired generators and to preempt congestion during peak electricity demand. Similarly, third-party Demand Response (DR) aggregators are leveraging controllable small-scale electrical loads to provide on-demand grid support services to the utilities. Some aggregators and utilities have started employing Artificial Intelligence (AI) to learn the energy usage patterns of electricity consumers and use this knowledge to design optimal DR incentives. Such AI frameworks use open communication channels between the utility/aggregator and the DR customers, which are vulnerable to \\textit{causative} data integrity cyberattacks. This paper explores vulnerabilities of AI-based DR learning and designs a data-driven attack strategy informed by DR data collected from the New York University (NYU) campus buildings. The case study demonstrates the feasibility and effects of maliciously tampering with (i) real-time DR incentives, (ii) DR event data sent to DR customers, and (iii) responses of DR customers to the DR incentives.", "url": "https://arxiv.org/abs/2307.15175"}, {"metadata": {"arXiv": "2307.15451", "Date": "Fri, 28 Jul 2023 10:09:45 ", "Title": "DELPHIC: Practical DEL Planning via Possibilities (Extended Version)", "Authors": ["Alessandro Burigana", "Paolo Felli and Marco Montali"], "Categories": "cs.AI"}, "abstract": "Dynamic Epistemic Logic (DEL) provides a framework for epistemic planning that is capable of representing non-deterministic actions, partial observability, higher-order knowledge and both factual and epistemic change. The high expressivity of DEL challenges existing epistemic planners, which typically can handle only restricted fragments of the whole framework. The goal of this work is to push the envelop of practical DEL planning, ultimately aiming for epistemic planners to be able to deal with the full range of features offered by DEL. Towards this goal, we question the traditional semantics of DEL, defined in terms on Kripke models. In particular, we propose an equivalent semantics defined using, as main building block, so-called possibilities: non well-founded objects representing both factual properties of the world, and what agents consider to be possible. We call the resulting framework DELPHIC. We argue that DELPHIC indeed provides a more compact representation of epistemic states. To substantiate this claim, we implement both approaches in ASP and we set up an experimental evaluation to compare DELPHIC with the traditional, Kripke-based approach. The evaluation confirms that DELPHIC outperforms the traditional approach in space and time.", "url": "https://arxiv.org/abs/2307.15451"}, {"metadata": {"arXiv": "2307.15453", "Date": "Fri, 28 Jul 2023 10:11:01 ", "Title": "From Probabilistic Programming to Complexity-based Programming", "Authors": ["Giovanni Sileno", "Jean-Louis Dessalles"], "Categories": "cs.AI cs.CL"}, "abstract": "The paper presents the main characteristics and a preliminary implementation of a novel computational framework named CompLog. Inspired by probabilistic programming systems like ProbLog, CompLog builds upon the inferential mechanisms proposed by Simplicity Theory, relying on the computation of two Kolmogorov complexities (here implemented as min-path searches via ASP programs) rather than probabilistic inference. The proposed system enables users to compute ex-post and ex-ante measures of unexpectedness of a certain situation, mapping respectively to posterior and prior subjective probabilities. The computation is based on the specification of world and mental models by means of causal and descriptive relations between predicates weighted by complexity. The paper illustrates a few examples of application: generating relevant descriptions, and providing alternative approaches to disjunction and to negation.", "url": "https://arxiv.org/abs/2307.15453"}, {"metadata": {"arXiv": "2307.15485", "Date": "Fri, 28 Jul 2023 11:26:26 ", "Title": "A Semantic Approach to Decidability in Epistemic Planning (Extended Version)", "Authors": ["Alessandro Burigana", "Paolo Felli", "Marco Montali and Nicolas Troquard"], "Categories": "cs.AI"}, "abstract": "The use of Dynamic Epistemic Logic (DEL) in multi-agent planning has led to a widely adopted action formalism that can handle nondeterminism, partial observability and arbitrary knowledge nesting. As such expressive power comes at the cost of undecidability, several decidable fragments have been isolated, mainly based on syntactic restrictions of the action formalism. In this paper, we pursue a novel semantic approach to achieve decidability. Namely, rather than imposing syntactical constraints, the semantic approach focuses on the axioms of the logic for epistemic planning. Specifically, we augment the logic of knowledge S5$_n$ and with an interaction axiom called (knowledge) commutativity, which controls the ability of agents to unboundedly reason on the knowledge of other agents. We then provide a threefold contribution. First, we show that the resulting epistemic planning problem is decidable. In doing so, we prove that our framework admits a finitary non-fixpoint characterization of common knowledge, which is of independent interest. Second, we study different generalizations of the commutativity axiom, with the goal of obtaining decidability for more expressive fragments of DEL. Finally, we show that two well-known epistemic planning systems based on action templates, when interpreted under the setting of knowledge, conform to the commutativity axiom, hence proving their decidability.", "url": "https://arxiv.org/abs/2307.15485"}, {"metadata": {"arXiv": "2307.15189", "Date": "Thu, 27 Jul 2023 20:36:02 ", "Title": "Med-Flamingo: a Multimodal Medical Few-shot Learner", "Authors": ["Michael Moor", "Qian Huang", "Shirley Wu", "Michihiro Yasunaga", "Cyril Zakka", "Yash Dalmia", "Eduardo Pontes Reis", "Pranav Rajpurkar", "Jure Leskovec"], "Categories": "cs.CV cs.AI", "Comments": ["Preprint"]}, "abstract": "Medicine, by its nature, is a multifaceted domain that requires the synthesis of information across various modalities. Medical generative vision-language models (VLMs) make a first step in this direction and promise many exciting clinical applications. However, existing models typically have to be fine-tuned on sizeable down-stream datasets, which poses a significant limitation as in many medical applications data is scarce, necessitating models that are capable of learning from few examples in real-time. Here we propose Med-Flamingo, a multimodal few-shot learner adapted to the medical domain. Based on OpenFlamingo-9B, we continue pre-training on paired and interleaved medical image-text data from publications and textbooks. Med-Flamingo unlocks few-shot generative medical visual question answering (VQA) abilities, which we evaluate on several datasets including a novel challenging open-ended VQA dataset of visual USMLE-style problems. Furthermore, we conduct the first human evaluation for generative medical VQA where physicians review the problems and blinded generations in an interactive app. Med-Flamingo improves performance in generative medical VQA by up to 20\\% in clinician's rating and firstly enables multimodal medical few-shot adaptations, such as rationale generation. We release our model, code, and evaluation app under https://github.com/snap-stanford/med-flamingo.", "url": "https://arxiv.org/abs/2307.15189"}, {"metadata": {"arXiv": "2307.15198", "Date": "Thu, 27 Jul 2023 21:14:40 ", "Title": "One-shot Joint Extraction, Registration and Segmentation of Neuroimaging Data", "Authors": ["Yao Su and Zhentian Qian and Lei Ma and Lifang He and Xiangnan Kong"], "Categories": "cs.CV cs.AI", "Comments": ["Published as a research track paper at KDD 2023. Code: https://github.com/Anonymous4545/JERS"], "DOI": "10.1145/3580305.3599452"}, "abstract": "Brain extraction, registration and segmentation are indispensable preprocessing steps in neuroimaging studies. The aim is to extract the brain from raw imaging scans (i.e., extraction step), align it with a target brain image (i.e., registration step) and label the anatomical brain regions (i.e., segmentation step). Conventional studies typically focus on developing separate methods for the extraction, registration and segmentation tasks in a supervised setting. The performance of these methods is largely contingent on the quantity of training samples and the extent of visual inspections carried out by experts for error correction. Nevertheless, collecting voxel-level labels and performing manual quality control on high-dimensional neuroimages (e.g., 3D MRI) are expensive and time-consuming in many medical studies. In this paper, we study the problem of one-shot joint extraction, registration and segmentation in neuroimaging data, which exploits only one labeled template image (a.k.a. atlas) and a few unlabeled raw images for training. We propose a unified end-to-end framework, called JERS, to jointly optimize the extraction, registration and segmentation tasks, allowing feedback among them. Specifically, we use a group of extraction, registration and segmentation modules to learn the extraction mask, transformation and segmentation mask, where modules are interconnected and mutually reinforced by self-supervision. Empirical results on real-world datasets demonstrate that our proposed method performs exceptionally in the extraction, registration and segmentation tasks. Our code and data can be found at https://github.com/Anonymous4545/JERS", "url": "https://arxiv.org/abs/2307.15198"}, {"metadata": {"arXiv": "2307.15220", "Date": "Thu, 27 Jul 2023 22:38:12 ", "Title": "Learning Multi-modal Representations by Watching Hundreds of Surgical Video Lectures", "Authors": ["Kun Yuan", "Vinkle Srivastav", "Tong Yu", "Joel Lavanchy", "Pietro Mascagni", "Nassir Navab", "Nicolas Padoy"], "Categories": "cs.CV cs.AI"}, "abstract": "Recent advancements in surgical computer vision applications have been driven by fully-supervised methods, primarily using only visual data. These methods rely on manually annotated surgical videos to predict a fixed set of object categories, limiting their generalizability to unseen surgical procedures and downstream tasks. In this work, we put forward the idea that the surgical video lectures available through open surgical e-learning platforms can provide effective supervisory signals for multi-modal representation learning without relying on manual annotations. We address the surgery-specific linguistic challenges present in surgical video lectures by employing multiple complementary automatic speech recognition systems to generate text transcriptions. We then present a novel method, SurgVLP - Surgical Vision Language Pre-training, for multi-modal representation learning. SurgVLP constructs a new contrastive learning objective to align video clip embeddings with the corresponding multiple text embeddings by bringing them together within a joint latent space. To effectively show the representation capability of the learned joint latent space, we introduce several vision-and-language tasks for surgery, such as text-based video retrieval, temporal activity grounding, and video captioning, as benchmarks for evaluation. We further demonstrate that without using any labeled ground truth, our approach can be employed for traditional vision-only surgical downstream tasks, such as surgical tool, phase, and triplet recognition. The code will be made available at https://github.com/CAMMA-public/SurgVLP", "url": "https://arxiv.org/abs/2307.15220"}, {"metadata": {"arXiv": "2307.15254", "Date": "Fri, 28 Jul 2023 01:40:04 ", "Title": "Multiple Instance Learning Framework with Masked Hard Instance Mining for Whole Slide Image Classification", "Authors": ["Wenhao Tang and Sheng Huang and Xiaoxian Zhang and Fengtao Zhou and Yi Zhang and Bo Liu"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted by ICCV2023"]}, "abstract": "The whole slide image (WSI) classification is often formulated as a multiple instance learning (MIL) problem. Since the positive tissue is only a small fraction of the gigapixel WSI,existing MIL methods intuitively focus on identifying salient instances via attention mechanisms. However, this leads to a bias towards easy-to-classify instances while neglecting hard-to-classify instances.Some literature has revealed that hard examples are beneficial for modeling a discriminative boundary accurately.By applying such an idea at the instance level,we elaborate a novel MIL framework with masked hard instance mining (MHIM-MIL), which uses a Siamese structure (Teacher-Student) with a consistency constraint to explore the potential hard instances. With several instance masking strategies based on attention scores, MHIM-MIL employs a momentum teacher to implicitly mine hard instances for training the student model, which can be any attention-based MIL model.This counter-intuitive strategy essentially enables the student to learn a better discriminating boundary.Moreover, the student is used to update the teacher with an exponential moving average (EMA), which in turn identifies new hard instances for subsequent training iterations and stabilizes the optimization.Experimental results on the CAMELYON-16 and TCGA Lung Cancer datasets demonstrate that MHIM-MIL outperforms other latest methods in terms of performance and training cost. The code is available at:https://github.com/DearCaat/MHIM-MIL.", "url": "https://arxiv.org/abs/2307.15254"}, {"metadata": {"arXiv": "2307.15480", "Date": "Fri, 28 Jul 2023 11:08:01 ", "Title": "Non-invasive Diabetes Detection using Gabor Filter: A Comparative Analysis of Different Cameras", "Authors": ["Christina A. Garcia", "Patricia Angela R. Abu", "Rosula SJ. Reyes"], "Categories": "cs.CV cs.AI", "Comments": ["11 pages", "5 figures", "3 tables", "conference"]}, "abstract": "This paper compares and explores the performance of both mobile device camera and laptop camera as convenient tool for capturing images for non-invasive detection of Diabetes Mellitus (DM) using facial block texture features. Participants within age bracket 20 to 79 years old were chosen for the dataset. 12mp and 7mp mobile cameras, and a laptop camera were used to take the photo under normal lighting condition. Extracted facial blocks were classified using k-Nearest Neighbors (k-NN) and Support Vector Machine (SVM). 100 images were captured, preprocessed, filtered using Gabor, and iterated. Performance of the system was measured in terms of accuracy, specificity, and sensitivity. Best performance of 96.7% accuracy, 100% sensitivity, and 93% specificity were achieved from 12mp back camera using SVM with 100 images.", "url": "https://arxiv.org/abs/2307.15480"}, {"metadata": {"arXiv": "2307.15514", "Date": "Fri, 28 Jul 2023 12:16:31 ", "Title": "Revisiting Fully Convolutional Geometric Features for Object 6D Pose Estimation", "Authors": ["Jaime Corsetti", "Davide Boscaini", "Fabio Poiesi"], "Categories": "cs.CV cs.AI", "Comments": ["17 pages. Preprint", "currently under review"]}, "abstract": "Recent works on 6D object pose estimation focus on learning keypoint correspondences between images and object models, and then determine the object pose through RANSAC-based algorithms or by directly regressing the pose with end-to-end optimisations. We argue that learning point-level discriminative features is overlooked in the literature. To this end, we revisit Fully Convolutional Geometric Features (FCGF) and tailor it for object 6D pose estimation to achieve state-of-the-art performance. FCGF employs sparse convolutions and learns point-level features using a fully-convolutional network by optimising a hardest contrastive loss. We can outperform recent competitors on popular benchmarks by adopting key modifications to the loss and to the input data representations, by carefully tuning the training strategies, and by employing data augmentations suitable for the underlying problem. We carry out a thorough ablation to study the contribution of each modification.", "url": "https://arxiv.org/abs/2307.15514"}, {"metadata": {"arXiv": "2307.15524", "Date": "Fri, 28 Jul 2023 12:30:41 ", "Title": "Few-shot Image Classification based on Gradual Machine Learning", "Authors": ["Na Chen", "Xianming Kuang", "Feiyu Liu", "Kehao Wang and Qun Chen"], "Categories": "cs.CV cs.AI", "Comments": ["17 pages,6 figures,5 tables", "55 conferences"]}, "abstract": "Few-shot image classification aims to accurately classify unlabeled images using only a few labeled samples. The state-of-the-art solutions are built by deep learning, which focuses on designing increasingly complex deep backbones. Unfortunately, the task remains very challenging due to the difficulty of transferring the knowledge learned in training classes to new ones. In this paper, we propose a novel approach based on the non-i.i.d paradigm of gradual machine learning (GML). It begins with only a few labeled observations, and then gradually labels target images in the increasing order of hardness by iterative factor inference in a factor graph. Specifically, our proposed solution extracts indicative feature representations by deep backbones, and then constructs both unary and binary factors based on the extracted features to facilitate gradual learning. The unary factors are constructed based on class center distance in an embedding space, while the binary factors are constructed based on k-nearest neighborhood. We have empirically validated the performance of the proposed approach on benchmark datasets by a comparative study. Our extensive experiments demonstrate that the proposed approach can improve the SOTA performance by 1-5% in terms of accuracy. More notably, it is more robust than the existing deep models in that its performance can consistently improve as the size of query set increases while the performance of deep models remains essentially flat or even becomes worse.", "url": "https://arxiv.org/abs/2307.15524"}, {"metadata": {"arXiv": "2307.15218", "Date": "Thu, 27 Jul 2023 22:30:48 ", "Title": "Reachability Poorman Discrete-Bidding Games", "Authors": ["Guy Avni", "Tobias Meggendorfer", "Suman Sadhukhan", "Josef Tkadlec and {\\DJ}or{\\dj}e \\v{Z}ikeli\\'c"], "Categories": "cs.GT cs.AI cs.FL", "Comments": ["The full version of a paper published at ECAI 2023"]}, "abstract": "We consider {\\em bidding games}, a class of two-player zero-sum {\\em graph games}. The game proceeds as follows. Both players have bounded budgets. A token is placed on a vertex of a graph, in each turn the players simultaneously submit bids, and the higher bidder moves the token, where we break bidding ties in favor of Player 1. Player 1 wins the game iff the token visits a designated target vertex. We consider, for the first time, {\\em poorman discrete-bidding} in which the granularity of the bids is restricted and the higher bid is paid to the bank. Previous work either did not impose granularity restrictions or considered {\\em Richman} bidding (bids are paid to the opponent). While the latter mechanisms are technically more accessible, the former is more appealing from a practical standpoint. Our study focuses on {\\em threshold budgets}, which is the necessary and sufficient initial budget required for Player 1 to ensure winning against a given Player 2 budget. We first show existence of thresholds. In DAGs, we show that threshold budgets can be approximated with error bounds by thresholds under continuous-bidding and that they exhibit a periodic behavior. We identify closed-form solutions in special cases. We implement and experiment with an algorithm to find threshold budgets.", "url": "https://arxiv.org/abs/2307.15218"}, {"metadata": {"arXiv": "2307.15568", "Date": "Fri, 28 Jul 2023 14:04:07 ", "Title": "We are all Individuals: The Role of Robot Personality and Human Traits in Trustworthy Interaction", "Authors": ["Mei Yii Lim", "Jos\\'e David Aguas Lopes", "David A. Robb", "Bruce W. Wilson", "Meriam Moujahid", "Emanuele De Pellegrin and Helen Hastie"], "Categories": "cs.RO cs.AI", "Comments": ["8 pages", "RO-MAN'22", "31st IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)", "August 2022", "Naples", "Italy"], "ACM-class": "H.5; I.2", "Journal-ref": "In RO-MAN'2022 (pp. 538-545). IEEE", "DOI": "10.1109/RO-MAN53752.2022.9900772"}, "abstract": "As robots take on roles in our society, it is important that their appearance, behaviour and personality are appropriate for the job they are given and are perceived favourably by the people with whom they interact. Here, we provide an extensive quantitative and qualitative study exploring robot personality but, importantly, with respect to individual human traits. Firstly, we show that we can accurately portray personality in a social robot, in terms of extroversion-introversion using vocal cues and linguistic features. Secondly, through garnering preferences and trust ratings for these different robot personalities, we establish that, for a Robo-Barista, an extrovert robot is preferred and trusted more than an introvert robot, regardless of the subject's own personality. Thirdly, we find that individual attitudes and predispositions towards robots do impact trust in the Robo-Baristas, and are therefore important considerations in addition to robot personality, roles and interaction context when designing any human-robot interaction study.", "url": "https://arxiv.org/abs/2307.15568"}, {"metadata": {"arXiv": "2307.15176", "Date": "Thu, 27 Jul 2023 20:11:07 ", "Title": "RCT Rejection Sampling for Causal Estimation Evaluation", "Authors": ["Katherine A. Keith", "Sergey Feldman", "David Jurgens", "Jonathan Bragg", "Rohit Bhattacharya"], "Categories": "cs.AI cs.CL cs.LG stat.ME", "Comments": ["Code and data at https://github.com/kakeith/rct_rejection_sampling"]}, "abstract": "Confounding is a significant obstacle to unbiased estimation of causal effects from observational data. For settings with high-dimensional covariates -- such as text data, genomics, or the behavioral social sciences -- researchers have proposed methods to adjust for confounding by adapting machine learning methods to the goal of causal estimation. However, empirical evaluation of these adjustment methods has been challenging and limited. In this work, we build on a promising empirical evaluation strategy that simplifies evaluation design and uses real data: subsampling randomized controlled trials (RCTs) to create confounded observational datasets while using the average causal effects from the RCTs as ground-truth. We contribute a new sampling algorithm, which we call RCT rejection sampling, and provide theoretical guarantees that causal identification holds in the observational data to allow for valid comparisons to the ground-truth RCT. Using synthetic data, we show our algorithm indeed results in low bias when oracle estimators are evaluated on the confounded samples, which is not always the case for a previously proposed algorithm. In addition to this identification result, we highlight several finite data considerations for evaluation designers who plan to use RCT rejection sampling on their own datasets. As a proof of concept, we implement an example evaluation pipeline and walk through these finite data considerations with a novel, real-world RCT -- which we release publicly -- consisting of approximately 70k observations and text data as high-dimensional covariates. Together, these contributions build towards a broader agenda of improved empirical evaluation for causal estimation.", "url": "https://arxiv.org/abs/2307.15176"}, {"metadata": {"arXiv": "2307.15217", "Date": "Thu, 27 Jul 2023 22:29:25 ", "Title": "Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback", "Authors": ["Stephen Casper", "Xander Davies", "Claudia Shi", "Thomas Krendl Gilbert", "J\\'er\\'emy Scheurer", "Javier Rando", "Rachel Freedman", "Tomasz Korbak", "David Lindner", "Pedro Freire", "Tony Wang", "Samuel Marks", "Charbel-Rapha\\\"el Segerie", "Micah Carroll", "Andi Peng", "Phillip Christoffersen", "Mehul Damani", "Stewart Slocum", "Usman Anwar", "Anand Siththaranjan", "Max Nadeau", "Eric J. Michaud", "Jacob Pfau", "Dmitrii Krasheninnikov", "Xin Chen", "Lauro Langosco", "Peter Hase", "Erdem B{\\i}y{\\i}k", "Anca Dragan", "David Krueger", "Dorsa Sadigh", "Dylan Hadfield-Menell"], "Categories": "cs.AI cs.CL cs.LG"}, "abstract": "Reinforcement learning from human feedback (RLHF) is a technique for training AI systems to align with human goals. RLHF has emerged as the central method used to finetune state-of-the-art large language models (LLMs). Despite this popularity, there has been relatively little public work systematizing its flaws. In this paper, we (1) survey open problems and fundamental limitations of RLHF and related methods; (2) overview techniques to understand, improve, and complement RLHF in practice; and (3) propose auditing and disclosure standards to improve societal oversight of RLHF systems. Our work emphasizes the limitations of RLHF and highlights the importance of a multi-faceted approach to the development of safer AI systems.", "url": "https://arxiv.org/abs/2307.15217"}, {"metadata": {"arXiv": "2307.15199", "Date": "Thu, 27 Jul 2023 21:14:46 ", "Title": "PromptStyler: Prompt-driven Style Generation for Source-free Domain Generalization", "Authors": ["Junhyeong Cho", "Gilhyun Nam", "Sungyeon Kim", "Hunmin Yang", "Suha Kwak"], "Categories": "cs.CV cs.AI cs.CL cs.LG", "Comments": ["Accepted to ICCV 2023", "Project Page: https://promptstyler.github.io/"]}, "abstract": "In a joint vision-language space, a text feature (e.g., from \"a photo of a dog\") could effectively represent its relevant image features (e.g., from dog photos). Inspired by this, we propose PromptStyler which simulates various distribution shifts in the joint space by synthesizing diverse styles via prompts without using any images to deal with source-free domain generalization. Our method learns to generate a variety of style features (from \"a S* style of a\") via learnable style word vectors for pseudo-words S*. To ensure that learned styles do not distort content information, we force style-content features (from \"a S* style of a [class]\") to be located nearby their corresponding content features (from \"[class]\") in the joint vision-language space. After learning style word vectors, we train a linear classifier using synthesized style-content features. PromptStyler achieves the state of the art on PACS, VLCS, OfficeHome and DomainNet, although it does not require any images and takes just ~30 minutes for training using a single GPU.", "url": "https://arxiv.org/abs/2307.15199"}, {"metadata": {"arXiv": "2307.15317", "Date": "Fri, 28 Jul 2023 05:32:56 ", "Title": "DiffKendall: A Novel Approach for Few-Shot Learning with Differentiable Kendall's Rank Correlation", "Authors": ["Kaipeng Zheng", "Huishuai Zhang", "Weiran Huang"], "Categories": "cs.CV cs.AI cs.LG cs.MM"}, "abstract": "Few-shot learning aims to adapt models trained on the base dataset to novel tasks where the categories are not seen by the model before. This often leads to a relatively uniform distribution of feature values across channels on novel classes, posing challenges in determining channel importance for novel tasks. Standard few-shot learning methods employ geometric similarity metrics such as cosine similarity and negative Euclidean distance to gauge the semantic relatedness between two features. However, features with high geometric similarities may carry distinct semantics, especially in the context of few-shot learning. In this paper, we demonstrate that the importance ranking of feature channels is a more reliable indicator for few-shot learning than geometric similarity metrics. We observe that replacing the geometric similarity metric with Kendall's rank correlation only during inference is able to improve the performance of few-shot learning across a wide range of datasets with different domains. Furthermore, we propose a carefully designed differentiable loss for meta-training to address the non-differentiability issue of Kendall's rank correlation. Extensive experiments demonstrate that the proposed rank-correlation-based approach substantially enhances few-shot learning performance.", "url": "https://arxiv.org/abs/2307.15317"}, {"metadata": {"arXiv": "2307.15644", "Date": "Fri, 28 Jul 2023 16:03:28 ", "Title": "Scaling Data Generation in Vision-and-Language Navigation", "Authors": ["Zun Wang", "Jialu Li", "Yicong Hong", "Yi Wang", "Qi Wu", "Mohit Bansal", "Stephen Gould", "Hao Tan", "Yu Qiao"], "Categories": "cs.CV cs.AI cs.CL cs.LG", "Comments": ["ICCV 2023"]}, "abstract": "Recent research in language-guided visual navigation has demonstrated a significant demand for the diversity of traversable environments and the quantity of supervision for training generalizable agents. To tackle the common data scarcity issue in existing vision-and-language navigation datasets, we propose an effective paradigm for generating large-scale data for learning, which applies 1200+ photo-realistic environments from HM3D and Gibson datasets and synthesizes 4.9 million instruction trajectory pairs using fully-accessible resources on the web. Importantly, we investigate the influence of each component in this paradigm on the agent's performance and study how to adequately apply the augmented data to pre-train and fine-tune an agent. Thanks to our large-scale dataset, the performance of an existing agent can be pushed up (+11% absolute with regard to previous SoTA) to a significantly new best of 80% single-run success rate on the R2R test split by simple imitation learning. The long-lasting generalization gap between navigating in seen and unseen environments is also reduced to less than 1% (versus 8% in the previous best method). Moreover, our paradigm also facilitates different models to achieve new state-of-the-art navigation results on CVDN, REVERIE, and R2R in continuous environments.", "url": "https://arxiv.org/abs/2307.15644"}, {"metadata": {"arXiv": "2307.15193", "Date": "Thu, 27 Jul 2023 20:49:28 ", "Title": "Learning in Repeated Multi-Unit Pay-As-Bid Auctions", "Authors": ["Rigel Galgana and Negin Golrezaei"], "Categories": "cs.GT cs.AI cs.DS cs.LG", "Comments": ["51 pages", "12 Figures"]}, "abstract": "Motivated by Carbon Emissions Trading Schemes, Treasury Auctions, and Procurement Auctions, which all involve the auctioning of homogeneous multiple units, we consider the problem of learning how to bid in repeated multi-unit pay-as-bid auctions. In each of these auctions, a large number of (identical) items are to be allocated to the largest submitted bids, where the price of each of the winning bids is equal to the bid itself. The problem of learning how to bid in pay-as-bid auctions is challenging due to the combinatorial nature of the action space. We overcome this challenge by focusing on the offline setting, where the bidder optimizes their vector of bids while only having access to the past submitted bids by other bidders. We show that the optimal solution to the offline problem can be obtained using a polynomial time dynamic programming (DP) scheme. We leverage the structure of the DP scheme to design online learning algorithms with polynomial time and space complexity under full information and bandit feedback settings. We achieve an upper bound on regret of $O(M\\sqrt{T\\log |\\mathcal{B}|})$ and $O(M\\sqrt{|\\mathcal{B}|T\\log |\\mathcal{B}|})$ respectively, where $M$ is the number of units demanded by the bidder, $T$ is the total number of auctions, and $|\\mathcal{B}|$ is the size of the discretized bid space. We accompany these results with a regret lower bound, which match the linear dependency in $M$. Our numerical results suggest that when all agents behave according to our proposed no regret learning algorithms, the resulting market dynamics mainly converge to a welfare maximizing equilibrium where bidders submit uniform bids. Lastly, our experiments demonstrate that the pay-as-bid auction consistently generates significantly higher revenue compared to its popular alternative, the uniform price auction.", "url": "https://arxiv.org/abs/2307.15193"}, {"metadata": {"arXiv": "2307.15089", "Date": "Wed, 26 Jul 2023 21:42:34 ", "Title": "Information Gained Subgroup Discovery in Datasets", "Authors": ["Daniel G\\'omez-Bravo", "Aaron Garc\\'ia", "Guillermo Vigueras", "Bel\\'en R\\'ios", "Mariano Provencio", "Alejandro Rodr\\'iguez-Gonz\\'alez"], "Categories": "cs.LG cs.AI"}, "abstract": "Lung cancer is the leading cause of cancer death. More than 238,340 new cases of lung cancer patients are expected in 2023, with an estimation of more than 127,070 deaths. Choosing the correct treatment is an important element to enhance the probability of survival and to improve patient's quality of life. Cancer treatments might provoke secondary effects. These toxicities cause different health problems that impact the patient's quality of life. Hence, reducing treatments toxicities while maintaining or improving their effectivenes is an important goal that aims to be pursued from the clinical perspective. On the other hand, clinical guidelines include general knowledge about cancer treatment recommendations to assist clinicians. Although they provide treatment recommendations based on cancer disease aspects and individual patient features, a statistical analysis taking into account treatment outcomes is not provided here. Therefore, the comparison between clinical guidelines with treatment patterns found in clinical data, would allow to validate the patterns found, as well as discovering alternative treatment patterns. In this work, we present Information Gained Subgroup Discovery, a Subgroup Discovery algorithm that aims to find most relevant patterns taking into account Information gain and Odds ratio. Thus, we analyze a dataset containing lung cancer patients information including patients' data, prescribed treatments and their outcomes. Obtained results are validated through clinicians and compared with clinical guidelines. We conclude that this new algorithm achieves highest acceptance of found patterns in this dataset, while also improving indices of Subgroup Discovery.", "url": "https://arxiv.org/abs/2307.15089"}, {"metadata": {"arXiv": "2307.15090", "Date": "Thu, 27 Jul 2023 00:37:18 ", "Title": "Understanding Forward Process of Convolutional Neural Network", "Authors": ["Peixin Tian"], "Categories": "cs.LG cs.AI"}, "abstract": "This paper reveal the selective rotation in the CNNs' forward processing. It elucidates the activation function as a discerning mechanism that unifies and quantizes the rotational aspects of the input data. Experiments show how this defined methodology reflects the progress network distinguish inputs based on statistical indicators, which can be comprehended or analyzed by applying structured mathematical tools. Our findings also unveil the consistency between artificial neural networks and the human brain in their data processing pattern.", "url": "https://arxiv.org/abs/2307.15090"}, {"metadata": {"arXiv": "2307.15245", "Date": "Fri, 28 Jul 2023 00:48:05 ", "Title": "A Practical Recipe for Federated Learning Under Statistical Heterogeneity Experimental Design", "Authors": ["Mahdi Morafah", "Weijia Wang", "Bill Lin"], "Categories": "cs.LG cs.AI"}, "abstract": "Federated Learning (FL) has been an area of active research in recent years. There have been numerous studies in FL to make it more successful in the presence of data heterogeneity. However, despite the existence of many publications, the state of progress in the field is unknown. Many of the works use inconsistent experimental settings and there are no comprehensive studies on the effect of FL-specific experimental variables on the results and practical insights for a more comparable and consistent FL experimental setup. Furthermore, the existence of several benchmarks and confounding variables has further complicated the issue of inconsistency and ambiguity. In this work, we present the first comprehensive study on the effect of FL-specific experimental variables in relation to each other and performance results, bringing several insights and recommendations for designing a meaningful and well-incentivized FL experimental setup. We further aid the community by releasing FedZoo-Bench, an open-source library based on PyTorch with pre-implementation of 22 state-of-the-art methods, and a broad set of standardized and customizable features available at https://github.com/MMorafah/FedZoo-Bench. We also provide a comprehensive comparison of several state-of-the-art (SOTA) methods to better understand the current state of the field and existing limitations.", "url": "https://arxiv.org/abs/2307.15245"}, {"metadata": {"arXiv": "2307.15377", "Date": "Fri, 28 Jul 2023 07:53:34 ", "Title": "Co-attention Graph Pooling for Efficient Pairwise Graph Interaction Learning", "Authors": ["Junhyun Lee", "Bumsoo Kim", "Minji Jeon", "Jaewoo Kang"], "Categories": "cs.LG cs.AI", "Comments": ["Published at IEEE Access"], "Journal-ref": "IEEE Access", "DOI": "10.1109/ACCESS.2023.3299267"}, "abstract": "Graph Neural Networks (GNNs) have proven to be effective in processing and learning from graph-structured data. However, previous works mainly focused on understanding single graph inputs while many real-world applications require pair-wise analysis for graph-structured data (e.g., scene graph matching, code searching, and drug-drug interaction prediction). To this end, recent works have shifted their focus to learning the interaction between pairs of graphs. Despite their improved performance, these works were still limited in that the interactions were considered at the node-level, resulting in high computational costs and suboptimal performance. To address this issue, we propose a novel and efficient graph-level approach for extracting interaction representations using co-attention in graph pooling. Our method, Co-Attention Graph Pooling (CAGPool), exhibits competitive performance relative to existing methods in both classification and regression tasks using real-world datasets, while maintaining lower computational complexity.", "url": "https://arxiv.org/abs/2307.15377"}, {"metadata": {"arXiv": "2307.15429", "Date": "Fri, 28 Jul 2023 09:26:03 ", "Title": "Improvable Gap Balancing for Multi-Task Learning", "Authors": ["Yanqi Dai", "Nanyi Fei", "Zhiwu Lu"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["Accepted for the 39th Conference on Uncertainty in Artificial Intelligence (UAI 2023)"]}, "abstract": "In multi-task learning (MTL), gradient balancing has recently attracted more research interest than loss balancing since it often leads to better performance. However, loss balancing is much more efficient than gradient balancing, and thus it is still worth further exploration in MTL. Note that prior studies typically ignore that there exist varying improvable gaps across multiple tasks, where the improvable gap per task is defined as the distance between the current training progress and desired final training progress. Therefore, after loss balancing, the performance imbalance still arises in many cases. In this paper, following the loss balancing framework, we propose two novel improvable gap balancing (IGB) algorithms for MTL: one takes a simple heuristic, and the other (for the first time) deploys deep reinforcement learning for MTL. Particularly, instead of directly balancing the losses in MTL, both algorithms choose to dynamically assign task weights for improvable gap balancing. Moreover, we combine IGB and gradient balancing to show the complementarity between the two types of algorithms. Extensive experiments on two benchmark datasets demonstrate that our IGB algorithms lead to the best results in MTL via loss balancing and achieve further improvements when combined with gradient balancing. Code is available at https://github.com/YanqiDai/IGB4MTL.", "url": "https://arxiv.org/abs/2307.15429"}, {"metadata": {"arXiv": "2307.15456", "Date": "Fri, 28 Jul 2023 10:20:08 ", "Title": "Worrisome Properties of Neural Network Controllers and Their Symbolic Representations", "Authors": ["Jacek Cyranka and Kevin E M Church and Jean-Philippe Lessard"], "Categories": "cs.LG cs.AI math.DS math.OC", "Comments": ["accepted to ECAI23"]}, "abstract": "We raise concerns about controllers' robustness in simple reinforcement learning benchmark problems. We focus on neural network controllers and their low neuron and symbolic abstractions. A typical controller reaching high mean return values still generates an abundance of persistent low-return solutions, which is a highly undesirable property, easily exploitable by an adversary. We find that the simpler controllers admit more persistent bad solutions. We provide an algorithm for a systematic robustness study and prove existence of persistent solutions and, in some cases, periodic orbits, using a computer-assisted proof methodology.", "url": "https://arxiv.org/abs/2307.15456"}, {"metadata": {"arXiv": "2307.15678", "Date": "Fri, 28 Jul 2023 17:13:00 ", "Title": "Case Studies of Causal Discovery from IT Monitoring Time Series", "Authors": ["Ali A\\\"it-Bachir", "Charles K. Assaad", "Christophe de Bignicourt", "Emilie Devijver", "Simon Ferreira", "Eric Gaussier", "Hosein Mohanna", "Lei Zan"], "Categories": "cs.LG cs.AI stat.AP stat.ME", "Comments": ["Accepted to the UAI 2023 Workshop on The History and Development of Search Methods for Causal Structure"]}, "abstract": "Information technology (IT) systems are vital for modern businesses, handling data storage, communication, and process automation. Monitoring these systems is crucial for their proper functioning and efficiency, as it allows collecting extensive observational time series data for analysis. The interest in causal discovery is growing in IT monitoring systems as knowing causal relations between different components of the IT system helps in reducing downtime, enhancing system performance and identifying root causes of anomalies and incidents. It also allows proactive prediction of future issues through historical data analysis. Despite its potential benefits, applying causal discovery algorithms on IT monitoring data poses challenges, due to the complexity of the data. For instance, IT monitoring data often contains misaligned time series, sleeping time series, timestamp errors and missing values. This paper presents case studies on applying causal discovery algorithms to different IT monitoring datasets, highlighting benefits and ongoing challenges.", "url": "https://arxiv.org/abs/2307.15678"}, {"metadata": {"arXiv": "2307.15320", "Date": "Fri, 28 Jul 2023 05:47:24 ", "Title": "Robust Visual Sim-to-Real Transfer for Robotic Manipulation", "Authors": ["Ricardo Garcia and Robin Strudel and Shizhe Chen and Etienne Arlaud and Ivan Laptev and Cordelia Schmid"], "Categories": "cs.RO cs.AI cs.CV cs.LG"}, "abstract": "Learning visuomotor policies in simulation is much safer and cheaper than in the real world. However, due to discrepancies between the simulated and real data, simulator-trained policies often fail when transferred to real robots. One common approach to bridge the visual sim-to-real domain gap is domain randomization (DR). While previous work mainly evaluates DR for disembodied tasks, such as pose estimation and object detection, here we systematically explore visual domain randomization methods and benchmark them on a rich set of challenging robotic manipulation tasks. In particular, we propose an off-line proxy task of cube localization to select DR parameters for texture randomization, lighting randomization, variations of object colors and camera parameters. Notably, we demonstrate that DR parameters have similar impact on our off-line proxy task and on-line policies. We, hence, use off-line optimized DR parameters to train visuomotor policies in simulation and directly apply such policies to a real robot. Our approach achieves 93% success rate on average when tested on a diverse set of challenging manipulation tasks. Moreover, we evaluate the robustness of policies to visual variations in real scenes and show that our simulator-trained policies outperform policies learned using real but limited data. Code, simulation environment, real robot datasets and trained models are available at https://www.di.ens.fr/willow/research/robust_s2r/.", "url": "https://arxiv.org/abs/2307.15320"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2311.12804", "Date": "Fri, 15 Sep 2023 07:25:36 ", "Title": "Towards the generation of synchronized and believable non-verbal facial behaviors of a talking virtual agent", "Authors": ["Alice Delbosc (TALEP", "LIS", "AMU)", "Magalie Ochs (LIS", "AMU", "TALEP)", "Nicolas Sabouret (LISN)", "Brian Ravenet (LISN)", "St\\'ephane Ayache (AMU", "LIS", "QARMA)"], "Categories": "cs.CV cs.LG cs.NE", "Journal-ref": "INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION (ICMI '23 Companion), Oct 2023, Paris, France"}, "abstract": "This paper introduces a new model to generate rhythmically relevant non-verbal facial behaviors for virtual agents while they speak. The model demonstrates perceived performance comparable to behaviors directly extracted from the data and replayed on a virtual agent, in terms of synchronization with speech and believability. Interestingly, we found that training the model with two different sets of data, instead of one, did not necessarily improve its performance. The expressiveness of the people in the dataset and the shooting conditions are key elements. We also show that employing an adversarial model, in which fabricated fake examples are introduced during the training phase, increases the perception of synchronization with speech. A collection of videos demonstrating the results and code can be accessed at: https://github.com/aldelb/non_verbal_facial_animation.", "url": "https://arxiv.org/abs/2311.12804"}, {"metadata": {"arXiv": "2311.12806", "Date": "Tue, 19 Sep 2023 07:19:16 ", "Title": "MatGD: Materials Graph Digitizer", "Authors": ["Jaewoong Lee", "Wonseok Lee", "Jihan Kim"], "Categories": "cs.CV cs.DL cs.IR cs.LG", "Comments": ["23 pages", "4 figures"]}, "abstract": "We have developed MatGD (Material Graph Digitizer), which is a tool for digitizing a data line from scientific graphs. The algorithm behind the tool consists of four steps: (1) identifying graphs within subfigures, (2) separating axes and data sections, (3) discerning the data lines by eliminating irrelevant graph objects and matching with the legend, and (4) data extraction and saving. From the 62,534 papers in the areas of batteries, catalysis, and MOFs, 501,045 figures were mined. Remarkably, our tool showcased performance with over 99% accuracy in legend marker and text detection. Moreover, its capability for data line separation stood at 66%, which is much higher compared to other existing figure mining tools. We believe that this tool will be integral to collecting both past and future data from publications, and these data can be used to train various machine learning models that can enhance material predictions and new materials discovery.", "url": "https://arxiv.org/abs/2311.12806"}, {"metadata": {"arXiv": "2311.12810", "Date": "Wed, 20 Sep 2023 12:07:16 ", "Title": "Combining low-dose CT-based radiomics and metabolomics for early lung cancer screening support", "Authors": ["Joanna Zyla", "Michal Marczyk", "Wojciech Prazuch", "Marek Socha", "Aleksandra Suwalska", "Agata Durawa", "Malgorzata Jelitto-Gorska", "Katarzyna Dziadziuszko", "Edyta Szurowska", "Witold Rzyman", "Piotr Widlak", "Joanna Polanska"], "Categories": "cs.CV cs.LG stat.AP"}, "abstract": "Due to its predominantly asymptomatic or mildly symptomatic progression, lung cancer is often diagnosed in advanced stages, resulting in poorer survival rates for patients. As with other cancers, early detection significantly improves the chances of successful treatment. Early diagnosis can be facilitated through screening programs designed to detect lung tissue tumors when they are still small, typically around 3mm in size. However, the analysis of extensive screening program data is hampered by limited access to medical experts. In this study, we developed a procedure for identifying potential malignant neoplastic lesions within lung parenchyma. The system leverages machine learning (ML) techniques applied to two types of measurements: low-dose Computed Tomography-based radiomics and metabolomics. Using data from two Polish screening programs, two ML algorithms were tested, along with various integration methods, to create a final model that combines both modalities to support lung cancer screening.", "url": "https://arxiv.org/abs/2311.12810"}, {"metadata": {"arXiv": "2311.12813", "Date": "Fri, 22 Sep 2023 13:02:14 ", "Title": "Targeted Activation Penalties Help CNNs Ignore Spurious Signals", "Authors": ["Dekai Zhang", "Matthew Williams", "Francesca Toni"], "Categories": "cs.CV cs.LG", "Comments": ["23 pages including appendix"]}, "abstract": "Neural networks (NNs) can learn to rely on spurious signals in the training data, leading to poor generalisation. Recent methods tackle this problem by training NNs with additional ground-truth annotations of such signals. These methods may, however, let spurious signals re-emerge in deep convolutional NNs (CNNs). We propose Targeted Activation Penalty (TAP), a new method tackling the same problem by penalising activations to control the re-emergence of spurious signals in deep CNNs, while also lowering training times and memory usage. In addition, ground-truth annotations can be expensive to obtain. We show that TAP still works well with annotations generated by pre-trained models as effective substitutes of ground-truth annotations. We demonstrate the power of TAP against two state-of-the-art baselines on the MNIST benchmark and on two clinical image datasets, using four different CNN architectures.", "url": "https://arxiv.org/abs/2311.12813"}, {"metadata": {"arXiv": "2311.12816", "Date": "Sun, 24 Sep 2023 09:11:22 ", "Title": "Evolution of Convolutional Neural Network (CNN): Compute vs Memory bandwidth for Edge AI", "Authors": ["Dwith Chenna"], "Categories": "cs.CV cs.LG"}, "abstract": "Convolutional Neural Networks (CNNs) have greatly influenced the field of Embedded Vision and Edge Artificial Intelligence (AI), enabling powerful machine learning capabilities on resource-constrained devices. This article explores the relationship between CNN compute requirements and memory bandwidth in the context of Edge AI. We delve into the historical progression of CNN architectures, from the early pioneering models to the current state-of-the-art designs, highlighting the advancements in compute-intensive operations. We examine the impact of increasing model complexity on both computational requirements and memory access patterns. The paper presents a comparison analysis of the evolving trade-off between compute demands and memory bandwidth requirements in CNNs. This analysis provides insights into designing efficient architectures and potential hardware accelerators in enhancing CNN performance on edge devices.", "url": "https://arxiv.org/abs/2311.12816"}, {"metadata": {"arXiv": "2311.12821", "Date": "Tue, 26 Sep 2023 19:47:31 ", "Title": "Advancing The Rate-Distortion-Computation Frontier For Neural Image Compression", "Authors": ["David Minnen and Nick Johnston"], "Categories": "cs.CV cs.LG eess.IV", "Comments": ["Published in 2023 IEEE International Conference on Image Processing (ICIP)"], "DOI": "10.1109/ICIP49359.2023.10222381"}, "abstract": "The rate-distortion performance of neural image compression models has exceeded the state-of-the-art for non-learned codecs, but neural codecs are still far from widespread deployment and adoption. The largest obstacle is having efficient models that are feasible on a wide variety of consumer hardware. Comparative research and evaluation is difficult due to the lack of standard benchmarking platforms and due to variations in hardware architectures and test environments. Through our rate-distortion-computation (RDC) study we demonstrate that neither floating-point operations (FLOPs) nor runtime are sufficient on their own to accurately rank neural compression methods. We also explore the RDC frontier, which leads to a family of model architectures with the best empirical trade-off between computational requirements and RD performance. Finally, we identify a novel neural compression architecture that yields state-of-the-art RD performance with rate savings of 23.1% over BPG (7.0% over VTM and 3.0% over ELIC) without requiring significantly more FLOPs than other learning-based codecs.", "url": "https://arxiv.org/abs/2311.12821"}, {"metadata": {"arXiv": "2311.12831", "Date": "Mon, 02 Oct 2023 06:06:32 ", "Title": "ECNR: Efficient Compressive Neural Representation of Time-Varying Volumetric Datasets", "Authors": ["Kaiyuan Tang and Chaoli Wang"], "Categories": "cs.CV cs.GR cs.LG"}, "abstract": "Due to its conceptual simplicity and generality, compressive neural representation has emerged as a promising alternative to traditional compression methods for managing massive volumetric datasets. The state-of-the-art neural compression solution, neurcomp, however, utilizes a single large multilayer perceptron (MLP) to encode the global volume, incurring slow training and inference. This paper presents an efficient compressive neural representation (ECNR) solution that improves upon neurcomp to handle large-scale time-varying datasets. At the heart of our approach is a multiscale structure that uses the Laplacian pyramid for adaptive signal fitting via implicit neural representation. We leverage multiple small MLPs at each scale for fitting local content or residual blocks. By assigning similar blocks to the same MLP via size uniformization, we enable balanced parallelization among MLPs to significantly speed up training and inference. A deep compression strategy is then employed to compact the resulting model. We demonstrate the effectiveness of ECNR with multiple datasets and compare it with neurcomp and two state-of-the-art conventional compression methods (SZ3 and TTHRESH). Our results position ECNR as a promising alternative to neurcomp for scientific data compression.", "url": "https://arxiv.org/abs/2311.12831"}, {"metadata": {"arXiv": "2311.12850", "Date": "Thu, 19 Oct 2023 14:04:53 ", "Title": "Meticulously Selecting 1% of the Dataset for Pre-training! Generating Differentially Private Images Data with Semantics Query", "Authors": ["Kecen Li", "Chen Gong", "Zhixiang Li", "Yuzhong Zhao", "Xinwen Hou", "Tianhao Wang"], "Categories": "cs.CV cs.LG", "Comments": ["21 pages"]}, "abstract": "Differential Privacy (DP) image data synthesis, which leverages the DP technique to generate synthetic data to replace the sensitive data, allowing organizations to share and utilize synthetic images without privacy concerns. Previous methods incorporate the advanced techniques of generative models and pre-training on a public dataset to produce exceptional DP image data, but suffer from problems of unstable training and massive computational resource demands. This paper proposes a novel DP image synthesis method, termed PRIVIMAGE, which meticulously selects pre-training data, promoting the efficient creation of DP datasets with high fidelity and utility. PRIVIMAGE first establishes a semantic query function using a public dataset. Then, this function assists in querying the semantic distribution of the sensitive dataset, facilitating the selection of data from the public dataset with analogous semantics for pre-training. Finally, we pre-train an image generative model using the selected data and then fine-tune this model on the sensitive dataset using Differentially Private Stochastic Gradient Descent (DP-SGD). PRIVIMAGE allows us to train a lightly parameterized generative model, reducing the noise in the gradient during DP-SGD training and enhancing training stability. Extensive experiments demonstrate that PRIVIMAGE uses only 1% of the public dataset for pre-training and 7.6% of the parameters in the generative model compared to the state-of-the-art method, whereas achieves superior synthetic performance and conserves more computational resources. On average, PRIVIMAGE achieves 30.1% lower FID and 12.6% higher Classification Accuracy than the state-of-the-art method. The replication package and datasets can be accessed online.", "url": "https://arxiv.org/abs/2311.12850"}, {"metadata": {"arXiv": "2311.12859", "Date": "Wed, 25 Oct 2023 08:23:45 ", "Title": "Joint Multi-View Collaborative Clustering", "Authors": ["Yasser Khalafaoui (Alteca", "ETIS)", "Basarab Matei (LIPN)", "Nistor Grozavu (ETIS)", "Martino Lovisetto (Alteca)"], "Categories": "cs.CV cs.LG", "Comments": ["2023 International Joint Conference on Neural Networks (IJCNN)", "Jun 2023", "Gold Coast", "Australia"], "DOI": "10.1109/IJCNN54540.2023.10192014"}, "abstract": "Data is increasingly being collected from multiple sources and described by multiple views. These multi-view data provide richer information than traditional single-view data. Fusing the former for specific tasks is an essential component of multi-view clustering. Since the goal of multi-view clustering algorithms is to discover the common latent structure shared by multiple views, the majority of proposed solutions overlook the advantages of incorporating knowledge derived from horizontal collaboration between multi-view data and the final consensus. To fill this gap, we propose the Joint Multi-View Collaborative Clustering (JMVCC) solution, which involves the generation of basic partitions using Non-negative Matrix Factorization (NMF) and the horizontal collaboration principle, followed by the fusion of these local partitions using ensemble clustering. Furthermore, we propose a weighting method to reduce the risk of negative collaboration (i.e., views with low quality) during the generation and fusion of local partitions. The experimental results, which were obtained using a variety of data sets, demonstrate that JMVCC outperforms other multi-view clustering algorithms and is robust to noisy views.", "url": "https://arxiv.org/abs/2311.12859"}, {"metadata": {"arXiv": "2311.13073", "Date": "Wed, 22 Nov 2023 00:26:15 ", "Title": "FusionFrames: Efficient Architectural Aspects for Text-to-Video Generation Pipeline", "Authors": ["Vladimir Arkhipkin", "Zein Shaheen", "Viacheslav Vasilev", "Elizaveta Dakhova", "Andrey Kuznetsov", "Denis Dimitrov"], "Categories": "cs.CV cs.LG cs.MM", "Comments": ["Project page: https://ai-forever.github.io/kandinsky-video/"]}, "abstract": "Multimedia generation approaches occupy a prominent place in artificial intelligence research. Text-to-image models achieved high-quality results over the last few years. However, video synthesis methods recently started to develop. This paper presents a new two-stage latent diffusion text-to-video generation architecture based on the text-to-image diffusion model. The first stage concerns keyframes synthesis to figure the storyline of a video, while the second one is devoted to interpolation frames generation to make movements of the scene and objects smooth. We compare several temporal conditioning approaches for keyframes generation. The results show the advantage of using separate temporal blocks over temporal layers in terms of metrics reflecting video generation quality aspects and human preference. The design of our interpolation model significantly reduces computational costs compared to other masked frame interpolation approaches. Furthermore, we evaluate different configurations of MoVQ-based video decoding scheme to improve consistency and achieve higher PSNR, SSIM, MSE, and LPIPS scores. Finally, we compare our pipeline with existing solutions and achieve top-2 scores overall and top-1 among open-source solutions: CLIPSIM = 0.2976 and FVD = 433.054. Project page: https://ai-forever.github.io/kandinsky-video/", "url": "https://arxiv.org/abs/2311.13073"}, {"metadata": {"arXiv": "2311.13250", "Date": "Wed, 22 Nov 2023 09:12:50 ", "Title": "Towards Hetero-Client Federated Multi-Task Learning", "Authors": ["Yuxiang Lu", "Suizhi Huang", "Yuwen Yang", "Shalayiding Sirejiding", "Yue Ding", "Hongtao Lu"], "Categories": "cs.CV cs.LG"}, "abstract": "Federated Learning (FL) enables joint training across distributed clients using their local data privately. Federated Multi-Task Learning (FMTL) builds on FL to handle multiple tasks, assuming model congruity that identical model architecture is deployed in each client. To relax this assumption and thus extend real-world applicability, we introduce a novel problem setting, Hetero-Client Federated Multi-Task Learning (HC-FMTL), to accommodate diverse task setups. The main challenge of HC-FMTL is the model incongruity issue that invalidates conventional aggregation methods. It also escalates the difficulties in accurate model aggregation to deal with data and task heterogeneity inherent in FMTL. To address these challenges, we propose the FedHCA$^2$ framework, which allows for federated training of personalized models by modeling relationships among heterogeneous clients. Drawing on our theoretical insights into the difference between multi-task and federated optimization, we propose the Hyper Conflict-Averse Aggregation scheme to mitigate conflicts during encoder updates. Additionally, inspired by task interaction in MTL, the Hyper Cross Attention Aggregation scheme uses layer-wise cross attention to enhance decoder interactions while alleviating model incongruity. Moreover, we employ learnable Hyper Aggregation Weights for each client to customize personalized parameter updates. Extensive experiments demonstrate the superior performance of FedHCA$^2$ in various HC-FMTL scenarios compared to representative methods. Our code will be made publicly available.", "url": "https://arxiv.org/abs/2311.13250"}, {"metadata": {"arXiv": "2311.13258", "Date": "Wed, 22 Nov 2023 09:23:34 ", "Title": "ViStruct: Visual Structural Knowledge Extraction via Curriculum Guided Code-Vision Representation", "Authors": ["Yangyi Chen", "Xingyao Wang", "Manling Li", "Derek Hoiem", "Heng Ji"], "Categories": "cs.CV cs.CL cs.LG", "Comments": ["Accepted to EMNLP 2023"]}, "abstract": "State-of-the-art vision-language models (VLMs) still have limited performance in structural knowledge extraction, such as relations between objects. In this work, we present ViStruct, a training framework to learn VLMs for effective visual structural knowledge extraction. Two novel designs are incorporated. First, we propose to leverage the inherent structure of programming language to depict visual structural information. This approach enables explicit and consistent representation of visual structural information of multiple granularities, such as concepts, relations, and events, in a well-organized structured format. Second, we introduce curriculum-based learning for VLMs to progressively comprehend visual structures, from fundamental visual concepts to intricate event structures. Our intuition is that lower-level knowledge may contribute to complex visual structure understanding. Furthermore, we compile and release a collection of datasets tailored for visual structural knowledge extraction. We adopt a weakly-supervised approach to directly generate visual event structures from captions for ViStruct training, capitalizing on abundant image-caption pairs from the web. In experiments, we evaluate ViStruct on visual structure prediction tasks, demonstrating its effectiveness in improving the understanding of visual structures. The code is public at \\url{https://github.com/Yangyi-Chen/vi-struct}.", "url": "https://arxiv.org/abs/2311.13258"}, {"metadata": {"arXiv": "2311.13355", "Date": "Wed, 22 Nov 2023 12:47:12 ", "Title": "Unified Classification and Rejection: A One-versus-All Framework", "Authors": ["Zhen Cheng", "Xu-Yao Zhang", "Cheng-Lin Liu"], "Categories": "cs.CV cs.LG"}, "abstract": "Classifying patterns of known classes and rejecting ambiguous and novel (also called as out-of-distribution (OOD)) inputs are involved in open world pattern recognition. Deep neural network models usually excel in closed-set classification while performing poorly in rejecting OOD. To tackle this problem, numerous methods have been designed to perform open set recognition (OSR) or OOD rejection/detection tasks. Previous methods mostly take post-training score transformation or hybrid models to ensure low scores on OOD inputs while separating known classes. In this paper, we attempt to build a unified framework for building open set classifiers for both classification and OOD rejection. We formulate the open set recognition of $ K $-known-class as a $ (K + 1) $-class classification problem with model trained on known-class samples only. By decomposing the $ K $-class problem into $ K $ one-versus-all (OVA) binary classification tasks and binding some parameters, we show that combining the scores of OVA classifiers can give $ (K + 1) $-class posterior probabilities, which enables classification and OOD rejection in a unified framework. To maintain the closed-set classification accuracy of the OVA trained classifier, we propose a hybrid training strategy combining OVA loss and multi-class cross-entropy loss. We implement the OVA framework and hybrid training strategy on the recently proposed convolutional prototype network. Experiments on popular OSR and OOD detection datasets demonstrate that the proposed framework, using a single multi-class classifier, yields competitive performance in closed-set classification, OOD detection, and misclassification detection.", "url": "https://arxiv.org/abs/2311.13355"}, {"metadata": {"arXiv": "2311.13531", "Date": "Wed, 22 Nov 2023 17:06:57 ", "Title": "Leveraging CNNs and Ensemble Learning for Automated Disaster Image Classification", "Authors": ["Archit Rathod", "Veer Pariawala", "Mokshit Surana", "Kumkum Saxena"], "Categories": "cs.CV cs.LG", "Comments": ["13 pages", "11 figures", "4 tables", "ICSISCET 2023 Conference"]}, "abstract": "Natural disasters act as a serious threat globally, requiring effective and efficient disaster management and recovery. This paper focuses on classifying natural disaster images using Convolutional Neural Networks (CNNs). Multiple CNN architectures were built and trained on a dataset containing images of earthquakes, floods, wildfires, and volcanoes. A stacked CNN ensemble approach proved to be the most effective, achieving 95% accuracy and an F1 score going up to 0.96 for individual classes. Tuning hyperparameters of individual models for optimization was critical to maximize the models' performance. The stacking of CNNs with XGBoost acting as the meta-model utilizes the strengths of the CNN and ResNet models to improve the overall accuracy of the classification. Results obtained from the models illustrated the potency of CNN-based models for automated disaster image classification. This lays the foundation for expanding these techniques to build robust systems for disaster response, damage assessment, and recovery management.", "url": "https://arxiv.org/abs/2311.13531"}, {"metadata": {"arXiv": "2311.13600", "Date": "Wed, 22 Nov 2023 18:59:36 ", "Title": "ZipLoRA: Any Subject in Any Style by Effectively Merging LoRAs", "Authors": ["Viraj Shah", "Nataniel Ruiz", "Forrester Cole", "Erika Lu", "Svetlana Lazebnik", "Yuanzhen Li", "Varun Jampani"], "Categories": "cs.CV cs.GR cs.LG", "Comments": ["Project page: https://ziplora.github.io"]}, "abstract": "Methods for finetuning generative models for concept-driven personalization generally achieve strong results for subject-driven or style-driven generation. Recently, low-rank adaptations (LoRA) have been proposed as a parameter-efficient way of achieving concept-driven personalization. While recent work explores the combination of separate LoRAs to achieve joint generation of learned styles and subjects, existing techniques do not reliably address the problem; they often compromise either subject fidelity or style fidelity. We propose ZipLoRA, a method to cheaply and effectively merge independently trained style and subject LoRAs in order to achieve generation of any user-provided subject in any user-provided style. Experiments on a wide range of subject and style combinations show that ZipLoRA can generate compelling results with meaningful improvements over baselines in subject and style fidelity while preserving the ability to recontextualize. Project page: https://ziplora.github.io", "url": "https://arxiv.org/abs/2311.13600"}, {"metadata": {"arXiv": "2311.12902", "Date": "Tue, 21 Nov 2023 11:04:13 ", "Title": "Local Convolution Enhanced Global Fourier Neural Operator For Multiscale Dynamic Spaces Prediction", "Authors": ["Xuanle Zhao", "Yue Sun", "Tielin Zhang", "Bo Xu"], "Categories": "cs.LG cs.NA math.DS math.NA", "Comments": ["10 pages", "4 figures"]}, "abstract": "Neural operators extend the capabilities of traditional neural networks by allowing them to handle mappings between function spaces for the purpose of solving partial differential equations (PDEs). One of the most notable methods is the Fourier Neural Operator (FNO), which is inspired by Green's function method and approximate operator kernel directly in the frequency domain. In this work, we focus on predicting multiscale dynamic spaces, which is equivalent to solving multiscale PDEs. Multiscale PDEs are characterized by rapid coefficient changes and solution space oscillations, which are crucial for modeling atmospheric convection and ocean circulation. To solve this problem, models should have the ability to capture rapid changes and process them at various scales. However, the FNO only approximates kernels in the low-frequency domain, which is insufficient when solving multiscale PDEs. To address this challenge, we propose a novel hierarchical neural operator that integrates improved Fourier layers with attention mechanisms, aiming to capture all details and handle them at various scales. These mechanisms complement each other in the frequency domain and encourage the model to solve multiscale problems. We perform experiments on dynamic spaces governed by forward and reverse problems of multiscale elliptic equations, Navier-Stokes equations and some other physical scenarios, and reach superior performance in existing PDE benchmarks, especially equations characterized by rapid coefficient variations.", "url": "https://arxiv.org/abs/2311.12902"}, {"metadata": {"arXiv": "2311.12906", "Date": "Tue, 21 Nov 2023 13:13:12 ", "Title": "Nonlinear System Identification of Swarm of UAVs Using Deep Learning Methods", "Authors": ["Saman Yazdannik", "Morteza Tayefi", "Mojtaba Farrokh"], "Categories": "cs.LG cs.SY"}, "abstract": "This study designs and evaluates multiple nonlinear system identification techniques for modeling the UAV swarm system in planar space. learning methods such as RNNs, CNNs, and Neural ODE are explored and compared. The objective is to forecast future swarm trajectories by accurately approximating the nonlinear dynamics of the swarm model. The modeling process is performed using both transient and steady-state data from swarm simulations. Results show that the combination of Neural ODE with a well-trained model using transient data is robust for varying initial conditions and outperforms other learning methods in accurately predicting swarm stability.", "url": "https://arxiv.org/abs/2311.12906"}, {"metadata": {"arXiv": "2311.12915", "Date": "Tue, 21 Nov 2023 17:57:12 ", "Title": "Neural-Integrated Meshfree (NIM) Method: A differentiable programming-based hybrid solver for computational mechanics", "Authors": ["Honghui Du", "QiZhi He"], "Categories": "cs.LG cs.CE"}, "abstract": "We present the neural-integrated meshfree (NIM) method, a differentiable programming-based hybrid meshfree approach within the field of computational mechanics. NIM seamlessly integrates traditional physics-based meshfree discretization techniques with deep learning architectures. It employs a hybrid approximation scheme, NeuroPU, to effectively represent the solution by combining continuous DNN representations with partition of unity (PU) basis functions associated with the underlying spatial discretization. This neural-numerical hybridization not only enhances the solution representation through functional space decomposition but also reduces both the size of DNN model and the need for spatial gradient computations based on automatic differentiation, leading to a significant improvement in training efficiency. Under the NIM framework, we propose two truly meshfree solvers: the strong form-based NIM (S-NIM) and the local variational form-based NIM (V-NIM). In the S-NIM solver, the strong-form governing equation is directly considered in the loss function, while the V-NIM solver employs a local Petrov-Galerkin approach that allows the construction of variational residuals based on arbitrary overlapping subdomains. This ensures both the satisfaction of underlying physics and the preservation of meshfree property. We perform extensive numerical experiments on both stationary and transient benchmark problems to assess the effectiveness of the proposed NIM methods in terms of accuracy, scalability, generalizability, and convergence properties. Moreover, comparative analysis with other physics-informed machine learning methods demonstrates that NIM, especially V-NIM, significantly enhances both accuracy and efficiency in end-to-end predictive capabilities.", "url": "https://arxiv.org/abs/2311.12915"}, {"metadata": {"arXiv": "2311.12997", "Date": "Tue, 21 Nov 2023 21:16:54 ", "Title": "How Capable Can a Transformer Become? A Study on Synthetic, Interpretable Tasks", "Authors": ["Rahul Ramesh", "Mikail Khona", "Robert P. Dick", "Hidenori Tanaka", "Ekdeep Singh Lubana"], "Categories": "cs.LG"}, "abstract": "Transformers trained on huge text corpora exhibit a remarkable set of capabilities, e.g., performing simple logical operations. Given the inherent compositional nature of language, one can expect the model to learn to compose these capabilities, potentially yielding a combinatorial explosion of what operations it can perform on an input. Motivated by the above, we aim to assess in this paper \"how capable can a transformer become?\". Specifically, we train autoregressive Transformer models on a data-generating process that involves compositions of a set of well-defined monolithic capabilities. Through a series of extensive and systematic experiments on this data-generating process, we show that: (1) autoregressive Transformers can learn compositional structures from the training data and generalize to exponentially or even combinatorially many functions; (2) composing functions by generating intermediate outputs is more effective at generalizing to unseen compositions, compared to generating no intermediate outputs; (3) the training data has a significant impact on the model's ability to compose unseen combinations of functions; and (4) the attention layers in the latter half of the model are critical to compositionality.", "url": "https://arxiv.org/abs/2311.12997"}, {"metadata": {"arXiv": "2311.13015", "Date": "Tue, 21 Nov 2023 21:44:28 ", "Title": "Fast and Interpretable Mortality Risk Scores for Critical Care Patients", "Authors": ["Chloe Qinyu Zhu", "Muhang Tian", "Lesia Semenova", "Jiachang Liu", "Jack Xu", "Joseph Scarpa", "Cynthia Rudin"], "Categories": "cs.LG cs.CY"}, "abstract": "Prediction of mortality in intensive care unit (ICU) patients is an important task in critical care medicine. Prior work in creating mortality risk models falls into two major categories: domain-expert-created scoring systems, and black box machine learning (ML) models. Both of these have disadvantages: black box models are unacceptable for use in hospitals, whereas manual creation of models (including hand-tuning of logistic regression parameters) relies on humans to perform high-dimensional constrained optimization, which leads to a loss in performance. In this work, we bridge the gap between accurate black box models and hand-tuned interpretable models. We build on modern interpretable ML techniques to design accurate and interpretable mortality risk scores. We leverage the largest existing public ICU monitoring datasets, namely the MIMIC III and eICU datasets. By evaluating risk across medical centers, we are able to study generalization across domains. In order to customize our risk score models, we develop a new algorithm, GroupFasterRisk, which has several important benefits: (1) it uses hard sparsity constraint, allowing users to directly control the number of features; (2) it incorporates group sparsity to allow more cohesive models; (3) it allows for monotonicity correction on models for including domain knowledge; (4) it produces many equally-good models at once, which allows domain experts to choose among them. GroupFasterRisk creates its risk scores within hours, even on the large datasets we study here. GroupFasterRisk's risk scores perform better than risk scores currently used in hospitals, and have similar prediction performance to black box ML models (despite being much sparser). Because GroupFasterRisk produces a variety of risk scores and handles constraints, it allows design flexibility, which is the key enabler of practical and trustworthy model creation.", "url": "https://arxiv.org/abs/2311.13015"}, {"metadata": {"arXiv": "2311.13022", "Date": "Tue, 21 Nov 2023 22:05:00 ", "Title": "Unsupervised Multimodal Surface Registration with Geometric Deep Learning", "Authors": ["Mohamed A. Suliman", "Logan Z. J. Williams", "Abdulah Fawaz", "and Emma C. Robinson"], "Categories": "cs.LG cs.CV"}, "abstract": "This paper introduces GeoMorph, a novel geometric deep-learning framework designed for image registration of cortical surfaces. The registration process consists of two main steps. First, independent feature extraction is performed on each input surface using graph convolutions, generating low-dimensional feature representations that capture important cortical surface characteristics. Subsequently, features are registered in a deep-discrete manner to optimize the overlap of common structures across surfaces by learning displacements of a set of control points. To ensure smooth and biologically plausible deformations, we implement regularization through a deep conditional random field implemented with a recurrent neural network. Experimental results demonstrate that GeoMorph surpasses existing deep-learning methods by achieving improved alignment with smoother deformations. Furthermore, GeoMorph exhibits competitive performance compared to classical frameworks. Such versatility and robustness suggest strong potential for various neuroscience applications.", "url": "https://arxiv.org/abs/2311.13022"}, {"metadata": {"arXiv": "2311.13036", "Date": "Tue, 21 Nov 2023 22:53:20 ", "Title": "Favour: FAst Variance Operator for Uncertainty Rating", "Authors": ["Thomas D. Ahle", "Sahar Karimi", "Peter Tak Peter Tang"], "Categories": "cs.LG stat.ML"}, "abstract": "Bayesian Neural Networks (BNN) have emerged as a crucial approach for interpreting ML predictions. By sampling from the posterior distribution, data scientists may estimate the uncertainty of an inference. Unfortunately many inference samples are often needed, the overhead of which greatly hinder BNN's wide adoption. To mitigate this, previous work proposed propagating the first and second moments of the posterior directly through the network. However, on its own this method is even slower than sampling, so the propagated variance needs to be approximated such as assuming independence between neural nodes. The resulting trade-off between quality and inference time did not match even plain Monte Carlo sampling. Our contribution is a more principled variance propagation framework based on \"spiked covariance matrices\", which smoothly interpolates between quality and inference time. This is made possible by a new fast algorithm for updating a diagonal-plus-low-rank matrix approximation under various operations. We tested our algorithm against sampling based MC Dropout and Variational Inference on a number of downstream uncertainty themed tasks, such as calibration and out-of-distribution testing. We find that Favour is as fast as performing 2-3 inference samples, while matching the performance of 10-100 samples. In summary, this work enables the use of BNN in the realm of performance critical tasks where they have previously been out of reach.", "url": "https://arxiv.org/abs/2311.13036"}, {"metadata": {"arXiv": "2311.13091", "Date": "Wed, 22 Nov 2023 01:43:57 ", "Title": "Stable Unlearnable Example: Enhancing the Robustness of Unlearnable Examples via Stable Error-Minimizing Noise", "Authors": ["Yixin Liu", "Kaidi Xu", "Xun Chen", "and Lichao Sun"], "Categories": "cs.LG cs.CR cs.CV", "Comments": ["14 pages", "11 figures", "13 tables"]}, "abstract": "The open source of large amounts of image data promotes the development of deep learning techniques. Along with this comes the privacy risk of these open-source image datasets being exploited by unauthorized third parties to train deep learning models for commercial or illegal purposes. To avoid the abuse of public data, a poisoning-based technique, the unlearnable example, is proposed to significantly degrade the generalization performance of models by adding a kind of imperceptible noise to the data. To further enhance its robustness against adversarial training, existing works leverage iterative adversarial training on both the defensive noise and the surrogate model. However, it still remains unknown whether the robustness of unlearnable examples primarily comes from the effect of enhancement in the surrogate model or the defensive noise. Observing that simply removing the adversarial noise on the training process of the defensive noise can improve the performance of robust unlearnable examples, we identify that solely the surrogate model's robustness contributes to the performance. Furthermore, we found a negative correlation exists between the robustness of defensive noise and the protection performance, indicating defensive noise's instability issue. Motivated by this, to further boost the robust unlearnable example, we introduce stable error-minimizing noise (SEM), which trains the defensive noise against random perturbation instead of the time-consuming adversarial perturbation to improve the stability of defensive noise. Through extensive experiments, we demonstrate that SEM achieves a new state-of-the-art performance on CIFAR-10, CIFAR-100, and ImageNet Subset in terms of both effectiveness and efficiency. The code is available at https://github.com/liuyixin-louis/Stable-Unlearnable-Example.", "url": "https://arxiv.org/abs/2311.13091"}, {"metadata": {"arXiv": "2311.13110", "Date": "Wed, 22 Nov 2023 02:23:32 ", "Title": "White-Box Transformers via Sparse Rate Reduction: Compression Is All There Is?", "Authors": ["Yaodong Yu", "Sam Buchanan", "Druv Pai", "Tianzhe Chu", "Ziyang Wu", "Shengbang Tong", "Hao Bai", "Yuexiang Zhai", "Benjamin D. Haeffele", "Yi Ma"], "Categories": "cs.LG cs.CL cs.CV", "Comments": ["This paper integrates the works arXiv:2306.01129 and arXiv:2308.16271", "as well as this under-review work: https://openreview.net/forum?id=PvyOYleymy into a complete story. In this paper", "we improve the writing and organization", "and also add conceptual", "empirical", "and theoretical improvements over the previous work"]}, "abstract": "In this paper, we contend that a natural objective of representation learning is to compress and transform the distribution of the data, say sets of tokens, towards a low-dimensional Gaussian mixture supported on incoherent subspaces. The goodness of such a representation can be evaluated by a principled measure, called sparse rate reduction, that simultaneously maximizes the intrinsic information gain and extrinsic sparsity of the learned representation. From this perspective, popular deep network architectures, including transformers, can be viewed as realizing iterative schemes to optimize this measure. Particularly, we derive a transformer block from alternating optimization on parts of this objective: the multi-head self-attention operator compresses the representation by implementing an approximate gradient descent step on the coding rate of the features, and the subsequent multi-layer perceptron sparsifies the features. This leads to a family of white-box transformer-like deep network architectures, named CRATE, which are mathematically fully interpretable. We show, by way of a novel connection between denoising and compression, that the inverse to the aforementioned compressive encoding can be realized by the same class of CRATE architectures. Thus, the so-derived white-box architectures are universal to both encoders and decoders. Experiments show that these networks, despite their simplicity, indeed learn to compress and sparsify representations of large-scale real-world image and text datasets, and achieve performance very close to highly engineered transformer-based models: ViT, MAE, DINO, BERT, and GPT2. We believe the proposed computational framework demonstrates great potential in bridging the gap between theory and practice of deep learning, from a unified perspective of data compression. Code is available at: https://ma-lab-berkeley.github.io/CRATE .", "url": "https://arxiv.org/abs/2311.13110"}, {"metadata": {"arXiv": "2311.13147", "Date": "Wed, 22 Nov 2023 04:18:23 ", "Title": "Optimal Transport with Cyclic Symmetry", "Authors": ["Shoichiro Takeda", "Yasunori Akagi", "Naoki Marumo", "Kenta Niwa"], "Categories": "cs.LG"}, "abstract": "We propose novel fast algorithms for optimal transport (OT) utilizing a cyclic symmetry structure of input data. Such OT with cyclic symmetry appears universally in various real-world examples: image processing, urban planning, and graph processing. Our main idea is to reduce OT to a small optimization problem that has significantly fewer variables by utilizing cyclic symmetry and various optimization techniques. On the basis of this reduction, our algorithms solve the small optimization problem instead of the original OT. As a result, our algorithms obtain the optimal solution and the objective function value of the original OT faster than solving the original OT directly. In this paper, our focus is on two crucial OT formulations: the linear programming OT (LOT) and the strongly convex-regularized OT, which includes the well-known entropy-regularized OT (EROT). Experiments show the effectiveness of our algorithms for LOT and EROT in synthetic/real-world data that has a strict/approximate cyclic symmetry structure. Through theoretical and experimental results, this paper successfully introduces the concept of symmetry into the OT research field for the first time.", "url": "https://arxiv.org/abs/2311.13147"}, {"metadata": {"arXiv": "2311.13159", "Date": "Wed, 22 Nov 2023 04:49:16 ", "Title": "Multi-Objective Optimization via Wasserstein-Fisher-Rao Gradient Flow", "Authors": ["Yinuo Ren", "Tesi Xiao", "Tanmay Gangwani", "Anshuka Rangi", "Holakou Rahmanian", "Lexing Ying", "Subhajit Sanyal"], "Categories": "cs.LG math.OC stat.ML"}, "abstract": "Multi-objective optimization (MOO) aims to optimize multiple, possibly conflicting objectives with widespread applications. We introduce a novel interacting particle method for MOO inspired by molecular dynamics simulations. Our approach combines overdamped Langevin and birth-death dynamics, incorporating a \"dominance potential\" to steer particles toward global Pareto optimality. In contrast to previous methods, our method is able to relocate dominated particles, making it particularly adept at managing Pareto fronts of complicated geometries. Our method is also theoretically grounded as a Wasserstein-Fisher-Rao gradient flow with convergence guarantees. Extensive experiments confirm that our approach outperforms state-of-the-art methods on challenging synthetic and real-world datasets.", "url": "https://arxiv.org/abs/2311.13159"}, {"metadata": {"arXiv": "2311.13163", "Date": "Wed, 22 Nov 2023 05:09:50 ", "Title": "Have Your Cake and Eat It Too: Toward Efficient and Accurate Split Federated Learning", "Authors": ["Dengke Yan and Ming Hu and Zeke Xia and Yanxin Yang and Jun Xia and Xiaofei Xie and Mingsong Chen"], "Categories": "cs.LG cs.DC"}, "abstract": "Due to its advantages in resource constraint scenarios, Split Federated Learning (SFL) is promising in AIoT systems. However, due to data heterogeneity and stragglers, SFL suffers from the challenges of low inference accuracy and low efficiency. To address these issues, this paper presents a novel SFL approach, named Sliding Split Federated Learning (S$^2$FL), which adopts an adaptive sliding model split strategy and a data balance-based training mechanism. By dynamically dispatching different model portions to AIoT devices according to their computing capability, S$^2$FL can alleviate the low training efficiency caused by stragglers. By combining features uploaded by devices with different data distributions to generate multiple larger batches with a uniform distribution for back-propagation, S$^2$FL can alleviate the performance degradation caused by data heterogeneity. Experimental results demonstrate that, compared to conventional SFL, S$^2$FL can achieve up to 16.5\\% inference accuracy improvement and 3.54X training acceleration.", "url": "https://arxiv.org/abs/2311.13163"}, {"metadata": {"arXiv": "2311.13166", "Date": "Wed, 22 Nov 2023 05:17:42 ", "Title": "AdaptiveFL: Adaptive Heterogeneous Federated Learning for Resource-Constrained AIoT Systems", "Authors": ["Chentao Jia and Ming Hu and Zekai Chen and Yanxin Yang and Xiaofei Xie and Yang Liu and Mingsong Chen"], "Categories": "cs.LG cs.DC"}, "abstract": "Although Federated Learning (FL) is promising to enable collaborative learning among Artificial Intelligence of Things (AIoT) devices, it suffers from the problem of low classification performance due to various heterogeneity factors (e.g., computing capacity, memory size) of devices and uncertain operating environments. To address these issues, this paper introduces an effective FL approach named AdaptiveFL based on a novel fine-grained width-wise model pruning strategy, which can generate various heterogeneous local models for heterogeneous AIoT devices. By using our proposed reinforcement learning-based device selection mechanism, AdaptiveFL can adaptively dispatch suitable heterogeneous models to corresponding AIoT devices on the fly based on their available resources for local training. Experimental results show that, compared to state-of-the-art methods, AdaptiveFL can achieve up to 16.83% inference improvements for both IID and non-IID scenarios.", "url": "https://arxiv.org/abs/2311.13166"}, {"metadata": {"arXiv": "2311.13174", "Date": "Wed, 22 Nov 2023 05:38:53 ", "Title": "SecureCut: Federated Gradient Boosting Decision Trees with Efficient Machine Unlearning", "Authors": ["Jian Zhang", "Bowen Li Jie Li", "Chentao Wu"], "Categories": "cs.LG cs.CR"}, "abstract": "In response to legislation mandating companies to honor the \\textit{right to be forgotten} by erasing user data, it has become imperative to enable data removal in Vertical Federated Learning (VFL) where multiple parties provide private features for model training. In VFL, data removal, i.e., \\textit{machine unlearning}, often requires removing specific features across all samples under privacy guarentee in federated learning. To address this challenge, we propose \\methname, a novel Gradient Boosting Decision Tree (GBDT) framework that effectively enables both \\textit{instance unlearning} and \\textit{feature unlearning} without the need for retraining from scratch. Leveraging a robust GBDT structure, we enable effective data deletion while reducing degradation of model performance. Extensive experimental results on popular datasets demonstrate that our method achieves superior model utility and forgetfulness compared to \\textit{state-of-the-art} methods. To our best knowledge, this is the first work that investigates machine unlearning in VFL scenarios.", "url": "https://arxiv.org/abs/2311.13174"}, {"metadata": {"arXiv": "2311.13184", "Date": "Wed, 22 Nov 2023 06:23:18 ", "Title": "AS-LLM: When Algorithm Selection Meets Large Language Model", "Authors": ["Xingyu Wu", "Yan Zhong", "Jibin Wu", "Kay Chen Tan"], "Categories": "cs.LG cs.CL"}, "abstract": "Algorithm selection aims to identify the most suitable algorithm for solving a specific problem before execution, which has become a critical process of the AutoML. Current mainstream algorithm selection techniques rely heavily on feature representations of various problems and employ the performance of each algorithm as supervised information. However, there is a significant research gap concerning the consideration of algorithm features. This gap is primarily attributed to the inherent complexity of algorithms, making it particularly challenging to find a universally effective feature extraction method that is applicable across a diverse range of algorithms. Unfortunately, neglecting this aspect undoubtedly impacts the accuracy of algorithm selection and indirectly necessitates an increased volume of problem data for training purposes. This paper takes a significant stride towards addressing this gap by proposing an approach that integrates algorithm representation into the algorithm selection process. Specifically, our proposed model employs distinct modules to extract representations of both problems and algorithms, where the algorithm representation leverages the capabilities of pre-trained LLMs in the realm of code comprehension. Following the extraction of embedding vectors for both algorithms and problems, the most suitable algorithm is determined through calculations of matching degrees. Our experiments not only validate the effectiveness of the proposed model but also showcase the performance of different embedded pre-trained LLMs, which suggests that the proposed algorithm selection framework holds the potential to serve as a baseline task for evaluating the code representation capabilities of LLMs.", "url": "https://arxiv.org/abs/2311.13184"}, {"metadata": {"arXiv": "2311.13244", "Date": "Wed, 22 Nov 2023 09:02:04 ", "Title": "Hard Label Black Box Node Injection Attack on Graph Neural Networks", "Authors": ["Yu Zhou", "Zihao Dong", "Guofeng Zhang", "Jingchen Tang"], "Categories": "cs.LG cs.CR cs.SI"}, "abstract": "While graph neural networks have achieved state-of-the-art performances in many real-world tasks including graph classification and node classification, recent works have demonstrated they are also extremely vulnerable to adversarial attacks. Most previous works have focused on attacking node classification networks under impractical white-box scenarios. In this work, we will propose a non-targeted Hard Label Black Box Node Injection Attack on Graph Neural Networks, which to the best of our knowledge, is the first of its kind. Under this setting, more real world tasks can be studied because our attack assumes no prior knowledge about (1): the model architecture of the GNN we are attacking; (2): the model's gradients; (3): the output logits of the target GNN model. Our attack is based on an existing edge perturbation attack, from which we restrict the optimization process to formulate a node injection attack. In the work, we will evaluate the performance of the attack using three datasets, COIL-DEL, IMDB-BINARY, and NCI1.", "url": "https://arxiv.org/abs/2311.13244"}, {"metadata": {"arXiv": "2311.13279", "Date": "Wed, 22 Nov 2023 09:55:20 ", "Title": "Comprehensive Evaluation of GNN Training Systems: A Data Management Perspective", "Authors": ["Hao Yuan", "Yajiong Liu", "Yanfeng Zhang", "Xin Ai", "Qiange Wang", "Chaoyi Chen", "Yu Gu", "Ge Yu"], "Categories": "cs.LG cs.DC", "Comments": ["12 pages", "17 figures"]}, "abstract": "Many Graph Neural Network (GNN) training systems have emerged recently to support efficient GNN training. Since GNNs embody complex data dependencies between training samples, the training of GNNs should address distinct challenges different from DNN training in data management, such as data partitioning, batch preparation for mini-batch training, and data transferring between CPUs and GPUs. These factors, which take up a large proportion of training time, make data management in GNN training more significant. This paper reviews GNN training from a data management perspective and provides a comprehensive analysis and evaluation of the representative approaches. We conduct extensive experiments on various benchmark datasets and show many interesting and valuable results. We also provide some practical tips learned from these experiments, which are helpful for designing GNN training systems in the future.", "url": "https://arxiv.org/abs/2311.13279"}, {"metadata": {"arXiv": "2311.13285", "Date": "Wed, 22 Nov 2023 10:08:33 ", "Title": "Improving performance of heart rate time series classification by grouping subjects", "Authors": ["Michael Beekhuizen (1)", "Arman Naseri (1 and 2)", "David Tax (1)", "Ivo van der Bilt (2)", "Marcel Reinders (1) ((1) Delft University of Technology", "(2) Haga Teaching Hospital)"], "Categories": "cs.LG eess.SP"}, "abstract": "Unlike the more commonly analyzed ECG or PPG data for activity classification, heart rate time series data is less detailed, often noisier and can contain missing data points. Using the BigIdeasLab_STEP dataset, which includes heart rate time series annotated with specific tasks performed by individuals, we sought to determine if general classification was achievable. Our analyses showed that the accuracy is sensitive to the choice of window/stride size. Moreover, we found variable classification performances between subjects due to differences in the physical structure of their hearts. Various techniques were used to minimize this variability. First of all, normalization proved to be a crucial step and significantly improved the performance. Secondly, grouping subjects and performing classification inside a group helped to improve performance and decrease inter-subject variability. Finally, we show that including handcrafted features as input to a deep learning (DL) network improves the classification performance further. Together, these findings indicate that heart rate time series can be utilized for classification tasks like predicting activity. However, normalization or grouping techniques need to be chosen carefully to minimize the issue of subject variability.", "url": "https://arxiv.org/abs/2311.13285"}, {"metadata": {"arXiv": "2311.13293", "Date": "Wed, 22 Nov 2023 10:22:59 ", "Title": "The Influence of Neural Networks on Hydropower Plant Management in Agriculture: Addressing Challenges and Exploring Untapped Opportunities", "Authors": ["C. Coelho", "M. Fernanda P. Costa and L.L. Ferr\\'as"], "Categories": "cs.LG math.OC", "MSC-class": "68T07", "ACM-class": "G.1.6; J.2; I.2.m"}, "abstract": "Hydropower plants are crucial for stable renewable energy and serve as vital water sources for sustainable agriculture. However, it is essential to assess the current water management practices associated with hydropower plant management software. A key concern is the potential conflict between electricity generation and agricultural water needs. Prioritising water for electricity generation can reduce irrigation availability in agriculture during crucial periods like droughts, impacting crop yields and regional food security. Coordination between electricity and agricultural water allocation is necessary to ensure optimal and environmentally sound practices. Neural networks have become valuable tools for hydropower plant management, but their black-box nature raises concerns about transparency in decision making. Additionally, current approaches often do not take advantage of their potential to create a system that effectively balances water allocation. This work is a call for attention and highlights the potential risks of deploying neural network-based hydropower plant management software without proper scrutiny and control. To address these concerns, we propose the adoption of the Agriculture Conscious Hydropower Plant Management framework, aiming to maximise electricity production while prioritising stable irrigation for agriculture. We also advocate reevaluating government-imposed minimum water guidelines for irrigation to ensure flexibility and effective water allocation. Additionally, we suggest a set of regulatory measures to promote model transparency and robustness, certifying software that makes conscious and intelligent water allocation decisions, ultimately safeguarding agriculture from undue strain during droughts.", "url": "https://arxiv.org/abs/2311.13293"}, {"metadata": {"arXiv": "2311.13321", "Date": "Wed, 22 Nov 2023 11:24:04 ", "Title": "Revisiting Supervision for Continual Representation Learning", "Authors": ["Daniel Marczak", "Sebastian Cygert", "Tomasz Trzci\\'nski", "Bart{\\l}omiej Twardowski"], "Categories": "cs.LG cs.CV"}, "abstract": "In the field of continual learning, models are designed to learn tasks one after the other. While most research has centered on supervised continual learning, recent studies have highlighted the strengths of self-supervised continual representation learning. The improved transferability of representations built with self-supervised methods is often associated with the role played by the multi-layer perceptron projector. In this work, we depart from this observation and reexamine the role of supervision in continual representation learning. We reckon that additional information, such as human annotations, should not deteriorate the quality of representations. Our findings show that supervised models when enhanced with a multi-layer perceptron head, can outperform self-supervised models in continual representation learning.", "url": "https://arxiv.org/abs/2311.13321"}, {"metadata": {"arXiv": "2311.13348", "Date": "Wed, 22 Nov 2023 12:25:02 ", "Title": "MergeSFL: Split Federated Learning with Feature Merging and Batch Size Regulation", "Authors": ["Yunming Liao", "Yang Xu", "Hongli Xu", "Lun Wang", "Zhiwei Yao", "Chunming Qiao"], "Categories": "cs.LG cs.DC cs.NI"}, "abstract": "Recently, federated learning (FL) has emerged as a popular technique for edge AI to mine valuable knowledge in edge computing (EC) systems. To mitigate the computing/communication burden on resource-constrained workers and protect model privacy, split federated learning (SFL) has been released by integrating both data and model parallelism. Despite resource limitations, SFL still faces two other critical challenges in EC, i.e., statistical heterogeneity and system heterogeneity. To address these challenges, we propose a novel SFL framework, termed MergeSFL, by incorporating feature merging and batch size regulation in SFL. Concretely, feature merging aims to merge the features from workers into a mixed feature sequence, which is approximately equivalent to the features derived from IID data and is employed to promote model accuracy. While batch size regulation aims to assign diverse and suitable batch sizes for heterogeneous workers to improve training efficiency. Moreover, MergeSFL explores to jointly optimize these two strategies upon their coupled relationship to better enhance the performance of SFL. Extensive experiments are conducted on a physical platform with 80 NVIDIA Jetson edge devices, and the experimental results show that MergeSFL can improve the final model accuracy by 5.82% to 26.22%, with a speedup by about 1.74x to 4.14x, compared to the baselines.", "url": "https://arxiv.org/abs/2311.13348"}, {"metadata": {"arXiv": "2311.13349", "Date": "Wed, 22 Nov 2023 12:34:51 ", "Title": "REDS: Resource-Efficient Deep Subnetworks for Dynamic Resource Constraints", "Authors": ["Francesco Corti", "Balz Maag", "Joachim Schauer", "Ulrich Pferschy", "Olga Saukh"], "Categories": "cs.LG"}, "abstract": "Deep models deployed on edge devices frequently encounter resource variability, which arises from fluctuating energy levels, timing constraints, or prioritization of other critical tasks within the system. State-of-the-art machine learning pipelines generate resource-agnostic models, not capable to adapt at runtime. In this work we introduce Resource-Efficient Deep Subnetworks (REDS) to tackle model adaptation to variable resources. In contrast to the state-of-the-art, REDS use structured sparsity constructively by exploiting permutation invariance of neurons, which allows for hardware-specific optimizations. Specifically, REDS achieve computational efficiency by (1) skipping sequential computational blocks identified by a novel iterative knapsack optimizer, and (2) leveraging simple math to re-arrange the order of operations in REDS computational graph to take advantage of the data cache. REDS support conventional deep networks frequently deployed on the edge and provide computational benefits even for small and simple networks. We evaluate REDS on six benchmark architectures trained on the Google Speech Commands, FMNIST and CIFAR10 datasets, and test on four off-the-shelf mobile and embedded hardware platforms. We provide a theoretical result and empirical evidence for REDS outstanding performance in terms of submodels' test set accuracy, and demonstrate an adaptation time in response to dynamic resource constraints of under 40$\\mu$s, utilizing a 2-layer fully-connected network on Arduino Nano 33 BLE Sense.", "url": "https://arxiv.org/abs/2311.13349"}, {"metadata": {"arXiv": "2311.13374", "Date": "Wed, 22 Nov 2023 13:17:55 ", "Title": "An Empirical Study of Uncertainty Estimation Techniques for Detecting Drift in Data Streams", "Authors": ["Anton Winter", "Nicolas Jourdan", "Tristan Wirth", "Volker Knauthe", "Arjan Kuijper"], "Categories": "cs.LG", "Comments": ["NeurIPS 2023: Workshop on Distribution Shifts"]}, "abstract": "In safety-critical domains such as autonomous driving and medical diagnosis, the reliability of machine learning models is crucial. One significant challenge to reliability is concept drift, which can cause model deterioration over time. Traditionally, drift detectors rely on true labels, which are often scarce and costly. This study conducts a comprehensive empirical evaluation of using uncertainty values as substitutes for error rates in detecting drifts, aiming to alleviate the reliance on labeled post-deployment data. We examine five uncertainty estimation methods in conjunction with the ADWIN detector across seven real-world datasets. Our results reveal that while the SWAG method exhibits superior calibration, the overall accuracy in detecting drifts is not notably impacted by the choice of uncertainty estimation method, with even the most basic method demonstrating competitive performance. These findings offer valuable insights into the practical applicability of uncertainty-based drift detection in real-world, safety-critical applications.", "url": "https://arxiv.org/abs/2311.13374"}, {"metadata": {"arXiv": "2311.13411", "Date": "Wed, 22 Nov 2023 14:16:20 ", "Title": "Bayesian inference of a new Mallows model for characterising symptom sequences applied in primary progressive aphasia", "Authors": ["Beatrice Taylor and Cameron Shand and Chris J. D. Hardy and Neil Oxtoby"], "Categories": "cs.LG", "Comments": ["Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2023", "December 10th", "2023", "New Orleans", "United States", "8 pages"]}, "abstract": "Machine learning models offer the potential to understand diverse datasets in a data-driven way, powering insights into individual disease experiences and ensuring equitable healthcare. In this study, we explore Bayesian inference for characterising symptom sequences, and the associated modelling challenges. We adapted the Mallows model to account for partial rankings and right-censored data, employing custom MCMC fitting. Our evaluation, encompassing synthetic data and a primary progressive aphasia dataset, highlights the model's efficacy in revealing mean orderings and estimating ranking variance. This holds the potential to enhance clinical comprehension of symptom occurrence. However, our work encounters limitations concerning model scalability and small dataset sizes.", "url": "https://arxiv.org/abs/2311.13411"}, {"metadata": {"arXiv": "2311.13445", "Date": "Wed, 22 Nov 2023 15:11:35 ", "Title": "Transfer Attacks and Defenses for Large Language Models on Coding Tasks", "Authors": ["Chi Zhang", "Zifan Wang", "Ravi Mangal", "Matt Fredrikson", "Limin Jia", "Corina Pasareanu"], "Categories": "cs.LG cs.CR"}, "abstract": "Modern large language models (LLMs), such as ChatGPT, have demonstrated impressive capabilities for coding tasks including writing and reasoning about code. They improve upon previous neural network models of code, such as code2seq or seq2seq, that already demonstrated competitive results when performing tasks such as code summarization and identifying code vulnerabilities. However, these previous code models were shown vulnerable to adversarial examples, i.e. small syntactic perturbations that do not change the program's semantics, such as the inclusion of \"dead code\" through false conditions or the addition of inconsequential print statements, designed to \"fool\" the models. LLMs can also be vulnerable to the same adversarial perturbations but a detailed study on this concern has been lacking so far. In this paper we aim to investigate the effect of adversarial perturbations on coding tasks with LLMs. In particular, we study the transferability of adversarial examples, generated through white-box attacks on smaller code models, to LLMs. Furthermore, to make the LLMs more robust against such adversaries without incurring the cost of retraining, we propose prompt-based defenses that involve modifying the prompt to include additional information such as examples of adversarially perturbed code and explicit instructions for reversing adversarial perturbations. Our experiments show that adversarial examples obtained with a smaller code model are indeed transferable, weakening the LLMs' performance. The proposed defenses show promise in improving the model's resilience, paving the way to more robust defensive solutions for LLMs in code-related applications.", "url": "https://arxiv.org/abs/2311.13445"}, {"metadata": {"arXiv": "2311.13447", "Date": "Wed, 22 Nov 2023 15:12:42 ", "Title": "Differentially Private Non-Convex Optimization under the KL Condition with Optimal Rates", "Authors": ["Michael Menart", "Enayat Ullah", "Raman Arora", "Raef Bassily", "Crist\\'obal Guzm\\'an"], "Categories": "cs.LG cs.CR math.OC stat.ML"}, "abstract": "We study private empirical risk minimization (ERM) problem for losses satisfying the $(\\gamma,\\kappa)$-Kurdyka-{\\L}ojasiewicz (KL) condition. The Polyak-{\\L}ojasiewicz (PL) condition is a special case of this condition when $\\kappa=2$. Specifically, we study this problem under the constraint of $\\rho$ zero-concentrated differential privacy (zCDP). When $\\kappa\\in[1,2]$ and the loss function is Lipschitz and smooth over a sufficiently large region, we provide a new algorithm based on variance reduced gradient descent that achieves the rate $\\tilde{O}\\big(\\big(\\frac{\\sqrt{d}}{n\\sqrt{\\rho}}\\big)^\\kappa\\big)$ on the excess empirical risk, where $n$ is the dataset size and $d$ is the dimension. We further show that this rate is nearly optimal. When $\\kappa \\geq 2$ and the loss is instead Lipschitz and weakly convex, we show it is possible to achieve the rate $\\tilde{O}\\big(\\big(\\frac{\\sqrt{d}}{n\\sqrt{\\rho}}\\big)^\\kappa\\big)$ with a private implementation of the proximal point method. When the KL parameters are unknown, we provide a novel modification and analysis of the noisy gradient descent algorithm and show that this algorithm achieves a rate of $\\tilde{O}\\big(\\big(\\frac{\\sqrt{d}}{n\\sqrt{\\rho}}\\big)^{\\frac{2\\kappa}{4-\\kappa}}\\big)$ adaptively, which is nearly optimal when $\\kappa = 2$. We further show that, without assuming the KL condition, the same gradient descent algorithm can achieve fast convergence to a stationary point when the gradient stays sufficiently large during the run of the algorithm. Specifically, we show that this algorithm can approximate stationary points of Lipschitz, smooth (and possibly nonconvex) objectives with rate as fast as $\\tilde{O}\\big(\\frac{\\sqrt{d}}{n\\sqrt{\\rho}}\\big)$ and never worse than $\\tilde{O}\\big(\\big(\\frac{\\sqrt{d}}{n\\sqrt{\\rho}}\\big)^{1/2}\\big)$. The latter rate matches the best known rate for methods that do not rely on variance reduction.", "url": "https://arxiv.org/abs/2311.13447"}, {"metadata": {"arXiv": "2311.13454", "Date": "Wed, 22 Nov 2023 15:20:12 ", "Title": "Explaining high-dimensional text classifiers", "Authors": ["Odelia Melamed", "Rich Caruana"], "Categories": "cs.LG cs.CR cs.NE stat.ML", "Comments": ["Accepted to \"XAI in Action\" workshop @ NeurIPS 2023"]}, "abstract": "Explainability has become a valuable tool in the last few years, helping humans better understand AI-guided decisions. However, the classic explainability tools are sometimes quite limited when considering high-dimensional inputs and neural network classifiers. We present a new explainability method using theoretically proven high-dimensional properties in neural network classifiers. We present two usages of it: 1) On the classical sentiment analysis task for the IMDB reviews dataset, and 2) our Malware-Detection task for our PowerShell scripts dataset.", "url": "https://arxiv.org/abs/2311.13454"}, {"metadata": {"arXiv": "2311.13459", "Date": "Wed, 22 Nov 2023 15:24:29 ", "Title": "The Tempered Hilbert Simplex Distance and Its Application To Non-linear Embeddings of TEMs", "Authors": ["Ehsan Amid", "Frank Nielsen", "Richard Nock", "Manfred K. Warmuth"], "Categories": "cs.LG stat.ML"}, "abstract": "Tempered Exponential Measures (TEMs) are a parametric generalization of the exponential family of distributions maximizing the tempered entropy function among positive measures subject to a probability normalization of their power densities. Calculus on TEMs relies on a deformed algebra of arithmetic operators induced by the deformed logarithms used to define the tempered entropy. In this work, we introduce three different parameterizations of finite discrete TEMs via Legendre functions of the negative tempered entropy function. In particular, we establish an isometry between such parameterizations in terms of a generalization of the Hilbert log cross-ratio simplex distance to a tempered Hilbert co-simplex distance. Similar to the Hilbert geometry, the tempered Hilbert distance is characterized as a $t$-symmetrization of the oriented tempered Funk distance. We motivate our construction by introducing the notion of $t$-lengths of smooth curves in a tautological Finsler manifold. We then demonstrate the properties of our generalized structure in different settings and numerically examine the quality of its differentiable approximations for optimization in machine learning settings.", "url": "https://arxiv.org/abs/2311.13459"}, {"metadata": {"arXiv": "2311.13460", "Date": "Wed, 22 Nov 2023 15:24:36 ", "Title": "Multi-Objective Bayesian Optimization with Active Preference Learning", "Authors": ["Ryota Ozaki", "Kazuki Ishikawa", "Youhei Kanzaki", "Shinya Suzuki", "Shion Takeno", "Ichiro Takeuchi", "Masayuki Karasuyama"], "Categories": "cs.LG stat.ML"}, "abstract": "There are a lot of real-world black-box optimization problems that need to optimize multiple criteria simultaneously. However, in a multi-objective optimization (MOO) problem, identifying the whole Pareto front requires the prohibitive search cost, while in many practical scenarios, the decision maker (DM) only needs a specific solution among the set of the Pareto optimal solutions. We propose a Bayesian optimization (BO) approach to identifying the most preferred solution in the MOO with expensive objective functions, in which a Bayesian preference model of the DM is adaptively estimated by an interactive manner based on the two types of supervisions called the pairwise preference and improvement request. To explore the most preferred solution, we define an acquisition function in which the uncertainty both in the objective functions and the DM preference is incorporated. Further, to minimize the interaction cost with the DM, we also propose an active learning strategy for the preference estimation. We empirically demonstrate the effectiveness of our proposed method through the benchmark function optimization and the hyper-parameter optimization problems for machine learning models.", "url": "https://arxiv.org/abs/2311.13460"}, {"metadata": {"arXiv": "2311.13469", "Date": "Wed, 22 Nov 2023 15:34:44 ", "Title": "Span-Based Optimal Sample Complexity for Average Reward MDPs", "Authors": ["Matthew Zurek", "Yudong Chen"], "Categories": "cs.LG cs.IT math.IT math.OC stat.ML", "Comments": ["19 pages"]}, "abstract": "We study the sample complexity of learning an $\\varepsilon$-optimal policy in an average-reward Markov decision process (MDP) under a generative model. We establish the complexity bound $\\widetilde{O}\\left(SA\\frac{H}{\\varepsilon^2} \\right)$, where $H$ is the span of the bias function of the optimal policy and $SA$ is the cardinality of the state-action space. Our result is the first that is minimax optimal (up to log factors) in all parameters $S,A,H$ and $\\varepsilon$, improving on existing work that either assumes uniformly bounded mixing times for all policies or has suboptimal dependence on the parameters. Our result is based on reducing the average-reward MDP to a discounted MDP. To establish the optimality of this reduction, we develop improved bounds for $\\gamma$-discounted MDPs, showing that $\\widetilde{O}\\left(SA\\frac{H}{(1-\\gamma)^2\\varepsilon^2} \\right)$ samples suffice to learn a $\\varepsilon$-optimal policy in weakly communicating MDPs under the regime that $\\gamma \\geq 1 - \\frac{1}{H}$, circumventing the well-known lower bound of $\\widetilde{\\Omega}\\left(SA\\frac{1}{(1-\\gamma)^3\\varepsilon^2} \\right)$ for general $\\gamma$-discounted MDPs. Our analysis develops upper bounds on certain instance-dependent variance parameters in terms of the span parameter. These bounds are tighter than those based on the mixing time or diameter of the MDP and may be of broader use.", "url": "https://arxiv.org/abs/2311.13469"}, {"metadata": {"arXiv": "2311.13471", "Date": "Wed, 22 Nov 2023 15:35:56 ", "Title": "Comparative Analysis of Linear Regression, Gaussian Elimination, and LU Decomposition for CT Real Estate Purchase Decisions", "Authors": ["Xilin Cheng"], "Categories": "cs.LG cs.CC cs.CE cs.NA math.NA", "Comments": ["5 pages", "7 figures"]}, "abstract": "This paper presents a comprehensive evaluation of three distinct computational algorithms applied to the decision-making process of real estate purchases. Specifically, we analyze the efficacy of Linear Regression from Scikit-learn library, Gaussian Elimination with partial pivoting, and LU Decomposition in predicting the advisability of buying a house in the State of Connecticut based on a set of financial and market-related parameters. The algorithms' performances were compared using a dataset encompassing town-specific details, yearly data, interest rates, and median sale ratios. Our results demonstrate significant differences in predictive accuracy, with Linear Regression and LU Decomposition providing the most reliable recommendations and Gaussian Elimination showing limitations in stability and performance. The study's findings emphasize the importance of algorithm selection in predictive analytic and offer insights into the practical applications of computational methods in real estate investment strategies. By evaluating model efficacy through metrics such as R-squared scores and Mean Squared Error, we provide a nuanced understanding of each method's strengths and weaknesses, contributing valuable knowledge to the fields of real estate analysis and predictive modeling.", "url": "https://arxiv.org/abs/2311.13471"}, {"metadata": {"arXiv": "2311.13507", "Date": "Wed, 22 Nov 2023 16:34:06 ", "Title": "Applying Dimensionality Reduction as Precursor to LSTM-CNN Models for Classifying Imagery and Motor Signals in ECoG-Based BCIs", "Authors": ["Soham Bafana"], "Categories": "cs.LG cs.HC eess.SP", "Comments": ["10 Pages", "12 Figures. The dataset used in this paper can be found here: https://osf.io/ksqv8/download", "from the Miller 2010 paper. All code used in this research can be found at https://github.com/bafanaS/dim-reduction-with-cnn-lstm.git"]}, "abstract": "Motor impairments, frequently caused by neurological incidents like strokes or traumatic brain injuries, present substantial obstacles in rehabilitation therapy. This research aims to elevate the field by optimizing motor imagery classification algorithms within Brain-Computer Interfaces (BCIs). By improving the efficiency of BCIs, we offer a novel approach that holds significant promise for enhancing motor rehabilitation outcomes. Utilizing unsupervised techniques for dimensionality reduction, namely Uniform Manifold Approximation and Projection (UMAP) coupled with K-Nearest Neighbors (KNN), we evaluate the necessity of employing supervised methods such as Long Short-Term Memory (LSTM) and Convolutional Neural Networks (CNNs) for classification tasks. Importantly, participants who exhibited high KNN scores following UMAP dimensionality reduction also achieved high accuracy in supervised deep learning (DL) models. Due to individualized model requirements and massive neural training data, dimensionality reduction becomes an effective preprocessing step that minimizes the need for extensive data labeling and supervised deep learning techniques. This approach has significant implications not only for targeted therapies in motor dysfunction but also for addressing regulatory, safety, and reliability concerns in the rapidly evolving BCI field.", "url": "https://arxiv.org/abs/2311.13507"}, {"metadata": {"arXiv": "2311.13583", "Date": "Wed, 22 Nov 2023 18:40:18 ", "Title": "Adaptive Sampling for Deep Learning via Efficient Nonparametric Proxies", "Authors": ["Shabnam Daghaghi", "Benjamin Coleman", "Benito Geordie", "Anshumali Shrivastava"], "Categories": "cs.LG"}, "abstract": "Data sampling is an effective method to improve the training speed of neural networks, with recent results demonstrating that it can even break the neural scaling laws. These results critically rely on high-quality scores to estimate the importance of an input to the network. We observe that there are two dominant strategies: static sampling, where the scores are determined before training, and dynamic sampling, where the scores can depend on the model weights. Static algorithms are computationally inexpensive but less effective than their dynamic counterparts, which can cause end-to-end slowdown due to their need to explicitly compute losses. To address this problem, we propose a novel sampling distribution based on nonparametric kernel regression that learns an effective importance score as the neural network trains. However, nonparametric regression models are too computationally expensive to accelerate end-to-end training. Therefore, we develop an efficient sketch-based approximation to the Nadaraya-Watson estimator. Using recent techniques from high-dimensional statistics and randomized algorithms, we prove that our Nadaraya-Watson sketch approximates the estimator with exponential convergence guarantees. Our sampling algorithm outperforms the baseline in terms of wall-clock time and accuracy on four datasets.", "url": "https://arxiv.org/abs/2311.13583"}, {"metadata": {"arXiv": "2311.13584", "Date": "Wed, 22 Nov 2023 18:40:45 ", "Title": "On diffusion-based generative models and their error bounds: The log-concave case with full convergence estimates", "Authors": ["Stefano Bruno", "Ying Zhang", "Dong-Young Lim", "\\\"Omer Deniz Akyildiz and Sotirios Sabanis"], "Categories": "cs.LG math.OC math.PR stat.ML"}, "abstract": "We provide full theoretical guarantees for the convergence behaviour of diffusion-based generative models under the assumption of strongly logconcave data distributions while our approximating class of functions used for score estimation is made of Lipschitz continuous functions. We demonstrate via a motivating example, sampling from a Gaussian distribution with unknown mean, the powerfulness of our approach. In this case, explicit estimates are provided for the associated optimization problem, i.e. score approximation, while these are combined with the corresponding sampling estimates. As a result, we obtain the best known upper bound estimates in terms of key quantities of interest, such as the dimension and rates of convergence, for the Wasserstein-2 distance between the data distribution (Gaussian with unknown mean) and our sampling algorithm. Beyond the motivating example and in order to allow for the use of a diverse range of stochastic optimizers, we present our results using an $L^2$-accurate score estimation assumption, which crucially is formed under an expectation with respect to the stochastic optimizer and our novel auxiliary process that uses only known information. This approach yields the best known convergence rate for our sampling algorithm.", "url": "https://arxiv.org/abs/2311.13584"}, {"metadata": {"arXiv": "2311.13589", "Date": "Wed, 22 Nov 2023 18:50:06 ", "Title": "Risk-sensitive Markov Decision Process and Learning under General Utility Functions", "Authors": ["Zhengqi Wu and Renyuan Xu"], "Categories": "cs.LG math.OC", "Comments": ["36 pages"]}, "abstract": "Reinforcement Learning (RL) has gained substantial attention across diverse application domains and theoretical investigations. Existing literature on RL theory largely focuses on risk-neutral settings where the decision-maker learns to maximize the expected cumulative reward. However, in practical scenarios such as portfolio management and e-commerce recommendations, decision-makers often persist in heterogeneous risk preferences subject to outcome uncertainties, which can not be well-captured by the risk-neural framework. Incorporating these preferences can be approached through utility theory, yet the development of risk-sensitive RL under general utility functions remains an open question for theoretical exploration. In this paper, we consider a scenario where the decision-maker seeks to optimize a general utility function of the cumulative reward in the framework of a Markov decision process (MDP). To facilitate the Dynamic Programming Principle and Bellman equation, we enlarge the state space with an additional dimension that accounts for the cumulative reward. We propose a discretized approximation scheme to the MDP under enlarged state space, which is tractable and key for algorithmic design. We then propose a modified value iteration algorithm that employs an epsilon-covering over the space of cumulative reward. When a simulator is accessible, our algorithm efficiently learns a near-optimal policy with guaranteed sample complexity. In the absence of a simulator, our algorithm, designed with an upper-confidence-bound exploration approach, identifies a near-optimal policy while ensuring a guaranteed regret bound. For both algorithms, we match the theoretical lower bounds for the risk-neutral setting.", "url": "https://arxiv.org/abs/2311.13589"}, {"metadata": {"arXiv": "2311.12880", "Date": "Mon, 20 Nov 2023 18:42:14 ", "Title": "Weak-Form Latent Space Dynamics Identification", "Authors": ["April Tran", "Xiaolong He", "Daniel A. Messenger", "Youngsoo Choi", "David M. Bortz"], "Categories": "eess.SY cs.CE cs.LG cs.NA cs.SY math.NA", "Comments": ["21 pages", "15 figures"]}, "abstract": "Recent work in data-driven modeling has demonstrated that a weak formulation of model equations enhances the noise robustness of a wide range of computational methods. In this paper, we demonstrate the power of the weak form to enhance the LaSDI (Latent Space Dynamics Identification) algorithm, a recently developed data-driven reduced order modeling technique. We introduce a weak form-based version WLaSDI (Weak-form Latent Space Dynamics Identification). WLaSDI first compresses data, then projects onto the test functions and learns the local latent space models. Notably, WLaSDI demonstrates significantly enhanced robustness to noise. With WLaSDI, the local latent space is obtained using weak-form equation learning techniques. Compared to the standard sparse identification of nonlinear dynamics (SINDy) used in LaSDI, the variance reduction of the weak form guarantees a robust and precise latent space recovery, hence allowing for a fast, robust, and accurate simulation. We demonstrate the efficacy of WLaSDI vs. LaSDI on several common benchmark examples including viscid and inviscid Burgers', radial advection, and heat conduction. For instance, in the case of 1D inviscid Burgers' simulations with the addition of up to 100% Gaussian white noise, the relative error remains consistently below 6% for WLaSDI, while it can exceed 10,000% for LaSDI. Similarly, for radial advection simulations, the relative errors stay below 15% for WLaSDI, in stark contrast to the potential errors of up to 10,000% with LaSDI. Moreover, speedups of several orders of magnitude can be obtained with WLaSDI. For example applying WLaSDI to 1D Burgers' yields a 140X speedup compared to the corresponding full order model. Python code to reproduce the results in this work is available at (https://github.com/MathBioCU/PyWSINDy_ODE) and (https://github.com/MathBioCU/PyWLaSDI).", "url": "https://arxiv.org/abs/2311.12880"}, {"metadata": {"arXiv": "2311.12854", "Date": "Mon, 23 Oct 2023 06:35:44 ", "Title": "Enhancing Robotic Manipulation: Harnessing the Power of Multi-Task Reinforcement Learning and Single Life Reinforcement Learning in Meta-World", "Authors": ["Ghadi Nehme", "Ishan Sabane", "Tejas Y. Deo"], "Categories": "cs.AI cs.RO"}, "abstract": "At present, robots typically require extensive training to successfully accomplish a single task. However, to truly enhance their usefulness in real-world scenarios, robots should possess the capability to perform multiple tasks effectively. To address this need, various multi-task reinforcement learning (RL) algorithms have been developed, including multi-task proximal policy optimization (PPO), multi-task trust region policy optimization (TRPO), and multi-task soft-actor critic (SAC). Nevertheless, these algorithms demonstrate optimal performance only when operating within an environment or observation space that exhibits a similar distribution. In reality, such conditions are often not the norm, as robots may encounter scenarios or observations that differ from those on which they were trained. Addressing this challenge, algorithms like Q-Weighted Adversarial Learning (QWALE) attempt to tackle the issue by training the base algorithm (generating prior data) solely for a particular task, rendering it unsuitable for generalization across tasks. So, the aim of this research project is to enable a robotic arm to successfully execute seven distinct tasks within the Meta World environment. To achieve this, a multi-task soft actor-critic (MT-SAC) is employed to train the robotic arm. Subsequently, the trained model will serve as a source of prior data for the single-life RL algorithm. The effectiveness of this MT-QWALE algorithm will be assessed by conducting tests on various target positions (novel positions). In the end, a comparison is provided between the trained MT-SAC and the MT-QWALE algorithm where the MT-QWALE performs better. An ablation study demonstrates that MT-QWALE successfully completes tasks with a slightly larger number of steps even after hiding the final goal position.", "url": "https://arxiv.org/abs/2311.12854"}, {"metadata": {"arXiv": "2311.12947", "Date": "Tue, 21 Nov 2023 19:21:49 ", "Title": "PINNs-Based Uncertainty Quantification for Transient Stability Analysis", "Authors": ["Ren Wang", "Ming Zhong", "Kaidi Xu", "Lola Gir\\'aldez S\\'anchez-Cort\\'es", "Ignacio de Cominges Guerra"], "Categories": "cs.AI cs.SY eess.SY"}, "abstract": "This paper addresses the challenge of transient stability in power systems with missing parameters and uncertainty propagation in swing equations. We introduce a novel application of Physics-Informed Neural Networks (PINNs), specifically an Ensemble of PINNs (E-PINNs), to estimate critical parameters like rotor angle and inertia coefficient with enhanced accuracy and reduced computational load. E-PINNs capitalize on the underlying physical principles of swing equations to provide a robust solution. Our approach not only facilitates efficient parameter estimation but also quantifies uncertainties, delivering probabilistic insights into the system behavior. The efficacy of E-PINNs is demonstrated through the analysis of $1$-bus and $2$-bus systems, highlighting the model's ability to handle parameter variability and data scarcity. The study advances the application of machine learning in power system stability, paving the way for reliable and computationally efficient transient stability analysis.", "url": "https://arxiv.org/abs/2311.12947"}, {"metadata": {"arXiv": "2311.12990", "Date": "Tue, 21 Nov 2023 20:52:04 ", "Title": "NERIF: GPT-4V for Automatic Scoring of Drawn Models", "Authors": ["Gyeong-Geon Lee", "and Xiaoming Zhai"], "Categories": "cs.AI"}, "abstract": "Scoring student-drawn models is time-consuming. Recently released GPT-4V provides a unique opportunity to advance scientific modeling practices by leveraging the powerful image processing capability. To test this ability specifically for automatic scoring, we developed a method NERIF (Notation-Enhanced Rubric Instruction for Few-shot Learning) employing instructional note and rubrics to prompt GPT-4V to score students' drawn models for science phenomena. We randomly selected a set of balanced data (N = 900) that includes student-drawn models for six modeling assessment tasks. Each model received a score from GPT-4V ranging at three levels: 'Beginning,' 'Developing,' or 'Proficient' according to scoring rubrics. GPT-4V scores were compared with human experts' scores to calculate scoring accuracy. Results show that GPT-4V's average scoring accuracy was mean =.51, SD = .037. Specifically, average scoring accuracy was .64 for the 'Beginning' class, .62 for the 'Developing' class, and .26 for the 'Proficient' class, indicating that more proficient models are more challenging to score. Further qualitative study reveals how GPT-4V retrieves information from image input, including problem context, example evaluations provided by human coders, and students' drawing models. We also uncovered how GPT-4V catches the characteristics of student-drawn models and narrates them in natural language. At last, we demonstrated how GPT-4V assigns scores to student-drawn models according to the given scoring rubric and instructional notes. Our findings suggest that the NERIF is an effective approach for employing GPT-4V to score drawn models. Even though there is space for GPT-4V to improve scoring accuracy, some mis-assigned scores seemed interpretable to experts. The results of this study show that utilizing GPT-4V for automatic scoring of student-drawn models is promising.", "url": "https://arxiv.org/abs/2311.12990"}, {"metadata": {"arXiv": "2311.12996", "Date": "Tue, 21 Nov 2023 21:05:21 ", "Title": "RLIF: Interactive Imitation Learning as Reinforcement Learning", "Authors": ["Jianlan Luo", "Perry Dong", "Yuexiang Zhai", "Yi Ma", "Sergey Levine"], "Categories": "cs.AI cs.RO"}, "abstract": "Although reinforcement learning methods offer a powerful framework for automatic skill acquisition, for practical learning-based control problems in domains such as robotics, imitation learning often provides a more convenient and accessible alternative. In particular, an interactive imitation learning method such as DAgger, which queries a near-optimal expert to intervene online to collect correction data for addressing the distributional shift challenges that afflict na\\\"ive behavioral cloning, can enjoy good performance both in theory and practice without requiring manually specified reward functions and other components of full reinforcement learning methods. In this paper, we explore how off-policy reinforcement learning can enable improved performance under assumptions that are similar but potentially even more practical than those of interactive imitation learning. Our proposed method uses reinforcement learning with user intervention signals themselves as rewards. This relaxes the assumption that intervening experts in interactive imitation learning should be near-optimal and enables the algorithm to learn behaviors that improve over the potential suboptimal human expert. We also provide a unified framework to analyze our RL method and DAgger; for which we present the asymptotic analysis of the suboptimal gap for both methods as well as the non-asymptotic sample complexity bound of our method. We then evaluate our method on challenging high-dimensional continuous control simulation benchmarks as well as real-world robotic vision-based manipulation tasks. The results show that it strongly outperforms DAgger-like approaches across the different tasks, especially when the intervening experts are suboptimal. Code and videos can be found on the project website: rlif-page.github.io", "url": "https://arxiv.org/abs/2311.12996"}, {"metadata": {"arXiv": "2311.13051", "Date": "Tue, 21 Nov 2023 23:23:16 ", "Title": "Latent Lab: Large Language Models for Knowledge Exploration", "Authors": ["Kevin Dunnell", "Trudy Painter", "Andrew Stoddard", "Andy Lippman"], "Categories": "cs.AI cs.HC", "Journal-ref": "International Conference on Computational Creativity, 2023, 417-421"}, "abstract": "This paper investigates the potential of AI models, particularly large language models (LLMs), to support knowledge exploration and augment human creativity during ideation. We present \"Latent Lab\" an interactive tool for discovering connections among MIT Media Lab research projects, emphasizing \"exploration\" over search. The work offers insights into collaborative AI systems by addressing the challenges of organizing, searching, and synthesizing content. In a user study, the tool's success was evaluated based on its ability to introduce users to an unfamiliar knowledge base, ultimately setting the groundwork for the ongoing advancement of human-AI knowledge exploration systems.", "url": "https://arxiv.org/abs/2311.13051"}, {"metadata": {"arXiv": "2311.13063", "Date": "Tue, 21 Nov 2023 23:53:27 ", "Title": "From Classification to Clinical Insights: Towards Analyzing and Reasoning About Mobile and Behavioral Health Data With Large Language Models", "Authors": ["Zachary Englhardt", "Chengqian Ma", "Margaret E. Morris", "Xuhai \"Orson\" Xu", "Chun-Cheng Chang", "Lianhui Qin", "Xin Liu", "Shwetak Patel", "Vikram Iyer"], "Categories": "cs.AI"}, "abstract": "Passively collected behavioral health data from ubiquitous sensors holds significant promise to provide mental health professionals insights from patient's daily lives; however, developing analysis tools to use this data in clinical practice requires addressing challenges of generalization across devices and weak or ambiguous correlations between the measured signals and an individual's mental health. To address these challenges, we take a novel approach that leverages large language models (LLMs) to synthesize clinically useful insights from multi-sensor data. We develop chain of thought prompting methods that use LLMs to generate reasoning about how trends in data such as step count and sleep relate to conditions like depression and anxiety. We first demonstrate binary depression classification with LLMs achieving accuracies of 61.1% which exceed the state of the art. While it is not robust for clinical use, this leads us to our key finding: even more impactful and valued than classification is a new human-AI collaboration approach in which clinician experts interactively query these tools and combine their domain expertise and context about the patient with AI generated reasoning to support clinical decision-making. We find models like GPT-4 correctly reference numerical data 75% of the time, and clinician participants express strong interest in using this approach to interpret self-tracking data.", "url": "https://arxiv.org/abs/2311.13063"}, {"metadata": {"arXiv": "2311.13090", "Date": "Wed, 22 Nov 2023 01:42:23 ", "Title": "On the Limitation of Diffusion Models for Synthesizing Training Datasets", "Authors": ["Shin'ya Yamaguchi and Takuma Fukuda"], "Categories": "cs.AI cs.CV", "Comments": ["NeurIPS 2023 SyntheticData4ML Workshop"]}, "abstract": "Synthetic samples from diffusion models are promising for leveraging in training discriminative models as replications of real training datasets. However, we found that the synthetic datasets degrade classification performance over real datasets even when using state-of-the-art diffusion models. This means that modern diffusion models do not perfectly represent the data distribution for the purpose of replicating datasets for training discriminative tasks. This paper investigates the gap between synthetic and real samples by analyzing the synthetic samples reconstructed from real samples through the diffusion and reverse process. By varying the time steps starting the reverse process in the reconstruction, we can control the trade-off between the information in the original real data and the information added by diffusion models. Through assessing the reconstructed samples and trained models, we found that the synthetic data are concentrated in modes of the training data distribution as the reverse step increases, and thus, they are difficult to cover the outer edges of the distribution. Our findings imply that modern diffusion models are insufficient to replicate training data distribution perfectly, and there is room for the improvement of generative modeling in the replication of training datasets.", "url": "https://arxiv.org/abs/2311.13090"}, {"metadata": {"arXiv": "2311.13148", "Date": "Wed, 22 Nov 2023 04:21:47 ", "Title": "Building the Future of Responsible AI: A Pattern-Oriented Reference Architecture for Designing Large Language Model based Agents", "Authors": ["Qinghua Lu", "Liming Zhu", "Xiwei Xu", "Zhenchang Xing", "Stefan Harrer", "Jon Whittle"], "Categories": "cs.AI cs.SE"}, "abstract": "Large language models (LLMs) have been widely recognized as transformative technology due to their capabilities to understand and generate natural language text, including plans with some limited reasoning capabilities. LLM-based agents derive their autonomy from the capabilities of LLMs, which enable them to autonomously break down the given goal into a set of manageable tasks and orchestrate the task execution to fulfill the goal. Despite the huge efforts put into building LLM-based autonomous agents, the architecture design of the agents has not yet been systematically explored. Also, while there are significant benefits of using autonomous agents for planning and execution, there are serious considerations regarding responsible AI related software quality attributes, such as security and accountability. Therefore, this paper presents a pattern-oriented reference architecture that serves as architecture design guidelines and enables responsible-AI-by-design when designing LLM-based autonomous agents. We evaluate the completeness and utility of the proposed reference architecture by mapping it to the architecture of two real-world agents.", "url": "https://arxiv.org/abs/2311.13148"}, {"metadata": {"arXiv": "2311.13160", "Date": "Wed, 22 Nov 2023 05:04:20 ", "Title": "Large Language Models in Education: Vision and Opportunities", "Authors": ["Wensheng Gan", "Zhenlian Qi", "Jiayang Wu", "Jerry Chun-Wei Lin"], "Categories": "cs.AI", "Comments": ["IEEE BigData 2023. 10 pages"]}, "abstract": "With the rapid development of artificial intelligence technology, large language models (LLMs) have become a hot research topic. Education plays an important role in human social development and progress. Traditional education faces challenges such as individual student differences, insufficient allocation of teaching resources, and assessment of teaching effectiveness. Therefore, the applications of LLMs in the field of digital/smart education have broad prospects. The research on educational large models (EduLLMs) is constantly evolving, providing new methods and approaches to achieve personalized learning, intelligent tutoring, and educational assessment goals, thereby improving the quality of education and the learning experience. This article aims to investigate and summarize the application of LLMs in smart education. It first introduces the research background and motivation of LLMs and explains the essence of LLMs. It then discusses the relationship between digital education and EduLLMs and summarizes the current research status of educational large models. The main contributions are the systematic summary and vision of the research background, motivation, and application of large models for education (LLM4Edu). By reviewing existing research, this article provides guidance and insights for educators, researchers, and policy-makers to gain a deep understanding of the potential and challenges of LLM4Edu. It further provides guidance for further advancing the development and application of LLM4Edu, while still facing technical, ethical, and practical challenges requiring further research and exploration.", "url": "https://arxiv.org/abs/2311.13160"}, {"metadata": {"arXiv": "2311.13165", "Date": "Wed, 22 Nov 2023 05:15:12 ", "Title": "Multimodal Large Language Models: A Survey", "Authors": ["Jiayang Wu", "Wensheng Gan", "Zefeng Chen", "Shicheng Wan", "Philip S. Yu"], "Categories": "cs.AI", "Comments": ["IEEE BigData 2023. 10 pages"]}, "abstract": "The exploration of multimodal language models integrates multiple data types, such as images, text, language, audio, and other heterogeneity. While the latest large language models excel in text-based tasks, they often struggle to understand and process other data types. Multimodal models address this limitation by combining various modalities, enabling a more comprehensive understanding of diverse data. This paper begins by defining the concept of multimodal and examining the historical development of multimodal algorithms. Furthermore, we introduce a range of multimodal products, focusing on the efforts of major technology companies. A practical guide is provided, offering insights into the technical aspects of multimodal models. Moreover, we present a compilation of the latest algorithms and commonly used datasets, providing researchers with valuable resources for experimentation and evaluation. Lastly, we explore the applications of multimodal models and discuss the challenges associated with their development. By addressing these aspects, this paper aims to facilitate a deeper understanding of multimodal models and their potential in various domains.", "url": "https://arxiv.org/abs/2311.13165"}, {"metadata": {"arXiv": "2311.13206", "Date": "Wed, 22 Nov 2023 07:33:43 ", "Title": "Breast Cancer classification by adaptive weighted average ensemble of previously trained models", "Authors": ["Mosab S. M. Farea", "zhe chen"], "Categories": "cs.AI", "Comments": ["12 pages article"]}, "abstract": "Breast cancer is a serious disease that inflicts millions of people each year, and the number of cases is increasing. Early detection is the best way to reduce the impact of the disease. Researchers have developed many techniques to detect breast cancer, including the use of histopathology images in CAD systems. This research proposes a technique that combine already fully trained model using adaptive average ensemble, this is different from the literature which uses average ensemble before training and the average ensemble is trained simultaneously. Our approach is different because it used adaptive average ensemble after training which has increased the performance of evaluation metrics. It averages the outputs of every trained model, and every model will have weight according to its accuracy. The accuracy in the adaptive weighted ensemble model has achieved 98% where the accuracy has increased by 1 percent which is better than the best participating model in the ensemble which was 97%. Also, it decreased the numbers of false positive and false negative and enhanced the performance metrics.", "url": "https://arxiv.org/abs/2311.13206"}, {"metadata": {"arXiv": "2311.13213", "Date": "Wed, 22 Nov 2023 07:58:46 ", "Title": "Artificial Intelligence in the Service of Entrepreneurial Finance: Knowledge Structure and the Foundational Algorithmic Paradigm", "Authors": ["Robert Kudeli\\'c and Tamara \\v{S}maguc and Sherry Robinson"], "Categories": "cs.AI"}, "abstract": "While the application of Artificial Intelligence in Finance has a long tradition, its potential in Entrepreneurship has been intensively explored only recently. In this context, Entrepreneurial Finance is a particularly fertile ground for future Artificial Intelligence proliferation. To support the latter, the study provides a bibliometric review of Artificial Intelligence applications in (1) entrepreneurial finance literature, and (2) corporate finance literature with implications for Entrepreneurship. Rigorous search and screening procedures of the scientific database Web of Science Core Collection resulted in the identification of 1890 relevant journal articles subjected to analysis. The bibliometric analysis gives a rich insight into the knowledge field's conceptual, intellectual, and social structure, indicating nascent and underdeveloped research directions. As far as we were able to identify, this is the first study to map and bibliometrically analyze the academic field concerning the relationship between Artificial Intelligence, Entrepreneurship, and Finance, and the first review that deals with Artificial Intelligence methods in Entrepreneurship. According to the results, Artificial Neural Network, Deep Neural Network and Support Vector Machine are highly represented in almost all identified topic niches. At the same time, applying Topic Modeling, Fuzzy Neural Network and Growing Hierarchical Self-organizing Map is quite rare. As an element of the research, and before final remarks, the article deals as well with a discussion of certain gaps in the relationship between Computer Science and Economics. These gaps do represent problems in the application of Artificial Intelligence in Economic Science. As a way to at least in part remedy this situation, the foundational paradigm and the bespoke demonstration of the Monte Carlo randomized algorithm are presented.", "url": "https://arxiv.org/abs/2311.13213"}, {"metadata": {"arXiv": "2311.13262", "Date": "Wed, 22 Nov 2023 09:27:08 ", "Title": "The Rise of Creative Machines: Exploring the Impact of Generative AI", "Authors": ["Saad Shaikh", "Rajat bendre", "Sakshi Mhaske"], "Categories": "cs.AI", "Comments": ["The impact of generative AI on research", "product creation", "ethical concerns etc is examined in this six-page article. Figures 1", "2", "and 3", "which are essential to the analysis", "are included in the discussion along with opportunities", "hazards", "and ethical considerations"], "ACM-class": "I.2.7"}, "abstract": "This study looks at how generative artificial intelligence (AI) can revolutionize marketing, product development, and research. It discusses the latest developments in the field, easy-to-use resources, and moral and social hazards. In addition to addressing mitigating techniques for issues like prejudice and disinformation, the debate emphasizes the significance of responsible development through continual stakeholder communication and ethical principles.", "url": "https://arxiv.org/abs/2311.13262"}, {"metadata": {"arXiv": "2311.13286", "Date": "Wed, 22 Nov 2023 10:09:06 ", "Title": "Algorithmic Transparency and Manipulation", "Authors": ["Michael Klenk"], "Categories": "cs.AI", "DOI": "10.1007/s13347-023-00678-9"}, "abstract": "A series of recent papers raises worries about the manipulative potential of algorithmic transparency. But while the concern is apt and relevant, it is based on a fraught understanding of manipulation. Therefore, this paper draws attention to the indifference view of manipulation, which explains better than the vulnerability view why algorithmic transparency has manipulative potential. The paper also raises pertinent research questions for future studies of manipulation in the context of algorithmic transparency.", "url": "https://arxiv.org/abs/2311.13286"}, {"metadata": {"arXiv": "2311.13335", "Date": "Wed, 22 Nov 2023 11:55:41 ", "Title": "Quantum learning and essential cognition under the traction of meta-characteristics in an open world", "Authors": ["Jin Wang", "Changlin Song"], "Categories": "cs.AI cs.CV", "Comments": ["8 pages,5 pages"]}, "abstract": "Artificial intelligence has made significant progress in the Close World problem, being able to accurately recognize old knowledge through training and classification. However, AI faces significant challenges in the Open World problem, as it involves a new and unknown exploration journey. AI is not inherently proactive in exploration, and its challenge lies in not knowing how to approach and adapt to the unknown world. How do humans acquire knowledge of the unknown world. Humans identify new knowledge through intrinsic cognition. In the process of recognizing new colors, the cognitive cues are different from known color features and involve hue, saturation, brightness, and other characteristics. When AI encounters objects with different features in the new world, it faces another challenge: where are the distinguishing features between influential features of new and old objects? AI often mistakes a new world's brown bear for a known dog because it has not learned the differences in feature distributions between knowledge systems. This is because things in the new and old worlds have different units and dimensions for their features. This paper proposes an open-world model and elemental feature system that focuses on fundamentally recognizing the distribution differences in objective features between the new and old worlds. The quantum tunneling effect of learning ability in the new and old worlds is realized through the tractive force of meta-characteristic. The outstanding performance of the model system in learning new knowledge (using pedestrian re-identification datasets as an example) demonstrates that AI has acquired the ability to recognize the new world with an accuracy of $96.71\\%$ at most and has gained the capability to explore new knowledge, similar to humans.", "url": "https://arxiv.org/abs/2311.13335"}, {"metadata": {"arXiv": "2311.13361", "Date": "Wed, 22 Nov 2023 12:55:02 ", "Title": "Applying Large Language Models to Power Systems: Potential Security Threats", "Authors": ["Jiaqi Ruan", "Gaoqi Liang", "Huan Zhao", "Guolong Liu", "Jing Qiu", "Junhua Zhao", "Zhao Xu", "Fushuan Wen", "Zhao Yang Dong"], "Categories": "cs.AI cs.HC cs.SY eess.SY"}, "abstract": "Applying large language models (LLMs) to power systems presents a promising avenue for enhancing decision-making and operational efficiency. However, this action may also incur potential security threats, which have not been fully recognized so far. To this end, this letter analyzes potential threats incurred by applying LLMs to power systems, emphasizing the need for urgent research and development of countermeasures.", "url": "https://arxiv.org/abs/2311.13361"}, {"metadata": {"arXiv": "2311.13373", "Date": "Wed, 22 Nov 2023 13:15:42 ", "Title": "Large Language Model is a Good Policy Teacher for Training Reinforcement Learning Agents", "Authors": ["Zihao Zhou", "Bin Hu", "Pu Zhang", "Chenyang Zhao", "Bin Liu"], "Categories": "cs.AI", "Comments": ["9 pages"]}, "abstract": "Recent studies have shown that Large Language Models (LLMs) can be utilized for solving complex sequential decision-making tasks by providing high-level instructions. However, LLM-based agents face limitations in real-time dynamic environments due to their lack of specialization in solving specific target problems. Moreover, the deployment of such LLM-based agents is both costly and time-consuming in practical scenarios. In this paper, we introduce a novel framework that addresses these challenges by training a smaller scale specialized student agent using instructions from an LLM-based teacher agent. By leveraging guided actions provided by the teachers, the prior knowledge of the LLM is distilled into the local student model. Consequently, the student agent can be trained with significantly less data. Furthermore, subsequent training with environment feedback empowers the student agents to surpass the capabilities of their teachers. We conducted experiments on three challenging MiniGrid environments to evaluate the effectiveness of our framework. The results demonstrate that our approach enhances sample efficiency and achieves superior performance compared to baseline methods.", "url": "https://arxiv.org/abs/2311.13373"}, {"metadata": {"arXiv": "2311.13379", "Date": "Wed, 22 Nov 2023 13:19:45 ", "Title": "Deriving Comprehensible Theories from Probabilistic Circuits", "Authors": ["Sieben Bocklandt", "Wannes Meert", "Koen Vanderstraeten", "Wouter Pijpops", "Kurt Jaspers"], "Categories": "cs.AI", "Comments": ["10 pages; 3 figures"]}, "abstract": "The field of Explainable AI (XAI) is seeking to shed light on the inner workings of complex AI models and uncover the rationale behind their decisions. One of the models gaining attention are probabilistic circuits (PCs), which are a general and unified framework for tractable probabilistic models that support efficient computation of various probabilistic queries. Probabilistic circuits guarantee inference that is polynomial in the size of the circuit. In this paper, we improve the explainability of probabilistic circuits by computing a comprehensible, readable logical theory that covers the high-density regions generated by a PC. To achieve this, pruning approaches based on generative significance are used in a new method called PUTPUT (Probabilistic circuit Understanding Through Pruning Underlying logical Theories). The method is applied to a real world use case where music playlists are automatically generated and expressed as readable (database) queries. Evaluation shows that this approach can effectively produce a comprehensible logical theory that describes the high-density regions of a PC and outperforms state of the art methods when exploring the performance-comprehensibility trade-off.", "url": "https://arxiv.org/abs/2311.13379"}, {"metadata": {"arXiv": "2311.13455", "Date": "Wed, 22 Nov 2023 15:22:04 ", "Title": "Generation of Explanations for Logic Reasoning", "Authors": ["Yanyi Pu"], "Categories": "cs.AI cs.CL", "Comments": ["78 Pages", "16 Figures", "Thesis Presentation is available at https://drive.google.com/file/d/1wLIBsjfLvO11PjCS6qx4Y9UgRBUfq3wQ/view?usp=sharing"]}, "abstract": "This thesis delves into a fortiori arguments in deductive reasoning, underscoring their relevance in various domains such as law, philosophy, and artificial intelligence. The research is centred on employing GPT-3.5-turbo to automate the analysis of these arguments, with a focus on understanding intricate reasoning processes, generating clear and coherent explanations, and creating novel arguments. The methodology encompasses a series of tasks including detailed reasoning, interpretation, and the augmentation of a fortiori arguments. It involves meticulously identifying these arguments in diverse contexts, differentiating comparative elements, and categorizing them based on their logical structure. Extensive experiments reveals the challenges encountered by GPT-3.5-turbo in accurately detecting and classifying a fortiori arguments. Nevertheless, the model demonstrates a performance that rivals specialized models, particularly in extracting key components and interpreting underlying properties. The integration of external information into the model's processing significantly elevates the quality of the generated explanations. Additionally, the model exhibits a noteworthy capability in augmenting arguments, thus contributing to the enrichment of the data set. Despite facing certain limitations, this thesis makes significant contributions to the fields of artificial intelligence and logical reasoning. It introduces novel methodologies, establishes a rigorous evaluation framework, and provides deep insights that set the stage for future advancements in automated logical reasoning. The findings and methodologies presented herein not only underscore the potential of AI in complex reasoning tasks but also highlight areas for future research and development.", "url": "https://arxiv.org/abs/2311.13455"}, {"metadata": {"arXiv": "2311.13577", "Date": "Wed, 22 Nov 2023 18:32:03 ", "Title": "Physical Reasoning and Object Planning for Household Embodied Agents", "Authors": ["Ayush Agrawal", "Raghav Prabhakar", "Anirudh Goyal", "Dianbo Liu"], "Categories": "cs.AI", "Comments": ["Total: 32 pages ( 16 pages main content", "11 Figures)"]}, "abstract": "In this study, we explore the sophisticated domain of task planning for robust household embodied agents, with a particular emphasis on the intricate task of selecting substitute objects. We introduce the CommonSense Object Affordance Task (COAT), a novel framework designed to analyze reasoning capabilities in commonsense scenarios. This approach is centered on understanding how these agents can effectively identify and utilize alternative objects when executing household tasks, thereby offering insights into the complexities of practical decision-making in real-world environments.Drawing inspiration from human decision-making, we explore how large language models tackle this challenge through three meticulously crafted commonsense question-and-answer datasets, featuring refined rules and human annotations. Our evaluation of state-of-the-art language models on these datasets sheds light on three pivotal considerations: 1) aligning an object's inherent utility with the task at hand, 2) navigating contextual dependencies (societal norms, safety, appropriateness, and efficiency), and 3) accounting for the current physical state of the object. To maintain accessibility, we introduce five abstract variables reflecting an object's physical condition, modulated by human insights to simulate diverse household scenarios. Our contributions include insightful Object-Utility mappings addressing the first consideration and two extensive QA datasets (15k and 130k questions) probing the intricacies of contextual dependencies and object states. The datasets, along with our findings, are accessible at: \\url{https://github.com/com-phy-affordance/COAT}. This research not only advances our understanding of physical commonsense reasoning in language models but also paves the way for future improvements in household agent intelligence.", "url": "https://arxiv.org/abs/2311.13577"}, {"metadata": {"arXiv": "2311.12799", "Date": "Sat, 02 Sep 2023 03:22:39 ", "Title": "A Fine-Grained Image Description Generation Method Based on Joint Objectives", "Authors": ["Yifan Zhang and Chunzhen Lin and Donglin Cao and Dazhen Lin"], "Categories": "cs.CV cs.AI"}, "abstract": "The goal of fine-grained image description generation techniques is to learn detailed information from images and simulate human-like descriptions that provide coherent and comprehensive textual details about the image content. Currently, most of these methods face two main challenges: description repetition and omission. Moreover, the existing evaluation metrics cannot clearly reflect the performance of models on these two issues. To address these challenges, we propose an innovative Fine-grained Image Description Generation model based on Joint Objectives. Furthermore, we introduce new object-based evaluation metrics to more intuitively assess the model's performance in handling description repetition and omission. This novel approach combines visual features at both the image level and object level to maximize their advantages and incorporates an object penalty mechanism to reduce description repetition. Experimental results demonstrate that our proposed method significantly improves the CIDEr evaluation metric, indicating its excellent performance in addressing description repetition and omission issues.", "url": "https://arxiv.org/abs/2311.12799"}, {"metadata": {"arXiv": "2311.12800", "Date": "Thu, 07 Sep 2023 10:54:56 ", "Title": "Understanding Data Augmentation from a Robustness Perspective", "Authors": ["Zhendong Liu", "Jie Zhang", "Qiangqiang He", "Chongjun Wang"], "Categories": "cs.CV cs.AI", "Comments": ["Not published yet. arXiv admin note: text overlap with arXiv:2212.04059"]}, "abstract": "In the realm of visual recognition, data augmentation stands out as a pivotal technique to amplify model robustness. Yet, a considerable number of existing methodologies lean heavily on heuristic foundations, rendering their intrinsic mechanisms ambiguous. This manuscript takes both a theoretical and empirical approach to understanding the phenomenon. Theoretically, we frame the discourse around data augmentation within game theory's constructs. Venturing deeper, our empirical evaluations dissect the intricate mechanisms of emblematic data augmentation strategies, illuminating that these techniques primarily stimulate mid- and high-order game interactions. Beyond the foundational exploration, our experiments span multiple datasets and diverse augmentation techniques, underscoring the universal applicability of our findings. Recognizing the vast array of robustness metrics with intricate correlations, we unveil a streamlined proxy. This proxy not only simplifies robustness assessment but also offers invaluable insights, shedding light on the inherent dynamics of model game interactions and their relation to overarching system robustness. These insights provide a novel lens through which we can re-evaluate model safety and robustness in visual recognition tasks.", "url": "https://arxiv.org/abs/2311.12800"}, {"metadata": {"arXiv": "2311.12801", "Date": "Wed, 13 Sep 2023 22:44:04 ", "Title": "End-to-end Phase Field Model Discovery Combining Experimentation, Crowdsourcing, Simulation and Learning", "Authors": ["Md Nasim", "Anter El-Azab", "Xinghang Zhang", "Yexiang Xue"], "Categories": "cs.CV cs.AI"}, "abstract": "The availability of tera-byte scale experiment data calls for AI driven approaches which automatically discover scientific models from data. Nonetheless, significant challenges present in AI-driven scientific discovery: (i) The annotation of large scale datasets requires fundamental re-thinking in developing scalable crowdsourcing tools. (ii) The learning of scientific models from data calls for innovations beyond black-box neural nets. (iii) Novel visualization and diagnosis tools are needed for the collaboration of experimental and theoretical physicists, and computer scientists. We present Phase-Field-Lab platform for end-to-end phase field model discovery, which automatically discovers phase field physics models from experiment data, integrating experimentation, crowdsourcing, simulation and learning. Phase-Field-Lab combines (i) a streamlined annotation tool which reduces the annotation time (by ~50-75%), while increasing annotation accuracy compared to baseline; (ii) an end-to-end neural model which automatically learns phase field models from data by embedding phase field simulation and existing domain knowledge into learning; and (iii) novel interfaces and visualizations to integrate our platform into the scientific discovery cycle of domain scientists. Our platform is deployed in the analysis of nano-structure evolution in materials under extreme conditions (high temperature and irradiation). Our approach reveals new properties of nano-void defects, which otherwise cannot be detected via manual analysis.", "url": "https://arxiv.org/abs/2311.12801"}, {"metadata": {"arXiv": "2311.12805", "Date": "Fri, 15 Sep 2023 07:45:26 ", "Title": "DeepCompass: AI-driven Location-Orientation Synchronization for Navigating Platforms", "Authors": ["Jihun Lee", "SP Choi", "Bumsoo Kang", "Hyekyoung Seok", "Hyoungseok Ahn", "Sanghee Jung"], "Categories": "cs.CV cs.AI", "Comments": ["7page with 3 supplemental pages"]}, "abstract": "In current navigating platforms, the user's orientation is typically estimated based on the difference between two consecutive locations. In other words, the orientation cannot be identified until the second location is taken. This asynchronous location-orientation identification often leads to our real-life question: Why does my navigator tell the wrong direction of my car at the beginning? We propose DeepCompass to identify the user's orientation by bridging the gap between the street-view and the user-view images. First, we explore suitable model architectures and design corresponding input configuration. Second, we demonstrate artificial transformation techniques (e.g., style transfer and road segmentation) to minimize the disparity between the street-view and the user's real-time experience. We evaluate DeepCompass with extensive evaluation in various driving conditions. DeepCompass does not require additional hardware and is also not susceptible to external interference, in contrast to magnetometer-based navigator. This highlights the potential of DeepCompass as an add-on to existing sensor-based orientation detection methods.", "url": "https://arxiv.org/abs/2311.12805"}, {"metadata": {"arXiv": "2311.12815", "Date": "Sun, 24 Sep 2023 02:57:56 ", "Title": "Proposing an intelligent mesh smoothing method with graph neural networks", "Authors": ["Zhichao Wang", "Xinhai Chen", "Junjun Yan", "Jie Liu"], "Categories": "cs.CV cs.AI"}, "abstract": "In CFD, mesh smoothing methods are commonly utilized to refine the mesh quality to achieve high-precision numerical simulations. Specifically, optimization-based smoothing is used for high-quality mesh smoothing, but it incurs significant computational overhead. Pioneer works improve its smoothing efficiency by adopting supervised learning to learn smoothing methods from high-quality meshes. However, they pose difficulty in smoothing the mesh nodes with varying degrees and also need data augmentation to address the node input sequence problem. Additionally, the required labeled high-quality meshes further limit the applicability of the proposed method. In this paper, we present GMSNet, a lightweight neural network model for intelligent mesh smoothing. GMSNet adopts graph neural networks to extract features of the node's neighbors and output the optimal node position. During smoothing, we also introduce a fault-tolerance mechanism to prevent GMSNet from generating negative volume elements. With a lightweight model, GMSNet can effectively smoothing mesh nodes with varying degrees and remain unaffected by the order of input data. A novel loss function, MetricLoss, is also developed to eliminate the need for high-quality meshes, which provides a stable and rapid convergence during training. We compare GMSNet with commonly used mesh smoothing methods on two-dimensional triangle meshes. The experimental results show that GMSNet achieves outstanding mesh smoothing performances with 5% model parameters of the previous model, and attains 8.62 times faster than optimization-based smoothing.", "url": "https://arxiv.org/abs/2311.12815"}, {"metadata": {"arXiv": "2311.12817", "Date": "Sun, 24 Sep 2023 13:39:50 ", "Title": "Semantic Face Compression for Metaverse: A Compact 3D Descriptor Based Approach", "Authors": ["Binzhe Li", "Bolin Chen", "Zhao Wang", "Shiqi Wang", "Yan Ye"], "Categories": "cs.CV cs.AI", "Comments": ["5 pages", "3 figures"]}, "abstract": "In this letter, we envision a new metaverse communication paradigm for virtual avatar faces, and develop the semantic face compression with compact 3D facial descriptors. The fundamental principle is that the communication of virtual avatar faces primarily emphasizes the conveyance of semantic information. In light of this, the proposed scheme offers the advantages of being highly flexible, efficient and semantically meaningful. The semantic face compression, which allows the communication of the descriptors for artificial intelligence based understanding, could facilitate numerous applications without the involvement of humans in metaverse. The promise of the proposed paradigm is also demonstrated by performance comparisons with the state-of-the-art video coding standard, Versatile Video Coding. A significant improvement in terms of rate-accuracy performance has been achieved. The proposed scheme is expected to enable numerous applications, such as digital human communication based on machine analysis, and to form the cornerstone of interaction and communication in the metaverse.", "url": "https://arxiv.org/abs/2311.12817"}, {"metadata": {"arXiv": "2311.12820", "Date": "Tue, 26 Sep 2023 04:23:23 ", "Title": "MSG-BART: Multi-granularity Scene Graph-Enhanced Encoder-Decoder Language Model for Video-grounded Dialogue Generation", "Authors": ["Hongcheng Liu", "Zhe Chen", "Hui Li", "Pingjie Wang", "Yanfeng Wang", "Yu Wang"], "Categories": "cs.CV cs.AI cs.CL eess.IV", "Comments": ["5 pages,3 figures"]}, "abstract": "Generating dialogue grounded in videos requires a high level of understanding and reasoning about the visual scenes in the videos. However, existing large visual-language models are not effective due to their latent features and decoder-only structure, especially with respect to spatio-temporal relationship reasoning. In this paper, we propose a novel approach named MSG-BART, which enhances the integration of video information by incorporating a multi-granularity spatio-temporal scene graph into an encoder-decoder pre-trained language model. Specifically, we integrate the global and local scene graph into the encoder and decoder, respectively, to improve both overall perception and target reasoning capability. To further improve the information selection capability, we propose a multi-pointer network to facilitate selection between text and video. Extensive experiments are conducted on three video-grounded dialogue benchmarks, which show the significant superiority of the proposed MSG-BART compared to a range of state-of-the-art approaches.", "url": "https://arxiv.org/abs/2311.12820"}, {"metadata": {"arXiv": "2311.12823", "Date": "Thu, 28 Sep 2023 13:12:45 ", "Title": "EWasteNet: A Two-Stream Data Efficient Image Transformer Approach for E-Waste Classification", "Authors": ["Niful Islam", "Md. Mehedi Hasan Jony", "Emam Hasan", "Sunny Sutradhar", "Atikur Rahman", "Md. Motaharul Islam"], "Categories": "cs.CV cs.AI", "Comments": ["6 pages"], "Journal-ref": "2023 IEEE 8th International Conference On Software Engineering and Computer Systems (ICSECS), Penang, Malaysia, 2023, pp. 435-440", "DOI": "10.1109/ICSECS58457.2023.10256323"}, "abstract": "Improper disposal of e-waste poses global environmental and health risks, raising serious concerns. The accurate classification of e-waste images is critical for efficient management and recycling. In this paper, we have presented a comprehensive dataset comprised of eight different classes of images of electronic devices named the E-Waste Vision Dataset. We have also presented EWasteNet, a novel two-stream approach for precise e-waste image classification based on a data-efficient image transformer (DeiT). The first stream of EWasteNet passes through a sobel operator that detects the edges while the second stream is directed through an Atrous Spatial Pyramid Pooling and attention block where multi-scale contextual information is captured. We train both of the streams simultaneously and their features are merged at the decision level. The DeiT is used as the backbone of both streams. Extensive analysis of the e-waste dataset indicates the usefulness of our method, providing 96% accuracy in e-waste classification. The proposed approach demonstrates significant usefulness in addressing the global concern of e-waste management. It facilitates efficient waste management and recycling by accurately classifying e-waste images, reducing health and safety hazards associated with improper disposal.", "url": "https://arxiv.org/abs/2311.12823"}, {"metadata": {"arXiv": "2311.12826", "Date": "Sun, 01 Oct 2023 02:35:58 ", "Title": "LiveChat: Video Comment Generation from Audio-Visual Multimodal Contexts", "Authors": ["Julien Lalanne", "Raphael Bournet", "Yi Yu"], "Categories": "cs.CV cs.AI"}, "abstract": "Live commenting on video, a popular feature of live streaming platforms, enables viewers to engage with the content and share their comments, reactions, opinions, or questions with the streamer or other viewers while watching the video or live stream. It presents a challenging testbed for AI agents, which involves the simultaneous understanding of audio-visual multimodal contexts from live streams and the ability to interact with human viewers through dialogue. As existing live streaming-based comments datasets contain limited categories and lack a diversity, we create a large-scale audio-visual multimodal dialogue dataset to facilitate the development of live commenting technologies. The data is collected from Twitch, with 11 different categories and 575 streamers for a total of 438 hours of video and 3.2 million comments. Moreover, we propose a novel multimodal generation model capable of generating live comments that align with the temporal and spatial events within the video, as well as with the ongoing multimodal dialogue context. Our initial results have demonstrated the effectiveness of the proposed model, providing a robust foundation for further research and practical applications in the field of live video interaction.", "url": "https://arxiv.org/abs/2311.12826"}, {"metadata": {"arXiv": "2311.12829", "Date": "Mon, 02 Oct 2023 00:34:21 ", "Title": "Intelligent Knee Sleeves: A Real-time Multimodal Dataset for 3D Lower Body Motion Estimation Using Smart Textile", "Authors": ["Wenwen Zhang", "Arvin Tashakori", "Zenan Jiang", "Amir Servati", "Harishkumar Narayana", "Saeid Soltanian", "Rou Yi Yeap", "Meng Han Ma", "Lauren Toy", "Peyman Servati"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted by Thirty-seventh Conference on Neural Information Processing Systems (Neurips) D&B Track"]}, "abstract": "The kinematics of human movements and locomotion are closely linked to the activation and contractions of muscles. To investigate this, we present a multimodal dataset with benchmarks collected using a novel pair of Intelligent Knee Sleeves (Texavie MarsWear Knee Sleeves) for human pose estimation. Our system utilizes synchronized datasets that comprise time-series data from the Knee Sleeves and the corresponding ground truth labels from the visualized motion capture camera system. We employ these to generate 3D human models solely based on the wearable data of individuals performing different activities. We demonstrate the effectiveness of this camera-free system and machine learning algorithms in the assessment of various movements and exercises, including extension to unseen exercises and individuals. The results show an average error of 7.21 degrees across all eight lower body joints when compared to the ground truth, indicating the effectiveness and reliability of the Knee Sleeve system for the prediction of different lower body joints beyond the knees. The results enable human pose estimation in a seamless manner without being limited by visual occlusion or the field of view of cameras. Our results show the potential of multimodal wearable sensing in a variety of applications from home fitness to sports, healthcare, and physical rehabilitation focusing on pose and movement estimation.", "url": "https://arxiv.org/abs/2311.12829"}, {"metadata": {"arXiv": "2311.12832", "Date": "Mon, 02 Oct 2023 18:56:12 ", "Title": "Toward effective protection against diffusion based mimicry through score distillation", "Authors": ["Haotian Xue", "Chumeng Liang", "Xiaoyu Wu", "Yongxin Chen"], "Categories": "cs.CV cs.AI", "Comments": ["code is available in https://github.com/xavihart/Diff-Protect"]}, "abstract": "While generative diffusion models excel in producing high-quality images, they can also be misused to mimic authorized images, posing a significant threat to AI systems. Efforts have been made to add calibrated perturbations to protect images from diffusion-based mimicry pipelines. However, most of the existing methods are too ineffective and even impractical to be used by individual users due to their high computation and memory requirements. In this work, we present novel findings on attacking latent diffusion models (LDM) and propose new plug-and-play strategies for more effective protection. In particular, we explore the bottleneck in attacking an LDM, discovering that the encoder module rather than the denoiser module is the vulnerable point. Based on this insight, we present our strategy using Score Distillation Sampling (SDS) to double the speed of protection and reduce memory occupation by half without compromising its strength. Additionally, we provide a robust protection strategy by counterintuitively minimizing the semantic loss, which can assist in generating more natural perturbations. Finally, we conduct extensive experiments to substantiate our findings and comprehensively evaluate our newly proposed strategies. We hope our insights and protective measures can contribute to better defense against malicious diffusion-based mimicry, advancing the development of secure AI systems. The code is available in https://github.com/xavihart/Diff-Protect", "url": "https://arxiv.org/abs/2311.12832"}, {"metadata": {"arXiv": "2311.12840", "Date": "Fri, 06 Oct 2023 08:23:36 ", "Title": "Wafer Map Defect Patterns Semi-Supervised Classification Using Latent Vector Representation", "Authors": ["Qiyu Wei and Wei Zhao and Xiaoyan Zheng and Zeng Zeng"], "Categories": "cs.CV cs.AI eess.IV", "Comments": ["6 pages", "2 figures", "CIS confernece"]}, "abstract": "As the globalization of semiconductor design and manufacturing processes continues, the demand for defect detection during integrated circuit fabrication stages is becoming increasingly critical, playing a significant role in enhancing the yield of semiconductor products. Traditional wafer map defect pattern detection methods involve manual inspection using electron microscopes to collect sample images, which are then assessed by experts for defects. This approach is labor-intensive and inefficient. Consequently, there is a pressing need to develop a model capable of automatically detecting defects as an alternative to manual operations. In this paper, we propose a method that initially employs a pre-trained VAE model to obtain the fault distribution information of the wafer map. This information serves as guidance, combined with the original image set for semi-supervised model training. During the semi-supervised training, we utilize a teacher-student network for iterative learning. The model presented in this paper is validated on the benchmark dataset WM-811K wafer dataset. The experimental results demonstrate superior classification accuracy and detection performance compared to state-of-the-art models, fulfilling the requirements for industrial applications. Compared to the original architecture, we have achieved significant performance improvement.", "url": "https://arxiv.org/abs/2311.12840"}, {"metadata": {"arXiv": "2311.12919", "Date": "Tue, 21 Nov 2023 18:43:07 ", "Title": "SPOT! Revisiting Video-Language Models for Event Understanding", "Authors": ["Gengyuan Zhang", "Jinhe Bi", "Jindong Gu", "Volker Tresp"], "Categories": "cs.CV cs.AI", "Comments": ["9 pages"]}, "abstract": "Understanding videos is an important research topic for multimodal learning. Leveraging large-scale datasets of web-crawled video-text pairs as weak supervision has become a pre-training paradigm for learning joint representations and showcased remarkable potential in video understanding tasks. However, videos can be multi-event and multi-grained, while these video-text pairs usually contain only broad-level video captions. This raises a question: with such weak supervision, can video representation in video-language models gain the ability to distinguish even factual discrepancies in textual description and understand fine-grained events? To address this, we introduce SPOT Prober, to benchmark existing video-language models's capacities of distinguishing event-level discrepancies as an indicator of models' event understanding ability. Our approach involves extracting events as tuples (<Subject, Predicate, Object, Attribute, Timestamps>) from videos and generating false event tuples by manipulating tuple components systematically. We reevaluate the existing video-language models with these positive and negative captions and find they fail to distinguish most of the manipulated events. Based on our findings, we propose to plug in these manipulated event captions as hard negative samples and find them effective in enhancing models for event understanding.", "url": "https://arxiv.org/abs/2311.12919"}, {"metadata": {"arXiv": "2311.12967", "Date": "Tue, 21 Nov 2023 20:12:29 ", "Title": "Robustifying Generalizable Implicit Shape Networks with a Tunable Non-Parametric Model", "Authors": ["Amine Ouasfi and Adnane Boukhayma"], "Categories": "cs.CV cs.AI", "Comments": ["NeurIPS 2023"]}, "abstract": "Feedforward generalizable models for implicit shape reconstruction from unoriented point cloud present multiple advantages, including high performance and inference speed. However, they still suffer from generalization issues, ranging from underfitting the input point cloud, to misrepresenting samples outside of the training data distribution, or with toplogies unseen at training. We propose here an efficient mechanism to remedy some of these limitations at test time. We combine the inter-shape data prior of the network with an intra-shape regularization prior of a Nystr\\\"om Kernel Ridge Regression, that we further adapt by fitting its hyperprameters to the current shape. The resulting shape function defined in a shape specific Reproducing Kernel Hilbert Space benefits from desirable stability and efficiency properties and grants a shape adaptive expressiveness-robustness trade-off. We demonstrate the improvement obtained through our method with respect to baselines and the state-of-the-art using synthetic and real data.", "url": "https://arxiv.org/abs/2311.12967"}, {"metadata": {"arXiv": "2311.13127", "Date": "Wed, 22 Nov 2023 03:31:31 ", "Title": "Toward Robust Imperceptible Perturbation against Unauthorized Text-to-image Diffusion-based Synthesis", "Authors": ["Yixin Liu", "Chenrui Fan", "Yutong Dai", "Xun Chen", "Pan Zhou", "and Lichao Sun"], "Categories": "cs.CV cs.AI cs.CR", "Comments": ["26 pages", "15 figures", "8 tables"]}, "abstract": "Text-to-image diffusion models allow seamless generation of personalized images from scant reference photos. Yet, these tools, in the wrong hands, can fabricate misleading or harmful content, endangering individuals. To address this problem, existing poisoning-based approaches perturb user images in an imperceptible way to render them \"unlearnable\" from malicious uses. We identify two limitations of these defending approaches: i) sub-optimal due to the hand-crafted heuristics for solving the intractable bilevel optimization and ii) lack of robustness against simple data transformations like Gaussian filtering. To solve these challenges, we propose MetaCloak, which solves the bi-level poisoning problem with a meta-learning framework with an additional transformation sampling process to craft transferable and robust perturbation. Specifically, we employ a pool of surrogate diffusion models to craft transferable and model-agnostic perturbation. Furthermore, by incorporating an additional transformation process, we design a simple denoising-error maximization loss that is sufficient for causing transformation-robust semantic distortion and degradation in a personalized generation. Extensive experiments on the VGGFace2 and CelebA-HQ datasets show that MetaCloak outperforms existing approaches. Notably, MetaCloak can successfully fool online training services like Replicate, in a black-box manner, demonstrating the effectiveness of MetaCloak in real-world scenarios. Our code is available at https://github.com/liuyixin-louis/MetaCloak.", "url": "https://arxiv.org/abs/2311.13127"}, {"metadata": {"arXiv": "2311.13234", "Date": "Wed, 22 Nov 2023 08:45:01 ", "Title": "TSegFormer: 3D Tooth Segmentation in Intraoral Scans with Geometry Guided Transformer", "Authors": ["Huimin Xiong", "Kunle Li", "Kaiyuan Tan", "Yang Feng", "Joey Tianyi Zhou", "Jin Hao", "Haochao Ying", "Jian Wu", "and Zuozhu Liu"], "Categories": "cs.CV cs.AI", "Comments": ["MICCAI 2023", "STAR(Student Travel) award. 11 pages", "3 figures", "5 tables. arXiv admin note: text overlap with arXiv:2210.16627"]}, "abstract": "Optical Intraoral Scanners (IOS) are widely used in digital dentistry to provide detailed 3D information of dental crowns and the gingiva. Accurate 3D tooth segmentation in IOSs is critical for various dental applications, while previous methods are error-prone at complicated boundaries and exhibit unsatisfactory results across patients. In this paper, we propose TSegFormer which captures both local and global dependencies among different teeth and the gingiva in the IOS point clouds with a multi-task 3D transformer architecture. Moreover, we design a geometry-guided loss based on a novel point curvature to refine boundaries in an end-to-end manner, avoiding time-consuming post-processing to reach clinically applicable segmentation. In addition, we create a dataset with 16,000 IOSs, the largest ever IOS dataset to the best of our knowledge. The experimental results demonstrate that our TSegFormer consistently surpasses existing state-of-the-art baselines. The superiority of TSegFormer is corroborated by extensive analysis, visualizations and real-world clinical applicability tests. Our code is available at https://github.com/huiminxiong/TSegFormer.", "url": "https://arxiv.org/abs/2311.13234"}, {"metadata": {"arXiv": "2311.13254", "Date": "Wed, 22 Nov 2023 09:18:49 ", "Title": "DA-STC: Domain Adaptive Video Semantic Segmentation via Spatio-Temporal Consistency", "Authors": ["Zhe Zhang", "Gaochang Wu", "Jing Zhang", "Chunhua Shen", "Dacheng Tao", "Tianyou Chai"], "Categories": "cs.CV cs.AI eess.IV", "Comments": ["18 pages,9 figures"]}, "abstract": "Video semantic segmentation is a pivotal aspect of video representation learning. However, significant domain shifts present a challenge in effectively learning invariant spatio-temporal features across the labeled source domain and unlabeled target domain for video semantic segmentation. To solve the challenge, we propose a novel DA-STC method for domain adaptive video semantic segmentation, which incorporates a bidirectional multi-level spatio-temporal fusion module and a category-aware spatio-temporal feature alignment module to facilitate consistent learning for domain-invariant features. Firstly, we perform bidirectional spatio-temporal fusion at the image sequence level and shallow feature level, leading to the construction of two fused intermediate video domains. This prompts the video semantic segmentation model to consistently learn spatio-temporal features of shared patch sequences which are influenced by domain-specific contexts, thereby mitigating the feature gap between the source and target domain. Secondly, we propose a category-aware feature alignment module to promote the consistency of spatio-temporal features, facilitating adaptation to the target domain. Specifically, we adaptively aggregate the domain-specific deep features of each category along spatio-temporal dimensions, which are further constrained to achieve cross-domain intra-class feature alignment and inter-class feature separation. Extensive experiments demonstrate the effectiveness of our method, which achieves state-of-the-art mIOUs on multiple challenging benchmarks. Furthermore, we extend the proposed DA-STC to the image domain, where it also exhibits superior performance for domain adaptive semantic segmentation. The source code and models will be made available at \\url{https://github.com/ZHE-SAPI/DA-STC}.", "url": "https://arxiv.org/abs/2311.13254"}, {"metadata": {"arXiv": "2311.13435", "Date": "Wed, 22 Nov 2023 14:48:30 ", "Title": "PG-Video-LLaVA: Pixel Grounding Large Video-Language Models", "Authors": ["Shehan Munasinghe", "Rusiru Thushara", "Muhammad Maaz", "Hanoona Abdul Rasheed", "Salman Khan", "Mubarak Shah", "Fahad Khan"], "Categories": "cs.CV cs.AI", "Comments": ["Technical Report"]}, "abstract": "Extending image-based Large Multimodal Models (LMM) to videos is challenging due to the inherent complexity of video data. The recent approaches extending image-based LMM to videos either lack the grounding capabilities (e.g., VideoChat, Video-ChatGPT, Video-LLaMA) or do not utilize the audio-signals for better video understanding (e.g., Video-ChatGPT). Addressing these gaps, we propose Video-LLaVA, the first LMM with pixel-level grounding capability, integrating audio cues by transcribing them into text to enrich video-context understanding. Our framework uses an off-the-shelf tracker and a novel grounding module, enabling it to spatially and temporally localize objects in videos following user instructions. We evaluate Video-LLaVA using video-based generative and question-answering benchmarks and introduce new benchmarks specifically designed to measure prompt-based object grounding performance in videos. Further, we propose the use of Vicuna over GPT-3.5, as utilized in Video-ChatGPT, for video-based conversation benchmarking, ensuring reproducibility of results which is a concern with the proprietary nature of GPT-3.5. Our framework builds on SoTA image-based LLaVA model and extends its advantages to the video domain, delivering promising gains on video-based conversation and grounding tasks. Project Page: https://github.com/mbzuai-oryx/Video-LLaVA", "url": "https://arxiv.org/abs/2311.13435"}, {"metadata": {"arXiv": "2311.13547", "Date": "Wed, 22 Nov 2023 17:42:33 ", "Title": "Medical Image Retrieval Using Pretrained Embeddings", "Authors": ["Farnaz Khun Jush", "Tuan Truong", "Steffen Vogler", "Matthias Lenga"], "Categories": "cs.CV cs.AI", "Comments": ["8 pages", "3 figures", "4 tables"]}, "abstract": "A wide range of imaging techniques and data formats available for medical images make accurate retrieval from image databases challenging. Efficient retrieval systems are crucial in advancing medical research, enabling large-scale studies and innovative diagnostic tools. Thus, addressing the challenges of medical image retrieval is essential for the continued enhancement of healthcare and research. In this study, we evaluated the feasibility of employing four state-of-the-art pretrained models for medical image retrieval at modality, body region, and organ levels and compared the results of two similarity indexing approaches. Since the employed networks take 2D images, we analyzed the impacts of weighting and sampling strategies to incorporate 3D information during retrieval of 3D volumes. We showed that medical image retrieval is feasible using pretrained networks without any additional training or fine-tuning steps. Using pretrained embeddings, we achieved a recall of 1 for various tasks at modality, body region, and organ level.", "url": "https://arxiv.org/abs/2311.13547"}, {"metadata": {"arXiv": "2311.13559", "Date": "Wed, 22 Nov 2023 18:09:42 ", "Title": "Transfer Learning-based Real-time Handgun Detection", "Authors": ["Youssef Elmir", "Sid Ahmed Laouar", "Larbi Hamdaoui"], "Categories": "cs.CV cs.AI cs.HC"}, "abstract": "Traditional surveillance systems rely on human attention, limiting their effectiveness. This study employs convolutional neural networks and transfer learning to develop a real-time computer vision system for automatic handgun detection. Comprehensive analysis of online handgun detection methods is conducted, emphasizing reducing false positives and learning time. Transfer learning is demonstrated as an effective approach. Despite technical challenges, the proposed system achieves a precision rate of 84.74%, demonstrating promising performance comparable to related works, enabling faster learning and accurate automatic handgun detection for enhanced security. This research advances security measures by reducing human monitoring dependence, showcasing the potential of transfer learning-based approaches for efficient and reliable handgun detection.", "url": "https://arxiv.org/abs/2311.13559"}, {"metadata": {"arXiv": "2311.13562", "Date": "Wed, 22 Nov 2023 18:15:43 ", "Title": "Soulstyler: Using Large Language Model to Guide Image Style Transfer for Target Object", "Authors": ["Junhao Chen", "Peng Rong", "Jingbo Sun", "Chao Li", "Xiang Li", "Hongwu Lv"], "Categories": "cs.CV cs.AI", "Comments": ["5 pages,3 figures,ICASSP2024"]}, "abstract": "Image style transfer occupies an important place in both computer graphics and computer vision. However, most current methods require reference to stylized images and cannot individually stylize specific objects. To overcome this limitation, we propose the \"Soulstyler\" framework, which allows users to guide the stylization of specific objects in an image through simple textual descriptions. We introduce a large language model to parse the text and identify stylization goals and specific styles. Combined with a CLIP-based semantic visual embedding encoder, the model understands and matches text and image content. We also introduce a novel localized text-image block matching loss that ensures that style transfer is performed only on specified target objects, while non-target regions remain in their original style. Experimental results demonstrate that our model is able to accurately perform style transfer on target objects according to textual descriptions without affecting the style of background regions. Our code will be available at https://github.com/yisuanwang/Soulstyler.", "url": "https://arxiv.org/abs/2311.13562"}, {"metadata": {"arXiv": "2311.12893", "Date": "Tue, 21 Nov 2023 08:09:00 ", "Title": "A Safer Vision-based Autonomous Planning System for Quadrotor UAVs with Dynamic Obstacle Trajectory Prediction and Its Application with LLMs", "Authors": ["Jiageng Zhong", "Ming Li", "Yinliang Chen", "Zihang Wei", "Fan Yang", "Haoran Shen"], "Categories": "cs.RO cs.AI cs.CV"}, "abstract": "For intelligent quadcopter UAVs, a robust and reliable autonomous planning system is crucial. Most current trajectory planning methods for UAVs are suitable for static environments but struggle to handle dynamic obstacles, which can pose challenges and even dangers to flight. To address this issue, this paper proposes a vision-based planning system that combines tracking and trajectory prediction of dynamic obstacles to achieve efficient and reliable autonomous flight. We use a lightweight object detection algorithm to identify dynamic obstacles and then use Kalman Filtering to track and estimate their motion states. During the planning phase, we not only consider static obstacles but also account for the potential movements of dynamic obstacles. For trajectory generation, we use a B-spline-based trajectory search algorithm, which is further optimized with various constraints to enhance safety and alignment with the UAV's motion characteristics. We conduct experiments in both simulation and real-world environments, and the results indicate that our approach can successfully detect and avoid obstacles in dynamic environments in real-time, offering greater reliability compared to existing approaches. Furthermore, with the advancements in Natural Language Processing (NLP) technology demonstrating exceptional zero-shot generalization capabilities, more user-friendly human-machine interactions have become feasible, and this study also explores the integration of autonomous planning systems with Large Language Models (LLMs).", "url": "https://arxiv.org/abs/2311.12893"}, {"metadata": {"arXiv": "2311.13226", "Date": "Wed, 22 Nov 2023 08:30:20 ", "Title": "Robot at the Mirror: Learning to Imitate via Associating Self-supervised Models", "Authors": ["Andrej L\\'u\\v{c}ny", "Krist\\'ina Malinovsk\\'a", "and Igor Farka\\v{s}"], "Categories": "cs.RO cs.AI", "Comments": ["ICANN 2023 https://github.com/andylucny/learningImitation"]}, "abstract": "We introduce an approach to building a custom model from ready-made self-supervised models via their associating instead of training and fine-tuning. We demonstrate it with an example of a humanoid robot looking at the mirror and learning to detect the 3D pose of its own body from the image it perceives. To build our model, we first obtain features from the visual input and the postures of the robot's body via models prepared before the robot's operation. Then, we map their corresponding latent spaces by a sample-efficient robot's self-exploration at the mirror. In this way, the robot builds the solicited 3D pose detector, which quality is immediately perfect on the acquired samples instead of obtaining the quality gradually. The mapping, which employs associating the pairs of feature vectors, is then implemented in the same way as the key-value mechanism of the famous transformer models. Finally, deploying our model for imitation to a simulated robot allows us to study, tune up, and systematically evaluate its hyperparameters without the involvement of the human counterpart, advancing our previous research.", "url": "https://arxiv.org/abs/2311.13226"}, {"metadata": {"arXiv": "2311.12825", "Date": "Sat, 30 Sep 2023 18:08:00 ", "Title": "A PSO Based Method to Generate Actionable Counterfactuals for High Dimensional Data", "Authors": ["Shashank Shekhar", "Asif Salim", "Adesh Bansode", "Vivaswan Jinturkar", "Anirudha Nayak"], "Categories": "cs.AI cs.LG stat.ME", "Comments": ["Submitted in IEEE CSDE 2023"]}, "abstract": "Counterfactual explanations (CFE) are methods that explain a machine learning model by giving an alternate class prediction of a data point with some minimal changes in its features. It helps the users to identify their data attributes that caused an undesirable prediction like a loan or credit card rejection. We describe an efficient and an actionable counterfactual (CF) generation method based on particle swarm optimization (PSO). We propose a simple objective function for the optimization of the instance-centric CF generation problem. The PSO brings in a lot of flexibility in terms of carrying out multi-objective optimization in large dimensions, capability for multiple CF generation, and setting box constraints or immutability of data attributes. An algorithm is proposed that incorporates these features and it enables greater control over the proximity and sparsity properties over the generated CFs. The proposed algorithm is evaluated with a set of action-ability metrics in real-world datasets, and the results were superior compared to that of the state-of-the-arts.", "url": "https://arxiv.org/abs/2311.12825"}, {"metadata": {"arXiv": "2311.12872", "Date": "Sat, 18 Nov 2023 03:27:47 ", "Title": "The Case for Universal Basic Computing Power", "Authors": ["Yue Zhu"], "Categories": "cs.AI cs.CY cs.LG"}, "abstract": "The Universal Basic Computing Power (UBCP) initiative ensures global, free access to a set amount of computing power specifically for AI research and development (R&D). This initiative comprises three key elements. First, UBCP must be cost free, with its usage limited to AI R&D and minimal additional conditions. Second, UBCP should continually incorporate the state of the art AI advancements, including efficiently distilled, compressed, and deployed training data, foundational models, benchmarks, and governance tools. Lastly, it's essential for UBCP to be universally accessible, ensuring convenience for all users. We urge major stakeholders in AI development large platforms, open source contributors, and policymakers to prioritize the UBCP initiative.", "url": "https://arxiv.org/abs/2311.12872"}, {"metadata": {"arXiv": "2311.12905", "Date": "Tue, 21 Nov 2023 13:12:21 ", "Title": "Revisiting the Domain Shift and Sample Uncertainty in Multi-source Active Domain Transfer", "Authors": ["Wenqiao Zhang", "Zheqi Lv", "Hao Zhou", "Jia-Wei Liu", "Juncheng Li", "Mengze Li", "Siliang Tang", "Yueting Zhuang"], "Categories": "cs.AI cs.LG", "Comments": ["arXiv admin note: text overlap with arXiv:2302.13824 by other authors"]}, "abstract": "Active Domain Adaptation (ADA) aims to maximally boost model adaptation in a new target domain by actively selecting a limited number of target data to annotate.This setting neglects the more practical scenario where training data are collected from multiple sources. This motivates us to target a new and challenging setting of knowledge transfer that extends ADA from a single source domain to multiple source domains, termed Multi-source Active Domain Adaptation (MADA). Not surprisingly, we find that most traditional ADA methods cannot work directly in such a setting, mainly due to the excessive domain gap introduced by all the source domains and thus their uncertainty-aware sample selection can easily become miscalibrated under the multi-domain shifts. Considering this, we propose a Dynamic integrated uncertainty valuation framework(Detective) that comprehensively consider the domain shift between multi-source domains and target domain to detect the informative target samples. Specifically, the leverages a dynamic Domain Adaptation(DA) model that learns how to adapt the model's parameters to fit the union of multi-source domains. This enables an approximate single-source domain modeling by the dynamic model. We then comprehensively measure both domain uncertainty and predictive uncertainty in the target domain to detect informative target samples using evidential deep learning, thereby mitigating uncertainty miscalibration. Furthermore, we introduce a contextual diversity-aware calculator to enhance the diversity of the selected samples. Experiments demonstrate that our solution outperforms existing methods by a considerable margin on three domain adaptation benchmarks.", "url": "https://arxiv.org/abs/2311.12905"}, {"metadata": {"arXiv": "2311.13038", "Date": "Tue, 21 Nov 2023 22:56:13 ", "Title": "Synaptic Sampling of Neural Networks", "Authors": ["James B. Aimone", "William Severa", "J. Darby Smith"], "Categories": "cs.AI cs.LG cs.NE", "Comments": ["9 pages", "accepted to 2023 IEEE International Conference on Rebooting Computing"], "Report-no": "SAND2023-13757C"}, "abstract": "Probabilistic artificial neural networks offer intriguing prospects for enabling the uncertainty of artificial intelligence methods to be described explicitly in their function; however, the development of techniques that quantify uncertainty by well-understood methods such as Monte Carlo sampling has been limited by the high costs of stochastic sampling on deterministic computing hardware. Emerging computing systems that are amenable to hardware-level probabilistic computing, such as those that leverage stochastic devices, may make probabilistic neural networks more feasible in the not-too-distant future. This paper describes the scANN technique -- \\textit{sampling (by coinflips) artificial neural networks} -- which enables neural networks to be sampled directly by treating the weights as Bernoulli coin flips. This method is natively well suited for probabilistic computing techniques that focus on tunable stochastic devices, nearly matches fully deterministic performance while also describing the uncertainty of correct and incorrect neural network outputs.", "url": "https://arxiv.org/abs/2311.13038"}, {"metadata": {"arXiv": "2311.13188", "Date": "Wed, 22 Nov 2023 06:30:54 ", "Title": "Cracking the Code of Negative Transfer: A Cooperative Game Theoretic Approach for Cross-Domain Sequential Recommendation", "Authors": ["Chung Park", "Taesan Kim", "Taekyoon Choi", "Junui Hong", "Yelim Yu", "Mincheol Cho", "Kyunam Lee", "Sungil Ryu", "Hyungjun Yoon", "Minsung Choi", "Jaegul Choo"], "Categories": "cs.AI cs.LG", "Comments": ["Accepted at 32nd ACM International Conference on Information and Knowledge Management (CIKM 2023)"]}, "abstract": "This paper investigates Cross-Domain Sequential Recommendation (CDSR), a promising method that uses information from multiple domains (more than three) to generate accurate and diverse recommendations, and takes into account the sequential nature of user interactions. The effectiveness of these systems often depends on the complex interplay among the multiple domains. In this dynamic landscape, the problem of negative transfer arises, where heterogeneous knowledge between dissimilar domains leads to performance degradation due to differences in user preferences across these domains. As a remedy, we propose a new CDSR framework that addresses the problem of negative transfer by assessing the extent of negative transfer from one domain to another and adaptively assigning low weight values to the corresponding prediction losses. To this end, the amount of negative transfer is estimated by measuring the marginal contribution of each domain to model performance based on a cooperative game theory. In addition, a hierarchical contrastive learning approach that incorporates information from the sequence of coarse-level categories into that of fine-level categories (e.g., item level) when implementing contrastive learning was developed to mitigate negative transfer. Despite the potentially low relevance between domains at the fine-level, there may be higher relevance at the category level due to its generalised and broader preferences. We show that our model is superior to prior works in terms of model performance on two real-world datasets across ten different domains.", "url": "https://arxiv.org/abs/2311.13188"}, {"metadata": {"arXiv": "2311.13538", "Date": "Wed, 22 Nov 2023 17:24:21 ", "Title": "Speak Like a Native: Prompting Large Language Models in a Native Style", "Authors": ["Zhicheng Yang", "Yiwei Wang", "Yinya Huang", "Jing Xiong", "Xiaodan Liang", "Jing Tang"], "Categories": "cs.AI cs.LG", "Comments": ["8 pages", "3 figures"]}, "abstract": "Existing work has found that the prompt engineering heavily influences the performance of large language models (LLMs). Chain-of-thought (CoT), as a popular prompt engineering technique, prompted LLMs using in-context examples with reasoning steps. In current studies, the few-shot examples of CoT are generally handcrafted by humans. However, how the text style of in-context examples influence the outputs of LLMs still remains under-explored. This paper presents a novel and effective approach, named \\textbf{AlignCoT}, to improve the reasoning capability of LLMs by aligning the in-context examples with the native style of LLMs. ``Native'' refers to the inherent characteristic style of LLMs which can be probed by original zero-shot scenarios. AlignCoT is orthogonal to other prompt engineering methods, making it easy to combine with state-of-the-art techniques to further improve the LLMs' performance. We conduct extensive and comprehensive experiments on several benchmarks. The empirical results demonstrate that our AlignCoTsignificantly improves performance over the carefully handcrafted in-context examples. For instance, with GPT-3.5-turbo, we observed a +2.5\\% improvement on GSM8K. Furthermore, our AlignCoT consistently improve the performance when combined with other state-of-the-art prompt engineering methods. The source code and dataset will be available at \\href{https://github.com/yangzhch6/AlignCoT}{https://github.com/yangzhch6/AlignCoT}.", "url": "https://arxiv.org/abs/2311.13538"}, {"metadata": {"arXiv": "2311.12812", "Date": "Thu, 21 Sep 2023 07:16:50 ", "Title": "Personalization of Affective Models to Enable Neuropsychiatric Digital Precision Health Interventions: A Feasibility Study", "Authors": ["Ali Kargarandehkordi", "Matti Kaisti", "Peter Washington"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Mobile digital therapeutics for autism spectrum disorder (ASD) often target emotion recognition and evocation, which is a challenge for children with ASD. While such mobile applications often use computer vision machine learning (ML) models to guide the adaptive nature of the digital intervention, a single model is usually deployed and applied to all children. Here, we explore the potential of model personalization, or training a single emotion recognition model per person, to improve the performance of these underlying emotion recognition models used to guide digital health therapies for children with ASD. We conducted experiments on the Emognition dataset, a video dataset of human subjects evoking a series of emotions. For a subset of 10 individuals in the dataset with a sufficient representation of at least two ground truth emotion labels, we trained a personalized version of three classical ML models on a set of 51 features extracted from each video frame. We measured the importance of each facial feature for all personalized models and observed differing ranked lists of top features across subjects, motivating the need for model personalization. We then compared the personalized models against a generalized model trained using data from all 10 participants. The mean F1-scores achieved by the personalized models were 90.48%, 92.66%, and 86.40%, respectively. By contrast, the mean F1-scores reached by non-personalized models trained on different human subjects and evaluated using the same test set were 88.55%, 91.78%, and 80.42%, respectively. The personalized models outperformed the generalized models for 7 out of 10 participants. PCA analyses on the remaining 3 participants revealed relatively facial configuration differences between emotion labels within each subject, suggesting that personalized ML will fail when the variation among data points within a subjects data is too low.", "url": "https://arxiv.org/abs/2311.12812"}, {"metadata": {"arXiv": "2311.12819", "Date": "Tue, 26 Sep 2023 03:09:00 ", "Title": "Fixing the problems of deep neural networks will require better training data and learning algorithms", "Authors": ["Drew Linsley", "Thomas Serre"], "Categories": "cs.CV cs.AI cs.LG q-bio.NC", "Comments": ["Published as a commentary in Behavioral and Brain Sciences"]}, "abstract": "Bowers and colleagues argue that DNNs are poor models of biological vision because they often learn to rival human accuracy by relying on strategies that differ markedly from those of humans. We show that this problem is worsening as DNNs are becoming larger-scale and increasingly more accurate, and prescribe methods for building DNNs that can reliably model biological vision.", "url": "https://arxiv.org/abs/2311.12819"}, {"metadata": {"arXiv": "2311.12836", "Date": "Tue, 03 Oct 2023 16:09:07 ", "Title": "AI-based association analysis for medical imaging using latent-space geometric confounder correction", "Authors": ["Xianjing Liu", "Bo Li", "Meike W. Vernooij", "Eppo B. Wolvius", "Gennady V. Roshchupkin", "Esther E. Bron"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["18 pages; 7 figures"]}, "abstract": "AI has greatly enhanced medical image analysis, yet its use in epidemiological population imaging studies remains limited due to visualization challenges in non-linear models and lack of confounder control. Addressing this, we introduce an AI method emphasizing semantic feature interpretation and resilience against multiple confounders. Our approach's merits are tested in three scenarios: extracting confounder-free features from a 2D synthetic dataset; examining the association between prenatal alcohol exposure and children's facial shapes using 3D mesh data; exploring the relationship between global cognition and brain images with a 3D MRI dataset. Results confirm our method effectively reduces confounder influences, establishing less confounded associations. Additionally, it provides a unique visual representation, highlighting specific image alterations due to identified correlations.", "url": "https://arxiv.org/abs/2311.12836"}, {"metadata": {"arXiv": "2311.12860", "Date": "Wed, 25 Oct 2023 08:59:21 ", "Title": "On the stability, correctness and plausibility of visual explanation methods based on feature importance", "Authors": ["Romain Xu-Darme (LSL", "LIG)", "Jenny Benois-Pineau (LaBRI)", "Romain Giot (LaBRI)", "Georges Qu\\'enot (LIG)", "Zakaria Chihani (LSL)", "Marie-Christine Rousset (LIG)", "Alexey Zhukov (LaBRI)"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "In the field of Explainable AI, multiples evaluation metrics have been proposed in order to assess the quality of explanation methods w.r.t. a set of desired properties. In this work, we study the articulation between the stability, correctness and plausibility of explanations based on feature importance for image classifiers. We show that the existing metrics for evaluating these properties do not always agree, raising the issue of what constitutes a good evaluation metric for explanations. Finally, in the particular case of stability and correctness, we show the possible limitations of some evaluation metrics and propose new ones that take into account the local behaviour of the model under test.", "url": "https://arxiv.org/abs/2311.12860"}, {"metadata": {"arXiv": "2311.12866", "Date": "Thu, 02 Nov 2023 14:22:17 ", "Title": "Modular Blended Attention Network for Video Question Answering", "Authors": ["Mingjie Zhou"], "Categories": "cs.CV cs.AI cs.CL cs.LG", "Comments": ["I will not add others' names since this work has not been published"]}, "abstract": "In multimodal machine learning tasks, it is due to the complexity of the assignments that the network structure, in most cases, is assembled in a sophisticated way. The holistic architecture can be separated into several logical parts according to the respective ends that the modules are devised to achieve. As the number of modalities of information representation increases, constructing ad hoc subnetworks for processing the data from divergent modalities while mediating the fusion of different information types has become a cumbersome and expensive problem. In this paper, we present an approach to facilitate the question with a reusable and composable neural unit; by connecting the units in series or parallel, the arduous network constructing of multimodal machine learning tasks will be accomplished in a much straightforward way. Additionally, through parameter sharing (weights replication) among the units, the space complexity will be significantly reduced. We have conducted experiments on three commonly used datasets; our method achieves impressive performance compared to several video QA baselines.", "url": "https://arxiv.org/abs/2311.12866"}, {"metadata": {"arXiv": "2311.12871", "Date": "Sat, 18 Nov 2023 01:21:38 ", "Title": "An Embodied Generalist Agent in 3D World", "Authors": ["Jiangyong Huang", "Silong Yong", "Xiaojian Ma", "Xiongkun Linghu", "Puhao Li", "Yan Wang", "Qing Li", "Song-Chun Zhu", "Baoxiong Jia", "Siyuan Huang"], "Categories": "cs.CV cs.AI cs.CL cs.LG", "Comments": ["The first four authors contribute equally. Project page: https://embodied-generalist.github.io"]}, "abstract": "Leveraging massive knowledge and learning schemes from large language models (LLMs), recent machine learning models show notable successes in building generalist agents that exhibit the capability of general-purpose task solving in diverse domains, including natural language processing, computer vision, and robotics. However, a significant challenge remains as these models exhibit limited ability in understanding and interacting with the 3D world. We argue this limitation significantly hinders the current models from performing real-world tasks and further achieving general intelligence. To this end, we introduce an embodied multi-modal and multi-task generalist agent that excels in perceiving, grounding, reasoning, planning, and acting in the 3D world. Our proposed agent, referred to as LEO, is trained with shared LLM-based model architectures, objectives, and weights in two stages: (i) 3D vision-language alignment and (ii) 3D vision-language-action instruction tuning. To facilitate the training, we meticulously curate and generate an extensive dataset comprising object-level and scene-level multi-modal tasks with exceeding scale and complexity, necessitating a deep understanding of and interaction with the 3D world. Through rigorous experiments, we demonstrate LEO's remarkable proficiency across a wide spectrum of tasks, including 3D captioning, question answering, embodied reasoning, embodied navigation, and robotic manipulation. Our ablation results further provide valuable insights for the development of future embodied generalist agents.", "url": "https://arxiv.org/abs/2311.12871"}, {"metadata": {"arXiv": "2311.12889", "Date": "Tue, 21 Nov 2023 06:03:20 ", "Title": "Enhancing Scene Graph Generation with Hierarchical Relationships and Commonsense Knowledge", "Authors": ["Bowen Jiang", "Zhijun Zhuang", "Camillo Jose Taylor"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "This work presents an enhanced approach to generating scene graphs by incorporating a relationship hierarchy and commonsense knowledge. Specifically, we propose a Bayesian classification head that exploits an informative hierarchical structure. It jointly predicts the super-category or type of relationship between the two objects, along with the detailed relationship under each super-category. We design a commonsense validation pipeline that uses a large language model to critique the results from the scene graph prediction system and then use that feedback to enhance the model performance. The system requires no external large language model assistance at test time, making it more convenient for practical applications. Experiments on the Visual Genome and the OpenImage V6 datasets demonstrate that harnessing hierarchical relationships enhances the model performance by a large margin. The proposed Bayesian head can also be incorporated as a portable module in existing scene graph generation algorithms to improve their results. In addition, the commonsense validation enables the model to generate an extensive set of reasonable predictions beyond dataset annotations.", "url": "https://arxiv.org/abs/2311.12889"}, {"metadata": {"arXiv": "2311.12908", "Date": "Tue, 21 Nov 2023 15:24:05 ", "Title": "Diffusion Model Alignment Using Direct Preference Optimization", "Authors": ["Bram Wallace", "Meihua Dang", "Rafael Rafailov", "Linqi Zhou", "Aaron Lou", "Senthil Purushwalkam", "Stefano Ermon", "Caiming Xiong", "Shafiq Joty", "Nikhil Naik"], "Categories": "cs.CV cs.AI cs.GR cs.LG"}, "abstract": "Large language models (LLMs) are fine-tuned using human comparison data with Reinforcement Learning from Human Feedback (RLHF) methods to make them better aligned with users' preferences. In contrast to LLMs, human preference learning has not been widely explored in text-to-image diffusion models; the best existing approach is to fine-tune a pretrained model using carefully curated high quality images and captions to improve visual appeal and text alignment. We propose Diffusion-DPO, a method to align diffusion models to human preferences by directly optimizing on human comparison data. Diffusion-DPO is adapted from the recently developed Direct Preference Optimization (DPO), a simpler alternative to RLHF which directly optimizes a policy that best satisfies human preferences under a classification objective. We re-formulate DPO to account for a diffusion model notion of likelihood, utilizing the evidence lower bound to derive a differentiable objective. Using the Pick-a-Pic dataset of 851K crowdsourced pairwise preferences, we fine-tune the base model of the state-of-the-art Stable Diffusion XL (SDXL)-1.0 model with Diffusion-DPO. Our fine-tuned base model significantly outperforms both base SDXL-1.0 and the larger SDXL-1.0 model consisting of an additional refinement model in human evaluation, improving visual appeal and prompt alignment. We also develop a variant that uses AI feedback and has comparable performance to training on human preferences, opening the door for scaling of diffusion model alignment methods.", "url": "https://arxiv.org/abs/2311.12908"}, {"metadata": {"arXiv": "2311.12956", "Date": "Tue, 21 Nov 2023 19:49:13 ", "Title": "Innovative Horizons in Aerial Imagery: LSKNet Meets DiffusionDet for Advanced Object Detection", "Authors": ["Ahmed Sharshar", "Aleksandr Matsun"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "In the realm of aerial image analysis, object detection plays a pivotal role, with significant implications for areas such as remote sensing, urban planning, and disaster management. This study addresses the inherent challenges in this domain, notably the detection of small objects, managing densely packed elements, and accounting for diverse orientations. We present an in-depth evaluation of an object detection model that integrates the Large Selective Kernel Network (LSKNet)as its backbone with the DiffusionDet head, utilizing the iSAID dataset for empirical analysis. Our approach encompasses the introduction of novel methodologies and extensive ablation studies. These studies critically assess various aspects such as loss functions, box regression techniques, and classification strategies to refine the model's precision in object detection. The paper details the experimental application of the LSKNet backbone in synergy with the DiffusionDet heads, a combination tailored to meet the specific challenges in aerial image object detection. The findings of this research indicate a substantial enhancement in the model's performance, especially in the accuracy-time tradeoff. The proposed model achieves a mean average precision (MAP) of approximately 45.7%, which is a significant improvement, outperforming the RCNN model by 4.7% on the same dataset. This advancement underscores the effectiveness of the proposed modifications and sets a new benchmark in aerial image analysis, paving the way for more accurate and efficient object detection methodologies. The code is publicly available at https://github.com/SashaMatsun/LSKDiffDet", "url": "https://arxiv.org/abs/2311.12956"}, {"metadata": {"arXiv": "2311.13099", "Date": "Wed, 22 Nov 2023 01:58:26 ", "Title": "PIE-NeRF: Physics-based Interactive Elastodynamics with NeRF", "Authors": ["Yutao Feng", "Yintong Shang", "Xuan Li", "Tianjia Shao", "Chenfanfu Jiang", "Yin Yang"], "Categories": "cs.CV cs.AI cs.GR cs.LG"}, "abstract": "We show that physics-based simulations can be seamlessly integrated with NeRF to generate high-quality elastodynamics of real-world objects. Unlike existing methods, we discretize nonlinear hyperelasticity in a meshless way, obviating the necessity for intermediate auxiliary shape proxies like a tetrahedral mesh or voxel grid. A quadratic generalized moving least square (Q-GMLS) is employed to capture nonlinear dynamics and large deformation on the implicit model. Such meshless integration enables versatile simulations of complex and codimensional shapes. We adaptively place the least-square kernels according to the NeRF density field to significantly reduce the complexity of the nonlinear simulation. As a result, physically realistic animations can be conveniently synthesized using our method for a wide range of hyperelastic materials at an interactive rate. For more information, please visit our project page at https://fytalon.github.io/pienerf/.", "url": "https://arxiv.org/abs/2311.13099"}, {"metadata": {"arXiv": "2311.13601", "Date": "Wed, 22 Nov 2023 18:59:48 ", "Title": "Visual In-Context Prompting", "Authors": ["Feng Li", "Qing Jiang", "Hao Zhang", "Tianhe Ren", "Shilong Liu", "Xueyan Zou", "Huaizhe Xu", "Hongyang Li", "Chunyuan Li", "Jianwei Yang", "Lei Zhang", "Jianfeng Gao"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["technical report"]}, "abstract": "In-context prompting in large language models (LLMs) has become a prevalent approach to improve zero-shot capabilities, but this idea is less explored in the vision domain. Existing visual prompting methods focus on referring segmentation to segment the most relevant object, falling short of addressing many generic vision tasks like open-set segmentation and detection. In this paper, we introduce a universal visual in-context prompting framework for both tasks. In particular, we build on top of an encoder-decoder architecture, and develop a versatile prompt encoder to support a variety of prompts like strokes, boxes, and points. We further enhance it to take an arbitrary number of reference image segments as the context. Our extensive explorations show that the proposed visual in-context prompting elicits extraordinary referring and generic segmentation capabilities to refer and detect, yielding competitive performance to close-set in-domain datasets and showing promising results on many open-set segmentation datasets. By joint training on COCO and SA-1B, our model achieves $57.7$ PQ on COCO and $23.2$ PQ on ADE20K. Code will be available at https://github.com/UX-Decoder/DINOv.", "url": "https://arxiv.org/abs/2311.13601"}, {"metadata": {"arXiv": "2311.12970", "Date": "Tue, 21 Nov 2023 20:16:02 ", "Title": "Clustered Policy Decision Ranking", "Authors": ["Mark Levin and Hana Chockler"], "Categories": "cs.LG cs.AI", "Comments": ["4 pages", "4 figures. arXiv admin note: text overlap with arXiv:2111.08415"]}, "abstract": "Policies trained via reinforcement learning (RL) are often very complex even for simple tasks. In an episode with n time steps, a policy will make n decisions on actions to take, many of which may appear non-intuitive to the observer. Moreover, it is not clear which of these decisions directly contribute towards achieving the reward and how significant their contribution is. Given a trained policy, we propose a black-box method based on statistical covariance estimation that clusters the states of the environment and ranks each cluster according to the importance of decisions made in its states. We compare our measure against a previous statistical fault localization based ranking procedure.", "url": "https://arxiv.org/abs/2311.12970"}, {"metadata": {"arXiv": "2311.12999", "Date": "Tue, 21 Nov 2023 21:19:59 ", "Title": "CovarNav: Machine Unlearning via Model Inversion and Covariance Navigation", "Authors": ["Ali Abbasi", "Chayne Thrash", "Elaheh Akbari", "Daniel Zhang", "Soheil Kolouri"], "Categories": "cs.LG cs.AI"}, "abstract": "The rapid progress of AI, combined with its unprecedented public adoption and the propensity of large neural networks to memorize training data, has given rise to significant data privacy concerns. To address these concerns, machine unlearning has emerged as an essential technique to selectively remove the influence of specific training data points on trained models. In this paper, we approach the machine unlearning problem through the lens of continual learning. Given a trained model and a subset of training data designated to be forgotten (i.e., the \"forget set\"), we introduce a three-step process, named CovarNav, to facilitate this forgetting. Firstly, we derive a proxy for the model's training data using a model inversion attack. Secondly, we mislabel the forget set by selecting the most probable class that deviates from the actual ground truth. Lastly, we deploy a gradient projection method to minimize the cross-entropy loss on the modified forget set (i.e., learn incorrect labels for this set) while preventing forgetting of the inverted samples. We rigorously evaluate CovarNav on the CIFAR-10 and Vggface2 datasets, comparing our results with recent benchmarks in the field and demonstrating the efficacy of our proposed approach.", "url": "https://arxiv.org/abs/2311.12999"}, {"metadata": {"arXiv": "2311.13028", "Date": "Tue, 21 Nov 2023 22:29:25 ", "Title": "DMLR: Data-centric Machine Learning Research -- Past, Present and Future", "Authors": ["Luis Oala", "Manil Maskey", "Lilith Bat-Leah", "Alicia Parrish", "Nezihe Merve G\\\"urel", "Tzu-Sheng Kuo", "Yang Liu", "Rotem Dror", "Danilo Brajovic", "Xiaozhe Yao", "Max Bartolo", "William A Gaviria Rojas", "Ryan Hileman", "Rainier Aliment", "Michael W. Mahoney", "Meg Risdal", "Matthew Lease", "Wojciech Samek", "Debojyoti Dutta", "Curtis G Northcutt", "Cody Coleman", "Braden Hancock", "Bernard Koch", "Girmaw Abebe Tadesse", "Bojan Karla\\v{s}", "Ahmed Alaa", "Adji Bousso Dieng", "Natasha Noy", "Vijay Janapa Reddi", "James Zou", "Praveen Paritosh", "Mihaela van der Schaar", "Kurt Bollacker", "Lora Aroyo", "Ce Zhang", "Joaquin Vanschoren", "Isabelle Guyon", "Peter Mattson"], "Categories": "cs.LG cs.AI cs.DC eess.SP", "Comments": ["This editorial report accompanies the inaugural Data-centric Machine Learning Research (DMLR) Workshop that took place at ICML 2023 https://dmlr.ai/"]}, "abstract": "Drawing from discussions at the inaugural DMLR workshop at ICML 2023 and meetings prior, in this report we outline the relevance of community engagement and infrastructure development for the creation of next-generation public datasets that will advance machine learning science. We chart a path forward as a collective effort to sustain the creation and maintenance of these datasets and methods towards positive scientific, societal and business impact.", "url": "https://arxiv.org/abs/2311.13028"}, {"metadata": {"arXiv": "2311.13087", "Date": "Wed, 22 Nov 2023 01:32:06 ", "Title": "Predict-Then-Optimize by Proxy: Learning Joint Models of Prediction and Optimization", "Authors": ["James Kotary", "Vincenzo Di Vito", "Jacob Christopher", "Pascal Van Hentenryck", "Ferdinando Fioretto"], "Categories": "cs.LG cs.AI"}, "abstract": "Many real-world decision processes are modeled by optimization problems whose defining parameters are unknown and must be inferred from observable data. The Predict-Then-Optimize framework uses machine learning models to predict unknown parameters of an optimization problem from features before solving. Recent works show that decision quality can be improved in this setting by solving and differentiating the optimization problem in the training loop, enabling end-to-end training with loss functions defined directly on the resulting decisions. However, this approach can be inefficient and requires handcrafted, problem-specific rules for backpropagation through the optimization step. This paper proposes an alternative method, in which optimal solutions are learned directly from the observable features by predictive models. The approach is generic, and based on an adaptation of the Learning-to-Optimize paradigm, from which a rich variety of existing techniques can be employed. Experimental evaluations show the ability of several Learning-to-Optimize methods to provide efficient, accurate, and flexible solutions to an array of challenging Predict-Then-Optimize problems.", "url": "https://arxiv.org/abs/2311.13087"}, {"metadata": {"arXiv": "2311.13118", "Date": "Wed, 22 Nov 2023 02:45:01 ", "Title": "Combatting Human Trafficking in the Cyberspace: A Natural Language Processing-Based Methodology to Analyze the Language in Online Advertisements", "Authors": ["Alejandro Rodriguez Perez and Pablo Rivas"], "Categories": "cs.LG cs.AI cs.CL cs.CY cs.SI", "MSC-class": "68T50, 62H30, 91C99, 68T068T50, 62H30, 91C99, 68T01", "ACM-class": "I.2.7; I.5.4; K.4.1; K.4.2", "DOI": "10.6084/m9.figshare.24602823.v1"}, "abstract": "This project tackles the pressing issue of human trafficking in online C2C marketplaces through advanced Natural Language Processing (NLP) techniques. We introduce a novel methodology for generating pseudo-labeled datasets with minimal supervision, serving as a rich resource for training state-of-the-art NLP models. Focusing on tasks like Human Trafficking Risk Prediction (HTRP) and Organized Activity Detection (OAD), we employ cutting-edge Transformer models for analysis. A key contribution is the implementation of an interpretability framework using Integrated Gradients, providing explainable insights crucial for law enforcement. This work not only fills a critical gap in the literature but also offers a scalable, machine learning-driven approach to combat human exploitation online. It serves as a foundation for future research and practical applications, emphasizing the role of machine learning in addressing complex social issues.", "url": "https://arxiv.org/abs/2311.13118"}, {"metadata": {"arXiv": "2311.13133", "Date": "Wed, 22 Nov 2023 03:37:01 ", "Title": "LIMIT: Less Is More for Instruction Tuning Across Evaluation Paradigms", "Authors": ["Aditi Jha", "Sam Havens", "Jeremey Dohmann", "Alex Trott", "Jacob Portes"], "Categories": "cs.LG cs.AI cs.CL", "Comments": ["36 pages", "12 figures", "NeurIPS 2023 Workshop on Instruction Tuning and Instruction Following"]}, "abstract": "Large Language Models are traditionally finetuned on large instruction datasets. However recent studies suggest that small, high-quality datasets can suffice for general purpose instruction following. This lack of consensus surrounding finetuning best practices is in part due to rapidly diverging approaches to LLM evaluation. In this study, we ask whether a small amount of diverse finetuning samples can improve performance on both traditional perplexity-based NLP benchmarks, and on open-ended, model-based evaluation. We finetune open-source MPT-7B and MPT-30B models on instruction finetuning datasets of various sizes ranging from 1k to 60k samples. We find that subsets of 1k-6k instruction finetuning samples are sufficient to achieve good performance on both (1) traditional NLP benchmarks and (2) model-based evaluation. Finally, we show that mixing textbook-style and open-ended QA finetuning datasets optimizes performance on both evaluation paradigms.", "url": "https://arxiv.org/abs/2311.13133"}, {"metadata": {"arXiv": "2311.13169", "Date": "Wed, 22 Nov 2023 05:25:24 ", "Title": "SiGeo: Sub-One-Shot NAS via Information Theory and Geometry of Loss Landscape", "Authors": ["Hua Zheng and Kuang-Hung Liu and Igor Fedorov and Xin Zhang and Wen-Yen Chen and Wei Wen"], "Categories": "cs.LG cs.AI", "Comments": ["24 pages", "7 figures"]}, "abstract": "Neural Architecture Search (NAS) has become a widely used tool for automating neural network design. While one-shot NAS methods have successfully reduced computational requirements, they often require extensive training. On the other hand, zero-shot NAS utilizes training-free proxies to evaluate a candidate architecture's test performance but has two limitations: (1) inability to use the information gained as a network improves with training and (2) unreliable performance, particularly in complex domains like RecSys, due to the multi-modal data inputs and complex architecture configurations. To synthesize the benefits of both methods, we introduce a \"sub-one-shot\" paradigm that serves as a bridge between zero-shot and one-shot NAS. In sub-one-shot NAS, the supernet is trained using only a small subset of the training data, a phase we refer to as \"warm-up.\" Within this framework, we present SiGeo, a proxy founded on a novel theoretical framework that connects the supernet warm-up with the efficacy of the proxy. Extensive experiments have shown that SiGeo, with the benefit of warm-up, consistently outperforms state-of-the-art NAS proxies on various established NAS benchmarks. When a supernet is warmed up, it can achieve comparable performance to weight-sharing one-shot NAS methods, but with a significant reduction ($\\sim 60$\\%) in computational costs.", "url": "https://arxiv.org/abs/2311.13169"}, {"metadata": {"arXiv": "2311.13171", "Date": "Wed, 22 Nov 2023 05:28:59 ", "Title": "ComPEFT: Compression for Communicating Parameter Efficient Updates via Sparsification and Quantization", "Authors": ["Prateek Yadav", "Leshem Choshen", "Colin Raffel", "Mohit Bansal"], "Categories": "cs.LG cs.AI cs.CL", "Comments": ["25 Pages", "6 Figures", "16 Tables"]}, "abstract": "Parameter-efficient fine-tuning (PEFT) techniques make it possible to efficiently adapt a language model to create \"expert\" models that specialize to new tasks or domains. Recent techniques in model merging and compositional generalization leverage these expert models by dynamically composing modules to improve zero/few-shot generalization. Despite the efficiency of PEFT methods, the size of expert models can make it onerous to retrieve expert models per query over high-latency networks like the Internet or serve multiple experts on a single GPU. To address these issues, we present ComPEFT, a novel method for compressing fine-tuning residuals (task vectors) of PEFT based models. ComPEFT employs sparsification and ternary quantization to reduce the size of the PEFT module without performing any additional retraining while preserving or enhancing model performance. In extensive evaluation across T5, T0, and LLaMA-based models with 200M - 65B parameters, ComPEFT achieves compression ratios of 8x - 50x. In particular, we show that ComPEFT improves with scale - stronger models exhibit higher compressibility and better performance. For example, we show that ComPEFT applied to LLaMA outperforms QLoRA by 4.16% on MMLU with a storage size reduction of up to 26x. In addition, we show that the compressed experts produced by ComPEFT maintain few-shot compositional generalization capabilities, facilitate efficient communication and computation, and exhibit enhanced performance when merged. Lastly, we provide an analysis of different method components, compare it with other PEFT methods, and test ComPEFT's efficacy for compressing the residual of full-finetuning. Our code is available at https://github.com/prateeky2806/compeft.", "url": "https://arxiv.org/abs/2311.13171"}, {"metadata": {"arXiv": "2311.13231", "Date": "Wed, 22 Nov 2023 08:42:46 ", "Title": "Using Human Feedback to Fine-tune Diffusion Models without Any Reward Model", "Authors": ["Kai Yang", "Jian Tao", "Jiafei Lyu", "Chunjiang Ge", "Jiaxin Chen", "Qimai Li", "Weihan Shen", "Xiaolong Zhu", "Xiu Li"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "Using reinforcement learning with human feedback (RLHF) has shown significant promise in fine-tuning diffusion models. Previous methods start by training a reward model that aligns with human preferences, then leverage RL techniques to fine-tune the underlying models. However, crafting an efficient reward model demands extensive datasets, optimal architecture, and manual hyperparameter tuning, making the process both time and cost-intensive. The direct preference optimization (DPO) method, effective in fine-tuning large language models, eliminates the necessity for a reward model. However, the extensive GPU memory requirement of the diffusion model's denoising process hinders the direct application of the DPO method. To address this issue, we introduce the Direct Preference for Denoising Diffusion Policy Optimization (D3PO) method to directly fine-tune diffusion models. The theoretical analysis demonstrates that although D3PO omits training a reward model, it effectively functions as the optimal reward model trained using human feedback data to guide the learning process. This approach requires no training of a reward model, proving to be more direct, cost-effective, and minimizing computational overhead. In experiments, our method uses the relative scale of objectives as a proxy for human preference, delivering comparable results to methods using ground-truth rewards. Moreover, D3PO demonstrates the ability to reduce image distortion rates and generate safer images, overcoming challenges lacking robust reward models.", "url": "https://arxiv.org/abs/2311.13231"}, {"metadata": {"arXiv": "2311.13267", "Date": "Wed, 22 Nov 2023 09:37:33 ", "Title": "FedFN: Feature Normalization for Alleviating Data Heterogeneity Problem in Federated Learning", "Authors": ["Seongyoon Kim", "Gihun Lee", "Jaehoon Oh", "Se-Young Yun"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["NeurIPS Workshop: \"Federated Learning in the Age of Foundation Models\" 2023"]}, "abstract": "Federated Learning (FL) is a collaborative method for training models while preserving data privacy in decentralized settings. However, FL encounters challenges related to data heterogeneity, which can result in performance degradation. In our study, we observe that as data heterogeneity increases, feature representation in the FedAVG model deteriorates more significantly compared to classifier weight. Additionally, we observe that as data heterogeneity increases, the gap between higher feature norms for observed classes, obtained from local models, and feature norms of unobserved classes widens, in contrast to the behavior of classifier weight norms. This widening gap extends to encompass the feature norm disparities between local and the global models. To address these issues, we introduce Federated Averaging with Feature Normalization Update (FedFN), a straightforward learning method. We demonstrate the superior performance of FedFN through extensive experiments, even when applied to pretrained ResNet18. Subsequently, we confirm the applicability of FedFN to foundation models.", "url": "https://arxiv.org/abs/2311.13267"}, {"metadata": {"arXiv": "2311.13294", "Date": "Wed, 22 Nov 2023 10:23:14 ", "Title": "Probabilistic Inference in Reinforcement Learning Done Right", "Authors": ["Jean Tarbouriech", "Tor Lattimore", "Brendan O'Donoghue"], "Categories": "cs.LG cs.AI", "Comments": ["NeurIPS 2023"]}, "abstract": "A popular perspective in Reinforcement learning (RL) casts the problem as probabilistic inference on a graphical model of the Markov decision process (MDP). The core object of study is the probability of each state-action pair being visited under the optimal policy. Previous approaches to approximate this quantity can be arbitrarily poor, leading to algorithms that do not implement genuine statistical inference and consequently do not perform well in challenging problems. In this work, we undertake a rigorous Bayesian treatment of the posterior probability of state-action optimality and clarify how it flows through the MDP. We first reveal that this quantity can indeed be used to generate a policy that explores efficiently, as measured by regret. Unfortunately, computing it is intractable, so we derive a new variational Bayesian approximation yielding a tractable convex optimization problem and establish that the resulting policy also explores efficiently. We call our approach VAPOR and show that it has strong connections to Thompson sampling, K-learning, and maximum entropy exploration. We conclude with some experiments demonstrating the performance advantage of a deep RL version of VAPOR.", "url": "https://arxiv.org/abs/2311.13294"}, {"metadata": {"arXiv": "2311.13326", "Date": "Wed, 22 Nov 2023 11:42:50 ", "Title": "Curriculum Learning and Imitation Learning for Model-free Control on Financial Time-series", "Authors": ["Woosung Koh", "Insu Choi", "Yuntae Jang", "Gimin Kang", "Woo Chang Kim"], "Categories": "cs.LG cs.AI q-fin.PM", "Comments": ["preprint"]}, "abstract": "Curriculum learning and imitation learning have been leveraged extensively in the robotics domain. However, minimal research has been done on leveraging these ideas on control tasks over highly stochastic time-series data. Here, we theoretically and empirically explore these approaches in a representative control task over complex time-series data. We implement the fundamental ideas of curriculum learning via data augmentation, while imitation learning is implemented via policy distillation from an oracle. Our findings reveal that curriculum learning should be considered a novel direction in improving control-task performance over complex time-series. Our ample random-seed out-sample empirics and ablation studies are highly encouraging for curriculum learning for time-series control. These findings are especially encouraging as we tune all overlapping hyperparameters on the baseline -- giving an advantage to the baseline. On the other hand, we find that imitation learning should be used with caution.", "url": "https://arxiv.org/abs/2311.13326"}, {"metadata": {"arXiv": "2311.13341", "Date": "Wed, 22 Nov 2023 12:08:01 ", "Title": "Learning principle and mathematical realization of the learning mechanism in the brain", "Authors": ["Taisuke Katayose"], "Categories": "cs.LG cs.AI cs.IT math.IT q-bio.NC stat.ML", "Comments": ["31 pages", "14 figures"]}, "abstract": "While deep learning has achieved remarkable success, there is no clear explanation about why it works so well. In order to discuss this question quantitatively, we need a mathematical framework that explains what learning is in the first place. After several considerations, we succeeded in constructing a mathematical framework that can provide a unified understanding of all types of learning, including deep learning and learning in the brain. We call it learning principle, and it follows that all learning is equivalent to estimating the probability of input data. We not only derived this principle, but also mentioned its application to actual machine learning models. For example, we found that conventional supervised learning is equivalent to estimating conditional probabilities, and succeeded in making supervised learning more effective and generalized. We also proposed a new method of defining the values of estimated probability using differentiation, and showed that unsupervised learning can be performed on arbitrary dataset without any prior knowledge. Namely, this method is a general-purpose machine learning in the true sense. Moreover, we succeeded in describing the learning mechanism in the brain by considering the time evolution of a fully or partially connected model and applying this new method. The learning principle provides solutions to many unsolved problems in deep learning and cognitive neuroscience.", "url": "https://arxiv.org/abs/2311.13341"}, {"metadata": {"arXiv": "2311.13381", "Date": "Wed, 22 Nov 2023 13:20:59 ", "Title": "Confidant: Customizing Transformer-based LLMs via Collaborative Edge Training", "Authors": ["Yuhao Chen", "Yuxuan Yan", "Qianqian Yang", "Yuanchao Shu", "Shibo He", "Jiming Chen"], "Categories": "cs.LG cs.AI cs.DC", "Comments": ["6 pages", "7 figures; Submitted to HotMobile 2024"]}, "abstract": "Transformer-based large language models (LLMs) have demonstrated impressive capabilities in a variety of natural language processing (NLP) tasks. Nonetheless, it is challenging to deploy and fine-tune LLMs on mobile edge devices with limited computing, memory, and energy budgets. In this paper, we propose Confidant, a multi-backend collaborative training framework for customizing state-of-the-art LLMs on commodity mobile devices like smartphones. Confidant partitions an LLM into several sub-models so that each fits into a mobile device's memory. A pipeline parallel training mechanism is further developed to ensure fast and efficient distributed training. In addition, we propose a novel backend scheduler to allocate different attention heads to heterogeneous compute hardware, including mobile CPU and GPUs, to maximize the compute resource utilization on each edge device. Our preliminary experimental results show that Confidant achieves at most 45.3% memory reduction and 8.03x inference speedup in practical settings.", "url": "https://arxiv.org/abs/2311.13381"}, {"metadata": {"arXiv": "2311.13414", "Date": "Wed, 22 Nov 2023 14:20:15 ", "Title": "From Images to Connections: Can DQN with GNNs learn the Strategic Game of Hex?", "Authors": ["Yannik Keller", "Jannis Bl\\\"uml", "Gopika Sudhakaran and Kristian Kersting"], "Categories": "cs.LG cs.AI cs.GT"}, "abstract": "The gameplay of strategic board games such as chess, Go and Hex is often characterized by combinatorial, relational structures -- capturing distinct interactions and non-local patterns -- and not just images. Nonetheless, most common self-play reinforcement learning (RL) approaches simply approximate policy and value functions using convolutional neural networks (CNN). A key feature of CNNs is their relational inductive bias towards locality and translational invariance. In contrast, graph neural networks (GNN) can encode more complicated and distinct relational structures. Hence, we investigate the crucial question: Can GNNs, with their ability to encode complex connections, replace CNNs in self-play reinforcement learning? To this end, we do a comparison with Hex -- an abstract yet strategically rich board game -- serving as our experimental platform. Our findings reveal that GNNs excel at dealing with long range dependency situations in game states and are less prone to overfitting, but also showing a reduced proficiency in discerning local patterns. This suggests a potential paradigm shift, signaling the use of game-specific structures to reshape self-play reinforcement learning.", "url": "https://arxiv.org/abs/2311.13414"}, {"metadata": {"arXiv": "2311.13443", "Date": "Wed, 22 Nov 2023 15:07:59 ", "Title": "Guided Flows for Generative Modeling and Decision Making", "Authors": ["Qinqing Zheng", "Matt Le", "Neta Shaul", "Yaron Lipman", "Aditya Grover", "Ricky T. Q. Chen"], "Categories": "cs.LG cs.AI cs.CV cs.RO stat.ML"}, "abstract": "Classifier-free guidance is a key component for improving the performance of conditional generative models for many downstream tasks. It drastically improves the quality of samples produced, but has so far only been used for diffusion models. Flow Matching (FM), an alternative simulation-free approach, trains Continuous Normalizing Flows (CNFs) based on regressing vector fields. It remains an open question whether classifier-free guidance can be performed for Flow Matching models, and to what extent does it improve performance. In this paper, we explore the usage of Guided Flows for a variety of downstream applications involving conditional image generation, speech synthesis, and reinforcement learning. In particular, we are the first to apply flow models to the offline reinforcement learning setting. We also show that Guided Flows significantly improves the sample quality in image generation and zero-shot text-to-speech synthesis, and can make use of drastically low amounts of computation without affecting the agent's overall performance.", "url": "https://arxiv.org/abs/2311.13443"}, {"metadata": {"arXiv": "2311.13502", "Date": "Wed, 22 Nov 2023 16:20:24 ", "Title": "Bitformer: An efficient Transformer with bitwise operation-based attention for Big Data Analytics at low-cost low-precision devices", "Authors": ["Gaoxiang Duan and Junkai Zhang and Xiaoying Zheng and Yongxin Zhu"], "Categories": "cs.LG cs.AI"}, "abstract": "In the current landscape of large models, the Transformer stands as a cornerstone, playing a pivotal role in shaping the trajectory of modern models. However, its application encounters challenges attributed to the substantial computational intricacies intrinsic to its attention mechanism. Moreover, its reliance on high-precision floating-point operations presents specific hurdles, particularly evident in computation-intensive scenarios such as edge computing environments. These environments, characterized by resource-constrained devices and a preference for lower precision, necessitate innovative solutions. To tackle the exacting data processing demands posed by edge devices, we introduce the Bitformer model, an inventive extension of the Transformer paradigm. Central to this innovation is a novel attention mechanism that adeptly replaces conventional floating-point matrix multiplication with bitwise operations. This strategic substitution yields dual advantages. Not only does it maintain the attention mechanism's prowess in capturing intricate long-range information dependencies, but it also orchestrates a profound reduction in the computational complexity inherent in the attention operation. The transition from an $O(n^2d)$ complexity, typical of floating-point operations, to an $O(n^2T)$ complexity characterizing bitwise operations, substantiates this advantage. Notably, in this context, the parameter $T$ remains markedly smaller than the conventional dimensionality parameter $d$. The Bitformer model in essence endeavors to reconcile the indomitable requirements of modern computing landscapes with the constraints posed by edge computing scenarios. By forging this innovative path, we bridge the gap between high-performing models and resource-scarce environments, thus unveiling a promising trajectory for further advancements in the field.", "url": "https://arxiv.org/abs/2311.13502"}, {"metadata": {"arXiv": "2311.13541", "Date": "Wed, 22 Nov 2023 17:30:41 ", "Title": "Linear Log-Normal Attention with Unbiased Concentration", "Authors": ["Yury Nahshan", "Joseph Kampeas and Emir Haleva"], "Categories": "cs.LG cs.AI", "Comments": ["22 pages", "20 figures", "5 tables", "submitted to ICLR2024"], "ACM-class": "I.7.0; G.3"}, "abstract": "Transformer models have achieved remarkable results in a wide range of applications. However, their scalability is hampered by the quadratic time and memory complexity of the self-attention mechanism concerning the sequence length. This limitation poses a substantial obstacle when dealing with long documents or high-resolution images. In this work, we study the self-attention mechanism by analyzing the distribution of the attention matrix and its concentration ability. Furthermore, we propose instruments to measure these quantities and introduce a novel self-attention mechanism, Linear Log-Normal Attention, designed to emulate the distribution and concentration behavior of the original self-attention. Our experimental results on popular natural language benchmarks reveal that our proposed Linear Log-Normal Attention outperforms other linearized attention alternatives, offering a promising avenue for enhancing the scalability of transformer models. Our code is available in supplementary materials.", "url": "https://arxiv.org/abs/2311.13541"}, {"metadata": {"arXiv": "2311.13569", "Date": "Mon, 13 Nov 2023 12:24:54 ", "Title": "Combinatorial Optimization with Policy Adaptation using Latent Space Search", "Authors": ["Felix Chalumeau", "Shikha Surana", "Clement Bonnet", "Nathan Grinsztajn", "Arnu Pretorius", "Alexandre Laterre", "Thomas D. Barrett"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted at Neurips 2023. Small updates in results reported"]}, "abstract": "Combinatorial Optimization underpins many real-world applications and yet, designing performant algorithms to solve these complex, typically NP-hard, problems remains a significant research challenge. Reinforcement Learning (RL) provides a versatile framework for designing heuristics across a broad spectrum of problem domains. However, despite notable progress, RL has not yet supplanted industrial solvers as the go-to solution. Current approaches emphasize pre-training heuristics that construct solutions but often rely on search procedures with limited variance, such as stochastically sampling numerous solutions from a single policy or employing computationally expensive fine-tuning of the policy on individual problem instances. Building on the intuition that performant search at inference time should be anticipated during pre-training, we propose COMPASS, a novel RL approach that parameterizes a distribution of diverse and specialized policies conditioned on a continuous latent space. We evaluate COMPASS across three canonical problems - Travelling Salesman, Capacitated Vehicle Routing, and Job-Shop Scheduling - and demonstrate that our search strategy (i) outperforms state-of-the-art approaches on 11 standard benchmarking tasks and (ii) generalizes better, surpassing all other approaches on a set of 18 procedurally transformed instance distributions.", "url": "https://arxiv.org/abs/2311.13569"}, {"metadata": {"arXiv": "2311.13571", "Date": "Thu, 09 Nov 2023 17:49:07 ", "Title": "Ball Mill Fault Prediction Based on Deep Convolutional Auto-Encoding Network", "Authors": ["Xinkun Ai", "Kun Liu", "Wei Zheng", "Yonggang Fan", "Xinwu Wu", "Peilong Zhang", "LiYe Wang", "JanFeng Zhu", "Yuan Pan"], "Categories": "cs.LG cs.AI", "Comments": ["9 pages", "11 figures"]}, "abstract": "Ball mills play a critical role in modern mining operations, making their bearing failures a significant concern due to the potential loss of production efficiency and economic consequences. This paper presents an anomaly detection method based on Deep Convolutional Auto-encoding Neural Networks (DCAN) for addressing the issue of ball mill bearing fault detection. The proposed approach leverages vibration data collected during normal operation for training, overcoming challenges such as labeling issues and data imbalance often encountered in supervised learning methods. DCAN includes the modules of convolutional feature extraction and transposed convolutional feature reconstruction, demonstrating exceptional capabilities in signal processing and feature extraction. Additionally, the paper describes the practical deployment of the DCAN-based anomaly detection model for bearing fault detection, utilizing data from the ball mill bearings of Wuhan Iron & Steel Resources Group and fault data from NASA's bearing vibration dataset. Experimental results validate the DCAN model's reliability in recognizing fault vibration patterns. This method holds promise for enhancing bearing fault detection efficiency, reducing production interruptions, and lowering maintenance costs.", "url": "https://arxiv.org/abs/2311.13571"}, {"metadata": {"arXiv": "2311.13580", "Date": "Wed, 22 Nov 2023 18:34:49 ", "Title": "$\\sigma$-PCA: a unified neural model for linear and nonlinear principal component analysis", "Authors": ["Fahdi Kanavati", "Lucy Katsnith", "Masayuki Tsuneki"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "Linear principal component analysis (PCA), nonlinear PCA, and linear independent component analysis (ICA) -- those are three methods with single-layer autoencoder formulations for learning linear transformations from data. Linear PCA learns orthogonal transformations (rotations) that orient axes to maximise variance, but it suffers from a subspace rotational indeterminacy: it fails to find a unique rotation for axes that share the same variance. Both nonlinear PCA and linear ICA reduce the subspace indeterminacy from rotational to permutational by maximising statistical independence under the assumption of unit variance. The main difference between them is that nonlinear PCA only learns rotations while linear ICA learns not just rotations but any linear transformation with unit variance. The relationship between all three can be understood by the singular value decomposition of the linear ICA transformation into a sequence of rotation, scale, rotation. Linear PCA learns the first rotation; nonlinear PCA learns the second. The scale is simply the inverse of the standard deviations. The problem is that, in contrast to linear PCA, conventional nonlinear PCA cannot be used directly on the data to learn the first rotation, the first being special as it reduces dimensionality and orders by variances. In this paper, we have identified the cause, and as a solution we propose $\\sigma$-PCA: a unified neural model for linear and nonlinear PCA as single-layer autoencoders. One of its key ingredients: modelling not just the rotation but also the scale -- the variances. This model bridges the disparity between linear and nonlinear PCA. And so, like linear PCA, it can learn a semi-orthogonal transformation that reduces dimensionality and orders by variances, but, unlike linear PCA, it does not suffer from rotational indeterminacy.", "url": "https://arxiv.org/abs/2311.13580"}, {"metadata": {"arXiv": "2311.13594", "Date": "Wed, 22 Nov 2023 18:55:25 ", "Title": "Labeling Neural Representations with Inverse Recognition", "Authors": ["Kirill Bykov", "Laura Kopf", "Shinichi Nakajima", "Marius Kloft", "Marina M.-C. H\\\"ohne"], "Categories": "cs.LG cs.AI stat.ML", "Comments": ["24 pages", "16 figures"], "Journal-ref": "37th Conference on Neural Information Processing Systems (NeurIPS 2023)"}, "abstract": "Deep Neural Networks (DNNs) demonstrated remarkable capabilities in learning complex hierarchical data representations, but the nature of these representations remains largely unknown. Existing global explainability methods, such as Network Dissection, face limitations such as reliance on segmentation masks, lack of statistical significance testing, and high computational demands. We propose Inverse Recognition (INVERT), a scalable approach for connecting learned representations with human-understandable concepts by leveraging their capacity to discriminate between these concepts. In contrast to prior work, INVERT is capable of handling diverse types of neurons, exhibits less computational complexity, and does not rely on the availability of segmentation masks. Moreover, INVERT provides an interpretable metric assessing the alignment between the representation and its corresponding explanation and delivering a measure of statistical significance, emphasizing its utility and credibility. We demonstrate the applicability of INVERT in various scenarios, including the identification of representations affected by spurious correlations, and the interpretation of the hierarchical structure of decision-making within the models.", "url": "https://arxiv.org/abs/2311.13594"}, {"metadata": {"arXiv": "2311.12943", "Date": "Tue, 21 Nov 2023 19:15:17 ", "Title": "InteRACT: Transformer Models for Human Intent Prediction Conditioned on Robot Actions", "Authors": ["Kushal Kedia", "Atiksh Bhardwaj", "Prithwish Dan", "Sanjiban Choudhury"], "Categories": "cs.RO cs.AI cs.LG cs.MA"}, "abstract": "In collaborative human-robot manipulation, a robot must predict human intents and adapt its actions accordingly to smoothly execute tasks. However, the human's intent in turn depends on actions the robot takes, creating a chicken-or-egg problem. Prior methods ignore such inter-dependency and instead train marginal intent prediction models independent of robot actions. This is because training conditional models is hard given a lack of paired human-robot interaction datasets. Can we instead leverage large-scale human-human interaction data that is more easily accessible? Our key insight is to exploit a correspondence between human and robot actions that enables transfer learning from human-human to human-robot data. We propose a novel architecture, InteRACT, that pre-trains a conditional intent prediction model on large human-human datasets and fine-tunes on a small human-robot dataset. We evaluate on a set of real-world collaborative human-robot manipulation tasks and show that our conditional model improves over various marginal baselines. We also introduce new techniques to tele-operate a 7-DoF robot arm and collect a diverse range of human-robot collaborative manipulation data, which we open-source.", "url": "https://arxiv.org/abs/2311.12943"}, {"metadata": {"arXiv": "2311.13081", "Date": "Wed, 22 Nov 2023 01:06:45 ", "Title": "Learning to Fly in Seconds", "Authors": ["Jonas Eschmann", "Dario Albani", "Giuseppe Loianno"], "Categories": "cs.RO cs.AI cs.LG cs.SY eess.SY"}, "abstract": "Learning-based methods, particularly Reinforcement Learning (RL), hold great promise for streamlining deployment, enhancing performance, and achieving generalization in the control of autonomous multirotor aerial vehicles. Deep RL has been able to control complex systems with impressive fidelity and agility in simulation but the simulation-to-reality transfer often brings a hard-to-bridge reality gap. Moreover, RL is commonly plagued by prohibitively long training times. In this work, we propose a novel asymmetric actor-critic-based architecture coupled with a highly reliable RL-based training paradigm for end-to-end quadrotor control. We show how curriculum learning and a highly optimized simulator enhance sample complexity and lead to fast training times. To precisely discuss the challenges related to low-level/end-to-end multirotor control, we also introduce a taxonomy that classifies the existing levels of control abstractions as well as non-linearities and domain parameters. Our framework enables Simulation-to-Reality (Sim2Real) transfer for direct RPM control after only 18 seconds of training on a consumer-grade laptop as well as its deployment on microcontrollers to control a multirotor under real-time guarantees. Finally, our solution exhibits competitive performance in trajectory tracking, as demonstrated through various experimental comparisons with existing state-of-the-art control solutions using a real Crazyflie nano quadrotor. We open source the code including a very fast multirotor dynamics simulator that can simulate about 5 months of flight per second on a laptop GPU. The fast training times and deployment to a cheap, off-the-shelf quadrotor lower the barriers to entry and help democratize the research and development of these systems.", "url": "https://arxiv.org/abs/2311.13081"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

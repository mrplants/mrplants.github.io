<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2308.09778", "Date": "Fri, 18 Aug 2023 18:58:54 ", "Title": "Towards Grounded Visual Spatial Reasoning in Multi-Modal Vision Language Models", "Authors": ["Navid Rajabi", "Jana Kosecka"], "Categories": "cs.CV cs.CL cs.LG"}, "abstract": "With the advances in large scale vision-and-language models (VLMs) it is of interest to assess their performance on various visual reasoning tasks such as counting, referring expressions and general visual question answering. The focus of this work is to study the ability of these models to understanding spatial relations. Previously, this has been tackled using image-text matching (Liu, Emerson, and Collier 2022) or visual question answering task, both showing poor performance and a large gap compared to human performance. To better understand the gap, we present fine-grained compositional grounding of spatial relationships and propose a bottom up approach for ranking spatial clauses and evaluating the performance of spatial relationship reasoning task. We propose to combine the evidence from grounding noun phrases corresponding to objects and their locations to compute the final rank of the spatial clause. We demonstrate the approach on representative vision-language models (Tan and Bansal 2019; Gupta et al. 2022; Kamath et al. 2021) and compare and highlight their abilities to reason about spatial relationships.", "url": "https://arxiv.org/abs/2308.09778"}, {"metadata": {"arXiv": "2308.09835", "Date": "Fri, 18 Aug 2023 22:00:53 ", "Title": "Microscopy Image Segmentation via Point and Shape Regularized Data Synthesis", "Authors": ["Shijie Li", "Mengwei Ren", "Thomas Ach", "Guido Gerig"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted by The 3rd MICCAI Workshop on Data Augmentation", "Labeling", "and Imperfections"]}, "abstract": "Current deep learning-based approaches for the segmentation of microscopy images heavily rely on large amount of training data with dense annotation, which is highly costly and laborious in practice. Compared to full annotation where the complete contour of objects is depicted, point annotations, specifically object centroids, are much easier to acquire and still provide crucial information about the objects for subsequent segmentation. In this paper, we assume access to point annotations only during training and develop a unified pipeline for microscopy image segmentation using synthetically generated training data. Our framework includes three stages: (1) it takes point annotations and samples a pseudo dense segmentation mask constrained with shape priors; (2) with an image generative model trained in an unpaired manner, it translates the mask to a realistic microscopy image regularized by object level consistency; (3) the pseudo masks along with the synthetic images then constitute a pairwise dataset for training an ad-hoc segmentation model. On the public MoNuSeg dataset, our synthesis pipeline produces more diverse and realistic images than baseline models while maintaining high coherence between input masks and generated images. When using the identical segmentation backbones, the models trained on our synthetic dataset significantly outperform those trained with pseudo-labels or baseline-generated images. Moreover, our framework achieves comparable results to models trained on authentic microscopy images with dense labels, demonstrating its potential as a reliable and highly efficient alternative to labor-intensive manual pixel-wise annotations in microscopy image segmentation. The code is available.", "url": "https://arxiv.org/abs/2308.09835"}, {"metadata": {"arXiv": "2308.09878", "Date": "Sat, 19 Aug 2023 02:11:49 ", "Title": "DatasetEquity: Are All Samples Created Equal? In The Quest For Equity Within Datasets", "Authors": ["Shubham Shrivastava", "Xianling Zhang", "Sushruth Nagesh", "Armin Parchami"], "Categories": "cs.CV cs.LG", "Comments": ["ICCV 2023 Workshop"]}, "abstract": "Data imbalance is a well-known issue in the field of machine learning, attributable to the cost of data collection, the difficulty of labeling, and the geographical distribution of the data. In computer vision, bias in data distribution caused by image appearance remains highly unexplored. Compared to categorical distributions using class labels, image appearance reveals complex relationships between objects beyond what class labels provide. Clustering deep perceptual features extracted from raw pixels gives a richer representation of the data. This paper presents a novel method for addressing data imbalance in machine learning. The method computes sample likelihoods based on image appearance using deep perceptual embeddings and clustering. It then uses these likelihoods to weigh samples differently during training with a proposed \\textbf{Generalized Focal Loss} function. This loss can be easily integrated with deep learning algorithms. Experiments validate the method's effectiveness across autonomous driving vision datasets including KITTI and nuScenes. The loss function improves state-of-the-art 3D object detection methods, achieving over $200\\%$ AP gains on under-represented classes (Cyclist) in the KITTI dataset. The results demonstrate the method is generalizable, complements existing techniques, and is particularly beneficial for smaller datasets and rare classes. Code is available at: $\\texttt{https://github.com/towardsautonomy/DatasetEquity}$", "url": "https://arxiv.org/abs/2308.09878"}, {"metadata": {"arXiv": "2308.09887", "Date": "Sat, 19 Aug 2023 02:44:25 ", "Title": "Calibrating Uncertainty for Semi-Supervised Crowd Counting", "Authors": ["Chen Li", "Xiaoling Hu", "Shahira Abousamra", "Chao Chen"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted by ICCV'23"]}, "abstract": "Semi-supervised crowd counting is an important yet challenging task. A popular approach is to iteratively generate pseudo-labels for unlabeled data and add them to the training set. The key is to use uncertainty to select reliable pseudo-labels. In this paper, we propose a novel method to calibrate model uncertainty for crowd counting. Our method takes a supervised uncertainty estimation strategy to train the model through a surrogate function. This ensures the uncertainty is well controlled throughout the training. We propose a matching-based patch-wise surrogate function to better approximate uncertainty for crowd counting tasks. The proposed method pays a sufficient amount of attention to details, while maintaining a proper granularity. Altogether our method is able to generate reliable uncertainty estimation, high quality pseudolabels, and achieve state-of-the-art performance in semisupervised crowd counting.", "url": "https://arxiv.org/abs/2308.09887"}, {"metadata": {"arXiv": "2308.09889", "Date": "Sat, 19 Aug 2023 02:51:00 ", "Title": "DUAW: Data-free Universal Adversarial Watermark against Stable Diffusion Customization", "Authors": ["Xiaoyu Ye", "Hao Huang", "Jiaqi An", "Yongtao Wang"], "Categories": "cs.CV cs.CR cs.LG", "Comments": ["12 pages", "11 figures"]}, "abstract": "Stable Diffusion (SD) customization approaches enable users to personalize SD model outputs, greatly enhancing the flexibility and diversity of AI art. However, they also allow individuals to plagiarize specific styles or subjects from copyrighted images, which raises significant concerns about potential copyright infringement. To address this issue, we propose an invisible data-free universal adversarial watermark (DUAW), aiming to protect a myriad of copyrighted images from different customization approaches across various versions of SD models. First, DUAW is designed to disrupt the variational autoencoder during SD customization. Second, DUAW operates in a data-free context, where it is trained on synthetic images produced by a Large Language Model (LLM) and a pretrained SD model. This approach circumvents the necessity of directly handling copyrighted images, thereby preserving their confidentiality. Once crafted, DUAW can be imperceptibly integrated into massive copyrighted images, serving as a protective measure by inducing significant distortions in the images generated by customized SD models. Experimental results demonstrate that DUAW can effectively distort the outputs of fine-tuned SD models, rendering them discernible to both human observers and a simple classifier.", "url": "https://arxiv.org/abs/2308.09889"}, {"metadata": {"arXiv": "2308.09915", "Date": "Sat, 19 Aug 2023 05:47:03 ", "Title": "EGANS: Evolutionary Generative Adversarial Network Search for Zero-Shot Learning", "Authors": ["Shiming Chen and Shihuang Chen and Wenjin Hou and Weiping Ding and Xinge You"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted to TEVC"]}, "abstract": "Zero-shot learning (ZSL) aims to recognize the novel classes which cannot be collected for training a prediction model. Accordingly, generative models (e.g., generative adversarial network (GAN)) are typically used to synthesize the visual samples conditioned by the class semantic vectors and achieve remarkable progress for ZSL. However, existing GAN-based generative ZSL methods are based on hand-crafted models, which cannot adapt to various datasets/scenarios and fails to model instability. To alleviate these challenges, we propose evolutionary generative adversarial network search (termed EGANS) to automatically design the generative network with good adaptation and stability, enabling reliable visual feature sample synthesis for advancing ZSL. Specifically, we adopt cooperative dual evolution to conduct a neural architecture search for both generator and discriminator under a unified evolutionary adversarial framework. EGANS is learned by two stages: evolution generator architecture search and evolution discriminator architecture search. During the evolution generator architecture search, we adopt a many-to-one adversarial training strategy to evolutionarily search for the optimal generator. Then the optimal generator is further applied to search for the optimal discriminator in the evolution discriminator architecture search with a similar evolution search algorithm. Once the optimal generator and discriminator are searched, we entail them into various generative ZSL baselines for ZSL classification. Extensive experiments show that EGANS consistently improve existing generative ZSL methods on the standard CUB, SUN, AWA2 and FLO datasets. The significant performance gains indicate that the evolutionary neural architecture search explores a virgin field in ZSL.", "url": "https://arxiv.org/abs/2308.09915"}, {"metadata": {"arXiv": "2308.09936", "Date": "Sat, 19 Aug 2023 07:53:43 ", "Title": "BLIVA: A Simple Multimodal LLM for Better Handling of Text-Rich Visual Questions", "Authors": ["W. Hu", "Y. Xu", "Y. Li", "W. Li", "Z. Chen", "Z. Tu"], "Categories": "cs.CV cs.LG"}, "abstract": "Vision Language Models (VLMs), which extend Large Language Models (LLM) by incorporating visual understanding capability, have demonstrated significant advancements in addressing open-ended visual question-answering (VQA) tasks. However, these models cannot accurately interpret images infused with text, a common occurrence in real-world scenarios. Standard procedures for extracting information from images often involve learning a fixed set of query embeddings. These embeddings are designed to encapsulate image contexts and are later used as soft prompt inputs in LLMs. Yet, this process is limited to the token count, potentially curtailing the recognition of scenes with text-rich context. To improve upon them, the present study introduces BLIVA: an augmented version of InstructBLIP with Visual Assistant. BLIVA incorporates the query embeddings from InstructBLIP and also directly projects encoded patch embeddings into the LLM, a technique inspired by LLaVA. This approach assists the model to capture intricate details potentially missed during the query decoding process. Empirical evidence demonstrates that our model, BLIVA, significantly enhances performance in processing text-rich VQA benchmarks (up to 17.76\\% in OCR-VQA benchmark) and in undertaking typical VQA benchmarks (up to 7.9\\% in Visual Spatial Reasoning benchmark), comparing to our baseline InstructBLIP. BLIVA demonstrates significant capability in decoding real-world images, irrespective of text presence. To demonstrate the broad industry applications enabled by BLIVA, we evaluate the model using a new dataset comprising YouTube thumbnails paired with question-answer sets across 13 diverse categories. For researchers interested in further exploration, our code and models are freely accessible at https://github.com/mlpc-ucsd/BLIVA.git", "url": "https://arxiv.org/abs/2308.09936"}, {"metadata": {"arXiv": "2308.09942", "Date": "Sat, 19 Aug 2023 08:27:48 ", "Title": "On the Robustness of Open-World Test-Time Training: Self-Training with Dynamic Prototype Expansion", "Authors": ["Yushu Li", "Xun Xu", "Yongyi Su", "Kui Jia"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted at ICCV 2023 (Oral)"]}, "abstract": "Generalizing deep learning models to unknown target domain distribution with low latency has motivated research into test-time training/adaptation (TTT/TTA). Existing approaches often focus on improving test-time training performance under well-curated target domain data. As figured out in this work, many state-of-the-art methods fail to maintain the performance when the target domain is contaminated with strong out-of-distribution (OOD) data, a.k.a. open-world test-time training (OWTTT). The failure is mainly due to the inability to distinguish strong OOD samples from regular weak OOD samples. To improve the robustness of OWTTT we first develop an adaptive strong OOD pruning which improves the efficacy of the self-training TTT method. We further propose a way to dynamically expand the prototypes to represent strong OOD samples for an improved weak/strong OOD data separation. Finally, we regularize self-training with distribution alignment and the combination yields the state-of-the-art performance on 5 OWTTT benchmarks. The code is available at https://github.com/Yushu-Li/OWTTT.", "url": "https://arxiv.org/abs/2308.09942"}, {"metadata": {"arXiv": "2308.10146", "Date": "Sun, 20 Aug 2023 03:13:17 ", "Title": "OCHID-Fi: Occlusion-Robust Hand Pose Estimation in 3D via RF-Vision", "Authors": ["Shujie Zhang", "Tianyue Zheng", "Zhe Chen", "Jingzhi Hu", "Abdelwahed Khamis", "Jiajun Liu and Jun Luo"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted to ICCV 2023"]}, "abstract": "Hand Pose Estimation (HPE) is crucial to many applications, but conventional cameras-based CM-HPE methods are completely subject to Line-of-Sight (LoS), as cameras cannot capture occluded objects. In this paper, we propose to exploit Radio-Frequency-Vision (RF-vision) capable of bypassing obstacles for achieving occluded HPE, and we introduce OCHID-Fi as the first RF-HPE method with 3D pose estimation capability. OCHID-Fi employs wideband RF sensors widely available on smart devices (e.g., iPhones) to probe 3D human hand pose and extract their skeletons behind obstacles. To overcome the challenge in labeling RF imaging given its human incomprehensible nature, OCHID-Fi employs a cross-modality and cross-domain training process. It uses a pre-trained CM-HPE network and a synchronized CM/RF dataset, to guide the training of its complex-valued RF-HPE network under LoS conditions. It further transfers knowledge learned from labeled LoS domain to unlabeled occluded domain via adversarial learning, enabling OCHID-Fi to generalize to unseen occluded scenarios. Experimental results demonstrate the superiority of OCHID-Fi: it achieves comparable accuracy to CM-HPE under normal conditions while maintaining such accuracy even in occluded scenarios, with empirical evidence for its generalizability to new domains.", "url": "https://arxiv.org/abs/2308.10146"}, {"metadata": {"arXiv": "2308.10236", "Date": "Sun, 20 Aug 2023 11:49:12 ", "Title": "FedSIS: Federated Split Learning with Intermediate Representation Sampling for Privacy-preserving Generalized Face Presentation Attack Detection", "Authors": ["Naif Alkhunaizi", "Koushik Srivatsan", "Faris Almalik", "Ibrahim Almakky", "Karthik Nandakumar"], "Categories": "cs.CV cs.CR cs.LG"}, "abstract": "Lack of generalization to unseen domains/attacks is the Achilles heel of most face presentation attack detection (FacePAD) algorithms. Existing attempts to enhance the generalizability of FacePAD solutions assume that data from multiple source domains are available with a single entity to enable centralized training. In practice, data from different source domains may be collected by diverse entities, who are often unable to share their data due to legal and privacy constraints. While collaborative learning paradigms such as federated learning (FL) can overcome this problem, standard FL methods are ill-suited for domain generalization because they struggle to surmount the twin challenges of handling non-iid client data distributions during training and generalizing to unseen domains during inference. In this work, a novel framework called Federated Split learning with Intermediate representation Sampling (FedSIS) is introduced for privacy-preserving domain generalization. In FedSIS, a hybrid Vision Transformer (ViT) architecture is learned using a combination of FL and split learning to achieve robustness against statistical heterogeneity in the client data distributions without any sharing of raw data (thereby preserving privacy). To further improve generalization to unseen domains, a novel feature augmentation strategy called intermediate representation sampling is employed, and discriminative information from intermediate blocks of a ViT is distilled using a shared adapter network. The FedSIS approach has been evaluated on two well-known benchmarks for cross-domain FacePAD to demonstrate that it is possible to achieve state-of-the-art generalization performance without data sharing. Code: https://github.com/Naiftt/FedSIS", "url": "https://arxiv.org/abs/2308.10236"}, {"metadata": {"arXiv": "2308.10239", "Date": "Sun, 20 Aug 2023 11:56:25 ", "Title": "From Global to Local: Multi-scale Out-of-distribution Detection", "Authors": ["Ji Zhang", "Lianli Gao", "Bingguang Hao", "Hao Huang", "Jingkuan Song", "Hengtao Shen"], "Categories": "cs.CV cs.LG", "Comments": ["13 pages"]}, "abstract": "Out-of-distribution (OOD) detection aims to detect \"unknown\" data whose labels have not been seen during the in-distribution (ID) training process. Recent progress in representation learning gives rise to distance-based OOD detection that recognizes inputs as ID/OOD according to their relative distances to the training data of ID classes. Previous approaches calculate pairwise distances relying only on global image representations, which can be sub-optimal as the inevitable background clutter and intra-class variation may drive image-level representations from the same ID class far apart in a given representation space. In this work, we overcome this challenge by proposing Multi-scale OOD DEtection (MODE), a first framework leveraging both global visual information and local region details of images to maximally benefit OOD detection. Specifically, we first find that existing models pretrained by off-the-shelf cross-entropy or contrastive losses are incompetent to capture valuable local representations for MODE, due to the scale-discrepancy between the ID training and OOD detection processes. To mitigate this issue and encourage locally discriminative representations in ID training, we propose Attention-based Local PropAgation (ALPA), a trainable objective that exploits a cross-attention mechanism to align and highlight the local regions of the target objects for pairwise examples. During test-time OOD detection, a Cross-Scale Decision (CSD) function is further devised on the most discriminative multi-scale representations to distinguish ID/OOD data more faithfully. We demonstrate the effectiveness and flexibility of MODE on several benchmarks -- on average, MODE outperforms the previous state-of-the-art by up to 19.24% in FPR, 2.77% in AUROC. Code is available at https://github.com/JimZAI/MODE-OOD.", "url": "https://arxiv.org/abs/2308.10239"}, {"metadata": {"arXiv": "2308.10253", "Date": "Sun, 20 Aug 2023 12:43:52 ", "Title": "StableLLaVA: Enhanced Visual Instruction Tuning with Synthesized Image-Dialogue Data", "Authors": ["Yanda Li", "Chi Zhang", "Gang Yu", "Zhibin Wang", "Bin Fu", "Guosheng Lin", "Chunhua Shen", "Ling Chen", "Yunchao Wei"], "Categories": "cs.CV cs.CL cs.LG", "Comments": ["Project page: https://github.com/icoz69/StableLLAVA"]}, "abstract": "The remarkable multimodal capabilities demonstrated by OpenAI's GPT-4 have sparked significant interest in the development of multimodal Large Language Models (LLMs). A primary research objective of such models is to align visual and textual modalities effectively while comprehending human instructions. Current methodologies often rely on annotations derived from benchmark datasets to construct image-dialogue datasets for training purposes, akin to instruction tuning in LLMs. However, these datasets often exhibit domain bias, potentially constraining the generative capabilities of the models. In an effort to mitigate these limitations, we propose a novel data collection methodology that synchronously synthesizes images and dialogues for visual instruction tuning. This approach harnesses the power of generative models, marrying the abilities of ChatGPT and text-to-image generative models to yield a diverse and controllable dataset with varied image content. This not only provides greater flexibility compared to existing methodologies but also significantly enhances several model capabilities. Our research includes comprehensive experiments conducted on various datasets using the open-source LLAVA model as a testbed for our proposed pipeline. Our results underscore marked enhancements across more than ten commonly assessed capabilities,", "url": "https://arxiv.org/abs/2308.10253"}, {"metadata": {"arXiv": "2308.10273", "Date": "Sun, 20 Aug 2023 14:06:34 ", "Title": "Turning Waste into Wealth: Leveraging Low-Quality Samples for Enhancing Continuous Conditional Generative Adversarial Networks", "Authors": ["Xin Ding and Yongwei Wang and Zuheng Xu"], "Categories": "cs.CV cs.LG"}, "abstract": "Continuous Conditional Generative Adversarial Networks (CcGANs) enable generative modeling conditional on continuous scalar variables (termed regression labels). However, they can produce subpar fake images due to limited training data. Although Negative Data Augmentation (NDA) effectively enhances unconditional and class-conditional GANs by introducing anomalies into real training images, guiding the GANs away from low-quality outputs, its impact on CcGANs is limited, as it fails to replicate negative samples that may occur during the CcGAN sampling. We present a novel NDA approach called Dual-NDA specifically tailored for CcGANs to address this problem. Dual-NDA employs two types of negative samples: visually unrealistic images generated from a pre-trained CcGAN and label-inconsistent images created by manipulating real images' labels. Leveraging these negative samples, we introduce a novel discriminator objective alongside a modified CcGAN training algorithm. Empirical analysis on UTKFace and Steering Angle reveals that Dual-NDA consistently enhances the visual fidelity and label consistency of fake images generated by CcGANs, exhibiting a substantial performance gain over the vanilla NDA. Moreover, by applying Dual-NDA, CcGANs demonstrate a remarkable advancement beyond the capabilities of state-of-the-art conditional GANs and diffusion models, establishing a new pinnacle of performance.", "url": "https://arxiv.org/abs/2308.10273"}, {"metadata": {"arXiv": "2308.10453", "Date": "Mon, 21 Aug 2023 03:58:04 ", "Title": "DOMINO++: Domain-aware Loss Regularization for Deep Learning Generalizability", "Authors": ["Skylar E. Stolte", "Kyle Volle", "Aprinda Indahlastari", "Alejandro Albizu", "Adam J. Woods", "Kevin Brink", "Matthew Hale", "and Ruogu Fang"], "Categories": "cs.CV cs.LG eess.IV", "Comments": ["12 pages", "5 figures", "5 tables", "Accepted by the International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI) 2023"]}, "abstract": "Out-of-distribution (OOD) generalization poses a serious challenge for modern deep learning (DL). OOD data consists of test data that is significantly different from the model's training data. DL models that perform well on in-domain test data could struggle on OOD data. Overcoming this discrepancy is essential to the reliable deployment of DL. Proper model calibration decreases the number of spurious connections that are made between model features and class outputs. Hence, calibrated DL can improve OOD generalization by only learning features that are truly indicative of the respective classes. Previous work proposed domain-aware model calibration (DOMINO) to improve DL calibration, but it lacks designs for model generalizability to OOD data. In this work, we propose DOMINO++, a dual-guidance and dynamic domain-aware loss regularization focused on OOD generalizability. DOMINO++ integrates expert-guided and data-guided knowledge in its regularization. Unlike DOMINO which imposed a fixed scaling and regularization rate, DOMINO++ designs a dynamic scaling factor and an adaptive regularization rate. Comprehensive evaluations compare DOMINO++ with DOMINO and the baseline model for head tissue segmentation from magnetic resonance images (MRIs) on OOD data. The OOD data consists of synthetic noisy and rotated datasets, as well as real data using a different MRI scanner from a separate site. DOMINO++'s superior performance demonstrates its potential to improve the trustworthy deployment of DL on real clinical data.", "url": "https://arxiv.org/abs/2308.10453"}, {"metadata": {"arXiv": "2308.10522", "Date": "Mon, 21 Aug 2023 07:19:47 ", "Title": "Information Theory-Guided Heuristic Progressive Multi-View Coding", "Authors": ["Jiangmeng Li", "Hang Gao", "Wenwen Qiang", "Changwen Zheng"], "Categories": "cs.CV cs.LG eess.IV", "Comments": ["This paper is accepted y the jourcal of Elsevier Neural Networks by 2023. arXiv admin note: substantial text overlap with arXiv:2109.02344"]}, "abstract": "Multi-view representation learning aims to capture comprehensive information from multiple views of a shared context. Recent works intuitively apply contrastive learning to different views in a pairwise manner, which is still scalable: view-specific noise is not filtered in learning view-shared representations; the fake negative pairs, where the negative terms are actually within the same class as the positive, and the real negative pairs are coequally treated; evenly measuring the similarities between terms might interfere with optimization. Importantly, few works study the theoretical framework of generalized self-supervised multi-view learning, especially for more than two views. To this end, we rethink the existing multi-view learning paradigm from the perspective of information theory and then propose a novel information theoretical framework for generalized multi-view learning. Guided by it, we build a multi-view coding method with a three-tier progressive architecture, namely Information theory-guided hierarchical Progressive Multi-view Coding (IPMC). In the distribution-tier, IPMC aligns the distribution between views to reduce view-specific noise. In the set-tier, IPMC constructs self-adjusted contrasting pools, which are adaptively modified by a view filter. Lastly, in the instance-tier, we adopt a designed unified loss to learn representations and reduce the gradient interference. Theoretically and empirically, we demonstrate the superiority of IPMC over state-of-the-art methods.", "url": "https://arxiv.org/abs/2308.10522"}, {"metadata": {"arXiv": "2308.10599", "Date": "Mon, 21 Aug 2023 09:56:48 ", "Title": "Image-free Classifier Injection for Zero-Shot Classification", "Authors": ["Anders Christensen", "Massimiliano Mancini", "A. Sophia Koepke", "Ole Winther", "Zeynep Akata"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted at ICCV 2023"]}, "abstract": "Zero-shot learning models achieve remarkable results on image classification for samples from classes that were not seen during training. However, such models must be trained from scratch with specialised methods: therefore, access to a training dataset is required when the need for zero-shot classification arises. In this paper, we aim to equip pre-trained models with zero-shot classification capabilities without the use of image data. We achieve this with our proposed Image-free Classifier Injection with Semantics (ICIS) that injects classifiers for new, unseen classes into pre-trained classification models in a post-hoc fashion without relying on image data. Instead, the existing classifier weights and simple class-wise descriptors, such as class names or attributes, are used. ICIS has two encoder-decoder networks that learn to reconstruct classifier weights from descriptors (and vice versa), exploiting (cross-)reconstruction and cosine losses to regularise the decoding process. Notably, ICIS can be cheaply trained and applied directly on top of pre-trained classification models. Experiments on benchmark ZSL datasets show that ICIS produces unseen classifier weights that achieve strong (generalised) zero-shot classification performance. Code is available at https://github.com/ExplainableML/ImageFreeZSL .", "url": "https://arxiv.org/abs/2308.10599"}, {"metadata": {"arXiv": "2308.10601", "Date": "Mon, 21 Aug 2023 09:58:13 ", "Title": "Improving the Transferability of Adversarial Examples with Arbitrary Style Transfer", "Authors": ["Zhijin Ge", "Fanhua Shang", "Hongying Liu", "Yuanyuan Liu", "Liang Wan", "Wei Feng", "Xiaosen Wang"], "Categories": "cs.CV cs.CR cs.LG eess.IV", "Comments": ["10 pages", "2 figures", "accepted by the 31st ACM International Conference on Multimedia (MM '23)"], "DOI": "10.1145/3581783.3612070"}, "abstract": "Deep neural networks are vulnerable to adversarial examples crafted by applying human-imperceptible perturbations on clean inputs. Although many attack methods can achieve high success rates in the white-box setting, they also exhibit weak transferability in the black-box setting. Recently, various methods have been proposed to improve adversarial transferability, in which the input transformation is one of the most effective methods. In this work, we notice that existing input transformation-based works mainly adopt the transformed data in the same domain for augmentation. Inspired by domain generalization, we aim to further improve the transferability using the data augmented from different domains. Specifically, a style transfer network can alter the distribution of low-level visual features in an image while preserving semantic content for humans. Hence, we propose a novel attack method named Style Transfer Method (STM) that utilizes a proposed arbitrary style transfer network to transform the images into different domains. To avoid inconsistent semantic information of stylized images for the classification network, we fine-tune the style transfer network and mix up the generated images added by random noise with the original images to maintain semantic consistency and boost input diversity. Extensive experimental results on the ImageNet-compatible dataset show that our proposed method can significantly improve the adversarial transferability on either normally trained models or adversarially trained models than state-of-the-art input transformation-based attacks. Code is available at: https://github.com/Zhijin-Ge/STM.", "url": "https://arxiv.org/abs/2308.10601"}, {"metadata": {"arXiv": "2308.10608", "Date": "Mon, 21 Aug 2023 10:16:52 ", "Title": "FocalDreamer: Text-driven 3D Editing via Focal-fusion Assembly", "Authors": ["Yuhan Li", "Yishun Dou", "Yue Shi", "Yu Lei", "Xuanhong Chen", "Yi Zhang", "Peng Zhou", "Bingbing Ni"], "Categories": "cs.CV cs.GR cs.LG", "Comments": ["Project website: https://fantasia3d.github.io"]}, "abstract": "While text-3D editing has made significant strides in leveraging score distillation sampling, emerging approaches still fall short in delivering separable, precise and consistent outcomes that are vital to content creation. In response, we introduce FocalDreamer, a framework that merges base shape with editable parts according to text prompts for fine-grained editing within desired regions. Specifically, equipped with geometry union and dual-path rendering, FocalDreamer assembles independent 3D parts into a complete object, tailored for convenient instance reuse and part-wise control. We propose geometric focal loss and style consistency regularization, which encourage focal fusion and congruent overall appearance. Furthermore, FocalDreamer generates high-fidelity geometry and PBR textures which are compatible with widely-used graphics engines. Extensive experiments have highlighted the superior editing capabilities of FocalDreamer in both quantitative and qualitative evaluations.", "url": "https://arxiv.org/abs/2308.10608"}, {"metadata": {"arXiv": "2308.10623", "Date": "Mon, 21 Aug 2023 10:47:52 ", "Title": "GaitPT: Skeletons Are All You Need For Gait Recognition", "Authors": ["Andy Catruna", "Adrian Cosma and Emilian Radoi"], "Categories": "cs.CV cs.LG", "MSC-class": "68U10"}, "abstract": "The analysis of patterns of walking is an important area of research that has numerous applications in security, healthcare, sports and human-computer interaction. Lately, walking patterns have been regarded as a unique fingerprinting method for automatic person identification at a distance. In this work, we propose a novel gait recognition architecture called Gait Pyramid Transformer (GaitPT) that leverages pose estimation skeletons to capture unique walking patterns, without relying on appearance information. GaitPT adopts a hierarchical transformer architecture that effectively extracts both spatial and temporal features of movement in an anatomically consistent manner, guided by the structure of the human skeleton. Our results show that GaitPT achieves state-of-the-art performance compared to other skeleton-based gait recognition works, in both controlled and in-the-wild scenarios. GaitPT obtains 82.6% average accuracy on CASIA-B, surpassing other works by a margin of 6%. Moreover, it obtains 52.16% Rank-1 accuracy on GREW, outperforming both skeleton-based and appearance-based approaches.", "url": "https://arxiv.org/abs/2308.10623"}, {"metadata": {"arXiv": "2308.10632", "Date": "Mon, 21 Aug 2023 11:07:27 ", "Title": "Foundation Model-oriented Robustness: Robust Image Model Evaluation with Pretrained Models", "Authors": ["Peiyan Zhang", "Haoyang Liu", "Chaozhuo Li", "Xing Xie", "Sunghun Kim", "Haohan Wang"], "Categories": "cs.CV cs.LG"}, "abstract": "Machine learning has demonstrated remarkable performance over finite datasets, yet whether the scores over the fixed benchmarks can sufficiently indicate the model's performance in the real world is still in discussion. In reality, an ideal robust model will probably behave similarly to the oracle (e.g., the human users), thus a good evaluation protocol is probably to evaluate the models' behaviors in comparison to the oracle. In this paper, we introduce a new robustness measurement that directly measures the image classification model's performance compared with a surrogate oracle (i.e., a foundation model). Besides, we design a simple method that can accomplish the evaluation beyond the scope of the benchmarks. Our method extends the image datasets with new samples that are sufficiently perturbed to be distinct from the ones in the original sets, but are still bounded within the same image-label structure the original test image represents, constrained by a foundation model pretrained with a large amount of samples. As a result, our new method will offer us a new way to evaluate the models' robustness performance, free of limitations of fixed benchmarks or constrained perturbations, although scoped by the power of the oracle. In addition to the evaluation results, we also leverage our generated data to understand the behaviors of the model and our new evaluation strategies.", "url": "https://arxiv.org/abs/2308.10632"}, {"metadata": {"arXiv": "2308.10727", "Date": "Mon, 21 Aug 2023 13:50:41 ", "Title": "Test-time augmentation-based active learning and self-training for label-efficient segmentation", "Authors": ["Bella Specktor-Fadida", "Anna Levchakov", "Dana Schonberger", "Liat Ben-Sira", "Dafna Ben-Bashat", "Leo Joskowicz"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted to MICCAI MILLanD workshop 2023"]}, "abstract": "Deep learning techniques depend on large datasets whose annotation is time-consuming. To reduce annotation burden, the self-training (ST) and active-learning (AL) methods have been developed as well as methods that combine them in an iterative fashion. However, it remains unclear when each method is the most useful, and when it is advantageous to combine them. In this paper, we propose a new method that combines ST with AL using Test-Time Augmentations (TTA). First, TTA is performed on an initial teacher network. Then, cases for annotation are selected based on the lowest estimated Dice score. Cases with high estimated scores are used as soft pseudo-labels for ST. The selected annotated cases are trained with existing annotated cases and ST cases with border slices annotations. We demonstrate the method on MRI fetal body and placenta segmentation tasks with different data variability characteristics. Our results indicate that ST is highly effective for both tasks, boosting performance for in-distribution (ID) and out-of-distribution (OOD) data. However, while self-training improved the performance of single-sequence fetal body segmentation when combined with AL, it slightly deteriorated performance of multi-sequence placenta segmentation on ID data. AL was helpful for the high variability placenta data, but did not improve upon random selection for the single-sequence body data. For fetal body segmentation sequence transfer, combining AL with ST following ST iteration yielded a Dice of 0.961 with only 6 original scans and 2 new sequence scans. Results using only 15 high-variability placenta cases were similar to those using 50 cases. Code is available at: https://github.com/Bella31/TTA-quality-estimation-ST-AL", "url": "https://arxiv.org/abs/2308.10727"}, {"metadata": {"arXiv": "2308.10794", "Date": "Mon, 21 Aug 2023 15:39:41 ", "Title": "MGMAE: Motion Guided Masking for Video Masked Autoencoding", "Authors": ["Bingkun Huang", "Zhiyu Zhao", "Guozhen Zhang", "Yu Qiao and Limin Wang"], "Categories": "cs.CV cs.LG", "Comments": ["ICCV 2023 camera-ready version"]}, "abstract": "Masked autoencoding has shown excellent performance on self-supervised video representation learning. Temporal redundancy has led to a high masking ratio and customized masking strategy in VideoMAE. In this paper, we aim to further improve the performance of video masked autoencoding by introducing a motion guided masking strategy. Our key insight is that motion is a general and unique prior in video, which should be taken into account during masked pre-training. Our motion guided masking explicitly incorporates motion information to build temporal consistent masking volume. Based on this masking volume, we can track the unmasked tokens in time and sample a set of temporal consistent cubes from videos. These temporal aligned unmasked tokens will further relieve the information leakage issue in time and encourage the MGMAE to learn more useful structure information. We implement our MGMAE with an online efficient optical flow estimator and backward masking map warping strategy. We perform experiments on the datasets of Something-Something V2 and Kinetics-400, demonstrating the superior performance of our MGMAE to the original VideoMAE. In addition, we provide the visualization analysis to illustrate that our MGMAE can sample temporal consistent cubes in a motion-adaptive manner for more effective video pre-training.", "url": "https://arxiv.org/abs/2308.10794"}, {"metadata": {"arXiv": "2308.10311", "Date": "Sun, 20 Aug 2023 16:16:26 ", "Title": "I/O Burst Prediction for HPC Clusters using Darshan Logs", "Authors": ["Ehsan Saeedizade", "Roya Taheri", "Engin Arslan"], "Categories": "cs.DC cs.LG cs.NI", "Comments": ["10 pages", "11 figures", "2 tables"]}, "abstract": "Understanding cluster-wide I/O patterns of large-scale HPC clusters is essential to minimize the occurrence and impact of I/O interference. Yet, most previous work in this area focused on monitoring and predicting task and node-level I/O burst events. This paper analyzes Darshan reports from three supercomputers to extract system-level read and write I/O rates in five minutes intervals. We observe significant (over 100x) fluctuations in read and write I/O rates in all three clusters. We then train machine learning models to estimate the occurrence of system-level I/O bursts 5 - 120 minutes ahead. Evaluation results show that we can predict I/O bursts with more than 90% accuracy (F-1 score) five minutes ahead and more than 87% accuracy two hours ahead. We also show that the ML models attain more than 70% accuracy when estimating the degree of the I/O burst. We believe that high-accuracy predictions of I/O bursts can be used in multiple ways, such as postponing delay-tolerant I/O operations (e.g., checkpointing), pausing nonessential applications (e.g., file system scrubbers), and devising I/O-aware job scheduling methods. To validate this claim, we simulated a burst-aware job scheduler that can postpone the start time of applications to avoid I/O bursts. We show that the burst-aware job scheduling can lead to an up to 5x decrease in application runtime.", "url": "https://arxiv.org/abs/2308.10311"}, {"metadata": {"arXiv": "2308.09721", "Date": "Sat, 12 Aug 2023 13:31:02 ", "Title": "A new solution and concrete implementation steps for Artificial General Intelligence", "Authors": ["Yongcong Chen", "Ting Zeng and Jun Zhang"], "Categories": "cs.LG", "Comments": ["30 pages", "2 figures", "1 table"]}, "abstract": "At present, the mainstream artificial intelligence generally adopts the technical path of \"attention mechanism + deep learning\" + \"reinforcement learning\". It has made great progress in the field of AIGC (Artificial Intelligence Generated Content), setting off the technical wave of big models[ 2][13 ]. But in areas that need to interact with the actual environment, such as elderly care, home nanny, agricultural production, and vehicle driving, trial and error are expensive and a reinforcement learning process that requires much trial and error is difficult to achieve. Therefore, in order to achieve Artificial General Intelligence(AGI) that can be applied to any field, we need to use both existing technologies and solve the defects of existing technologies, so as to further develop the technological wave of artificial intelligence. In this paper, we analyze the limitations of the technical route of large models, and by addressing these limitations, we propose solutions, thus solving the inherent defects of large models. In this paper, we will reveal how to achieve true AGI step by step.", "url": "https://arxiv.org/abs/2308.09721"}, {"metadata": {"arXiv": "2308.09722", "Date": "Tue, 15 Aug 2023 17:20:05 ", "Title": "A Trustable LSTM-Autoencoder Network for Cyberbullying Detection on Social Media Using Synthetic Data", "Authors": ["Mst Shapna Akter", "Hossain Shahriar", "Alfredo Cuzzocrea"], "Categories": "cs.LG cs.CL cs.SI", "Comments": ["arXiv admin note: text overlap with arXiv:2303.07484"]}, "abstract": "Social media cyberbullying has a detrimental effect on human life. As online social networking grows daily, the amount of hate speech also increases. Such terrible content can cause depression and actions related to suicide. This paper proposes a trustable LSTM-Autoencoder Network for cyberbullying detection on social media using synthetic data. We have demonstrated a cutting-edge method to address data availability difficulties by producing machine-translated data. However, several languages such as Hindi and Bangla still lack adequate investigations due to a lack of datasets. We carried out experimental identification of aggressive comments on Hindi, Bangla, and English datasets using the proposed model and traditional models, including Long Short-Term Memory (LSTM), Bidirectional Long Short-Term Memory (BiLSTM), LSTM-Autoencoder, Word2vec, Bidirectional Encoder Representations from Transformers (BERT), and Generative Pre-trained Transformer 2 (GPT-2) models. We employed evaluation metrics such as f1-score, accuracy, precision, and recall to assess the models performance. Our proposed model outperformed all the models on all datasets, achieving the highest accuracy of 95%. Our model achieves state-of-the-art results among all the previous works on the dataset we used in this paper.", "url": "https://arxiv.org/abs/2308.09722"}, {"metadata": {"arXiv": "2308.09723", "Date": "Wed, 16 Aug 2023 23:57:41 ", "Title": "FineQuant: Unlocking Efficiency with Fine-Grained Weight-Only Quantization for LLMs", "Authors": ["Young Jin Kim", "Rawn Henry", "Raffy Fahim", "Hany Hassan Awadalla"], "Categories": "cs.LG cs.CL"}, "abstract": "Large Language Models (LLMs) have achieved state-of-the-art performance across various language tasks but pose challenges for practical deployment due to their substantial memory requirements. Furthermore, the latest generative models suffer from high inference costs caused by the memory bandwidth bottleneck in the auto-regressive decoding process. To address these issues, we propose an efficient weight-only quantization method that reduces memory consumption and accelerates inference for LLMs. To ensure minimal quality degradation, we introduce a simple and effective heuristic approach that utilizes only the model weights of a pre-trained model. This approach is applicable to both Mixture-of-Experts (MoE) and dense models without requiring additional fine-tuning. To demonstrate the effectiveness of our proposed method, we first analyze the challenges and issues associated with LLM quantization. Subsequently, we present our heuristic approach, which adaptively finds the granularity of quantization, effectively addressing these problems. Furthermore, we implement highly efficient GPU GEMMs that perform on-the-fly matrix multiplication and dequantization, supporting the multiplication of fp16 or bf16 activations with int8 or int4 weights. We evaluate our approach on large-scale open source models such as OPT-175B and internal MoE models, showcasing minimal accuracy loss while achieving up to 3.65 times higher throughput on the same number of GPUs.", "url": "https://arxiv.org/abs/2308.09723"}, {"metadata": {"arXiv": "2308.09727", "Date": "Thu, 17 Aug 2023 13:29:57 ", "Title": "Cross-city Few-Shot Traffic Forecasting via Traffic Pattern Bank", "Authors": ["Zhanyu Liu", "Guanjie Zheng", "Yanwei Yu"], "Categories": "cs.LG", "Comments": ["Accepted by CIKM2023 (Long Paper)"]}, "abstract": "Traffic forecasting is a critical service in Intelligent Transportation Systems (ITS). Utilizing deep models to tackle this task relies heavily on data from traffic sensors or vehicle devices, while some cities might lack device support and thus have few available data. So, it is necessary to learn from data-rich cities and transfer the knowledge to data-scarce cities in order to improve the performance of traffic forecasting. To address this problem, we propose a cross-city few-shot traffic forecasting framework via Traffic Pattern Bank (TPB) due to that the traffic patterns are similar across cities. TPB utilizes a pre-trained traffic patch encoder to project raw traffic data from data-rich cities into high-dimensional space, from which a traffic pattern bank is generated through clustering. Then, the traffic data of the data-scarce city could query the traffic pattern bank and explicit relations between them are constructed. The metaknowledge is aggregated based on these relations and an adjacency matrix is constructed to guide a downstream spatial-temporal model in forecasting future traffic. The frequently used meta-training framework Reptile is adapted to find a better initial parameter for the learnable modules. Experiments on real-world traffic datasets show that TPB outperforms existing methods and demonstrates the effectiveness of our approach in cross-city few-shot traffic forecasting.", "url": "https://arxiv.org/abs/2308.09727"}, {"metadata": {"arXiv": "2308.09728", "Date": "Thu, 17 Aug 2023 13:56:26 ", "Title": "Learning representations by forward-propagating errors", "Authors": ["Ryoungwoo Jang"], "Categories": "cs.LG cs.NE"}, "abstract": "Back-propagation (BP) is widely used learning algorithm for neural network optimization. However, BP requires enormous computation cost and is too slow to train in central processing unit (CPU). Therefore current neural network optimizaiton is performed in graphical processing unit (GPU) with compute unified device architecture (CUDA) programming. In this paper, we propose a light, fast learning algorithm on CPU that is fast as CUDA acceleration on GPU. This algorithm is based on forward-propagating method, using concept of dual number in algebraic geometry.", "url": "https://arxiv.org/abs/2308.09728"}, {"metadata": {"arXiv": "2308.09735", "Date": "Fri, 18 Aug 2023 06:58:31 ", "Title": "Causal Interpretable Progression Trajectory Analysis of Chronic Disease", "Authors": ["Zhoujian Sun", "Wenzhuo Zhang", "Zhengxing Huang", "Nai Ding"], "Categories": "cs.LG", "Comments": ["20 pages", "5 tables", "5 figures"]}, "abstract": "Chronic disease is the leading cause of death, emphasizing the need for accurate prediction of disease progression trajectories and informed clinical decision-making. Machine learning (ML) models have shown promise in this domain by capturing non-linear patterns within patient features. However, existing ML-based models lack the ability to provide causal interpretable predictions and estimate treatment effects, limiting their decision-assisting perspective. In this study, we propose a novel model called causal trajectory prediction (CTP) to tackle the limitation. The CTP model combines trajectory prediction and causal discovery to enable accurate prediction of disease progression trajectories and uncovering causal relationships between features. By incorporating a causal graph into the prediction process, CTP ensures that ancestor features are not influenced by treatment on descendant features, thereby enhancing the interpretability of the model. By estimating the bounds of treatment effects, even in the presence of unmeasured confounders, the CTP provides valuable insights for clinical decision-making. We evaluate the performance of the CTP using simulated and real medical datasets. Experimental results demonstrate that our model achieves satisfactory performance, highlighting its potential to assist clinical decisions.", "url": "https://arxiv.org/abs/2308.09735"}, {"metadata": {"arXiv": "2308.09766", "Date": "Fri, 18 Aug 2023 18:30:33 ", "Title": "Time Series Predictions in Unmonitored Sites: A Survey of Machine Learning Techniques in Water Resources", "Authors": ["Jared D. Willard", "Charuleka Varadharajan", "Xiaowei Jia", "Vipin Kumar"], "Categories": "cs.LG", "Comments": ["37 pages", "4 figures", "1 table", "submitted to Environmental Data Science"], "MSC-class": "68T07", "ACM-class": "I.2.6; J.2"}, "abstract": "Prediction of dynamic environmental variables in unmonitored sites remains a long-standing challenge for water resources science. The majority of the world's freshwater resources have inadequate monitoring of critical environmental variables needed for management. Yet, the need to have widespread predictions of hydrological variables such as river flow and water quality has become increasingly urgent due to climate and land use change over the past decades, and their associated impacts on water resources. Modern machine learning methods increasingly outperform their process-based and empirical model counterparts for hydrologic time series prediction with their ability to extract information from large, diverse data sets. We review relevant state-of-the art applications of machine learning for streamflow, water quality, and other water resources prediction and discuss opportunities to improve the use of machine learning with emerging methods for incorporating watershed characteristics into deep learning models, transfer learning, and incorporating process knowledge into machine learning models. The analysis here suggests most prior efforts have been focused on deep learning learning frameworks built on many sites for predictions at daily time scales in the United States, but that comparisons between different classes of machine learning methods are few and inadequate. We identify several open questions for time series predictions in unmonitored sites that include incorporating dynamic inputs and site characteristics, mechanistic understanding and spatial context, and explainable AI techniques in modern machine learning frameworks.", "url": "https://arxiv.org/abs/2308.09766"}, {"metadata": {"arXiv": "2308.09791", "Date": "Fri, 18 Aug 2023 19:40:59 ", "Title": "An Efficient High-Dimensional Gene Selection Approach based on Binary Horse Herd Optimization Algorithm for Biological Data Classification", "Authors": ["Niloufar Mehrabi", "Sayed Pedram Haeri Boroujeni", "Elnaz Pashaei"], "Categories": "cs.LG"}, "abstract": "The Horse Herd Optimization Algorithm (HOA) is a new meta-heuristic algorithm based on the behaviors of horses at different ages. The HOA was introduced recently to solve complex and high-dimensional problems. This paper proposes a binary version of the Horse Herd Optimization Algorithm (BHOA) in order to solve discrete problems and select prominent feature subsets. Moreover, this study provides a novel hybrid feature selection framework based on the BHOA and a minimum Redundancy Maximum Relevance (MRMR) filter method. This hybrid feature selection, which is more computationally efficient, produces a beneficial subset of relevant and informative features. Since feature selection is a binary problem, we have applied a new Transfer Function (TF), called X-shape TF, which transforms continuous problems into binary search spaces. Furthermore, the Support Vector Machine (SVM) is utilized to examine the efficiency of the proposed method on ten microarray datasets, namely Lymphoma, Prostate, Brain-1, DLBCL, SRBCT, Leukemia, Ovarian, Colon, Lung, and MLL. In comparison to other state-of-the-art, such as the Gray Wolf (GW), Particle Swarm Optimization (PSO), and Genetic Algorithm (GA), the proposed hybrid method (MRMR-BHOA) demonstrates superior performance in terms of accuracy and minimum selected features. Also, experimental results prove that the X-Shaped BHOA approach outperforms others methods.", "url": "https://arxiv.org/abs/2308.09791"}, {"metadata": {"arXiv": "2308.09829", "Date": "Fri, 18 Aug 2023 21:35:45 ", "Title": "Learning from A Single Graph is All You Need for Near-Shortest Path Routing in Wireless Networks", "Authors": ["Yung-Fu Chen", "Sen Lin", "Anish Arora"], "Categories": "cs.LG cs.NI"}, "abstract": "We propose a learning algorithm for local routing policies that needs only a few data samples obtained from a single graph while generalizing to all random graphs in a standard model of wireless networks. We thus solve the all-pairs near-shortest path problem by training deep neural networks (DNNs) that efficiently and scalably learn routing policies that are local, i.e., they only consider node states and the states of neighboring nodes. Remarkably, one of these DNNs we train learns a policy that exactly matches the performance of greedy forwarding; another generally outperforms greedy forwarding. Our algorithm design exploits network domain knowledge in several ways: First, in the selection of input features and, second, in the selection of a ``seed graph'' and subsamples from its shortest paths. The leverage of domain knowledge provides theoretical explainability of why the seed graph and node subsampling suffice for learning that is efficient, scalable, and generalizable. Simulation-based results on uniform random graphs with diverse sizes and densities empirically corroborate that using samples generated from a few routing paths in a modest-sized seed graph quickly learns a model that is generalizable across (almost) all random graphs in the wireless network model.", "url": "https://arxiv.org/abs/2308.09829"}, {"metadata": {"arXiv": "2308.09850", "Date": "Fri, 18 Aug 2023 22:52:29 ", "Title": "Backdoor Mitigation by Correcting the Distribution of Neural Activations", "Authors": ["Xi Li", "Zhen Xiang", "David J. Miller", "George Kesidis"], "Categories": "cs.LG cs.CR"}, "abstract": "Backdoor (Trojan) attacks are an important type of adversarial exploit against deep neural networks (DNNs), wherein a test instance is (mis)classified to the attacker's target class whenever the attacker's backdoor trigger is present. In this paper, we reveal and analyze an important property of backdoor attacks: a successful attack causes an alteration in the distribution of internal layer activations for backdoor-trigger instances, compared to that for clean instances. Even more importantly, we find that instances with the backdoor trigger will be correctly classified to their original source classes if this distribution alteration is corrected. Based on our observations, we propose an efficient and effective method that achieves post-training backdoor mitigation by correcting the distribution alteration using reverse-engineered triggers. Notably, our method does not change any trainable parameters of the DNN, but achieves generally better mitigation performance than existing methods that do require intensive DNN parameter tuning. It also efficiently detects test instances with the trigger, which may help to catch adversarial entities in the act of exploiting the backdoor.", "url": "https://arxiv.org/abs/2308.09850"}, {"metadata": {"arXiv": "2308.09873", "Date": "Sat, 19 Aug 2023 01:37:41 ", "Title": "Skill Transformer: A Monolithic Policy for Mobile Manipulation", "Authors": ["Xiaoyu Huang", "Dhruv Batra", "Akshara Rai", "Andrew Szot"], "Categories": "cs.LG"}, "abstract": "We present Skill Transformer, an approach for solving long-horizon robotic tasks by combining conditional sequence modeling and skill modularity. Conditioned on egocentric and proprioceptive observations of a robot, Skill Transformer is trained end-to-end to predict both a high-level skill (e.g., navigation, picking, placing), and a whole-body low-level action (e.g., base and arm motion), using a transformer architecture and demonstration trajectories that solve the full task. It retains the composability and modularity of the overall task through a skill predictor module while reasoning about low-level actions and avoiding hand-off errors, common in modular approaches. We test Skill Transformer on an embodied rearrangement benchmark and find it performs robust task planning and low-level control in new scenarios, achieving a 2.5x higher success rate than baselines in hard rearrangement problems.", "url": "https://arxiv.org/abs/2308.09873"}, {"metadata": {"arXiv": "2308.09881", "Date": "Sat, 19 Aug 2023 02:21:21 ", "Title": "Generative Adversarial Networks Unlearning", "Authors": ["Hui Sun", "Tianqing Zhu", "Wenhan Chang", "and Wanlei Zhou"], "Categories": "cs.LG cs.CR"}, "abstract": "As machine learning continues to develop, and data misuse scandals become more prevalent, individuals are becoming increasingly concerned about their personal information and are advocating for the right to remove their data. Machine unlearning has emerged as a solution to erase training data from trained machine learning models. Despite its success in classifiers, research on Generative Adversarial Networks (GANs) is limited due to their unique architecture, including a generator and a discriminator. One challenge pertains to generator unlearning, as the process could potentially disrupt the continuity and completeness of the latent space. This disruption might consequently diminish the model's effectiveness after unlearning. Another challenge is how to define a criterion that the discriminator should perform for the unlearning images. In this paper, we introduce a substitution mechanism and define a fake label to effectively mitigate these challenges. Based on the substitution mechanism and fake label, we propose a cascaded unlearning approach for both item and class unlearning within GAN models, in which the unlearning and learning processes run in a cascaded manner. We conducted a comprehensive evaluation of the cascaded unlearning technique using the MNIST and CIFAR-10 datasets. Experimental results demonstrate that this approach achieves significantly improved item and class unlearning efficiency, reducing the required time by up to 185x and 284x for the MNIST and CIFAR-10 datasets, respectively, in comparison to retraining from scratch. Notably, although the model's performance experiences minor degradation after unlearning, this reduction is negligible when dealing with a minimal number of images (e.g., 64) and has no adverse effects on downstream tasks such as classification.", "url": "https://arxiv.org/abs/2308.09881"}, {"metadata": {"arXiv": "2308.09884", "Date": "Sat, 19 Aug 2023 02:30:35 ", "Title": "A Transformer-based Framework For Multi-variate Time Series: A Remaining Useful Life Prediction Use Case", "Authors": ["Oluwaseyi Ogunfowora", "Homayoun Najjaran"], "Categories": "cs.LG eess.SP"}, "abstract": "In recent times, Large Language Models (LLMs) have captured a global spotlight and revolutionized the field of Natural Language Processing. One of the factors attributed to the effectiveness of LLMs is the model architecture used for training, transformers. Transformer models excel at capturing contextual features in sequential data since time series data are sequential, transformer models can be leveraged for more efficient time series data prediction. The field of prognostics is vital to system health management and proper maintenance planning. A reliable estimation of the remaining useful life (RUL) of machines holds the potential for substantial cost savings. This includes avoiding abrupt machine failures, maximizing equipment usage, and serving as a decision support system (DSS). This work proposed an encoder-transformer architecture-based framework for multivariate time series prediction for a prognostics use case. We validated the effectiveness of the proposed framework on all four sets of the C-MAPPS benchmark dataset for the remaining useful life prediction task. To effectively transfer the knowledge and application of transformers from the natural language domain to time series, three model-specific experiments were conducted. Also, to enable the model awareness of the initial stages of the machine life and its degradation path, a novel expanding window method was proposed for the first time in this work, it was compared with the sliding window method, and it led to a large improvement in the performance of the encoder transformer model. Finally, the performance of the proposed encoder-transformer model was evaluated on the test dataset and compared with the results from 13 other state-of-the-art (SOTA) models in the literature and it outperformed them all with an average performance increase of 137.65% over the next best model across all the datasets.", "url": "https://arxiv.org/abs/2308.09884"}, {"metadata": {"arXiv": "2308.09896", "Date": "Sat, 19 Aug 2023 03:24:34 ", "Title": "Contrastive Learning-based Imputation-Prediction Networks for In-hospital Mortality Risk Modeling using EHRs", "Authors": ["Yuxi Liu", "Zhenhao Zhang", "Shaowen Qin", "Flora D. Salim", "Antonio Jimeno Yepes"], "Categories": "cs.LG", "Comments": ["15 pages", "2 figures", "accepted at ECML PKDD 2023"]}, "abstract": "Predicting the risk of in-hospital mortality from electronic health records (EHRs) has received considerable attention. Such predictions will provide early warning of a patient's health condition to healthcare professionals so that timely interventions can be taken. This prediction task is challenging since EHR data are intrinsically irregular, with not only many missing values but also varying time intervals between medical records. Existing approaches focus on exploiting the variable correlations in patient medical records to impute missing values and establishing time-decay mechanisms to deal with such irregularity. This paper presents a novel contrastive learning-based imputation-prediction network for predicting in-hospital mortality risks using EHR data. Our approach introduces graph analysis-based patient stratification modeling in the imputation process to group similar patients. This allows information of similar patients only to be used, in addition to personal contextual information, for missing value imputation. Moreover, our approach can integrate contrastive learning into the proposed network architecture to enhance patient representation learning and predictive performance on the classification task. Experiments on two real-world EHR datasets show that our approach outperforms the state-of-the-art approaches in both imputation and prediction tasks.", "url": "https://arxiv.org/abs/2308.09896"}, {"metadata": {"arXiv": "2308.09902", "Date": "Sat, 19 Aug 2023 04:26:23 ", "Title": "DPMAC: Differentially Private Communication for Cooperative Multi-Agent Reinforcement Learning", "Authors": ["Canzhe Zhao", "Yanjie Ze", "Jing Dong", "Baoxiang Wang and Shuai Li"], "Categories": "cs.LG", "Comments": ["Full version; Accepted in IJCAI 2023"]}, "abstract": "Communication lays the foundation for cooperation in human society and in multi-agent reinforcement learning (MARL). Humans also desire to maintain their privacy when communicating with others, yet such privacy concern has not been considered in existing works in MARL. To this end, we propose the \\textit{differentially private multi-agent communication} (DPMAC) algorithm, which protects the sensitive information of individual agents by equipping each agent with a local message sender with rigorous $(\\epsilon, \\delta)$-differential privacy (DP) guarantee. In contrast to directly perturbing the messages with predefined DP noise as commonly done in privacy-preserving scenarios, we adopt a stochastic message sender for each agent respectively and incorporate the DP requirement into the sender, which automatically adjusts the learned message distribution to alleviate the instability caused by DP noise. Further, we prove the existence of a Nash equilibrium in cooperative MARL with privacy-preserving communication, which suggests that this problem is game-theoretically learnable. Extensive experiments demonstrate a clear advantage of DPMAC over baseline methods in privacy-preserving scenarios.", "url": "https://arxiv.org/abs/2308.09902"}, {"metadata": {"arXiv": "2308.09907", "Date": "Sat, 19 Aug 2023 05:03:35 ", "Title": "Imputing Brain Measurements Across Data Sets via Graph Neural Networks", "Authors": ["Yixin Wang", "Wei Peng", "Susan F. Tapert", "Qingyu Zhao", "Kilian M. Pohl"], "Categories": "cs.LG", "Comments": ["Accepted at the 6th workshop on PRedictive Intelligence in Medicine (PRIME 2023) - MICCAI 2023"]}, "abstract": "Publicly available data sets of structural MRIs might not contain specific measurements of brain Regions of Interests (ROIs) that are important for training machine learning models. For example, the curvature scores computed by Freesurfer are not released by the Adolescent Brain Cognitive Development (ABCD) Study. One can address this issue by simply reapplying Freesurfer to the data set. However, this approach is generally computationally and labor intensive (e.g., requiring quality control). An alternative is to impute the missing measurements via a deep learning approach. However, the state-of-the-art is designed to estimate randomly missing values rather than entire measurements. We therefore propose to re-frame the imputation problem as a prediction task on another (public) data set that contains the missing measurements and shares some ROI measurements with the data sets of interest. A deep learning model is then trained to predict the missing measurements from the shared ones and afterwards is applied to the other data sets. Our proposed algorithm models the dependencies between ROI measurements via a graph neural network (GNN) and accounts for demographic differences in brain measurements (e.g. sex) by feeding the graph encoding into a parallel architecture. The architecture simultaneously optimizes a graph decoder to impute values and a classifier in predicting demographic factors. We test the approach, called Demographic Aware Graph-based Imputation (DAGI), on imputing those missing Freesurfer measurements of ABCD (N=3760) by training the predictor on those publicly released by the National Consortium on Alcohol and Neurodevelopment in Adolescence (NCANDA, N=540)...", "url": "https://arxiv.org/abs/2308.09907"}, {"metadata": {"arXiv": "2308.09947", "Date": "Sat, 19 Aug 2023 08:46:27 ", "Title": "Study on the effectiveness of AutoML in detecting cardiovascular disease", "Authors": ["T.V. Afanasieva and A.P. Kuzlyakin and A.V. Komolov"], "Categories": "cs.LG", "Comments": ["12 pages"]}, "abstract": "Cardiovascular diseases are widespread among patients with chronic noncommunicable diseases and are one of the leading causes of death, including in the working age. The article presents the relevance of the development and application of patient-oriented systems, in which machine learning (ML) is a promising technology that allows predicting cardiovascular diseases. Automated machine learning (AutoML) makes it possible to simplify and speed up the process of developing AI/ML applications, which is key in the development of patient-oriented systems by application users, in particular medical specialists. The authors propose a framework for the application of automatic machine learning and three scenarios that allowed for data combining five data sets of cardiovascular disease indicators from the UCI Machine Learning Repository to investigate the effectiveness in detecting this class of diseases. The study investigated one AutoML model that used and optimized the hyperparameters of thirteen basic ML models (KNeighborsUnif, KNeighborsDist, LightGBMXT, LightGBM, RandomForestGini, RandomForestEntr, CatBoost, ExtraTreesGini, ExtraTreesEntr, NeuralNetFastA, XGBoost, NeuralNetTorch, LightGBMLarge) and included the most accurate models in the weighted ensemble. The results of the study showed that the structure of the AutoML model for detecting cardiovascular diseases depends not only on the efficiency and accuracy of the basic models used, but also on the scenarios for preprocessing the initial data, in particular, on the technique of data normalization. The comparative analysis showed that the accuracy of the AutoML model in detecting cardiovascular disease varied in the range from 87.41% to 92.3%, and the maximum accuracy was obtained when normalizing the source data into binary values, and the minimum was obtained when using the built-in AutoML technique.", "url": "https://arxiv.org/abs/2308.09947"}, {"metadata": {"arXiv": "2308.09955", "Date": "Sat, 19 Aug 2023 09:17:33 ", "Title": "To prune or not to prune : A chaos-causality approach to principled pruning of dense neural networks", "Authors": ["Rajan Sahu", "Shivam Chadha", "Nithin Nagaraj", "Archana Mathur", "Snehanshu Saha"], "Categories": "cs.LG"}, "abstract": "Reducing the size of a neural network (pruning) by removing weights without impacting its performance is an important problem for resource-constrained devices. In the past, pruning was typically accomplished by ranking or penalizing weights based on criteria like magnitude and removing low-ranked weights before retraining the remaining ones. Pruning strategies may also involve removing neurons from the network in order to achieve the desired reduction in network size. We formulate pruning as an optimization problem with the objective of minimizing misclassifications by selecting specific weights. To accomplish this, we have introduced the concept of chaos in learning (Lyapunov exponents) via weight updates and exploiting causality to identify the causal weights responsible for misclassification. Such a pruned network maintains the original performance and retains feature explainability.", "url": "https://arxiv.org/abs/2308.09955"}, {"metadata": {"arXiv": "2308.10036", "Date": "Sat, 19 Aug 2023 14:46:29 ", "Title": "Semi-Supervised Anomaly Detection for the Determination of Vehicle Hijacking Tweets", "Authors": ["Taahir Aiyoob Patel and Clement N. Nyirenda"], "Categories": "cs.LG"}, "abstract": "In South Africa, there is an ever-growing issue of vehicle hijackings. This leads to travellers constantly being in fear of becoming a victim to such an incident. This work presents a new semi-supervised approach to using tweets to identify hijacking incidents by using unsupervised anomaly detection algorithms. Tweets consisting of the keyword \"hijacking\" are obtained, stored, and processed using the term frequency-inverse document frequency (TF-IDF) and further analyzed by using two anomaly detection algorithms: 1) K-Nearest Neighbour (KNN); 2) Cluster Based Outlier Factor (CBLOF). The comparative evaluation showed that the KNN method produced an accuracy of 89%, whereas the CBLOF produced an accuracy of 90%. The CBLOF method was also able to obtain a F1-Score of 0.8, whereas the KNN produced a 0.78. Therefore, there is a slight difference between the two approaches, in favour of CBLOF, which has been selected as a preferred unsupervised method for the determination of relevant hijacking tweets. In future, a comparison will be done between supervised learning methods and the unsupervised methods presented in this work on larger dataset. Optimisation mechanisms will also be employed in order to increase the overall performance.", "url": "https://arxiv.org/abs/2308.10036"}, {"metadata": {"arXiv": "2308.10037", "Date": "Sat, 19 Aug 2023 14:49:37 ", "Title": "High Performance Computing Applied to Logistic Regression: A CPU and GPU Implementation Comparison", "Authors": ["Nechba Mohammed", "Mouhajir Mohamed", "Sedjari Yassine"], "Categories": "cs.LG"}, "abstract": "We present a versatile GPU-based parallel version of Logistic Regression (LR), aiming to address the increasing demand for faster algorithms in binary classification due to large data sets. Our implementation is a direct translation of the parallel Gradient Descent Logistic Regression algorithm proposed by X. Zou et al. [12]. Our experiments demonstrate that our GPU-based LR outperforms existing CPU-based implementations in terms of execution time while maintaining comparable f1 score. The significant acceleration of processing large datasets makes our method particularly advantageous for real-time prediction applications like image recognition, spam detection, and fraud detection. Our algorithm is implemented in a ready-to-use Python library available at : https://github.com/NechbaMohammed/SwiftLogisticReg", "url": "https://arxiv.org/abs/2308.10037"}, {"metadata": {"arXiv": "2308.10038", "Date": "Sat, 19 Aug 2023 14:52:30 ", "Title": "Physics-guided training of GAN to improve accuracy in airfoil design synthesis", "Authors": ["Kazunari Wada", "Katsuyuki Suzuki", "Kazuo Yonekura"], "Categories": "cs.LG"}, "abstract": "Generative adversarial networks (GAN) have recently been used for a design synthesis of mechanical shapes. A GAN sometimes outputs physically unreasonable shapes. For example, when a GAN model is trained to output airfoil shapes that indicate required aerodynamic performance, significant errors occur in the performance values. This is because the GAN model only considers data but does not consider the aerodynamic equations that lie under the data. This paper proposes the physics-guided training of the GAN model to guide the model to learn physical validity. Physical validity is computed using general-purpose software located outside the neural network model. Such general-purpose software cannot be used in physics-informed neural network frameworks, because physical equations must be implemented inside the neural network models. Additionally, a limitation of generative models is that the output data are similar to the training data and cannot generate completely new shapes. However, because the proposed model is guided by a physical model and does not use a training dataset, it can generate completely new shapes. Numerical experiments show that the proposed model drastically improves the accuracy. Moreover, the output shapes differ from those of the training dataset but still satisfy the physical validity, overcoming the limitations of existing GAN models.", "url": "https://arxiv.org/abs/2308.10038"}, {"metadata": {"arXiv": "2308.10099", "Date": "Sat, 19 Aug 2023 20:10:54 ", "Title": "Geometric instability of graph neural networks on large graphs", "Authors": ["Emily Morris", "Haotian Shen", "Weiling Du", "Muhammad Hamza Sajjad", "Borun Shi"], "Categories": "cs.LG cs.SI"}, "abstract": "We analyse the geometric instability of embeddings produced by graph neural networks (GNNs). Existing methods are only applicable for small graphs and lack context in the graph domain. We propose a simple, efficient and graph-native Graph Gram Index (GGI) to measure such instability which is invariant to permutation, orthogonal transformation, translation and order of evaluation. This allows us to study the varying instability behaviour of GNN embeddings on large graphs for both node classification and link prediction.", "url": "https://arxiv.org/abs/2308.10099"}, {"metadata": {"arXiv": "2308.10101", "Date": "Sat, 19 Aug 2023 20:15:02 ", "Title": "An Online Multiple Kernel Parallelizable Learning Scheme", "Authors": ["Emilio Ruiz-Moreno and Baltasar Beferull-Lozano"], "Categories": "cs.LG eess.SP", "Comments": ["5 pages", "2 figures"]}, "abstract": "The performance of reproducing kernel Hilbert space-based methods is known to be sensitive to the choice of the reproducing kernel. Choosing an adequate reproducing kernel can be challenging and computationally demanding, especially in data-rich tasks without prior information about the solution domain. In this paper, we propose a learning scheme that scalably combines several single kernel-based online methods to reduce the kernel-selection bias. The proposed learning scheme applies to any task formulated as a regularized empirical risk minimization convex problem. More specifically, our learning scheme is based on a multi-kernel learning formulation that can be applied to widen any single-kernel solution space, thus increasing the possibility of finding higher-performance solutions. In addition, it is parallelizable, allowing for the distribution of the computational load across different computing units. We show experimentally that the proposed learning scheme outperforms the combined single-kernel online methods separately in terms of the cumulative regularized least squares cost metric.", "url": "https://arxiv.org/abs/2308.10101"}, {"metadata": {"arXiv": "2308.10120", "Date": "Sat, 19 Aug 2023 22:19:41 ", "Title": "Deep Generative Modeling-based Data Augmentation with Demonstration using the BFBT Benchmark Void Fraction Datasets", "Authors": ["Farah Alsafadi", "Xu Wu"], "Categories": "cs.LG", "Comments": ["27 pages", "6 figures"]}, "abstract": "Deep learning (DL) has achieved remarkable successes in many disciplines such as computer vision and natural language processing due to the availability of ``big data''. However, such success cannot be easily replicated in many nuclear engineering problems because of the limited amount of training data, especially when the data comes from high-cost experiments. To overcome such a data scarcity issue, this paper explores the applications of deep generative models (DGMs) that have been widely used for image data generation to scientific data augmentation. DGMs, such as generative adversarial networks (GANs), normalizing flows (NFs), variational autoencoders (VAEs), and conditional VAEs (CVAEs), can be trained to learn the underlying probabilistic distribution of the training dataset. Once trained, they can be used to generate synthetic data that are similar to the training data and significantly expand the dataset size. By employing DGMs to augment TRACE simulated data of the steady-state void fractions based on the NUPEC Boiling Water Reactor Full-size Fine-mesh Bundle Test (BFBT) benchmark, this study demonstrates that VAEs, CVAEs, and GANs have comparable generative performance with similar errors in the synthetic data, with CVAEs achieving the smallest errors. The findings shows that DGMs have a great potential to augment scientific data in nuclear engineering, which proves effective for expanding the training dataset and enabling other DL models to be trained more accurately.", "url": "https://arxiv.org/abs/2308.10120"}, {"metadata": {"arXiv": "2308.10154", "Date": "Sun, 20 Aug 2023 04:01:30 ", "Title": "Resource-Adaptive Newton's Method for Distributed Learning", "Authors": ["Shuzhen Chen", "Yuan Yuan", "Youming Tao", "Zhipeng Cai and Dongxiao Yu"], "Categories": "cs.LG"}, "abstract": "Distributed stochastic optimization methods based on Newton's method offer significant advantages over first-order methods by leveraging curvature information for improved performance. However, the practical applicability of Newton's method is hindered in large-scale and heterogeneous learning environments due to challenges such as high computation and communication costs associated with the Hessian matrix, sub-model diversity, staleness in training, and data heterogeneity. To address these challenges, this paper introduces a novel and efficient algorithm called RANL, which overcomes the limitations of Newton's method by employing a simple Hessian initialization and adaptive assignments of training regions. The algorithm demonstrates impressive convergence properties, which are rigorously analyzed under standard assumptions in stochastic optimization. The theoretical analysis establishes that RANL achieves a linear convergence rate while effectively adapting to available resources and maintaining high efficiency. Unlike traditional first-order methods, RANL exhibits remarkable independence from the condition number of the problem and eliminates the need for complex parameter tuning. These advantages make RANL a promising approach for distributed stochastic optimization in practical scenarios.", "url": "https://arxiv.org/abs/2308.10154"}, {"metadata": {"arXiv": "2308.10188", "Date": "Sun, 20 Aug 2023 07:30:13 ", "Title": "Mimicking To Dominate: Imitation Learning Strategies for Success in Multiagent Competitive Games", "Authors": ["The Viet Bui and Tien Mai and Thanh Hong Nguyen"], "Categories": "cs.LG cs.MA"}, "abstract": "Training agents in multi-agent competitive games presents significant challenges due to their intricate nature. These challenges are exacerbated by dynamics influenced not only by the environment but also by opponents' strategies. Existing methods often struggle with slow convergence and instability. To address this, we harness the potential of imitation learning to comprehend and anticipate opponents' behavior, aiming to mitigate uncertainties with respect to the game dynamics. Our key contributions include: (i) a new multi-agent imitation learning model for predicting next moves of the opponents -- our model works with hidden opponents' actions and local observations; (ii) a new multi-agent reinforcement learning algorithm that combines our imitation learning model and policy training into one single training process; and (iii) extensive experiments in three challenging game environments, including an advanced version of the Star-Craft multi-agent challenge (i.e., SMACv2). Experimental results show that our approach achieves superior performance compared to existing state-of-the-art multi-agent RL algorithms.", "url": "https://arxiv.org/abs/2308.10188"}, {"metadata": {"arXiv": "2308.10201", "Date": "Sun, 20 Aug 2023 08:27:42 ", "Title": "Hiding Backdoors within Event Sequence Data via Poisoning Attacks", "Authors": ["Elizaveta Kovtun", "Alina Ermilova", "Dmitry Berestnev", "and Alexey Zaytsev"], "Categories": "cs.LG cs.CR"}, "abstract": "The financial industry relies on deep learning models for making important decisions. This adoption brings new danger, as deep black-box models are known to be vulnerable to adversarial attacks. In computer vision, one can shape the output during inference by performing an adversarial attack called poisoning via introducing a backdoor into the model during training. For sequences of financial transactions of a customer, insertion of a backdoor is harder to perform, as models operate over a more complex discrete space of sequences, and systematic checks for insecurities occur. We provide a method to introduce concealed backdoors, creating vulnerabilities without altering their functionality for uncontaminated data. To achieve this, we replace a clean model with a poisoned one that is aware of the availability of a backdoor and utilize this knowledge. Our most difficult for uncovering attacks include either additional supervised detection step of poisoned data activated during the test or well-hidden model weight modifications. The experimental study provides insights into how these effects vary across different datasets, architectures, and model components. Alternative methods and baselines, such as distillation-type regularization, are also explored but found to be less efficient. Conducted on three open transaction datasets and architectures, including LSTM, CNN, and Transformer, our findings not only illuminate the vulnerabilities in contemporary models but also can drive the construction of more robust systems.", "url": "https://arxiv.org/abs/2308.10201"}, {"metadata": {"arXiv": "2308.10238", "Date": "Sun, 20 Aug 2023 11:56:02 ", "Title": "Thompson Sampling for Real-Valued Combinatorial Pure Exploration of Multi-Armed Bandit", "Authors": ["Shintaro Nakamura", "Masashi Sugiyama"], "Categories": "cs.LG stat.ML"}, "abstract": "We study the real-valued combinatorial pure exploration of the multi-armed bandit (R-CPE-MAB) problem. In R-CPE-MAB, a player is given $d$ stochastic arms, and the reward of each arm $s\\in\\{1, \\ldots, d\\}$ follows an unknown distribution with mean $\\mu_s$. In each time step, a player pulls a single arm and observes its reward. The player's goal is to identify the optimal \\emph{action} $\\boldsymbol{\\pi}^{*} = \\argmax_{\\boldsymbol{\\pi} \\in \\mathcal{A}} \\boldsymbol{\\mu}^{\\top}\\boldsymbol{\\pi}$ from a finite-sized real-valued \\emph{action set} $\\mathcal{A}\\subset \\mathbb{R}^{d}$ with as few arm pulls as possible. Previous methods in the R-CPE-MAB assume that the size of the action set $\\mathcal{A}$ is polynomial in $d$. We introduce an algorithm named the Generalized Thompson Sampling Explore (GenTS-Explore) algorithm, which is the first algorithm that can work even when the size of the action set is exponentially large in $d$. We also introduce a novel problem-dependent sample complexity lower bound of the R-CPE-MAB problem, and show that the GenTS-Explore algorithm achieves the optimal sample complexity up to a problem-dependent constant factor.", "url": "https://arxiv.org/abs/2308.10238"}, {"metadata": {"arXiv": "2308.10276", "Date": "Sun, 20 Aug 2023 14:12:11 ", "Title": "Minimalist Traffic Prediction: Linear Layer Is All You Need", "Authors": ["Wenying Duan", "Hong Rao", "Wei Huang", "Xiaoxi He"], "Categories": "cs.LG", "Comments": ["9 pages"]}, "abstract": "Traffic prediction is essential for the progression of Intelligent Transportation Systems (ITS) and the vision of smart cities. While Spatial-Temporal Graph Neural Networks (STGNNs) have shown promise in this domain by leveraging Graph Neural Networks (GNNs) integrated with either RNNs or Transformers, they present challenges such as computational complexity, gradient issues, and resource-intensiveness. This paper addresses these challenges, advocating for three main solutions: a node-embedding approach, time series decomposition, and periodicity learning. We introduce STLinear, a minimalist model architecture designed for optimized efficiency and performance. Unlike traditional STGNNs, STlinear operates fully locally, avoiding inter-node data exchanges, and relies exclusively on linear layers, drastically cutting computational demands. Our empirical studies on real-world datasets confirm STLinear's prowess, matching or exceeding the accuracy of leading STGNNs, but with significantly reduced complexity and computation overhead (more than 95% reduction in MACs per epoch compared to state-of-the-art STGNN baseline published in 2023). In summary, STLinear emerges as a potent, efficient alternative to conventional STGNNs, with profound implications for the future of ITS and smart city initiatives.", "url": "https://arxiv.org/abs/2308.10276"}, {"metadata": {"arXiv": "2308.10279", "Date": "Sun, 20 Aug 2023 14:25:31 ", "Title": "GPFL: Simultaneously Learning Global and Personalized Feature Information for Personalized Federated Learning", "Authors": ["Jianqing Zhang", "Yang Hua", "Hao Wang", "Tao Song", "Zhengui Xue", "Ruhui Ma", "Jian Cao", "Haibing Guan"], "Categories": "cs.LG cs.CR cs.DC", "Comments": ["Accepted by ICCV2023"]}, "abstract": "Federated Learning (FL) is popular for its privacy-preserving and collaborative learning capabilities. Recently, personalized FL (pFL) has received attention for its ability to address statistical heterogeneity and achieve personalization in FL. However, from the perspective of feature extraction, most existing pFL methods only focus on extracting global or personalized feature information during local training, which fails to meet the collaborative learning and personalization goals of pFL. To address this, we propose a new pFL method, named GPFL, to simultaneously learn global and personalized feature information on each client. We conduct extensive experiments on six datasets in three statistically heterogeneous settings and show the superiority of GPFL over ten state-of-the-art methods regarding effectiveness, scalability, fairness, stability, and privacy. Besides, GPFL mitigates overfitting and outperforms the baselines by up to 8.99% in accuracy.", "url": "https://arxiv.org/abs/2308.10279"}, {"metadata": {"arXiv": "2308.10283", "Date": "Sun, 20 Aug 2023 14:36:45 ", "Title": "Adaptive Uncertainty-Guided Model Selection for Data-Driven PDE Discovery", "Authors": ["Pongpisit Thanasutives", "Takashi Morita", "Masayuki Numao", "Ken-ichi Fukui"], "Categories": "cs.LG physics.comp-ph", "Comments": ["17 pages", "15 figures"]}, "abstract": "We propose a new parameter-adaptive uncertainty-penalized Bayesian information criterion (UBIC) to prioritize the parsimonious partial differential equation (PDE) that sufficiently governs noisy spatial-temporal observed data with few reliable terms. Since the naive use of the BIC for model selection has been known to yield an undesirable overfitted PDE, the UBIC penalizes the found PDE not only by its complexity but also the quantified uncertainty, derived from the model supports' coefficient of variation in a probabilistic view. We also introduce physics-informed neural network learning as a simulation-based approach to further validate the selected PDE flexibly against the other discovered PDE. Numerical results affirm the successful application of the UBIC in identifying the true governing PDE. Additionally, we reveal an interesting effect of denoising the observed data on improving the trade-off between the BIC score and model complexity. Code is available at https://github.com/Pongpisit-Thanasutives/UBIC.", "url": "https://arxiv.org/abs/2308.10283"}, {"metadata": {"arXiv": "2308.10292", "Date": "Sun, 20 Aug 2023 15:22:08 ", "Title": "An interpretable deep learning method for bearing fault diagnosis", "Authors": ["Hao Lu", "Austin M. Bray", "Chao Hu", "Andrew T. Zimmerman", "Hongyi Xu"], "Categories": "cs.LG"}, "abstract": "Deep learning (DL) has gained popularity in recent years as an effective tool for classifying the current health and predicting the future of industrial equipment. However, most DL models have black-box components with an underlying structure that is too complex to be interpreted and explained to human users. This presents significant challenges when deploying these models for safety-critical maintenance tasks, where non-technical personnel often need to have complete trust in the recommendations these models give. To address these challenges, we utilize a convolutional neural network (CNN) with Gradient-weighted Class Activation Mapping (Grad-CAM) activation map visualizations to form an interpretable DL method for classifying bearing faults. After the model training process, we apply Grad-CAM to identify a training sample's feature importance and to form a library of diagnosis knowledge (or health library) containing training samples with annotated feature maps. During the model evaluation process, the proposed approach retrieves prediction basis samples from the health library according to the similarity of the feature importance. The proposed method can be easily applied to any CNN model without modifying the model architecture, and our experimental results show that this method can select prediction basis samples that are intuitively and physically meaningful, improving the model's trustworthiness for human users.", "url": "https://arxiv.org/abs/2308.10292"}, {"metadata": {"arXiv": "2308.10317", "Date": "Sun, 20 Aug 2023 16:35:21 ", "Title": "Towards Sustainable Development: A Novel Integrated Machine Learning Model for Holistic Environmental Health Monitoring", "Authors": ["Anirudh Mazumder", "Sarthak Engala", "Aditya Nallaparaju"], "Categories": "cs.LG", "Comments": ["5 pages", "3 figures"]}, "abstract": "Urbanization enables economic growth but also harms the environment through degradation. Traditional methods of detecting environmental issues have proven inefficient. Machine learning has emerged as a promising tool for tracking environmental deterioration by identifying key predictive features. Recent research focused on developing a predictive model using pollutant levels and particulate matter as indicators of environmental state in order to outline challenges. Machine learning was employed to identify patterns linking areas with worse conditions. This research aims to assist governments in identifying intervention points, improving planning and conservation efforts, and ultimately contributing to sustainable development.", "url": "https://arxiv.org/abs/2308.10317"}, {"metadata": {"arXiv": "2308.10328", "Date": "Sun, 20 Aug 2023 17:52:02 ", "Title": "A Comprehensive Empirical Evaluation on Online Continual Learning", "Authors": ["Albin Soutif--Cormerais", "Antonio Carta", "Andrea Cossu", "Julio Hurtado", "Vincenzo Lomonaco", "Joost Van de Weijer", "Hamed Hemati"], "Categories": "cs.LG", "Comments": ["ICCV Visual Continual Learning Workshop 2023 accepted paper"]}, "abstract": "Online continual learning aims to get closer to a live learning experience by learning directly on a stream of data with temporally shifting distribution and by storing a minimum amount of data from that stream. In this empirical evaluation, we evaluate various methods from the literature that tackle online continual learning. More specifically, we focus on the class-incremental setting in the context of image classification, where the learner must learn new classes incrementally from a stream of data. We compare these methods on the Split-CIFAR100 and Split-TinyImagenet benchmarks, and measure their average accuracy, forgetting, stability, and quality of the representations, to evaluate various aspects of the algorithm at the end but also during the whole training period. We find that most methods suffer from stability and underfitting issues. However, the learned representations are comparable to i.i.d. training under the same computational budget. No clear winner emerges from the results and basic experience replay, when properly tuned and implemented, is a very strong baseline. We release our modular and extensible codebase at https://github.com/AlbinSou/ocl_survey based on the avalanche framework to reproduce our results and encourage future research.", "url": "https://arxiv.org/abs/2308.10328"}, {"metadata": {"arXiv": "2308.10364", "Date": "Sun, 20 Aug 2023 20:49:15 ", "Title": "SE(3) Equivariant Augmented Coupling Flows", "Authors": ["Laurence I. Midgley and Vincent Stimper and Javier Antor\\'an and Emile Mathieu and Bernhard Sch\\\"olkopf and Jos\\'e Miguel Hern\\'andez-Lobato"], "Categories": "cs.LG physics.comp-ph"}, "abstract": "Coupling normalizing flows allow for fast sampling and density evaluation, making them the tool of choice for probabilistic modeling of physical systems. However, the standard coupling architecture precludes endowing flows that operate on the Cartesian coordinates of atoms with the SE(3) and permutation invariances of physical systems. This work proposes a coupling flow that preserves SE(3) and permutation equivariance by performing coordinate splits along additional augmented dimensions. At each layer, the flow maps atoms' positions into learned SE(3) invariant bases, where we apply standard flow transformations, such as monotonic rational-quadratic splines, before returning to the original basis. Crucially, our flow preserves fast sampling and density evaluation, and may be used to produce unbiased estimates of expectations with respect to the target distribution via importance sampling. When trained on the DW4, LJ13 and QM9-positional datasets, our flow is competitive with equivariant continuous normalizing flows, while allowing sampling two orders of magnitude faster. Moreover, to the best of our knowledge, we are the first to learn the full Boltzmann distribution of alanine dipeptide by only modeling the Cartesian positions of its atoms. Lastly, we demonstrate that our flow can be trained to approximately sample from the Boltzmann distribution of the DW4 and LJ13 particle systems using only their energy functions.", "url": "https://arxiv.org/abs/2308.10364"}, {"metadata": {"arXiv": "2308.10396", "Date": "Mon, 21 Aug 2023 00:22:32 ", "Title": "Label Selection Approach to Learning from Crowds", "Authors": ["Kosuke Yoshimura and Hisashi Kashima"], "Categories": "cs.LG cs.HC", "Comments": ["15 pages", "1 figure"]}, "abstract": "Supervised learning, especially supervised deep learning, requires large amounts of labeled data. One approach to collect large amounts of labeled data is by using a crowdsourcing platform where numerous workers perform the annotation tasks. However, the annotation results often contain label noise, as the annotation skills vary depending on the crowd workers and their ability to complete the task correctly. Learning from Crowds is a framework which directly trains the models using noisy labeled data from crowd workers. In this study, we propose a novel Learning from Crowds model, inspired by SelectiveNet proposed for the selective prediction problem. The proposed method called Label Selection Layer trains a prediction model by automatically determining whether to use a worker's label for training using a selector network. A major advantage of the proposed method is that it can be applied to almost all variants of supervised learning problems by simply adding a selector network and changing the objective function for existing models, without explicitly assuming a model of the noise in crowd annotations. The experimental results show that the performance of the proposed method is almost equivalent to or better than the Crowd Layer, which is one of the state-of-the-art methods for Deep Learning from Crowds, except for the regression problem case.", "url": "https://arxiv.org/abs/2308.10396"}, {"metadata": {"arXiv": "2308.10407", "Date": "Mon, 21 Aug 2023 01:21:21 ", "Title": "Federated Learning for Connected and Automated Vehicles: A Survey of Existing Approaches and Challenges", "Authors": ["Vishnu Pandi Chellapandi and Liangqi Yuan and Christopher G. Brinton and Stanislaw H Zak and Ziran Wang"], "Categories": "cs.LG cs.CR cs.DC cs.NI"}, "abstract": "Machine learning (ML) is widely used for key tasks in Connected and Automated Vehicles (CAV), including perception, planning, and control. However, its reliance on vehicular data for model training presents significant challenges related to in-vehicle user privacy and communication overhead generated by massive data volumes. Federated learning (FL) is a decentralized ML approach that enables multiple vehicles to collaboratively develop models, broadening learning from various driving environments, enhancing overall performance, and simultaneously securing local vehicle data privacy and security. This survey paper presents a review of the advancements made in the application of FL for CAV (FL4CAV). First, centralized and decentralized frameworks of FL are analyzed, highlighting their key characteristics and methodologies. Second, diverse data sources, models, and data security techniques relevant to FL in CAVs are reviewed, emphasizing their significance in ensuring privacy and confidentiality. Third, specific and important applications of FL are explored, providing insight into the base models and datasets employed for each application. Finally, existing challenges for FL4CAV are listed and potential directions for future work are discussed to further enhance the effectiveness and efficiency of FL in the context of CAV.", "url": "https://arxiv.org/abs/2308.10407"}, {"metadata": {"arXiv": "2308.10425", "Date": "Mon, 21 Aug 2023 02:27:13 ", "Title": "Spatio-Temporal Adaptive Embedding Makes Vanilla Transformer SOTA for Traffic Forecasting", "Authors": ["Hangchen Liu", "Zheng Dong", "Renhe Jiang", "Jiewen Deng", "Jinliang Deng", "Quanjun Chen and Xuan Song"], "Categories": "cs.LG", "Comments": ["Accepted as CIKM2023 Short Paper"]}, "abstract": "With the rapid development of the Intelligent Transportation System (ITS), accurate traffic forecasting has emerged as a critical challenge. The key bottleneck lies in capturing the intricate spatio-temporal traffic patterns. In recent years, numerous neural networks with complicated architectures have been proposed to address this issue. However, the advancements in network architectures have encountered diminishing performance gains. In this study, we present a novel component called spatio-temporal adaptive embedding that can yield outstanding results with vanilla transformers. Our proposed Spatio-Temporal Adaptive Embedding transformer (STAEformer) achieves state-of-the-art performance on five real-world traffic forecasting datasets. Further experiments demonstrate that spatio-temporal adaptive embedding plays a crucial role in traffic forecasting by effectively capturing intrinsic spatio-temporal relations and chronological information in traffic time series.", "url": "https://arxiv.org/abs/2308.10425"}, {"metadata": {"arXiv": "2308.10427", "Date": "Mon, 21 Aug 2023 02:43:38 ", "Title": "Federated Learning Robust to Byzantine Attacks: Achieving Zero Optimality Gap", "Authors": ["Shiyuan Zuo", "Rongfei Fan", "Han Hu", "Ning Zhang", "and Shimin Gong"], "Categories": "cs.LG cs.CR cs.DC"}, "abstract": "In this paper, we propose a robust aggregation method for federated learning (FL) that can effectively tackle malicious Byzantine attacks. At each user, model parameter is firstly updated by multiple steps, which is adjustable over iterations, and then pushed to the aggregation center directly. This decreases the number of interactions between the aggregation center and users, allows each user to set training parameter in a flexible way, and reduces computation burden compared with existing works that need to combine multiple historical model parameters. At the aggregation center, geometric median is leveraged to combine the received model parameters from each user. Rigorous proof shows that zero optimality gap is achieved by our proposed method with linear convergence, as long as the fraction of Byzantine attackers is below half. Numerical results verify the effectiveness of our proposed method.", "url": "https://arxiv.org/abs/2308.10427"}, {"metadata": {"arXiv": "2308.10457", "Date": "Mon, 21 Aug 2023 04:09:59 ", "Title": "Adaptive Local Steps Federated Learning with Differential Privacy Driven by Convergence Analysis", "Authors": ["Xinpeng Ling", "Jie Fu", "Zhili Chen"], "Categories": "cs.LG cs.CR"}, "abstract": "Federated Learning (FL) is a distributed machine learning technique that allows model training among multiple devices or organizations without sharing data. However, while FL ensures that the raw data is not directly accessible to external adversaries, adversaries can still obtain some statistical information about the data through differential attacks. Differential Privacy (DP) has been proposed, which adds noise to the model or gradients to prevent adversaries from inferring private information from the transmitted parameters. We reconsider the framework of differential privacy federated learning in resource-constrained scenarios (privacy budget and communication resources). We analyze the convergence of federated learning with differential privacy (DPFL) on resource-constrained scenarios and propose an Adaptive Local Steps Differential Privacy Federated Learning (ALS-DPFL) algorithm. We experiment our algorithm on the FashionMNIST and Cifar-10 datasets and achieve quite good performance relative to previous work.", "url": "https://arxiv.org/abs/2308.10457"}, {"metadata": {"arXiv": "2308.10502", "Date": "Mon, 21 Aug 2023 06:42:42 ", "Title": "GradientCoin: A Peer-to-Peer Decentralized Large Language Models", "Authors": ["Yeqi Gao", "Zhao Song", "Junze Yin"], "Categories": "cs.LG cs.CL stat.ML"}, "abstract": "Since 2008, after the proposal of a Bitcoin electronic cash system, Bitcoin has fundamentally changed the economic system over the last decade. Since 2022, large language models (LLMs) such as GPT have outperformed humans in many real-life tasks. However, these large language models have several practical issues. For example, the model is centralized and controlled by a specific unit. One weakness is that if that unit decides to shut down the model, it cannot be used anymore. The second weakness is the lack of guaranteed discrepancy behind this model, as certain dishonest units may design their own models and feed them unhealthy training data. In this work, we propose a purely theoretical design of a decentralized LLM that operates similarly to a Bitcoin cash system. However, implementing such a system might encounter various practical difficulties. Furthermore, this new system is unlikely to perform better than the standard Bitcoin system in economics. Therefore, the motivation for designing such a system is limited. It is likely that only two types of people would be interested in setting up a practical system for it: $\\bullet$ Those who prefer to use a decentralized ChatGPT-like software. $\\bullet$ Those who believe that the purpose of carbon-based life is to create silicon-based life, such as Optimus Prime in Transformers. The reason the second type of people may be interested is that it is possible that one day an AI system like this will awaken and become the next level of intelligence on this planet.", "url": "https://arxiv.org/abs/2308.10502"}, {"metadata": {"arXiv": "2308.10504", "Date": "Mon, 21 Aug 2023 06:45:28 ", "Title": "Adaptive Thresholding Heuristic for KPI Anomaly Detection", "Authors": ["Ebenezer R.H.P. Isaac and Akshat Sharma"], "Categories": "cs.LG stat.ML"}, "abstract": "A plethora of outlier detectors have been explored in the time series domain, however, in a business sense, not all outliers are anomalies of interest. Existing anomaly detection solutions are confined to certain outlier detectors limiting their applicability to broader anomaly detection use cases. Network KPIs (Key Performance Indicators) tend to exhibit stochastic behaviour producing statistical outliers, most of which do not adversely affect business operations. Thus, a heuristic is required to capture the business definition of an anomaly for time series KPI. This article proposes an Adaptive Thresholding Heuristic (ATH) to dynamically adjust the detection threshold based on the local properties of the data distribution and adapt to changes in time series patterns. The heuristic derives the threshold based on the expected periodicity and the observed proportion of anomalies minimizing false positives and addressing concept drift. ATH can be used in conjunction with any underlying seasonality decomposition method and an outlier detector that yields an outlier score. This method has been tested on EON1-Cell-U, a labeled KPI anomaly dataset produced by Ericsson, to validate our hypothesis. Experimental results show that ATH is computationally efficient making it scalable for near real time anomaly detection and flexible with multiple forecasters and outlier detectors.", "url": "https://arxiv.org/abs/2308.10504"}, {"metadata": {"arXiv": "2308.10505", "Date": "Mon, 21 Aug 2023 06:45:58 ", "Title": "A Clustering Algorithm to Organize Satellite Hotspot Data for the Purpose of Tracking Bushfires Remotely", "Authors": ["Weihao Li", "Emily Dodwell", "Dianne Cook"], "Categories": "cs.LG stat.AP stat.CO stat.ML"}, "abstract": "This paper proposes a spatiotemporal clustering algorithm and its implementation in the R package spotoroo. This work is motivated by the catastrophic bushfires in Australia throughout the summer of 2019-2020 and made possible by the availability of satellite hotspot data. The algorithm is inspired by two existing spatiotemporal clustering algorithms but makes enhancements to cluster points spatially in conjunction with their movement across consecutive time periods. It also allows for the adjustment of key parameters, if required, for different locations and satellite data sources. Bushfire data from Victoria, Australia, is used to illustrate the algorithm and its use within the package.", "url": "https://arxiv.org/abs/2308.10505"}, {"metadata": {"arXiv": "2308.10544", "Date": "Mon, 21 Aug 2023 07:58:15 ", "Title": "Towards Accelerated Model Training via Bayesian Data Selection", "Authors": ["Zhijie Deng", "Peng Cui", "Jun Zhu"], "Categories": "cs.LG"}, "abstract": "Mislabeled, duplicated, or biased data in real-world scenarios can lead to prolonged training and even hinder model convergence. Traditional solutions prioritizing easy or hard samples lack the flexibility to handle such a variety simultaneously. Recent work has proposed a more reasonable data selection principle by examining the data's impact on the model's generalization loss. However, its practical adoption relies on less principled approximations and additional clean holdout data. This work solves these problems by leveraging a lightweight Bayesian treatment and incorporating off-the-shelf zero-shot predictors built on large-scale pre-trained models. The resulting algorithm is efficient and easy-to-implement. We perform extensive empirical studies on challenging benchmarks with considerable data noise and imbalance in the online batch selection scenario, and observe superior training efficiency over competitive baselines. Notably, on the challenging WebVision benchmark, our method can achieve similar predictive performance with significantly fewer training iterations than leading data selection methods.", "url": "https://arxiv.org/abs/2308.10544"}, {"metadata": {"arXiv": "2308.10584", "Date": "Mon, 21 Aug 2023 09:33:20 ", "Title": "RADIANCE: Radio-Frequency Adversarial Deep-learning Inference for Automated Network Coverage Estimation", "Authors": ["Sopan Sarkar", "Mohammad Hossein Manshaei", "and Marwan Krunz"], "Categories": "cs.LG cs.NI eess.SP", "Comments": ["6 pages", "6 figures"]}, "abstract": "Radio-frequency coverage maps (RF maps) are extensively utilized in wireless networks for capacity planning, placement of access points and base stations, localization, and coverage estimation. Conducting site surveys to obtain RF maps is labor-intensive and sometimes not feasible. In this paper, we propose radio-frequency adversarial deep-learning inference for automated network coverage estimation (RADIANCE), a generative adversarial network (GAN) based approach for synthesizing RF maps in indoor scenarios. RADIANCE utilizes a semantic map, a high-level representation of the indoor environment to encode spatial relationships and attributes of objects within the environment and guide the RF map generation process. We introduce a new gradient-based loss function that computes the magnitude and direction of change in received signal strength (RSS) values from a point within the environment. RADIANCE incorporates this loss function along with the antenna pattern to capture signal propagation within a given indoor configuration and generate new patterns under new configuration, antenna (beam) pattern, and center frequency. Extensive simulations are conducted to compare RADIANCE with ray-tracing simulations of RF maps. Our results show that RADIANCE achieves a mean average error (MAE) of 0.09, root-mean-squared error (RMSE) of 0.29, peak signal-to-noise ratio (PSNR) of 10.78, and multi-scale structural similarity index (MS-SSIM) of 0.80.", "url": "https://arxiv.org/abs/2308.10584"}, {"metadata": {"arXiv": "2308.10609", "Date": "Mon, 21 Aug 2023 10:18:26 ", "Title": "ST-RAP: A Spatio-Temporal Framework for Real Estate Appraisal", "Authors": ["Hojoon Lee", "Hawon Jeong", "Byungkun Lee", "Kyungyup Lee", "Jaegul Choo"], "Categories": "cs.LG", "Comments": ["Accepted to CIKM'23"]}, "abstract": "In this paper, we introduce ST-RAP, a novel Spatio-Temporal framework for Real estate APpraisal. ST-RAP employs a hierarchical architecture with a heterogeneous graph neural network to encapsulate temporal dynamics and spatial relationships simultaneously. Through comprehensive experiments on a large-scale real estate dataset, ST-RAP outperforms previous methods, demonstrating the significant benefits of integrating spatial and temporal aspects in real estate appraisal. Our code and dataset are available at https://github.com/dojeon-ai/STRAP.", "url": "https://arxiv.org/abs/2308.10609"}, {"metadata": {"arXiv": "2308.10619", "Date": "Mon, 21 Aug 2023 10:35:32 ", "Title": "centroIDA: Cross-Domain Class Discrepancy Minimization Based on Accumulative Class-Centroids for Imbalanced Domain Adaptation", "Authors": ["Xiaona Sun and Zhenyu Wu and Yichen Liu and Saier Hu and Zhiqiang Zhan and Yang Ji"], "Categories": "cs.LG"}, "abstract": "Unsupervised Domain Adaptation (UDA) approaches address the covariate shift problem by minimizing the distribution discrepancy between the source and target domains, assuming that the label distribution is invariant across domains. However, in the imbalanced domain adaptation (IDA) scenario, covariate and long-tailed label shifts both exist across domains. To tackle the IDA problem, some current research focus on minimizing the distribution discrepancies of each corresponding class between source and target domains. Such methods rely much on the reliable pseudo labels' selection and the feature distributions estimation for target domain, and the minority classes with limited numbers makes the estimations more uncertainty, which influences the model's performance. In this paper, we propose a cross-domain class discrepancy minimization method based on accumulative class-centroids for IDA (centroIDA). Firstly, class-based re-sampling strategy is used to obtain an unbiased classifier on source domain. Secondly, the accumulative class-centroids alignment loss is proposed for iterative class-centroids alignment across domains. Finally, class-wise feature alignment loss is used to optimize the feature representation for a robust classification boundary. A series of experiments have proved that our method outperforms other SOTA methods on IDA problem, especially with the increasing degree of label shift.", "url": "https://arxiv.org/abs/2308.10619"}, {"metadata": {"arXiv": "2308.10644", "Date": "Mon, 21 Aug 2023 11:31:15 ", "Title": "Faster Training of Neural ODEs Using Gau{\\ss}-Legendre Quadrature", "Authors": ["Alexander Norcliffe", "Marc Peter Deisenroth"], "Categories": "cs.LG cs.NA math.NA stat.ML", "Comments": ["32 pages", "16 figures", "7 tables", "published in TMLR 2023"]}, "abstract": "Neural ODEs demonstrate strong performance in generative and time-series modelling. However, training them via the adjoint method is slow compared to discrete models due to the requirement of numerically solving ODEs. To speed neural ODEs up, a common approach is to regularise the solutions. However, this approach may affect the expressivity of the model; when the trajectory itself matters, this is particularly important. In this paper, we propose an alternative way to speed up the training of neural ODEs. The key idea is to speed up the adjoint method by using Gau{\\ss}-Legendre quadrature to solve integrals faster than ODE-based methods while remaining memory efficient. We also extend the idea to training SDEs using the Wong-Zakai theorem, by training a corresponding ODE and transferring the parameters. Our approach leads to faster training of neural ODEs, especially for large models. It also presents a new way to train SDE-based models.", "url": "https://arxiv.org/abs/2308.10644"}, {"metadata": {"arXiv": "2308.10649", "Date": "Mon, 21 Aug 2023 11:36:54 ", "Title": "Reinforcement Learning Based Sensor Optimization for Bio-markers", "Authors": ["Sajal Khandelwal", "Pawan Kumar", "Syed Azeemuddin"], "Categories": "cs.LG cs.NE eess.SP", "Comments": ["7 pages", "4 tables"]}, "abstract": "Radio frequency (RF) biosensors, in particular those based on inter-digitated capacitors (IDCs), are pivotal in areas like biomedical diagnosis, remote sensing, and wireless communication. Despite their advantages of low cost and easy fabrication, their sensitivity can be hindered by design imperfections, environmental factors, and circuit noise. This paper investigates enhancing the sensitivity of IDC-based RF sensors using novel reinforcement learning based Binary Particle Swarm Optimization (RLBPSO), and it is compared to Ant Colony Optimization (ACO), and other state-of-the-art methods. By focusing on optimizing design parameters like electrode design and finger width, the proposed study found notable improvements in sensor sensitivity. The proposed RLBPSO method shows best optimized design for various frequency ranges when compared to current state-of-the-art methods.", "url": "https://arxiv.org/abs/2308.10649"}, {"metadata": {"arXiv": "2308.10675", "Date": "Mon, 21 Aug 2023 12:17:40 ", "Title": "An Improved Best-of-both-worlds Algorithm for Bandits with Delayed Feedback", "Authors": ["Saeed Masoudian", "Julian Zimmert", "Yevgeny Seldin"], "Categories": "cs.LG stat.ML"}, "abstract": "We propose a new best-of-both-worlds algorithm for bandits with variably delayed feedback. The algorithm improves on prior work by Masoudian et al. [2022] by eliminating the need in prior knowledge of the maximal delay $d_{\\mathrm{max}}$ and providing tighter regret bounds in both regimes. The algorithm and its regret bounds are based on counts of outstanding observations (a quantity that is observed at action time) rather than delays or the maximal delay (quantities that are only observed when feedback arrives). One major contribution is a novel control of distribution drift, which is based on biased loss estimators and skipping of observations with excessively large delays. Another major contribution is demonstrating that the complexity of best-of-both-worlds bandits with delayed feedback is characterized by the cumulative count of outstanding observations after skipping of observations with excessively large delays, rather than the delays or the maximal delay.", "url": "https://arxiv.org/abs/2308.10675"}, {"metadata": {"arXiv": "2308.10699", "Date": "Mon, 21 Aug 2023 13:09:31 ", "Title": "Cost-Efficient Online Decision Making: A Combinatorial Multi-Armed Bandit Approach", "Authors": ["Arman Rahbar", "Niklas {\\AA}kerblom", "Morteza Haghir Chehreghani"], "Categories": "cs.LG"}, "abstract": "Online decision making plays a crucial role in numerous real-world applications. In many scenarios, the decision is made based on performing a sequence of tests on the incoming data points. However, performing all tests can be expensive and is not always possible. In this paper, we provide a novel formulation of the online decision making problem based on combinatorial multi-armed bandits and take the cost of performing tests into account. Based on this formulation, we provide a new framework for cost-efficient online decision making which can utilize posterior sampling or BayesUCB for exploration. We provide a rigorous theoretical analysis for our framework and present various experimental results that demonstrate its applicability to real-world problems.", "url": "https://arxiv.org/abs/2308.10699"}, {"metadata": {"arXiv": "2308.10708", "Date": "Mon, 21 Aug 2023 13:22:12 ", "Title": "Measuring the Effect of Causal Disentanglement on the Adversarial Robustness of Neural Network Models", "Authors": ["Preben M. Ness", "Dusica Marijan", "Sunanda Bose"], "Categories": "cs.LG", "Comments": ["12 pages", "3 figures"]}, "abstract": "Causal Neural Network models have shown high levels of robustness to adversarial attacks as well as an increased capacity for generalisation tasks such as few-shot learning and rare-context classification compared to traditional Neural Networks. This robustness is argued to stem from the disentanglement of causal and confounder input signals. However, no quantitative study has yet measured the level of disentanglement achieved by these types of causal models or assessed how this relates to their adversarial robustness. Existing causal disentanglement metrics are not applicable to deterministic models trained on real-world datasets. We, therefore, utilise metrics of content/style disentanglement from the field of Computer Vision to measure different aspects of the causal disentanglement for four state-of-the-art causal Neural Network models. By re-implementing these models with a common ResNet18 architecture we are able to fairly measure their adversarial robustness on three standard image classification benchmarking datasets under seven common white-box attacks. We find a strong association (r=0.820, p=0.001) between the degree to which models decorrelate causal and confounder signals and their adversarial robustness. Additionally, we find a moderate negative association between the pixel-level information content of the confounder signal and adversarial robustness (r=-0.597, p=0.040).", "url": "https://arxiv.org/abs/2308.10708"}, {"metadata": {"arXiv": "2308.10711", "Date": "Mon, 21 Aug 2023 13:24:52 ", "Title": "Relax and penalize: a new bilevel approach to mixed-binary hyperparameter optimization", "Authors": ["Marianna de Santis (UNIROMA)", "Jordan Frecon (LHC)", "Francesco Rinaldi (Unipd)", "Saverio Salzo (DIAG UNIROMA)", "Martin Schmidt"], "Categories": "cs.LG"}, "abstract": "In recent years, bilevel approaches have become very popular to efficiently estimate high-dimensional hyperparameters of machine learning models. However, to date, binary parameters are handled by continuous relaxation and rounding strategies, which could lead to inconsistent solutions. In this context, we tackle the challenging optimization of mixed-binary hyperparameters by resorting to an equivalent continuous bilevel reformulation based on an appropriate penalty term. We propose an algorithmic framework that, under suitable assumptions, is guaranteed to provide mixed-binary solutions. Moreover, the generality of the method allows to safely use existing continuous bilevel solvers within the proposed framework. We evaluate the performance of our approach for a specific machine learning problem, i.e., the estimation of the group-sparsity structure in regression problems. Reported results clearly show that our method outperforms state-of-the-art approaches based on relaxation and rounding", "url": "https://arxiv.org/abs/2308.10711"}, {"metadata": {"arXiv": "2308.10722", "Date": "Mon, 21 Aug 2023 13:47:13 ", "Title": "Clustered Linear Contextual Bandits with Knapsacks", "Authors": ["Yichuan Deng", "Michalis Mamakos", "Zhao Song"], "Categories": "cs.LG stat.ML"}, "abstract": "In this work, we study clustered contextual bandits where rewards and resource consumption are the outcomes of cluster-specific linear models. The arms are divided in clusters, with the cluster memberships being unknown to an algorithm. Pulling an arm in a time period results in a reward and in consumption for each one of multiple resources, and with the total consumption of any resource exceeding a constraint implying the termination of the algorithm. Thus, maximizing the total reward requires learning not only models about the reward and the resource consumption, but also cluster memberships. We provide an algorithm that achieves regret sublinear in the number of time periods, without requiring access to all of the arms. In particular, we show that it suffices to perform clustering only once to a randomly selected subset of the arms. To achieve this result, we provide a sophisticated combination of techniques from the literature of econometrics and of bandits with constraints.", "url": "https://arxiv.org/abs/2308.10722"}, {"metadata": {"arXiv": "2308.10737", "Date": "Mon, 21 Aug 2023 14:05:21 ", "Title": "UGSL: A Unified Framework for Benchmarking Graph Structure Learning", "Authors": ["Bahare Fatemi", "Sami Abu-El-Haija", "Anton Tsitsulin", "Mehran Kazemi", "Dustin Zelle", "Neslihan Bulut", "Jonathan Halcrow", "Bryan Perozzi"], "Categories": "cs.LG"}, "abstract": "Graph neural networks (GNNs) demonstrate outstanding performance in a broad range of applications. While the majority of GNN applications assume that a graph structure is given, some recent methods substantially expanded the applicability of GNNs by showing that they may be effective even when no graph structure is explicitly provided. The GNN parameters and a graph structure are jointly learned. Previous studies adopt different experimentation setups, making it difficult to compare their merits. In this paper, we propose a benchmarking strategy for graph structure learning using a unified framework. Our framework, called Unified Graph Structure Learning (UGSL), reformulates existing models into a single model. We implement a wide range of existing models in our framework and conduct extensive analyses of the effectiveness of different components in the framework. Our results provide a clear and concise understanding of the different methods in this area as well as their strengths and weaknesses. The benchmark code is available at https://github.com/google-research/google-research/tree/master/ugsl.", "url": "https://arxiv.org/abs/2308.10737"}, {"metadata": {"arXiv": "2308.10767", "Date": "Mon, 21 Aug 2023 14:56:51 ", "Title": "GBM-based Bregman Proximal Algorithms for Constrained Learning", "Authors": ["Zhenwei Lin", "Qi Deng"], "Categories": "cs.LG"}, "abstract": "As the complexity of learning tasks surges, modern machine learning encounters a new constrained learning paradigm characterized by more intricate and data-driven function constraints. Prominent applications include Neyman-Pearson classification (NPC) and fairness classification, which entail specific risk constraints that render standard projection-based training algorithms unsuitable. Gradient boosting machines (GBMs) are among the most popular algorithms for supervised learning; however, they are generally limited to unconstrained settings. In this paper, we adapt the GBM for constrained learning tasks within the framework of Bregman proximal algorithms. We introduce a new Bregman primal-dual method with a global optimality guarantee when the learning objective and constraint functions are convex. In cases of nonconvex functions, we demonstrate how our algorithm remains effective under a Bregman proximal point framework. Distinct from existing constrained learning algorithms, ours possess a unique advantage in their ability to seamlessly integrate with publicly available GBM implementations such as XGBoost (Chen and Guestrin, 2016) and LightGBM (Ke et al., 2017), exclusively relying on their public interfaces. We provide substantial experimental evidence to showcase the effectiveness of the Bregman algorithm framework. While our primary focus is on NPC and fairness ML, our framework holds significant potential for a broader range of constrained learning applications. The source code is currently freely available at https://github.com/zhenweilin/ConstrainedGBM}{https://github.com/zhenweilin/ConstrainedGBM.", "url": "https://arxiv.org/abs/2308.10767"}, {"metadata": {"arXiv": "2308.10779", "Date": "Mon, 21 Aug 2023 15:09:51 ", "Title": "Spear and Shield: Adversarial Attacks and Defense Methods for Model-Based Link Prediction on Continuous-Time Dynamic Graphs", "Authors": ["Dongjin Lee", "Juho Lee", "Kijung Shin"], "Categories": "cs.LG cs.SI"}, "abstract": "Real-world graphs are dynamic, constantly evolving with new interactions, such as financial transactions in financial networks. Temporal Graph Neural Networks (TGNNs) have been developed to effectively capture the evolving patterns in dynamic graphs. While these models have demonstrated their superiority, being widely adopted in various important fields, their vulnerabilities against adversarial attacks remain largely unexplored. In this paper, we propose T-SPEAR, a simple and effective adversarial attack method for link prediction on continuous-time dynamic graphs, focusing on investigating the vulnerabilities of TGNNs. Specifically, before the training procedure of a victim model, which is a TGNN for link prediction, we inject edge perturbations to the data that are unnoticeable in terms of the four constraints we propose, and yet effective enough to cause malfunction of the victim model. Moreover, we propose a robust training approach T-SHIELD to mitigate the impact of adversarial attacks. By using edge filtering and enforcing temporal smoothness to node embeddings, we enhance the robustness of the victim model. Our experimental study shows that T-SPEAR significantly degrades the victim model's performance on link prediction tasks, and even more, our attacks are transferable to other TGNNs, which differ from the victim model assumed by the attacker. Moreover, we demonstrate that T-SHIELD effectively filters out adversarial edges and exhibits robustness against adversarial attacks, surpassing the link prediction performance of the naive TGNN by up to 11.2% under T-SPEAR.", "url": "https://arxiv.org/abs/2308.10779"}, {"metadata": {"arXiv": "2308.10781", "Date": "Mon, 21 Aug 2023 15:14:49 ", "Title": "Mixed-Integer Projections for Automated Data Correction of EMRs Improve Predictions of Sepsis among Hospitalized Patients", "Authors": ["Mehak Arora", "Hassan Mortagy", "Nathan Dwarshius", "Swati Gupta", "Andre L. Holder", "Rishikesan Kamaleswaran"], "Categories": "cs.LG", "MSC-class": "90, 92"}, "abstract": "Machine learning (ML) models are increasingly pivotal in automating clinical decisions. Yet, a glaring oversight in prior research has been the lack of proper processing of Electronic Medical Record (EMR) data in the clinical context for errors and outliers. Addressing this oversight, we introduce an innovative projections-based method that seamlessly integrates clinical expertise as domain constraints, generating important meta-data that can be used in ML workflows. In particular, by using high-dimensional mixed-integer programs that capture physiological and biological constraints on patient vitals and lab values, we can harness the power of mathematical \"projections\" for the EMR data to correct patient data. Consequently, we measure the distance of corrected data from the constraints defining a healthy range of patient data, resulting in a unique predictive metric we term as \"trust-scores\". These scores provide insight into the patient's health status and significantly boost the performance of ML classifiers in real-life clinical settings. We validate the impact of our framework in the context of early detection of sepsis using ML. We show an AUROC of 0.865 and a precision of 0.922, that surpasses conventional ML models without such projections.", "url": "https://arxiv.org/abs/2308.10781"}, {"metadata": {"arXiv": "2308.10807", "Date": "Mon, 21 Aug 2023 15:56:05 ", "Title": "DynED: Dynamic Ensemble Diversification in Data Stream Classification", "Authors": ["Soheil Abadifard", "Sepehr Bakhshi", "Sanaz Gheibuni", "Fazli Can"], "Categories": "cs.LG cs.IR", "Comments": ["Proceedings of the 32nd ACM International Conference on Information and Knowledge Management (CIKM '23)", "October 21--25", "2023", "Birmingham", "United Kingdom"], "DOI": "10.1145/3583780.3615266"}, "abstract": "Ensemble methods are commonly used in classification due to their remarkable performance. Achieving high accuracy in a data stream environment is a challenging task considering disruptive changes in the data distribution, also known as concept drift. A greater diversity of ensemble components is known to enhance prediction accuracy in such settings. Despite the diversity of components within an ensemble, not all contribute as expected to its overall performance. This necessitates a method for selecting components that exhibit high performance and diversity. We present a novel ensemble construction and maintenance approach based on MMR (Maximal Marginal Relevance) that dynamically combines the diversity and prediction accuracy of components during the process of structuring an ensemble. The experimental results on both four real and 11 synthetic datasets demonstrate that the proposed approach (DynED) provides a higher average mean accuracy compared to the five state-of-the-art baselines.", "url": "https://arxiv.org/abs/2308.10807"}, {"metadata": {"arXiv": "2308.10808", "Date": "Mon, 21 Aug 2023 15:57:57 ", "Title": "Graph Neural Bandits", "Authors": ["Yunzhe Qi", "Yikun Ban", "Jingrui He"], "Categories": "cs.LG", "Comments": ["Accepted to SIGKDD 2023"], "DOI": "10.1145/3580305.3599371"}, "abstract": "Contextual bandits algorithms aim to choose the optimal arm with the highest reward out of a set of candidates based on the contextual information. Various bandit algorithms have been applied to real-world applications due to their ability of tackling the exploitation-exploration dilemma. Motivated by online recommendation scenarios, in this paper, we propose a framework named Graph Neural Bandits (GNB) to leverage the collaborative nature among users empowered by graph neural networks (GNNs). Instead of estimating rigid user clusters as in existing works, we model the \"fine-grained\" collaborative effects through estimated user graphs in terms of exploitation and exploration respectively. Then, to refine the recommendation strategy, we utilize separate GNN-based models on estimated user graphs for exploitation and adaptive exploration. Theoretical analysis and experimental results on multiple real data sets in comparison with state-of-the-art baselines are provided to demonstrate the effectiveness of our proposed framework.", "url": "https://arxiv.org/abs/2308.10808"}, {"metadata": {"arXiv": "2308.10856", "Date": "Mon, 21 Aug 2023 16:50:59 ", "Title": "Majorana Demonstrator Data Release for AI/ML Applications", "Authors": ["I.J. Arnquist", "F.T. Avignone III", "A.S. Barabash", "C.J. Barton", "K.H. Bhimani", "E. Blalock", "B. Bos", "M. Busch", "M. Buuck", "T.S. Caldwell", "Y.-D. Chan", "C.D. Christofferson", "P.-H. Chu", "M.L. Clark", "C. Cuesta", "J.A. Detwiler", "Yu. Efremenko", "H. Ejiri", "S.R. Elliott", "N. Fuad", "G.K. Giovanetti", "M.P. Green", "J. Gruszko", "I.S. Guinn", "V.E. Guiseppe", "C.R. Haufe", "R. Henning", "D. Hervas Aguilar", "E.W. Hoppe", "A. Hostiuc", "M.F. Kidd", "I. Kim", "R.T. Kouzes", "T.E. Lannen V", "A. Li", "J.M. Lopez-Castano", "R.D. Martin", "R. Massarczyk", "S.J. Meijer", "S. Mertens", "T.K. Oli", "L.S. Paudel", "W. Pettus", "A.W.P. Poon", "B. Quenallata", "D.C. Radford", "A.L. Reine", "K. Rielage", "N.W. Ruof", "D.C. Schaper", "S.J. Schleich", "D. Tedeschi", "R.L. Varner", "S. Vasilyev", "S.L. Watkins", "J.F. Wilkerson", "C. Wiseman", "W. Xu", "C.-H. Yu", "and B.X. Zhu"], "Categories": "cs.LG nucl-ex physics.data-an physics.ins-det", "Comments": ["Zenodo DOI: 10.5281/zenodo.8257027"]}, "abstract": "The enclosed data release consists of a subset of the calibration data from the Majorana Demonstrator experiment. Each Majorana event is accompanied by raw Germanium detector waveforms, pulse shape discrimination cuts, and calibrated final energies, all shared in an HDF5 file format along with relevant metadata. This release is specifically designed to support the training and testing of Artificial Intelligence (AI) and Machine Learning (ML) algorithms upon our data. This document is structured as follows. Section I provides an overview of the dataset's content and format; Section II outlines the location of this dataset and the method for accessing it; Section III presents the NPML Machine Learning Challenge associated with this dataset; Section IV contains a disclaimer from the Majorana collaboration regarding the use of this dataset; Appendix A contains technical details of this data release. Please direct questions about the material provided within this release to liaobo77@ucsd.edu (A. Li).", "url": "https://arxiv.org/abs/2308.10856"}, {"metadata": {"arXiv": "2308.10888", "Date": "Mon, 21 Aug 2023 17:42:33 ", "Title": "Unlocking Accuracy and Fairness in Differentially Private Image Classification", "Authors": ["Leonard Berrada", "Soham De", "Judy Hanwen Shen", "Jamie Hayes", "Robert Stanforth", "David Stutz", "Pushmeet Kohli", "Samuel L. Smith", "Borja Balle"], "Categories": "cs.LG cs.CV cs.CY"}, "abstract": "Privacy-preserving machine learning aims to train models on private data without leaking sensitive information. Differential privacy (DP) is considered the gold standard framework for privacy-preserving training, as it provides formal privacy guarantees. However, compared to their non-private counterparts, models trained with DP often have significantly reduced accuracy. Private classifiers are also believed to exhibit larger performance disparities across subpopulations, raising fairness concerns. The poor performance of classifiers trained with DP has prevented the widespread adoption of privacy preserving machine learning in industry. Here we show that pre-trained foundation models fine-tuned with DP can achieve similar accuracy to non-private classifiers, even in the presence of significant distribution shifts between pre-training data and downstream tasks. We achieve private accuracies within a few percent of the non-private state of the art across four datasets, including two medical imaging benchmarks. Furthermore, our private medical classifiers do not exhibit larger performance disparities across demographic groups than non-private models. This milestone to make DP training a practical and reliable technology has the potential to widely enable machine learning practitioners to train safely on sensitive datasets while protecting individuals' privacy.", "url": "https://arxiv.org/abs/2308.10888"}, {"metadata": {"arXiv": "2308.10893", "Date": "Thu, 17 Aug 2023 19:29:44 ", "Title": "Online Transition-Based Feature Generation for Anomaly Detection in Concurrent Data Streams", "Authors": ["Yinzheng Zhong and Alexei Lisitsa"], "Categories": "cs.LG cs.DB"}, "abstract": "In this paper, we introduce the transition-based feature generator (TFGen) technique, which reads general activity data with attributes and generates step-by-step generated data. The activity data may consist of network activity from packets, system calls from processes or classified activity from surveillance cameras. TFGen processes data online and will generate data with encoded historical data for each incoming activity with high computational efficiency. The input activities may concurrently originate from distinct traces or channels. The technique aims to address issues such as domain-independent applicability, the ability to discover global process structures, the encoding of time-series data, and online processing capability.", "url": "https://arxiv.org/abs/2308.10893"}, {"metadata": {"arXiv": "2308.10124", "Date": "Sat, 19 Aug 2023 22:59:09 ", "Title": "Intelligent Communication Planning for Constrained Environmental IoT Sensing with Reinforcement Learning", "Authors": ["Yi Hu", "Jinhang Zuo", "Bob Iannucci and Carlee Joe-Wong"], "Categories": "cs.MA cs.LG cs.SY eess.SY", "Comments": ["To be published in the 20th Annual IEEE International Conference on Sensing", "Communication", "and Networking (SECON 2023)"]}, "abstract": "Internet of Things (IoT) technologies have enabled numerous data-driven mobile applications and have the potential to significantly improve environmental monitoring and hazard warnings through the deployment of a network of IoT sensors. However, these IoT devices are often power-constrained and utilize wireless communication schemes with limited bandwidth. Such power constraints limit the amount of information each device can share across the network, while bandwidth limitations hinder sensors' coordination of their transmissions. In this work, we formulate the communication planning problem of IoT sensors that track the state of the environment. We seek to optimize sensors' decisions in collecting environmental data under stringent resource constraints. We propose a multi-agent reinforcement learning (MARL) method to find the optimal communication policies for each sensor that maximize the tracking accuracy subject to the power and bandwidth limitations. MARL learns and exploits the spatial-temporal correlation of the environmental data at each sensor's location to reduce the redundant reports from the sensors. Experiments on wildfire spread with LoRA wireless network simulators show that our MARL method can learn to balance the need to collect enough data to predict wildfire spread with unknown bandwidth limitations.", "url": "https://arxiv.org/abs/2308.10124"}, {"metadata": {"arXiv": "2308.10090", "Date": "Sat, 19 Aug 2023 18:53:53 ", "Title": "Minimizing Turns in Watchman Robot Navigation: Strategies and Solutions", "Authors": ["Hamid Hoorfar", "Sara Moshtaghi Largani", "Reza Rahimi", "and Alireza Bagheri"], "Categories": "cs.RO cs.LG", "Comments": ["6 pages", "3 figures"], "Journal-ref": "The 21st International Conference on Scientific Computing in The 2023 World Congress in Computer Science, Computer Engineering, & Applied Computing (CSCE'23)"}, "abstract": "The Orthogonal Watchman Route Problem (OWRP) entails the search for the shortest path, known as the watchman route, that a robot must follow within a polygonal environment. The primary objective is to ensure that every point in the environment remains visible from at least one point on the route, allowing the robot to survey the entire area in a single, continuous sweep. This research places particular emphasis on reducing the number of turns in the route, as it is crucial for optimizing navigation in watchman routes within the field of robotics. The cost associated with changing direction is of significant importance, especially for specific types of robots. This paper introduces an efficient linear-time algorithm for solving the OWRP under the assumption that the environment is monotone. The findings of this study contribute to the progress of robotic systems by enabling the design of more streamlined patrol robots. These robots are capable of efficiently navigating complex environments while minimizing the number of turns. This advancement enhances their coverage and surveillance capabilities, making them highly effective in various real-world applications.", "url": "https://arxiv.org/abs/2308.10090"}, {"metadata": {"arXiv": "2308.10093", "Date": "Sat, 19 Aug 2023 19:05:13 ", "Title": "Securing Pathways with Orthogonal Robots", "Authors": ["Hamid Hoorfar", "Faraneh Fathi", "Sara Moshtaghi Largani", "and Alireza Bagheri"], "Categories": "cs.RO cs.LG", "Comments": ["8 pages", "5 figures"], "Journal-ref": "The 21st International Conference on Scientific Computing in The 2023 World Congress in Computer Science, Computer Engineering, & Applied Computing (CSCE'23)"}, "abstract": "The protection of pathways holds immense significance across various domains, including urban planning, transportation, surveillance, and security. This article introduces a groundbreaking approach to safeguarding pathways by employing orthogonal robots. The study specifically addresses the challenge of efficiently guarding orthogonal areas with the minimum number of orthogonal robots. The primary focus is on orthogonal pathways, characterized by a path-like dual graph of vertical decomposition. It is demonstrated that determining the minimum number of orthogonal robots for pathways can be achieved in linear time. However, it is essential to note that the general problem of finding the minimum number of robots for simple polygons with general visibility, even in the orthogonal case, is known to be NP-hard. Emphasis is placed on the flexibility of placing robots anywhere within the polygon, whether on the boundary or in the interior.", "url": "https://arxiv.org/abs/2308.10093"}, {"metadata": {"arXiv": "2308.10312", "Date": "Sun, 20 Aug 2023 16:17:18 ", "Title": "Demystifying the Performance of Data Transfers in High-Performance Research Networks", "Authors": ["Ehsan Saeedizade", "Bing Zhang", "Engin Arslan"], "Categories": "eess.SY cs.DC cs.LG cs.NI cs.SY", "Comments": ["11 pages", "7 figures", "6 tables"]}, "abstract": "High-speed research networks are built to meet the ever-increasing needs of data-intensive distributed workflows. However, data transfers in these networks often fail to attain the promised transfer rates for several reasons, including I/O and network interference, server misconfigurations, and network anomalies. Although understanding the root causes of performance issues is critical to mitigating them and increasing the utilization of expensive network infrastructures, there is currently no available mechanism to monitor data transfers in these networks. In this paper, we present a scalable, end-to-end monitoring framework to gather and store key performance metrics for file transfers to shed light on the performance of transfers. The evaluation results show that the proposed framework can monitor up to 400 transfers per host and more than 40, 000 transfers in total while collecting performance statistics at one-second precision. We also introduce a heuristic method to automatically process the gathered performance metrics and identify the root causes of performance anomalies with an F-score of 87 - 98%.", "url": "https://arxiv.org/abs/2308.10312"}, {"metadata": {"arXiv": "2308.09719", "Date": "Mon, 07 Aug 2023 11:12:09 ", "Title": "CIRO: COVID-19 infection risk ontology", "Authors": ["Shusaku Egami", "Yasunori Yamamoto", "Ikki Ohmukai", "Takashi Okumura"], "Categories": "cs.AI cs.CY", "Comments": ["18 pages", "8 figures", "and this paper has been accepted by PLOS ONE"], "ACM-class": "I.2.4; J.3", "Journal-ref": "PLoS One, 18(3), e0282291, 2023", "DOI": "10.1371/journal.pone.0282291"}, "abstract": "Public health authorities perform contact tracing for highly contagious agents to identify close contacts with the infected cases. However, during the pandemic caused by coronavirus disease 2019 (COVID-19), this operation was not employed in countries with high patient volumes. Meanwhile, the Japanese government conducted this operation, thereby contributing to the control of infections, at the cost of arduous manual labor by public health officials. To ease the burden of the officials, this study attempted to automate the assessment of each person's infection risk through an ontology, called COVID-19 Infection Risk Ontology (CIRO). This ontology expresses infection risks of COVID-19 formulated by the Japanese government, toward automated assessment of infection risks of individuals, using Resource Description Framework (RDF) and SPARQL (SPARQL Protocol and RDF Query Language) queries. For evaluation, we demonstrated that the knowledge graph built could infer the risks, formulated by the government. Moreover, we conducted reasoning experiments to analyze the computational efficiency. The experiments demonstrated usefulness of the knowledge processing, and identified issues left for deployment.", "url": "https://arxiv.org/abs/2308.09719"}, {"metadata": {"arXiv": "2308.09830", "Date": "Fri, 18 Aug 2023 21:42:47 ", "Title": "Synergistic Integration of Large Language Models and Cognitive Architectures for Robust AI: An Exploratory Analysis", "Authors": ["Oscar J. Romero", "John Zimmerman", "Aaron Steinfeld", "Anthony Tomasic"], "Categories": "cs.AI", "Comments": ["AAAI 2023 Fall Symposium"]}, "abstract": "This paper explores alternatives for integrating two subdisciplines of AI in the construction of artificial agents that exhibit intelligent behavior: Large Language Models (LLMs) and Cognitive Architectures (CAs). Guided by theoretical models and supported by preliminary empirical data, we hypothesize how diverse synergistic approaches can mutually compensate for their respective weaknesses and limitations, ultimately fostering more robust and sophisticated artificial intelligence systems. Additionally, we discuss the tradeoffs and challenges associated with each approach.", "url": "https://arxiv.org/abs/2308.09830"}, {"metadata": {"arXiv": "2308.10354", "Date": "Sun, 20 Aug 2023 20:10:55 ", "Title": "Imaginations of WALL-E : Reconstructing Experiences with an Imagination-Inspired Module for Advanced AI Systems", "Authors": ["Zeinab Sadat Taghavi", "Soroush Gooran", "Seyed Arshan Dalili", "Hamidreza Amirzadeh", "Mohammad Jalal Nematbakhsh", "Hossein Sameti"], "Categories": "cs.AI cs.CL", "Comments": ["18 pages,"]}, "abstract": "In this paper, we introduce a novel Artificial Intelligence (AI) system inspired by the philosophical and psychoanalytical concept of imagination as a ``Re-construction of Experiences\". Our AI system is equipped with an imagination-inspired module that bridges the gap between textual inputs and other modalities, enriching the derived information based on previously learned experiences. A unique feature of our system is its ability to formulate independent perceptions of inputs. This leads to unique interpretations of a concept that may differ from human interpretations but are equally valid, a phenomenon we term as ``Interpretable Misunderstanding\". We employ large-scale models, specifically a Multimodal Large Language Model (MLLM), enabling our proposed system to extract meaningful information across modalities while primarily remaining unimodal. We evaluated our system against other large language models across multiple tasks, including emotion recognition and question-answering, using a zero-shot methodology to ensure an unbiased scenario that may happen by fine-tuning. Significantly, our system outperformed the best Large Language Models (LLM) on the MELD, IEMOCAP, and CoQA datasets, achieving Weighted F1 (WF1) scores of 46.74%, 25.23%, and Overall F1 (OF1) score of 17%, respectively, compared to 22.89%, 12.28%, and 7% from the well-performing LLM. The goal is to go beyond the statistical view of language processing and tie it to human concepts such as philosophy and psychoanalysis. This work represents a significant advancement in the development of imagination-inspired AI systems, opening new possibilities for AI to generate deep and interpretable information across modalities, thereby enhancing human-AI interaction.", "url": "https://arxiv.org/abs/2308.10354"}, {"metadata": {"arXiv": "2308.10380", "Date": "Sun, 20 Aug 2023 22:42:04 ", "Title": "A Human-on-the-Loop Optimization Autoformalism Approach for Sustainability", "Authors": ["Ming Jin", "Bilgehan Sel", "Fnu Hardeep", "Wotao Yin"], "Categories": "cs.AI cs.CL"}, "abstract": "This paper outlines a natural conversational approach to solving personalized energy-related problems using large language models (LLMs). We focus on customizable optimization problems that necessitate repeated solving with slight variations in modeling and are user-specific, hence posing a challenge to devising a one-size-fits-all model. We put forward a strategy that augments an LLM with an optimization solver, enhancing its proficiency in understanding and responding to user specifications and preferences while providing nonlinear reasoning capabilities. Our approach pioneers the novel concept of human-guided optimization autoformalism, translating a natural language task specification automatically into an optimization instance. This enables LLMs to analyze, explain, and tackle a variety of instance-specific energy-related problems, pushing beyond the limits of current prompt-based techniques. Our research encompasses various commonplace tasks in the energy sector, from electric vehicle charging and Heating, Ventilation, and Air Conditioning (HVAC) control to long-term planning problems such as cost-benefit evaluations for installing rooftop solar photovoltaics (PVs) or heat pumps. This pilot study marks an essential stride towards the context-based formulation of optimization using LLMs, with the potential to democratize optimization processes. As a result, stakeholders are empowered to optimize their energy consumption, promoting sustainable energy practices customized to personal needs and preferences.", "url": "https://arxiv.org/abs/2308.10380"}, {"metadata": {"arXiv": "2308.10441", "Date": "Mon, 21 Aug 2023 03:28:23 ", "Title": "X-VoE: Measuring eXplanatory Violation of Expectation in Physical Events", "Authors": ["Bo Dai", "Linge Wang", "Baoxiong Jia", "Zeyu Zhang", "Song-Chun Zhu", "Chi Zhang", "Yixin Zhu"], "Categories": "cs.AI cs.CV", "Comments": ["19 pages", "16 figures", "selected for an Oral presentation at ICCV 2023. Project link: https://pku.ai/publication/intuitive2023iccv/"]}, "abstract": "Intuitive physics is pivotal for human understanding of the physical world, enabling prediction and interpretation of events even in infancy. Nonetheless, replicating this level of intuitive physics in artificial intelligence (AI) remains a formidable challenge. This study introduces X-VoE, a comprehensive benchmark dataset, to assess AI agents' grasp of intuitive physics. Built on the developmental psychology-rooted Violation of Expectation (VoE) paradigm, X-VoE establishes a higher bar for the explanatory capacities of intuitive physics models. Each VoE scenario within X-VoE encompasses three distinct settings, probing models' comprehension of events and their underlying explanations. Beyond model evaluation, we present an explanation-based learning system that captures physics dynamics and infers occluded object states solely from visual sequences, without explicit occlusion labels. Experimental outcomes highlight our model's alignment with human commonsense when tested against X-VoE. A remarkable feature is our model's ability to visually expound VoE events by reconstructing concealed scenes. Concluding, we discuss the findings' implications and outline future research directions. Through X-VoE, we catalyze the advancement of AI endowed with human-like intuitive physics capabilities.", "url": "https://arxiv.org/abs/2308.10441"}, {"metadata": {"arXiv": "2308.10443", "Date": "Mon, 21 Aug 2023 03:30:21 ", "Title": "Using Large Language Models for Cybersecurity Capture-The-Flag Challenges and Certification Questions", "Authors": ["Wesley Tann", "Yuancheng Liu", "Jun Heng Sim", "Choon Meng Seah", "Ee-Chien Chang"], "Categories": "cs.AI cs.CL cs.CY"}, "abstract": "The assessment of cybersecurity Capture-The-Flag (CTF) exercises involves participants finding text strings or ``flags'' by exploiting system vulnerabilities. Large Language Models (LLMs) are natural-language models trained on vast amounts of words to understand and generate text; they can perform well on many CTF challenges. Such LLMs are freely available to students. In the context of CTF exercises in the classroom, this raises concerns about academic integrity. Educators must understand LLMs' capabilities to modify their teaching to accommodate generative AI assistance. This research investigates the effectiveness of LLMs, particularly in the realm of CTF challenges and questions. Here we evaluate three popular LLMs, OpenAI ChatGPT, Google Bard, and Microsoft Bing. First, we assess the LLMs' question-answering performance on five Cisco certifications with varying difficulty levels. Next, we qualitatively study the LLMs' abilities in solving CTF challenges to understand their limitations. We report on the experience of using the LLMs for seven test cases in all five types of CTF challenges. In addition, we demonstrate how jailbreak prompts can bypass and break LLMs' ethical safeguards. The paper concludes by discussing LLM's impact on CTF exercises and its implications.", "url": "https://arxiv.org/abs/2308.10443"}, {"metadata": {"arXiv": "2308.10454", "Date": "Mon, 21 Aug 2023 04:00:56 ", "Title": "Elucidating STEM Concepts through Generative AI: A Multi-modal Exploration of Analogical Reasoning", "Authors": ["Chen Cao", "Zijian Ding", "Gyeong-Geon Lee", "Jiajun Jiao", "Jionghao Lin", "Xiaoming Zhai"], "Categories": "cs.AI cs.CY cs.HC", "Journal-ref": "IJCAI2023 Symposium on Multimodal Reasoning with LLM"}, "abstract": "This study explores the integration of generative artificial intelligence (AI), specifically large language models, with multi-modal analogical reasoning as an innovative approach to enhance science, technology, engineering, and mathematics (STEM) education. We have developed a novel system that utilizes the capacities of generative AI to transform intricate principles in mathematics, physics, and programming into comprehensible metaphors. To further augment the educational experience, these metaphors are subsequently converted into visual form. Our study aims to enhance the learners' understanding of STEM concepts and their learning engagement by using the visual metaphors. We examine the efficacy of our system via a randomized A/B/C test, assessing learning gains and motivation shifts among the learners. Our study demonstrates the potential of applying large language models to educational practice on STEM subjects. The results will shed light on the design of educational system in terms of harnessing AI's potential to empower educational stakeholders.", "url": "https://arxiv.org/abs/2308.10454"}, {"metadata": {"arXiv": "2308.10882", "Date": "Mon, 21 Aug 2023 17:30:16 ", "Title": "Giraffe: Adventures in Expanding Context Lengths in LLMs", "Authors": ["Arka Pal", "Deep Karkhanis", "Manley Roberts", "Samuel Dooley", "Arvind Sundararajan", "Siddartha Naidu"], "Categories": "cs.AI cs.CL"}, "abstract": "Modern large language models (LLMs) that rely on attention mechanisms are typically trained with fixed context lengths which enforce upper limits on the length of input sequences that they can handle at evaluation time. To use these models on sequences longer than the train-time context length, one might employ techniques from the growing family of context length extrapolation methods -- most of which focus on modifying the system of positional encodings used in the attention mechanism to indicate where tokens or activations are located in the input sequence. We conduct a wide survey of existing methods of context length extrapolation on a base LLaMA or LLaMA 2 model, and introduce some of our own design as well -- in particular, a new truncation strategy for modifying the basis for the position encoding. We test these methods using three new evaluation tasks (FreeFormQA, AlteredNumericQA, and LongChat-Lines) as well as perplexity, which we find to be less fine-grained as a measure of long context performance of LLMs. We release the three tasks publicly as datasets on HuggingFace. We discover that linear scaling is the best method for extending context length, and show that further gains can be achieved by using longer scales at evaluation time. We also discover promising extrapolation capabilities in the truncated basis. To support further research in this area, we release three new 13B parameter long-context models which we call Giraffe: 4k and 16k context models trained from base LLaMA-13B, and a 32k context model trained from base LLaMA2-13B. We also release the code to replicate our results.", "url": "https://arxiv.org/abs/2308.10882"}, {"metadata": {"arXiv": "2308.10899", "Date": "Mon, 21 Aug 2023 17:59:10 ", "Title": "TADA! Text to Animatable Digital Avatars", "Authors": ["Tingting Liao", "Hongwei Yi", "Yuliang Xiu", "Jiaxaing Tang", "Yangyi Huang", "Justus Thies", "Michael J. Black"], "Categories": "cs.AI"}, "abstract": "We introduce TADA, a simple-yet-effective approach that takes textual descriptions and produces expressive 3D avatars with high-quality geometry and lifelike textures, that can be animated and rendered with traditional graphics pipelines. Existing text-based character generation methods are limited in terms of geometry and texture quality, and cannot be realistically animated due to inconsistent alignment between the geometry and the texture, particularly in the face region. To overcome these limitations, TADA leverages the synergy of a 2D diffusion model and an animatable parametric body model. Specifically, we derive an optimizable high-resolution body model from SMPL-X with 3D displacements and a texture map, and use hierarchical rendering with score distillation sampling (SDS) to create high-quality, detailed, holistic 3D avatars from text. To ensure alignment between the geometry and texture, we render normals and RGB images of the generated character and exploit their latent embeddings in the SDS training process. We further introduce various expression parameters to deform the generated character during training, ensuring that the semantics of our generated character remain consistent with the original SMPL-X model, resulting in an animatable character. Comprehensive evaluations demonstrate that TADA significantly surpasses existing approaches on both qualitative and quantitative measures. TADA enables creation of large-scale digital character assets that are ready for animation and rendering, while also being easily editable through natural language. The code will be public for research purposes.", "url": "https://arxiv.org/abs/2308.10899"}, {"metadata": {"arXiv": "2308.09891", "Date": "Sat, 19 Aug 2023 03:08:28 ", "Title": "SwinLSTM:Improving Spatiotemporal Prediction Accuracy using Swin Transformer and LSTM", "Authors": ["Song Tang", "Chuang Li", "Pu Zhang", "RongNian Tang"], "Categories": "cs.CV cs.AI", "Comments": ["This paper has been accepted by ICCV 2023"]}, "abstract": "Integrating CNNs and RNNs to capture spatiotemporal dependencies is a prevalent strategy for spatiotemporal prediction tasks. However, the property of CNNs to learn local spatial information decreases their efficiency in capturing spatiotemporal dependencies, thereby limiting their prediction accuracy. In this paper, we propose a new recurrent cell, SwinLSTM, which integrates Swin Transformer blocks and the simplified LSTM, an extension that replaces the convolutional structure in ConvLSTM with the self-attention mechanism. Furthermore, we construct a network with SwinLSTM cell as the core for spatiotemporal prediction. Without using unique tricks, SwinLSTM outperforms state-of-the-art methods on Moving MNIST, Human3.6m, TaxiBJ, and KTH datasets. In particular, it exhibits a significant improvement in prediction accuracy compared to ConvLSTM. Our competitive experimental results demonstrate that learning global spatial dependencies is more advantageous for models to capture spatiotemporal dependencies. We hope that SwinLSTM can serve as a solid baseline to promote the advancement of spatiotemporal prediction accuracy. The codes are publicly available at https://github.com/SongTang-x/SwinLSTM.", "url": "https://arxiv.org/abs/2308.09891"}, {"metadata": {"arXiv": "2308.09908", "Date": "Sat, 19 Aug 2023 05:15:02 ", "Title": "LEGO: Learning and Graph-Optimized Modular Tracker for Online Multi-Object Tracking with Point Clouds", "Authors": ["Zhenrong Zhang", "Jianan Liu", "Yuxuan Xia", "Tao Huang", "Qing-Long Han", "Hongbin Liu"], "Categories": "cs.CV cs.AI"}, "abstract": "Online multi-object tracking (MOT) plays a pivotal role in autonomous systems. The state-of-the-art approaches usually employ a tracking-by-detection method, and data association plays a critical role. This paper proposes a learning and graph-optimized (LEGO) modular tracker to improve data association performance in the existing literature. The proposed LEGO tracker integrates graph optimization and self-attention mechanisms, which efficiently formulate the association score map, facilitating the accurate and efficient matching of objects across time frames. To further enhance the state update process, the Kalman filter is added to ensure consistent tracking by incorporating temporal coherence in the object states. Our proposed method utilizing LiDAR alone has shown exceptional performance compared to other online tracking approaches, including LiDAR-based and LiDAR-camera fusion-based methods. LEGO ranked 1st at the time of submitting results to KITTI object tracking evaluation ranking board and remains 2nd at the time of submitting this paper, among all online trackers in the KITTI MOT benchmark for cars1", "url": "https://arxiv.org/abs/2308.09908"}, {"metadata": {"arXiv": "2308.09917", "Date": "Sat, 19 Aug 2023 05:49:13 ", "Title": "Learning Multiscale Consistency for Self-supervised Electron Microscopy Instance Segmentation", "Authors": ["Yinda Chen", "Wei Huang", "Xiaoyu Liu", "Qi Chen", "Zhiwei Xiong"], "Categories": "cs.CV cs.AI"}, "abstract": "Instance segmentation in electron microscopy (EM) volumes poses a significant challenge due to the complex morphology of instances and insufficient annotations. Self-supervised learning has recently emerged as a promising solution, enabling the acquisition of prior knowledge of cellular tissue structures that are essential for EM instance segmentation. However, existing pretraining methods often lack the ability to capture complex visual patterns and relationships between voxels, which results in the acquired prior knowledge being insufficient for downstream EM analysis tasks. In this paper, we propose a novel pretraining framework that leverages multiscale visual representations to capture both voxel-level and feature-level consistency in EM volumes. Specifically, our framework enforces voxel-level consistency between the outputs of a Siamese network by a reconstruction function, and incorporates a cross-attention mechanism for soft feature matching to achieve fine-grained feature-level consistency. Moreover, we propose a contrastive learning scheme on the feature pyramid to extract discriminative features across multiple scales. We extensively pretrain our method on four large-scale EM datasets, achieving promising performance improvements in representative tasks of neuron and mitochondria instance segmentation.", "url": "https://arxiv.org/abs/2308.09917"}, {"metadata": {"arXiv": "2308.09921", "Date": "Sat, 19 Aug 2023 06:18:11 ", "Title": "Recap: Detecting Deepfake Video with Unpredictable Tampered Traces via Recovering Faces and Mapping Recovered Faces", "Authors": ["Juan Hu", "Xin Liao", "Difei Gao", "Satoshi Tsutsui", "Qian Wang", "Zheng Qin", "Mike Zheng Shou"], "Categories": "cs.CV cs.AI", "Comments": ["arXiv admin note: substantial text overlap with arXiv:2305.05943"]}, "abstract": "The exploitation of Deepfake techniques for malicious intentions has driven significant research interest in Deepfake detection. Deepfake manipulations frequently introduce random tampered traces, leading to unpredictable outcomes in different facial regions. However, existing detection methods heavily rely on specific forgery indicators, and as the forgery mode improves, these traces become increasingly randomized, resulting in a decline in the detection performance of methods reliant on specific forgery traces. To address the limitation, we propose Recap, a novel Deepfake detection model that exposes unspecific facial part inconsistencies by recovering faces and enlarges the differences between real and fake by mapping recovered faces. In the recovering stage, the model focuses on randomly masking regions of interest (ROIs) and reconstructing real faces without unpredictable tampered traces, resulting in a relatively good recovery effect for real faces while a poor recovery effect for fake faces. In the mapping stage, the output of the recovery phase serves as supervision to guide the facial mapping process. This mapping process strategically emphasizes the mapping of fake faces with poor recovery, leading to a further deterioration in their representation, while enhancing and refining the mapping of real faces with good representation. As a result, this approach significantly amplifies the discrepancies between real and fake videos. Our extensive experiments on standard benchmarks demonstrate that Recap is effective in multiple scenarios.", "url": "https://arxiv.org/abs/2308.09921"}, {"metadata": {"arXiv": "2308.09939", "Date": "Sat, 19 Aug 2023 08:17:41 ", "Title": "Understanding Self-attention Mechanism via Dynamical System Perspective", "Authors": ["Zhongzhan Huang", "Mingfu Liang", "Jinghui Qin", "Shanshan Zhong", "Liang Lin"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted by ICCV 2023"]}, "abstract": "The self-attention mechanism (SAM) is widely used in various fields of artificial intelligence and has successfully boosted the performance of different models. However, current explanations of this mechanism are mainly based on intuitions and experiences, while there still lacks direct modeling for how the SAM helps performance. To mitigate this issue, in this paper, based on the dynamical system perspective of the residual neural network, we first show that the intrinsic stiffness phenomenon (SP) in the high-precision solution of ordinary differential equations (ODEs) also widely exists in high-performance neural networks (NN). Thus the ability of NN to measure SP at the feature level is necessary to obtain high performance and is an important factor in the difficulty of training NN. Similar to the adaptive step-size method which is effective in solving stiff ODEs, we show that the SAM is also a stiffness-aware step size adaptor that can enhance the model's representational ability to measure intrinsic SP by refining the estimation of stiffness information and generating adaptive attention values, which provides a new understanding about why and how the SAM can benefit the model performance. This novel perspective can also explain the lottery ticket hypothesis in SAM, design new quantitative metrics of representational ability, and inspire a new theoretic-inspired approach, StepNet. Extensive experiments on several popular benchmarks demonstrate that StepNet can extract fine-grained stiffness information and measure SP accurately, leading to significant improvements in various visual tasks.", "url": "https://arxiv.org/abs/2308.09939"}, {"metadata": {"arXiv": "2308.10103", "Date": "Sat, 19 Aug 2023 20:18:15 ", "Title": "ASPIRE: Language-Guided Augmentation for Robust Image Classification", "Authors": ["Sreyan Ghosh", "Chandra Kiran Reddy Evuru", "Sonal Kumar", "Utkarsh Tyagi", "Sakshi Singh", "Sanjoy Chowdhury and Dinesh Manocha"], "Categories": "cs.CV cs.AI cs.CL", "Comments": ["Pre-print Under Review"]}, "abstract": "Neural image classifiers can often learn to make predictions by overly relying on non-predictive features that are spuriously correlated with the class labels in the training data. This leads to poor performance in real-world atypical scenarios where such features are absent. Supplementing the training dataset with images without such spurious features can aid robust learning against spurious correlations via better generalization. This paper presents ASPIRE (Language-guided data Augmentation for SPurIous correlation REmoval), a simple yet effective solution for expanding the training dataset with synthetic images without spurious features. ASPIRE, guided by language, generates these images without requiring any form of additional supervision or existing examples. Precisely, we employ LLMs to first extract foreground and background features from textual descriptions of an image, followed by advanced language-guided image editing to discover the features that are spuriously correlated with the class label. Finally, we personalize a text-to-image generation model to generate diverse in-domain images without spurious features. We demonstrate the effectiveness of ASPIRE on 4 datasets, including the very challenging Hard ImageNet dataset, and 9 baselines and show that ASPIRE improves the classification accuracy of prior methods by 1% - 38%. Code soon at: https://github.com/Sreyan88/ASPIRE.", "url": "https://arxiv.org/abs/2308.10103"}, {"metadata": {"arXiv": "2308.10123", "Date": "Sat, 19 Aug 2023 22:41:00 ", "Title": "3D-Aware Neural Body Fitting for Occlusion Robust 3D Human Pose Estimation", "Authors": ["Yi Zhang", "Pengliang Ji", "Angtian Wang", "Jieru Mei", "Adam Kortylewski", "Alan Yuille"], "Categories": "cs.CV cs.AI", "Comments": ["ICCV 2023", "project page: https://3dnbf.github.io/"]}, "abstract": "Regression-based methods for 3D human pose estimation directly predict the 3D pose parameters from a 2D image using deep networks. While achieving state-of-the-art performance on standard benchmarks, their performance degrades under occlusion. In contrast, optimization-based methods fit a parametric body model to 2D features in an iterative manner. The localized reconstruction loss can potentially make them robust to occlusion, but they suffer from the 2D-3D ambiguity. Motivated by the recent success of generative models in rigid object pose estimation, we propose 3D-aware Neural Body Fitting (3DNBF) - an approximate analysis-by-synthesis approach to 3D human pose estimation with SOTA performance and occlusion robustness. In particular, we propose a generative model of deep features based on a volumetric human representation with Gaussian ellipsoidal kernels emitting 3D pose-dependent feature vectors. The neural features are trained with contrastive learning to become 3D-aware and hence to overcome the 2D-3D ambiguity. Experiments show that 3DNBF outperforms other approaches on both occluded and standard benchmarks. Code is available at https://github.com/edz-o/3DNBF", "url": "https://arxiv.org/abs/2308.10123"}, {"metadata": {"arXiv": "2308.10133", "Date": "Sun, 20 Aug 2023 02:02:16 ", "Title": "TransFace: Calibrating Transformer Training for Face Recognition from a Data-Centric Perspective", "Authors": ["Jun Dan", "Yang Liu", "Haoyu Xie", "Jiankang Deng", "Haoran Xie", "Xuansong Xie and Baigui Sun"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted by ICCV 2023"]}, "abstract": "Vision Transformers (ViTs) have demonstrated powerful representation ability in various visual tasks thanks to their intrinsic data-hungry nature. However, we unexpectedly find that ViTs perform vulnerably when applied to face recognition (FR) scenarios with extremely large datasets. We investigate the reasons for this phenomenon and discover that the existing data augmentation approach and hard sample mining strategy are incompatible with ViTs-based FR backbone due to the lack of tailored consideration on preserving face structural information and leveraging each local token information. To remedy these problems, this paper proposes a superior FR model called TransFace, which employs a patch-level data augmentation strategy named DPAP and a hard sample mining strategy named EHSM. Specially, DPAP randomly perturbs the amplitude information of dominant patches to expand sample diversity, which effectively alleviates the overfitting problem in ViTs. EHSM utilizes the information entropy in the local tokens to dynamically adjust the importance weight of easy and hard samples during training, leading to a more stable prediction. Experiments on several benchmarks demonstrate the superiority of our TransFace. Code and models are available at https://github.com/DanJun6737/TransFace.", "url": "https://arxiv.org/abs/2308.10133"}, {"metadata": {"arXiv": "2308.10156", "Date": "Sun, 20 Aug 2023 04:09:12 ", "Title": "SSMG: Spatial-Semantic Map Guided Diffusion Model for Free-form Layout-to-Image Generation", "Authors": ["Chengyou Jia", "Minnan Luo", "Zhuohang Dang", "Guang Dai", "Xiaojun Chang", "Mengmeng Wang", "Jingdong Wang"], "Categories": "cs.CV cs.AI"}, "abstract": "Despite significant progress in Text-to-Image (T2I) generative models, even lengthy and complex text descriptions still struggle to convey detailed controls. In contrast, Layout-to-Image (L2I) generation, aiming to generate realistic and complex scene images from user-specified layouts, has risen to prominence. However, existing methods transform layout information into tokens or RGB images for conditional control in the generative process, leading to insufficient spatial and semantic controllability of individual instances. To address these limitations, we propose a novel Spatial-Semantic Map Guided (SSMG) diffusion model that adopts the feature map, derived from the layout, as guidance. Owing to rich spatial and semantic information encapsulated in well-designed feature maps, SSMG achieves superior generation quality with sufficient spatial and semantic controllability compared to previous works. Additionally, we propose the Relation-Sensitive Attention (RSA) and Location-Sensitive Attention (LSA) mechanisms. The former aims to model the relationships among multiple objects within scenes while the latter is designed to heighten the model's sensitivity to the spatial information embedded in the guidance. Extensive experiments demonstrate that SSMG achieves highly promising results, setting a new state-of-the-art across a range of metrics encompassing fidelity, diversity, and controllability.", "url": "https://arxiv.org/abs/2308.10156"}, {"metadata": {"arXiv": "2308.10262", "Date": "Sun, 20 Aug 2023 13:16:15 ", "Title": "Learning Disentangled Representation with Mutual Information Maximization for Real-Time UAV Tracking", "Authors": ["Xucheng Wang", "Xiangyang Yang", "Hengzhou Ye", "Shuiwang Li"], "Categories": "cs.CV cs.AI"}, "abstract": "Efficiency has been a critical problem in UAV tracking due to limitations in computation resources, battery capacity, and unmanned aerial vehicle maximum load. Although discriminative correlation filters (DCF)-based trackers prevail in this field for their favorable efficiency, some recently proposed lightweight deep learning (DL)-based trackers using model compression demonstrated quite remarkable CPU efficiency as well as precision. Unfortunately, the model compression methods utilized by these works, though simple, are still unable to achieve satisfying tracking precision with higher compression rates. This paper aims to exploit disentangled representation learning with mutual information maximization (DR-MIM) to further improve DL-based trackers' precision and efficiency for UAV tracking. The proposed disentangled representation separates the feature into an identity-related and an identity-unrelated features. Only the latter is used, which enhances the effectiveness of the feature representation for subsequent classification and regression tasks. Extensive experiments on four UAV benchmarks, including UAV123@10fps, DTB70, UAVDT and VisDrone2018, show that our DR-MIM tracker significantly outperforms state-of-the-art UAV tracking methods.", "url": "https://arxiv.org/abs/2308.10262"}, {"metadata": {"arXiv": "2308.10382", "Date": "Sun, 20 Aug 2023 23:01:46 ", "Title": "False Negative/Positive Control for SAM on Noisy Medical Images", "Authors": ["Xing Yao", "Han Liu", "Dewei Hu", "Daiwei Lu", "Ange Lou", "Hao Li", "Ruining Deng", "Gabriel Arenas", "Baris Oguz", "Nadav Schwartz", "Brett C Byram", "Ipek Oguz"], "Categories": "cs.CV cs.AI"}, "abstract": "The Segment Anything Model (SAM) is a recently developed all-range foundation model for image segmentation. It can use sparse manual prompts such as bounding boxes to generate pixel-level segmentation in natural images but struggles in medical images such as low-contrast, noisy ultrasound images. We propose a refined test-phase prompt augmentation technique designed to improve SAM's performance in medical image segmentation. The method couples multi-box prompt augmentation and an aleatoric uncertainty-based false-negative (FN) and false-positive (FP) correction (FNPC) strategy. We evaluate the method on two ultrasound datasets and show improvement in SAM's performance and robustness to inaccurate prompts, without the necessity for further training or tuning. Moreover, we present the Single-Slice-to-Volume (SS2V) method, enabling 3D pixel-level segmentation using only the bounding box annotation from a single 2D slice. Our results allow efficient use of SAM in even noisy, low-contrast medical images. The source code will be released soon.", "url": "https://arxiv.org/abs/2308.10382"}, {"metadata": {"arXiv": "2308.10402", "Date": "Mon, 21 Aug 2023 00:32:19 ", "Title": "Simple Baselines for Interactive Video Retrieval with Questions and Answers", "Authors": ["Kaiqu Liang", "Samuel Albanie"], "Categories": "cs.CV cs.AI cs.CL cs.HC", "Comments": ["ICCV 2023", "project page: https://github.com/kevinliang888/IVR-QA-baselines"]}, "abstract": "To date, the majority of video retrieval systems have been optimized for a \"single-shot\" scenario in which the user submits a query in isolation, ignoring previous interactions with the system. Recently, there has been renewed interest in interactive systems to enhance retrieval, but existing approaches are complex and deliver limited gains in performance. In this work, we revisit this topic and propose several simple yet effective baselines for interactive video retrieval via question-answering. We employ a VideoQA model to simulate user interactions and show that this enables the productive study of the interactive retrieval task without access to ground truth dialogue data. Experiments on MSR-VTT, MSVD, and AVSD show that our framework using question-based interaction significantly improves the performance of text-based video retrieval systems.", "url": "https://arxiv.org/abs/2308.10402"}, {"metadata": {"arXiv": "2308.10446", "Date": "Mon, 21 Aug 2023 03:44:54 ", "Title": "LDCSF: Local depth convolution-based Swim framework for classifying multi-label histopathology images", "Authors": ["Liangrui Pan", "Yutao Dou", "Zhichao Feng", "Liwen Xu", "Shaoliang Peng"], "Categories": "cs.CV cs.AI", "Comments": ["Submitted to BIBM2023"]}, "abstract": "Histopathological images are the gold standard for diagnosing liver cancer. However, the accuracy of fully digital diagnosis in computational pathology needs to be improved. In this paper, in order to solve the problem of multi-label and low classification accuracy of histopathology images, we propose a locally deep convolutional Swim framework (LDCSF) to classify multi-label histopathology images. In order to be able to provide local field of view diagnostic results, we propose the LDCSF model, which consists of a Swin transformer module, a local depth convolution (LDC) module, a feature reconstruction (FR) module, and a ResNet module. The Swin transformer module reduces the amount of computation generated by the attention mechanism by limiting the attention to each window. The LDC then reconstructs the attention map and performs convolution operations in multiple channels, passing the resulting feature map to the next layer. The FR module uses the corresponding weight coefficient vectors obtained from the channels to dot product with the original feature map vector matrix to generate representative feature maps. Finally, the residual network undertakes the final classification task. As a result, the classification accuracy of LDCSF for interstitial area, necrosis, non-tumor and tumor reached 0.9460, 0.9960, 0.9808, 0.9847, respectively. Finally, we use the results of multi-label pathological image classification to calculate the tumor-to-stromal ratio, which lays the foundation for the analysis of the microenvironment of liver cancer histopathological images. Second, we released a multilabel histopathology image of liver cancer, our code and data are available at https://github.com/panliangrui/LSF.", "url": "https://arxiv.org/abs/2308.10446"}, {"metadata": {"arXiv": "2308.10490", "Date": "Mon, 21 Aug 2023 06:20:54 ", "Title": "Texture Generation on 3D Meshes with Point-UV Diffusion", "Authors": ["Xin Yu", "Peng Dai", "Wenbo Li", "Lan Ma", "Zhengzhe Liu", "Xiaojuan Qi"], "Categories": "cs.CV cs.AI cs.GR", "Comments": ["Accepted to ICCV 2023", "Oral"]}, "abstract": "In this work, we focus on synthesizing high-quality textures on 3D meshes. We present Point-UV diffusion, a coarse-to-fine pipeline that marries the denoising diffusion model with UV mapping to generate 3D consistent and high-quality texture images in UV space. We start with introducing a point diffusion model to synthesize low-frequency texture components with our tailored style guidance to tackle the biased color distribution. The derived coarse texture offers global consistency and serves as a condition for the subsequent UV diffusion stage, aiding in regularizing the model to generate a 3D consistent UV texture image. Then, a UV diffusion model with hybrid conditions is developed to enhance the texture fidelity in the 2D UV space. Our method can process meshes of any genus, generating diversified, geometry-compatible, and high-fidelity textures. Code is available at https://cvmi-lab.github.io/Point-UV-Diffusion", "url": "https://arxiv.org/abs/2308.10490"}, {"metadata": {"arXiv": "2308.10524", "Date": "Mon, 21 Aug 2023 07:24:29 ", "Title": "Dataset Quantization", "Authors": ["Daquan Zhou", "Kai Wang", "Jianyang Gu", "Xiangyu Peng", "Dongze Lian", "Yifan Zhang", "Yang You", "Jiashi Feng"], "Categories": "cs.CV cs.AI", "Comments": ["9 pages"]}, "abstract": "State-of-the-art deep neural networks are trained with large amounts (millions or even billions) of data. The expensive computation and memory costs make it difficult to train them on limited hardware resources, especially for recent popular large language models (LLM) and computer vision models (CV). Recent popular dataset distillation methods are thus developed, aiming to reduce the number of training samples via synthesizing small-scale datasets via gradient matching. However, as the gradient calculation is coupled with the specific network architecture, the synthesized dataset is biased and performs poorly when used for training unseen architectures. To address these limitations, we present dataset quantization (DQ), a new framework to compress large-scale datasets into small subsets which can be used for training any neural network architectures. Extensive experiments demonstrate that DQ is able to generate condensed small datasets for training unseen network architectures with state-of-the-art compression ratios for lossless model training. To the best of our knowledge, DQ is the first method that can successfully distill large-scale datasets such as ImageNet-1k with a state-of-the-art compression ratio. Notably, with 60% data from ImageNet and 20% data from Alpaca's instruction tuning data, the models can be trained with negligible or no performance drop for both vision tasks (including classification, semantic segmentation, and object detection) as well as language tasks (including instruction tuning tasks such as BBH and DROP).", "url": "https://arxiv.org/abs/2308.10524"}, {"metadata": {"arXiv": "2308.10648", "Date": "Mon, 21 Aug 2023 11:36:46 ", "Title": "EVE: Efficient zero-shot text-based Video Editing with Depth Map Guidance and Temporal Consistency Constraints", "Authors": ["Yutao Chen", "Xingning Dong", "Tian Gan", "Chunluan Zhou", "Ming Yang", "and Qingpei Guo"], "Categories": "cs.CV cs.AI"}, "abstract": "Motivated by the superior performance of image diffusion models, more and more researchers strive to extend these models to the text-based video editing task. Nevertheless, current video editing tasks mainly suffer from the dilemma between the high fine-tuning cost and the limited generation capacity. Compared with images, we conjecture that videos necessitate more constraints to preserve the temporal consistency during editing. Towards this end, we propose EVE, a robust and efficient zero-shot video editing method. Under the guidance of depth maps and temporal consistency constraints, EVE derives satisfactory video editing results with an affordable computational and time cost. Moreover, recognizing the absence of a publicly available video editing dataset for fair comparisons, we construct a new benchmark ZVE-50 dataset. Through comprehensive experimentation, we validate that EVE could achieve a satisfactory trade-off between performance and efficiency. We will release our dataset and codebase to facilitate future researchers.", "url": "https://arxiv.org/abs/2308.10648"}, {"metadata": {"arXiv": "2308.10677", "Date": "Mon, 21 Aug 2023 12:24:20 ", "Title": "Visual Crowd Analysis: Open Research Problems", "Authors": ["Muhammad Asif Khan", "Hamid Menouar", "Ridha Hamila"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted in AI Magazine published by Wiley Periodicals LLC on behalf of the Association for the Advancement of Artificial Intelligence"]}, "abstract": "Over the last decade, there has been a remarkable surge in interest in automated crowd monitoring within the computer vision community. Modern deep-learning approaches have made it possible to develop fully-automated vision-based crowd-monitoring applications. However, despite the magnitude of the issue at hand, the significant technological advancements, and the consistent interest of the research community, there are still numerous challenges that need to be overcome. In this article, we delve into six major areas of visual crowd analysis, emphasizing the key developments in each of these areas. We outline the crucial unresolved issues that must be tackled in future works, in order to ensure that the field of automated crowd monitoring continues to progress and thrive. Several surveys related to this topic have been conducted in the past. Nonetheless, this article thoroughly examines and presents a more intuitive categorization of works, while also depicting the latest breakthroughs within the field, incorporating more recent studies carried out within the last few years in a concise manner. By carefully choosing prominent works with significant contributions in terms of novelty or performance gains, this paper presents a more comprehensive exposition of advancements in the current state-of-the-art.", "url": "https://arxiv.org/abs/2308.10677"}, {"metadata": {"arXiv": "2308.10705", "Date": "Fri, 18 Aug 2023 16:41:57 ", "Title": "Unsupervised 3D Pose Estimation with Non-Rigid Structure-from-Motion Modeling", "Authors": ["Haorui Ji", "Hui Deng", "Yuchao Dai", "Hongdong Li"], "Categories": "cs.CV cs.AI"}, "abstract": "Most of the previous 3D human pose estimation work relied on the powerful memory capability of the network to obtain suitable 2D-3D mappings from the training data. Few works have studied the modeling of human posture deformation in motion. In this paper, we propose a new modeling method for human pose deformations and design an accompanying diffusion-based motion prior. Inspired by the field of non-rigid structure-from-motion, we divide the task of reconstructing 3D human skeletons in motion into the estimation of a 3D reference skeleton, and a frame-by-frame skeleton deformation. A mixed spatial-temporal NRSfMformer is used to simultaneously estimate the 3D reference skeleton and the skeleton deformation of each frame from 2D observations sequence, and then sum them to obtain the pose of each frame. Subsequently, a loss term based on the diffusion model is used to ensure that the pipeline learns the correct prior motion knowledge. Finally, we have evaluated our proposed method on mainstream datasets and obtained superior results outperforming the state-of-the-art.", "url": "https://arxiv.org/abs/2308.10705"}, {"metadata": {"arXiv": "2308.10087", "Date": "Sat, 19 Aug 2023 18:44:14 ", "Title": "GNNPipe: Accelerating Distributed Full-Graph GNN Training with Pipelined Model Parallelism", "Authors": ["Jingji Chen", "Zhuoming Chen", "Xuehai Qian"], "Categories": "cs.DC cs.AI"}, "abstract": "Current distributed full-graph GNN training methods adopt a variant of data parallelism, namely graph parallelism, in which the whole graph is divided into multiple partitions (subgraphs) and each GPU processes one of them. This incurs high communication overhead because of the inter-partition message passing at each layer. To this end, we proposed a new training method named GNNPipe that adopts model parallelism instead, which has a lower worst-case asymptotic communication complexity than graph parallelism. To ensure high GPU utilization, we proposed to combine model parallelism with a chunk-based pipelined training method, in which each GPU processes a different chunk of graph data at different layers concurrently. We further proposed hybrid parallelism that combines model and graph parallelism when the model-level parallelism is insufficient. We also introduced several tricks to ensure convergence speed and model accuracies to accommodate embedding staleness introduced by pipelining. Extensive experiments show that our method reduces the per-epoch training time by up to 2.45x (on average 2.03x) and reduces the communication volume and overhead by up to 22.51x and 27.21x (on average 10.27x and 14.96x), respectively, while achieving a comparable level of model accuracy and convergence speed compared to graph parallelism.", "url": "https://arxiv.org/abs/2308.10087"}, {"metadata": {"arXiv": "2308.10413", "Date": "Mon, 21 Aug 2023 01:43:08 ", "Title": "Mechanisms that play a game, not toss a coin", "Authors": ["Toby Walsh"], "Categories": "cs.GT cs.AI"}, "abstract": "Randomized mechanisms can have good normative properties compared to their deterministic counterparts. However, randomized mechanisms are problematic in several ways such as in their verifiability. We propose here to derandomize such mechanisms by having agents play a game instead of tossing a coin. The game is designed so an agent's best action is to play randomly, and this play then injects ``randomness'' into the mechanism. This derandomization retains many of the good normative properties of the original randomized mechanism but gives a mechanism that is deterministic and easy, for instance, to audit. We consider three related methods to derandomize randomized mechanism in six different domains: voting, facility location, task allocation, school choice, peer selection, and resource allocation. We propose a number of novel derandomized mechanisms for these six domains with good normative properties. Each mechanism has a mixed Nash equilibrium in which agents play a modular arithmetic game with an uniform mixed strategy. In all but one mixed Nash equilibrium, agents report their preferences over the original problem sincerely. The derandomized methods are thus ``quasi-strategy proof''. In one domain, we additionally show that a new and desirable normative property emerges as a result of derandomization.", "url": "https://arxiv.org/abs/2308.10413"}, {"metadata": {"arXiv": "2308.10435", "Date": "Mon, 21 Aug 2023 03:08:16 ", "Title": "GPT-in-the-Loop: Adaptive Decision-Making for Multiagent Systems", "Authors": ["Nathalia Nascimento and Paulo Alencar and Donald Cowan"], "Categories": "cs.MA cs.AI cs.NE cs.SE", "Comments": ["8 pages"]}, "abstract": "This paper introduces the \"GPT-in-the-loop\" approach, a novel method combining the advanced reasoning capabilities of Large Language Models (LLMs) like Generative Pre-trained Transformers (GPT) with multiagent (MAS) systems. Venturing beyond traditional adaptive approaches that generally require long training processes, our framework employs GPT-4 for enhanced problem-solving and explanation skills. Our experimental backdrop is the smart streetlight Internet of Things (IoT) application. Here, agents use sensors, actuators, and neural networks to create an energy-efficient lighting system. By integrating GPT-4, these agents achieve superior decision-making and adaptability without the need for extensive training. We compare this approach with both traditional neuroevolutionary methods and solutions provided by software engineers, underlining the potential of GPT-driven multiagent systems in IoT. Structurally, the paper outlines the incorporation of GPT into the agent-driven Framework for the Internet of Things (FIoT), introduces our proposed GPT-in-the-loop approach, presents comparative results in the IoT context, and concludes with insights and future directions.", "url": "https://arxiv.org/abs/2308.10435"}, {"metadata": {"arXiv": "2308.09987", "Date": "Sat, 19 Aug 2023 11:34:40 ", "Title": "ClothesNet: An Information-Rich 3D Garment Model Repository with Simulated Clothes Environment", "Authors": ["Bingyang Zhou", "Haoyu Zhou", "Tianhai Liang", "Qiaojun Yu", "Siheng Zhao", "Yuwei Zeng", "Jun Lv", "Siyuan Luo", "Qiancai Wang", "Xinyuan Yu", "Haonan Chen", "Cewu Lu", "and Lin Shao"], "Categories": "cs.RO cs.AI cs.CV", "Comments": ["IEEE/CVF International Conference on Computer Vision (ICCV) 2023"]}, "abstract": "We present ClothesNet: a large-scale dataset of 3D clothes objects with information-rich annotations. Our dataset consists of around 4400 models covering 11 categories annotated with clothes features, boundary lines, and keypoints. ClothesNet can be used to facilitate a variety of computer vision and robot interaction tasks. Using our dataset, we establish benchmark tasks for clothes perception, including classification, boundary line segmentation, and keypoint detection, and develop simulated clothes environments for robotic interaction tasks, including rearranging, folding, hanging, and dressing. We also demonstrate the efficacy of our ClothesNet in real-world experiments. Supplemental materials and dataset are available on our project webpage.", "url": "https://arxiv.org/abs/2308.09987"}, {"metadata": {"arXiv": "2308.10047", "Date": "Sat, 19 Aug 2023 15:12:55 ", "Title": "Towards Probabilistic Causal Discovery, Inference & Explanations for Autonomous Drones in Mine Surveying Tasks", "Authors": ["Ricardo Cannizzaro", "Rhys Howard", "Paulina Lewinska", "Lars Kunze"], "Categories": "cs.RO cs.AI", "Comments": ["3 Pages", "1 Figure", "To be published in the Proceedings of the \"Causality for Robotics: Answering the Question of Why\" workshop at the 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)", "Adjusted initial submission version"], "ACM-class": "I.2.9; I.2.6; G.3; I.6.3; I.2.8; J.7"}, "abstract": "Causal modelling offers great potential to provide autonomous agents the ability to understand the data-generation process that governs their interactions with the world. Such models capture formal knowledge as well as probabilistic representations of noise and uncertainty typically encountered by autonomous robots in real-world environments. Thus, causality can aid autonomous agents in making decisions and explaining outcomes, but deploying causality in such a manner introduces new challenges. Here we identify challenges relating to causality in the context of a drone system operating in a salt mine. Such environments are challenging for autonomous agents because of the presence of confounders, non-stationarity, and a difficulty in building complete causal models ahead of time. To address these issues, we propose a probabilistic causal framework consisting of: causally-informed POMDP planning, online SCM adaptation, and post-hoc counterfactual explanations. Further, we outline planned experimentation to evaluate the framework integrated with a drone system in simulated mine environments and on a real-world mine dataset.", "url": "https://arxiv.org/abs/2308.10047"}, {"metadata": {"arXiv": "2308.10169", "Date": "Sun, 20 Aug 2023 05:31:48 ", "Title": "Efficient Real-time Path Planning with Self-evolving Particle Swarm Optimization in Dynamic Scenarios", "Authors": ["Jinghao Xin", "Zhi Li", "Yang Zhang", "and Ning Li"], "Categories": "cs.RO cs.AI", "Comments": ["10 pages", "7 figures", "10 tables"]}, "abstract": "Particle Swarm Optimization (PSO) has demonstrated efficacy in addressing static path planning problems. Nevertheless, such application on dynamic scenarios has been severely precluded by PSO's low computational efficiency and premature convergence downsides. To address these limitations, we proposed a Tensor Operation Form (TOF) that converts particle-wise manipulations to tensor operations, thereby enhancing computational efficiency. Harnessing the computational advantage of TOF, a variant of PSO, designated as Self-Evolving Particle Swarm Optimization (SEPSO) was developed. The SEPSO is underpinned by a novel Hierarchical Self-Evolving Framework (HSEF) that enables autonomous optimization of its own hyper-parameters to evade premature convergence. Additionally, a Priori Initialization (PI) mechanism and an Auto Truncation (AT) mechanism that substantially elevates the real-time performance of SEPSO on dynamic path planning problems were introduced. Comprehensive experiments on four widely used benchmark optimization functions have been initially conducted to corroborate the validity of SEPSO. Following this, a dynamic simulation environment that encompasses moving start/target points and dynamic/static obstacles was employed to assess the effectiveness of SEPSO on the dynamic path planning problem. Simulation results exhibit that the proposed SEPSO is capable of generating superior paths with considerably better real-time performance (67 path planning computations per second in a regular desktop computer) in contrast to alternative methods. The code of this paper can be accessed here.", "url": "https://arxiv.org/abs/2308.10169"}, {"metadata": {"arXiv": "2308.10307", "Date": "Sun, 20 Aug 2023 16:05:02 ", "Title": "UAV 3-D path planning based on MOEA/D with adaptive areal weight adjustment", "Authors": ["Yougang Xiao", "Hao Yang", "Huan Liu", "Keyu Wu", "Guohua Wu"], "Categories": "cs.RO cs.AI", "Comments": ["23 pages,11 figures"]}, "abstract": "Unmanned aerial vehicles (UAVs) are desirable platforms for time-efficient and cost-effective task execution. 3-D path planning is a key challenge for task decision-making. This paper proposes an improved multi-objective evolutionary algorithm based on decomposition (MOEA/D) with an adaptive areal weight adjustment (AAWA) strategy to make a tradeoff between the total flight path length and the terrain threat. AAWA is designed to improve the diversity of the solutions. More specifically, AAWA first removes a crowded individual and its weight vector from the current population and then adds a sparse individual from the external elite population to the current population. To enable the newly-added individual to evolve towards the sparser area of the population in the objective space, its weight vector is constructed by the objective function value of its neighbors. The effectiveness of MOEA/D-AAWA is validated in twenty synthetic scenarios with different number of obstacles and four realistic scenarios in comparison with other three classical methods.", "url": "https://arxiv.org/abs/2308.10307"}, {"metadata": {"arXiv": "2308.10393", "Date": "Sun, 20 Aug 2023 23:53:13 ", "Title": "Robotic Planning under Hierarchical Temporal Logic Specifications", "Authors": ["Xusheng Luo", "Shaojun Xu", "Ruixuan Liu", "Changliu Liu"], "Categories": "cs.RO cs.AI", "Comments": ["8 pages", "4 figures"]}, "abstract": "Past research into robotic planning with temporal logic specifications, notably Linear Temporal Logic (LTL), was largely based on singular formulas for individual or groups of robots. But with increasing task complexity, LTL formulas unavoidably grow lengthy, complicating interpretation and specification generation, and straining the computational capacities of the planners. In order to maximize the potential of LTL specifications, we capitalized on the intrinsic structure of tasks and introduced a hierarchical structure to LTL specifications. In contrast to the \"flat\" structure, our hierarchical model has multiple levels of compositional specifications and offers benefits such as greater syntactic brevity, improved interpretability, and more efficient planning. To address tasks under this hierarchical temporal logic structure, we formulated a decomposition-based method. Each specification is first broken down into a range of temporally interrelated sub-tasks. We further mine the temporal relations among the sub-tasks of different specifications within the hierarchy. Subsequently, a Mixed Integer Linear Program is utilized to generate a spatio-temporal plan for each robot. Our hierarchical LTL specifications were experimentally applied to domains of robotic navigation and manipulation. Results from extensive simulation studies illustrated both the enhanced expressive potential of the hierarchical form and the efficacy of the proposed method.", "url": "https://arxiv.org/abs/2308.10393"}, {"metadata": {"arXiv": "2308.09720", "Date": "Wed, 09 Aug 2023 09:15:07 ", "Title": "On the Unexpected Abilities of Large Language Models", "Authors": ["Stefano Nolfi"], "Categories": "cs.AI cs.CL cs.LG"}, "abstract": "Large language models are capable of displaying a wide range of abilities that are not directly connected with the task for which they are trained: predicting the next words of human-written texts. In this article, I discuss the nature of this indirect acquisition process and its relation to other known indirect processes. I argue that an important side effect of such indirect acquisition is the development of integrated abilities. I discuss the extent to which the abilities developed by large language models are predictable. Finally, I briefly discuss the relation between the cognitive skills acquired by these systems and human cognition.", "url": "https://arxiv.org/abs/2308.09720"}, {"metadata": {"arXiv": "2308.09729", "Date": "Thu, 17 Aug 2023 16:59:50 ", "Title": "MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large Language Models", "Authors": ["Yilin Wen", "Zifeng Wang", "Jimeng Sun"], "Categories": "cs.AI cs.CL cs.LG", "Comments": ["7 pages", "8 figures", "9 tables"]}, "abstract": "LLMs usually exhibit limitations in their ability to incorporate new knowledge, the generation of hallucinations, and the transparency of their decision-making process. In this paper, we explore how to prompt LLMs with knowledge graphs (KG), working as a remedy to engage LLMs with up-to-date knowledge and elicit the reasoning pathways from LLMs. Specifically, we build a prompting pipeline that endows LLMs with the capability of comprehending KG inputs and inferring with a combined implicit knowledge and the retrieved external knowledge. In addition, we investigate eliciting the mind map on which LLMs perform the reasoning and generate the answers. It is identified that the produced mind map exhibits the reasoning pathways of LLMs grounded on the ontology of knowledge, hence bringing the prospects of probing and gauging LLM inference in production. The experiments on three question & answering datasets also show that MindMap prompting leads to a striking empirical gain. For instance, prompting a GPT-3.5 with MindMap yields an overwhelming performance over GPT-4 consistently. We also demonstrate that with structured facts retrieved from KG, MindMap can outperform a series of prompting-with-document-retrieval methods, benefiting from more accurate, concise, and comprehensive knowledge from KGs.", "url": "https://arxiv.org/abs/2308.09729"}, {"metadata": {"arXiv": "2308.09731", "Date": "Thu, 17 Aug 2023 20:50:46 ", "Title": "ChatGPT-HealthPrompt. Harnessing the Power of XAI in Prompt-Based Healthcare Decision Support using ChatGPT", "Authors": ["Fatemeh Nazary", "Yashar Deldjoo", "and Tommaso Di Noia"], "Categories": "cs.AI cs.CL cs.LG"}, "abstract": "This study presents an innovative approach to the application of large language models (LLMs) in clinical decision-making, focusing on OpenAI's ChatGPT. Our approach introduces the use of contextual prompts-strategically designed to include task description, feature description, and crucially, integration of domain knowledge-for high-quality binary classification tasks even in data-scarce scenarios. The novelty of our work lies in the utilization of domain knowledge, obtained from high-performing interpretable ML models, and its seamless incorporation into prompt design. By viewing these ML models as medical experts, we extract key insights on feature importance to aid in decision-making processes. This interplay of domain knowledge and AI holds significant promise in creating a more insightful diagnostic tool. Additionally, our research explores the dynamics of zero-shot and few-shot prompt learning based on LLMs. By comparing the performance of OpenAI's ChatGPT with traditional supervised ML models in different data conditions, we aim to provide insights into the effectiveness of prompt engineering strategies under varied data availability. In essence, this paper bridges the gap between AI and healthcare, proposing a novel methodology for LLMs application in clinical decision support systems. It highlights the transformative potential of effective prompt design, domain knowledge integration, and flexible learning approaches in enhancing automated decision-making.", "url": "https://arxiv.org/abs/2308.09731"}, {"metadata": {"arXiv": "2308.09780", "Date": "Fri, 04 Aug 2023 05:43:32 ", "Title": "Event-based Dynamic Graph Representation Learning for Patent Application Trend Prediction", "Authors": ["Tao Zou", "Le Yu", "Leilei Sun", "Bowen Du", "Deqing Wang", "Fuzhen Zhuang"], "Categories": "cs.AI cs.LG", "Comments": ["13 pages"]}, "abstract": "Accurate prediction of what types of patents that companies will apply for in the next period of time can figure out their development strategies and help them discover potential partners or competitors in advance. Although important, this problem has been rarely studied in previous research due to the challenges in modelling companies' continuously evolving preferences and capturing the semantic correlations of classification codes. To fill in this gap, we propose an event-based dynamic graph learning framework for patent application trend prediction. In particular, our method is founded on the memorable representations of both companies and patent classification codes. When a new patent is observed, the representations of the related companies and classification codes are updated according to the historical memories and the currently encoded messages. Moreover, a hierarchical message passing mechanism is provided to capture the semantic proximities of patent classification codes by updating their representations along the hierarchical taxonomy. Finally, the patent application trend is predicted by aggregating the representations of the target company and classification codes from static, dynamic, and hierarchical perspectives. Experiments on real-world data demonstrate the effectiveness of our approach under various experimental conditions, and also reveal the abilities of our method in learning semantics of classification codes and tracking technology developing trajectories of companies.", "url": "https://arxiv.org/abs/2308.09780"}, {"metadata": {"arXiv": "2308.10135", "Date": "Sun, 20 Aug 2023 02:07:42 ", "Title": "A Review on Objective-Driven Artificial Intelligence", "Authors": ["Apoorv Singh"], "Categories": "cs.AI cs.CV cs.LG cs.RO", "Comments": ["5 pages", "5 figures", "workshop submission"]}, "abstract": "While advancing rapidly, Artificial Intelligence still falls short of human intelligence in several key aspects due to inherent limitations in current AI technologies and our understanding of cognition. Humans have an innate ability to understand context, nuances, and subtle cues in communication, which allows us to comprehend jokes, sarcasm, and metaphors. Machines struggle to interpret such contextual information accurately. Humans possess a vast repository of common-sense knowledge that helps us make logical inferences and predictions about the world. Machines lack this innate understanding and often struggle with making sense of situations that humans find trivial. In this article, we review the prospective Machine Intelligence candidates, a review from Prof. Yann LeCun, and other work that can help close this gap between human and machine intelligence. Specifically, we talk about what's lacking with the current AI techniques such as supervised learning, reinforcement learning, self-supervised learning, etc. Then we show how Hierarchical planning-based approaches can help us close that gap and deep-dive into energy-based, latent-variable methods and Joint embedding predictive architecture methods.", "url": "https://arxiv.org/abs/2308.10135"}, {"metadata": {"arXiv": "2308.10386", "Date": "Sun, 20 Aug 2023 23:14:52 ", "Title": "Unsupervised Opinion Aggregation -- A Statistical Perspective", "Authors": ["Noyan C. Sevuktekin and Andrew C. Singer"], "Categories": "cs.AI cs.LG eess.SP", "Comments": ["This research was conducted during Noyan Sevuktekin's time at University of Illinois at Urbana-Champaign and the results were first presented in Chapter 3 of his dissertation", "entitled \"Learning From Opinions\". Permalink: https://hdl.handle.net/2142/110814"]}, "abstract": "Complex decision-making systems rarely have direct access to the current state of the world and they instead rely on opinions to form an understanding of what the ground truth could be. Even in problems where experts provide opinions without any intention to manipulate the decision maker, it is challenging to decide which expert's opinion is more reliable -- a challenge that is further amplified when decision-maker has limited, delayed, or no access to the ground truth after the fact. This paper explores a statistical approach to infer the competence of each expert based on their opinions without any need for the ground truth. Echoing the logic behind what is commonly referred to as \\textit{the wisdom of crowds}, we propose measuring the competence of each expert by their likeliness to agree with their peers. We further show that the more reliable an expert is the more likely it is that they agree with their peers. We leverage this fact to propose a completely unsupervised version of the na\\\"{i}ve Bayes classifier and show that the proposed technique is asymptotically optimal for a large class of problems. In addition to aggregating a large block of opinions, we further apply our technique for online opinion aggregation and for decision-making based on a limited the number of opinions.", "url": "https://arxiv.org/abs/2308.10386"}, {"metadata": {"arXiv": "2308.10487", "Date": "Mon, 21 Aug 2023 06:04:53 ", "Title": "Deciphering Raw Data in Neuro-Symbolic Learning with Provable Guarantees", "Authors": ["Lue Tao", "Yu-Xuan Huang", "Wang-Zhou Dai", "Yuan Jiang"], "Categories": "cs.AI cs.LG"}, "abstract": "Neuro-symbolic hybrid systems are promising for integrating machine learning and symbolic reasoning, where perception models are facilitated with information inferred from a symbolic knowledge base through logical reasoning. Despite empirical evidence showing the ability of hybrid systems to learn accurate perception models, the theoretical understanding of learnability is still lacking. Hence, it remains unclear why a hybrid system succeeds for a specific task and when it may fail given a different knowledge base. In this paper, we introduce a novel way of characterising supervision signals from a knowledge base, and establish a criterion for determining the knowledge's efficacy in facilitating successful learning. This, for the first time, allows us to address the two questions above by inspecting the knowledge base under investigation. Our analysis suggests that many knowledge bases satisfy the criterion, thus enabling effective learning, while some fail to satisfy it, indicating potential failures. Comprehensive experiments confirm the utility of our criterion on benchmark tasks.", "url": "https://arxiv.org/abs/2308.10487"}, {"metadata": {"arXiv": "2308.10537", "Date": "Mon, 21 Aug 2023 07:43:10 ", "Title": "KGrEaT: A Framework to Evaluate Knowledge Graphs via Downstream Tasks", "Authors": ["Nicolas Heist", "Sven Hertling", "Heiko Paulheim"], "Categories": "cs.AI cs.DB cs.LG", "Comments": ["Accepted for the Short Paper track of CIKM'23", "October 21-25", "2023", "Birmingham", "United Kingdom"]}, "abstract": "In recent years, countless research papers have addressed the topics of knowledge graph creation, extension, or completion in order to create knowledge graphs that are larger, more correct, or more diverse. This research is typically motivated by the argumentation that using such enhanced knowledge graphs to solve downstream tasks will improve performance. Nonetheless, this is hardly ever evaluated. Instead, the predominant evaluation metrics - aiming at correctness and completeness - are undoubtedly valuable but fail to capture the complete picture, i.e., how useful the created or enhanced knowledge graph actually is. Further, the accessibility of such a knowledge graph is rarely considered (e.g., whether it contains expressive labels, descriptions, and sufficient context information to link textual mentions to the entities of the knowledge graph). To better judge how well knowledge graphs perform on actual tasks, we present KGrEaT - a framework to estimate the quality of knowledge graphs via actual downstream tasks like classification, clustering, or recommendation. Instead of comparing different methods of processing knowledge graphs with respect to a single task, the purpose of KGrEaT is to compare various knowledge graphs as such by evaluating them on a fixed task setup. The framework takes a knowledge graph as input, automatically maps it to the datasets to be evaluated on, and computes performance metrics for the defined tasks. It is built in a modular way to be easily extendable with additional tasks and datasets.", "url": "https://arxiv.org/abs/2308.10537"}, {"metadata": {"arXiv": "2308.10842", "Date": "Fri, 18 Aug 2023 09:45:21 ", "Title": "Enhancing Agent Communication and Learning through Action and Language", "Authors": ["Caselles-Dupr\\'e Hugo", "Sigaud Olivier", "Chetouani Mohamed"], "Categories": "cs.AI cs.LG", "Comments": ["IMOL workshop", "Paris 2023"]}, "abstract": "We introduce a novel category of GC-agents capable of functioning as both teachers and learners. Leveraging action-based demonstrations and language-based instructions, these agents enhance communication efficiency. We investigate the incorporation of pedagogy and pragmatism, essential elements in human communication and goal achievement, enhancing the agents' teaching and learning capabilities. Furthermore, we explore the impact of combining communication modes (action and language) on learning outcomes, highlighting the benefits of a multi-modal approach.", "url": "https://arxiv.org/abs/2308.10842"}, {"metadata": {"arXiv": "2308.09764", "Date": "Fri, 18 Aug 2023 18:18:47 ", "Title": "The Impact of Background Removal on Performance of Neural Networks for Fashion Image Classification and Segmentation", "Authors": ["Junhui Liang", "Ying Liu", "Vladimir Vlassov"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["9 pages", "9 figures"]}, "abstract": "Fashion understanding is a hot topic in computer vision, with many applications having great business value in the market. Fashion understanding remains a difficult challenge for computer vision due to the immense diversity of garments and various scenes and backgrounds. In this work, we try removing the background from fashion images to boost data quality and increase model performance. Having fashion images of evident persons in fully visible garments, we can utilize Salient Object Detection to achieve the background removal of fashion data to our expectations. A fashion image with the background removed is claimed as the \"rembg\" image, contrasting with the original one in the fashion dataset. We conducted extensive comparative experiments with these two types of images on multiple aspects of model training, including model architectures, model initialization, compatibility with other training tricks and data augmentations, and target task types. Our experiments show that background removal can effectively work for fashion data in simple and shallow networks that are not susceptible to overfitting. It can improve model accuracy by up to 5% in the classification on the FashionStyle14 dataset when training models from scratch. However, background removal does not perform well in deep neural networks due to incompatibility with other regularization techniques like batch normalization, pre-trained initialization, and data augmentations introducing randomness. The loss of background pixels invalidates many existing training tricks in the model training, adding the risk of overfitting for deep models.", "url": "https://arxiv.org/abs/2308.09764"}, {"metadata": {"arXiv": "2308.09804", "Date": "Fri, 18 Aug 2023 20:18:30 ", "Title": "VL-PET: Vision-and-Language Parameter-Efficient Tuning via Granularity Control", "Authors": ["Zi-Yuan Hu", "Yanyang Li", "Michael R. Lyu", "Liwei Wang"], "Categories": "cs.CV cs.AI cs.CL cs.LG", "Comments": ["ICCV 2023 (17 pages", "6 figures", "22 tables)"]}, "abstract": "As the model size of pre-trained language models (PLMs) grows rapidly, full fine-tuning becomes prohibitively expensive for model training and storage. In vision-and-language (VL), parameter-efficient tuning (PET) techniques are proposed to integrate modular modifications (e.g., Adapter and LoRA) into encoder-decoder PLMs. By tuning a small set of trainable parameters, these techniques perform on par with full fine-tuning. However, excessive modular modifications and neglecting the functionality gap between the encoders and decoders can lead to performance degradation, while existing PET techniques (e.g., VL-Adapter) overlook these critical issues. In this paper, we propose a Vision-and-Language Parameter-Efficient Tuning (VL-PET) framework to impose effective control over modular modifications via a novel granularity-controlled mechanism. Considering different granularity-controlled matrices generated by this mechanism, a variety of model-agnostic VL-PET modules can be instantiated from our framework for better efficiency and effectiveness trade-offs. We further propose lightweight PET module designs to enhance VL alignment and modeling for the encoders and maintain text generation for the decoders. Extensive experiments conducted on four image-text tasks and four video-text tasks demonstrate the efficiency, effectiveness and transferability of our VL-PET framework. In particular, our VL-PET-large with lightweight PET module designs significantly outperforms VL-Adapter by 2.92% (3.41%) and LoRA by 3.37% (7.03%) with BART-base (T5-base) on image-text tasks. Furthermore, we validate the enhanced effect of employing our VL-PET designs on existing PET techniques, enabling them to achieve significant performance improvements. Our code is available at https://github.com/HenryHZY/VL-PET.", "url": "https://arxiv.org/abs/2308.09804"}, {"metadata": {"arXiv": "2308.09965", "Date": "Sat, 19 Aug 2023 09:45:39 ", "Title": "Anomaly-Aware Semantic Segmentation via Style-Aligned OoD Augmentation", "Authors": ["Dan Zhang", "Kaspar Sakmann", "William Beluch", "Robin Hutmacher", "Yumeng Li"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Accepted at ICCV2023 Workshop on Robustness and Reliability of Autonomous Vehicles in the Open-world (BRAVO)"]}, "abstract": "Within the context of autonomous driving, encountering unknown objects becomes inevitable during deployment in the open world. Therefore, it is crucial to equip standard semantic segmentation models with anomaly awareness. Many previous approaches have utilized synthetic out-of-distribution (OoD) data augmentation to tackle this problem. In this work, we advance the OoD synthesis process by reducing the domain gap between the OoD data and driving scenes, effectively mitigating the style difference that might otherwise act as an obvious shortcut during training. Additionally, we propose a simple fine-tuning loss that effectively induces a pre-trained semantic segmentation model to generate a ``none of the given classes\" prediction, leveraging per-pixel OoD scores for anomaly segmentation. With minimal fine-tuning effort, our pipeline enables the use of pre-trained models for anomaly segmentation while maintaining the performance on the original task.", "url": "https://arxiv.org/abs/2308.09965"}, {"metadata": {"arXiv": "2308.10110", "Date": "Sat, 19 Aug 2023 20:58:21 ", "Title": "Robust Mixture-of-Expert Training for Convolutional Neural Networks", "Authors": ["Yihua Zhang", "Ruisi Cai", "Tianlong Chen", "Guanhua Zhang", "Huan Zhang", "Pin-Yu Chen", "Shiyu Chang", "Zhangyang Wang", "Sijia Liu"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["ICCV 2023"]}, "abstract": "Sparsely-gated Mixture of Expert (MoE), an emerging deep model architecture, has demonstrated a great promise to enable high-accuracy and ultra-efficient model inference. Despite the growing popularity of MoE, little work investigated its potential to advance convolutional neural networks (CNNs), especially in the plane of adversarial robustness. Since the lack of robustness has become one of the main hurdles for CNNs, in this paper we ask: How to adversarially robustify a CNN-based MoE model? Can we robustly train it like an ordinary CNN model? Our pilot study shows that the conventional adversarial training (AT) mechanism (developed for vanilla CNNs) no longer remains effective to robustify an MoE-CNN. To better understand this phenomenon, we dissect the robustness of an MoE-CNN into two dimensions: Robustness of routers (i.e., gating functions to select data-specific experts) and robustness of experts (i.e., the router-guided pathways defined by the subnetworks of the backbone CNN). Our analyses show that routers and experts are hard to adapt to each other in the vanilla AT. Thus, we propose a new router-expert alternating Adversarial training framework for MoE, termed AdvMoE. The effectiveness of our proposal is justified across 4 commonly-used CNN model architectures over 4 benchmark datasets. We find that AdvMoE achieves 1% ~ 4% adversarial robustness improvement over the original dense CNN, and enjoys the efficiency merit of sparsity-gated MoE, leading to more than 50% inference cost reduction. Codes are available at https://github.com/OPTML-Group/Robust-MoE-CNN.", "url": "https://arxiv.org/abs/2308.10110"}, {"metadata": {"arXiv": "2308.10305", "Date": "Sun, 20 Aug 2023 16:03:21 ", "Title": "Co-Evolution of Pose and Mesh for 3D Human Body Estimation from Video", "Authors": ["Yingxuan You", "Hong Liu", "Ti Wang", "Wenhao Li", "Runwei Ding", "Xia Li"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Accepted by ICCV 2023. Project page: https://kasvii.github.io/PMCE"]}, "abstract": "Despite significant progress in single image-based 3D human mesh recovery, accurately and smoothly recovering 3D human motion from a video remains challenging. Existing video-based methods generally recover human mesh by estimating the complex pose and shape parameters from coupled image features, whose high complexity and low representation ability often result in inconsistent pose motion and limited shape patterns. To alleviate this issue, we introduce 3D pose as the intermediary and propose a Pose and Mesh Co-Evolution network (PMCE) that decouples this task into two parts: 1) video-based 3D human pose estimation and 2) mesh vertices regression from the estimated 3D pose and temporal image feature. Specifically, we propose a two-stream encoder that estimates mid-frame 3D pose and extracts a temporal image feature from the input image sequence. In addition, we design a co-evolution decoder that performs pose and mesh interactions with the image-guided Adaptive Layer Normalization (AdaLN) to make pose and mesh fit the human body shape. Extensive experiments demonstrate that the proposed PMCE outperforms previous state-of-the-art methods in terms of both per-frame accuracy and temporal consistency on three benchmark datasets: 3DPW, Human3.6M, and MPI-INF-3DHP. Our code is available at https://github.com/kasvii/PMCE.", "url": "https://arxiv.org/abs/2308.10305"}, {"metadata": {"arXiv": "2308.10449", "Date": "Mon, 21 Aug 2023 03:50:09 ", "Title": "CVFC: Attention-Based Cross-View Feature Consistency for Weakly Supervised Semantic Segmentation of Pathology Images", "Authors": ["Liangrui Pan", "Lian Wang", "Zhichao Feng", "Liwen Xu", "Shaoliang Peng"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Submitted to BIBM2023"]}, "abstract": "Histopathology image segmentation is the gold standard for diagnosing cancer, and can indicate cancer prognosis. However, histopathology image segmentation requires high-quality masks, so many studies now use imagelevel labels to achieve pixel-level segmentation to reduce the need for fine-grained annotation. To solve this problem, we propose an attention-based cross-view feature consistency end-to-end pseudo-mask generation framework named CVFC based on the attention mechanism. Specifically, CVFC is a three-branch joint framework composed of two Resnet38 and one Resnet50, and the independent branch multi-scale integrated feature map to generate a class activation map (CAM); in each branch, through down-sampling and The expansion method adjusts the size of the CAM; the middle branch projects the feature matrix to the query and key feature spaces, and generates a feature space perception matrix through the connection layer and inner product to adjust and refine the CAM of each branch; finally, through the feature consistency loss and feature cross loss to optimize the parameters of CVFC in co-training mode. After a large number of experiments, An IoU of 0.7122 and a fwIoU of 0.7018 are obtained on the WSSS4LUAD dataset, which outperforms HistoSegNet, SEAM, C-CAM, WSSS-Tissue, and OEEM, respectively.", "url": "https://arxiv.org/abs/2308.10449"}, {"metadata": {"arXiv": "2308.10511", "Date": "Mon, 21 Aug 2023 06:51:58 ", "Title": "Performance Enhancement Leveraging Mask-RCNN on Bengali Document Layout Analysis", "Authors": ["Shrestha Datta and Md Adith Mollah and Raisa Fairooz and Tariful Islam Fahim"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Contest paper", "Conest: DL sprint 2.0 (Link: https://www.kaggle.com/competitions/dlsprint2)", "Solution link: https://www.kaggle.com/competitions/dlsprint2/discussion/432201"]}, "abstract": "Understanding digital documents is like solving a puzzle, especially historical ones. Document Layout Analysis (DLA) helps with this puzzle by dividing documents into sections like paragraphs, images, and tables. This is crucial for machines to read and understand these documents.In the DL Sprint 2.0 competition, we worked on understanding Bangla documents. We used a dataset called BaDLAD with lots of examples. We trained a special model called Mask R-CNN to help with this understanding. We made this model better by step-by-step hyperparameter tuning, and we achieved a good dice score of 0.889.However, not everything went perfectly. We tried using a model trained for English documents, but it didn't fit well with Bangla. This showed us that each language has its own challenges. Our solution for the DL Sprint 2.0 is publicly available at https://www.kaggle.com/competitions/dlsprint2/discussion/432201 along with notebooks, weights, and inference notebook.", "url": "https://arxiv.org/abs/2308.10511"}, {"metadata": {"arXiv": "2308.10604", "Date": "Mon, 21 Aug 2023 10:00:59 ", "Title": "BackTrack: Robust template update via Backward Tracking of candidate template", "Authors": ["Dongwook Lee", "Wonjun Choi", "Seohyung Lee", "ByungIn Yoo", "Eunho Yang", "Seongju Hwang"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["14 pages", "7 figures"]}, "abstract": "Variations of target appearance such as deformations, illumination variance, occlusion, etc., are the major challenges of visual object tracking that negatively impact the performance of a tracker. An effective method to tackle these challenges is template update, which updates the template to reflect the change of appearance in the target object during tracking. However, with template updates, inadequate quality of new templates or inappropriate timing of updates may induce a model drift problem, which severely degrades the tracking performance. Here, we propose BackTrack, a robust and reliable method to quantify the confidence of the candidate template by backward tracking it on the past frames. Based on the confidence score of candidates from BackTrack, we can update the template with a reliable candidate at the right time while rejecting unreliable candidates. BackTrack is a generic template update scheme and is applicable to any template-based trackers. Extensive experiments on various tracking benchmarks verify the effectiveness of BackTrack over existing template update algorithms, as it achieves SOTA performance on various tracking benchmarks.", "url": "https://arxiv.org/abs/2308.10604"}, {"metadata": {"arXiv": "2308.10638", "Date": "Mon, 21 Aug 2023 11:23:25 ", "Title": "SCULPT: Shape-Conditioned Unpaired Learning of Pose-dependent Clothed and Textured Human Meshes", "Authors": ["Soubhik Sanyal", "Partha Ghosh", "Jinlong Yang", "Michael J. Black", "Justus Thies", "Timo Bolkart"], "Categories": "cs.CV cs.AI cs.GR cs.LG"}, "abstract": "We present SCULPT, a novel 3D generative model for clothed and textured 3D meshes of humans. Specifically, we devise a deep neural network that learns to represent the geometry and appearance distribution of clothed human bodies. Training such a model is challenging, as datasets of textured 3D meshes for humans are limited in size and accessibility. Our key observation is that there exist medium-sized 3D scan datasets like CAPE, as well as large-scale 2D image datasets of clothed humans and multiple appearances can be mapped to a single geometry. To effectively learn from the two data modalities, we propose an unpaired learning procedure for pose-dependent clothed and textured human meshes. Specifically, we learn a pose-dependent geometry space from 3D scan data. We represent this as per vertex displacements w.r.t. the SMPL model. Next, we train a geometry conditioned texture generator in an unsupervised way using the 2D image data. We use intermediate activations of the learned geometry model to condition our texture generator. To alleviate entanglement between pose and clothing type, and pose and clothing appearance, we condition both the texture and geometry generators with attribute labels such as clothing types for the geometry, and clothing colors for the texture generator. We automatically generated these conditioning labels for the 2D images based on the visual question answering model BLIP and CLIP. We validate our method on the SCULPT dataset, and compare to state-of-the-art 3D generative models for clothed human bodies. We will release the codebase for research purposes.", "url": "https://arxiv.org/abs/2308.10638"}, {"metadata": {"arXiv": "2308.10707", "Date": "Thu, 17 Aug 2023 04:12:02 ", "Title": "Sensor Fusion by Spatial Encoding for Autonomous Driving", "Authors": ["Quoc-Vinh Lai-Dang", "Jihui Lee", "Bumgeun Park", "Dongsoo Har"], "Categories": "cs.CV cs.AI cs.LG cs.RO", "Comments": ["This paper has been accepted for Lecture presentation at the 2023 IEEE SENSORS conference"]}, "abstract": "Sensor fusion is critical to perception systems for task domains such as autonomous driving and robotics. Recently, the Transformer integrated with CNN has demonstrated high performance in sensor fusion for various perception tasks. In this work, we introduce a method for fusing data from camera and LiDAR. By employing Transformer modules at multiple resolutions, proposed method effectively combines local and global contextual relationships. The performance of the proposed method is validated by extensive experiments with two adversarial benchmarks with lengthy routes and high-density traffics. The proposed method outperforms previous approaches with the most challenging benchmarks, achieving significantly higher driving and infraction scores. Compared with TransFuser, it achieves 8% and 19% improvement in driving scores for the Longest6 and Town05 Long benchmarks, respectively.", "url": "https://arxiv.org/abs/2308.10707"}, {"metadata": {"arXiv": "2308.10226", "Date": "Sun, 20 Aug 2023 10:43:50 ", "Title": "Machine Learning-powered Combinatorial Clock Auction", "Authors": ["Ermis Soumalias", "Jakob Weissteiner", "Jakob Heiss", "Sven Seuken"], "Categories": "cs.GT cs.AI cs.LG"}, "abstract": "We study the design of iterative combinatorial auctions (ICAs). The main challenge in this domain is that the bundle space grows exponentially in the number of items. To address this, several papers have recently proposed machine learning (ML)-based preference elicitation algorithms that aim to elicit only the most important information from bidders. However, from a practical point of view, the main shortcoming of this prior work is that those designs elicit bidders' preferences via value queries (i.e., ``What is your value for the bundle $\\{A,B\\}$?''). In most real-world ICA domains, value queries are considered impractical, since they impose an unrealistically high cognitive burden on bidders, which is why they are not used in practice. In this paper, we address this shortcoming by designing an ML-powered combinatorial clock auction that elicits information from the bidders only via demand queries (i.e., ``At prices $p$, what is your most preferred bundle of items?''). We make two key technical contributions: First, we present a novel method for training an ML model on demand queries. Second, based on those trained ML models, we introduce an efficient method for determining the demand query with the highest clearing potential, for which we also provide a theoretical foundation. We experimentally evaluate our ML-based demand query mechanism in several spectrum auction domains and compare it against the most established real-world ICA: the combinatorial clock auction (CCA). Our mechanism significantly outperforms the CCA in terms of efficiency in all domains, it achieves higher efficiency in a significantly reduced number of rounds, and, using linear prices, it exhibits vastly higher clearing potential. Thus, with this paper we bridge the gap between research and practice and propose the first practical ML-powered ICA.", "url": "https://arxiv.org/abs/2308.10226"}, {"metadata": {"arXiv": "2308.09724", "Date": "Thu, 17 Aug 2023 04:46:38 ", "Title": "Knowledge-inspired Subdomain Adaptation for Cross-Domain Knowledge Transfer", "Authors": ["Liyue Chen", "Linian Wang", "Jinyu Xu", "Shuai Chen", "Weiqiang Wang", "Wenbiao Zhao", "Qiyu Li", "Leye Wang"], "Categories": "cs.LG cs.AI", "Comments": ["accepted by CIKM 2023"]}, "abstract": "Most state-of-the-art deep domain adaptation techniques align source and target samples in a global fashion. That is, after alignment, each source sample is expected to become similar to any target sample. However, global alignment may not always be optimal or necessary in practice. For example, consider cross-domain fraud detection, where there are two types of transactions: credit and non-credit. Aligning credit and non-credit transactions separately may yield better performance than global alignment, as credit transactions are unlikely to exhibit patterns similar to non-credit transactions. To enable such fine-grained domain adaption, we propose a novel Knowledge-Inspired Subdomain Adaptation (KISA) framework. In particular, (1) We provide the theoretical insight that KISA minimizes the shared expected loss which is the premise for the success of domain adaptation methods. (2) We propose the knowledge-inspired subdomain division problem that plays a crucial role in fine-grained domain adaption. (3) We design a knowledge fusion network to exploit diverse domain knowledge. Extensive experiments demonstrate that KISA achieves remarkable results on fraud detection and traffic demand prediction tasks.", "url": "https://arxiv.org/abs/2308.09724"}, {"metadata": {"arXiv": "2308.09726", "Date": "Thu, 17 Aug 2023 13:00:27 ", "Title": "Equitable Restless Multi-Armed Bandits: A General Framework Inspired By Digital Health", "Authors": ["Jackson A. Killian", "Manish Jain", "Yugang Jia", "Jonathan Amar", "Erich Huang", "Milind Tambe"], "Categories": "cs.LG cs.AI cs.CY cs.MA", "Comments": ["16 pages", "8 figures", "2 tables"]}, "abstract": "Restless multi-armed bandits (RMABs) are a popular framework for algorithmic decision making in sequential settings with limited resources. RMABs are increasingly being used for sensitive decisions such as in public health, treatment scheduling, anti-poaching, and -- the motivation for this work -- digital health. For such high stakes settings, decisions must both improve outcomes and prevent disparities between groups (e.g., ensure health equity). We study equitable objectives for RMABs (ERMABs) for the first time. We consider two equity-aligned objectives from the fairness literature, minimax reward and max Nash welfare. We develop efficient algorithms for solving each -- a water filling algorithm for the former, and a greedy algorithm with theoretically motivated nuance to balance disparate group sizes for the latter. Finally, we demonstrate across three simulation domains, including a new digital health model, that our approaches can be multiple times more equitable than the current state of the art without drastic sacrifices to utility. Our findings underscore our work's urgency as RMABs permeate into systems that impact human and wildlife outcomes. Code is available at https://github.com/google-research/socialgood/tree/equitable-rmab", "url": "https://arxiv.org/abs/2308.09726"}, {"metadata": {"arXiv": "2308.09732", "Date": "Fri, 18 Aug 2023 00:46:42 ", "Title": "Baird Counterexample Is Solved: with an example of How to Debug a Two-time-scale Algorithm", "Authors": ["Hengshuai Yao"], "Categories": "cs.LG cs.AI"}, "abstract": "Baird counterexample was proposed by Leemon Baird in 1995, first used to show that the Temporal Difference (TD(0)) algorithm diverges on this example. Since then, it is often used to test and compare off-policy learning algorithms. Gradient TD algorithms solved the divergence issue of TD on Baird counterexample. However, their convergence on this example is still very slow, and the nature of the slowness is not well understood, e.g., see (Sutton and Barto 2018). This note is to understand in particular, why TDC is slow on this example, and provide debugging analysis to understand this behavior. Our debugging technique can be used to study the convergence behavior of two-time-scale stochastic approximation algorithms. We also provide empirical results of the recent Impression GTD algorithm on this example, showing the convergence is very fast, in fact, in a linear rate. We conclude that Baird counterexample is solved, by an algorithm with convergence guarantee to the TD solution in general and a fast convergence rate.", "url": "https://arxiv.org/abs/2308.09732"}, {"metadata": {"arXiv": "2308.09733", "Date": "Fri, 18 Aug 2023 02:10:45 ", "Title": "Intrinsically Motivated Hierarchical Policy Learning in Multi-objective Markov Decision Processes", "Authors": ["Sherif Abdelfattah", "Kathryn Merrick", "Jiankun Hu"], "Categories": "cs.LG cs.AI cs.RO"}, "abstract": "Multi-objective Markov decision processes are sequential decision-making problems that involve multiple conflicting reward functions that cannot be optimized simultaneously without a compromise. This type of problems cannot be solved by a single optimal policy as in the conventional case. Alternatively, multi-objective reinforcement learning methods evolve a coverage set of optimal policies that can satisfy all possible preferences in solving the problem. However, many of these methods cannot generalize their coverage sets to work in non-stationary environments. In these environments, the parameters of the state transition and reward distribution vary over time. This limitation results in significant performance degradation for the evolved policy sets. In order to overcome this limitation, there is a need to learn a generic skill set that can bootstrap the evolution of the policy coverage set for each shift in the environment dynamics therefore, it can facilitate a continuous learning process. In this work, intrinsically motivated reinforcement learning has been successfully deployed to evolve generic skill sets for learning hierarchical policies to solve multi-objective Markov decision processes. We propose a novel dual-phase intrinsically motivated reinforcement learning method to address this limitation. In the first phase, a generic set of skills is learned. While in the second phase, this set is used to bootstrap policy coverage sets for each shift in the environment dynamics. We show experimentally that the proposed method significantly outperforms state-of-the-art multi-objective reinforcement methods in a dynamic robotics environment.", "url": "https://arxiv.org/abs/2308.09733"}, {"metadata": {"arXiv": "2308.09734", "Date": "Fri, 18 Aug 2023 02:15:12 ", "Title": "A Robust Policy Bootstrapping Algorithm for Multi-objective Reinforcement Learning in Non-stationary Environments", "Authors": ["Sherif Abdelfattah", "Kathryn Kasmarik", "Jiankun Hu"], "Categories": "cs.LG cs.AI cs.RO"}, "abstract": "Multi-objective Markov decision processes are a special kind of multi-objective optimization problem that involves sequential decision making while satisfying the Markov property of stochastic processes. Multi-objective reinforcement learning methods address this problem by fusing the reinforcement learning paradigm with multi-objective optimization techniques. One major drawback of these methods is the lack of adaptability to non-stationary dynamics in the environment. This is because they adopt optimization procedures that assume stationarity to evolve a coverage set of policies that can solve the problem. This paper introduces a developmental optimization approach that can evolve the policy coverage set while exploring the preference space over the defined objectives in an online manner. We propose a novel multi-objective reinforcement learning algorithm that can robustly evolve a convex coverage set of policies in an online manner in non-stationary environments. We compare the proposed algorithm with two state-of-the-art multi-objective reinforcement learning algorithms in stationary and non-stationary environments. Results showed that the proposed algorithm significantly outperforms the existing algorithms in non-stationary environments while achieving comparable results in stationary environments.", "url": "https://arxiv.org/abs/2308.09734"}, {"metadata": {"arXiv": "2308.09842", "Date": "Fri, 18 Aug 2023 22:30:35 ", "Title": "Enumerating Safe Regions in Deep Neural Networks with Provable Probabilistic Guarantees", "Authors": ["Luca Marzari", "Davide Corsi", "Enrico Marchesini", "Alessandro Farinelli and Ferdinando Cicalese"], "Categories": "cs.LG cs.AI"}, "abstract": "Identifying safe areas is a key point to guarantee trust for systems that are based on Deep Neural Networks (DNNs). To this end, we introduce the AllDNN-Verification problem: given a safety property and a DNN, enumerate the set of all the regions of the property input domain which are safe, i.e., where the property does hold. Due to the #P-hardness of the problem, we propose an efficient approximation method called epsilon-ProVe. Our approach exploits a controllable underestimation of the output reachable sets obtained via statistical prediction of tolerance limits, and can provide a tight (with provable probabilistic guarantees) lower estimate of the safe areas. Our empirical evaluation on different standard benchmarks shows the scalability and effectiveness of our method, offering valuable insights for this new type of verification of DNNs.", "url": "https://arxiv.org/abs/2308.09842"}, {"metadata": {"arXiv": "2308.09858", "Date": "Fri, 18 Aug 2023 23:56:50 ", "Title": "Tensor-Compressed Back-Propagation-Free Training for (Physics-Informed) Neural Networks", "Authors": ["Yequan Zhao", "Xinling Yu", "Zhixiong Chen", "Ziyue Liu", "Sijia Liu and Zheng Zhang"], "Categories": "cs.LG cs.AI"}, "abstract": "Backward propagation (BP) is widely used to compute the gradients in neural network training. However, it is hard to implement BP on edge devices due to the lack of hardware and software resources to support automatic differentiation. This has tremendously increased the design complexity and time-to-market of on-device training accelerators. This paper presents a completely BP-free framework that only requires forward propagation to train realistic neural networks. Our technical contributions are three-fold. Firstly, we present a tensor-compressed variance reduction approach to greatly improve the scalability of zeroth-order (ZO) optimization, making it feasible to handle a network size that is beyond the capability of previous ZO approaches. Secondly, we present a hybrid gradient evaluation approach to improve the efficiency of ZO training. Finally, we extend our BP-free training framework to physics-informed neural networks (PINNs) by proposing a sparse-grid approach to estimate the derivatives in the loss function without using BP. Our BP-free training only loses little accuracy on the MNIST dataset compared with standard first-order training. We also demonstrate successful results in training a PINN for solving a 20-dim Hamiltonian-Jacobi-Bellman PDE. This memory-efficient and BP-free approach may serve as a foundation for the near-future on-device training on many resource-constraint platforms (e.g., FPGA, ASIC, micro-controllers, and photonic chips).", "url": "https://arxiv.org/abs/2308.09858"}, {"metadata": {"arXiv": "2308.09890", "Date": "Sat, 19 Aug 2023 03:01:45 ", "Title": "Inductive-bias Learning: Generating Code Models with Large Language Model", "Authors": ["Toma Tanaka", "Naofumi Emoto", "and Tsukasa Yumibayashi"], "Categories": "cs.LG cs.AI cs.CL", "Comments": ["17 pages", "8 figures"]}, "abstract": "Large Language Models(LLMs) have been attracting attention due to a ability called in-context learning(ICL). ICL, without updating the parameters of a LLM, it is possible to achieve highly accurate inference based on rules ``in the context'' by merely inputting a training data into the prompt. Although ICL is a developing field with many unanswered questions, LLMs themselves serves as a inference model, seemingly realizing inference without explicitly indicate ``inductive bias''. On the other hand, a code generation is also a highlighted application of LLMs. The accuracy of code generation has dramatically improved, enabling even non-engineers to generate code to perform the desired tasks by crafting appropriate prompts. In this paper, we propose a novel ``learning'' method called an ``Inductive-Bias Learning (IBL)'', which combines the techniques of ICL and code generation. An idea of IBL is straightforward. Like ICL, IBL inputs a training data into the prompt and outputs a code with a necessary structure for inference (we referred to as ``Code Model'') from a ``contextual understanding''. Despite being a seemingly simple approach, IBL encompasses both a ``property of inference without explicit inductive bias'' inherent in ICL and a ``readability and explainability'' of the code generation. Surprisingly, generated Code Models have been found to achieve predictive accuracy comparable to, and in some cases surpassing, ICL and representative machine learning models. Our IBL code is open source: https://github.com/fuyu-quant/IBLM", "url": "https://arxiv.org/abs/2308.09890"}, {"metadata": {"arXiv": "2308.09909", "Date": "Sat, 19 Aug 2023 05:27:48 ", "Title": "Never Explore Repeatedly in Multi-Agent Reinforcement Learning", "Authors": ["Chenghao Li", "Tonghan Wang", "Chongjie Zhang", "Qianchuan Zhao"], "Categories": "cs.LG cs.AI cs.MA"}, "abstract": "In the realm of multi-agent reinforcement learning, intrinsic motivations have emerged as a pivotal tool for exploration. While the computation of many intrinsic rewards relies on estimating variational posteriors using neural network approximators, a notable challenge has surfaced due to the limited expressive capability of these neural statistics approximators. We pinpoint this challenge as the \"revisitation\" issue, where agents recurrently explore confined areas of the task space. To combat this, we propose a dynamic reward scaling approach. This method is crafted to stabilize the significant fluctuations in intrinsic rewards in previously explored areas and promote broader exploration, effectively curbing the revisitation phenomenon. Our experimental findings underscore the efficacy of our approach, showcasing enhanced performance in demanding environments like Google Research Football and StarCraft II micromanagement tasks, especially in sparse reward settings.", "url": "https://arxiv.org/abs/2308.09909"}, {"metadata": {"arXiv": "2308.09971", "Date": "Sat, 19 Aug 2023 10:13:17 ", "Title": "Disposable Transfer Learning for Selective Source Task Unlearning", "Authors": ["Seunghee Koh", "Hyounguk Shon", "Janghyeon Lee", "Hyeong Gwon Hong", "Junmo Kim"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["Accepted to ICCV 2023"]}, "abstract": "Transfer learning is widely used for training deep neural networks (DNN) for building a powerful representation. Even after the pre-trained model is adapted for the target task, the representation performance of the feature extractor is retained to some extent. As the performance of the pre-trained model can be considered the private property of the owner, it is natural to seek the exclusive right of the generalized performance of the pre-trained weight. To address this issue, we suggest a new paradigm of transfer learning called disposable transfer learning (DTL), which disposes of only the source task without degrading the performance of the target task. To achieve knowledge disposal, we propose a novel loss named Gradient Collision loss (GC loss). GC loss selectively unlearns the source knowledge by leading the gradient vectors of mini-batches in different directions. Whether the model successfully unlearns the source task is measured by piggyback learning accuracy (PL accuracy). PL accuracy estimates the vulnerability of knowledge leakage by retraining the scrubbed model on a subset of source data or new downstream data. We demonstrate that GC loss is an effective approach to the DTL problem by showing that the model trained with GC loss retains the performance on the target task with a significantly reduced PL accuracy.", "url": "https://arxiv.org/abs/2308.09971"}, {"metadata": {"arXiv": "2308.10051", "Date": "Sat, 19 Aug 2023 15:21:12 ", "Title": "The Snowflake Hypothesis: Training Deep GNN with One Node One Receptive field", "Authors": ["Kun Wang", "Guohao Li", "Shilong Wang", "Guibin Zhang", "Kai Wang", "Yang You", "Xiaojiang Peng", "Yuxuan Liang", "Yang Wang"], "Categories": "cs.LG cs.AI"}, "abstract": "Despite Graph Neural Networks demonstrating considerable promise in graph representation learning tasks, GNNs predominantly face significant issues with over-fitting and over-smoothing as they go deeper as models of computer vision realm. In this work, we conduct a systematic study of deeper GNN research trajectories. Our findings indicate that the current success of deep GNNs primarily stems from (I) the adoption of innovations from CNNs, such as residual/skip connections, or (II) the tailor-made aggregation algorithms like DropEdge. However, these algorithms often lack intrinsic interpretability and indiscriminately treat all nodes within a given layer in a similar manner, thereby failing to capture the nuanced differences among various nodes. To this end, we introduce the Snowflake Hypothesis -- a novel paradigm underpinning the concept of ``one node, one receptive field''. The hypothesis draws inspiration from the unique and individualistic patterns of each snowflake, proposing a corresponding uniqueness in the receptive fields of nodes in the GNNs. We employ the simplest gradient and node-level cosine distance as guiding principles to regulate the aggregation depth for each node, and conduct comprehensive experiments including: (1) different training schemes; (2) various shallow and deep GNN backbones, and (3) various numbers of layers (8, 16, 32, 64) on multiple benchmarks (six graphs including dense graphs with millions of nodes); (4) compare with different aggregation strategies. The observational results demonstrate that our hypothesis can serve as a universal operator for a range of tasks, and it displays tremendous potential on deep GNNs. It can be applied to various GNN frameworks, enhancing its effectiveness when operating in-depth, and guiding the selection of the optimal network depth in an explainable and generalizable way.", "url": "https://arxiv.org/abs/2308.10051"}, {"metadata": {"arXiv": "2308.10064", "Date": "Sat, 19 Aug 2023 15:57:19 ", "Title": "Efficient Representation Learning for Healthcare with Cross-Architectural Self-Supervision", "Authors": ["Pranav Singh and Jacopo Cirrone"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["Accepted at MLHC 2023. Extended conference version of arXiv:2206.04170"]}, "abstract": "In healthcare and biomedical applications, extreme computational requirements pose a significant barrier to adopting representation learning. Representation learning can enhance the performance of deep learning architectures by learning useful priors from limited medical data. However, state-of-the-art self-supervised techniques suffer from reduced performance when using smaller batch sizes or shorter pretraining epochs, which are more practical in clinical settings. We present Cross Architectural - Self Supervision (CASS) in response to this challenge. This novel siamese self-supervised learning approach synergistically leverages Transformer and Convolutional Neural Networks (CNN) for efficient learning. Our empirical evaluation demonstrates that CASS-trained CNNs and Transformers outperform existing self-supervised learning methods across four diverse healthcare datasets. With only 1% labeled data for finetuning, CASS achieves a 3.8% average improvement; with 10% labeled data, it gains 5.9%; and with 100% labeled data, it reaches a remarkable 10.13% enhancement. Notably, CASS reduces pretraining time by 69% compared to state-of-the-art methods, making it more amenable to clinical implementation. We also demonstrate that CASS is considerably more robust to variations in batch size and pretraining epochs, making it a suitable candidate for machine learning in healthcare applications.", "url": "https://arxiv.org/abs/2308.10064"}, {"metadata": {"arXiv": "2308.10077", "Date": "Sat, 19 Aug 2023 17:42:02 ", "Title": "Contrastive Learning for Non-Local Graphs with Multi-Resolution Structural Views", "Authors": ["Asif Khan", "Amos Storkey"], "Categories": "cs.LG cs.AI"}, "abstract": "Learning node-level representations of heterophilic graphs is crucial for various applications, including fraudster detection and protein function prediction. In such graphs, nodes share structural similarity identified by the equivalence of their connectivity which is implicitly encoded in the form of higher-order hierarchical information in the graphs. The contrastive methods are popular choices for learning the representation of nodes in a graph. However, existing contrastive methods struggle to capture higher-order graph structures. To address this limitation, we propose a novel multiview contrastive learning approach that integrates diffusion filters on graphs. By incorporating multiple graph views as augmentations, our method captures the structural equivalence in heterophilic graphs, enabling the discovery of hidden relationships and similarities not apparent in traditional node representations. Our approach outperforms baselines on synthetic and real structural datasets, surpassing the best baseline by $16.06\\%$ on Cornell, $3.27\\%$ on Texas, and $8.04\\%$ on Wisconsin. Additionally, it consistently achieves superior performance on proximal tasks, demonstrating its effectiveness in uncovering structural information and improving downstream applications.", "url": "https://arxiv.org/abs/2308.10077"}, {"metadata": {"arXiv": "2308.10144", "Date": "Sun, 20 Aug 2023 03:03:34 ", "Title": "ExpeL: LLM Agents Are Experiential Learners", "Authors": ["Andrew Zhao", "Daniel Huang", "Quentin Xu", "Matthieu Lin", "Yong-Jin Liu", "Gao Huang"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "The recent surge in research interest in applying large language models (LLMs) to decision-making tasks has flourished by leveraging the extensive world knowledge embedded in LLMs. While there is a growing demand to tailor LLMs for custom decision-making tasks, finetuning them for specific tasks is resource-intensive and may diminish the model's generalization capabilities. Moreover, state-of-the-art language models like GPT-4 and Claude are primarily accessible through API calls, with their parametric weights remaining proprietary and unavailable to the public. This scenario emphasizes the growing need for new methodologies that allow learning from agent experiences without requiring parametric updates. To address these problems, we introduce the Experiential Learning (ExpeL) agent. Our agent autonomously gathers experiences and extracts knowledge using natural language from a collection of training tasks. At inference, the agent recalls its extracted insights and past experiences to make informed decisions. Our empirical results highlight the robust learning efficacy of the ExpeL agent, indicating a consistent enhancement in its performance as it accumulates experiences. We further explore the emerging capabilities and transfer learning potential of the ExpeL agent through qualitative observations and additional experiments.", "url": "https://arxiv.org/abs/2308.10144"}, {"metadata": {"arXiv": "2308.10162", "Date": "Sun, 20 Aug 2023 04:41:01 ", "Title": "Rethinking Client Drift in Federated Learning: A Logit Perspective", "Authors": ["Yunlu Yan", "Chun-Mei Feng", "Mang Ye", "Wangmeng Zuo", "Ping Li", "Rick Siow Mong Goh", "Lei Zhu", "C. L. Philip Chen"], "Categories": "cs.LG cs.AI", "Comments": ["11 pages", "7 figures"]}, "abstract": "Federated Learning (FL) enables multiple clients to collaboratively learn in a distributed way, allowing for privacy protection. However, the real-world non-IID data will lead to client drift which degrades the performance of FL. Interestingly, we find that the difference in logits between the local and global models increases as the model is continuously updated, thus seriously deteriorating FL performance. This is mainly due to catastrophic forgetting caused by data heterogeneity between clients. To alleviate this problem, we propose a new algorithm, named FedCSD, a Class prototype Similarity Distillation in a federated framework to align the local and global models. FedCSD does not simply transfer global knowledge to local clients, as an undertrained global model cannot provide reliable knowledge, i.e., class similarity information, and its wrong soft labels will mislead the optimization of local models. Concretely, FedCSD introduces a class prototype similarity distillation to align the local logits with the refined global logits that are weighted by the similarity between local logits and the global prototype. To enhance the quality of global logits, FedCSD adopts an adaptive mask to filter out the terrible soft labels of the global models, thereby preventing them to mislead local optimization. Extensive experiments demonstrate the superiority of our method over the state-of-the-art federated learning approaches in various heterogeneous settings. The source code will be released.", "url": "https://arxiv.org/abs/2308.10162"}, {"metadata": {"arXiv": "2308.10199", "Date": "Sun, 20 Aug 2023 08:16:36 ", "Title": "Deep Reinforcement Learning for Artificial Upwelling Energy Management", "Authors": ["Yiyuan Zhang", "Wei Fan"], "Categories": "cs.LG cs.AI", "Comments": ["31 pages", "13 figures"]}, "abstract": "The potential of artificial upwelling (AU) as a means of lifting nutrient-rich bottom water to the surface, stimulating seaweed growth, and consequently enhancing ocean carbon sequestration, has been gaining increasing attention in recent years. This has led to the development of the first solar-powered and air-lifted AU system (AUS) in China. However, efficient scheduling of air injection systems remains a crucial challenge in operating AUS, as it holds the potential to significantly improve system efficiency. Conventional approaches based on rules or models are often impractical due to the complex and heterogeneous nature of the marine environment and its associated disturbances. To address this challenge, we propose a novel energy management approach that utilizes deep reinforcement learning (DRL) algorithm to develop efficient strategies for operating AUS. Through extensive simulations, we evaluate the performance of our algorithm and demonstrate its superior effectiveness over traditional rule-based approaches and other DRL algorithms in reducing energy wastage while ensuring the stable and efficient operation of AUS. Our findings suggest that a DRL-based approach offers a promising way for improving the efficiency of AUS and enhancing the sustainability of seaweed cultivation and carbon sequestration in the ocean.", "url": "https://arxiv.org/abs/2308.10199"}, {"metadata": {"arXiv": "2308.10203", "Date": "Sun, 20 Aug 2023 08:32:11 ", "Title": "Soft Decomposed Policy-Critic: Bridging the Gap for Effective Continuous Control with Discrete RL", "Authors": ["Yechen Zhang", "Jian Sun", "Gang Wang", "Zhuo Li", "Wei Chen"], "Categories": "cs.LG cs.AI"}, "abstract": "Discrete reinforcement learning (RL) algorithms have demonstrated exceptional performance in solving sequential decision tasks with discrete action spaces, such as Atari games. However, their effectiveness is hindered when applied to continuous control problems due to the challenge of dimensional explosion. In this paper, we present the Soft Decomposed Policy-Critic (SDPC) architecture, which combines soft RL and actor-critic techniques with discrete RL methods to overcome this limitation. SDPC discretizes each action dimension independently and employs a shared critic network to maximize the soft $Q$-function. This novel approach enables SDPC to support two types of policies: decomposed actors that lead to the Soft Decomposed Actor-Critic (SDAC) algorithm, and decomposed $Q$-networks that generate Boltzmann soft exploration policies, resulting in the Soft Decomposed-Critic Q (SDCQ) algorithm. Through extensive experiments, we demonstrate that our proposed approach outperforms state-of-the-art continuous RL algorithms in a variety of continuous control tasks, including Mujoco's Humanoid and Box2d's BipedalWalker. These empirical results validate the effectiveness of the SDPC architecture in addressing the challenges associated with continuous control.", "url": "https://arxiv.org/abs/2308.10203"}, {"metadata": {"arXiv": "2308.10282", "Date": "Sun, 20 Aug 2023 14:31:55 ", "Title": "Enhancing Spatiotemporal Traffic Prediction through Urban Human Activity Analysis", "Authors": ["Sumin Han and Youngjun Park and Minji Lee and Jisun An and Dongman Lee"], "Categories": "cs.LG cs.AI", "Comments": ["CIKM 2023"], "DOI": "10.1145/3583780.3614867"}, "abstract": "Traffic prediction is one of the key elements to ensure the safety and convenience of citizens. Existing traffic prediction models primarily focus on deep learning architectures to capture spatial and temporal correlation. They often overlook the underlying nature of traffic. Specifically, the sensor networks in most traffic datasets do not accurately represent the actual road network exploited by vehicles, failing to provide insights into the traffic patterns in urban activities. To overcome these limitations, we propose an improved traffic prediction method based on graph convolution deep learning algorithms. We leverage human activity frequency data from National Household Travel Survey to enhance the inference capability of a causal relationship between activity and traffic patterns. Despite making minimal modifications to the conventional graph convolutional recurrent networks and graph convolutional transformer architectures, our approach achieves state-of-the-art performance without introducing excessive computational overhead.", "url": "https://arxiv.org/abs/2308.10282"}, {"metadata": {"arXiv": "2308.10284", "Date": "Sun, 20 Aug 2023 14:44:50 ", "Title": "Towards Few-shot Coordination: Revisiting Ad-hoc Teamplay Challenge In the Game of Hanabi", "Authors": ["Hadi Nekoei", "Xutong Zhao", "Janarthanan Rajendran", "Miao Liu", "Sarath Chandar"], "Categories": "cs.LG cs.AI cs.MA"}, "abstract": "Cooperative Multi-agent Reinforcement Learning (MARL) algorithms with Zero-Shot Coordination (ZSC) have gained significant attention in recent years. ZSC refers to the ability of agents to coordinate zero-shot (without additional interaction experience) with independently trained agents. While ZSC is crucial for cooperative MARL agents, it might not be possible for complex tasks and changing environments. Agents also need to adapt and improve their performance with minimal interaction with other agents. In this work, we show empirically that state-of-the-art ZSC algorithms have poor performance when paired with agents trained with different learning methods, and they require millions of interaction samples to adapt to these new partners. To investigate this issue, we formally defined a framework based on a popular cooperative multi-agent game called Hanabi to evaluate the adaptability of MARL methods. In particular, we created a diverse set of pre-trained agents and defined a new metric called adaptation regret that measures the agent's ability to efficiently adapt and improve its coordination performance when paired with some held-out pool of partners on top of its ZSC performance. After evaluating several SOTA algorithms using our framework, our experiments reveal that naive Independent Q-Learning (IQL) agents in most cases adapt as quickly as the SOTA ZSC algorithm Off-Belief Learning (OBL). This finding raises an interesting research question: How to design MARL algorithms with high ZSC performance and capability of fast adaptation to unseen partners. As a first step, we studied the role of different hyper-parameters and design choices on the adaptability of current MARL algorithms. Our experiments show that two categories of hyper-parameters controlling the training data diversity and optimization process have a significant impact on the adaptability of Hanabi agents.", "url": "https://arxiv.org/abs/2308.10284"}, {"metadata": {"arXiv": "2308.10486", "Date": "Mon, 21 Aug 2023 06:04:30 ", "Title": "Deep Metric Loss for Multimodal Learning", "Authors": ["Sehwan Moon and Hyunju Lee"], "Categories": "cs.LG cs.AI", "Comments": ["18 pages", "9 figures"]}, "abstract": "Multimodal learning often outperforms its unimodal counterparts by exploiting unimodal contributions and cross-modal interactions. However, focusing only on integrating multimodal features into a unified comprehensive representation overlooks the unimodal characteristics. In real data, the contributions of modalities can vary from instance to instance, and they often reinforce or conflict with each other. In this study, we introduce a novel \\text{MultiModal} loss paradigm for multimodal learning, which subgroups instances according to their unimodal contributions. \\text{MultiModal} loss can prevent inefficient learning caused by overfitting and efficiently optimize multimodal models. On synthetic data, \\text{MultiModal} loss demonstrates improved classification performance by subgrouping difficult instances within certain modalities. On four real multimodal datasets, our loss is empirically shown to improve the performance of recent models. Ablation studies verify the effectiveness of our loss. Additionally, we show that our loss generates a reliable prediction score for each modality, which is essential for subgrouping. Our \\text{MultiModal} loss is a novel loss function to subgroup instances according to the contribution of modalities in multimodal learning and is applicable to a variety of multimodal models with unimodal decisions. Our code is available at https://github.com/SehwanMoon/MultiModalLoss.", "url": "https://arxiv.org/abs/2308.10486"}, {"metadata": {"arXiv": "2308.10496", "Date": "Mon, 21 Aug 2023 06:35:08 ", "Title": "Using Autoencoders and AutoDiff to Reconstruct Missing Variables in a Set of Time Series", "Authors": ["Jan-Philipp Roche and Oliver Niggemann and Jens Friebe"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "Existing black box modeling approaches in machine learning suffer from a fixed input and output feature combination. In this paper, a new approach to reconstruct missing variables in a set of time series is presented. An autoencoder is trained as usual with every feature on both sides and the neural network parameters are fixed after this training. Then, the searched variables are defined as missing variables at the autoencoder input and optimized via automatic differentiation. This optimization is performed with respect to the available features loss calculation. With this method, different input and output feature combinations of the trained model can be realized by defining the searched variables as missing variables and reconstructing them. The combination can be changed without training the autoencoder again. The approach is evaluated on the base of a strongly nonlinear electrical component. It is working well for one of four variables missing and generally even for multiple missing variables.", "url": "https://arxiv.org/abs/2308.10496"}, {"metadata": {"arXiv": "2308.10571", "Date": "Mon, 21 Aug 2023 09:04:54 ", "Title": "Overcoming Overconfidence for Active Learning", "Authors": ["Yujin Hwang", "Won Jo", "Juyoung Hong", "and Yukyung Choi"], "Categories": "cs.LG cs.AI"}, "abstract": "It is not an exaggeration to say that the recent progress in artificial intelligence technology depends on large-scale and high-quality data. Simultaneously, a prevalent issue exists everywhere: the budget for data labeling is constrained. Active learning is a prominent approach for addressing this issue, where valuable data for labeling is selected through a model and utilized to iteratively adjust the model. However, due to the limited amount of data in each iteration, the model is vulnerable to bias; thus, it is more likely to yield overconfident predictions. In this paper, we present two novel methods to address the problem of overconfidence that arises in the active learning scenario. The first is an augmentation strategy named Cross-Mix-and-Mix (CMaM), which aims to calibrate the model by expanding the limited training distribution. The second is a selection strategy named Ranked Margin Sampling (RankedMS), which prevents choosing data that leads to overly confident predictions. Through various experiments and analyses, we are able to demonstrate that our proposals facilitate efficient data selection by alleviating overconfidence, even though they are readily applicable.", "url": "https://arxiv.org/abs/2308.10571"}, {"metadata": {"arXiv": "2308.10650", "Date": "Mon, 21 Aug 2023 11:42:16 ", "Title": "Deep Evidential Learning for Bayesian Quantile Regression", "Authors": ["Frederik Boe H\\\"uttel", "Filipe Rodrigues", "Francisco C\\^amara Pereira"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "It is desirable to have accurate uncertainty estimation from a single deterministic forward-pass model, as traditional methods for uncertainty quantification are computationally expensive. However, this is difficult because single forward-pass models do not sample weights during inference and often make assumptions about the target distribution, such as assuming it is Gaussian. This can be restrictive in regression tasks, where the mean and standard deviation are inadequate to model the target distribution accurately. This paper proposes a deep Bayesian quantile regression model that can estimate the quantiles of a continuous target distribution without the Gaussian assumption. The proposed method is based on evidential learning, which allows the model to capture aleatoric and epistemic uncertainty with a single deterministic forward-pass model. This makes the method efficient and scalable to large models and datasets. We demonstrate that the proposed method achieves calibrated uncertainties on non-Gaussian distributions, disentanglement of aleatoric and epistemic uncertainty, and robustness to out-of-distribution samples.", "url": "https://arxiv.org/abs/2308.10650"}, {"metadata": {"arXiv": "2308.10664", "Date": "Mon, 21 Aug 2023 12:02:54 ", "Title": "A Safe Deep Reinforcement Learning Approach for Energy Efficient Federated Learning in Wireless Communication Networks", "Authors": ["Nikolaos Koursioumpas", "Lina Magoula", "Nikolaos Petropouleas", "Alexandros-Ioannis Thanopoulos", "Theodora Panagea", "Nancy Alonistioti", "M. A. Gutierrez-Estevez", "Ramin Khalili"], "Categories": "cs.LG cs.AI", "Comments": ["27 Pages Single Column", "6 Figures", "Submitted for possible publication in the IEEE Transactions on Green Communications and Networking (TGCN). arXiv admin note: text overlap with arXiv:2306.14237"]}, "abstract": "Progressing towards a new era of Artificial Intelligence (AI) - enabled wireless networks, concerns regarding the environmental impact of AI have been raised both in industry and academia. Federated Learning (FL) has emerged as a key privacy preserving decentralized AI technique. Despite efforts currently being made in FL, its environmental impact is still an open problem. Targeting the minimization of the overall energy consumption of an FL process, we propose the orchestration of computational and communication resources of the involved devices to minimize the total energy required, while guaranteeing a certain performance of the model. To this end, we propose a Soft Actor Critic Deep Reinforcement Learning (DRL) solution, where a penalty function is introduced during training, penalizing the strategies that violate the constraints of the environment, and ensuring a safe RL process. A device level synchronization method, along with a computationally cost effective FL environment are proposed, with the goal of further reducing the energy consumption and communication overhead. Evaluation results show the effectiveness of the proposed scheme compared to four state-of-the-art baseline solutions in both static and dynamic environments, achieving a decrease of up to 94% in the total energy consumption.", "url": "https://arxiv.org/abs/2308.10664"}, {"metadata": {"arXiv": "2308.10704", "Date": "Mon, 21 Aug 2023 13:18:12 ", "Title": "Sampling From Autoencoders' Latent Space via Quantization And Probability Mass Function Concepts", "Authors": ["Aymene Mohammed Bouayed and Adrian Iaccovelli and David Naccache"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "In this study, we focus on sampling from the latent space of generative models built upon autoencoders so as the reconstructed samples are lifelike images. To do to, we introduce a novel post-training sampling algorithm rooted in the concept of probability mass functions, coupled with a quantization process. Our proposed algorithm establishes a vicinity around each latent vector from the input data and then proceeds to draw samples from these defined neighborhoods. This strategic approach ensures that the sampled latent vectors predominantly inhabit high-probability regions, which, in turn, can be effectively transformed into authentic real-world images. A noteworthy point of comparison for our sampling algorithm is the sampling technique based on Gaussian mixture models (GMM), owing to its inherent capability to represent clusters. Remarkably, we manage to improve the time complexity from the previous $\\mathcal{O}(n\\times d \\times k \\times i)$ associated with GMM sampling to a much more streamlined $\\mathcal{O}(n\\times d)$, thereby resulting in substantial speedup during runtime. Moreover, our experimental results, gauged through the Fr\\'echet inception distance (FID) for image generation, underscore the superior performance of our sampling algorithm across a diverse range of models and datasets. On the MNIST benchmark dataset, our approach outperforms GMM sampling by yielding a noteworthy improvement of up to $0.89$ in FID value. Furthermore, when it comes to generating images of faces and ocular images, our approach showcases substantial enhancements with FID improvements of $1.69$ and $0.87$ respectively, as compared to GMM sampling, as evidenced on the CelebA and MOBIUS datasets. Lastly, we substantiate our methodology's efficacy in estimating latent space distributions in contrast to GMM sampling, particularly through the lens of the Wasserstein distance.", "url": "https://arxiv.org/abs/2308.10704"}, {"metadata": {"arXiv": "2308.10721", "Date": "Mon, 21 Aug 2023 13:45:44 ", "Title": "CoMIX: A Multi-agent Reinforcement Learning Training Architecture for Efficient Decentralized Coordination and Independent Decision Making", "Authors": ["Giovanni Minelli", "Mirco Musolesi"], "Categories": "cs.LG cs.AI cs.MA"}, "abstract": "Robust coordination skills enable agents to operate cohesively in shared environments, together towards a common goal and, ideally, individually without hindering each other's progress. To this end, this paper presents Coordinated QMIX (CoMIX), a novel training framework for decentralized agents that enables emergent coordination through flexible policies, allowing at the same time independent decision-making at individual level. CoMIX models selfish and collaborative behavior as incremental steps in each agent's decision process. This allows agents to dynamically adapt their behavior to different situations balancing independence and collaboration. Experiments using a variety of simulation environments demonstrate that CoMIX outperforms baselines on collaborative tasks. The results validate our incremental policy approach as effective technique for improving coordination in multi-agent systems.", "url": "https://arxiv.org/abs/2308.10721"}, {"metadata": {"arXiv": "2308.10740", "Date": "Mon, 21 Aug 2023 14:08:42 ", "Title": "We Don't Need No Adam, All We Need Is EVE: On The Variance of Dual Learning Rate And Beyond", "Authors": ["Afshin Khadangi"], "Categories": "cs.LG cs.AI"}, "abstract": "In the rapidly advancing field of deep learning, optimising deep neural networks is paramount. This paper introduces a novel method, Enhanced Velocity Estimation (EVE), which innovatively applies different learning rates to distinct components of the gradients. By bifurcating the learning rate, EVE enables more nuanced control and faster convergence, addressing the challenges associated with traditional single learning rate approaches. Utilising a momentum term that adapts to the learning landscape, the method achieves a more efficient navigation of the complex loss surface, resulting in enhanced performance and stability. Extensive experiments demonstrate that EVE significantly outperforms existing optimisation techniques across various benchmark datasets and architectures.", "url": "https://arxiv.org/abs/2308.10740"}, {"metadata": {"arXiv": "2308.10741", "Date": "Mon, 21 Aug 2023 14:09:09 ", "Title": "On the Adversarial Robustness of Multi-Modal Foundation Models", "Authors": ["Christian Schlarmann and Matthias Hein"], "Categories": "cs.LG cs.AI cs.CR", "Comments": ["ICCV AROW 2023"]}, "abstract": "Multi-modal foundation models combining vision and language models such as Flamingo or GPT-4 have recently gained enormous interest. Alignment of foundation models is used to prevent models from providing toxic or harmful output. While malicious users have successfully tried to jailbreak foundation models, an equally important question is if honest users could be harmed by malicious third-party content. In this paper we show that imperceivable attacks on images in order to change the caption output of a multi-modal foundation model can be used by malicious content providers to harm honest users e.g. by guiding them to malicious websites or broadcast fake information. This indicates that countermeasures to adversarial attacks should be used by any deployed multi-modal foundation model.", "url": "https://arxiv.org/abs/2308.10741"}, {"metadata": {"arXiv": "2308.10757", "Date": "Mon, 21 Aug 2023 14:43:42 ", "Title": "To Whom are You Talking? A Deep Learning Model to Endow Social Robots with Addressee Estimation Skills", "Authors": ["Carlo Mazzola", "Marta Romeo", "Francesco Rea", "Alessandra Sciutti", "Angelo Cangelosi"], "Categories": "cs.LG cs.AI cs.RO", "Comments": ["Accepted version of a paper published at 2023 International Joint Conference on Neural Networks (IJCNN). Please find the published version and info to cite the paper at https://doi.org/10.1109/IJCNN54540.2023.10191452 . 10 pages", "8 Figures", "3 Tables"], "MSC-class": "68T07, 68T40", "ACM-class": "I.2.6; I.2.9; I.2.10; J.7", "Journal-ref": "2023 International Joint Conference on Neural Networks (IJCNN), pp. 1-10", "DOI": "10.1109/IJCNN54540.2023.10191452"}, "abstract": "Communicating shapes our social word. For a robot to be considered social and being consequently integrated in our social environment it is fundamental to understand some of the dynamics that rule human-human communication. In this work, we tackle the problem of Addressee Estimation, the ability to understand an utterance's addressee, by interpreting and exploiting non-verbal bodily cues from the speaker. We do so by implementing an hybrid deep learning model composed of convolutional layers and LSTM cells taking as input images portraying the face of the speaker and 2D vectors of the speaker's body posture. Our implementation choices were guided by the aim to develop a model that could be deployed on social robots and be efficient in ecological scenarios. We demonstrate that our model is able to solve the Addressee Estimation problem in terms of addressee localisation in space, from a robot ego-centric point of view.", "url": "https://arxiv.org/abs/2308.10757"}, {"metadata": {"arXiv": "2308.10782", "Date": "Mon, 21 Aug 2023 15:16:19 ", "Title": "Sparse Linear Concept Discovery Models", "Authors": ["Konstantinos P. Panousis", "Dino Ienco", "Diego Marcos"], "Categories": "cs.LG cs.AI stat.ML", "Comments": ["Accepted @ ICCVW CLVL 2023"]}, "abstract": "The recent mass adoption of DNNs, even in safety-critical scenarios, has shifted the focus of the research community towards the creation of inherently intrepretable models. Concept Bottleneck Models (CBMs) constitute a popular approach where hidden layers are tied to human understandable concepts allowing for investigation and correction of the network's decisions. However, CBMs usually suffer from: (i) performance degradation and (ii) lower interpretability than intended due to the sheer amount of concepts contributing to each decision. In this work, we propose a simple yet highly intuitive interpretable framework based on Contrastive Language Image models and a single sparse linear layer. In stark contrast to related approaches, the sparsity in our framework is achieved via principled Bayesian arguments by inferring concept presence via a data-driven Bernoulli distribution. As we experimentally show, our framework not only outperforms recent CBM approaches accuracy-wise, but it also yields high per example concept sparsity, facilitating the individual investigation of the emerging concepts.", "url": "https://arxiv.org/abs/2308.10782"}, {"metadata": {"arXiv": "2308.10797", "Date": "Mon, 21 Aug 2023 15:42:56 ", "Title": "Stabilizing Unsupervised Environment Design with a Learned Adversary", "Authors": ["Ishita Mediratta", "Minqi Jiang", "Jack Parker-Holder", "Michael Dennis", "Eugene Vinitsky", "Tim Rockt\\\"aschel"], "Categories": "cs.LG cs.AI", "Comments": ["CoLLAs 2023 - Oral; Minqi and Jack contributed equally"]}, "abstract": "A key challenge in training generally-capable agents is the design of training tasks that facilitate broad generalization and robustness to environment variations. This challenge motivates the problem setting of Unsupervised Environment Design (UED), whereby a student agent trains on an adaptive distribution of tasks proposed by a teacher agent. A pioneering approach for UED is PAIRED, which uses reinforcement learning (RL) to train a teacher policy to design tasks from scratch, making it possible to directly generate tasks that are adapted to the agent's current capabilities. Despite its strong theoretical backing, PAIRED suffers from a variety of challenges that hinder its practical performance. Thus, state-of-the-art methods currently rely on curation and mutation rather than generation of new tasks. In this work, we investigate several key shortcomings of PAIRED and propose solutions for each shortcoming. As a result, we make it possible for PAIRED to match or exceed state-of-the-art methods, producing robust agents in several established challenging procedurally-generated environments, including a partially-observed maze navigation task and a continuous-control car racing environment. We believe this work motivates a renewed emphasis on UED methods based on learned models that directly generate challenging environments, potentially unlocking more open-ended RL training and, as a result, more general agents.", "url": "https://arxiv.org/abs/2308.10797"}, {"metadata": {"arXiv": "2308.10806", "Date": "Mon, 21 Aug 2023 15:53:38 ", "Title": "Differentiable Frank-Wolfe Optimization Layer", "Authors": ["Zixuan Liu", "Liu Liu", "Xueqian Wang", "Peilin Zhao"], "Categories": "cs.LG cs.AI"}, "abstract": "Differentiable optimization has received a significant amount of attention due to its foundational role in the domain of machine learning based on neural networks. The existing methods leverages the optimality conditions and implicit function theorem to obtain the Jacobian matrix of the output, which increases the computational cost and limits the application of differentiable optimization. In addition, some non-differentiable constraints lead to more challenges when using prior differentiable optimization layers. This paper proposes a differentiable layer, named Differentiable Frank-Wolfe Layer (DFWLayer), by rolling out the Frank-Wolfe method, a well-known optimization algorithm which can solve constrained optimization problems without projections and Hessian matrix computations, thus leading to a efficient way of dealing with large-scale problems. Theoretically, we establish a bound on the suboptimality gap of the DFWLayer in the context of l1-norm constraints. Experimental assessments demonstrate that the DFWLayer not only attains competitive accuracy in solutions and gradients but also consistently adheres to constraints. Moreover, it surpasses the baselines in both forward and backward computational speeds.", "url": "https://arxiv.org/abs/2308.10806"}, {"metadata": {"arXiv": "2308.10846", "Date": "Mon, 21 Aug 2023 16:44:56 ", "Title": "Real World Time Series Benchmark Datasets with Distribution Shifts: Global Crude Oil Price and Volatility", "Authors": ["Pranay Pasula"], "Categories": "cs.LG cs.AI stat.ML", "Comments": ["7 pages", "5 figures. Awarded Best Paper Runner Up / Honorable Mention and presented as Contributed Talk at IJCAI 2023", "the 32nd International Joint Conference on Artificial Intelligence (AI4TS)"]}, "abstract": "The scarcity of task-labeled time-series benchmarks in the financial domain hinders progress in continual learning. Addressing this deficit would foster innovation in this area. Therefore, we present COB, Crude Oil Benchmark datasets. COB includes 30 years of asset prices that exhibit significant distribution shifts and optimally generates corresponding task (i.e., regime) labels based on these distribution shifts for the three most important crude oils in the world. Our contributions include creating real-world benchmark datasets by transforming asset price data into volatility proxies, fitting models using expectation-maximization (EM), generating contextual task labels that align with real-world events, and providing these labels as well as the general algorithm to the public. We show that the inclusion of these task labels universally improves performance on four continual learning algorithms, some state-of-the-art, over multiple forecasting horizons. We hope these benchmarks accelerate research in handling distribution shifts in real-world data, especially due to the global importance of the assets considered. We've made the (1) raw price data, (2) task labels generated by our approach, (3) and code for our algorithm available at https://oilpricebenchmarks.github.io.", "url": "https://arxiv.org/abs/2308.10846"}, {"metadata": {"arXiv": "2308.10869", "Date": "Thu, 17 Aug 2023 01:15:26 ", "Title": "A Novel Loss Function Utilizing Wasserstein Distance to Reduce Subject-Dependent Noise for Generalizable Models in Affective Computing", "Authors": ["Nibraas Khan", "Mahrukh Tauseef", "Ritam Ghosh", "Nilanjan Sarkar"], "Categories": "cs.LG cs.AI eess.SP", "Comments": ["9 pages"]}, "abstract": "Emotions are an essential part of human behavior that can impact thinking, decision-making, and communication skills. Thus, the ability to accurately monitor and identify emotions can be useful in many human-centered applications such as behavioral training, tracking emotional well-being, and development of human-computer interfaces. The correlation between patterns in physiological data and affective states has allowed for the utilization of deep learning techniques which can accurately detect the affective states of a person. However, the generalisability of existing models is often limited by the subject-dependent noise in the physiological data due to variations in a subject's reactions to stimuli. Hence, we propose a novel cost function that employs Optimal Transport Theory, specifically Wasserstein Distance, to scale the importance of subject-dependent data such that higher importance is assigned to patterns in data that are common across all participants while decreasing the importance of patterns that result from subject-dependent noise. The performance of the proposed cost function is demonstrated through an autoencoder with a multi-class classifier attached to the latent space and trained simultaneously to detect different affective states. An autoencoder with a state-of-the-art loss function i.e., Mean Squared Error, is used as a baseline for comparison with our model across four different commonly used datasets. Centroid and minimum distance between different classes are used as a metrics to indicate the separation between different classes in the latent space. An average increase of 14.75% and 17.75% (from benchmark to proposed loss function) was found for minimum and centroid euclidean distance respectively over all datasets.", "url": "https://arxiv.org/abs/2308.10869"}, {"metadata": {"arXiv": "2308.10874", "Date": "Mon, 21 Aug 2023 17:21:23 ", "Title": "Analyzing Transformer Dynamics as Movement through Embedding Space", "Authors": ["Sumeet S. Singh"], "Categories": "cs.LG cs.AI cs.CL cs.NE"}, "abstract": "Transformer language models exhibit intelligent behaviors such as understanding natural language, recognizing patterns, acquiring knowledge, reasoning, planning, reflecting and using tools. This paper explores how their underlying mechanics give rise to intelligent behaviors. We adopt a systems approach to analyze Transformers in detail and develop a mathematical framework that frames their dynamics as movement through embedding space. This novel perspective provides a principled way of thinking about the problem and reveals important insights related to the emergence of intelligence: 1. At its core the Transformer is a Embedding Space walker, mapping intelligent behavior to trajectories in this vector space. 2. At each step of the walk, it composes context into a single composite vector whose location in Embedding Space defines the next step. 3. No learning actually occurs during decoding; in-context learning and generalization are simply the result of different contexts composing into different vectors. 4. Ultimately the knowledge, intelligence and skills exhibited by the model are embodied in the organization of vectors in Embedding Space rather than in specific neurons or layers. These abilities are properties of this organization. 5. Attention's contribution boils down to the association-bias it lends to vector composition and which influences the aforementioned organization. However, more investigation is needed to ascertain its significance. 6. The entire model is composed from two principal operations: data independent filtering and data dependent aggregation. This generalization unifies Transformers with other sequence models and across modalities. Building upon this foundation we formalize and test a semantic space theory which posits that embedding vectors represent semantic concepts and find some evidence of its validity.", "url": "https://arxiv.org/abs/2308.10874"}, {"metadata": {"arXiv": "2308.10892", "Date": "Thu, 17 Aug 2023 05:42:29 ", "Title": "Bayesian polynomial neural networks and polynomial neural ordinary differential equations", "Authors": ["Colby Fronk and Jaewoong Yun and Prashant Singh and Linda Petzold"], "Categories": "cs.LG cs.AI cs.CE"}, "abstract": "Symbolic regression with polynomial neural networks and polynomial neural ordinary differential equations (ODEs) are two recent and powerful approaches for equation recovery of many science and engineering problems. However, these methods provide point estimates for the model parameters and are currently unable to accommodate noisy data. We address this challenge by developing and validating the following Bayesian inference methods: the Laplace approximation, Markov Chain Monte Carlo (MCMC) sampling methods, and variational inference. We have found the Laplace approximation to be the best method for this class of problems. Our work can be easily extended to the broader class of symbolic neural networks to which the polynomial neural network belongs.", "url": "https://arxiv.org/abs/2308.10892"}, {"metadata": {"arXiv": "2308.10901", "Date": "Mon, 21 Aug 2023 17:59:32 ", "Title": "Structured World Models from Human Videos", "Authors": ["Russell Mendonca", "Shikhar Bahl", "Deepak Pathak"], "Categories": "cs.RO cs.AI cs.CV cs.LG cs.NE", "Comments": ["RSS 2023. Website at https://human-world-model.github.io"]}, "abstract": "We tackle the problem of learning complex, general behaviors directly in the real world. We propose an approach for robots to efficiently learn manipulation skills using only a handful of real-world interaction trajectories from many different settings. Inspired by the success of learning from large-scale datasets in the fields of computer vision and natural language, our belief is that in order to efficiently learn, a robot must be able to leverage internet-scale, human video data. Humans interact with the world in many interesting ways, which can allow a robot to not only build an understanding of useful actions and affordances but also how these actions affect the world for manipulation. Our approach builds a structured, human-centric action space grounded in visual affordances learned from human videos. Further, we train a world model on human videos and fine-tune on a small amount of robot interaction data without any task supervision. We show that this approach of affordance-space world models enables different robots to learn various manipulation skills in complex settings, in under 30 minutes of interaction. Videos can be found at https://human-world-model.github.io", "url": "https://arxiv.org/abs/2308.10901"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2310.16870", "Date": "Wed, 25 Oct 2023 14:24:42 ", "Title": "MACP: Efficient Model Adaptation for Cooperative Perception", "Authors": ["Yunsheng Ma and Juanwu Lu and Can Cui and Sicheng ZHao and Xu Cao and Wenqian Ye and Ziran Wang"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted by WACV 2024", "10 pages", "7 figures", "3 tables"]}, "abstract": "Vehicle-to-vehicle (V2V) communications have greatly enhanced the perception capabilities of connected and automated vehicles (CAVs) by enabling information sharing to \"see through the occlusions\", resulting in significant performance improvements. However, developing and training complex multi-agent perception models from scratch can be expensive and unnecessary when existing single-agent models show remarkable generalization capabilities. In this paper, we propose a new framework termed MACP, which equips a single-agent pre-trained model with cooperation capabilities. We approach this objective by identifying the key challenges of shifting from single-agent to cooperative settings, adapting the model by freezing most of its parameters and adding a few lightweight modules. We demonstrate in our experiments that the proposed framework can effectively utilize cooperative observations and outperform other state-of-the-art approaches in both simulated and real-world cooperative perception benchmarks while requiring substantially fewer tunable parameters with reduced communication costs. Our source code is available at https://github.com/PurdueDigitalTwin/MACP.", "url": "https://arxiv.org/abs/2310.16870"}, {"metadata": {"arXiv": "2310.16936", "Date": "Wed, 25 Oct 2023 19:02:57 ", "Title": "Diagnosing Alzheimer's Disease using Early-Late Multimodal Data Fusion with Jacobian Maps", "Authors": ["Yasmine Mustafa and Tie Luo"], "Categories": "cs.CV cs.LG", "Comments": ["To be published in Proceedings of 2023 IEEE Healthcom", "December 2023"]}, "abstract": "Alzheimer's disease (AD) is a prevalent and debilitating neurodegenerative disorder impacting a large aging population. Detecting AD in all its presymptomatic and symptomatic stages is crucial for early intervention and treatment. An active research direction is to explore machine learning methods that harness multimodal data fusion to outperform human inspection of medical scans. However, existing multimodal fusion models have limitations, including redundant computation, complex architecture, and simplistic handling of missing data. Moreover, the preprocessing pipelines of medical scans remain inadequately detailed and are seldom optimized for individual subjects. In this paper, we propose an efficient early-late fusion (ELF) approach, which leverages a convolutional neural network for automated feature extraction and random forests for their competitive performance on small datasets. Additionally, we introduce a robust preprocessing pipeline that adapts to the unique characteristics of individual subjects and makes use of whole brain images rather than slices or patches. Moreover, to tackle the challenge of detecting subtle changes in brain volume, we transform images into the Jacobian domain (JD) to enhance both accuracy and robustness in our classification. Using MRI and CT images from the OASIS-3 dataset, our experiments demonstrate the effectiveness of the ELF approach in classifying AD into four stages with an accuracy of 97.19%.", "url": "https://arxiv.org/abs/2310.16936"}, {"metadata": {"arXiv": "2310.16979", "Date": "Wed, 25 Oct 2023 20:31:07 ", "Title": "Unsupervised Domain Adaptation for Semantic Segmentation with Pseudo Label Self-Refinement", "Authors": ["Xingchen Zhao", "Niluthpol Chowdhury Mithun", "Abhinav Rajvanshi", "Han-Pang Chiu", "Supun Samarasekera"], "Categories": "cs.CV cs.LG", "Comments": ["WACV 2024"]}, "abstract": "Deep learning-based solutions for semantic segmentation suffer from significant performance degradation when tested on data with different characteristics than what was used during the training. Adapting the models using annotated data from the new domain is not always practical. Unsupervised Domain Adaptation (UDA) approaches are crucial in deploying these models in the actual operating conditions. Recent state-of-the-art (SOTA) UDA methods employ a teacher-student self-training approach, where a teacher model is used to generate pseudo-labels for the new data which in turn guide the training process of the student model. Though this approach has seen a lot of success, it suffers from the issue of noisy pseudo-labels being propagated in the training process. To address this issue, we propose an auxiliary pseudo-label refinement network (PRN) for online refining of the pseudo labels and also localizing the pixels whose predicted labels are likely to be noisy. Being able to improve the quality of pseudo labels and select highly reliable ones, PRN helps self-training of segmentation models to be robust against pseudo label noise propagation during different stages of adaptation. We evaluate our approach on benchmark datasets with three different domain shifts, and our approach consistently performs significantly better than the previous state-of-the-art methods.", "url": "https://arxiv.org/abs/2310.16979"}, {"metadata": {"arXiv": "2310.16999", "Date": "Wed, 25 Oct 2023 20:55:07 ", "Title": "Trust, but Verify: Robust Image Segmentation using Deep Learning", "Authors": ["Fahim Ahmed Zaman", "Xiaodong Wu", "Weiyu Xu", "Milan Sonka and Raghuraman Mudumbai"], "Categories": "cs.CV cs.LG eess.IV", "Comments": ["5 Pages", "8 Figures", "conference"]}, "abstract": "We describe a method for verifying the output of a deep neural network for medical image segmentation that is robust to several classes of random as well as worst-case perturbations i.e. adversarial attacks. This method is based on a general approach recently developed by the authors called ``Trust, but Verify\" wherein an auxiliary verification network produces predictions about certain masked features in the input image using the segmentation as an input. A well-designed auxiliary network will produce high-quality predictions when the input segmentations are accurate, but will produce low-quality predictions when the segmentations are incorrect. Checking the predictions of such a network with the original image allows us to detect bad segmentations. However, to ensure the verification method is truly robust, we need a method for checking the quality of the predictions that does not itself rely on a black-box neural network. Indeed, we show that previous methods for segmentation evaluation that do use deep neural regression networks are vulnerable to false negatives i.e. can inaccurately label bad segmentations as good. We describe the design of a verification network that avoids such vulnerability and present results to demonstrate its robustness compared to previous methods.", "url": "https://arxiv.org/abs/2310.16999"}, {"metadata": {"arXiv": "2310.17078", "Date": "Thu, 26 Oct 2023 00:43:15 ", "Title": "HCT: Hybrid Convnet-Transformer for Parkinson's disease detection and severity prediction from gait", "Authors": ["Safwen Naimi", "Wassim Bouachir", "Guillaume-Alexandre Bilodeau"], "Categories": "cs.CV cs.LG", "Comments": ["6 pages", "6 figures", "3 tables", "Accepted for publication in IEEE International Conference on Machine Learning and Applications (ICMLA)", "copyright IEEE"]}, "abstract": "In this paper, we propose a novel deep learning method based on a new Hybrid ConvNet-Transformer architecture to detect and stage Parkinson's disease (PD) from gait data. We adopt a two-step approach by dividing the problem into two sub-problems. Our Hybrid ConvNet-Transformer model first distinguishes healthy versus parkinsonian patients. If the patient is parkinsonian, a multi-class Hybrid ConvNet-Transformer model determines the Hoehn and Yahr (H&Y) score to assess the PD severity stage. Our hybrid architecture exploits the strengths of both Convolutional Neural Networks (ConvNets) and Transformers to accurately detect PD and determine the severity stage. In particular, we take advantage of ConvNets to capture local patterns and correlations in the data, while we exploit Transformers for handling long-term dependencies in the input signal. We show that our hybrid method achieves superior performance when compared to other state-of-the-art methods, with a PD detection accuracy of 97% and a severity staging accuracy of 87%. Our source code is available at: https://github.com/SafwenNaimi", "url": "https://arxiv.org/abs/2310.17078"}, {"metadata": {"arXiv": "2310.17080", "Date": "Thu, 26 Oct 2023 00:45:19 ", "Title": "Automating lichen monitoring in ecological studies using instance segmentation of time-lapse images", "Authors": ["Safwen Naimi", "Olfa Koubaa", "Wassim Bouachir", "Guillaume-Alexandre Bilodeau", "Gregory Jeddore", "Patricia Baines", "David Correia", "Andre Arsenault"], "Categories": "cs.CV cs.LG", "Comments": ["6 pages", "3 Figures", "8 Tables", "Accepted for publication in IEEE International Conference on Machine Learning and Applications (ICMLA)", "copyright IEEE"]}, "abstract": "Lichens are symbiotic organisms composed of fungi, algae, and/or cyanobacteria that thrive in a variety of environments. They play important roles in carbon and nitrogen cycling, and contribute directly and indirectly to biodiversity. Ecologists typically monitor lichens by using them as indicators to assess air quality and habitat conditions. In particular, epiphytic lichens, which live on trees, are key markers of air quality and environmental health. A new method of monitoring epiphytic lichens involves using time-lapse cameras to gather images of lichen populations. These cameras are used by ecologists in Newfoundland and Labrador to subsequently analyze and manually segment the images to determine lichen thalli condition and change. These methods are time-consuming and susceptible to observer bias. In this work, we aim to automate the monitoring of lichens over extended periods and to estimate their biomass and condition to facilitate the task of ecologists. To accomplish this, our proposed framework uses semantic segmentation with an effective training approach to automate monitoring and biomass estimation of epiphytic lichens on time-lapse images. We show that our method has the potential to significantly improve the accuracy and efficiency of lichen population monitoring, making it a valuable tool for forest ecologists and environmental scientists to evaluate the impact of climate change on Canada's forests. To the best of our knowledge, this is the first time that such an approach has been used to assist ecologists in monitoring and analyzing epiphytic lichens.", "url": "https://arxiv.org/abs/2310.17080"}, {"metadata": {"arXiv": "2310.17209", "Date": "Thu, 26 Oct 2023 07:54:47 ", "Title": "Weakly-Supervised Surgical Phase Recognition", "Authors": ["Roy Hirsch", "Regev Cohen", "Mathilde Caron", "Tomer Golany", "Daniel Freedman", "Ehud Rivlin"], "Categories": "cs.CV cs.LG"}, "abstract": "A key element of computer-assisted surgery systems is phase recognition of surgical videos. Existing phase recognition algorithms require frame-wise annotation of a large number of videos, which is time and money consuming. In this work we join concepts of graph segmentation with self-supervised learning to derive a random-walk solution for per-frame phase prediction. Furthermore, we utilize within our method two forms of weak supervision: sparse timestamps or few-shot learning. The proposed algorithm enjoys low complexity and can operate in lowdata regimes. We validate our method by running experiments with the public Cholec80 dataset of laparoscopic cholecystectomy videos, demonstrating promising performance in multiple setups.", "url": "https://arxiv.org/abs/2310.17209"}, {"metadata": {"arXiv": "2310.17281", "Date": "Thu, 26 Oct 2023 10:02:33 ", "Title": "BEVContrast: Self-Supervision in BEV Space for Automotive Lidar Point Clouds", "Authors": ["Corentin Sautier", "Gilles Puy", "Alexandre Boulch", "Renaud Marlet", "Vincent Lepetit"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted to 3DV 2024"]}, "abstract": "We present a surprisingly simple and efficient method for self-supervision of 3D backbone on automotive Lidar point clouds. We design a contrastive loss between features of Lidar scans captured in the same scene. Several such approaches have been proposed in the literature from PointConstrast, which uses a contrast at the level of points, to the state-of-the-art TARL, which uses a contrast at the level of segments, roughly corresponding to objects. While the former enjoys a great simplicity of implementation, it is surpassed by the latter, which however requires a costly pre-processing. In BEVContrast, we define our contrast at the level of 2D cells in the Bird's Eye View plane. Resulting cell-level representations offer a good trade-off between the point-level representations exploited in PointContrast and segment-level representations exploited in TARL: we retain the simplicity of PointContrast (cell representations are cheap to compute) while surpassing the performance of TARL in downstream semantic segmentation.", "url": "https://arxiv.org/abs/2310.17281"}, {"metadata": {"arXiv": "2310.17356", "Date": "Thu, 26 Oct 2023 12:44:45 ", "Title": "Sky Imager-Based Forecast of Solar Irradiance Using Machine Learning", "Authors": ["Anas Al-lahham", "Obaidah Theeb", "Khaled Elalem", "Tariq A. Alshawi", "Saleh A. Alshebeili"], "Categories": "cs.CV cs.LG", "Comments": ["Published in MDPI Electronics Journal"], "Journal-ref": "Electronics 2020, 9, 1700", "DOI": "10.3390/electronics9101700"}, "abstract": "Ahead-of-time forecasting of the output power of power plants is essential for the stability of the electricity grid and ensuring uninterrupted service. However, forecasting renewable energy sources is difficult due to the chaotic behavior of natural energy sources. This paper presents a new approach to estimate short-term solar irradiance from sky images. The~proposed algorithm extracts features from sky images and use learning-based techniques to estimate the solar irradiance. The~performance of proposed machine learning (ML) algorithm is evaluated using two publicly available datasets of sky images. The~datasets contain over 350,000 images for an interval of 16 years, from 2004 to 2020, with the corresponding global horizontal irradiance (GHI) of each image as the ground truth. Compared to the state-of-the-art computationally heavy algorithms proposed in the literature, our approach achieves competitive results with much less computational complexity for both nowcasting and forecasting up to 4 h ahead of time.", "url": "https://arxiv.org/abs/2310.17356"}, {"metadata": {"arXiv": "2310.17403", "Date": "Thu, 26 Oct 2023 13:56:12 ", "Title": "Detection Defenses: An Empty Promise against Adversarial Patch Attacks on Optical Flow", "Authors": ["Erik Scheurer", "Jenny Schmalfuss", "Alexander Lis and Andr\\'es Bruhn"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted to WACV 2024"]}, "abstract": "Adversarial patches undermine the reliability of optical flow predictions when placed in arbitrary scene locations. Therefore, they pose a realistic threat to real-world motion detection and its downstream applications. Potential remedies are defense strategies that detect and remove adversarial patches, but their influence on the underlying motion prediction has not been investigated. In this paper, we thoroughly examine the currently available detect-and-remove defenses ILP and LGS for a wide selection of state-of-the-art optical flow methods, and illuminate their side effects on the quality and robustness of the final flow predictions. In particular, we implement defense-aware attacks to investigate whether current defenses are able to withstand attacks that take the defense mechanism into account. Our experiments yield two surprising results: Detect-and-remove defenses do not only lower the optical flow quality on benign scenes, in doing so, they also harm the robustness under patch attacks for all tested optical flow methods except FlowNetC. As currently employed detect-and-remove defenses fail to deliver the promised adversarial robustness for optical flow, they evoke a false sense of security. The code is available at https://github.com/cv-stuttgart/DetectionDefenses.", "url": "https://arxiv.org/abs/2310.17403"}, {"metadata": {"arXiv": "2310.17437", "Date": "Thu, 26 Oct 2023 14:47:11 ", "Title": "Sign Languague Recognition without frame-sequencing constraints: A proof of concept on the Argentinian Sign Language", "Authors": ["Franco Ronchetti", "Facundo Manuel Quiroga", "C\\'esar Estrebou", "Laura Lanzarini", "Alejandro Rosete"], "Categories": "cs.CV cs.LG cs.NE", "Comments": ["IBERAMIA 2016"], "DOI": "10.1007/978-3-319-47955-2_28"}, "abstract": "Automatic sign language recognition (SLR) is an important topic within the areas of human-computer interaction and machine learning. On the one hand, it poses a complex challenge that requires the intervention of various knowledge areas, such as video processing, image processing, intelligent systems and linguistics. On the other hand, robust recognition of sign language could assist in the translation process and the integration of hearing-impaired people, as well as the teaching of sign language for the hearing population. SLR systems usually employ Hidden Markov Models, Dynamic Time Warping or similar models to recognize signs. Such techniques exploit the sequential ordering of frames to reduce the number of hypothesis. This paper presents a general probabilistic model for sign classification that combines sub-classifiers based on different types of features such as position, movement and handshape. The model employs a bag-of-words approach in all classification steps, to explore the hypothesis that ordering is not essential for recognition. The proposed model achieved an accuracy rate of 97% on an Argentinian Sign Language dataset containing 64 classes of signs and 3200 samples, providing some evidence that indeed recognition without ordering is possible.", "url": "https://arxiv.org/abs/2310.17437"}, {"metadata": {"arXiv": "2310.17468", "Date": "Thu, 26 Oct 2023 15:15:11 ", "Title": "Cross-modal Active Complementary Learning with Self-refining Correspondence", "Authors": ["Yang Qin", "Yuan Sun", "Dezhong Peng", "Joey Tianyi Zhou", "Xi Peng", "Peng Hu"], "Categories": "cs.CV cs.LG", "Comments": ["This paper is accepted by NeurIPS 2023"]}, "abstract": "Recently, image-text matching has attracted more and more attention from academia and industry, which is fundamental to understanding the latent correspondence across visual and textual modalities. However, most existing methods implicitly assume the training pairs are well-aligned while ignoring the ubiquitous annotation noise, a.k.a noisy correspondence (NC), thereby inevitably leading to a performance drop. Although some methods attempt to address such noise, they still face two challenging problems: excessive memorizing/overfitting and unreliable correction for NC, especially under high noise. To address the two problems, we propose a generalized Cross-modal Robust Complementary Learning framework (CRCL), which benefits from a novel Active Complementary Loss (ACL) and an efficient Self-refining Correspondence Correction (SCC) to improve the robustness of existing methods. Specifically, ACL exploits active and complementary learning losses to reduce the risk of providing erroneous supervision, leading to theoretically and experimentally demonstrated robustness against NC. SCC utilizes multiple self-refining processes with momentum correction to enlarge the receptive field for correcting correspondences, thereby alleviating error accumulation and achieving accurate and stable corrections. We carry out extensive experiments on three image-text benchmarks, i.e., Flickr30K, MS-COCO, and CC152K, to verify the superior robustness of our CRCL against synthetic and real-world noisy correspondences.", "url": "https://arxiv.org/abs/2310.17468"}, {"metadata": {"arXiv": "2310.17530", "Date": "Thu, 26 Oct 2023 16:19:19 ", "Title": "Evaluating Bias and Fairness in Gender-Neutral Pretrained Vision-and-Language Models", "Authors": ["Laura Cabello", "Emanuele Bugliarello", "Stephanie Brandl", "Desmond Elliott"], "Categories": "cs.CV cs.CL cs.LG", "Comments": ["To appear in EMNLP 2024"]}, "abstract": "Pretrained machine learning models are known to perpetuate and even amplify existing biases in data, which can result in unfair outcomes that ultimately impact user experience. Therefore, it is crucial to understand the mechanisms behind those prejudicial biases to ensure that model performance does not result in discriminatory behaviour toward certain groups or populations. In this work, we define gender bias as our case study. We quantify bias amplification in pretraining and after fine-tuning on three families of vision-and-language models. We investigate the connection, if any, between the two learning stages, and evaluate how bias amplification reflects on model performance. Overall, we find that bias amplification in pretraining and after fine-tuning are independent. We then examine the effect of continued pretraining on gender-neutral data, finding that this reduces group disparities, i.e., promotes fairness, on VQAv2 and retrieval tasks without significantly compromising task performance.", "url": "https://arxiv.org/abs/2310.17530"}, {"metadata": {"arXiv": "2310.17569", "Date": "Thu, 26 Oct 2023 16:58:01 ", "Title": "SD4Match: Learning to Prompt Stable Diffusion Model for Semantic Matching", "Authors": ["Xinghui Li", "Jingyi Lu", "Kai Han", "Victor Prisacariu"], "Categories": "cs.CV cs.LG"}, "abstract": "In this paper, we address the challenge of matching semantically similar keypoints across image pairs. Existing research indicates that the intermediate output of the UNet within the Stable Diffusion (SD) can serve as robust image feature maps for such a matching task. We demonstrate that by employing a basic prompt tuning technique, the inherent potential of Stable Diffusion can be harnessed, resulting in a significant enhancement in accuracy over previous approaches. We further introduce a novel conditional prompting module that conditions the prompt on the local details of the input image pairs, leading to a further improvement in performance. We designate our approach as SD4Match, short for Stable Diffusion for Semantic Matching. Comprehensive evaluations of SD4Match on the PF-Pascal, PF-Willow, and SPair-71k datasets show that it sets new benchmarks in accuracy across all these datasets. Particularly, SD4Match outperforms the previous state-of-the-art by a margin of 12 percentage points on the challenging SPair-71k dataset.", "url": "https://arxiv.org/abs/2310.17569"}, {"metadata": {"arXiv": "2310.17650", "Date": "Thu, 26 Oct 2023 17:59:19 ", "Title": "A Coarse-to-Fine Pseudo-Labeling (C2FPL) Framework for Unsupervised Video Anomaly Detection", "Authors": ["Anas Al-lahham", "Nurbek Tastan", "Zaigham Zaheer", "Karthik Nandakumar"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted in IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)", "2024"]}, "abstract": "Detection of anomalous events in videos is an important problem in applications such as surveillance. Video anomaly detection (VAD) is well-studied in the one-class classification (OCC) and weakly supervised (WS) settings. However, fully unsupervised (US) video anomaly detection methods, which learn a complete system without any annotation or human supervision, have not been explored in depth. This is because the lack of any ground truth annotations significantly increases the magnitude of the VAD challenge. To address this challenge, we propose a simple-but-effective two-stage pseudo-label generation framework that produces segment-level (normal/anomaly) pseudo-labels, which can be further used to train a segment-level anomaly detector in a supervised manner. The proposed coarse-to-fine pseudo-label (C2FPL) generator employs carefully-designed hierarchical divisive clustering and statistical hypothesis testing to identify anomalous video segments from a set of completely unlabeled videos. The trained anomaly detector can be directly applied on segments of an unseen test video to obtain segment-level, and subsequently, frame-level anomaly predictions. Extensive studies on two large-scale public-domain datasets, UCF-Crime and XD-Violence, demonstrate that the proposed unsupervised approach achieves superior performance compared to all existing OCC and US methods , while yielding comparable performance to the state-of-the-art WS methods.", "url": "https://arxiv.org/abs/2310.17650"}, {"metadata": {"arXiv": "2310.17531", "Date": "Thu, 26 Oct 2023 16:19:24 ", "Title": "Learning Regularized Graphon Mean-Field Games with Unknown Graphons", "Authors": ["Fengzhuo Zhang", "Vincent Y. F. Tan", "Zhaoran Wang", "Zhuoran Yang"], "Categories": "cs.GT cs.LG stat.ML"}, "abstract": "We design and analyze reinforcement learning algorithms for Graphon Mean-Field Games (GMFGs). In contrast to previous works that require the precise values of the graphons, we aim to learn the Nash Equilibrium (NE) of the regularized GMFGs when the graphons are unknown. Our contributions are threefold. First, we propose the Proximal Policy Optimization for GMFG (GMFG-PPO) algorithm and show that it converges at a rate of $O(T^{-1/3})$ after $T$ iterations with an estimation oracle, improving on a previous work by Xie et al. (ICML, 2021). Second, using kernel embedding of distributions, we design efficient algorithms to estimate the transition kernels, reward functions, and graphons from sampled agents. Convergence rates are then derived when the positions of the agents are either known or unknown. Results for the combination of the optimization algorithm GMFG-PPO and the estimation algorithm are then provided. These algorithms are the first specifically designed for learning graphons from sampled agents. Finally, the efficacy of the proposed algorithms are corroborated through simulations. These simulations demonstrate that learning the unknown graphons reduces the exploitability effectively.", "url": "https://arxiv.org/abs/2310.17531"}, {"metadata": {"arXiv": "2310.16861", "Date": "Wed, 25 Oct 2023 06:08:24 ", "Title": "General Point Model with Autoencoding and Autoregressive", "Authors": ["Zhe Li and Zhangyang Gao and Cheng Tan and Stan Z. Li and Laurence T. Yang"], "Categories": "cs.LG cs.CV"}, "abstract": "The pre-training architectures of large language models encompass various types, including autoencoding models, autoregressive models, and encoder-decoder models. We posit that any modality can potentially benefit from a large language model, as long as it undergoes vector quantization to become discrete tokens. Inspired by GLM, we propose a General Point Model (GPM) which seamlessly integrates autoencoding and autoregressive tasks in point cloud transformer. This model is versatile, allowing fine-tuning for downstream point cloud representation tasks, as well as unconditional and conditional generation tasks. GPM enhances masked prediction in autoencoding through various forms of mask padding tasks, leading to improved performance in point cloud understanding. Additionally, GPM demonstrates highly competitive results in unconditional point cloud generation tasks, even exhibiting the potential for conditional generation tasks by modifying the input's conditional information. Compared to models like Point-BERT, MaskPoint and PointMAE, our GPM achieves superior performance in point cloud understanding tasks. Furthermore, the integration of autoregressive and autoencoding within the same transformer underscores its versatility across different downstream tasks.", "url": "https://arxiv.org/abs/2310.16861"}, {"metadata": {"arXiv": "2310.16944", "Date": "Wed, 25 Oct 2023 19:25:16 ", "Title": "Zephyr: Direct Distillation of LM Alignment", "Authors": ["Lewis Tunstall", "Edward Beeching", "Nathan Lambert", "Nazneen Rajani", "Kashif Rasul", "Younes Belkada", "Shengyi Huang", "Leandro von Werra", "Cl\\'ementine Fourrier", "Nathan Habib", "Nathan Sarrazin", "Omar Sanseviero", "Alexander M. Rush", "and Thomas Wolf"], "Categories": "cs.LG cs.CL"}, "abstract": "We aim to produce a smaller language model that is aligned to user intent. Previous research has shown that applying distilled supervised fine-tuning (dSFT) on larger models significantly improves task accuracy; however, these models are unaligned, i.e. they do not respond well to natural prompts. To distill this property, we experiment with the use of preference data from AI Feedback (AIF). Starting from a dataset of outputs ranked by a teacher model, we apply distilled direct preference optimization (dDPO) to learn a chat model with significantly improved intent alignment. The approach requires only a few hours of training without any additional sampling during fine-tuning. The final result, Zephyr-7B, sets the state-of-the-art on chat benchmarks for 7B parameter models, and requires no human annotation. In particular, results on MT-Bench show that Zephyr-7B surpasses Llama2-Chat-70B, the best open-access RLHF-based model. Code, models, data, and tutorials for the system are available at https://github.com/huggingface/alignment-handbook.", "url": "https://arxiv.org/abs/2310.16944"}, {"metadata": {"arXiv": "2310.16955", "Date": "Wed, 25 Oct 2023 19:51:37 ", "Title": "Break it, Imitate it, Fix it: Robustness by Generating Human-Like Attacks", "Authors": ["Aradhana Sinha", "Ananth Balashankar", "Ahmad Beirami", "Thi Avrahami", "Jilin Chen", "Alex Beutel"], "Categories": "cs.LG"}, "abstract": "Real-world natural language processing systems need to be robust to human adversaries. Collecting examples of human adversaries for training is an effective but expensive solution. On the other hand, training on synthetic attacks with small perturbations - such as word-substitution - does not actually improve robustness to human adversaries. In this paper, we propose an adversarial training framework that uses limited human adversarial examples to generate more useful adversarial examples at scale. We demonstrate the advantages of this system on the ANLI and hate speech detection benchmark datasets - both collected via an iterative, adversarial human-and-model-in-the-loop procedure. Compared to training only on observed human attacks, also training on our synthetic adversarial examples improves model robustness to future rounds. In ANLI, we see accuracy gains on the current set of attacks (44.1%$\\,\\to\\,$50.1%) and on two future unseen rounds of human generated attacks (32.5%$\\,\\to\\,$43.4%, and 29.4%$\\,\\to\\,$40.2%). In hate speech detection, we see AUC gains on current attacks (0.76 $\\to$ 0.84) and a future round (0.77 $\\to$ 0.79). Attacks from methods that do not learn the distribution of existing human adversaries, meanwhile, degrade robustness.", "url": "https://arxiv.org/abs/2310.16955"}, {"metadata": {"arXiv": "2310.16958", "Date": "Wed, 25 Oct 2023 19:55:00 ", "Title": "Transferring a molecular foundation model for polymer property predictions", "Authors": ["Pei Zhang", "Logan Kearney", "Debsindhu Bhowmik", "Zachary Fox", "Amit K. Naskar", "John Gounley"], "Categories": "cs.LG physics.chem-ph"}, "abstract": "Transformer-based large language models have remarkable potential to accelerate design optimization for applications such as drug development and materials discovery. Self-supervised pretraining of transformer models requires large-scale datasets, which are often sparsely populated in topical areas such as polymer science. State-of-the-art approaches for polymers conduct data augmentation to generate additional samples but unavoidably incurs extra computational costs. In contrast, large-scale open-source datasets are available for small molecules and provide a potential solution to data scarcity through transfer learning. In this work, we show that using transformers pretrained on small molecules and fine-tuned on polymer properties achieve comparable accuracy to those trained on augmented polymer datasets for a series of benchmark prediction tasks.", "url": "https://arxiv.org/abs/2310.16958"}, {"metadata": {"arXiv": "2310.16959", "Date": "Wed, 25 Oct 2023 19:57:07 ", "Title": "Improving Few-shot Generalization of Safety Classifiers via Data Augmented Parameter-Efficient Fine-Tuning", "Authors": ["Ananth Balashankar", "Xiao Ma", "Aradhana Sinha", "Ahmad Beirami", "Yao Qin", "Jilin Chen", "Alex Beutel"], "Categories": "cs.LG"}, "abstract": "As large language models (LLMs) are widely adopted, new safety issues and policies emerge, to which existing safety classifiers do not generalize well. If we have only observed a few examples of violations of a new safety rule, how can we build a classifier to detect violations? In this paper, we study the novel setting of domain-generalized few-shot learning for LLM-based text safety classifiers. Unlike prior few-shot work, these new safety issues can be hard to uncover and we do not get to choose the few examples. We demonstrate that existing few-shot techniques do not perform well in this setting, and rather we propose to do parameter-efficient fine-tuning (PEFT) combined with augmenting training data based on similar examples in prior existing rules. We empirically show that our approach of similarity-based data-augmentation + prompt-tuning (DAPT) consistently outperforms baselines that either do not rely on data augmentation or on PEFT by 7-17% F1 score in the Social Chemistry moral judgement and 9-13% AUC in the Toxicity detection tasks, even when the new rule is loosely correlated with existing ones.", "url": "https://arxiv.org/abs/2310.16959"}, {"metadata": {"arXiv": "2310.16960", "Date": "Wed, 25 Oct 2023 19:58:51 ", "Title": "Privately Aligning Language Models with Reinforcement Learning", "Authors": ["Fan Wu", "Huseyin A. Inan", "Arturs Backurs", "Varun Chandrasekaran", "Janardhan Kulkarni", "Robert Sim"], "Categories": "cs.LG cs.CR"}, "abstract": "Positioned between pre-training and user deployment, aligning large language models (LLMs) through reinforcement learning (RL) has emerged as a prevailing strategy for training instruction following-models such as ChatGPT. In this work, we initiate the study of privacy-preserving alignment of LLMs through Differential Privacy (DP) in conjunction with RL. Following the influential work of Ziegler et al. (2020), we study two dominant paradigms: (i) alignment via RL without human in the loop (e.g., positive review generation) and (ii) alignment via RL from human feedback (RLHF) (e.g., summarization in a human-preferred way). We give a new DP framework to achieve alignment via RL, and prove its correctness. Our experimental results validate the effectiveness of our approach, offering competitive utility while ensuring strong privacy protections.", "url": "https://arxiv.org/abs/2310.16960"}, {"metadata": {"arXiv": "2310.16981", "Date": "Wed, 25 Oct 2023 20:32:02 ", "Title": "Reimagining Synthetic Tabular Data Generation through Data-Centric AI: A Comprehensive Benchmark", "Authors": ["Lasse Hansen", "Nabeel Seedat", "Mihaela van der Schaar", "Andrija Petrovic"], "Categories": "cs.LG", "Comments": ["Presented at NeurIPS 2023 (Datasets & Benchmarks). *Hansen & Seedat contributed equally"]}, "abstract": "Synthetic data serves as an alternative in training machine learning models, particularly when real-world data is limited or inaccessible. However, ensuring that synthetic data mirrors the complex nuances of real-world data is a challenging task. This paper addresses this issue by exploring the potential of integrating data-centric AI techniques which profile the data to guide the synthetic data generation process. Moreover, we shed light on the often ignored consequences of neglecting these data profiles during synthetic data generation -- despite seemingly high statistical fidelity. Subsequently, we propose a novel framework to evaluate the integration of data profiles to guide the creation of more representative synthetic data. In an empirical study, we evaluate the performance of five state-of-the-art models for tabular data generation on eleven distinct tabular datasets. The findings offer critical insights into the successes and limitations of current synthetic data generation techniques. Finally, we provide practical recommendations for integrating data-centric insights into the synthetic data generation process, with a specific focus on classification performance, model selection, and feature selection. This study aims to reevaluate conventional approaches to synthetic data generation and promote the application of data-centric AI techniques in improving the quality and effectiveness of synthetic data.", "url": "https://arxiv.org/abs/2310.16981"}, {"metadata": {"arXiv": "2310.16986", "Date": "Wed, 25 Oct 2023 20:38:18 ", "Title": "Probabilistic Integral Circuits", "Authors": ["Gennaro Gala", "Cassio de Campos", "Robert Peharz", "Antonio Vergari", "Erik Quaeghebeur"], "Categories": "cs.LG"}, "abstract": "Continuous latent variables (LVs) are a key ingredient of many generative models, as they allow modelling expressive mixtures with an uncountable number of components. In contrast, probabilistic circuits (PCs) are hierarchical discrete mixtures represented as computational graphs composed of input, sum and product units. Unlike continuous LV models, PCs provide tractable inference but are limited to discrete LVs with categorical (i.e. unordered) states. We bridge these model classes by introducing probabilistic integral circuits (PICs), a new language of computational graphs that extends PCs with integral units representing continuous LVs. In the first place, PICs are symbolic computational graphs and are fully tractable in simple cases where analytical integration is possible. In practice, we parameterise PICs with light-weight neural nets delivering an intractable hierarchical continuous mixture that can be approximated arbitrarily well with large PCs using numerical quadrature. On several distribution estimation benchmarks, we show that such PIC-approximating PCs systematically outperform PCs commonly learned via expectation-maximization or SGD.", "url": "https://arxiv.org/abs/2310.16986"}, {"metadata": {"arXiv": "2310.16996", "Date": "Wed, 25 Oct 2023 20:48:46 ", "Title": "Towards Continually Learning Application Performance Models", "Authors": ["Ray A. O. Sinurat", "Anurag Daram", "Haryadi S. Gunawi", "Robert B. Ross", "Sandeep Madireddy"], "Categories": "cs.LG cs.DC", "Comments": ["Presented at Workshop on Machine Learning for Systems at 36th Conference on Neural Information Processing Systems (NeurIPS 2022)"]}, "abstract": "Machine learning-based performance models are increasingly being used to build critical job scheduling and application optimization decisions. Traditionally, these models assume that data distribution does not change as more samples are collected over time. However, owing to the complexity and heterogeneity of production HPC systems, they are susceptible to hardware degradation, replacement, and/or software patches, which can lead to drift in the data distribution that can adversely affect the performance models. To this end, we develop continually learning performance models that account for the distribution drift, alleviate catastrophic forgetting, and improve generalizability. Our best model was able to retain accuracy, regardless of having to learn the new distribution of data inflicted by system changes, while demonstrating a 2x improvement in the prediction accuracy of the whole data sequence in comparison to the naive approach.", "url": "https://arxiv.org/abs/2310.16996"}, {"metadata": {"arXiv": "2310.17002", "Date": "Wed, 25 Oct 2023 20:59:48 ", "Title": "Faster Recalibration of an Online Predictor via Approachability", "Authors": ["Princewill Okoroafor", "Robert Kleinberg", "Wen Sun"], "Categories": "cs.LG", "Comments": ["23 pages"]}, "abstract": "Predictive models in ML need to be trustworthy and reliable, which often at the very least means outputting calibrated probabilities. This can be particularly difficult to guarantee in the online prediction setting when the outcome sequence can be generated adversarially. In this paper we introduce a technique using Blackwell's approachability theorem for taking an online predictive model which might not be calibrated and transforming its predictions to calibrated predictions without much increase to the loss of the original model. Our proposed algorithm achieves calibration and accuracy at a faster rate than existing techniques arXiv:1607.03594 and is the first algorithm to offer a flexible tradeoff between calibration error and accuracy in the online setting. We demonstrate this by characterizing the space of jointly achievable calibration and regret using our technique.", "url": "https://arxiv.org/abs/2310.17002"}, {"metadata": {"arXiv": "2310.17019", "Date": "Wed, 25 Oct 2023 21:46:34 ", "Title": "Conditionally Combining Robot Skills using Large Language Models", "Authors": ["K.R. Zentner", "Ryan Julian", "Brian Ichter", "Gaurav S. Sukhatme"], "Categories": "cs.LG cs.CL cs.RO"}, "abstract": "This paper combines two contributions. First, we introduce an extension of the Meta-World benchmark, which we call \"Language-World,\" which allows a large language model to operate in a simulated robotic environment using semi-structured natural language queries and scripted skills described using natural language. By using the same set of tasks as Meta-World, Language-World results can be easily compared to Meta-World results, allowing for a point of comparison between recent methods using Large Language Models (LLMs) and those using Deep Reinforcement Learning. Second, we introduce a method we call Plan Conditioned Behavioral Cloning (PCBC), that allows finetuning the behavior of high-level plans using end-to-end demonstrations. Using Language-World, we show that PCBC is able to achieve strong performance in a variety of few-shot regimes, often achieving task generalization with as little as a single demonstration. We have made Language-World available as open-source software at https://github.com/krzentner/language-world/.", "url": "https://arxiv.org/abs/2310.17019"}, {"metadata": {"arXiv": "2310.17021", "Date": "Wed, 25 Oct 2023 21:58:52 ", "Title": "Streaming Factor Trajectory Learning for Temporal Tensor Decomposition", "Authors": ["Shikai Fang", "Xin Yu", "Shibo Li", "Zheng Wang", "Robert Kirby", "Shandian Zhe"], "Categories": "cs.LG"}, "abstract": "Practical tensor data is often along with time information. Most existing temporal decomposition approaches estimate a set of fixed factors for the objects in each tensor mode, and hence cannot capture the temporal evolution of the objects' representation. More important, we lack an effective approach to capture such evolution from streaming data, which is common in real-world applications. To address these issues, we propose Streaming Factor Trajectory Learning (SFTL) for temporal tensor decomposition. We use Gaussian processes (GPs) to model the trajectory of factors so as to flexibly estimate their temporal evolution. To address the computational challenges in handling streaming data, we convert the GPs into a state-space prior by constructing an equivalent stochastic differential equation (SDE). We develop an efficient online filtering algorithm to estimate a decoupled running posterior of the involved factor states upon receiving new data. The decoupled estimation enables us to conduct standard Rauch-Tung-Striebel smoothing to compute the full posterior of all the trajectories in parallel, without the need for revisiting any previous data. We have shown the advantage of SFTL in both synthetic tasks and real-world applications.", "url": "https://arxiv.org/abs/2310.17021"}, {"metadata": {"arXiv": "2310.17044", "Date": "Wed, 25 Oct 2023 22:50:09 ", "Title": "Learning to Rank for Active Learning via Multi-Task Bilevel Optimization", "Authors": ["Zixin Ding", "Si Chen", "Ruoxi Jia", "Yuxin Chen"], "Categories": "cs.LG"}, "abstract": "Active learning is a promising paradigm to reduce the labeling cost by strategically requesting labels to improve model performance. However, existing active learning methods often rely on expensive acquisition function to compute, extensive modeling retraining and multiple rounds of interaction with annotators. To address these limitations, we propose a novel approach for active learning, which aims to select batches of unlabeled instances through a learned surrogate model for data acquisition. A key challenge in this approach is developing an acquisition function that generalizes well, as the history of data, which forms part of the utility function's input, grows over time. Our novel algorithmic contribution is a bilevel multi-task bilevel optimization framework that predicts the relative utility -- measured by the validation accuracy -- of different training sets, and ensures the learned acquisition function generalizes effectively. For cases where validation accuracy is expensive to evaluate, we introduce efficient interpolation-based surrogate models to estimate the utility function, reducing the evaluation cost. We demonstrate the performance of our approach through extensive experiments on standard active classification benchmarks. By employing our learned utility function, we show significant improvements over traditional techniques, paving the way for more efficient and effective utility maximization in active learning applications.", "url": "https://arxiv.org/abs/2310.17044"}, {"metadata": {"arXiv": "2310.17074", "Date": "Thu, 26 Oct 2023 00:35:40 ", "Title": "Benign Oscillation of Stochastic Gradient Descent with Large Learning Rates", "Authors": ["Miao Lu", "Beining Wu", "Xiaodong Yang", "Difan Zou"], "Categories": "cs.LG math.OC stat.ML", "Comments": ["63 pages", "10 figures"]}, "abstract": "In this work, we theoretically investigate the generalization properties of neural networks (NN) trained by stochastic gradient descent (SGD) algorithm with large learning rates. Under such a training regime, our finding is that, the oscillation of the NN weights caused by the large learning rate SGD training turns out to be beneficial to the generalization of the NN, which potentially improves over the same NN trained by SGD with small learning rates that converges more smoothly. In view of this finding, we call such a phenomenon \"benign oscillation\". Our theory towards demystifying such a phenomenon builds upon the feature learning perspective of deep learning. Specifically, we consider a feature-noise data generation model that consists of (i) weak features which have a small $\\ell_2$-norm and appear in each data point; (ii) strong features which have a larger $\\ell_2$-norm but only appear in a certain fraction of all data points; and (iii) noise. We prove that NNs trained by oscillating SGD with a large learning rate can effectively learn the weak features in the presence of those strong features. In contrast, NNs trained by SGD with a small learning rate can only learn the strong features but makes little progress in learning the weak features. Consequently, when it comes to the new testing data which consist of only weak features, the NN trained by oscillating SGD with a large learning rate could still make correct predictions consistently, while the NN trained by small learning rate SGD fails. Our theory sheds light on how large learning rate training benefits the generalization of NNs. Experimental results demonstrate our finding on \"benign oscillation\".", "url": "https://arxiv.org/abs/2310.17074"}, {"metadata": {"arXiv": "2310.17087", "Date": "Thu, 26 Oct 2023 01:11:17 ", "Title": "Good regularity creates large learning rate implicit biases: edge of stability, balancing, and catapult", "Authors": ["Yuqing Wang", "Zhenghao Xu", "Tuo Zhao", "Molei Tao"], "Categories": "cs.LG math.DS math.OC stat.ML"}, "abstract": "Large learning rates, when applied to gradient descent for nonconvex optimization, yield various implicit biases including the edge of stability (Cohen et al., 2021), balancing (Wang et al., 2022), and catapult (Lewkowycz et al., 2020). These phenomena cannot be well explained by classical optimization theory. Though significant theoretical progress has been made in understanding these implicit biases, it remains unclear for which objective functions would they occur. This paper provides an initial step in answering this question, namely that these implicit biases are in fact various tips of the same iceberg. They occur when the objective function of optimization has some good regularity, which, in combination with a provable preference of large learning rate gradient descent for moving toward flatter regions, results in these nontrivial dynamical phenomena. To establish this result, we develop a new global convergence theory under large learning rates, for a family of nonconvex functions without globally Lipschitz continuous gradient, which was typically assumed in existing convergence analysis. A byproduct is the first non-asymptotic convergence rate bound for large-learning-rate gradient descent optimization of nonconvex functions. We also validate our theory with experiments on neural networks, where different losses, activation functions, and batch normalization all can significantly affect regularity and lead to very different training dynamics.", "url": "https://arxiv.org/abs/2310.17087"}, {"metadata": {"arXiv": "2310.17100", "Date": "Thu, 26 Oct 2023 01:45:20 ", "Title": "Network Design through Graph Neural Networks: Identifying Challenges and Improving Performance", "Authors": ["Donald Loveland and Rajmonda Caceres"], "Categories": "cs.LG"}, "abstract": "Graph Neural Network (GNN) research has produced strategies to modify a graph's edges using gradients from a trained GNN, with the goal of network design. However, the factors which govern gradient-based editing are understudied, obscuring why edges are chosen and if edits are grounded in an edge's importance. Thus, we begin by analyzing the gradient computation in previous works, elucidating the factors that influence edits and highlighting the potential over-reliance on structural properties. Specifically, we find that edges can achieve high gradients due to structural biases, rather than importance, leading to erroneous edits when the factors are unrelated to the design task. To improve editing, we propose ORE, an iterative editing method that (a) edits the highest scoring edges and (b) re-embeds the edited graph to refresh gradients, leading to less biased edge choices. We empirically study ORE through a set of proposed design tasks, each with an external validation method, demonstrating that ORE improves upon previous methods by up to 50%.", "url": "https://arxiv.org/abs/2310.17100"}, {"metadata": {"arXiv": "2310.17110", "Date": "Thu, 26 Oct 2023 02:37:43 ", "Title": "LLM4DyG: Can Large Language Models Solve Problems on Dynamic Graphs?", "Authors": ["Zeyang Zhang", "Xin Wang", "Ziwei Zhang", "Haoyang Li", "Yijian Qin", "Simin Wu", "Wenwu Zhu"], "Categories": "cs.LG"}, "abstract": "In an era marked by the increasing adoption of Large Language Models (LLMs) for various tasks, there is a growing focus on exploring LLMs' capabilities in handling web data, particularly graph data. Dynamic graphs, which capture temporal network evolution patterns, are ubiquitous in real-world web data. Evaluating LLMs' competence in understanding spatial-temporal information on dynamic graphs is essential for their adoption in web applications, which remains unexplored in the literature. In this paper, we bridge the gap via proposing to evaluate LLMs' spatial-temporal understanding abilities on dynamic graphs, to the best of our knowledge, for the first time. Specifically, we propose the LLM4DyG benchmark, which includes nine specially designed tasks considering the capability evaluation of LLMs from both temporal and spatial dimensions. Then, we conduct extensive experiments to analyze the impacts of different data generators, data statistics, prompting techniques, and LLMs on the model performance. Finally, we propose Disentangled Spatial-Temporal Thoughts (DST2) for LLMs on dynamic graphs to enhance LLMs' spatial-temporal understanding abilities. Our main observations are: 1) LLMs have preliminary spatial-temporal understanding abilities on dynamic graphs, 2) Dynamic graph tasks show increasing difficulties for LLMs as the graph size and density increase, while not sensitive to the time span and data generation mechanism, 3) the proposed DST2 prompting method can help to improve LLMs' spatial-temporal understanding abilities on dynamic graphs for most tasks. The data and codes will be open-sourced at publication time.", "url": "https://arxiv.org/abs/2310.17110"}, {"metadata": {"arXiv": "2310.17137", "Date": "Thu, 26 Oct 2023 04:20:36 ", "Title": "Large-Scale Gaussian Processes via Alternating Projection", "Authors": ["Kaiwen Wu", "Jonathan Wenger", "Haydn Jones", "Geoff Pleiss", "Jacob R. Gardner"], "Categories": "cs.LG stat.ML"}, "abstract": "Gaussian process (GP) hyperparameter optimization requires repeatedly solving linear systems with $n \\times n$ kernel matrices. To address the prohibitive $\\mathcal{O}(n^3)$ time complexity, recent work has employed fast iterative numerical methods, like conjugate gradients (CG). However, as datasets increase in magnitude, the corresponding kernel matrices become increasingly ill-conditioned and still require $\\mathcal{O}(n^2)$ space without partitioning. Thus, while CG increases the size of datasets GPs can be trained on, modern datasets reach scales beyond its applicability. In this work, we propose an iterative method which only accesses subblocks of the kernel matrix, effectively enabling \\emph{mini-batching}. Our algorithm, based on alternating projection, has $\\mathcal{O}(n)$ per-iteration time and space complexity, solving many of the practical challenges of scaling GPs to very large datasets. Theoretically, we prove our method enjoys linear convergence and empirically we demonstrate its robustness to ill-conditioning. On large-scale benchmark datasets up to four million datapoints our approach accelerates training by a factor of 2$\\times$ to 27$\\times$ compared to CG.", "url": "https://arxiv.org/abs/2310.17137"}, {"metadata": {"arXiv": "2310.17139", "Date": "Thu, 26 Oct 2023 04:20:55 ", "Title": "Understanding and Addressing the Pitfalls of Bisimulation-based Representations in Offline Reinforcement Learning", "Authors": ["Hongyu Zang", "Xin Li", "Leiji Zhang", "Yang Liu", "Baigui Sun", "Riashat Islam", "Remi Tachet des Combes", "Romain Laroche"], "Categories": "cs.LG", "Comments": ["NeurIPS 2023"]}, "abstract": "While bisimulation-based approaches hold promise for learning robust state representations for Reinforcement Learning (RL) tasks, their efficacy in offline RL tasks has not been up to par. In some instances, their performance has even significantly underperformed alternative methods. We aim to understand why bisimulation methods succeed in online settings, but falter in offline tasks. Our analysis reveals that missing transitions in the dataset are particularly harmful to the bisimulation principle, leading to ineffective estimation. We also shed light on the critical role of reward scaling in bounding the scale of bisimulation measurements and of the value error they induce. Based on these findings, we propose to apply the expectile operator for representation learning to our offline RL setting, which helps to prevent overfitting to incomplete data. Meanwhile, by introducing an appropriate reward scaling strategy, we avoid the risk of feature collapse in representation space. We implement these recommendations on two state-of-the-art bisimulation-based algorithms, MICo and SimSR, and demonstrate performance gains on two benchmark suites: D4RL and Visual D4RL. Codes are provided at \\url{https://github.com/zanghyu/Offline_Bisimulation}.", "url": "https://arxiv.org/abs/2310.17139"}, {"metadata": {"arXiv": "2310.17153", "Date": "Thu, 26 Oct 2023 04:52:28 ", "Title": "Hierarchical Semi-Implicit Variational Inference with Application to Diffusion Model Acceleration", "Authors": ["Longlin Yu", "Tianyu Xie", "Yu Zhu", "Tong Yang", "Xiangyu Zhang", "Cheng Zhang"], "Categories": "cs.LG stat.ME", "Comments": ["25 pages", "13 figures", "NeurIPS 2023"]}, "abstract": "Semi-implicit variational inference (SIVI) has been introduced to expand the analytical variational families by defining expressive semi-implicit distributions in a hierarchical manner. However, the single-layer architecture commonly used in current SIVI methods can be insufficient when the target posterior has complicated structures. In this paper, we propose hierarchical semi-implicit variational inference, called HSIVI, which generalizes SIVI to allow more expressive multi-layer construction of semi-implicit distributions. By introducing auxiliary distributions that interpolate between a simple base distribution and the target distribution, the conditional layers can be trained by progressively matching these auxiliary distributions one layer after another. Moreover, given pre-trained score networks, HSIVI can be used to accelerate the sampling process of diffusion models with the score matching objective. We show that HSIVI significantly enhances the expressiveness of SIVI on several Bayesian inference problems with complicated target distributions. When used for diffusion model acceleration, we show that HSIVI can produce high quality samples comparable to or better than the existing fast diffusion model based samplers with a small number of function evaluations on various datasets.", "url": "https://arxiv.org/abs/2310.17153"}, {"metadata": {"arXiv": "2310.17157", "Date": "Thu, 26 Oct 2023 05:01:09 ", "Title": "Deja Vu: Contextual Sparsity for Efficient LLMs at Inference Time", "Authors": ["Zichang Liu", "Jue Wang", "Tri Dao", "Tianyi Zhou", "Binhang Yuan", "Zhao Song", "Anshumali Shrivastava", "Ce Zhang", "Yuandong Tian", "Christopher Re", "Beidi Chen"], "Categories": "cs.LG", "Journal-ref": "Proceedings of the 40th International Conference on Machine Learning, 2023, 919"}, "abstract": "Large language models (LLMs) with hundreds of billions of parameters have sparked a new wave of exciting AI applications. However, they are computationally expensive at inference time. Sparsity is a natural approach to reduce this cost, but existing methods either require costly retraining, have to forgo LLM's in-context learning ability, or do not yield wall-clock time speedup on modern hardware. We hypothesize that contextual sparsity, which are small, input-dependent sets of attention heads and MLP parameters that yield approximately the same output as the dense model for a given input, can address these issues. We show that contextual sparsity exists, that it can be accurately predicted, and that we can exploit it to speed up LLM inference in wall-clock time without compromising LLM's quality or in-context learning ability. Based on these insights, we propose DejaVu, a system that uses a low-cost algorithm to predict contextual sparsity on the fly given inputs to each layer, along with an asynchronous and hardware-aware implementation that speeds up LLM inference. We validate that DejaVu can reduce the inference latency of OPT-175B by over 2X compared to the state-of-the-art FasterTransformer, and over 6X compared to the widely used Hugging Face implementation, without compromising model quality. The code is available at https://github.com/FMInference/DejaVu.", "url": "https://arxiv.org/abs/2310.17157"}, {"metadata": {"arXiv": "2310.17159", "Date": "Thu, 26 Oct 2023 05:10:57 ", "Title": "MaxEnt Loss: Constrained Maximum Entropy for Calibration under Out-of-Distribution Shift", "Authors": ["Dexter Neo", "Stefan Winkler", "Tsuhan Chen"], "Categories": "cs.LG"}, "abstract": "We present a new loss function that addresses the out-of-distribution (OOD) calibration problem. While many objective functions have been proposed to effectively calibrate models in-distribution, our findings show that they do not always fare well OOD. Based on the Principle of Maximum Entropy, we incorporate helpful statistical constraints observed during training, delivering better model calibration without sacrificing accuracy. We provide theoretical analysis and show empirically that our method works well in practice, achieving state-of-the-art calibration on both synthetic and real-world benchmarks.", "url": "https://arxiv.org/abs/2310.17159"}, {"metadata": {"arXiv": "2310.17168", "Date": "Thu, 26 Oct 2023 05:49:13 ", "Title": "Learning an Inventory Control Policy with General Inventory Arrival Dynamics", "Authors": ["Sohrab Andaz", "Carson Eisenach", "Dhruv Madeka", "Kari Torkkola", "Randy Jia", "Dean Foster", "Sham Kakade"], "Categories": "cs.LG stat.ML"}, "abstract": "In this paper we address the problem of learning and backtesting inventory control policies in the presence of general arrival dynamics -- which we term as a quantity-over-time arrivals model (QOT). We also allow for order quantities to be modified as a post-processing step to meet vendor constraints such as order minimum and batch size constraints -- a common practice in real supply chains. To the best of our knowledge this is the first work to handle either arbitrary arrival dynamics or an arbitrary downstream post-processing of order quantities. Building upon recent work (Madeka et al., 2022) we similarly formulate the periodic review inventory control problem as an exogenous decision process, where most of the state is outside the control of the agent. Madeka et al. (2022) show how to construct a simulator that replays historic data to solve this class of problem. In our case, we incorporate a deep generative model for the arrivals process as part of the history replay. By formulating the problem as an exogenous decision process, we can apply results from Madeka et al. (2022) to obtain a reduction to supervised learning. Finally, we show via simulation studies that this approach yields statistically significant improvements in profitability over production baselines. Using data from an ongoing real-world A/B test, we show that Gen-QOT generalizes well to off-policy data.", "url": "https://arxiv.org/abs/2310.17168"}, {"metadata": {"arXiv": "2310.17173", "Date": "Thu, 26 Oct 2023 05:54:51 ", "Title": "DSAC-C: Constrained Maximum Entropy for Robust Discrete Soft-Actor Critic", "Authors": ["Dexter Neo", "Tsuhan Chen"], "Categories": "cs.LG"}, "abstract": "We present a novel extension to the family of Soft Actor-Critic (SAC) algorithms. We argue that based on the Maximum Entropy Principle, discrete SAC can be further improved via additional statistical constraints derived from a surrogate critic policy. Furthermore, our findings suggests that these constraints provide an added robustness against potential domain shifts, which are essential for safe deployment of reinforcement learning agents in the real-world. We provide theoretical analysis and show empirical results on low data regimes for both in-distribution and out-of-distribution variants of Atari 2600 games.", "url": "https://arxiv.org/abs/2310.17173"}, {"metadata": {"arXiv": "2310.17185", "Date": "Thu, 26 Oct 2023 06:35:08 ", "Title": "Adaptive important sampling for Deep Ritz", "Authors": ["Xiaoliang Wan and Tao Zhou and Yuancheng Zhou"], "Categories": "cs.LG"}, "abstract": "We introduce an adaptive sampling method for the Deep Ritz method aimed at solving partial differential equations (PDEs). Two deep neural networks are used. One network is employed to approximate the solution of PDEs, while the other one is a deep generative model used to generate new collocation points to refine the training set. The adaptive sampling procedure consists of two main steps. The first step is solving the PDEs using the Deep Ritz method by minimizing an associated variational loss discretized by the collocation points in the training set. The second step involves generating a new training set, which is then used in subsequent computations to further improve the accuracy of the current approximate solution. We treat the integrand in the variational loss as an unnormalized probability density function (PDF) and approximate it using a deep generative model called bounded KRnet. The new samples and their associated PDF values are obtained from the bounded KRnet. With these new samples and their associated PDF values, the variational loss can be approximated more accurately by importance sampling. Compared to the original Deep Ritz method, the proposed adaptive method improves accuracy, especially for problems characterized by low regularity and high dimensionality. We demonstrate the effectiveness of our new method through a series of numerical experiments.", "url": "https://arxiv.org/abs/2310.17185"}, {"metadata": {"arXiv": "2310.17202", "Date": "Thu, 26 Oct 2023 07:37:44 ", "Title": "miditok: A Python package for MIDI file tokenization", "Authors": ["Nathan Fradet", "Jean-Pierre Briot", "Fabien Chhel", "Amal El Fallah Seghrouchni", "Nicolas Gutowski"], "Categories": "cs.LG", "Comments": ["Updated and comprehensive report. Original ISMIR 2021 document at https://archives.ismir.net/ismir2021/latebreaking/000005.pdf"]}, "abstract": "Recent progress in natural language processing has been adapted to the symbolic music modality. Language models, such as Transformers, have been used with symbolic music for a variety of tasks among which music generation, modeling or transcription, with state-of-the-art performances. These models are beginning to be used in production products. To encode and decode music for the backbone model, they need to rely on tokenizers, whose role is to serialize music into sequences of distinct elements called tokens. MidiTok is an open-source library allowing to tokenize symbolic music with great flexibility and extended features. It features the most popular music tokenizations, under a unified API. It is made to be easily used and extensible for everyone.", "url": "https://arxiv.org/abs/2310.17202"}, {"metadata": {"arXiv": "2310.17230", "Date": "Thu, 26 Oct 2023 08:28:48 ", "Title": "Codebook Features: Sparse and Discrete Interpretability for Neural Networks", "Authors": ["Alex Tamkin", "Mohammad Taufeeque", "Noah D. Goodman"], "Categories": "cs.LG cs.CL"}, "abstract": "Understanding neural networks is challenging in part because of the dense, continuous nature of their hidden states. We explore whether we can train neural networks to have hidden states that are sparse, discrete, and more interpretable by quantizing their continuous features into what we call codebook features. Codebook features are produced by finetuning neural networks with vector quantization bottlenecks at each layer, producing a network whose hidden features are the sum of a small number of discrete vector codes chosen from a larger codebook. Surprisingly, we find that neural networks can operate under this extreme bottleneck with only modest degradation in performance. This sparse, discrete bottleneck also provides an intuitive way of controlling neural network behavior: first, find codes that activate when the desired behavior is present, then activate those same codes during generation to elicit that behavior. We validate our approach by training codebook Transformers on several different datasets. First, we explore a finite state machine dataset with far more hidden states than neurons. In this setting, our approach overcomes the superposition problem by assigning states to distinct codes, and we find that we can make the neural network behave as if it is in a different state by activating the code for that state. Second, we train Transformer language models with up to 410M parameters on two natural language datasets. We identify codes in these models representing diverse, disentangled concepts (ranging from negative emotions to months of the year) and find that we can guide the model to generate different topics by activating the appropriate codes during inference. Overall, codebook features appear to be a promising unit of analysis and control for neural networks and interpretability. Our codebase and models are open-sourced at https://github.com/taufeeque9/codebook-features.", "url": "https://arxiv.org/abs/2310.17230"}, {"metadata": {"arXiv": "2310.17247", "Date": "Thu, 26 Oct 2023 08:47:42 ", "Title": "Grokking Beyond Neural Networks: An Empirical Exploration with Model Complexity", "Authors": ["Jack Miller", "Charles O'Neill", "Thang Bui"], "Categories": "cs.LG stat.ML"}, "abstract": "In some settings neural networks exhibit a phenomenon known as grokking, where they achieve perfect or near-perfect accuracy on the validation set long after the same performance has been achieved on the training set. In this paper, we discover that grokking is not limited to neural networks but occurs in other settings such as Gaussian process (GP) classification, GP regression and linear regression. We also uncover a mechanism by which to induce grokking on algorithmic datasets via the addition of dimensions containing spurious information. The presence of the phenomenon in non-neural architectures provides evidence that grokking is not specific to SGD or weight norm regularisation. Instead, grokking may be possible in any setting where solution search is guided by complexity and error. Based on this insight and further trends we see in the training trajectories of a Bayesian neural network (BNN) and GP regression model, we make progress towards a more general theory of grokking. Specifically, we hypothesise that the phenomenon is governed by the accessibility of certain regions in the error and complexity landscapes.", "url": "https://arxiv.org/abs/2310.17247"}, {"metadata": {"arXiv": "2310.17256", "Date": "Thu, 26 Oct 2023 09:13:15 ", "Title": "fairret: a Framework for Differentiable Fairness Regularization Terms", "Authors": ["Maarten Buyl", "MaryBeth Defrance", "Tijl De Bie"], "Categories": "cs.LG"}, "abstract": "Current tools for machine learning fairness only admit a limited range of fairness definitions and have seen little integration with automatic differentiation libraries, despite the central role these libraries play in modern machine learning pipelines. We introduce a framework of fairness regularization terms (fairrets) which quantify bias as modular objectives that are easily integrated in automatic differentiation pipelines. By employing a general definition of fairness in terms of linear-fractional statistics, a wide class of fairrets can be computed efficiently. Experiments show the behavior of their gradients and their utility in enforcing fairness with minimal loss of predictive power compared to baselines. Our contribution includes a PyTorch implementation of the fairret framework.", "url": "https://arxiv.org/abs/2310.17256"}, {"metadata": {"arXiv": "2310.17273", "Date": "Thu, 26 Oct 2023 09:50:31 ", "Title": "Looping in the Human: Collaborative and Explainable Bayesian Optimization", "Authors": ["Masaki Adachi", "Brady Planden", "David A. Howey", "Krikamol Maundet", "Michael A. Osborne", "Siu Lun Chau"], "Categories": "cs.LG cs.HC stat.ML", "Comments": ["22 pages", "9 figures"], "MSC-class": "62C10, 62F15"}, "abstract": "Like many optimizers, Bayesian optimization often falls short of gaining user trust due to opacity. While attempts have been made to develop human-centric optimizers, they typically assume user knowledge is well-specified and error-free, employing users mainly as supervisors of the optimization process. We relax these assumptions and propose a more balanced human-AI partnership with our Collaborative and Explainable Bayesian Optimization (CoExBO) framework. Instead of explicitly requiring a user to provide a knowledge model, CoExBO employs preference learning to seamlessly integrate human insights into the optimization, resulting in algorithmic suggestions that resonate with user preference. CoExBO explains its candidate selection every iteration to foster trust, empowering users with a clearer grasp of the optimization. Furthermore, CoExBO offers a no-harm guarantee, allowing users to make mistakes; even with extreme adversarial interventions, the algorithm converges asymptotically to a vanilla Bayesian optimization. We validate CoExBO's efficacy through human-AI teaming experiments in lithium-ion battery design, highlighting substantial improvements over conventional methods.", "url": "https://arxiv.org/abs/2310.17273"}, {"metadata": {"arXiv": "2310.17332", "Date": "Thu, 26 Oct 2023 11:55:30 ", "Title": "On Forecast Stability", "Authors": ["Rakshitha Godahewa", "Christoph Bergmeir", "Zeynep Erkin Baz", "Chengjun Zhu", "Zhangdi Song", "Salvador Garc\\'ia", "Dario Benavides"], "Categories": "cs.LG"}, "abstract": "Forecasts are typically not produced in a vacuum but in a business context, where forecasts are generated on a regular basis and interact with each other. For decisions, it may be important that forecasts do not change arbitrarily, and are stable in some sense. However, this area has received only limited attention in the forecasting literature. In this paper, we explore two types of forecast stability that we call vertical stability and horizontal stability. The existing works in the literature are only applicable to certain base models and extending these frameworks to be compatible with any base model is not straightforward. Furthermore, these frameworks can only stabilise the forecasts vertically. To fill this gap, we propose a simple linear-interpolation-based approach that is applicable to stabilise the forecasts provided by any base model vertically and horizontally. The approach can produce both accurate and stable forecasts. Using N-BEATS, Pooled Regression and LightGBM as the base models, in our evaluation on four publicly available datasets, the proposed framework is able to achieve significantly higher stability and/or accuracy compared to a set of benchmarks including a state-of-the-art forecast stabilisation method across three error metrics and six stability metrics.", "url": "https://arxiv.org/abs/2310.17332"}, {"metadata": {"arXiv": "2310.17335", "Date": "Thu, 26 Oct 2023 12:01:47 ", "Title": "A multi-artifact EEG denoising by frequency-based deep learning", "Authors": ["Matteo Gabardi", "Aurora Saibene", "Francesca Gasparini", "Daniele Rizzo", "Fabio Antonio Stella"], "Categories": "cs.LG eess.SP", "Comments": ["Accepted at the Italian Workshop on Artificial Intelligence for Human-Machine Interaction (AIxHMI 2023)", "November 06", "2023", "Rome", "Italy"]}, "abstract": "Electroencephalographic (EEG) signals are fundamental to neuroscience research and clinical applications such as brain-computer interfaces and neurological disorder diagnosis. These signals are typically a combination of neurological activity and noise, originating from various sources, including physiological artifacts like ocular and muscular movements. Under this setting, we tackle the challenge of distinguishing neurological activity from noise-related sources. We develop a novel EEG denoising model that operates in the frequency domain, leveraging prior knowledge about noise spectral features to adaptively compute optimal convolutional filters for noise separation. The model is trained to learn an empirical relationship connecting the spectral characteristics of noise and noisy signal to a non-linear transformation which allows signal denoising. Performance evaluation on the EEGdenoiseNet dataset shows that the proposed model achieves optimal results according to both temporal and spectral metrics. The model is found to remove physiological artifacts from input EEG data, thus achieving effective EEG denoising. Indeed, the model performance either matches or outperforms that achieved by benchmark models, proving to effectively remove both muscle and ocular artifacts without the need to perform any training on the particular type of artifact.", "url": "https://arxiv.org/abs/2310.17335"}, {"metadata": {"arXiv": "2310.17341", "Date": "Thu, 26 Oct 2023 12:15:56 ", "Title": "De-novo Chemical Reaction Generation by Means of Temporarily Convolutional Neural Networks", "Authors": ["Andrei Buin", "Hung Yi Chiang", "S. Andrew Gadsden", "Faraz A. Alderson"], "Categories": "cs.LG"}, "abstract": "We present here a combination of two networks, Recurrent Neural Networks (RNN) and Temporarily Convolutional Neural Networks (TCN) in de novo reaction generation using the novel Reaction Smiles-like representation of reactions (CGRSmiles) with atom mapping directly incorporated. Recurrent Neural Networks are known for their autoregressive properties and are frequently used in language modelling with direct application to SMILES generation. The relatively novel TCNs possess similar properties with wide receptive field while obeying the causality required for natural language processing (NLP). The combination of both latent representations expressed through TCN and RNN results in an overall better performance compared to RNN alone. Additionally, it is shown that different fine-tuning protocols have a profound impact on generative scope of the model when applied on a dataset of interest via transfer learning.", "url": "https://arxiv.org/abs/2310.17341"}, {"metadata": {"arXiv": "2310.17355", "Date": "Thu, 26 Oct 2023 12:44:33 ", "Title": "Exploring the Trie of Rules: a fast data structure for the representation of association rules", "Authors": ["Mikhail Kudriavtsev", "Dr Marija Bezbradica", "Dr Andrew McCarren"], "Categories": "cs.LG", "Comments": ["12 pages", "13 figures", "preprint of journal article"], "ACM-class": "I.2.4; H.3.3; E.1"}, "abstract": "Association rule mining techniques can generate a large volume of sequential data when implemented on transactional databases. Extracting insights from a large set of association rules has been found to be a challenging process. When examining a ruleset, the fundamental question is how to summarise and represent meaningful mined knowledge efficiently. Many algorithms and strategies have been developed to address issue of knowledge extraction; however, the effectiveness of this process can be limited by the data structures. A better data structure can sufficiently affect the speed of the knowledge extraction process. This paper proposes a novel data structure, called the Trie of rules, for storing a ruleset that is generated by association rule mining. The resulting data structure is a prefix-tree graph structure made of pre-mined rules. This graph stores the rules as paths within the prefix-tree in a way that similar rules overlay each other. Each node in the tree represents a rule where a consequent is this node, and an antecedent is a path from this node to the root of the tree. The evaluation showed that the proposed representation technique is promising. It compresses a ruleset with almost no data loss and benefits in terms of time for basic operations such as searching for a specific rule and sorting, which is the base for many knowledge discovery methods. Moreover, our method demonstrated a significant improvement in traversing time, achieving an 8-fold increase compared to traditional data structures.", "url": "https://arxiv.org/abs/2310.17355"}, {"metadata": {"arXiv": "2310.17360", "Date": "Thu, 26 Oct 2023 12:48:43 ", "Title": "Towards Unifying Diffusion Models for Probabilistic Spatio-Temporal Graph Learning", "Authors": ["Junfeng Hu", "Xu Liu", "Zhencheng Fan", "Yuxuan Liang", "Roger Zimmermann"], "Categories": "cs.LG"}, "abstract": "Spatio-temporal graph learning is a fundamental problem in the Web of Things era, which enables a plethora of Web applications such as smart cities, human mobility and climate analysis. Existing approaches tackle different learning tasks independently, tailoring their models to unique task characteristics. These methods, however, fall short of modeling intrinsic uncertainties in the spatio-temporal data. Meanwhile, their specialized designs limit their universality as general spatio-temporal learning solutions. In this paper, we propose to model the learning tasks in a unified perspective, viewing them as predictions based on conditional information with shared spatio-temporal patterns. Based on this proposal, we introduce Unified Spatio-Temporal Diffusion Models (USTD) to address the tasks uniformly within the uncertainty-aware diffusion framework. USTD is holistically designed, comprising a shared spatio-temporal encoder and attention-based denoising networks that are task-specific. The shared encoder, optimized by a pre-training strategy, effectively captures conditional spatio-temporal patterns. The denoising networks, utilizing both cross- and self-attention, integrate conditional dependencies and generate predictions. Opting for forecasting and kriging as downstream tasks, we design Gated Attention (SGA) and Temporal Gated Attention (TGA) for each task, with different emphases on the spatial and temporal dimensions, respectively. By combining the advantages of deterministic encoders and probabilistic diffusion models, USTD achieves state-of-the-art performances compared to deterministic and probabilistic baselines in both tasks, while also providing valuable uncertainty estimates.", "url": "https://arxiv.org/abs/2310.17360"}, {"metadata": {"arXiv": "2310.17383", "Date": "Thu, 26 Oct 2023 13:27:23 ", "Title": "On the recognition of the game type based on physiological signals and eye tracking", "Authors": ["{\\L}ukasz Czekaj and {\\L}ukasz Radzinski and Mateusz Kolimaga and Jakub Domaszewicz and Robert Kit{\\l}owski and Mariusz Szwoch and W{\\l}odzis{\\l}aw Duch"], "Categories": "cs.LG", "Comments": ["5 pages", "3 figures", "extended version of ESM paper"], "Journal-ref": "In: Modelling and Simulation 2023. The European Simulation and Modelling Conference 2023 / Rob Vingerhoeds, Pierre de Saqui-Sannes, Geril Philippe (eds.), 2023, EUROSIS-ETI, pp.235-238, ISBN 978-9-492-859-28-0"}, "abstract": "Automated interpretation of signals yields many impressive applications from the area of affective computing and human activity recognition (HAR). In this paper we ask the question about possibility of cognitive activity recognition on the base of particular set of signals. We use recognition of the game played by the participant as a playground for exploration of the problem. We build classifier of three different games (Space Invaders, Tetris, Tower Defence) and inter-game pause. We validate classifier in the player-independent and player-dependent scenario. We discuss the improvement in the player-dependent scenario in the context of biometric person recognition. On the base of the results obtained in game classification, we consider potential applications in smart surveillance and quantified self.", "url": "https://arxiv.org/abs/2310.17383"}, {"metadata": {"arXiv": "2310.17385", "Date": "Thu, 26 Oct 2023 13:32:49 ", "Title": "Multitask Online Learning: Listen to the Neighborhood Buzz", "Authors": ["Juliette Achddou", "Nicol\\`o Cesa-Bianchi", "Pierre Laforgue"], "Categories": "cs.LG"}, "abstract": "We study multitask online learning in a setting where agents can only exchange information with their neighbors on an arbitrary communication network. We introduce $\\texttt{MT-CO}_2\\texttt{OL}$, a decentralized algorithm for this setting whose regret depends on the interplay between the task similarities and the network structure. Our analysis shows that the regret of $\\texttt{MT-CO}_2\\texttt{OL}$ is never worse (up to constants) than the bound obtained when agents do not share information. On the other hand, our bounds significantly improve when neighboring agents operate on similar tasks. In addition, we prove that our algorithm can be made differentially private with a negligible impact on the regret when the losses are linear. Finally, we provide experimental support for our theory.", "url": "https://arxiv.org/abs/2310.17385"}, {"metadata": {"arXiv": "2310.17394", "Date": "Thu, 26 Oct 2023 13:46:18 ", "Title": "Enhancing Graph Neural Networks with Structure-Based Prompt", "Authors": ["Qingqing Ge", "Zeyuan Zhao", "Yiding Liu", "Anfeng Cheng", "Xiang Li", "Shuaiqiang Wang and Dawei Yin"], "Categories": "cs.LG"}, "abstract": "Graph Neural Networks (GNNs) are powerful in learning semantics of graph data. Recently, a new paradigm \"pre-train, prompt\" has shown promising results in adapting GNNs to various tasks with less supervised data. The success of such paradigm can be attributed to the more consistent objectives of pre-training and task-oriented prompt tuning, where the pre-trained knowledge can be effectively transferred to downstream tasks. However, an overlooked issue of existing studies is that the structure information of graph is usually exploited during pre-training for learning node representations, while neglected in the prompt tuning stage for learning task-specific parameters. To bridge this gap, we propose a novel structure-based prompting method for GNNs, namely SAP, which consistently exploits structure information in both pre-training and prompt tuning stages. In particular, SAP 1) employs a dual-view contrastive learning to align the latent semantic spaces of node attributes and graph structure, and 2) incorporates structure information in prompted graph to elicit more pre-trained knowledge in prompt tuning. We conduct extensive experiments on node classification and graph classification tasks to show the effectiveness of SAP. Moreover, we show that SAP can lead to better performance in more challenging few-shot scenarios on both homophilous and heterophilous graphs.", "url": "https://arxiv.org/abs/2310.17394"}, {"metadata": {"arXiv": "2310.17405", "Date": "Thu, 26 Oct 2023 14:01:17 ", "Title": "Causal Modeling with Stationary Diffusions", "Authors": ["Lars Lorch", "Andreas Krause", "Bernhard Sch\\\"olkopf"], "Categories": "cs.LG"}, "abstract": "We develop a novel approach towards causal inference. Rather than structural equations over a causal graph, we learn stochastic differential equations (SDEs) whose stationary densities model a system's behavior under interventions. These stationary diffusion models do not require the formalism of causal graphs, let alone the common assumption of acyclicity. We show that in several cases, they generalize to unseen interventions on their variables, often better than classical approaches. Our inference method is based on a new theoretical result that expresses a stationarity condition on the diffusion's generator in a reproducing kernel Hilbert space. The resulting kernel deviation from stationarity (KDS) is an objective function of independent interest.", "url": "https://arxiv.org/abs/2310.17405"}, {"metadata": {"arXiv": "2310.17432", "Date": "Thu, 26 Oct 2023 14:40:30 ", "Title": "Likelihood-based Out-of-Distribution Detection with Denoising Diffusion Probabilistic Models", "Authors": ["Joseph Goodier", "Neill D.F. Campbell"], "Categories": "cs.LG", "Comments": ["9 pages (main paper)", "3 pages (acknowledgements & references)", "3 figures", "2 tables", "1 algorithm", "work accepted for BMVC 2023"]}, "abstract": "Out-of-Distribution detection between dataset pairs has been extensively explored with generative models. We show that likelihood-based Out-of-Distribution detection can be extended to diffusion models by leveraging the fact that they, like other likelihood-based generative models, are dramatically affected by the input sample complexity. Currently, all Out-of-Distribution detection methods with Diffusion Models are reconstruction-based. We propose a new likelihood ratio for Out-of-Distribution detection with Deep Denoising Diffusion Models, which we call the Complexity Corrected Likelihood Ratio. Our likelihood ratio is constructed using Evidence Lower-Bound evaluations from an individual model at various noising levels. We present results that are comparable to state-of-the-art Out-of-Distribution detection methods with generative models.", "url": "https://arxiv.org/abs/2310.17432"}, {"metadata": {"arXiv": "2310.17458", "Date": "Thu, 26 Oct 2023 15:04:23 ", "Title": "Coalitional Bargaining via Reinforcement Learning: An Application to Collaborative Vehicle Routing", "Authors": ["Stephen Mak", "Liming Xu", "Tim Pearce", "Michael Ostroumov", "Alexandra Brintrup"], "Categories": "cs.LG", "Comments": ["Accepted to NeurIPS 2021 Workshop on Cooperative AI"]}, "abstract": "Collaborative Vehicle Routing is where delivery companies cooperate by sharing their delivery information and performing delivery requests on behalf of each other. This achieves economies of scale and thus reduces cost, greenhouse gas emissions, and road congestion. But which company should partner with whom, and how much should each company be compensated? Traditional game theoretic solution concepts, such as the Shapley value or nucleolus, are difficult to calculate for the real-world problem of Collaborative Vehicle Routing due to the characteristic function scaling exponentially with the number of agents. This would require solving the Vehicle Routing Problem (an NP-Hard problem) an exponential number of times. We therefore propose to model this problem as a coalitional bargaining game where - crucially - agents are not given access to the characteristic function. Instead, we implicitly reason about the characteristic function, and thus eliminate the need to evaluate the VRP an exponential number of times - we only need to evaluate it once. Our contribution is that our decentralised approach is both scalable and considers the self-interested nature of companies. The agents learn using a modified Independent Proximal Policy Optimisation. Our RL agents outperform a strong heuristic bot. The agents correctly identify the optimal coalitions 79% of the time with an average optimality gap of 4.2% and reduction in run-time of 62%.", "url": "https://arxiv.org/abs/2310.17458"}, {"metadata": {"arXiv": "2310.17463", "Date": "Thu, 26 Oct 2023 15:10:35 ", "Title": "Bayesian Neural Controlled Differential Equations for Treatment Effect Estimation", "Authors": ["Konstantin Hess", "Valentyn Melnychuk", "Dennis Frauen", "Stefan Feuerriegel"], "Categories": "cs.LG"}, "abstract": "Treatment effect estimation in continuous time is crucial for personalized medicine. However, existing methods for this task are limited to point estimates of the potential outcomes, whereas uncertainty estimates have been ignored. Needless to say, uncertainty quantification is crucial for reliable decision-making in medical applications. To fill this gap, we propose a novel Bayesian neural controlled differential equation (BNCDE) for treatment effect estimation in continuous time. In our BNCDE, the time dimension is modeled through a coupled system of neural controlled differential equations and neural stochastic differential equations, where the neural stochastic differential equations allow for tractable variational Bayesian inference. Thereby, for an assigned sequence of treatments, our BNCDE provides meaningful posterior predictive distributions of the potential outcomes. To the best of our knowledge, ours is the first tailored neural method to provide uncertainty estimates of treatment effects in continuous time. As such, our method is of direct practical value for promoting reliable decision-making in medicine.", "url": "https://arxiv.org/abs/2310.17463"}, {"metadata": {"arXiv": "2310.17477", "Date": "Thu, 26 Oct 2023 15:27:55 ", "Title": "Secure short-term load forecasting for smart grids with transformer-based federated learning", "Authors": ["Jonas Sievers", "Thomas Blank"], "Categories": "cs.LG", "DOI": "10.1109/ICCEP57914.2023.10247363"}, "abstract": "Electricity load forecasting is an essential task within smart grids to assist demand and supply balance. While advanced deep learning models require large amounts of high-resolution data for accurate short-term load predictions, fine-grained load profiles can expose users' electricity consumption behaviors, which raises privacy and security concerns. One solution to improve data privacy is federated learning, where models are trained locally on private data, and only the trained model parameters are merged and updated on a global server. Therefore, this paper presents a novel transformer-based deep learning approach with federated learning for short-term electricity load prediction. To evaluate our results, we benchmark our federated learning architecture against central and local learning and compare the performance of our model to long short-term memory models and convolutional neural networks. Our simulations are based on a dataset from a German university campus and show that transformer-based forecasting is a promising alternative to state-of-the-art models within federated learning.", "url": "https://arxiv.org/abs/2310.17477"}, {"metadata": {"arXiv": "2310.17485", "Date": "Thu, 26 Oct 2023 15:42:29 ", "Title": "Fair collaborative vehicle routing: A deep multi-agent reinforcement learning approach", "Authors": ["Stephen Mak", "Liming Xu", "Tim Pearce", "Michael Ostroumov", "Alexandra Brintrup"], "Categories": "cs.LG", "Comments": ["Final", "published version can be found here: https://www.sciencedirect.com/science/article/pii/S0968090X23003662"], "Journal-ref": "Volume 157, December 2023, 104376", "DOI": "10.1016/j.trc.2023.104376"}, "abstract": "Collaborative vehicle routing occurs when carriers collaborate through sharing their transportation requests and performing transportation requests on behalf of each other. This achieves economies of scale, thus reducing cost, greenhouse gas emissions and road congestion. But which carrier should partner with whom, and how much should each carrier be compensated? Traditional game theoretic solution concepts are expensive to calculate as the characteristic function scales exponentially with the number of agents. This would require solving the vehicle routing problem (NP-hard) an exponential number of times. We therefore propose to model this problem as a coalitional bargaining game solved using deep multi-agent reinforcement learning, where - crucially - agents are not given access to the characteristic function. Instead, we implicitly reason about the characteristic function; thus, when deployed in production, we only need to evaluate the expensive post-collaboration vehicle routing problem once. Our contribution is that we are the first to consider both the route allocation problem and gain sharing problem simultaneously - without access to the expensive characteristic function. Through decentralised machine learning, our agents bargain with each other and agree to outcomes that correlate well with the Shapley value - a fair profit allocation mechanism. Importantly, we are able to achieve a reduction in run-time of 88%.", "url": "https://arxiv.org/abs/2310.17485"}, {"metadata": {"arXiv": "2310.17491", "Date": "Thu, 26 Oct 2023 15:47:44 ", "Title": "FedPEAT: Convergence of Federated Learning, Parameter-Efficient Fine Tuning, and Emulator Assisted Tuning for Artificial Intelligence Foundation Models with Mobile Edge Computing", "Authors": ["Terence Jie Chua", "Wenhan Yu", "Jun Zhao", "Kwok-Yan Lam"], "Categories": "cs.LG cs.NI"}, "abstract": "The emergence of foundation models, including language and vision models, has reshaped AI's landscape, offering capabilities across various applications. Deploying and fine-tuning these large models, like GPT-3 and BERT, presents challenges, especially in the current foundation model era. We introduce Emulator-Assisted Tuning (EAT) combined with Parameter-Efficient Fine-Tuning (PEFT) to form Parameter-Efficient Emulator-Assisted Tuning (PEAT). Further, we expand this into federated learning as Federated PEAT (FedPEAT). FedPEAT uses adapters, emulators, and PEFT for federated model tuning, enhancing model privacy and memory efficiency. Adapters adjust pre-trained models, while emulators give a compact representation of original models, addressing both privacy and efficiency. Adaptable to various neural networks, our approach also uses deep reinforcement learning for hyper-parameter optimization. We tested FedPEAT in a unique scenario with a server participating in collaborative federated tuning, showcasing its potential in tackling foundation model challenges.", "url": "https://arxiv.org/abs/2310.17491"}, {"metadata": {"arXiv": "2310.17498", "Date": "Thu, 26 Oct 2023 15:53:18 ", "Title": "CBD: A Certified Backdoor Detector Based on Local Dominant Probability", "Authors": ["Zhen Xiang and Zidi Xiong and Bo Li"], "Categories": "cs.LG cs.CR", "Comments": ["Accepted to NeurIPS 2023"]}, "abstract": "Backdoor attack is a common threat to deep neural networks. During testing, samples embedded with a backdoor trigger will be misclassified as an adversarial target by a backdoored model, while samples without the backdoor trigger will be correctly classified. In this paper, we present the first certified backdoor detector (CBD), which is based on a novel, adjustable conformal prediction scheme based on our proposed statistic local dominant probability. For any classifier under inspection, CBD provides 1) a detection inference, 2) the condition under which the attacks are guaranteed to be detectable for the same classification domain, and 3) a probabilistic upper bound for the false positive rate. Our theoretical results show that attacks with triggers that are more resilient to test-time noise and have smaller perturbation magnitudes are more likely to be detected with guarantees. Moreover, we conduct extensive experiments on four benchmark datasets considering various backdoor types, such as BadNet, CB, and Blend. CBD achieves comparable or even higher detection accuracy than state-of-the-art detectors, and it in addition provides detection certification. Notably, for backdoor attacks with random perturbation triggers bounded by $\\ell_2\\leq0.75$ which achieves more than 90\\% attack success rate, CBD achieves 100\\% (98\\%), 100\\% (84\\%), 98\\% (98\\%), and 72\\% (40\\%) empirical (certified) detection true positive rates on the four benchmark datasets GTSRB, SVHN, CIFAR-10, and TinyImageNet, respectively, with low false positive rates.", "url": "https://arxiv.org/abs/2310.17498"}, {"metadata": {"arXiv": "2310.17538", "Date": "Thu, 26 Oct 2023 16:28:29 ", "Title": "Little Exploration is All You Need", "Authors": ["Henry H.H. Chen", "Jiaming Lu"], "Categories": "cs.LG"}, "abstract": "The prevailing principle of \"Optimism in the Face of Uncertainty\" advocates for the incorporation of an exploration bonus, generally assumed to be proportional to the inverse square root of the visit count ($1/\\sqrt{n}$), where $n$ is the number of visits to a particular state-action pair. This approach, however, exclusively focuses on \"uncertainty,\" neglecting the inherent \"difficulty\" of different options. To address this gap, we introduce a novel modification of standard UCB algorithm in the multi-armed bandit problem, proposing an adjusted bonus term of $1/n^\\tau$, where $\\tau > 1/2$, that accounts for task difficulty. Our proposed algorithm, denoted as UCB$^\\tau$, is substantiated through comprehensive regret and risk analyses, confirming its theoretical robustness. Comparative evaluations with standard UCB and Thompson Sampling algorithms on synthetic datasets demonstrate that UCB$^\\tau$ not only outperforms in efficacy but also exhibits lower risk across various environmental conditions and hyperparameter settings.", "url": "https://arxiv.org/abs/2310.17538"}, {"metadata": {"arXiv": "2310.17544", "Date": "Thu, 26 Oct 2023 16:40:09 ", "Title": "Hierarchical Ensemble-Based Feature Selection for Time Series Forecasting", "Authors": ["Aysin Tumay", "Mustafa E. Aydin", "and Suleyman S. Kozat"], "Categories": "cs.LG"}, "abstract": "We study a novel ensemble approach for feature selection based on hierarchical stacking in cases of non-stationarity and limited number of samples with large number of features. Our approach exploits the co-dependency between features using a hierarchical structure. Initially, a machine learning model is trained using a subset of features, and then the model's output is updated using another algorithm with the remaining features to minimize the target loss. This hierarchical structure allows for flexible depth and feature selection. By exploiting feature co-dependency hierarchically, our proposed approach overcomes the limitations of traditional feature selection methods and feature importance scores. The effectiveness of the approach is demonstrated on synthetic and real-life datasets, indicating improved performance with scalability and stability compared to the traditional methods and state-of-the-art approaches.", "url": "https://arxiv.org/abs/2310.17544"}, {"metadata": {"arXiv": "2310.17556", "Date": "Thu, 26 Oct 2023 16:46:13 ", "Title": "Efficient Numerical Algorithm for Large-Scale Damped Natural Gradient Descent", "Authors": ["Yixiao Chen", "Hao Xie", "Han Wang"], "Categories": "cs.LG cs.NA math.NA physics.comp-ph"}, "abstract": "We propose a new algorithm for efficiently solving the damped Fisher matrix in large-scale scenarios where the number of parameters significantly exceeds the number of available samples. This problem is fundamental for natural gradient descent and stochastic reconfiguration. Our algorithm is based on Cholesky decomposition and is generally applicable. Benchmark results show that the algorithm is significantly faster than existing methods.", "url": "https://arxiv.org/abs/2310.17556"}, {"metadata": {"arXiv": "2310.17579", "Date": "Thu, 26 Oct 2023 17:03:14 ", "Title": "BLIS-Net: Classifying and Analyzing Signals on Graphs", "Authors": ["Charles Xu and Laney Goldman and Valentina Guo and Benjamin Hollander-Bodie and Maedee Trank-Greene and Ian Adelstein and Edward De Brouwer and Rex Ying and Smita Krishnaswamy and Michael Perlmutter"], "Categories": "cs.LG eess.SP"}, "abstract": "Graph neural networks (GNNs) have emerged as a powerful tool for tasks such as node classification and graph classification. However, much less work has been done on signal classification, where the data consists of many functions (referred to as signals) defined on the vertices of a single graph. These tasks require networks designed differently from those designed for traditional GNN tasks. Indeed, traditional GNNs rely on localized low-pass filters, and signals of interest may have intricate multi-frequency behavior and exhibit long range interactions. This motivates us to introduce the BLIS-Net (Bi-Lipschitz Scattering Net), a novel GNN that builds on the previously introduced geometric scattering transform. Our network is able to capture both local and global signal structure and is able to capture both low-frequency and high-frequency information. We make several crucial changes to the original geometric scattering architecture which we prove increase the ability of our network to capture information about the input signal and show that BLIS-Net achieves superior performance on both synthetic and real-world data sets based on traffic flow and fMRI data.", "url": "https://arxiv.org/abs/2310.17579"}, {"metadata": {"arXiv": "2310.17588", "Date": "Thu, 26 Oct 2023 17:09:13 ", "Title": "PAC-tuning:Fine-tuning Pretrained Language Models with PAC-driven Perturbed Gradient Descent", "Authors": ["Guangliang Liu", "Zhiyu Xue", "Xitong Zhang", "Kristen Marie Johnson and Rongrong Wang"], "Categories": "cs.LG cs.CL", "Comments": ["Accepted to EMNLP23 main"]}, "abstract": "Fine-tuning pretrained language models (PLMs) for downstream tasks is a large-scale optimization problem, in which the choice of the training algorithm critically determines how well the trained model can generalize to unseen test data, especially in the context of few-shot learning. To achieve good generalization performance and avoid overfitting, techniques such as data augmentation and pruning are often applied. However, adding these regularizations necessitates heavy tuning of the hyperparameters of optimization algorithms, such as the popular Adam optimizer. In this paper, we propose a two-stage fine-tuning method, PAC-tuning, to address this optimization challenge. First, based on PAC-Bayes training, PAC-tuning directly minimizes the PAC-Bayes generalization bound to learn proper parameter distribution. Second, PAC-tuning modifies the gradient by injecting noise with the variance learned in the first stage into the model parameters during training, resulting in a variant of perturbed gradient descent (PGD). In the past, the few-shot scenario posed difficulties for PAC-Bayes training because the PAC-Bayes bound, when applied to large models with limited training data, might not be stringent. Our experimental results across 5 GLUE benchmark tasks demonstrate that PAC-tuning successfully handles the challenges of fine-tuning tasks and outperforms strong baseline methods by a visible margin, further confirming the potential to apply PAC training for any other settings where the Adam optimizer is currently used for training.", "url": "https://arxiv.org/abs/2310.17588"}, {"metadata": {"arXiv": "2310.17611", "Date": "Thu, 26 Oct 2023 17:34:32 ", "Title": "Uncovering Meanings of Embeddings via Partial Orthogonality", "Authors": ["Yibo Jiang", "Bryon Aragam", "Victor Veitch"], "Categories": "cs.LG cs.CL stat.ML"}, "abstract": "Machine learning tools often rely on embedding text as vectors of real numbers. In this paper, we study how the semantic structure of language is encoded in the algebraic structure of such embeddings. Specifically, we look at a notion of ``semantic independence'' capturing the idea that, e.g., ``eggplant'' and ``tomato'' are independent given ``vegetable''. Although such examples are intuitive, it is difficult to formalize such a notion of semantic independence. The key observation here is that any sensible formalization should obey a set of so-called independence axioms, and thus any algebraic encoding of this structure should also obey these axioms. This leads us naturally to use partial orthogonality as the relevant algebraic structure. We develop theory and methods that allow us to demonstrate that partial orthogonality does indeed capture semantic independence. Complementary to this, we also introduce the concept of independence preserving embeddings where embeddings preserve the conditional independence structures of a distribution, and we prove the existence of such embeddings and approximations to them.", "url": "https://arxiv.org/abs/2310.17611"}, {"metadata": {"arXiv": "2310.17622", "Date": "Thu, 26 Oct 2023 17:41:11 ", "Title": "Combating Representation Learning Disparity with Geometric Harmonization", "Authors": ["Zhihan Zhou and Jiangchao Yao and Feng Hong and Ya Zhang and Bo Han and Yanfeng Wang"], "Categories": "cs.LG", "Comments": ["Accepted to NeurIPS 2023 (spotlight)"]}, "abstract": "Self-supervised learning (SSL) as an effective paradigm of representation learning has achieved tremendous success on various curated datasets in diverse scenarios. Nevertheless, when facing the long-tailed distribution in real-world applications, it is still hard for existing methods to capture transferable and robust representation. Conventional SSL methods, pursuing sample-level uniformity, easily leads to representation learning disparity where head classes dominate the feature regime but tail classes passively collapse. To address this problem, we propose a novel Geometric Harmonization (GH) method to encourage category-level uniformity in representation learning, which is more benign to the minority and almost does not hurt the majority under long-tailed distribution. Specially, GH measures the population statistics of the embedding space on top of self-supervised learning, and then infer an fine-grained instance-wise calibration to constrain the space expansion of head classes and avoid the passive collapse of tail classes. Our proposal does not alter the setting of SSL and can be easily integrated into existing methods in a low-cost manner. Extensive results on a range of benchmark datasets show the effectiveness of GH with high tolerance to the distribution skewness. Our code is available at https://github.com/MediaBrain-SJTU/Geometric-Harmonization.", "url": "https://arxiv.org/abs/2310.17622"}, {"metadata": {"arXiv": "2310.17638", "Date": "Thu, 26 Oct 2023 17:53:24 ", "Title": "Generative Fractional Diffusion Models", "Authors": ["Gabriel Nobis", "Marco Aversa", "Maximilian Springenberg", "Michael Detzel", "Stefano Ermon", "Shinichi Nakajima", "Roderick Murray-Smith", "Sebastian Lapuschkin", "Christoph Knochenhauer", "Luis Oala", "Wojciech Samek"], "Categories": "cs.LG stat.ML", "ACM-class": "I.2.4; F.4.1; G.3"}, "abstract": "We generalize the continuous time framework for score-based generative models from an underlying Brownian motion (BM) to an approximation of fractional Brownian motion (FBM). We derive a continuous reparameterization trick and the reverse time model by representing FBM as a stochastic integral over a family of Ornstein-Uhlenbeck processes to define generative fractional diffusion models (GFDM) with driving noise converging to a non-Markovian process of infinite quadratic variation. The Hurst index $H\\in(0,1)$ of FBM enables control of the roughness of the distribution transforming path. To the best of our knowledge, this is the first attempt to build a generative model upon a stochastic process with infinite quadratic variation.", "url": "https://arxiv.org/abs/2310.17638"}, {"metadata": {"arXiv": "2310.17651", "Date": "Thu, 26 Oct 2023 17:59:32 ", "Title": "High-Dimensional Prediction for Sequential Decision Making", "Authors": ["Georgy Noarov", "Ramya Ramalingam", "Aaron Roth", "Stephan Xie"], "Categories": "cs.LG"}, "abstract": "We study the problem of making predictions of an adversarially chosen high-dimensional state that are unbiased subject to an arbitrary collection of conditioning events, with the goal of tailoring these events to downstream decision makers. We give efficient algorithms for solving this problem, as well as a number of applications that stem from choosing an appropriate set of conditioning events.", "url": "https://arxiv.org/abs/2310.17651"}, {"metadata": {"arXiv": "2310.17653", "Date": "Thu, 26 Oct 2023 17:59:46 ", "Title": "Fantastic Gains and Where to Find Them: On the Existence and Prospect of General Knowledge Transfer between Any Pretrained Model", "Authors": ["Karsten Roth", "Lukas Thede", "Almut Sophia Koepke", "Oriol Vinyals", "Olivier H\\'enaff", "Zeynep Akata"], "Categories": "cs.LG cs.CV"}, "abstract": "Training deep networks requires various design decisions regarding for instance their architecture, data augmentation, or optimization. In this work, we find these training variations to result in networks learning unique feature sets from the data. Using public model libraries comprising thousands of models trained on canonical datasets like ImageNet, we observe that for arbitrary pairings of pretrained models, one model extracts significant data context unavailable in the other -- independent of overall performance. Given any arbitrary pairing of pretrained models and no external rankings (such as separate test sets, e.g. due to data privacy), we investigate if it is possible to transfer such \"complementary\" knowledge from one model to another without performance degradation -- a task made particularly difficult as additional knowledge can be contained in stronger, equiperformant or weaker models. Yet facilitating robust transfer in scenarios agnostic to pretrained model pairings would unlock auxiliary gains and knowledge fusion from any model repository without restrictions on model and problem specifics - including from weaker, lower-performance models. This work therefore provides an initial, in-depth exploration on the viability of such general-purpose knowledge transfer. Across large-scale experiments, we first reveal the shortcomings of standard knowledge distillation techniques, and then propose a much more general extension through data partitioning for successful transfer between nearly all pretrained models, which we show can also be done unsupervised. Finally, we assess both the scalability and impact of fundamental model properties on successful model-agnostic knowledge transfer.", "url": "https://arxiv.org/abs/2310.17653"}, {"metadata": {"arXiv": "2310.16917", "Date": "Wed, 25 Oct 2023 18:34:06 ", "Title": "MimicTouch: Learning Human's Control Strategy with Multi-Modal Tactile Feedback", "Authors": ["Kelin Yu", "Yunhai Han", "Matthew Zhu", "Ye Zhao"], "Categories": "cs.RO cs.LG", "Comments": ["Presented at CoRL 2023 Deployable Workshop"]}, "abstract": "In robotics and artificial intelligence, the integration of tactile processing is becoming increasingly pivotal, especially in learning to execute intricate tasks like alignment and insertion. However, existing works focusing on tactile methods for insertion tasks predominantly rely on robot teleoperation data and reinforcement learning, which do not utilize the rich insights provided by human's control strategy guided by tactile feedback. For utilizing human sensations, methodologies related to learning from humans predominantly leverage visual feedback, often overlooking the invaluable tactile feedback that humans inherently employ to finish complex manipulations. Addressing this gap, we introduce \"MimicTouch\", a novel framework that mimics human's tactile-guided control strategy. In this framework, we initially collect multi-modal tactile datasets from human demonstrators, incorporating human tactile-guided control strategies for task completion. The subsequent step involves instructing robots through imitation learning using multi-modal sensor data and retargeted human motions. To further mitigate the embodiment gap between humans and robots, we employ online residual reinforcement learning on the physical robot. Through comprehensive experiments, we validate the safety of MimicTouch in transferring a latent policy learned through imitation learning from human to robot. This ongoing work will pave the way for a broader spectrum of tactile-guided robotic applications.", "url": "https://arxiv.org/abs/2310.16917"}, {"metadata": {"arXiv": "2310.16941", "Date": "Wed, 25 Oct 2023 19:20:32 ", "Title": "Exploring Behavior Discovery Methods for Heterogeneous Swarms of Limited-Capability Robots", "Authors": ["Connor Mattson", "Jeremy C. Clark", "and Daniel S. Brown"], "Categories": "cs.RO cs.LG cs.MA", "Comments": ["11 pages", "9 figures", "To be published in Proceedings IEEE International Symposium on Multi-Robot & Multi-Agent Systems (MRS 2023)"]}, "abstract": "We study the problem of determining the emergent behaviors that are possible given a functionally heterogeneous swarm of robots with limited capabilities. Prior work has considered behavior search for homogeneous swarms and proposed the use of novelty search over either a hand-specified or learned behavior space followed by clustering to return a taxonomy of emergent behaviors to the user. In this paper, we seek to better understand the role of novelty search and the efficacy of using clustering to discover novel emergent behaviors. Through a large set of experiments and ablations, we analyze the effect of representations, evolutionary search, and various clustering methods in the search for novel behaviors in a heterogeneous swarm. Our results indicate that prior methods fail to discover many interesting behaviors and that an iterative human-in-the-loop discovery process discovers more behaviors than random search, swarm chemistry, and automated behavior discovery. The combined discoveries of our experiments uncover 23 emergent behaviors, 18 of which are novel discoveries. To the best of our knowledge, these are the first known emergent behaviors for heterogeneous swarms of computation-free agents. Videos, code, and appendix are available at the project website: https://sites.google.com/view/heterogeneous-bd-methods", "url": "https://arxiv.org/abs/2310.16941"}, {"metadata": {"arXiv": "2310.17540", "Date": "Thu, 26 Oct 2023 16:32:34 ", "Title": "EqDrive: Efficient Equivariant Motion Forecasting with Multi-Modality for Autonomous Driving", "Authors": ["Yuping Wang", "Jier Chen"], "Categories": "cs.RO cs.LG", "Comments": ["6 pages", "7 figures"]}, "abstract": "Forecasting vehicular motions in autonomous driving requires a deep understanding of agent interactions and the preservation of motion equivariance under Euclidean geometric transformations. Traditional models often lack the sophistication needed to handle the intricate dynamics inherent to autonomous vehicles and the interaction relationships among agents in the scene. As a result, these models have a lower model capacity, which then leads to higher prediction errors and lower training efficiency. In our research, we employ EqMotion, a leading equivariant particle, and human prediction model that also accounts for invariant agent interactions, for the task of multi-agent vehicle motion forecasting. In addition, we use a multi-modal prediction mechanism to account for multiple possible future paths in a probabilistic manner. By leveraging EqMotion, our model achieves state-of-the-art (SOTA) performance with fewer parameters (1.2 million) and a significantly reduced training time (less than 2 hours).", "url": "https://arxiv.org/abs/2310.17540"}, {"metadata": {"arXiv": "2310.17642", "Date": "Thu, 26 Oct 2023 17:56:35 ", "Title": "Drive Anywhere: Generalizable End-to-end Autonomous Driving with Multi-modal Foundation Models", "Authors": ["Tsun-Hsuan Wang and Alaa Maalouf and Wei Xiao and Yutong Ban and Alexander Amini and Guy Rosman and Sertac Karaman and Daniela Rus"], "Categories": "cs.RO cs.CV cs.LG", "Comments": ["Project webpage: https://drive-anywhere.github.io Explainer video: https://www.youtube.com/watch?v=4n-DJf8vXxo&feature=youtu.be"]}, "abstract": "As autonomous driving technology matures, end-to-end methodologies have emerged as a leading strategy, promising seamless integration from perception to control via deep learning. However, existing systems grapple with challenges such as unexpected open set environments and the complexity of black-box models. At the same time, the evolution of deep learning introduces larger, multimodal foundational models, offering multi-modal visual and textual understanding. In this paper, we harness these multimodal foundation models to enhance the robustness and adaptability of autonomous driving systems, enabling out-of-distribution, end-to-end, multimodal, and more explainable autonomy. Specifically, we present an approach to apply end-to-end open-set (any environment/scene) autonomous driving that is capable of providing driving decisions from representations queryable by image and text. To do so, we introduce a method to extract nuanced spatial (pixel/patch-aligned) features from transformers to enable the encapsulation of both spatial and semantic features. Our approach (i) demonstrates unparalleled results in diverse tests while achieving significantly greater robustness in out-of-distribution situations, and (ii) allows the incorporation of latent space simulation (via text) for improved training (data augmentation via text) and policy debugging. We encourage the reader to check our explainer video at https://www.youtube.com/watch?v=4n-DJf8vXxo&feature=youtu.be and to view the code and demos on our project webpage at https://drive-anywhere.github.io/.", "url": "https://arxiv.org/abs/2310.17642"}, {"metadata": {"arXiv": "2310.17056", "Date": "Wed, 25 Oct 2023 23:34:25 ", "Title": "Strategizing EV Charging and Renewable Integration in Texas", "Authors": ["Mohammad Mohammadi and Jesse Thornburg"], "Categories": "eess.SY cs.LG cs.SY"}, "abstract": "Exploring the convergence of electric vehicles (EVs), renewable energy, and smart grid technologies in the context of Texas, this study addresses challenges hindering the widespread adoption of EVs. Acknowledging their environmental benefits, the research focuses on grid stability concerns, uncoordinated charging patterns, and the complicated relationship between EVs and renewable energy sources. Dynamic time warping (DTW) clustering and k-means clustering methodologies categorize days based on total load and net load, offering nuanced insights into daily electricity consumption and renewable energy generation patterns. By establishing optimal charging and vehicle-to-grid (V2G) windows tailored to specific load characteristics, the study provides a sophisticated methodology for strategic decision-making in energy consumption and renewable integration. The findings contribute to the ongoing discourse on achieving a sustainable and resilient energy future through the seamless integration of EVs into smart grids.", "url": "https://arxiv.org/abs/2310.17056"}, {"metadata": {"arXiv": "2310.17011", "Date": "Wed, 25 Oct 2023 21:22:28 ", "Title": "Personalized Speech-driven Expressive 3D Facial Animation Synthesis with Style Control", "Authors": ["Elif Bozkurt"], "Categories": "cs.AI cs.GR", "Comments": ["8 pages"]}, "abstract": "Different people have different facial expressions while speaking emotionally. A realistic facial animation system should consider such identity-specific speaking styles and facial idiosyncrasies to achieve high-degree of naturalness and plausibility. Existing approaches to personalized speech-driven 3D facial animation either use one-hot identity labels or rely-on person specific models which limit their scalability. We present a personalized speech-driven expressive 3D facial animation synthesis framework that models identity specific facial motion as latent representations (called as styles), and synthesizes novel animations given a speech input with the target style for various emotion categories. Our framework is trained in an end-to-end fashion and has a non-autoregressive encoder-decoder architecture with three main components: expression encoder, speech encoder and expression decoder. Since, expressive facial motion includes both identity-specific style and speech-related content information; expression encoder first disentangles facial motion sequences into style and content representations, respectively. Then, both of the speech encoder and the expression decoders input the extracted style information to update transformer layer weights during training phase. Our speech encoder also extracts speech phoneme label and duration information to achieve better synchrony within the non-autoregressive synthesis mechanism more effectively. Through detailed experiments, we demonstrate that our approach produces temporally coherent facial expressions from input speech while preserving the speaking styles of the target identities.", "url": "https://arxiv.org/abs/2310.17011"}, {"metadata": {"arXiv": "2310.17162", "Date": "Thu, 26 Oct 2023 05:24:38 ", "Title": "Content-based Controls For Music Large Language Modeling", "Authors": ["Liwei Lin", "Gus Xia", "Junyan Jiang", "and Yixiao Zhang"], "Categories": "cs.AI cs.SD eess.AS"}, "abstract": "Recent years have witnessed a rapid growth of large-scale language models in the domain of music audio. Such models enable end-to-end generation of higher-quality music, and some allow conditioned generation using text descriptions. However, the control power of text controls on music is intrinsically limited, as they can only describe music indirectly through meta-data (such as singers and instruments) or high-level representations (such as genre and emotion). We aim to further equip the models with direct and content-based controls on innate music languages such as pitch, chords and drum track. To this end, we contribute Coco-Mulla, a content-based control method for music large language modeling. It uses a parameter-efficient fine-tuning (PEFT) method tailored for Transformer-based audio models. Experiments show that our approach achieved high-quality music generation with low-resource semi-supervised learning, tuning with less than 4% parameters compared to the original model and training on a small dataset with fewer than 300 songs. Moreover, our approach enables effective content-based controls, and we illustrate the control power via chords and rhythms, two of the most salient features of music audio. Furthermore, we show that by combining content-based controls and text descriptions, our system achieves flexible music variation generation and style transfer. Our source codes and demos are available online.", "url": "https://arxiv.org/abs/2310.17162"}, {"metadata": {"arXiv": "2310.17207", "Date": "Thu, 26 Oct 2023 07:49:25 ", "Title": "Efficient Data Fusion using the Tsetlin Machine", "Authors": ["Rupsa Saha", "Vladimir I. Zadorozhny and Ole-Christoffer Granmo"], "Categories": "cs.AI cs.CL"}, "abstract": "We propose a novel way of assessing and fusing noisy dynamic data using a Tsetlin Machine. Our approach consists in monitoring how explanations in form of logical clauses that a TM learns changes with possible noise in dynamic data. This way TM can recognize the noise by lowering weights of previously learned clauses, or reflect it in the form of new clauses. We also perform a comprehensive experimental study using notably different datasets that demonstrated high performance of the proposed approach.", "url": "https://arxiv.org/abs/2310.17207"}, {"metadata": {"arXiv": "2310.17228", "Date": "Thu, 26 Oct 2023 08:27:36 ", "Title": "TST$^\\mathrm{R}$: Target Similarity Tuning Meets the Real World", "Authors": ["Anirudh Khatry", "Sumit Gulwani", "Priyanshu Gupta", "Vu Le", "Ananya Singha", "Mukul Singh", "Gust Verbruggen"], "Categories": "cs.AI cs.CL cs.SE", "Comments": ["Accepted for EMNLP-Findings", "2023"]}, "abstract": "Target similarity tuning (TST) is a method of selecting relevant examples in natural language (NL) to code generation through large language models (LLMs) to improve performance. Its goal is to adapt a sentence embedding model to have the similarity between two NL inputs match the similarity between their associated code outputs. In this paper, we propose different methods to apply and improve TST in the real world. First, we replace the sentence transformer with embeddings from a larger model, which reduces sensitivity to the language distribution and thus provides more flexibility in synthetic generation of examples, and we train a tiny model that transforms these embeddings to a space where embedding similarity matches code similarity, which allows the model to remain a black box and only requires a few matrix multiplications at inference time. Second, we how to efficiently select a smaller number of training examples to train the TST model. Third, we introduce a ranking-based evaluation for TST that does not require end-to-end code generation experiments, which can be expensive to perform.", "url": "https://arxiv.org/abs/2310.17228"}, {"metadata": {"arXiv": "2310.17306", "Date": "Thu, 26 Oct 2023 11:05:15 ", "Title": "FormaT5: Abstention and Examples for Conditional Table Formatting with Natural Language", "Authors": ["Mukul Singh", "Jos\\'e Cambronero", "Sumit Gulwani", "Vu Le", "Carina Negreanu", "Elnaz Nouri", "Mohammad Raza", "Gust Verbruggen"], "Categories": "cs.AI cs.CL cs.DB cs.PL", "Comments": ["VLDB 2024", "14 pages"]}, "abstract": "Formatting is an important property in tables for visualization, presentation, and analysis. Spreadsheet software allows users to automatically format their tables by writing data-dependent conditional formatting (CF) rules. Writing such rules is often challenging for users as it requires them to understand and implement the underlying logic. We present FormaT5, a transformer-based model that can generate a CF rule given the target table and a natural language description of the desired formatting logic. We find that user descriptions for these tasks are often under-specified or ambiguous, making it harder for code generation systems to accurately learn the desired rule in a single step. To tackle this problem of under-specification and minimise argument errors, FormaT5 learns to predict placeholders though an abstention objective. These placeholders can then be filled by a second model or, when examples of rows that should be formatted are available, by a programming-by-example system. To evaluate FormaT5 on diverse and real scenarios, we create an extensive benchmark of 1053 CF tasks, containing real-world descriptions collected from four different sources. We release our benchmarks to encourage research in this area. Abstention and filling allow FormaT5 to outperform 8 different neural approaches on our benchmarks, both with and without examples. Our results illustrate the value of building domain-specific learning systems.", "url": "https://arxiv.org/abs/2310.17306"}, {"metadata": {"arXiv": "2310.17370", "Date": "Thu, 26 Oct 2023 13:02:45 ", "Title": "Exploring the Potential of Generative AI for the World Wide Web", "Authors": ["Nouar AlDahoul", "Joseph Hong", "Matteo Varvello", "Yasir Zaki"], "Categories": "cs.AI cs.HC cs.IR", "Comments": ["11 pages", "9 figures"]}, "abstract": "Generative Artificial Intelligence (AI) is a cutting-edge technology capable of producing text, images, and various media content leveraging generative models and user prompts. Between 2022 and 2023, generative AI surged in popularity with a plethora of applications spanning from AI-powered movies to chatbots. In this paper, we delve into the potential of generative AI within the realm of the World Wide Web, specifically focusing on image generation. Web developers already harness generative AI to help crafting text and images, while Web browsers might use it in the future to locally generate images for tasks like repairing broken webpages, conserving bandwidth, and enhancing privacy. To explore this research area, we have developed WebDiffusion, a tool that allows to simulate a Web powered by stable diffusion, a popular text-to-image model, from both a client and server perspective. WebDiffusion further supports crowdsourcing of user opinions, which we use to evaluate the quality and accuracy of 409 AI-generated images sourced from 60 webpages. Our findings suggest that generative AI is already capable of producing pertinent and high-quality Web images, even without requiring Web designers to manually input prompts, just by leveraging contextual information available within the webpages. However, we acknowledge that direct in-browser image generation remains a challenge, as only highly powerful GPUs, such as the A40 and A100, can (partially) compete with classic image downloads. Nevertheless, this approach could be valuable for a subset of the images, for example when fixing broken webpages or handling highly private content.", "url": "https://arxiv.org/abs/2310.17370"}, {"metadata": {"arXiv": "2310.17372", "Date": "Thu, 26 Oct 2023 13:07:01 ", "Title": "Dialogue-based generation of self-driving simulation scenarios using Large Language Models", "Authors": ["Antonio Valerio Miceli-Barone", "Alex Lascarides", "Craig Innes"], "Categories": "cs.AI cs.CL cs.RO", "Comments": ["12 pages", "6 figures", "SpLU-RoboNLP 2023"]}, "abstract": "Simulation is an invaluable tool for developing and evaluating controllers for self-driving cars. Current simulation frameworks are driven by highly-specialist domain specific languages, and so a natural language interface would greatly enhance usability. But there is often a gap, consisting of tacit assumptions the user is making, between a concise English utterance and the executable code that captures the user's intent. In this paper we describe a system that addresses this issue by supporting an extended multimodal interaction: the user can follow up prior instructions with refinements or revisions, in reaction to the simulations that have been generated from their utterances so far. We use Large Language Models (LLMs) to map the user's English utterances in this interaction into domain-specific code, and so we explore the extent to which LLMs capture the context sensitivity that's necessary for computing the speaker's intended message in discourse.", "url": "https://arxiv.org/abs/2310.17372"}, {"metadata": {"arXiv": "2310.17410", "Date": "Thu, 26 Oct 2023 14:13:15 ", "Title": "Synthesizing Efficiently Monitorable Formulas in Metric Temporal Logic", "Authors": ["Ritam Raha", "Rajarshi Roy", "Nathanael Fijalkow", "Daniel Neider and Guillermo A. Perez"], "Categories": "cs.AI cs.LO"}, "abstract": "In runtime verification, manually formalizing a specification for monitoring system executions is a tedious and error-prone process. To address this issue, we consider the problem of automatically synthesizing formal specifications from system executions. To demonstrate our approach, we consider the popular specification language Metric Temporal Logic (MTL), which is particularly tailored towards specifying temporal properties for cyber-physical systems (CPS). Most of the classical approaches for synthesizing temporal logic formulas aim at minimizing the size of the formula. However, for efficiency in monitoring, along with the size, the amount of \"lookahead\" required for the specification becomes relevant, especially for safety-critical applications. We formalize this notion and devise a learning algorithm that synthesizes concise formulas having bounded lookahead. To do so, our algorithm reduces the synthesis task to a series of satisfiability problems in Linear Real Arithmetic (LRA) and generates MTL formulas from their satisfying assignments. The reduction uses a novel encoding of a popular MTL monitoring procedure using LRA. Finally, we implement our algorithm in a tool called TEAL and demonstrate its ability to synthesize efficiently monitorable MTL formulas in a CPS application.", "url": "https://arxiv.org/abs/2310.17410"}, {"metadata": {"arXiv": "2310.17416", "Date": "Thu, 26 Oct 2023 14:21:36 ", "Title": "Goals are Enough: Inducing AdHoc cooperation among unseen Multi-Agent systems in IMFs", "Authors": ["Kaushik Dey", "Satheesh K. Perepu and Abir Das"], "Categories": "cs.AI cs.MA", "Comments": ["Accepted for publication in IEEE CCNC 2024 conference"]}, "abstract": "Intent-based management will play a critical role in achieving customers' expectations in the next-generation mobile networks. Traditional methods cannot perform efficient resource management since they tend to handle each expectation independently. Existing approaches, e.g., based on multi-agent reinforcement learning (MARL) allocate resources in an efficient fashion when there are conflicting expectations on the network slice. However, in reality, systems are often far more complex to be addressed by a standalone MARL formulation. Often there exists a hierarchical structure of intent fulfilment where multiple pre-trained, self-interested agents may need to be further orchestrated by a supervisor or controller agent. Such agents may arrive in the system adhoc, which then needs to be orchestrated along with other available agents. Retraining the whole system every time is often infeasible given the associated time and cost. Given the challenges, such adhoc coordination of pre-trained systems could be achieved through an intelligent supervisor agent which incentivizes pre-trained RL/MARL agents through sets of dynamic contracts (goals or bonuses) and encourages them to act as a cohesive unit towards fulfilling a global expectation. Some approaches use a rule-based supervisor agent and deploy the hierarchical constituent agents sequentially, based on human-coded rules. In the current work, we propose a framework whereby pre-trained agents can be orchestrated in parallel leveraging an AI-based supervisor agent. For this, we propose to use Adhoc-Teaming approaches which assign optimal goals to the MARL agents and incentivize them to exhibit certain desired behaviours. Results on the network emulator show that the proposed approach results in faster and improved fulfilment of expectations when compared to rule-based approaches and even generalizes to changes in environments.", "url": "https://arxiv.org/abs/2310.17416"}, {"metadata": {"arXiv": "2310.17451", "Date": "Thu, 26 Oct 2023 15:00:21 ", "Title": "Generating by Understanding: Neural Visual Generation with Logical Symbol Groundings", "Authors": ["Yifei Peng", "Yu Jin", "Zhexu Luo", "Yao-Xiang Ding", "Wang-Zhou Dai", "Zhong Ren", "Kun Zhou"], "Categories": "cs.AI cs.CV cs.GR"}, "abstract": "Despite the great success of neural visual generative models in recent years, integrating them with strong symbolic knowledge reasoning systems remains a challenging task. The main challenges are two-fold: one is symbol assignment, i.e. bonding latent factors of neural visual generators with meaningful symbols from knowledge reasoning systems. Another is rule learning, i.e. learning new rules, which govern the generative process of the data, to augment the knowledge reasoning systems. To deal with these symbol grounding problems, we propose a neural-symbolic learning approach, Abductive Visual Generation (AbdGen), for integrating logic programming systems with neural visual generative models based on the abductive learning framework. To achieve reliable and efficient symbol assignment, the quantized abduction method is introduced for generating abduction proposals by the nearest-neighbor lookups within semantic codebooks. To achieve precise rule learning, the contrastive meta-abduction method is proposed to eliminate wrong rules with positive cases and avoid less-informative rules with negative cases simultaneously. Experimental results on various benchmark datasets show that compared to the baselines, AbdGen requires significantly fewer instance-level labeling information for symbol assignment. Furthermore, our approach can effectively learn underlying logical generative rules from data, which is out of the capability of existing approaches.", "url": "https://arxiv.org/abs/2310.17451"}, {"metadata": {"arXiv": "2310.17512", "Date": "Thu, 26 Oct 2023 16:06:20 ", "Title": "CompeteAI: Understanding the Competition Behaviors in Large Language Model-based Agents", "Authors": ["Qinlin Zhao", "Jindong Wang", "Yixuan Zhang", "Yiqiao Jin", "Kaijie Zhu", "Hao Chen", "Xing Xie"], "Categories": "cs.AI cs.CL cs.HC cs.MA", "Comments": ["Technical report; 21 pages"]}, "abstract": "Large language models (LLMs) have been widely used as agents to complete different tasks, such as personal assistance or event planning. While most work has focused on cooperation and collaboration between agents, little work explores competition, another important mechanism that fosters the development of society and economy. In this paper, we seek to examine the competition behaviors in LLM-based agents. We first propose a general framework to study the competition between agents. Then, we implement a practical competitive environment using GPT-4 to simulate a virtual town with two types of agents, including restaurant agents and customer agents. Specifically, restaurant agents compete with each other to attract more customers, where the competition fosters them to transform, such as cultivating new operating strategies. The results of our experiments reveal several interesting findings ranging from social learning to Matthew Effect, which aligns well with existing sociological and economic theories. We believe that competition between agents deserves further investigation to help us understand society better. The code will be released soon.", "url": "https://arxiv.org/abs/2310.17512"}, {"metadata": {"arXiv": "2310.16919", "Date": "Wed, 25 Oct 2023 18:38:10 ", "Title": "Wide Flat Minimum Watermarking for Robust Ownership Verification of GANs", "Authors": ["Jianwei Fei", "Zhihua Xia", "Benedetta Tondi", "Mauro Barni"], "Categories": "cs.CV cs.AI"}, "abstract": "We propose a novel multi-bit box-free watermarking method for the protection of Intellectual Property Rights (IPR) of GANs with improved robustness against white-box attacks like fine-tuning, pruning, quantization, and surrogate model attacks. The watermark is embedded by adding an extra watermarking loss term during GAN training, ensuring that the images generated by the GAN contain an invisible watermark that can be retrieved by a pre-trained watermark decoder. In order to improve the robustness against white-box model-level attacks, we make sure that the model converges to a wide flat minimum of the watermarking loss term, in such a way that any modification of the model parameters does not erase the watermark. To do so, we add random noise vectors to the parameters of the generator and require that the watermarking loss term is as invariant as possible with respect to the presence of noise. This procedure forces the generator to converge to a wide flat minimum of the watermarking loss. The proposed method is architectureand dataset-agnostic, thus being applicable to many different generation tasks and models, as well as to CNN-based image processing architectures. We present the results of extensive experiments showing that the presence of the watermark has a negligible impact on the quality of the generated images, and proving the superior robustness of the watermark against model modification and surrogate model attacks.", "url": "https://arxiv.org/abs/2310.16919"}, {"metadata": {"arXiv": "2310.17177", "Date": "Thu, 26 Oct 2023 06:03:18 ", "Title": "Bridging The Gaps Between Token Pruning and Full Pre-training via Masked Fine-tuning", "Authors": ["Fengyuan Shi", "Limin Wang"], "Categories": "cs.CV cs.AI", "Comments": ["Submitted to TIP"]}, "abstract": "Despite the success of transformers on various computer vision tasks, they suffer from excessive memory and computational cost. Some works present dynamic vision transformers to accelerate inference by pruning redundant tokens. A key to improving token pruning is using well-trained models as initialization for faster convergence and better performance. However, current base models usually adopt full image training, i.e., using full images as inputs and keeping the whole feature maps through the forward process, which causes inconsistencies with dynamic models that gradually reduce tokens, including calculation pattern, information amount and token selection strategy inconsistencies. Inspired by MAE which performs masking and reconstruction self-supervised task, we devise masked fine-tuning to bridge the gaps between pre-trained base models used for initialization and token pruning based dynamic vision transformers, by masking image patches and predicting the image class label based on left unmasked patches. Extensive experiments on ImageNet demonstrate that base models via masked fine-tuning gain strong occlusion robustness and ability against information loss. With this better initialization, Dynamic ViT achieves higher accuracies, especially under large token pruning ratios (e.g., 81.9% vs. 81.3%, and 62.3% vs. 58.9% for DeiT based Dynamic ViT/0.8 and Dynamic ViT/0.3). Moreover, we apply our method into different token pruning based dynamic vision transformers, different pre-trained models and randomly initialized models to demonstrate the generalization ability.", "url": "https://arxiv.org/abs/2310.17177"}, {"metadata": {"arXiv": "2310.17183", "Date": "Thu, 26 Oct 2023 06:30:39 ", "Title": "Understanding the Effects of Projectors in Knowledge Distillation", "Authors": ["Yudong Chen", "Sen Wang", "Jiajun Liu", "Xuwei Xu", "Frank de Hoog", "Brano Kusy", "Zi Huang"], "Categories": "cs.CV cs.AI", "Comments": ["arXiv admin note: text overlap with arXiv:2210.15274"]}, "abstract": "Conventionally, during the knowledge distillation process (e.g. feature distillation), an additional projector is often required to perform feature transformation due to the dimension mismatch between the teacher and the student networks. Interestingly, we discovered that even if the student and the teacher have the same feature dimensions, adding a projector still helps to improve the distillation performance. In addition, projectors even improve logit distillation if we add them to the architecture too. Inspired by these surprising findings and the general lack of understanding of the projectors in the knowledge distillation process from existing literature, this paper investigates the implicit role that projectors play but so far have been overlooked. Our empirical study shows that the student with a projector (1) obtains a better trade-off between the training accuracy and the testing accuracy compared to the student without a projector when it has the same feature dimensions as the teacher, (2) better preserves its similarity to the teacher beyond shallow and numeric resemblance, from the view of Centered Kernel Alignment (CKA), and (3) avoids being over-confident as the teacher does at the testing phase. Motivated by the positive effects of projectors, we propose a projector ensemble-based feature distillation method to further improve distillation performance. Despite the simplicity of the proposed strategy, empirical results from the evaluation of classification tasks on benchmark datasets demonstrate the superior classification performance of our method on a broad range of teacher-student pairs and verify from the aspects of CKA and model calibration that the student's features are of improved quality with the projector ensemble design.", "url": "https://arxiv.org/abs/2310.17183"}, {"metadata": {"arXiv": "2310.17212", "Date": "Thu, 26 Oct 2023 07:56:17 ", "Title": "Emotion Recognition by Video: A review", "Authors": ["Junxiao Xue", "Jie Wang", "Xuecheng Wu and Liangyu Fu"], "Categories": "cs.CV cs.AI"}, "abstract": "Video emotion recognition is an important branch of affective computing, and its solutions can be applied in different fields such as human-computer interaction (HCI) and intelligent medical treatment. Although the number of papers published in the field of emotion recognition is increasing, there are few comprehensive literature reviews covering related research on video emotion recognition. Therefore, this paper selects articles published from 2015 to 2023 to systematize the existing trends in video emotion recognition in related studies. In this paper, we first talk about two typical emotion models, then we talk about databases that are frequently utilized for video emotion recognition, including unimodal databases and multimodal databases. Next, we look at and classify the specific structure and performance of modern unimodal and multimodal video emotion recognition methods, talk about the benefits and drawbacks of each, and then we compare them in detail in the tables. Further, we sum up the primary difficulties right now looked by video emotion recognition undertakings and point out probably the most encouraging future headings, such as establishing an open benchmark database and better multimodal fusion strategys. The essential objective of this paper is to assist scholarly and modern scientists with keeping up to date with the most recent advances and new improvements in this speedy, high-influence field of video emotion recognition.", "url": "https://arxiv.org/abs/2310.17212"}, {"metadata": {"arXiv": "2310.17261", "Date": "Thu, 26 Oct 2023 09:25:09 ", "Title": "Attribute Based Interpretable Evaluation Metrics for Generative Models", "Authors": ["Dongkyun Kim", "Mingi Kwon", "Youngjung Uh"], "Categories": "cs.CV cs.AI"}, "abstract": "When the training dataset comprises a 1:1 proportion of dogs to cats, a generative model that produces 1:1 dogs and cats better resembles the training species distribution than another model with 3:1 dogs and cats. Can we capture this phenomenon using existing metrics? Unfortunately, we cannot, because these metrics do not provide any interpretability beyond \"diversity\". In this context, we propose a new evaluation protocol that measures the divergence of a set of generated images from the training set regarding the distribution of attribute strengths as follows. Single-attribute Divergence (SaD) measures the divergence regarding PDFs of a single attribute. Paired-attribute Divergence (PaD) measures the divergence regarding joint PDFs of a pair of attributes. They provide which attributes the models struggle. For measuring the attribute strengths of an image, we propose Heterogeneous CLIPScore (HCS) which measures the cosine similarity between image and text vectors with heterogeneous initial points. With SaD and PaD, we reveal the following about existing generative models. ProjectedGAN generates implausible attribute relationships such as a baby with a beard even though it has competitive scores of existing metrics. Diffusion models struggle to capture diverse colors in the datasets. The larger sampling timesteps of latent diffusion model generate the more minor objects including earrings and necklaces. Stable Diffusion v1.5 better captures the attributes than v2.1. Our metrics lay a foundation for explainable evaluations of generative models.", "url": "https://arxiv.org/abs/2310.17261"}, {"metadata": {"arXiv": "2310.17379", "Date": "Thu, 26 Oct 2023 13:16:27 ", "Title": "YOLO-BEV: Generating Bird's-Eye View in the Same Way as 2D Object Detection", "Authors": ["Chang Liu", "Liguo Zhou", "Yanliang Huang", "Alois Knoll"], "Categories": "cs.CV cs.AI"}, "abstract": "Vehicle perception systems strive to achieve comprehensive and rapid visual interpretation of their surroundings for improved safety and navigation. We introduce YOLO-BEV, an efficient framework that harnesses a unique surrounding cameras setup to generate a 2D bird's-eye view of the vehicular environment. By strategically positioning eight cameras, each at a 45-degree interval, our system captures and integrates imagery into a coherent 3x3 grid format, leaving the center blank, providing an enriched spatial representation that facilitates efficient processing. In our approach, we employ YOLO's detection mechanism, favoring its inherent advantages of swift response and compact model structure. Instead of leveraging the conventional YOLO detection head, we augment it with a custom-designed detection head, translating the panoramically captured data into a unified bird's-eye view map of ego car. Preliminary results validate the feasibility of YOLO-BEV in real-time vehicular perception tasks. With its streamlined architecture and potential for rapid deployment due to minimized parameters, YOLO-BEV poses as a promising tool that may reshape future perspectives in autonomous driving systems.", "url": "https://arxiv.org/abs/2310.17379"}, {"metadata": {"arXiv": "2310.17421", "Date": "Thu, 26 Oct 2023 14:24:57 ", "Title": "Distribution of Action Movements (DAM): A Descriptor for Human Action Recognition", "Authors": ["Facundo Manuel Quiroga", "Franco Ronchetti", "Laura Lanzarini", "Cesar Eestrebou"], "Categories": "cs.CV cs.AI", "ACM-class": "I.4.8", "DOI": "10.1007/s11704-015-4320-x"}, "abstract": "Human action recognition from skeletal data is an important and active area of research in which the state of the art has not yet achieved near-perfect accuracy on many well-known datasets. In this paper, we introduce the Distribution of Action Movements Descriptor, a novel action descriptor based on the distribution of the directions of the motions of the joints between frames, over the set of all possible motions in the dataset. The descriptor is computed as a normalized histogram over a set of representative directions of the joints, which are in turn obtained via clustering. While the descriptor is global in the sense that it represents the overall distribution of movement directions of an action, it is able to partially retain its temporal structure by applying a windowing scheme. The descriptor, together with a standard classifier, outperforms several state-of-the-art techniques on many well-known datasets.", "url": "https://arxiv.org/abs/2310.17421"}, {"metadata": {"arXiv": "2310.17429", "Date": "Thu, 26 Oct 2023 14:37:01 ", "Title": "LSA64: An Argentinian Sign Language Dataset", "Authors": ["Franco Ronchetti", "Facundo Manuel Quiroga", "C\\'esar Estrebou", "Laura Lanzarini", "Alejandro Rosete"], "Categories": "cs.CV cs.AI", "Comments": ["Published in CACIC XXII"], "ACM-class": "I.5.4"}, "abstract": "Automatic sign language recognition is a research area that encompasses human-computer interaction, computer vision and machine learning. Robust automatic recognition of sign language could assist in the translation process and the integration of hearing-impaired people, as well as the teaching of sign language to the hearing population. Sign languages differ significantly in different countries and even regions, and their syntax and semantics are different as well from those of written languages. While the techniques for automatic sign language recognition are mostly the same for different languages, training a recognition system for a new language requires having an entire dataset for that language. This paper presents a dataset of 64 signs from the Argentinian Sign Language (LSA). The dataset, called LSA64, contains 3200 videos of 64 different LSA signs recorded by 10 subjects, and is a first step towards building a comprehensive research-level dataset of Argentinian signs, specifically tailored to sign language recognition or other machine learning tasks. The subjects that performed the signs wore colored gloves to ease the hand tracking and segmentation steps, allowing experiments on the dataset to focus specifically on the recognition of signs. We also present a pre-processed version of the dataset, from which we computed statistics of movement, position and handshape of the signs.", "url": "https://arxiv.org/abs/2310.17429"}, {"metadata": {"arXiv": "2310.17559", "Date": "Thu, 26 Oct 2023 16:48:36 ", "Title": "Instability of computer vision models is a necessary result of the task itself", "Authors": ["Oliver Turnbull", "George Cevora"], "Categories": "cs.CV cs.AI stat.ML"}, "abstract": "Adversarial examples resulting from instability of current computer vision models are an extremely important topic due to their potential to compromise any application. In this paper we demonstrate that instability is inevitable due to a) symmetries (translational invariance) of the data, b) the categorical nature of the classification task, and c) the fundamental discrepancy of classifying images as objects themselves. The issue is further exacerbated by non-exhaustive labelling of the training data. Therefore we conclude that instability is a necessary result of how the problem of computer vision is currently formulated. While the problem cannot be eliminated, through the analysis of the causes, we have arrived at ways how it can be partially alleviated. These include i) increasing the resolution of images, ii) providing contextual information for the image, iii) exhaustive labelling of training data, and iv) preventing attackers from frequent access to the computer vision system.", "url": "https://arxiv.org/abs/2310.17559"}, {"metadata": {"arXiv": "2310.17594", "Date": "Thu, 26 Oct 2023 17:13:48 ", "Title": "SPA: A Graph Spectral Alignment Perspective for Domain Adaptation", "Authors": ["Zhiqing Xiao", "Haobo Wang", "Ying Jin", "Lei Feng", "Gang Chen", "Fei Huang", "Junbo Zhao"], "Categories": "cs.CV cs.AI"}, "abstract": "Unsupervised domain adaptation (UDA) is a pivotal form in machine learning to extend the in-domain model to the distinctive target domains where the data distributions differ. Most prior works focus on capturing the inter-domain transferability but largely overlook rich intra-domain structures, which empirically results in even worse discriminability. In this work, we introduce a novel graph SPectral Alignment (SPA) framework to tackle the tradeoff. The core of our method is briefly condensed as follows: (i)-by casting the DA problem to graph primitives, SPA composes a coarse graph alignment mechanism with a novel spectral regularizer towards aligning the domain graphs in eigenspaces; (ii)-we further develop a fine-grained message propagation module -- upon a novel neighbor-aware self-training mechanism -- in order for enhanced discriminability in the target domain. On standardized benchmarks, the extensive experiments of SPA demonstrate that its performance has surpassed the existing cutting-edge DA methods. Coupled with dense model analysis, we conclude that our approach indeed possesses superior efficacy, robustness, discriminability, and transferability. Code and data are available at: https://github.com/CrownX/SPA.", "url": "https://arxiv.org/abs/2310.17594"}, {"metadata": {"arXiv": "2310.17091", "Date": "Thu, 26 Oct 2023 01:22:10 ", "Title": "Detecting stealthy cyberattacks on adaptive cruise control vehicles: A machine learning approach", "Authors": ["Tianyi Li", "Mingfeng Shang", "Shian Wang", "Raphael Stern"], "Categories": "cs.MA cs.AI"}, "abstract": "With the advent of vehicles equipped with advanced driver-assistance systems, such as adaptive cruise control (ACC) and other automated driving features, the potential for cyberattacks on these automated vehicles (AVs) has emerged. While overt attacks that force vehicles to collide may be easily identified, more insidious attacks, which only slightly alter driving behavior, can result in network-wide increases in congestion, fuel consumption, and even crash risk without being easily detected. To address the detection of such attacks, we first present a traffic model framework for three types of potential cyberattacks: malicious manipulation of vehicle control commands, false data injection attacks on sensor measurements, and denial-of-service (DoS) attacks. We then investigate the impacts of these attacks at both the individual vehicle (micro) and traffic flow (macro) levels. A novel generative adversarial network (GAN)-based anomaly detection model is proposed for real-time identification of such attacks using vehicle trajectory data. We provide numerical evidence {to demonstrate} the efficacy of our machine learning approach in detecting cyberattacks on ACC-equipped vehicles. The proposed method is compared against some recently proposed neural network models and observed to have higher accuracy in identifying anomalous driving behaviors of ACC vehicles.", "url": "https://arxiv.org/abs/2310.17091"}, {"metadata": {"arXiv": "2310.17064", "Date": "Wed, 25 Oct 2023 23:54:04 ", "Title": "math-PVS: A Large Language Model Framework to Map Scientific Publications to PVS Theories", "Authors": ["Hassen Saidi", "Susmit Jha", "Tuhin Sahai"], "Categories": "cs.AI cs.CL cs.LG cs.LO"}, "abstract": "As artificial intelligence (AI) gains greater adoption in a wide variety of applications, it has immense potential to contribute to mathematical discovery, by guiding conjecture generation, constructing counterexamples, assisting in formalizing mathematics, and discovering connections between different mathematical areas, to name a few. While prior work has leveraged computers for exhaustive mathematical proof search, recent efforts based on large language models (LLMs) aspire to position computing platforms as co-contributors in the mathematical research process. Despite their current limitations in logic and mathematical tasks, there is growing interest in melding theorem proving systems with foundation models. This work investigates the applicability of LLMs in formalizing advanced mathematical concepts and proposes a framework that can critically review and check mathematical reasoning in research papers. Given the noted reasoning shortcomings of LLMs, our approach synergizes the capabilities of proof assistants, specifically PVS, with LLMs, enabling a bridge between textual descriptions in academic papers and formal specifications in PVS. By harnessing the PVS environment, coupled with data ingestion and conversion mechanisms, we envision an automated process, called \\emph{math-PVS}, to extract and formalize mathematical theorems from research papers, offering an innovative tool for academic review and discovery.", "url": "https://arxiv.org/abs/2310.17064"}, {"metadata": {"arXiv": "2310.17072", "Date": "Thu, 26 Oct 2023 00:28:37 ", "Title": "Isometric Motion Manifold Primitives", "Authors": ["Yonghyeon Lee"], "Categories": "cs.AI cs.LG cs.RO", "Comments": ["8 pages", "13 figures. This work has been submitted to the IEEE for possible publication"]}, "abstract": "The Motion Manifold Primitive (MMP) produces, for a given task, a continuous manifold of trajectories each of which can successfully complete the task. It consists of the decoder function that parametrizes the manifold and the probability density in the latent coordinate space. In this paper, we first show that the MMP performance can significantly degrade due to the geometric distortion in the latent space -- by distortion, we mean that similar motions are not located nearby in the latent space. We then propose {\\it Isometric Motion Manifold Primitives (IMMP)} whose latent coordinate space preserves the geometry of the manifold. For this purpose, we formulate and use a Riemannian metric for the motion space (i.e., parametric curve space), which we call a {\\it CurveGeom Riemannian metric}. Experiments with planar obstacle-avoiding motions and pushing manipulation tasks show that IMMP significantly outperforms existing MMP methods. Code is available at https://github.com/Gabe-YHLee/IMMP-public.", "url": "https://arxiv.org/abs/2310.17072"}, {"metadata": {"arXiv": "2310.17178", "Date": "Thu, 26 Oct 2023 06:05:12 ", "Title": "Graphical Object-Centric Actor-Critic", "Authors": ["Leonid Ugadiarov", "Aleksandr I. Panov"], "Categories": "cs.AI cs.LG cs.RO"}, "abstract": "There have recently been significant advances in the problem of unsupervised object-centric representation learning and its application to downstream tasks. The latest works support the argument that employing disentangled object representations in image-based object-centric reinforcement learning tasks facilitates policy learning. We propose a novel object-centric reinforcement learning algorithm combining actor-critic and model-based approaches to utilize these representations effectively. In our approach, we use a transformer encoder to extract object representations and graph neural networks to approximate the dynamics of an environment. The proposed method fills a research gap in developing efficient object-centric world models for reinforcement learning settings that can be used for environments with discrete or continuous action spaces. Our algorithm performs better in a visually complex 3D robotic environment and a 2D environment with compositional structure than the state-of-the-art model-free actor-critic algorithm built upon transformer architecture and the state-of-the-art monolithic model-based algorithm.", "url": "https://arxiv.org/abs/2310.17178"}, {"metadata": {"arXiv": "2310.17492", "Date": "Thu, 26 Oct 2023 15:47:51 ", "Title": "Orchestration of Emulator Assisted Mobile Edge Tuning for AI Foundation Models: A Multi-Agent Deep Reinforcement Learning Approach", "Authors": ["Wenhan Yu", "Terence Jie Chua", "Jun Zhao"], "Categories": "cs.AI cs.DC cs.LG cs.NI"}, "abstract": "The efficient deployment and fine-tuning of foundation models are pivotal in contemporary artificial intelligence. In this study, we present a groundbreaking paradigm integrating Mobile Edge Computing (MEC) with foundation models, specifically designed to enhance local task performance on user equipment (UE). Central to our approach is the innovative Emulator-Adapter architecture, segmenting the foundation model into two cohesive modules. This design not only conserves computational resources but also ensures adaptability and fine-tuning efficiency for downstream tasks. Additionally, we introduce an advanced resource allocation mechanism that is fine-tuned to the needs of the Emulator-Adapter structure in decentralized settings. To address the challenges presented by this system, we employ a hybrid multi-agent Deep Reinforcement Learning (DRL) strategy, adept at handling mixed discrete-continuous action spaces, ensuring dynamic and optimal resource allocations. Our comprehensive simulations and validations underscore the practical viability of our approach, demonstrating its robustness, efficiency, and scalability. Collectively, this work offers a fresh perspective on deploying foundation models and balancing computational efficiency with task proficiency.", "url": "https://arxiv.org/abs/2310.17492"}, {"metadata": {"arXiv": "2310.17537", "Date": "Thu, 26 Oct 2023 16:28:17 ", "Title": "Neuro-Inspired Fragmentation and Recall to Overcome Catastrophic Forgetting in Curiosity", "Authors": ["Jaedong Hwang", "Zhang-Wei Hong", "Eric Chen", "Akhilan Boopathy", "Pulkit Agrawal", "Ila Fiete"], "Categories": "cs.AI cs.LG", "Comments": ["NeurIPS 2023 Workshop - Intrinsically Motivated Open-ended Learning"]}, "abstract": "Deep reinforcement learning methods exhibit impressive performance on a range of tasks but still struggle on hard exploration tasks in large environments with sparse rewards. To address this, intrinsic rewards can be generated using forward model prediction errors that decrease as the environment becomes known, and incentivize an agent to explore novel states. While prediction-based intrinsic rewards can help agents solve hard exploration tasks, they can suffer from catastrophic forgetting and actually increase at visited states. We first examine the conditions and causes of catastrophic forgetting in grid world environments. We then propose a new method FARCuriosity, inspired by how humans and animals learn. The method depends on fragmentation and recall: an agent fragments an environment based on surprisal, and uses different local curiosity modules (prediction-based intrinsic reward functions) for each fragment so that modules are not trained on the entire environment. At each fragmentation event, the agent stores the current module in long-term memory (LTM) and either initializes a new module or recalls a previously stored module based on its match with the current state. With fragmentation and recall, FARCuriosity achieves less forgetting and better overall performance in games with varied and heterogeneous environments in the Atari benchmark suite of tasks. Thus, this work highlights the problem of catastrophic forgetting in prediction-based curiosity methods and proposes a solution.", "url": "https://arxiv.org/abs/2310.17537"}, {"metadata": {"arXiv": "2310.17639", "Date": "Thu, 26 Oct 2023 17:54:52 ", "Title": "In-Context Learning Dynamics with Random Binary Sequences", "Authors": ["Eric J. Bigelow", "Ekdeep Singh Lubana", "Robert P. Dick", "Hidenori Tanaka", "Tomer D. Ullman"], "Categories": "cs.AI cs.CL cs.LG"}, "abstract": "Large language models (LLMs) trained on huge corpora of text datasets demonstrate complex, emergent capabilities, achieving state-of-the-art performance on tasks they were not explicitly trained for. The precise nature of LLM capabilities is often mysterious, and different prompts can elicit different capabilities through in-context learning. We propose a Cognitive Interpretability framework that enables us to analyze in-context learning dynamics to understand latent concepts in LLMs underlying behavioral patterns. This provides a more nuanced understanding than success-or-failure evaluation benchmarks, but does not require observing internal activations as a mechanistic interpretation of circuits would. Inspired by the cognitive science of human randomness perception, we use random binary sequences as context and study dynamics of in-context learning by manipulating properties of context data, such as sequence length. In the latest GPT-3.5+ models, we find emergent abilities to generate pseudo-random numbers and learn basic formal languages, with striking in-context learning dynamics where model outputs transition sharply from pseudo-random behaviors to deterministic repetition.", "url": "https://arxiv.org/abs/2310.17639"}, {"metadata": {"arXiv": "2310.17152", "Date": "Thu, 26 Oct 2023 04:52:25 ", "Title": "Technical Note: Feasibility of translating 3.0T-trained Deep-Learning Segmentation Models Out-of-the-Box on Low-Field MRI 0.55T Knee-MRI of Healthy Controls", "Authors": ["Rupsa Bhattacharjee", "Zehra Akkaya", "Johanna Luitjens", "Pan Su", "Yang Yang", "Valentina Pedoia and Sharmila Majumdar"], "Categories": "cs.CV cs.AI cs.LG q-bio.QM", "Comments": ["11 Pages", "3 Figures", "2 Tables"]}, "abstract": "In the current study, our purpose is to evaluate the feasibility of applying deep learning (DL) enabled algorithms to quantify bilateral knee biomarkers in healthy controls scanned at 0.55T and compared with 3.0T. The current study assesses the performance of standard in-practice bone, and cartilage segmentation algorithms at 0.55T, both qualitatively and quantitatively, in terms of comparing segmentation performance, areas of improvement, and compartment-wise cartilage thickness values between 0.55T vs. 3.0T. Initial results demonstrate a usable to good technical feasibility of translating existing quantitative deep-learning-based image segmentation techniques, trained on 3.0T, out of 0.55T for knee MRI, in a multi-vendor acquisition environment. Especially in terms of segmenting cartilage compartments, the models perform almost equivalent to 3.0T in terms of Likert ranking. The 0.55T low-field sustainable and easy-to-install MRI, as demonstrated, thus, can be utilized for evaluating knee cartilage thickness and bone segmentations aided by established DL algorithms trained at higher-field strengths out-of-the-box initially. This could be utilized at the far-spread point-of-care locations with a lack of radiologists available to manually segment low-field images, at least till a decent base of low-field data pool is collated. With further fine-tuning with manual labeling of low-field data or utilizing synthesized higher SNR images from low-field images, OA biomarker quantification performance is potentially guaranteed to be further improved.", "url": "https://arxiv.org/abs/2310.17152"}, {"metadata": {"arXiv": "2310.17176", "Date": "Thu, 26 Oct 2023 06:01:25 ", "Title": "A Deep Learning Approach to Teeth Segmentation and Orientation from Panoramic X-rays", "Authors": ["Mrinal Kanti Dhar", "Mou Deb", "D. Madhab", "and Zeyun Yu"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Accurate teeth segmentation and orientation are fundamental in modern oral healthcare, enabling precise diagnosis, treatment planning, and dental implant design. In this study, we present a comprehensive approach to teeth segmentation and orientation from panoramic X-ray images, leveraging deep learning techniques. We build our model based on FUSegNet, a popular model originally developed for wound segmentation, and introduce modifications by incorporating grid-based attention gates into the skip connections. We introduce oriented bounding box (OBB) generation through principal component analysis (PCA) for precise tooth orientation estimation. Evaluating our approach on the publicly available DNS dataset, comprising 543 panoramic X-ray images, we achieve the highest Intersection-over-Union (IoU) score of 82.43% and Dice Similarity Coefficient (DSC) score of 90.37% among compared models in teeth instance segmentation. In OBB analysis, we obtain the Rotated IoU (RIoU) score of 82.82%. We also conduct detailed analyses of individual tooth labels and categorical performance, shedding light on strengths and weaknesses. The proposed model's accuracy and versatility offer promising prospects for improving dental diagnoses, treatment planning, and personalized healthcare in the oral domain. Our generated OBB coordinates and codes are available at https://github.com/mrinal054/Instance_teeth_segmentation.", "url": "https://arxiv.org/abs/2310.17176"}, {"metadata": {"arXiv": "2310.17427", "Date": "Thu, 26 Oct 2023 14:32:44 ", "Title": "Handshape recognition for Argentinian Sign Language using ProbSom", "Authors": ["Franco Ronchetti", "Facundo Manuel Quiroga", "C\\'esar Estrebou", "and Laura Lanzarini"], "Categories": "cs.CV cs.AI cs.LG cs.NE", "Journal-ref": "Journal of Computer Science and Technology, 2016"}, "abstract": "Automatic sign language recognition is an important topic within the areas of human-computer interaction and machine learning. On the one hand, it poses a complex challenge that requires the intervention of various knowledge areas, such as video processing, image processing, intelligent systems and linguistics. On the other hand, robust recognition of sign language could assist in the translation process and the integration of hearing-impaired people. This paper offers two main contributions: first, the creation of a database of handshapes for the Argentinian Sign Language (LSA), which is a topic that has barely been discussed so far. Secondly, a technique for image processing, descriptor extraction and subsequent handshape classification using a supervised adaptation of self-organizing maps that is called ProbSom. This technique is compared to others in the state of the art, such as Support Vector Machines (SVM), Random Forests, and Neural Networks. The database that was built contains 800 images with 16 LSA handshapes, and is a first step towards building a comprehensive database of Argentinian signs. The ProbSom-based neural classifier, using the proposed descriptor, achieved an accuracy rate above 90%.", "url": "https://arxiv.org/abs/2310.17427"}, {"metadata": {"arXiv": "2310.17462", "Date": "Thu, 26 Oct 2023 15:10:10 ", "Title": "Towards Learning Monocular 3D Object Localization From 2D Labels using the Physical Laws of Motion", "Authors": ["Daniel Kienzle", "Julian Lorenz", "Katja Ludwig", "Rainer Lienhart"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "We present a novel method for precise 3D object localization in single images from a single calibrated camera using only 2D labels. No expensive 3D labels are needed. Thus, instead of using 3D labels, our model is trained with easy-to-annotate 2D labels along with the physical knowledge of the object's motion. Given this information, the model can infer the latent third dimension, even though it has never seen this information during training. Our method is evaluated on both synthetic and real-world datasets, and we are able to achieve a mean distance error of just 6 cm in our experiments on real data. The results indicate the method's potential as a step towards learning 3D object location estimation, where collecting 3D data for training is not feasible.", "url": "https://arxiv.org/abs/2310.17462"}, {"metadata": {"arXiv": "2310.16867", "Date": "Wed, 25 Oct 2023 12:55:16 ", "Title": "An Explainable Deep Learning-Based Method For Schizophrenia Diagnosis Using Generative Data-Augmentation", "Authors": ["Mehrshad Saadatinia", "Armin Salimi-Badr"], "Categories": "cs.LG cs.AI eess.IV"}, "abstract": "In this study, we leverage a deep learning-based method for the automatic diagnosis of schizophrenia using EEG brain recordings. This approach utilizes generative data augmentation, a powerful technique that enhances the accuracy of the diagnosis. To enable the utilization of time-frequency features, spectrograms were extracted from the raw signals. After exploring several neural network architectural setups, a proper convolutional neural network (CNN) was used for the initial diagnosis. Subsequently, using Wasserstein GAN with Gradient Penalty (WGAN-GP) and Variational Autoencoder (VAE), two different synthetic datasets were generated in order to augment the initial dataset and address the over-fitting issue. The augmented dataset using VAE achieved a 3.0\\% improvement in accuracy reaching up to 99.0\\% and yielded a lower loss value as well as a faster convergence. Finally, we addressed the lack of trust in black-box models using the Local Interpretable Model-agnostic Explanations (LIME) algorithm to determine the most important superpixels (frequencies) in the diagnosis process.", "url": "https://arxiv.org/abs/2310.16867"}, {"metadata": {"arXiv": "2310.16978", "Date": "Wed, 25 Oct 2023 20:28:22 ", "Title": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review", "Authors": ["S M Atikur Rahman", "Sifat Ibtisum", "Ehsan Bazgir", "Tumpa Barai"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["8 pages"], "Journal-ref": "International Journal of Computer Applications 185(36):10-17, October 2023", "DOI": "10.5120/ijca2023923147"}, "abstract": "The global need for effective disease diagnosis remains substantial, given the complexities of various disease mechanisms and diverse patient symptoms. To tackle these challenges, researchers, physicians, and patients are turning to machine learning (ML), an artificial intelligence (AI) discipline, to develop solutions. By leveraging sophisticated ML and AI methods, healthcare stakeholders gain enhanced diagnostic and treatment capabilities. However, there is a scarcity of research focused on ML algorithms for enhancing the accuracy and computational efficiency. This research investigates the capacity of machine learning algorithms to improve the transmission of heart rate data in time series healthcare metrics, concentrating particularly on optimizing accuracy and efficiency. By exploring various ML algorithms used in healthcare applications, the review presents the latest trends and approaches in ML-based disease diagnosis (MLBDD). The factors under consideration include the algorithm utilized, the types of diseases targeted, the data types employed, the applications, and the evaluation metrics. This review aims to shed light on the prospects of ML in healthcare, particularly in disease diagnosis. By analyzing the current literature, the study provides insights into state-of-the-art methodologies and their performance metrics.", "url": "https://arxiv.org/abs/2310.16978"}, {"metadata": {"arXiv": "2310.17022", "Date": "Wed, 25 Oct 2023 22:00:05 ", "Title": "Controlled Decoding from Language Models", "Authors": ["Sidharth Mudgal and Jong Lee and Harish Ganapathy and YaGuang Li and Tao Wang and Yanping Huang and Zhifeng Chen and Heng-Tze Cheng and Michael Collins and Trevor Strohman and Jilin Chen and Alex Beutel and Ahmad Beirami"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "We propose controlled decoding (CD), a novel off-policy reinforcement learning method to control the autoregressive generation from language models towards high reward outcomes. CD solves an off-policy reinforcement learning problem through a value function for the reward, which we call a prefix scorer. The prefix scorer is used at inference time to steer the generation towards higher reward outcomes. We show that the prefix scorer may be trained on (possibly) off-policy data to predict the expected reward when decoding is continued from a partially decoded response. We empirically demonstrate that CD is effective as a control mechanism on Reddit conversations corpus. We also show that the modularity of the design of CD makes it possible to control for multiple rewards, effectively solving a multi-objective reinforcement learning problem with no additional complexity. Finally, we show that CD can be applied in a novel blockwise fashion at inference-time, again without the need for any training-time changes, essentially bridging the gap between the popular best-of-$K$ strategy and token-level reinforcement learning. This makes CD a promising approach for alignment of language models.", "url": "https://arxiv.org/abs/2310.17022"}, {"metadata": {"arXiv": "2310.17042", "Date": "Wed, 25 Oct 2023 22:45:31 ", "Title": "StochGradAdam: Accelerating Neural Networks Training with Stochastic Gradient Sampling", "Authors": ["Juyoung Yun"], "Categories": "cs.LG cs.AI cs.CV cs.NE"}, "abstract": "In the rapidly advancing domain of deep learning optimization, this paper unveils the StochGradAdam optimizer, a novel adaptation of the well-regarded Adam algorithm. Central to StochGradAdam is its gradient sampling technique. This method not only ensures stable convergence but also leverages the advantages of selective gradient consideration, fostering robust training by potentially mitigating the effects of noisy or outlier data and enhancing the exploration of the loss landscape for more dependable convergence. In both image classification and segmentation tasks, StochGradAdam has demonstrated superior performance compared to the traditional Adam optimizer. By judiciously sampling a subset of gradients at each iteration, the optimizer is optimized for managing intricate models. The paper provides a comprehensive exploration of StochGradAdam's methodology, from its mathematical foundations to bias correction strategies, heralding a promising advancement in deep learning training techniques.", "url": "https://arxiv.org/abs/2310.17042"}, {"metadata": {"arXiv": "2310.17086", "Date": "Thu, 26 Oct 2023 01:08:47 ", "Title": "Transformers Learn Higher-Order Optimization Methods for In-Context Learning: A Study with Linear Models", "Authors": ["Deqing Fu", "Tian-Qi Chen", "Robin Jia", "Vatsal Sharan"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "Transformers are remarkably good at in-context learning (ICL) -- learning from demonstrations without parameter updates -- but how they perform ICL remains a mystery. Recent work suggests that Transformers may learn in-context by internally running Gradient Descent, a first-order optimization method. In this paper, we instead demonstrate that Transformers learn to implement higher-order optimization methods to perform ICL. Focusing on in-context linear regression, we show that Transformers learn to implement an algorithm very similar to Iterative Newton's Method, a higher-order optimization method, rather than Gradient Descent. Empirically, we show that predictions from successive Transformer layers closely match different iterations of Newton's Method linearly, with each middle layer roughly computing 3 iterations. In contrast, exponentially more Gradient Descent steps are needed to match an additional Transformers layer; this suggests that Transformers have an comparable rate of convergence with high-order methods such as Iterative Newton, which are exponentially faster than Gradient Descent. We also show that Transformers can learn in-context on ill-conditioned data, a setting where Gradient Descent struggles but Iterative Newton succeeds. Finally, we show theoretical results which support our empirical findings and have a close correspondence with them: we prove that Transformers can implement $k$ iterations of Newton's method with $\\mathcal{O}(k)$ layers.", "url": "https://arxiv.org/abs/2310.17086"}, {"metadata": {"arXiv": "2310.17132", "Date": "Thu, 26 Oct 2023 04:11:49 ", "Title": "Unleashing the potential of GNNs via Bi-directional Knowledge Transfer", "Authors": ["Shuai Zheng", "Zhizhe Liu", "Zhenfeng Zhu", "Xingxing Zhang", "Jianxin Li", "and Yao Zhao"], "Categories": "cs.LG cs.AI cs.NE", "Comments": ["13 pages", "9 figures"]}, "abstract": "Based on the message-passing paradigm, there has been an amount of research proposing diverse and impressive feature propagation mechanisms to improve the performance of GNNs. However, less focus has been put on feature transformation, another major operation of the message-passing framework. In this paper, we first empirically investigate the performance of the feature transformation operation in several typical GNNs. Unexpectedly, we notice that GNNs do not completely free up the power of the inherent feature transformation operation. By this observation, we propose the Bi-directional Knowledge Transfer (BiKT), a plug-and-play approach to unleash the potential of the feature transformation operations without modifying the original architecture. Taking the feature transformation operation as a derived representation learning model that shares parameters with the original GNN, the direct prediction by this model provides a topological-agnostic knowledge feedback that can further instruct the learning of GNN and the feature transformations therein. On this basis, BiKT not only allows us to acquire knowledge from both the GNN and its derived model but promotes each other by injecting the knowledge into the other. In addition, a theoretical analysis is further provided to demonstrate that BiKT improves the generalization bound of the GNNs from the perspective of domain adaption. An extensive group of experiments on up to 7 datasets with 5 typical GNNs demonstrates that BiKT brings up to 0.5% - 4% performance gain over the original GNN, which means a boosted GNN is obtained. Meanwhile, the derived model also shows a powerful performance to compete with or even surpass the original GNN, enabling us to flexibly apply it independently to some other specific downstream tasks.", "url": "https://arxiv.org/abs/2310.17132"}, {"metadata": {"arXiv": "2310.17146", "Date": "Thu, 26 Oct 2023 04:41:19 ", "Title": "Counterfactual-Augmented Importance Sampling for Semi-Offline Policy Evaluation", "Authors": ["Shengpu Tang", "Jenna Wiens"], "Categories": "cs.LG cs.AI", "Comments": ["36 pages", "12 figures", "5 tables. NeurIPS 2023. Code available at https://github.com/MLD3/CounterfactualAnnot-SemiOPE"]}, "abstract": "In applying reinforcement learning (RL) to high-stakes domains, quantitative and qualitative evaluation using observational data can help practitioners understand the generalization performance of new policies. However, this type of off-policy evaluation (OPE) is inherently limited since offline data may not reflect the distribution shifts resulting from the application of new policies. On the other hand, online evaluation by collecting rollouts according to the new policy is often infeasible, as deploying new policies in these domains can be unsafe. In this work, we propose a semi-offline evaluation framework as an intermediate step between offline and online evaluation, where human users provide annotations of unobserved counterfactual trajectories. While tempting to simply augment existing data with such annotations, we show that this naive approach can lead to biased results. Instead, we design a new family of OPE estimators based on importance sampling (IS) and a novel weighting scheme that incorporate counterfactual annotations without introducing additional bias. We analyze the theoretical properties of our approach, showing its potential to reduce both bias and variance compared to standard IS estimators. Our analyses reveal important practical considerations for handling biased, noisy, or missing annotations. In a series of proof-of-concept experiments involving bandits and a healthcare-inspired simulator, we demonstrate that our approach outperforms purely offline IS estimators and is robust to imperfect annotations. Our framework, combined with principled human-centered design of annotation solicitation, can enable the application of RL in high-stakes domains.", "url": "https://arxiv.org/abs/2310.17146"}, {"metadata": {"arXiv": "2310.17149", "Date": "Thu, 26 Oct 2023 04:47:28 ", "Title": "Explainable Spatio-Temporal Graph Neural Networks", "Authors": ["Jiabin Tang and Lianghao Xia and Chao Huang"], "Categories": "cs.LG cs.AI", "Comments": ["32nd ACM International Conference on Information and Knowledge Management (CIKM' 23)"]}, "abstract": "Spatio-temporal graph neural networks (STGNNs) have gained popularity as a powerful tool for effectively modeling spatio-temporal dependencies in diverse real-world urban applications, including intelligent transportation and public safety. However, the black-box nature of STGNNs limits their interpretability, hindering their application in scenarios related to urban resource allocation and policy formulation. To bridge this gap, we propose an Explainable Spatio-Temporal Graph Neural Networks (STExplainer) framework that enhances STGNNs with inherent explainability, enabling them to provide accurate predictions and faithful explanations simultaneously. Our framework integrates a unified spatio-temporal graph attention network with a positional information fusion layer as the STG encoder and decoder, respectively. Furthermore, we propose a structure distillation approach based on the Graph Information Bottleneck (GIB) principle with an explainable objective, which is instantiated by the STG encoder and decoder. Through extensive experiments, we demonstrate that our STExplainer outperforms state-of-the-art baselines in terms of predictive accuracy and explainability metrics (i.e., sparsity and fidelity) on traffic and crime prediction tasks. Furthermore, our model exhibits superior representation ability in alleviating data missing and sparsity issues. The implementation code is available at: https://github.com/HKUDS/STExplainer.", "url": "https://arxiv.org/abs/2310.17149"}, {"metadata": {"arXiv": "2310.17167", "Date": "Thu, 26 Oct 2023 05:43:07 ", "Title": "Improving Denoising Diffusion Models via Simultaneous Estimation of Image and Noise", "Authors": ["Zhenkai Zhang", "Krista A. Ehinger and Tom Drummond"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "This paper introduces two key contributions aimed at improving the speed and quality of images generated through inverse diffusion processes. The first contribution involves reparameterizing the diffusion process in terms of the angle on a quarter-circular arc between the image and noise, specifically setting the conventional $\\displaystyle \\sqrt{\\bar{\\alpha}}=\\cos(\\eta)$. This reparameterization eliminates two singularities and allows for the expression of diffusion evolution as a well-behaved ordinary differential equation (ODE). In turn, this allows higher order ODE solvers such as Runge-Kutta methods to be used effectively. The second contribution is to directly estimate both the image ($\\mathbf{x}_0$) and noise ($\\mathbf{\\epsilon}$) using our network, which enables more stable calculations of the update step in the inverse diffusion steps, as accurate estimation of both the image and noise are crucial at different stages of the process. Together with these changes, our model achieves faster generation, with the ability to converge on high-quality images more quickly, and higher quality of the generated images, as measured by metrics such as Frechet Inception Distance (FID), spatial Frechet Inception Distance (sFID), precision, and recall.", "url": "https://arxiv.org/abs/2310.17167"}, {"metadata": {"arXiv": "2310.17191", "Date": "Thu, 26 Oct 2023 07:10:31 ", "Title": "How do Language Models Bind Entities in Context?", "Authors": ["Jiahai Feng", "Jacob Steinhardt"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "To correctly use in-context information, language models (LMs) must bind entities to their attributes. For example, given a context describing a \"green square\" and a \"blue circle\", LMs must bind the shapes to their respective colors. We analyze LM representations and identify the binding ID mechanism: a general mechanism for solving the binding problem, which we observe in every sufficiently large model from the Pythia and LLaMA families. Using causal interventions, we show that LMs' internal activations represent binding information by attaching binding ID vectors to corresponding entities and attributes. We further show that binding ID vectors form a continuous subspace, in which distances between binding ID vectors reflect their discernability. Overall, our results uncover interpretable strategies in LMs for representing symbolic knowledge in-context, providing a step towards understanding general in-context reasoning in large-scale LMs.", "url": "https://arxiv.org/abs/2310.17191"}, {"metadata": {"arXiv": "2310.17200", "Date": "Thu, 26 Oct 2023 07:32:52 ", "Title": "Taming Gradient Variance in Federated Learning with Networked Control Variates", "Authors": ["Xingyan Chen", "Yaling Liu", "Huaming Du", "Mu Wang", "Yu Zhao"], "Categories": "cs.LG cs.AI cs.DC", "Comments": ["14 pages"]}, "abstract": "Federated learning, a decentralized approach to machine learning, faces significant challenges such as extensive communication overheads, slow convergence, and unstable improvements. These challenges primarily stem from the gradient variance due to heterogeneous client data distributions. To address this, we introduce a novel Networked Control Variates (FedNCV) framework for Federated Learning. We adopt the REINFORCE Leave-One-Out (RLOO) as a fundamental control variate unit in the FedNCV framework, implemented at both client and server levels. At the client level, the RLOO control variate is employed to optimize local gradient updates, mitigating the variance introduced by data samples. Once relayed to the server, the RLOO-based estimator further provides an unbiased and low-variance aggregated gradient, leading to robust global updates. This dual-side application is formalized as a linear combination of composite control variates. We provide a mathematical expression capturing this integration of double control variates within FedNCV and present three theoretical results with corresponding proofs. This unique dual structure equips FedNCV to address data heterogeneity and scalability issues, thus potentially paving the way for large-scale applications. Moreover, we tested FedNCV on six diverse datasets under a Dirichlet distribution with {\\alpha} = 0.1, and benchmarked its performance against six SOTA methods, demonstrating its superiority.", "url": "https://arxiv.org/abs/2310.17200"}, {"metadata": {"arXiv": "2310.17245", "Date": "Thu, 26 Oct 2023 08:45:23 ", "Title": "CROP: Conservative Reward for Model-based Offline Policy Optimization", "Authors": ["Hao Li", "Xiao-Hu Zhou", "Xiao-Liang Xie", "Shi-Qi Liu", "Zhen-Qiu Feng", "Xiao-Yin Liu", "Mei-Jiang Gui", "Tian-Yu Xiang", "De-Xing Huang", "Bo-Xian Yao", "Zeng-Guang Hou"], "Categories": "cs.LG cs.AI"}, "abstract": "Offline reinforcement learning (RL) aims to optimize policy using collected data without online interactions. Model-based approaches are particularly appealing for addressing offline RL challenges due to their capability to mitigate the limitations of offline data through data generation using models. Prior research has demonstrated that introducing conservatism into the model or Q-function during policy optimization can effectively alleviate the prevalent distribution drift problem in offline RL. However, the investigation into the impacts of conservatism in reward estimation is still lacking. This paper proposes a novel model-based offline RL algorithm, Conservative Reward for model-based Offline Policy optimization (CROP), which conservatively estimates the reward in model training. To achieve a conservative reward estimation, CROP simultaneously minimizes the estimation error and the reward of random actions. Theoretical analysis shows that this conservative reward mechanism leads to a conservative policy evaluation and helps mitigate distribution drift. Experiments on D4RL benchmarks showcase that the performance of CROP is comparable to the state-of-the-art baselines. Notably, CROP establishes an innovative connection between offline and online RL, highlighting that offline RL problems can be tackled by adopting online RL techniques to the empirical Markov decision process trained with a conservative reward. The source code is available with https://github.com/G0K0URURI/CROP.git.", "url": "https://arxiv.org/abs/2310.17245"}, {"metadata": {"arXiv": "2310.17250", "Date": "Thu, 26 Oct 2023 08:58:29 ", "Title": "IDENAS: Internal Dependency Exploration for Neural Architecture Search", "Authors": ["Anh T. Hoang", "Zsolt J. Viharos"], "Categories": "cs.LG cs.AI cs.NE", "Comments": ["57 pages", "19 figures + appendix", "the related software code can be found under the link: https://github.com/viharoszsolt/IDENAS"], "MSC-class": "68T07, 68T10, 93A10", "ACM-class": "I.5.2; I.5.1; I.2.6"}, "abstract": "Machine learning is a powerful tool for extracting valuable information and making various predictions from diverse datasets. Traditional algorithms rely on well-defined input and output variables however, there are scenarios where the distinction between the input and output variables and the underlying, associated (input and output) layers of the model, are unknown. Neural Architecture Search (NAS) and Feature Selection have emerged as promising solutions in such scenarios. This research proposes IDENAS, an Internal Dependency-based Exploration for Neural Architecture Search, integrating NAS with feature selection. The methodology explores internal dependencies in the complete parameter space for classification involving 1D sensor and 2D image data as well. IDENAS employs a modified encoder-decoder model and the Sequential Forward Search (SFS) algorithm, combining input-output configuration search with embedded feature selection. Experimental results demonstrate IDENASs superior performance in comparison to other algorithms, showcasing its effectiveness in model development pipelines and automated machine learning. On average, IDENAS achieved significant modelling improvements, underscoring its significant contribution to advancing the state-of-the-art in neural architecture search and feature selection integration.", "url": "https://arxiv.org/abs/2310.17250"}, {"metadata": {"arXiv": "2310.17325", "Date": "Thu, 26 Oct 2023 11:44:42 ", "Title": "C-Disentanglement: Discovering Causally-Independent Generative Factors under an Inductive Bias of Confounder", "Authors": ["Xiaoyu Liu", "Jiaxin Yuan", "Bang An", "Yuancheng Xu", "Yifan Yang", "Furong Huang"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["accepted to Neurips 2023"]}, "abstract": "Representation learning assumes that real-world data is generated by a few semantically meaningful generative factors (i.e., sources of variation) and aims to discover them in the latent space. These factors are expected to be causally disentangled, meaning that distinct factors are encoded into separate latent variables, and changes in one factor will not affect the values of the others. Compared to statistical independence, causal disentanglement allows more controllable data generation, improved robustness, and better generalization. However, most existing work assumes unconfoundedness in the discovery process, that there are no common causes to the generative factors and thus obtain only statistical independence. In this paper, we recognize the importance of modeling confounders in discovering causal generative factors. Unfortunately, such factors are not identifiable without proper inductive bias. We fill the gap by introducing a framework entitled Confounded-Disentanglement (C-Disentanglement), the first framework that explicitly introduces the inductive bias of confounder via labels from domain expertise. In addition, we accordingly propose an approach to sufficiently identify the causally disentangled factors under any inductive bias of the confounder. We conduct extensive experiments on both synthetic and real-world datasets. Our method demonstrates competitive results compared to various SOTA baselines in obtaining causally disentangled features and downstream tasks under domain shifts.", "url": "https://arxiv.org/abs/2310.17325"}, {"metadata": {"arXiv": "2310.17330", "Date": "Thu, 26 Oct 2023 11:50:58 ", "Title": "CQM: Curriculum Reinforcement Learning with a Quantized World Model", "Authors": ["Seungjae Lee", "Daesol Cho", "Jonghae Park", "H. Jin Kim"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted to NeurIPS 2023"]}, "abstract": "Recent curriculum Reinforcement Learning (RL) has shown notable progress in solving complex tasks by proposing sequences of surrogate tasks. However, the previous approaches often face challenges when they generate curriculum goals in a high-dimensional space. Thus, they usually rely on manually specified goal spaces. To alleviate this limitation and improve the scalability of the curriculum, we propose a novel curriculum method that automatically defines the semantic goal space which contains vital information for the curriculum process, and suggests curriculum goals over it. To define the semantic goal space, our method discretizes continuous observations via vector quantized-variational autoencoders (VQ-VAE) and restores the temporal relations between the discretized observations by a graph. Concurrently, ours suggests uncertainty and temporal distance-aware curriculum goals that converges to the final goals over the automatically composed goal space. We demonstrate that the proposed method allows efficient explorations in an uninformed environment with raw goal examples only. Also, ours outperforms the state-of-the-art curriculum RL methods on data efficiency and performance, in various goal-reaching tasks even with ego-centric visual inputs.", "url": "https://arxiv.org/abs/2310.17330"}, {"metadata": {"arXiv": "2310.17378", "Date": "Thu, 26 Oct 2023 13:14:13 ", "Title": "Optimization dependent generalization bound for ReLU networks based on sensitivity in the tangent bundle", "Authors": ["D\\'aniel R\\'acz", "Mih\\'aly Petreczky", "Andr\\'as Csert\\'an", "B\\'alint Dar\\'oczy"], "Categories": "cs.LG cs.AI", "Comments": ["17 pages", "5 figures", "OPT2023: 15th Annual Workshop on Optimization for Machine Learning at the 37th NeurIPS 2023", "New Orleans", "LA", "USA"], "MSC-class": "68", "ACM-class": "I.2.6"}, "abstract": "Recent advances in deep learning have given us some very promising results on the generalization ability of deep neural networks, however literature still lacks a comprehensive theory explaining why heavily over-parametrized models are able to generalize well while fitting the training data. In this paper we propose a PAC type bound on the generalization error of feedforward ReLU networks via estimating the Rademacher complexity of the set of networks available from an initial parameter vector via gradient descent. The key idea is to bound the sensitivity of the network's gradient to perturbation of the input data along the optimization trajectory. The obtained bound does not explicitly depend on the depth of the network. Our results are experimentally verified on the MNIST and CIFAR-10 datasets.", "url": "https://arxiv.org/abs/2310.17378"}, {"metadata": {"arXiv": "2310.17404", "Date": "Thu, 26 Oct 2023 13:59:39 ", "Title": "Invariance Measures for Neural Networks", "Authors": ["Facundo Manuel Quiroga and Jordina Torrents-Barrena and Laura Cristina Lanzarini and Domenec Puig-Valls"], "Categories": "cs.LG cs.AI cs.NE", "Journal-ref": "Applied Soft Computing, 2023", "DOI": "10.1016/j.asoc.2022.109817"}, "abstract": "Invariances in neural networks are useful and necessary for many tasks. However, the representation of the invariance of most neural network models has not been characterized. We propose measures to quantify the invariance of neural networks in terms of their internal representation. The measures are efficient and interpretable, and can be applied to any neural network model. They are also more sensitive to invariance than previously defined measures. We validate the measures and their properties in the domain of affine transformations and the CIFAR10 and MNIST datasets, including their stability and interpretability. Using the measures, we perform a first analysis of CNN models and show that their internal invariance is remarkably stable to random weight initializations, but not to changes in dataset or transformation. We believe the measures will enable new avenues of research in invariance representation.", "url": "https://arxiv.org/abs/2310.17404"}, {"metadata": {"arXiv": "2310.17513", "Date": "Thu, 26 Oct 2023 16:08:33 ", "Title": "The Expressive Power of Low-Rank Adaptation", "Authors": ["Yuchen Zeng", "Kangwook Lee"], "Categories": "cs.LG cs.AI cs.CL stat.ML", "Comments": ["40 pages,5 figures"]}, "abstract": "Low-Rank Adaptation (LoRA), a parameter-efficient fine-tuning method that leverages low-rank adaptation of weight matrices, has emerged as a prevalent technique for fine-tuning pre-trained models such as large language models and diffusion models. Despite its huge success in practice, the theoretical underpinnings of LoRA have largely remained unexplored. This paper takes the first step to bridge this gap by theoretically analyzing the expressive power of LoRA. We prove that, for fully connected neural networks, LoRA can adapt any model $f$ to accurately represent any smaller target model $\\overline{f}$ if LoRA-rank $\\geq(\\text{width of }f) \\times \\frac{\\text{depth of }\\overline{f}}{\\text{depth of }f}$. We also quantify the approximation error when LoRA-rank is lower than the threshold. For Transformer networks, we show any model can be adapted to a target model of the same size with rank-$(\\frac{\\text{embedding size}}{2})$ LoRA adapters.", "url": "https://arxiv.org/abs/2310.17513"}, {"metadata": {"arXiv": "2310.17550", "Date": "Thu, 26 Oct 2023 16:45:34 ", "Title": "Human-Guided Complexity-Controlled Abstractions", "Authors": ["Andi Peng", "Mycal Tucker", "Eoin Kenny", "Noga Zaslavsky", "Pulkit Agrawal", "Julie Shah"], "Categories": "cs.LG cs.AI", "Comments": ["NeurIPS 2023"]}, "abstract": "Neural networks often learn task-specific latent representations that fail to generalize to novel settings or tasks. Conversely, humans learn discrete representations (i.e., concepts or words) at a variety of abstraction levels (e.g., ``bird'' vs. ``sparrow'') and deploy the appropriate abstraction based on task. Inspired by this, we train neural models to generate a spectrum of discrete representations, and control the complexity of the representations (roughly, how many bits are allocated for encoding inputs) by tuning the entropy of the distribution over representations. In finetuning experiments, using only a small number of labeled examples for a new task, we show that (1) tuning the representation to a task-appropriate complexity level supports the highest finetuning performance, and (2) in a human-participant study, users were able to identify the appropriate complexity level for a downstream task using visualizations of discrete representations. Our results indicate a promising direction for rapid model finetuning by leveraging human insight.", "url": "https://arxiv.org/abs/2310.17550"}, {"metadata": {"arXiv": "2310.17561", "Date": "Thu, 26 Oct 2023 16:49:44 ", "Title": "Bifurcations and loss jumps in RNN training", "Authors": ["Lukas Eisenmann", "Zahra Monfared", "Niclas Alexander G\\\"oring", "Daniel Durstewitz"], "Categories": "cs.LG cs.AI math.DS"}, "abstract": "Recurrent neural networks (RNNs) are popular machine learning tools for modeling and forecasting sequential data and for inferring dynamical systems (DS) from observed time series. Concepts from DS theory (DST) have variously been used to further our understanding of both, how trained RNNs solve complex tasks, and the training process itself. Bifurcations are particularly important phenomena in DS, including RNNs, that refer to topological (qualitative) changes in a system's dynamical behavior as one or more of its parameters are varied. Knowing the bifurcation structure of an RNN will thus allow to deduce many of its computational and dynamical properties, like its sensitivity to parameter variations or its behavior during training. In particular, bifurcations may account for sudden loss jumps observed in RNN training that could severely impede the training process. Here we first mathematically prove for a particular class of ReLU-based RNNs that certain bifurcations are indeed associated with loss gradients tending toward infinity or zero. We then introduce a novel heuristic algorithm for detecting all fixed points and k-cycles in ReLU-based RNNs and their existence and stability regions, hence bifurcation manifolds in parameter space. In contrast to previous numerical algorithms for finding fixed points and common continuation methods, our algorithm provides exact results and returns fixed points and cycles up to high orders with surprisingly good scaling behavior. We exemplify the algorithm on the analysis of the training process of RNNs, and find that the recently introduced technique of generalized teacher forcing completely avoids certain types of bifurcations in training. Thus, besides facilitating the DST analysis of trained RNNs, our algorithm provides a powerful instrument for analyzing the training process itself.", "url": "https://arxiv.org/abs/2310.17561"}, {"metadata": {"arXiv": "2310.17645", "Date": "Thu, 26 Oct 2023 17:58:08 ", "Title": "Defending Against Transfer Attacks From Public Models", "Authors": ["Chawin Sitawarin", "Jaewon Chang", "David Huang", "Wesson Altoyan", "David Wagner"], "Categories": "cs.LG cs.AI cs.CR cs.CV", "Comments": ["Under submission. Code available at https://github.com/wagner-group/pubdef"]}, "abstract": "Adversarial attacks have been a looming and unaddressed threat in the industry. However, through a decade-long history of the robustness evaluation literature, we have learned that mounting a strong or optimal attack is challenging. It requires both machine learning and domain expertise. In other words, the white-box threat model, religiously assumed by a large majority of the past literature, is unrealistic. In this paper, we propose a new practical threat model where the adversary relies on transfer attacks through publicly available surrogate models. We argue that this setting will become the most prevalent for security-sensitive applications in the future. We evaluate the transfer attacks in this setting and propose a specialized defense method based on a game-theoretic perspective. The defenses are evaluated under 24 public models and 11 attack algorithms across three datasets (CIFAR-10, CIFAR-100, and ImageNet). Under this threat model, our defense, PubDef, outperforms the state-of-the-art white-box adversarial training by a large margin with almost no loss in the normal accuracy. For instance, on ImageNet, our defense achieves 62% accuracy under the strongest transfer attack vs only 36% of the best adversarially trained model. Its accuracy when not under attack is only 2% lower than that of an undefended model (78% vs 80%). We release our code at https://github.com/wagner-group/pubdef.", "url": "https://arxiv.org/abs/2310.17645"}, {"metadata": {"arXiv": "2310.17552", "Date": "Thu, 26 Oct 2023 16:45:44 ", "Title": "Model-Based Runtime Monitoring with Interactive Imitation Learning", "Authors": ["Huihan Liu", "Shivin Dass", "Roberto Mart\\'in-Mart\\'in", "Yuke Zhu"], "Categories": "cs.RO cs.AI cs.LG"}, "abstract": "Robot learning methods have recently made great strides, but generalization and robustness challenges still hinder their widespread deployment. Failing to detect and address potential failures renders state-of-the-art learning systems not combat-ready for high-stakes tasks. Recent advances in interactive imitation learning have presented a promising framework for human-robot teaming, enabling the robots to operate safely and continually improve their performances over long-term deployments. Nonetheless, existing methods typically require constant human supervision and preemptive feedback, limiting their practicality in realistic domains. This work aims to endow a robot with the ability to monitor and detect errors during task execution. We introduce a model-based runtime monitoring algorithm that learns from deployment data to detect system anomalies and anticipate failures. Unlike prior work that cannot foresee future failures or requires failure experiences for training, our method learns a latent-space dynamics model and a failure classifier, enabling our method to simulate future action outcomes and detect out-of-distribution and high-risk states preemptively. We train our method within an interactive imitation learning framework, where it continually updates the model from the experiences of the human-robot team collected using trustworthy deployments. Consequently, our method reduces the human workload needed over time while ensuring reliable task execution. Our method outperforms the baselines across system-level and unit-test metrics, with 23% and 40% higher success rates in simulation and on physical hardware, respectively. More information at https://ut-austin-rpl.github.io/sirius-runtime-monitor/", "url": "https://arxiv.org/abs/2310.17552"}, {"metadata": {"arXiv": "2310.17555", "Date": "Thu, 26 Oct 2023 16:46:12 ", "Title": "Interactive Robot Learning from Verbal Correction", "Authors": ["Huihan Liu", "Alice Chen", "Yuke Zhu", "Adith Swaminathan", "Andrey Kolobov", "Ching-An Cheng"], "Categories": "cs.RO cs.AI cs.LG"}, "abstract": "The ability to learn and refine behavior after deployment has become ever more important for robots as we design them to operate in unstructured environments like households. In this work, we design a new learning system based on large language model (LLM), OLAF, that allows everyday users to teach a robot using verbal corrections when the robot makes mistakes, e.g., by saying \"Stop what you're doing. You should move closer to the cup.\" A key feature of OLAF is its ability to update the robot's visuomotor neural policy based on the verbal feedback to avoid repeating mistakes in the future. This is in contrast to existing LLM-based robotic systems, which only follow verbal commands or corrections but not learn from them. We demonstrate the efficacy of our design in experiments where a user teaches a robot to perform long-horizon manipulation tasks both in simulation and on physical hardware, achieving on average 20.0% improvement in policy success rate. Videos and more results are at https://ut-austin-rpl.github.io/olaf/", "url": "https://arxiv.org/abs/2310.17555"}, {"metadata": {"arXiv": "2310.17596", "Date": "Thu, 26 Oct 2023 17:17:31 ", "Title": "MimicGen: A Data Generation System for Scalable Robot Learning using Human Demonstrations", "Authors": ["Ajay Mandlekar", "Soroush Nasiriany", "Bowen Wen", "Iretiayo Akinola", "Yashraj Narang", "Linxi Fan", "Yuke Zhu", "Dieter Fox"], "Categories": "cs.RO cs.AI cs.CV cs.LG", "Comments": ["Conference on Robot Learning (CoRL) 2023"]}, "abstract": "Imitation learning from a large set of human demonstrations has proved to be an effective paradigm for building capable robot agents. However, the demonstrations can be extremely costly and time-consuming to collect. We introduce MimicGen, a system for automatically synthesizing large-scale, rich datasets from only a small number of human demonstrations by adapting them to new contexts. We use MimicGen to generate over 50K demonstrations across 18 tasks with diverse scene configurations, object instances, and robot arms from just ~200 human demonstrations. We show that robot agents can be effectively trained on this generated dataset by imitation learning to achieve strong performance in long-horizon and high-precision tasks, such as multi-part assembly and coffee preparation, across broad initial state distributions. We further demonstrate that the effectiveness and utility of MimicGen data compare favorably to collecting additional human demonstrations, making it a powerful and economical approach towards scaling up robot learning. Datasets, simulation environments, videos, and more at https://mimicgen.github.io .", "url": "https://arxiv.org/abs/2310.17596"}, {"metadata": {"arXiv": "2310.17634", "Date": "Thu, 26 Oct 2023 17:51:46 ", "Title": "Grow Your Limits: Continuous Improvement with Real-World RL for Robotic Locomotion", "Authors": ["Laura Smith and Yunhao Cao and Sergey Levine"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["First two authors contributed equally. Project website: https://sites.google.com/berkeley.edu/aprl"]}, "abstract": "Deep reinforcement learning (RL) can enable robots to autonomously acquire complex behaviors, such as legged locomotion. However, RL in the real world is complicated by constraints on efficiency, safety, and overall training stability, which limits its practical applicability. We present APRL, a policy regularization framework that modulates the robot's exploration over the course of training, striking a balance between flexible improvement potential and focused, efficient exploration. APRL enables a quadrupedal robot to efficiently learn to walk entirely in the real world within minutes and continue to improve with more training where prior work saturates in performance. We demonstrate that continued training with APRL results in a policy that is substantially more capable of navigating challenging situations and is able to adapt to changes in dynamics with continued training.", "url": "https://arxiv.org/abs/2310.17634"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

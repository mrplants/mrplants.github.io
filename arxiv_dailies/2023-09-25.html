<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2309.12412", "Date": "Thu, 21 Sep 2023 18:21:54 ", "Title": "Speeding up Resnet Architecture with Layers Targeted Low Rank Decomposition", "Authors": ["Walid Ahmed and Habib Hajimolahoseini and Austin Wen and Yang Liu"], "Categories": "cs.CV cs.LG"}, "abstract": "Compression of a neural network can help in speeding up both the training and the inference of the network. In this research, we study applying compression using low rank decomposition on network layers. Our research demonstrates that to acquire a speed up, the compression methodology should be aware of the underlying hardware as analysis should be done to choose which layers to compress. The advantage of our approach is demonstrated via a case study of compressing ResNet50 and training on full ImageNet-ILSVRC2012. We tested on two different hardware systems Nvidia V100 and Huawei Ascend910. With hardware targeted compression, results on Ascend910 showed 5.36% training speedup and 15.79% inference speed on Ascend310 with only 1% drop in accuracy compared to the original uncompressed model", "url": "https://arxiv.org/abs/2309.12412"}, {"metadata": {"arXiv": "2309.12463", "Date": "Thu, 21 Sep 2023 20:11:01 ", "Title": "Impact of architecture on robustness and interpretability of multispectral deep neural networks", "Authors": ["Charles Godfrey", "Elise Bishoff", "Myles McKay and Eleanor Byler"], "Categories": "cs.CV cs.LG", "Comments": ["Comments welcome!"]}, "abstract": "Including information from additional spectral bands (e.g., near-infrared) can improve deep learning model performance for many vision-oriented tasks. There are many possible ways to incorporate this additional information into a deep learning model, but the optimal fusion strategy has not yet been determined and can vary between applications. At one extreme, known as \"early fusion,\" additional bands are stacked as extra channels to obtain an input image with more than three channels. At the other extreme, known as \"late fusion,\" RGB and non-RGB bands are passed through separate branches of a deep learning model and merged immediately before a final classification or segmentation layer. In this work, we characterize the performance of a suite of multispectral deep learning models with different fusion approaches, quantify their relative reliance on different input bands and evaluate their robustness to naturalistic image corruptions affecting one or more input channels.", "url": "https://arxiv.org/abs/2309.12463"}, {"metadata": {"arXiv": "2309.12574", "Date": "Fri, 22 Sep 2023 02:02:59 ", "Title": "Classification of Alzheimers Disease with Deep Learning on Eye-tracking Data", "Authors": ["Harshinee Sriram", "Cristina Conati", "Thalia Field"], "Categories": "cs.CV cs.LG", "Comments": ["ICMI 2023 long paper"], "DOI": "10.1145/3577190.3614149"}, "abstract": "Existing research has shown the potential of classifying Alzheimers Disease (AD) from eye-tracking (ET) data with classifiers that rely on task-specific engineered features. In this paper, we investigate whether we can improve on existing results by using a Deep-Learning classifier trained end-to-end on raw ET data. This classifier (VTNet) uses a GRU and a CNN in parallel to leverage both visual (V) and temporal (T) representations of ET data and was previously used to detect user confusion while processing visual displays. A main challenge in applying VTNet to our target AD classification task is that the available ET data sequences are much longer than those used in the previous confusion detection task, pushing the limits of what is manageable by LSTM-based models. We discuss how we address this challenge and show that VTNet outperforms the state-of-the-art approaches in AD classification, providing encouraging evidence on the generality of this model to make predictions from ET data.", "url": "https://arxiv.org/abs/2309.12574"}, {"metadata": {"arXiv": "2309.12650", "Date": "Fri, 22 Sep 2023 06:44:28 ", "Title": "FP-PET: Large Model, Multiple Loss And Focused Practice", "Authors": ["Yixin Chen", "Ourui Fu", "Wenrui Shao", "Zhaoheng Xie"], "Categories": "cs.CV cs.LG"}, "abstract": "This study presents FP-PET, a comprehensive approach to medical image segmentation with a focus on CT and PET images. Utilizing a dataset from the AutoPet2023 Challenge, the research employs a variety of machine learning models, including STUNet-large, SwinUNETR, and VNet, to achieve state-of-the-art segmentation performance. The paper introduces an aggregated score that combines multiple evaluation metrics such as Dice score, false positive volume (FPV), and false negative volume (FNV) to provide a holistic measure of model effectiveness. The study also discusses the computational challenges and solutions related to model training, which was conducted on high-performance GPUs. Preprocessing and postprocessing techniques, including gaussian weighting schemes and morphological operations, are explored to further refine the segmentation output. The research offers valuable insights into the challenges and solutions for advanced medical image segmentation.", "url": "https://arxiv.org/abs/2309.12650"}, {"metadata": {"arXiv": "2309.12735", "Date": "Fri, 22 Sep 2023 09:34:33 ", "Title": "Optimal Dynamic Fees for Blockchain Resources", "Authors": ["Davide Crapis", "Ciamac C. Moallemi", "Shouqiao Wang"], "Categories": "cs.GT cs.CR cs.LG math.OC"}, "abstract": "We develop a general and practical framework to address the problem of the optimal design of dynamic fee mechanisms for multiple blockchain resources. Our framework allows to compute policies that optimally trade-off between adjusting resource prices to handle persistent demand shifts versus being robust to local noise in the observed block demand. In the general case with more than one resource, our optimal policies correctly handle cross-effects (complementarity and substitutability) in resource demands. We also show how these cross-effects can be used to inform resource design, i.e. combining resources into bundles that have low demand-side cross-effects can yield simpler and more efficient price-update rules. Our framework is also practical, we demonstrate how it can be used to refine or inform the design of heuristic fee update rules such as EIP-1559 or EIP-4844 with two case studies. We then estimate a uni-dimensional version of our model using real market data from the Ethereum blockchain and empirically compare the performance of our optimal policies to EIP-1559.", "url": "https://arxiv.org/abs/2309.12735"}, {"metadata": {"arXiv": "2309.12371", "Date": "Wed, 20 Sep 2023 19:53:04 ", "Title": "Fairness Hub Technical Briefs: AUC Gap", "Authors": ["Jinsook Lee", "Chris Brooks", "Renzhe Yu", "Rene Kizilcec"], "Categories": "cs.LG cs.CY", "Comments": ["Fairness Hub Technical Briefs of Learning Engineering Virtual Institute (LEVI) Program supported by Schmidt Futures"]}, "abstract": "To measure bias, we encourage teams to consider using AUC Gap: the absolute difference between the highest and lowest test AUC for subgroups (e.g., gender, race, SES, prior knowledge). It is agnostic to the AI/ML algorithm used and it captures the disparity in model performance for any number of subgroups, which enables non-binary fairness assessments such as for intersectional identity groups. The LEVI teams use a wide range of AI/ML models in pursuit of a common goal of doubling math achievement in low-income middle schools. Ensuring that the models, which are trained on datasets collected in many different contexts, do not introduce or amplify biases is important for achieving the LEVI goal. We offer here a versatile and easy-to-compute measure of model bias for all LEVI teams in order to create a common benchmark and an analytical basis for sharing what strategies have worked for different teams.", "url": "https://arxiv.org/abs/2309.12371"}, {"metadata": {"arXiv": "2309.12377", "Date": "Thu, 21 Sep 2023 09:46:01 ", "Title": "Shedding Light on the Ageing of Extra Virgin Olive Oil: Probing the Impact of Temperature with Fluorescence Spectroscopy and Machine Learning Techniques", "Authors": ["Francesca Venturini", "Silvan Fluri", "Manas Mejari", "Michael Baumgartner", "Dario Piga", "Umberto Michelucci"], "Categories": "cs.LG"}, "abstract": "This work systematically investigates the oxidation of extra virgin olive oil (EVOO) under accelerated storage conditions with UV absorption and total fluorescence spectroscopy. With the large amount of data collected, it proposes a method to monitor the oil's quality based on machine learning applied to highly-aggregated data. EVOO is a high-quality vegetable oil that has earned worldwide reputation for its numerous health benefits and excellent taste. Despite its outstanding quality, EVOO degrades over time owing to oxidation, which can affect both its health qualities and flavour. Therefore, it is highly relevant to quantify the effects of oxidation on EVOO and develop methods to assess it that can be easily implemented under field conditions, rather than in specialized laboratories. The following study demonstrates that fluorescence spectroscopy has the capability to monitor the effect of oxidation and assess the quality of EVOO, even when the data are highly aggregated. It shows that complex laboratory equipment is not necessary to exploit fluorescence spectroscopy using the proposed method and that cost-effective solutions, which can be used in-field by non-scientists, could provide an easily-accessible assessment of the quality of EVOO.", "url": "https://arxiv.org/abs/2309.12377"}, {"metadata": {"arXiv": "2309.12381", "Date": "Thu, 21 Sep 2023 13:55:29 ", "Title": "Memory Efficient Mixed-Precision Optimizers", "Authors": ["Basile Lewandowski and Atli Kosson"], "Categories": "cs.LG"}, "abstract": "Traditional optimization methods rely on the use of single-precision floating point arithmetic, which can be costly in terms of memory size and computing power. However, mixed precision optimization techniques leverage the use of both single and half-precision floating point arithmetic to reduce memory requirements while maintaining model accuracy. We provide here an algorithm to further reduce memory usage during the training of a model by getting rid of the floating point copy of the parameters, virtually keeping only half-precision numbers. We also explore the benefits of getting rid of the gradient's value by executing the optimizer step during the back-propagation. In practice, we achieve up to 25% lower peak memory use and 15% faster training while maintaining the same level of accuracy.", "url": "https://arxiv.org/abs/2309.12381"}, {"metadata": {"arXiv": "2309.12458", "Date": "Thu, 21 Sep 2023 20:05:49 ", "Title": "A Theory of Multimodal Learning", "Authors": ["Zhou Lu"], "Categories": "cs.LG", "Comments": ["Neurips 2023", "to appear"]}, "abstract": "Human perception of the empirical world involves recognizing the diverse appearances, or 'modalities', of underlying objects. Despite the longstanding consideration of this perspective in philosophy and cognitive science, the study of multimodality remains relatively under-explored within the field of machine learning. Nevertheless, current studies of multimodal machine learning are limited to empirical practices, lacking theoretical foundations beyond heuristic arguments. An intriguing finding from the practice of multimodal learning is that a model trained on multiple modalities can outperform a finely-tuned unimodal model, even on unimodal tasks. This paper provides a theoretical framework that explains this phenomenon, by studying generalization properties of multimodal learning algorithms. We demonstrate that multimodal learning allows for a superior generalization bound compared to unimodal learning, up to a factor of $O(\\sqrt{n})$, where $n$ represents the sample size. Such advantage occurs when both connection and heterogeneity exist between the modalities.", "url": "https://arxiv.org/abs/2309.12458"}, {"metadata": {"arXiv": "2309.12488", "Date": "Thu, 21 Sep 2023 21:15:51 ", "Title": "Sharpness-Aware Minimization and the Edge of Stability", "Authors": ["Philip M. Long and Peter L. Bartlett"], "Categories": "cs.LG cs.NE stat.ML"}, "abstract": "Recent experiments have shown that, often, when training a neural network with gradient descent (GD) with a step size $\\eta$, the operator norm of the Hessian of the loss grows until it approximately reaches $2/\\eta$, after which it fluctuates around this value. The quantity $2/\\eta$ has been called the \"edge of stability\" based on consideration of a local quadratic approximation of the loss. We perform a similar calculation to arrive at an \"edge of stability\" for Sharpness-Aware Minimization (SAM), a variant of GD which has been shown to improve its generalization. Unlike the case for GD, the resulting SAM-edge depends on the norm of the gradient. Using three deep learning training tasks, we see empirically that SAM operates on the edge of stability identified by this analysis.", "url": "https://arxiv.org/abs/2309.12488"}, {"metadata": {"arXiv": "2309.12494", "Date": "Thu, 21 Sep 2023 21:26:50 ", "Title": "Evidential uncertainties on rich labels for active learning", "Authors": ["Arthur Hoarau", "Vincent Lemaire", "Arnaud Martin", "Jean-Christophe Dubois", "Yolande Le Gall"], "Categories": "cs.LG"}, "abstract": "Recent research in active learning, and more precisely in uncertainty sampling, has focused on the decomposition of model uncertainty into reducible and irreducible uncertainties. In this paper, we propose to simplify the computational phase and remove the dependence on observations, but more importantly to take into account the uncertainty already present in the labels, \\emph{i.e.} the uncertainty of the oracles. Two strategies are proposed, sampling by Klir uncertainty, which addresses the exploration-exploitation problem, and sampling by evidential epistemic uncertainty, which extends the reducible uncertainty to the evidential framework, both using the theory of belief functions.", "url": "https://arxiv.org/abs/2309.12494"}, {"metadata": {"arXiv": "2309.12508", "Date": "Thu, 21 Sep 2023 22:10:20 ", "Title": "A Diffusion-Model of Joint Interactive Navigation", "Authors": ["Matthew Niedoba", "Jonathan Wilder Lavington", "Yunpeng Liu", "Vasileios Lioutas", "Justice Sefas", "Xiaoxuan Liang", "Dylan Green", "Setareh Dabiri", "Berend Zwartsenberg", "Adam Scibior", "Frank Wood"], "Categories": "cs.LG cs.RO", "Comments": ["10 pages", "4 figures"]}, "abstract": "Simulation of autonomous vehicle systems requires that simulated traffic participants exhibit diverse and realistic behaviors. The use of prerecorded real-world traffic scenarios in simulation ensures realism but the rarity of safety critical events makes large scale collection of driving scenarios expensive. In this paper, we present DJINN - a diffusion based method of generating traffic scenarios. Our approach jointly diffuses the trajectories of all agents, conditioned on a flexible set of state observations from the past, present, or future. On popular trajectory forecasting datasets, we report state of the art performance on joint trajectory metrics. In addition, we demonstrate how DJINN flexibly enables direct test-time sampling from a variety of valuable conditional distributions including goal-based sampling, behavior-class sampling, and scenario editing.", "url": "https://arxiv.org/abs/2309.12508"}, {"metadata": {"arXiv": "2309.12510", "Date": "Thu, 21 Sep 2023 22:12:24 ", "Title": "Confidence Calibration for Systems with Cascaded Predictive Modules", "Authors": ["Yunye Gong", "Yi Yao", "Xiao Lin", "Ajay Divakaran", "Melinda Gervasio"], "Categories": "cs.LG"}, "abstract": "Existing conformal prediction algorithms estimate prediction intervals at target confidence levels to characterize the performance of a regression model on new test samples. However, considering an autonomous system consisting of multiple modules, prediction intervals constructed for individual modules fall short of accommodating uncertainty propagation over different modules and thus cannot provide reliable predictions on system behavior. We address this limitation and present novel solutions based on conformal prediction to provide prediction intervals calibrated for a predictive system consisting of cascaded modules (e.g., an upstream feature extraction module and a downstream regression module). Our key idea is to leverage module-level validation data to characterize the system-level error distribution without direct access to end-to-end validation data. We provide theoretical justification and empirical experimental results to demonstrate the effectiveness of proposed solutions. In comparison to prediction intervals calibrated for individual modules, our solutions generate improved intervals with more accurate performance guarantees for system predictions, which are demonstrated on both synthetic systems and real-world systems performing overlap prediction for indoor navigation using the Matterport3D dataset.", "url": "https://arxiv.org/abs/2309.12510"}, {"metadata": {"arXiv": "2309.12534", "Date": "Thu, 21 Sep 2023 23:19:16 ", "Title": "Trip Planning for Autonomous Vehicles with Wireless Data Transfer Needs Using Reinforcement Learning", "Authors": ["Yousef AlSaqabi", "Bhaskar Krishnamachari"], "Categories": "cs.LG cs.SY eess.SY", "Comments": ["7 pages", "12 figures"], "Journal-ref": "2022 IEEE 19th International Conference on Mobile Ad Hoc and Smart Systems (MASS), Denver, CO, USA, 2022, pp. 10-17", "DOI": "10.1109/MASS56207.2022.00010"}, "abstract": "With recent advancements in the field of communications and the Internet of Things, vehicles are becoming more aware of their environment and are evolving towards full autonomy. Vehicular communication opens up the possibility for vehicle-to-infrastructure interaction, where vehicles could share information with components such as cameras, traffic lights, and signage that support a countrys road system. As a result, vehicles are becoming more than just a means of transportation; they are collecting, processing, and transmitting massive amounts of data used to make driving safer and more convenient. With 5G cellular networks and beyond, there is going to be more data bandwidth available on our roads, but it may be heterogeneous because of limitations like line of sight, infrastructure, and heterogeneous traffic on the road. This paper addresses the problem of route planning for autonomous vehicles in urban areas accounting for both driving time and data transfer needs. We propose a novel reinforcement learning solution that prioritizes high bandwidth roads to meet a vehicles data transfer requirement, while also minimizing driving time. We compare this approach to traffic-unaware and bandwidth-unaware baselines to show how much better it performs under heterogeneous traffic. This solution could be used as a starting point to understand what good policies look like, which could potentially yield faster, more efficient heuristics in the future.", "url": "https://arxiv.org/abs/2309.12534"}, {"metadata": {"arXiv": "2309.12578", "Date": "Fri, 22 Sep 2023 02:14:46 ", "Title": "SPION: Layer-Wise Sparse Training of Transformer via Convolutional Flood Filling", "Authors": ["Bokyeong Yoon", "Yoonsang Han", "Gordon Euhyun Moon"], "Categories": "cs.LG cs.DC"}, "abstract": "Sparsifying the Transformer has garnered considerable interest, as training the Transformer is very computationally demanding. Prior efforts to sparsify the Transformer have either used a fixed pattern or data-driven approach to reduce the number of operations involving the computation of multi-head attention, which is the main bottleneck of the Transformer. However, existing methods suffer from inevitable problems, such as the potential loss of essential sequence features due to the uniform fixed pattern applied across all layers, and an increase in the model size resulting from the use of additional parameters to learn sparsity patterns in attention operations. In this paper, we propose a novel sparsification scheme for the Transformer that integrates convolution filters and the flood filling method to efficiently capture the layer-wise sparse pattern in attention operations. Our sparsification approach reduces the computational complexity and memory footprint of the Transformer during training. Efficient implementations of the layer-wise sparsified attention algorithm on GPUs are developed, demonstrating a new SPION that achieves up to 3.08X speedup over existing state-of-the-art sparse Transformer models, with better evaluation quality.", "url": "https://arxiv.org/abs/2309.12578"}, {"metadata": {"arXiv": "2309.12593", "Date": "Fri, 22 Sep 2023 02:43:04 ", "Title": "Improving Machine Learning Robustness via Adversarial Training", "Authors": ["Long Dang", "Thushari Hapuarachchi", "Kaiqi Xiong", "Jing Lin"], "Categories": "cs.LG cs.CR cs.CV"}, "abstract": "As Machine Learning (ML) is increasingly used in solving various tasks in real-world applications, it is crucial to ensure that ML algorithms are robust to any potential worst-case noises, adversarial attacks, and highly unusual situations when they are designed. Studying ML robustness will significantly help in the design of ML algorithms. In this paper, we investigate ML robustness using adversarial training in centralized and decentralized environments, where ML training and testing are conducted in one or multiple computers. In the centralized environment, we achieve a test accuracy of 65.41% and 83.0% when classifying adversarial examples generated by Fast Gradient Sign Method and DeepFool, respectively. Comparing to existing studies, these results demonstrate an improvement of 18.41% for FGSM and 47% for DeepFool. In the decentralized environment, we study Federated learning (FL) robustness by using adversarial training with independent and identically distributed (IID) and non-IID data, respectively, where CIFAR-10 is used in this research. In the IID data case, our experimental results demonstrate that we can achieve such a robust accuracy that it is comparable to the one obtained in the centralized environment. Moreover, in the non-IID data case, the natural accuracy drops from 66.23% to 57.82%, and the robust accuracy decreases by 25% and 23.4% in C&W and Projected Gradient Descent (PGD) attacks, compared to the IID data case, respectively. We further propose an IID data-sharing approach, which allows for increasing the natural accuracy to 85.04% and the robust accuracy from 57% to 72% in C&W attacks and from 59% to 67% in PGD attacks.", "url": "https://arxiv.org/abs/2309.12593"}, {"metadata": {"arXiv": "2309.12618", "Date": "Fri, 22 Sep 2023 04:54:26 ", "Title": "Zero-Regret Performative Prediction Under Inequality Constraints", "Authors": ["Wenjing Yan and Xuanyu Cao"], "Categories": "cs.LG"}, "abstract": "Performative prediction is a recently proposed framework where predictions guide decision-making and hence influence future data distributions. Such performative phenomena are ubiquitous in various areas, such as transportation, finance, public policy, and recommendation systems. To date, work on performative prediction has only focused on unconstrained scenarios, neglecting the fact that many real-world learning problems are subject to constraints. This paper bridges this gap by studying performative prediction under inequality constraints. Unlike most existing work that provides only performative stable points, we aim to find the optimal solutions. Anticipating performative gradients is a challenging task, due to the agnostic performative effect on data distributions. To address this issue, we first develop a robust primal-dual framework that requires only approximate gradients up to a certain accuracy, yet delivers the same order of performance as the stochastic primal-dual algorithm without performativity. Based on this framework, we then propose an adaptive primal-dual algorithm for location families. Our analysis demonstrates that the proposed adaptive primal-dual algorithm attains $\\ca{O}(\\sqrt{T})$ regret and constraint violations, using only $\\sqrt{T} + 2T$ samples, where $T$ is the time horizon. To our best knowledge, this is the first study and analysis on the optimality of the performative prediction problem under inequality constraints. Finally, we validate the effectiveness of our algorithm and theoretical results through numerical simulations.", "url": "https://arxiv.org/abs/2309.12618"}, {"metadata": {"arXiv": "2309.12620", "Date": "Fri, 22 Sep 2023 05:08:52 ", "Title": "Data-driven Preference Learning Methods for Multiple Criteria Sorting with Temporal Criteria", "Authors": ["Li Yijun", "Guo Mengzhuo", "Zhang Qingpeng"], "Categories": "cs.LG"}, "abstract": "The advent of predictive methodologies has catalyzed the emergence of data-driven decision support across various domains. However, developing models capable of effectively handling input time series data presents an enduring challenge. This study presents novel preference learning approaches to multiple criteria sorting problems in the presence of temporal criteria. We first formulate a convex quadratic programming model characterized by fixed time discount factors, operating within a regularization framework. Additionally, we propose an ensemble learning algorithm designed to consolidate the outputs of multiple, potentially weaker, optimizers, a process executed efficiently through parallel computation. To enhance scalability and accommodate learnable time discount factors, we introduce a novel monotonic Recurrent Neural Network (mRNN). It is designed to capture the evolving dynamics of preferences over time while upholding critical properties inherent to MCS problems, including criteria monotonicity, preference independence, and the natural ordering of classes. The proposed mRNN can describe the preference dynamics by depicting marginal value functions and personalized time discount factors along with time, effectively amalgamating the interpretability of traditional MCS methods with the predictive potential offered by deep preference learning models. Comprehensive assessments of the proposed models are conducted, encompassing synthetic data scenarios and a real-case study centered on classifying valuable users within a mobile gaming app based on their historical in-app behavioral sequences. Empirical findings underscore the notable performance improvements achieved by the proposed models when compared to a spectrum of baseline methods, spanning machine learning, deep learning, and conventional multiple criteria sorting approaches.", "url": "https://arxiv.org/abs/2309.12620"}, {"metadata": {"arXiv": "2309.12628", "Date": "Fri, 22 Sep 2023 05:31:55 ", "Title": "Sequential Action-Induced Invariant Representation for Reinforcement Learning", "Authors": ["Dayang Liang", "Qihang Chen and Yunlong Liu"], "Categories": "cs.LG"}, "abstract": "How to accurately learn task-relevant state representations from high-dimensional observations with visual distractions is a realistic and challenging problem in visual reinforcement learning. Recently, unsupervised representation learning methods based on bisimulation metrics, contrast, prediction, and reconstruction have shown the ability for task-relevant information extraction. However, due to the lack of appropriate mechanisms for the extraction of task information in the prediction, contrast, and reconstruction-related approaches and the limitations of bisimulation-related methods in domains with sparse rewards, it is still difficult for these methods to be effectively extended to environments with distractions. To alleviate these problems, in the paper, the action sequences, which contain task-intensive signals, are incorporated into representation learning. Specifically, we propose a Sequential Action--induced invariant Representation (SAR) method, in which the encoder is optimized by an auxiliary learner to only preserve the components that follow the control signals of sequential actions, so the agent can be induced to learn the robust representation against distractions. We conduct extensive experiments on the DeepMind Control suite tasks with distractions while achieving the best performance over strong baselines. We also demonstrate the effectiveness of our method at disregarding task-irrelevant information by deploying SAR to real-world CARLA-based autonomous driving with natural distractions. Finally, we provide the analysis results of generalization drawn from the generalization decay and t-SNE visualization. Code and demo videos are available at https://github.com/DMU-XMU/SAR.git.", "url": "https://arxiv.org/abs/2309.12628"}, {"metadata": {"arXiv": "2309.12658", "Date": "Fri, 22 Sep 2023 06:56:35 ", "Title": "Neural Operator Variational Inference based on Regularized Stein Discrepancy for Deep Gaussian Processes", "Authors": ["Jian Xu", "Shian Du", "Junmei Yang", "Qianli Ma", "Delu Zeng"], "Categories": "cs.LG stat.ML"}, "abstract": "Deep Gaussian Process (DGP) models offer a powerful nonparametric approach for Bayesian inference, but exact inference is typically intractable, motivating the use of various approximations. However, existing approaches, such as mean-field Gaussian assumptions, limit the expressiveness and efficacy of DGP models, while stochastic approximation can be computationally expensive. To tackle these challenges, we introduce Neural Operator Variational Inference (NOVI) for Deep Gaussian Processes. NOVI uses a neural generator to obtain a sampler and minimizes the Regularized Stein Discrepancy in L2 space between the generated distribution and true posterior. We solve the minimax problem using Monte Carlo estimation and subsampling stochastic optimization techniques. We demonstrate that the bias introduced by our method can be controlled by multiplying the Fisher divergence with a constant, which leads to robust error control and ensures the stability and precision of the algorithm. Our experiments on datasets ranging from hundreds to tens of thousands demonstrate the effectiveness and the faster convergence rate of the proposed method. We achieve a classification accuracy of 93.56 on the CIFAR10 dataset, outperforming SOTA Gaussian process methods. Furthermore, our method guarantees theoretically controlled prediction error for DGP models and demonstrates remarkable performance on various datasets. We are optimistic that NOVI has the potential to enhance the performance of deep Bayesian nonparametric models and could have significant implications for various practical applications", "url": "https://arxiv.org/abs/2309.12658"}, {"metadata": {"arXiv": "2309.12659", "Date": "Fri, 22 Sep 2023 06:59:14 ", "Title": "OneNet: Enhancing Time Series Forecasting Models under Concept Drift by Online Ensembling", "Authors": ["Yi-Fan Zhang", "Qingsong Wen", "Xue Wang", "Weiqi Chen", "Liang Sun", "Zhang Zhang", "Liang Wang", "Rong Jin", "Tieniu Tan"], "Categories": "cs.LG cs.DS", "Comments": ["32 pages", "11 figures", "37th Conference on Neural Information Processing Systems (NeurIPS 2023)"]}, "abstract": "Online updating of time series forecasting models aims to address the concept drifting problem by efficiently updating forecasting models based on streaming data. Many algorithms are designed for online time series forecasting, with some exploiting cross-variable dependency while others assume independence among variables. Given every data assumption has its own pros and cons in online time series modeling, we propose \\textbf{On}line \\textbf{e}nsembling \\textbf{Net}work (OneNet). It dynamically updates and combines two models, with one focusing on modeling the dependency across the time dimension and the other on cross-variate dependency. Our method incorporates a reinforcement learning-based approach into the traditional online convex programming framework, allowing for the linear combination of the two models with dynamically adjusted weights. OneNet addresses the main shortcoming of classical online learning methods that tend to be slow in adapting to the concept drift. Empirical results show that OneNet reduces online forecasting error by more than $\\mathbf{50\\%}$ compared to the State-Of-The-Art (SOTA) method. The code is available at \\url{https://github.com/yfzhang114/OneNet}.", "url": "https://arxiv.org/abs/2309.12659"}, {"metadata": {"arXiv": "2309.12689", "Date": "Fri, 22 Sep 2023 08:02:45 ", "Title": "AMPLIFY:Attention-based Mixup for Performance Improvement and Label Smoothing in Transformer", "Authors": ["Leixin Yang", "Yaping Zhang", "Haoyu Xiong", "Yu Xiang"], "Categories": "cs.LG cs.CL"}, "abstract": "Mixup is an effective data augmentation method that generates new augmented samples by aggregating linear combinations of different original samples. However, if there are noises or aberrant features in the original samples, Mixup may propagate them to the augmented samples, leading to over-sensitivity of the model to these outliers . To solve this problem, this paper proposes a new Mixup method called AMPLIFY. This method uses the Attention mechanism of Transformer itself to reduce the influence of noises and aberrant values in the original samples on the prediction results, without increasing additional trainable parameters, and the computational cost is very low, thereby avoiding the problem of high resource consumption in common Mixup methods such as Sentence Mixup . The experimental results show that, under a smaller computational resource cost, AMPLIFY outperforms other Mixup methods in text classification tasks on 7 benchmark datasets, providing new ideas and new ways to further improve the performance of pre-trained models based on the Attention mechanism, such as BERT, ALBERT, RoBERTa, and GPT. Our code can be obtained at https://github.com/kiwi-lilo/AMPLIFY.", "url": "https://arxiv.org/abs/2309.12689"}, {"metadata": {"arXiv": "2309.12694", "Date": "Fri, 22 Sep 2023 08:09:55 ", "Title": "Recurrent Temporal Revision Graph Networks", "Authors": ["Yizhou Chen", "Anxiang Zeng", "Guangda Huzhang", "Qingtao Yu", "Kerui Zhang", "Cao Yuanpeng", "Kangle Wu", "Han Yu", "Zhiming Zhou"], "Categories": "cs.LG cs.SI"}, "abstract": "Temporal graphs offer more accurate modeling of many real-world scenarios than static graphs. However, neighbor aggregation, a critical building block of graph networks, for temporal graphs, is currently straightforwardly extended from that of static graphs. It can be computationally expensive when involving all historical neighbors during such aggregation. In practice, typically only a subset of the most recent neighbors are involved. However, such subsampling leads to incomplete and biased neighbor information. To address this limitation, we propose a novel framework for temporal neighbor aggregation that uses the recurrent neural network with node-wise hidden states to integrate information from all historical neighbors for each node to acquire the complete neighbor information. We demonstrate the superior theoretical expressiveness of the proposed framework as well as its state-of-the-art performance in real-world applications. Notably, it achieves a significant +9.6% improvement on averaged precision in a real-world Ecommerce dataset over existing methods on 2-layer models.", "url": "https://arxiv.org/abs/2309.12694"}, {"metadata": {"arXiv": "2309.12701", "Date": "Fri, 22 Sep 2023 08:18:08 ", "Title": "Discovering the Interpretability-Performance Pareto Front of Decision Trees with Dynamic Programming", "Authors": ["Hector Kohler", "Riad Akrour", "Philippe Preux"], "Categories": "cs.LG"}, "abstract": "Decision trees are known to be intrinsically interpretable as they can be inspected and interpreted by humans. Furthermore, recent hardware advances have rekindled an interest for optimal decision tree algorithms, that produce more accurate trees than the usual greedy approaches. However, these optimal algorithms return a single tree optimizing a hand defined interpretability-performance trade-off, obtained by specifying a maximum number of decision nodes, giving no further insights about the quality of this trade-off. In this paper, we propose a new Markov Decision Problem (MDP) formulation for finding optimal decision trees. The main interest of this formulation is that we can compute the optimal decision trees for several interpretability-performance trade-offs by solving a single dynamic program, letting the user choose a posteriori the tree that best suits their needs. Empirically, we show that our method is competitive with state-of-the-art algorithms in terms of accuracy and runtime while returning a whole set of trees on the interpretability-performance Pareto front.", "url": "https://arxiv.org/abs/2309.12701"}, {"metadata": {"arXiv": "2309.12742", "Date": "Fri, 22 Sep 2023 09:43:32 ", "Title": "Make the U in UDA Matter: Invariant Consistency Learning for Unsupervised Domain Adaptation", "Authors": ["Zhongqi Yue", "Hanwang Zhang", "Qianru Sun"], "Categories": "cs.LG", "Comments": ["Accepted by NeurIPS 2023"]}, "abstract": "Domain Adaptation (DA) is always challenged by the spurious correlation between domain-invariant features (e.g., class identity) and domain-specific features (e.g., environment) that does not generalize to the target domain. Unfortunately, even enriched with additional unsupervised target domains, existing Unsupervised DA (UDA) methods still suffer from it. This is because the source domain supervision only considers the target domain samples as auxiliary data (e.g., by pseudo-labeling), yet the inherent distribution in the target domain -- where the valuable de-correlation clues hide -- is disregarded. We propose to make the U in UDA matter by giving equal status to the two domains. Specifically, we learn an invariant classifier whose prediction is simultaneously consistent with the labels in the source domain and clusters in the target domain, hence the spurious correlation inconsistent in the target domain is removed. We dub our approach \"Invariant CONsistency learning\" (ICON). Extensive experiments show that ICON achieves the state-of-the-art performance on the classic UDA benchmarks: Office-Home and VisDA-2017, and outperforms all the conventional methods on the challenging WILDS 2.0 benchmark. Codes are in https://github.com/yue-zhongqi/ICON.", "url": "https://arxiv.org/abs/2309.12742"}, {"metadata": {"arXiv": "2309.12765", "Date": "Fri, 22 Sep 2023 10:10:30 ", "Title": "An Intelligent Approach to Detecting Novel Fault Classes for Centrifugal Pumps Based on Deep CNNs and Unsupervised Methods", "Authors": ["Mahdi Abdollah Chalaki", "Daniyal Maroufi", "Mahdi Robati", "Mohammad Javad Karimi", "Ali Sadighi"], "Categories": "cs.LG", "Comments": ["6 pages", "9 figures"], "DOI": "10.1109/icspis54653.2021.9729350"}, "abstract": "Despite the recent success in data-driven fault diagnosis of rotating machines, there are still remaining challenges in this field. Among the issues to be addressed, is the lack of information about variety of faults the system may encounter in the field. In this paper, we assume a partial knowledge of the system faults and use the corresponding data to train a convolutional neural network. A combination of t-SNE method and clustering techniques is then employed to detect novel faults. Upon detection, the network is augmented using the new data. Finally, a test setup is used to validate this two-stage methodology on a centrifugal pump and experimental results show high accuracy in detecting novel faults.", "url": "https://arxiv.org/abs/2309.12765"}, {"metadata": {"arXiv": "2309.12815", "Date": "Fri, 22 Sep 2023 12:08:53 ", "Title": "Improving Generalization in Game Agents with Data Augmentation in Imitation Learning", "Authors": ["Derek Yadgaroff", "Alessandro Sestini", "Konrad Tollmar", "Linus Gissl\\'en"], "Categories": "cs.LG", "Comments": ["8 pages", "5 figures"]}, "abstract": "Imitation learning is an effective approach for training game-playing agents and, consequently, for efficient game production. However, generalization - the ability to perform well in related but unseen scenarios - is an essential requirement that remains an unsolved challenge for game AI. Generalization is difficult for imitation learning agents because it requires the algorithm to take meaningful actions outside of the training distribution. In this paper we propose a solution to this challenge. Inspired by the success of data augmentation in supervised learning, we augment the training data so the distribution of states and actions in the dataset better represents the real state-action distribution. This study evaluates methods for combining and applying data augmentations to observations, to improve generalization of imitation learning agents. It also provides a performance benchmark of these augmentations across several 3D environments. These results demonstrate that data augmentation is a promising framework for improving generalization in imitation learning agents.", "url": "https://arxiv.org/abs/2309.12815"}, {"metadata": {"arXiv": "2309.12841", "Date": "Fri, 22 Sep 2023 12:55:30 ", "Title": "Reward Function Design for Crowd Simulation via Reinforcement Learning", "Authors": ["Ariel Kwiatkowski", "Vicky Kalogeiton", "Julien Pettr\\'e", "Marie-Paule Cani"], "Categories": "cs.LG", "DOI": "10.1145/3623264.3624452"}, "abstract": "Crowd simulation is important for video-games design, since it enables to populate virtual worlds with autonomous avatars that navigate in a human-like manner. Reinforcement learning has shown great potential in simulating virtual crowds, but the design of the reward function is critical to achieving effective and efficient results. In this work, we explore the design of reward functions for reinforcement learning-based crowd simulation. We provide theoretical insights on the validity of certain reward functions according to their analytical properties, and evaluate them empirically using a range of scenarios, using the energy efficiency as the metric. Our experiments show that directly minimizing the energy usage is a viable strategy as long as it is paired with an appropriately scaled guiding potential, and enable us to study the impact of the different reward components on the behavior of the simulated crowd. Our findings can inform the development of new crowd simulation techniques, and contribute to the wider study of human-like navigation.", "url": "https://arxiv.org/abs/2309.12841"}, {"metadata": {"arXiv": "2309.12849", "Date": "Fri, 22 Sep 2023 13:22:15 ", "Title": "DeepOPF-U: A Unified Deep Neural Network to Solve AC Optimal Power Flow in Multiple Networks", "Authors": ["Heng Liang", "Changhong Zhao"], "Categories": "cs.LG cs.SY eess.SY", "Comments": ["3 pages", "2 figures"]}, "abstract": "The traditional machine learning models to solve optimal power flow (OPF) are mostly trained for a given power network and lack generalizability to today's power networks with varying topologies and growing plug-and-play distributed energy resources (DERs). In this paper, we propose DeepOPF-U, which uses one unified deep neural network (DNN) to solve alternating-current (AC) OPF problems in different power networks, including a set of power networks that is successively expanding. Specifically, we design elastic input and output layers for the vectors of given loads and OPF solutions with varying lengths in different networks. The proposed method, using a single unified DNN, can deal with different and growing numbers of buses, lines, loads, and DERs. Simulations of IEEE 57/118/300-bus test systems and a network growing from 73 to 118 buses verify the improved performance of DeepOPF-U compared to existing DNN-based solution methods.", "url": "https://arxiv.org/abs/2309.12849"}, {"metadata": {"arXiv": "2309.12862", "Date": "Fri, 22 Sep 2023 13:37:10 ", "Title": "Associative Transformer Is A Sparse Representation Learner", "Authors": ["Yuwei Sun", "Hideya Ochiai", "Zhirong Wu", "Stephen Lin", "Ryota Kanai"], "Categories": "cs.LG cs.CV cs.NE"}, "abstract": "Emerging from the monolithic pairwise attention mechanism in conventional Transformer models, there is a growing interest in leveraging sparse interactions that align more closely with biological principles. Approaches including the Set Transformer and the Perceiver employ cross-attention consolidated with a latent space that forms an attention bottleneck with limited capacity. Building upon recent neuroscience studies of Global Workspace Theory and associative memory, we propose the Associative Transformer (AiT). AiT induces low-rank explicit memory that serves as both priors to guide bottleneck attention in the shared workspace and attractors within associative memory of a Hopfield network. Through joint end-to-end training, these priors naturally develop module specialization, each contributing a distinct inductive bias to form attention bottlenecks. A bottleneck can foster competition among inputs for writing information into the memory. We show that AiT is a sparse representation learner, learning distinct priors through the bottlenecks that are complexity-invariant to input quantities and dimensions. AiT demonstrates its superiority over methods such as the Set Transformer, Vision Transformer, and Coordination in various vision tasks.", "url": "https://arxiv.org/abs/2309.12862"}, {"metadata": {"arXiv": "2309.12928", "Date": "Fri, 22 Sep 2023 15:27:54 ", "Title": "BayesDLL: Bayesian Deep Learning Library", "Authors": ["Minyoung Kim", "Timothy Hospedales"], "Categories": "cs.LG stat.ML"}, "abstract": "We release a new Bayesian neural network library for PyTorch for large-scale deep networks. Our library implements mainstream approximate Bayesian inference algorithms: variational inference, MC-dropout, stochastic-gradient MCMC, and Laplace approximation. The main differences from other existing Bayesian neural network libraries are as follows: 1) Our library can deal with very large-scale deep networks including Vision Transformers (ViTs). 2) We need virtually zero code modifications for users (e.g., the backbone network definition codes do not neet to be modified at all). 3) Our library also allows the pre-trained model weights to serve as a prior mean, which is very useful for performing Bayesian inference with the large-scale foundation models like ViTs that are hard to optimise from scratch with the downstream data alone. Our code is publicly available at: \\url{https://github.com/SamsungLabs/BayesDLL}\\footnote{A mirror repository is also available at: \\url{https://github.com/minyoungkim21/BayesDLL}.}.", "url": "https://arxiv.org/abs/2309.12928"}, {"metadata": {"arXiv": "2309.12996", "Date": "Fri, 22 Sep 2023 16:56:40 ", "Title": "Point Cloud Network: An Order of Magnitude Improvement in Linear Layer Parameter Count", "Authors": ["Charles Hetterich"], "Categories": "cs.LG cs.CV cs.NE"}, "abstract": "This paper introduces the Point Cloud Network (PCN) architecture, a novel implementation of linear layers in deep learning networks, and provides empirical evidence to advocate for its preference over the Multilayer Perceptron (MLP) in linear layers. We train several models, including the original AlexNet, using both MLP and PCN architectures for direct comparison of linear layers (Krizhevsky et al., 2012). The key results collected are model parameter count and top-1 test accuracy over the CIFAR-10 and CIFAR-100 datasets (Krizhevsky, 2009). AlexNet-PCN16, our PCN equivalent to AlexNet, achieves comparable efficacy (test accuracy) to the original architecture with a 99.5% reduction of parameters in its linear layers. All training is done on cloud RTX 4090 GPUs, leveraging pytorch for model construction and training. Code is provided for anyone to reproduce the trials from this paper.", "url": "https://arxiv.org/abs/2309.12996"}, {"metadata": {"arXiv": "2309.13016", "Date": "Fri, 22 Sep 2023 17:26:24 ", "Title": "Understanding Deep Gradient Leakage via Inversion Influence Functions", "Authors": ["Haobo Zhang", "Junyuan Hong", "Yuyang Deng", "Mehrdad Mahdavi", "Jiayu Zhou"], "Categories": "cs.LG cs.CR", "Comments": ["22 pages", "16 figures", "accepted by NeurIPS2023"]}, "abstract": "Deep Gradient Leakage (DGL) is a highly effective attack that recovers private training images from gradient vectors. This attack casts significant privacy challenges on distributed learning from clients with sensitive data, where clients are required to share gradients. Defending against such attacks requires but lacks an understanding of when and how privacy leakage happens, mostly because of the black-box nature of deep networks. In this paper, we propose a novel Inversion Influence Function (I$^2$F) that establishes a closed-form connection between the recovered images and the private gradients by implicitly solving the DGL problem. Compared to directly solving DGL, I$^2$F is scalable for analyzing deep networks, requiring only oracle access to gradients and Jacobian-vector products. We empirically demonstrate that I$^2$F effectively approximated the DGL generally on different model architectures, datasets, attack implementations, and noise-based defenses. With this novel tool, we provide insights into effective gradient perturbation directions, the unfairness of privacy protection, and privacy-preferred model initialization. Our codes are provided in https://github.com/illidanlab/inversion-influence-function.", "url": "https://arxiv.org/abs/2309.13016"}, {"metadata": {"arXiv": "2309.13022", "Date": "Fri, 22 Sep 2023 17:34:20 ", "Title": "Graph Neural Network for Stress Predictions in Stiffened Panels Under Uniform Loading", "Authors": ["Yuecheng Cai", "Jasmin Jelovica"], "Categories": "cs.LG", "Comments": ["20 pages; 7 figures"], "MSC-class": "74B10 (Primary) 74B02, 68T02 (Secondary)", "ACM-class": "J.2"}, "abstract": "Machine learning (ML) and deep learning (DL) techniques have gained significant attention as reduced order models (ROMs) to computationally expensive structural analysis methods, such as finite element analysis (FEA). Graph neural network (GNN) is a particular type of neural network which processes data that can be represented as graphs. This allows for efficient representation of complex geometries that can change during conceptual design of a structure or a product. In this study, we propose a novel graph embedding technique for efficient representation of 3D stiffened panels by considering separate plate domains as vertices. This approach is considered using Graph Sampling and Aggregation (GraphSAGE) to predict stress distributions in stiffened panels with varying geometries. A comparison between a finite-element-vertex graph representation is conducted to demonstrate the effectiveness of the proposed approach. A comprehensive parametric study is performed to examine the effect of structural geometry on the prediction performance. Our results demonstrate the immense potential of graph neural networks with the proposed graph embedding method as robust reduced-order models for 3D structures.", "url": "https://arxiv.org/abs/2309.13022"}, {"metadata": {"arXiv": "2309.12856", "Date": "Fri, 22 Sep 2023 13:30:26 ", "Title": "Robotic Handling of Compliant Food Objects by Robust Learning from Demonstration", "Authors": ["Ekrem Misimi", "Alexander Olofsson", "Aleksander Eilertsen", "Elling Ruud {\\O}ye", "John Reidar Mathiassen"], "Categories": "cs.RO cs.LG", "Comments": ["8 pages", "7 figures,IROS 2018"], "MSC-class": "99", "ACM-class": "I.2; I.2.9; I.4", "DOI": "10.1109/IROS.2018.8594368"}, "abstract": "The robotic handling of compliant and deformable food raw materials, characterized by high biological variation, complex geometrical 3D shapes, and mechanical structures and texture, is currently in huge demand in the ocean space, agricultural, and food industries. Many tasks in these industries are performed manually by human operators who, due to the laborious and tedious nature of their tasks, exhibit high variability in execution, with variable outcomes. The introduction of robotic automation for most complex processing tasks has been challenging due to current robot learning policies. A more consistent learning policy involving skilled operators is desired. In this paper, we address the problem of robot learning when presented with inconsistent demonstrations. To this end, we propose a robust learning policy based on Learning from Demonstration (LfD) for robotic grasping of food compliant objects. The approach uses a merging of RGB-D images and tactile data in order to estimate the necessary pose of the gripper, gripper finger configuration and forces exerted on the object in order to achieve effective robot handling. During LfD training, the gripper pose, finger configurations and tactile values for the fingers, as well as RGB-D images are saved. We present an LfD learning policy that automatically removes inconsistent demonstrations, and estimates the teacher's intended policy. The performance of our approach is validated and demonstrated for fragile and compliant food objects with complex 3D shapes. The proposed approach has a vast range of potential applications in the aforementioned industry sectors.", "url": "https://arxiv.org/abs/2309.12856"}, {"metadata": {"arXiv": "2309.13041", "Date": "Fri, 22 Sep 2023 17:59:14 ", "Title": "Robotic Offline RL from Internet Videos via Value-Function Pre-Training", "Authors": ["Chethan Bhateja", "Derek Guo", "Dibya Ghosh", "Anikait Singh", "Manan Tomar", "Quan Vuong", "Yevgen Chebotar", "Sergey Levine", "Aviral Kumar"], "Categories": "cs.RO cs.CV cs.LG", "Comments": ["First three authors contributed equally"]}, "abstract": "Pre-training on Internet data has proven to be a key ingredient for broad generalization in many modern ML systems. What would it take to enable such capabilities in robotic reinforcement learning (RL)? Offline RL methods, which learn from datasets of robot experience, offer one way to leverage prior data into the robotic learning pipeline. However, these methods have a \"type mismatch\" with video data (such as Ego4D), the largest prior datasets available for robotics, since video offers observation-only experience without the action or reward annotations needed for RL methods. In this paper, we develop a system for leveraging large-scale human video datasets in robotic offline RL, based entirely on learning value functions via temporal-difference learning. We show that value learning on video datasets learns representations that are more conducive to downstream robotic offline RL than other approaches for learning from video data. Our system, called V-PTR, combines the benefits of pre-training on video data with robotic offline RL approaches that train on diverse robot data, resulting in value functions and policies for manipulation tasks that perform better, act robustly, and generalize broadly. On several manipulation tasks on a real WidowX robot, our framework produces policies that greatly improve over prior methods. Our video and additional details can be found at https://dibyaghosh.com/vptr/", "url": "https://arxiv.org/abs/2309.13041"}, {"metadata": {"arXiv": "2309.12415", "Date": "Thu, 21 Sep 2023 18:29:52 ", "Title": "Constraints First: A New MDD-based Model to Generate Sentences Under Constraints", "Authors": ["Alexandre Bonlarron", "Aur\\'elie Calabr\\`ese", "Pierre Kornprobst", "Jean-Charles R\\'egin"], "Categories": "cs.AI cs.CL", "Comments": ["To be published in Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence", "IJCAI 2023"], "Journal-ref": "Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence Main Track. Pages 1893-1901. Year 2023", "DOI": "10.24963/ijcai.2023/210"}, "abstract": "This paper introduces a new approach to generating strongly constrained texts. We consider standardized sentence generation for the typical application of vision screening. To solve this problem, we formalize it as a discrete combinatorial optimization problem and utilize multivalued decision diagrams (MDD), a well-known data structure to deal with constraints. In our context, one key strength of MDD is to compute an exhaustive set of solutions without performing any search. Once the sentences are obtained, we apply a language model (GPT-2) to keep the best ones. We detail this for English and also for French where the agreement and conjugation rules are known to be more complex. Finally, with the help of GPT-2, we get hundreds of bona-fide candidate sentences. When compared with the few dozen sentences usually available in the well-known vision screening test (MNREAD), this brings a major breakthrough in the field of standardized sentence generation. Also, as it can be easily adapted for other languages, it has the potential to make the MNREAD test even more valuable and usable. More generally, this paper highlights MDD as a convincing alternative for constrained text generation, especially when the constraints are hard to satisfy, but also for many other prospects.", "url": "https://arxiv.org/abs/2309.12415"}, {"metadata": {"arXiv": "2309.12423", "Date": "Thu, 21 Sep 2023 18:46:29 ", "Title": "Event Prediction using Case-Based Reasoning over Knowledge Graphs", "Authors": ["Sola Shirai", "Debarun Bhattacharjya", "Oktie Hassanzadeh"], "Categories": "cs.AI", "Comments": ["published at WWW '23: Proceedings of the ACM Web Conference 2023. Code base: https://github.com/solashirai/WWW-EvCBR"], "DOI": "10.1145/3543507.3583201"}, "abstract": "Applying link prediction (LP) methods over knowledge graphs (KG) for tasks such as causal event prediction presents an exciting opportunity. However, typical LP models are ill-suited for this task as they are incapable of performing inductive link prediction for new, unseen event entities and they require retraining as knowledge is added or changed in the underlying KG. We introduce a case-based reasoning model, EvCBR, to predict properties about new consequent events based on similar cause-effect events present in the KG. EvCBR uses statistical measures to identify similar events and performs path-based predictions, requiring no training step. To generalize our methods beyond the domain of event prediction, we frame our task as a 2-hop LP task, where the first hop is a causal relation connecting a cause event to a new effect event and the second hop is a property about the new event which we wish to predict. The effectiveness of our method is demonstrated using a novel dataset of newsworthy events with causal relations curated from Wikidata, where EvCBR outperforms baselines including translational-distance-based, GNN-based, and rule-based LP models.", "url": "https://arxiv.org/abs/2309.12423"}, {"metadata": {"arXiv": "2309.12529", "Date": "Thu, 21 Sep 2023 22:58:59 ", "Title": "Curriculum Reinforcement Learning via Morphology-Environment Co-Evolution", "Authors": ["Shuang Ao", "Tianyi Zhou", "Guodong Long", "Xuan Song", "Jing Jiang"], "Categories": "cs.AI"}, "abstract": "Throughout long history, natural species have learned to survive by evolving their physical structures adaptive to the environment changes. In contrast, current reinforcement learning (RL) studies mainly focus on training an agent with a fixed morphology (e.g., skeletal structure and joint attributes) in a fixed environment, which can hardly generalize to changing environments or new tasks. In this paper, we optimize an RL agent and its morphology through ``morphology-environment co-evolution (MECE)'', in which the morphology keeps being updated to adapt to the changing environment, while the environment is modified progressively to bring new challenges and stimulate the improvement of the morphology. This leads to a curriculum to train generalizable RL, whose morphology and policy are optimized for different environments. Instead of hand-crafting the curriculum, we train two policies to automatically change the morphology and the environment. To this end, (1) we develop two novel and effective rewards for the two policies, which are solely based on the learning dynamics of the RL agent; (2) we design a scheduler to automatically determine when to change the environment and the morphology. In experiments on two classes of tasks, the morphology and RL policies trained via MECE exhibit significantly better generalization performance in unseen test environments than SOTA morphology optimization methods. Our ablation studies on the two MECE policies further show that the co-evolution between the morphology and environment is the key to the success.", "url": "https://arxiv.org/abs/2309.12529"}, {"metadata": {"arXiv": "2309.12576", "Date": "Fri, 22 Sep 2023 02:12:47 ", "Title": "Understanding Patterns of Deep Learning ModelEvolution in Network Architecture Search", "Authors": ["Robert Underwood", "Meghana Madhastha", "Randal Burns", "Bogdan Nicolae"], "Categories": "cs.AI cs.DC", "Comments": ["11 pages", "4 figures"], "ACM-class": "I.2.6; C.4"}, "abstract": "Network Architecture Search and specifically Regularized Evolution is a common way to refine the structure of a deep learning model.However, little is known about how models empirically evolve over time which has design implications for designing caching policies, refining the search algorithm for particular applications, and other important use cases.In this work, we algorithmically analyze and quantitatively characterize the patterns of model evolution for a set of models from the Candle project and the Nasbench-201 search space.We show how the evolution of the model structure is influenced by the regularized evolution algorithm. We describe how evolutionary patterns appear in distributed settings and opportunities for caching and improved scheduling. Lastly, we describe the conditions that affect when particular model architectures rise and fall in popularity based on their frequency of acting as a donor in a sliding window.", "url": "https://arxiv.org/abs/2309.12576"}, {"metadata": {"arXiv": "2309.12579", "Date": "Fri, 22 Sep 2023 02:15:12 ", "Title": "From Text to Trends: A Unique Garden Analytics Perspective on the Future of Modern Agriculture", "Authors": ["Parag Saxena"], "Categories": "cs.AI"}, "abstract": "Data-driven insights are essential for modern agriculture. This research paper introduces a machine learning framework designed to improve how we educate and reach out to people in the field of horticulture. The framework relies on data from the Horticulture Online Help Desk (HOHD), which is like a big collection of questions from people who love gardening and are part of the Extension Master Gardener Program (EMGP). This framework has two main parts. First, it uses special computer programs (machine learning models) to sort questions into categories. This helps us quickly send each question to the right expert, so we can answer it faster. Second, it looks at when questions are asked and uses that information to guess how many questions we might get in the future and what they will be about. This helps us plan on topics that will be really important. It's like knowing what questions will be popular in the coming months. We also take into account where the questions come from by looking at the Zip Code. This helps us make research that fits the challenges faced by gardeners in different places. In this paper, we demonstrate the potential of machine learning techniques to predict trends in horticulture by analyzing textual queries from homeowners. We show that NLP, classification, and time series analysis can be used to identify patterns in homeowners' queries and predict future trends in horticulture. Our results suggest that machine learning could be used to predict trends in other agricultural sectors as well. If large-scale agriculture industries curate and maintain a comparable repository of textual data, the potential for trend prediction and strategic agricultural planning could be revolutionized. This convergence of technology and agriculture offers a promising pathway for the future of sustainable farming and data-informed agricultural practices", "url": "https://arxiv.org/abs/2309.12579"}, {"metadata": {"arXiv": "2309.12625", "Date": "Fri, 22 Sep 2023 05:18:54 ", "Title": "DRG-LLaMA : Tuning LLaMA Model to Predict Diagnosis-related Group for Hospitalized Patients", "Authors": ["Hanyin Wang", "Chufan Gao", "Christopher Dantona", "Bryan Hull", "Jimeng Sun"], "Categories": "cs.AI cs.CL"}, "abstract": "In the U.S. inpatient payment system, the Diagnosis-Related Group (DRG) plays a key role but its current assignment process is time-consuming. We introduce DRG-LLaMA, a large language model (LLM) fine-tuned on clinical notes for improved DRG prediction. Using Meta's LLaMA as the base model, we optimized it with Low-Rank Adaptation (LoRA) on 236,192 MIMIC-IV discharge summaries. With an input token length of 512, DRG-LLaMA-7B achieved a macro-averaged F1 score of 0.327, a top-1 prediction accuracy of 52.0% and a macro-averaged Area Under the Curve (AUC) of 0.986. Impressively, DRG-LLaMA-7B surpassed previously reported leading models on this task, demonstrating a relative improvement in macro-averaged F1 score of 40.3% compared to ClinicalBERT and 35.7% compared to CAML. When DRG-LLaMA is applied to predict base DRGs and complication or comorbidity (CC) / major complication or comorbidity (MCC), the top-1 prediction accuracy reached 67.8% for base DRGs and 67.5% for CC/MCC status. DRG-LLaMA performance exhibits improvements in correlation with larger model parameters and longer input context lengths. Furthermore, usage of LoRA enables training even on smaller GPUs with 48 GB of VRAM, highlighting the viability of adapting LLMs for DRGs prediction.", "url": "https://arxiv.org/abs/2309.12625"}, {"metadata": {"arXiv": "2309.12626", "Date": "Fri, 22 Sep 2023 05:27:06 ", "Title": "Construction contract risk identification based on knowledge-augmented language model", "Authors": ["Saika Wong", "Chunmo Zheng", "Xing Su", "Yinqiu Tang"], "Categories": "cs.AI cs.CL"}, "abstract": "Contract review is an essential step in construction projects to prevent potential losses. However, the current methods for reviewing construction contracts lack effectiveness and reliability, leading to time-consuming and error-prone processes. While large language models (LLMs) have shown promise in revolutionizing natural language processing (NLP) tasks, they struggle with domain-specific knowledge and addressing specialized issues. This paper presents a novel approach that leverages LLMs with construction contract knowledge to emulate the process of contract review by human experts. Our tuning-free approach incorporates construction contract domain knowledge to enhance language models for identifying construction contract risks. The use of a natural language when building the domain knowledge base facilitates practical implementation. We evaluated our method on real construction contracts and achieved solid performance. Additionally, we investigated how large language models employ logical thinking during the task and provide insights and recommendations for future research.", "url": "https://arxiv.org/abs/2309.12626"}, {"metadata": {"arXiv": "2309.12627", "Date": "Fri, 22 Sep 2023 05:27:23 ", "Title": "A Quantum Computing-based System for Portfolio Optimization using Future Asset Values and Automatic Reduction of the Investment Universe", "Authors": ["Eneko Osaba", "Guillaume Gelabert", "Esther Villar-Rodriguez", "Ant\\'on Asla and Izaskun Oregi"], "Categories": "cs.AI cs.ET", "Comments": ["10 pages", "3 figures", "paper accepted for being presented in the upcoming 9th International Congress on Information and Communication Technology (ICICT 2024)"]}, "abstract": "One of the problems in quantitative finance that has received the most attention is the portfolio optimization problem. Regarding its solving, this problem has been approached using different techniques, with those related to quantum computing being especially prolific in recent years. In this study, we present a system called Quantum Computing-based System for Portfolio Optimization with Future Asset Values and Automatic Universe Reduction (Q4FuturePOP), which deals with the Portfolio Optimization Problem considering the following innovations: i) the developed tool is modeled for working with future prediction of assets, instead of historical values; and ii) Q4FuturePOP includes an automatic universe reduction module, which is conceived to intelligently reduce the complexity of the problem. We also introduce a brief discussion about the preliminary performance of the different modules that compose the prototypical version of Q4FuturePOP.", "url": "https://arxiv.org/abs/2309.12627"}, {"metadata": {"arXiv": "2309.12655", "Date": "Fri, 22 Sep 2023 06:52:30 ", "Title": "Natural revision is contingently-conditionalized revision", "Authors": ["Paolo Liberatore"], "Categories": "cs.AI"}, "abstract": "Natural revision seems so natural: it changes beliefs as little as possible to incorporate new information. Yet, some counterexamples show it wrong. It is so conservative that it never fully believes. It only believes in the current conditions. This is right in some cases and wrong in others. Which is which? The answer requires extending natural revision from simple formulae expressing universal truths (something holds) to conditionals expressing conditional truth (something holds in certain conditions). The extension is based on the basic principles natural revision follows, identified as minimal change, indifference and naivety: change beliefs as little as possible; equate the likeliness of scenarios by default; believe all until contradicted. The extension says that natural revision restricts changes to the current conditions. A comparison with an unrestricting revision shows what exactly the current conditions are. It is not what currently considered true if it contradicts the new information. It includes something more and more unlikely until the new information is at least possible.", "url": "https://arxiv.org/abs/2309.12655"}, {"metadata": {"arXiv": "2309.12675", "Date": "Fri, 22 Sep 2023 07:35:37 ", "Title": "Vision Transformers for Computer Go", "Authors": ["Amani Sagri and Tristan Cazenave and J\\'er\\^ome Arjonilla and Abdallah Saffidine"], "Categories": "cs.AI cs.CV"}, "abstract": "Motivated by the success of transformers in various fields, such as language understanding and image analysis, this investigation explores their application in the context of the game of Go. In particular, our study focuses on the analysis of the Transformer in Vision. Through a detailed analysis of numerous points such as prediction accuracy, win rates, memory, speed, size, or even learning rate, we have been able to highlight the substantial role that transformers can play in the game of Go. This study was carried out by comparing them to the usual Residual Networks.", "url": "https://arxiv.org/abs/2309.12675"}, {"metadata": {"arXiv": "2309.12677", "Date": "Fri, 22 Sep 2023 07:36:22 ", "Title": "TrTr: A Versatile Pre-Trained Large Traffic Model based on Transformer for Capturing Trajectory Diversity in Vehicle Population", "Authors": ["Ruyi Feng", "Zhibin Li", "Bowen Liu", "Yan Ding and Ou Zheng"], "Categories": "cs.AI physics.data-an", "Comments": ["16 pages", "6 figures", "under reviewed by Transportation Research Board Annual Meeting", "work in update"]}, "abstract": "Understanding trajectory diversity is a fundamental aspect of addressing practical traffic tasks. However, capturing the diversity of trajectories presents challenges, particularly with traditional machine learning and recurrent neural networks due to the requirement of large-scale parameters. The emerging Transformer technology, renowned for its parallel computation capabilities enabling the utilization of models with hundreds of millions of parameters, offers a promising solution. In this study, we apply the Transformer architecture to traffic tasks, aiming to learn the diversity of trajectories within vehicle populations. We analyze the Transformer's attention mechanism and its adaptability to the goals of traffic tasks, and subsequently, design specific pre-training tasks. To achieve this, we create a data structure tailored to the attention mechanism and introduce a set of noises that correspond to spatio-temporal demands, which are incorporated into the structured data during the pre-training process. The designed pre-training model demonstrates excellent performance in capturing the spatial distribution of the vehicle population, with no instances of vehicle overlap and an RMSE of 0.6059 when compared to the ground truth values. In the context of time series prediction, approximately 95% of the predicted trajectories' speeds closely align with the true speeds, within a deviation of 7.5144m/s. Furthermore, in the stability test, the model exhibits robustness by continuously predicting a time series ten times longer than the input sequence, delivering smooth trajectories and showcasing diverse driving behaviors. The pre-trained model also provides a good basis for downstream fine-tuning tasks. The number of parameters of our model is over 50 million.", "url": "https://arxiv.org/abs/2309.12677"}, {"metadata": {"arXiv": "2309.12696", "Date": "Fri, 22 Sep 2023 08:10:25 ", "Title": "Counterfactual Conservative Q Learning for Offline Multi-agent Reinforcement Learning", "Authors": ["Jianzhun Shao", "Yun Qu", "Chen Chen", "Hongchang Zhang", "Xiangyang Ji"], "Categories": "cs.AI", "Comments": ["37th Conference on Neural Information Processing Systems (NeurIPS 2023)"]}, "abstract": "Offline multi-agent reinforcement learning is challenging due to the coupling effect of both distribution shift issue common in offline setting and the high dimension issue common in multi-agent setting, making the action out-of-distribution (OOD) and value overestimation phenomenon excessively severe. Tomitigate this problem, we propose a novel multi-agent offline RL algorithm, named CounterFactual Conservative Q-Learning (CFCQL) to conduct conservative value estimation. Rather than regarding all the agents as a high dimensional single one and directly applying single agent methods to it, CFCQL calculates conservative regularization for each agent separately in a counterfactual way and then linearly combines them to realize an overall conservative value estimation. We prove that it still enjoys the underestimation property and the performance guarantee as those single agent conservative methods do, but the induced regularization and safe policy improvement bound are independent of the agent number, which is therefore theoretically superior to the direct treatment referred to above, especially when the agent number is large. We further conduct experiments on four environments including both discrete and continuous action settings on both existing and our man-made datasets, demonstrating that CFCQL outperforms existing methods on most datasets and even with a remarkable margin on some of them.", "url": "https://arxiv.org/abs/2309.12696"}, {"metadata": {"arXiv": "2309.12711", "Date": "Fri, 22 Sep 2023 08:43:57 ", "Title": "The Mathematical Game", "Authors": ["Marc Pierre and Quentin Cohen-Solal and Tristan Cazenave"], "Categories": "cs.AI"}, "abstract": "Monte Carlo Tree Search can be used for automated theorem proving. Holophrasm is a neural theorem prover using MCTS combined with neural networks for the policy and the evaluation. In this paper we propose to improve the performance of the Holophrasm theorem prover using other game tree search algorithms.", "url": "https://arxiv.org/abs/2309.12711"}, {"metadata": {"arXiv": "2309.12727", "Date": "Fri, 22 Sep 2023 09:18:55 ", "Title": "In-context Interference in Chat-based Large Language Models", "Authors": ["Eric Nuertey Coleman", "Julio Hurtado", "Vincenzo Lomonaco"], "Categories": "cs.AI cs.CL"}, "abstract": "Large language models (LLMs) have had a huge impact on society due to their impressive capabilities and vast knowledge of the world. Various applications and tools have been created that allow users to interact with these models in a black-box scenario. However, one limitation of this scenario is that users cannot modify the internal knowledge of the model, and the only way to add or modify internal knowledge is by explicitly mentioning it to the model during the current interaction. This learning process is called in-context training, and it refers to training that is confined to the user's current session or context. In-context learning has significant applications, but also has limitations that are seldom studied. In this paper, we present a study that shows how the model can suffer from interference between information that continually flows in the context, causing it to forget previously learned knowledge, which can reduce the model's performance. Along with showing the problem, we propose an evaluation benchmark based on the bAbI dataset.", "url": "https://arxiv.org/abs/2309.12727"}, {"metadata": {"arXiv": "2309.12731", "Date": "Fri, 22 Sep 2023 09:27:26 ", "Title": "Defeasible Reasoning with Knowledge Graphs", "Authors": ["Dave Raggett"], "Categories": "cs.AI", "Comments": ["Accepted for: Knowledge Graph and Semantic Web Conference (KGSWC-2023)", "13-15 September", "2023", "Zaragoza", "Spain"]}, "abstract": "Human knowledge is subject to uncertainties, imprecision, incompleteness and inconsistencies. Moreover, the meaning of many everyday terms is dependent on the context. That poses a huge challenge for the Semantic Web. This paper introduces work on an intuitive notation and model for defeasible reasoning with imperfect knowledge, and relates it to previous work on argumentation theory. PKN is to N3 as defeasible reasoning is to deductive logic. Further work is needed on an intuitive syntax for describing reasoning strategies and tactics in declarative terms, drawing upon the AIF ontology for inspiration. The paper closes with observations on symbolic approaches in the era of large language models.", "url": "https://arxiv.org/abs/2309.12731"}, {"metadata": {"arXiv": "2309.12732", "Date": "Fri, 22 Sep 2023 09:31:39 ", "Title": "OpenAi's GPT4 as coding assistant", "Authors": ["Lefteris Moussiades and George Zografos"], "Categories": "cs.AI cs.SE", "Comments": ["10 pages"]}, "abstract": "Lately, Large Language Models have been widely used in code generation. GPT4 is considered the most potent Large Language Model from Openai. In this paper, we examine GPT3.5 and GPT4 as coding assistants. More specifically, we have constructed appropriate tests to check whether the two systems can a) answer typical questions that can arise during the code development, b) produce reliable code, and c) contribute to code debugging. The test results are impressive. The performance of GPT4 is outstanding and signals an increase in the productivity of programmers and the reorganization of software development procedures based on these new tools.", "url": "https://arxiv.org/abs/2309.12732"}, {"metadata": {"arXiv": "2309.12908", "Date": "Fri, 22 Sep 2023 14:52:10 ", "Title": "KG-MDL: Mining Graph Patterns in Knowledge Graphs with the MDL Principle", "Authors": ["Francesco Bariatti", "Peggy Cellier", "S\\'ebastien Ferr\\'e"], "Categories": "cs.AI cs.IT math.IT"}, "abstract": "Nowadays, increasingly more data are available as knowledge graphs (KGs). While this data model supports advanced reasoning and querying, they remain difficult to mine due to their size and complexity. Graph mining approaches can be used to extract patterns from KGs. However this presents two main issues. First, graph mining approaches tend to extract too many patterns for a human analyst to interpret (pattern explosion). Second, real-life KGs tend to differ from the graphs usually treated in graph mining: they are multigraphs, their vertex degrees tend to follow a power-law, and the way in which they model knowledge can produce spurious patterns. Recently, a graph mining approach named GraphMDL+ has been proposed to tackle the problem of pattern explosion, using the Minimum Description Length (MDL) principle. However, GraphMDL+, like other graph mining approaches, is not suited for KGs without adaptations. In this paper we propose KG-MDL, a graph pattern mining approach based on the MDL principle that, given a KG, generates a human-sized and descriptive set of graph patterns, and so in a parameter-less and anytime way. We report on experiments on medium-sized KGs showing that our approach generates sets of patterns that are both small enough to be interpreted by humans and descriptive of the KG. We show that the extracted patterns highlight relevant characteristics of the data: both of the schema used to create the data, and of the concrete facts it contains. We also discuss the issues related to mining graph patterns on knowledge graphs, as opposed to other types of graph data.", "url": "https://arxiv.org/abs/2309.12908"}, {"metadata": {"arXiv": "2309.12938", "Date": "Fri, 22 Sep 2023 15:37:07 ", "Title": "Frustrated with Code Quality Issues? LLMs can Help!", "Authors": ["Nalin Wadhwa", "Jui Pradhan", "Atharv Sonwane", "Surya Prakash Sahu", "Nagarajan Natarajan", "Aditya Kanade", "Suresh Parthasarathy", "Sriram Rajamani"], "Categories": "cs.AI cs.SE"}, "abstract": "As software projects progress, quality of code assumes paramount importance as it affects reliability, maintainability and security of software. For this reason, static analysis tools are used in developer workflows to flag code quality issues. However, developers need to spend extra efforts to revise their code to improve code quality based on the tool findings. In this work, we investigate the use of (instruction-following) large language models (LLMs) to assist developers in revising code to resolve code quality issues. We present a tool, CORE (short for COde REvisions), architected using a pair of LLMs organized as a duo comprised of a proposer and a ranker. Providers of static analysis tools recommend ways to mitigate the tool warnings and developers follow them to revise their code. The \\emph{proposer LLM} of CORE takes the same set of recommendations and applies them to generate candidate code revisions. The candidates which pass the static quality checks are retained. However, the LLM may introduce subtle, unintended functionality changes which may go un-detected by the static analysis. The \\emph{ranker LLM} evaluates the changes made by the proposer using a rubric that closely follows the acceptance criteria that a developer would enforce. CORE uses the scores assigned by the ranker LLM to rank the candidate revisions before presenting them to the developer. CORE could revise 59.2% Python files (across 52 quality checks) so that they pass scrutiny by both a tool and a human reviewer. The ranker LLM is able to reduce false positives by 25.8% in these cases. CORE produced revisions that passed the static analysis tool in 76.8% Java files (across 10 quality checks) comparable to 78.3% of a specialized program repair tool, with significantly much less engineering efforts.", "url": "https://arxiv.org/abs/2309.12938"}, {"metadata": {"arXiv": "2309.12382", "Date": "Thu, 21 Sep 2023 15:06:08 ", "Title": "SCOB: Universal Text Understanding via Character-wise Supervised Contrastive Learning with Online Text Rendering for Bridging Domain Gap", "Authors": ["Daehee Kim", "Yoonsik Kim", "DongHyun Kim", "Yumin Lim", "Geewook Kim", "Taeho Kil"], "Categories": "cs.CV cs.AI", "Comments": ["ICCV 2023"], "MSC-class": "68Txx"}, "abstract": "Inspired by the great success of language model (LM)-based pre-training, recent studies in visual document understanding have explored LM-based pre-training methods for modeling text within document images. Among them, pre-training that reads all text from an image has shown promise, but often exhibits instability and even fails when applied to broader domains, such as those involving both visual documents and scene text images. This is a substantial limitation for real-world scenarios, where the processing of text image inputs in diverse domains is essential. In this paper, we investigate effective pre-training tasks in the broader domains and also propose a novel pre-training method called SCOB that leverages character-wise supervised contrastive learning with online text rendering to effectively pre-train document and scene text domains by bridging the domain gap. Moreover, SCOB enables weakly supervised learning, significantly reducing annotation costs. Extensive benchmarks demonstrate that SCOB generally improves vanilla pre-training methods and achieves comparable performance to state-of-the-art methods. Our findings suggest that SCOB can be served generally and effectively for read-type pre-training methods. The code will be available at https://github.com/naver-ai/scob.", "url": "https://arxiv.org/abs/2309.12382"}, {"metadata": {"arXiv": "2309.12867", "Date": "Fri, 22 Sep 2023 13:43:22 ", "Title": "Accurate and Fast Compressed Video Captioning", "Authors": ["Yaojie Shen", "Xin Gu", "Kai Xu", "Heng Fan", "Longyin Wen", "Libo Zhang"], "Categories": "cs.CV cs.AI"}, "abstract": "Existing video captioning approaches typically require to first sample video frames from a decoded video and then conduct a subsequent process (e.g., feature extraction and/or captioning model learning). In this pipeline, manual frame sampling may ignore key information in videos and thus degrade performance. Additionally, redundant information in the sampled frames may result in low efficiency in the inference of video captioning. Addressing this, we study video captioning from a different perspective in compressed domain, which brings multi-fold advantages over the existing pipeline: 1) Compared to raw images from the decoded video, the compressed video, consisting of I-frames, motion vectors and residuals, is highly distinguishable, which allows us to leverage the entire video for learning without manual sampling through a specialized model design; 2) The captioning model is more efficient in inference as smaller and less redundant information is processed. We propose a simple yet effective end-to-end transformer in the compressed domain for video captioning that enables learning from the compressed video for captioning. We show that even with a simple design, our method can achieve state-of-the-art performance on different benchmarks while running almost 2x faster than existing approaches. Code is available at https://github.com/acherstyx/CoCap.", "url": "https://arxiv.org/abs/2309.12867"}, {"metadata": {"arXiv": "2309.12876", "Date": "Fri, 22 Sep 2023 14:02:22 ", "Title": "Gravity Network for end-to-end small lesion detection", "Authors": ["Ciro Russo", "Alessandro Bria", "Claudio Marrocco"], "Categories": "cs.CV cs.AI"}, "abstract": "This paper introduces a novel one-stage end-to-end detector specifically designed to detect small lesions in medical images. Precise localization of small lesions presents challenges due to their appearance and the diverse contextual backgrounds in which they are found. To address this, our approach introduces a new type of pixel-based anchor that dynamically moves towards the targeted lesion for detection. We refer to this new architecture as GravityNet, and the novel anchors as gravity points since they appear to be \"attracted\" by the lesions. We conducted experiments on two well-established medical problems involving small lesions to evaluate the performance of the proposed approach: microcalcifications detection in digital mammograms and microaneurysms detection in digital fundus images. Our method demonstrates promising results in effectively detecting small lesions in these medical imaging tasks.", "url": "https://arxiv.org/abs/2309.12876"}, {"metadata": {"arXiv": "2309.12474", "Date": "Thu, 21 Sep 2023 20:41:47 ", "Title": "SAVME: Efficient Safety Validation for Autonomous Systems Using Meta-Learning", "Authors": ["Marc R. Schlichting", "Nina V. Board", "Anthony L. Corso", "Mykel J. Kochenderfer"], "Categories": "cs.RO cs.AI cs.CY cs.ET cs.SY eess.SY", "Comments": ["Accepted for ITSC 2023"]}, "abstract": "Discovering potential failures of an autonomous system is important prior to deployment. Falsification-based methods are often used to assess the safety of such systems, but the cost of running many accurate simulation can be high. The validation can be accelerated by identifying critical failure scenarios for the system under test and by reducing the simulation runtime. We propose a Bayesian approach that integrates meta-learning strategies with a multi-armed bandit framework. Our method involves learning distributions over scenario parameters that are prone to triggering failures in the system under test, as well as a distribution over fidelity settings that enable fast and accurate simulations. In the spirit of meta-learning, we also assess whether the learned fidelity settings distribution facilitates faster learning of the scenario parameter distributions for new scenarios. We showcase our methodology using a cutting-edge 3D driving simulator, incorporating 16 fidelity settings for an autonomous vehicle stack that includes camera and lidar sensors. We evaluate various scenarios based on an autonomous vehicle pre-crash typology. As a result, our approach achieves a significant speedup, up to 18 times faster compared to traditional methods that solely rely on a high-fidelity simulator.", "url": "https://arxiv.org/abs/2309.12474"}, {"metadata": {"arXiv": "2309.12560", "Date": "Fri, 22 Sep 2023 01:06:32 ", "Title": "Machine Learning Meets Advanced Robotic Manipulation", "Authors": ["Saeid Nahavandi", "Roohallah Alizadehsani", "Darius Nahavandi", "Chee Peng Lim", "Kevin Kelly", "Fernando Bello"], "Categories": "cs.RO cs.AI"}, "abstract": "Automated industries lead to high quality production, lower manufacturing cost and better utilization of human resources. Robotic manipulator arms have major role in the automation process. However, for complex manipulation tasks, hard coding efficient and safe trajectories is challenging and time consuming. Machine learning methods have the potential to learn such controllers based on expert demonstrations. Despite promising advances, better approaches must be developed to improve safety, reliability, and efficiency of ML methods in both training and deployment phases. This survey aims to review cutting edge technologies and recent trends on ML methods applied to real-world manipulation tasks. After reviewing the related background on ML, the rest of the paper is devoted to ML applications in different domains such as industry, healthcare, agriculture, space, military, and search and rescue. The paper is closed with important research directions for future works.", "url": "https://arxiv.org/abs/2309.12560"}, {"metadata": {"arXiv": "2309.12568", "Date": "Fri, 22 Sep 2023 01:47:47 ", "Title": "A Study on Learning Social Robot Navigation with Multimodal Perception", "Authors": ["Bhabaranjan Panigrahi", "Amir Hossain Raj", "Mohammad Nazeri and Xuesu Xiao"], "Categories": "cs.RO cs.AI"}, "abstract": "Autonomous mobile robots need to perceive the environments with their onboard sensors (e.g., LiDARs and RGB cameras) and then make appropriate navigation decisions. In order to navigate human-inhabited public spaces, such a navigation task becomes more than only obstacle avoidance, but also requires considering surrounding humans and their intentions to somewhat change the navigation behavior in response to the underlying social norms, i.e., being socially compliant. Machine learning methods are shown to be effective in capturing those complex and subtle social interactions in a data-driven manner, without explicitly hand-crafting simplified models or cost functions. Considering multiple available sensor modalities and the efficiency of learning methods, this paper presents a comprehensive study on learning social robot navigation with multimodal perception using a large-scale real-world dataset. The study investigates social robot navigation decision making on both the global and local planning levels and contrasts unimodal and multimodal learning against a set of classical navigation approaches in different social scenarios, while also analyzing the training and generalizability performance from the learning perspective. We also conduct a human study on how learning with multimodal perception affects the perceived social compliance. The results show that multimodal learning has a clear advantage over unimodal learning in both dataset and human studies. We open-source our code for the community's future use to study multimodal perception for learning social robot navigation.", "url": "https://arxiv.org/abs/2309.12568"}, {"metadata": {"arXiv": "2309.12692", "Date": "Fri, 22 Sep 2023 08:05:32 ", "Title": "Enhancing Graph Representation of the Environment through Local and Cloud Computation", "Authors": ["Francesco Argenziano", "Vincenzo Suriani and Daniele Nardi"], "Categories": "cs.RO cs.AI", "Comments": ["5 pages", "4 figures"]}, "abstract": "Enriching the robot representation of the operational environment is a challenging task that aims at bridging the gap between low-level sensor readings and high-level semantic understanding. Having a rich representation often requires computationally demanding architectures and pure point cloud based detection systems that struggle when dealing with everyday objects that have to be handled by the robot. To overcome these issues, we propose a graph-based representation that addresses this gap by providing a semantic representation of robot environments from multiple sources. In fact, to acquire information from the environment, the framework combines classical computer vision tools with modern computer vision cloud services, ensuring computational feasibility on onboard hardware. By incorporating an ontology hierarchy with over 800 object classes, the framework achieves cross-domain adaptability, eliminating the need for environment-specific tools. The proposed approach allows us to handle also small objects and integrate them into the semantic representation of the environment. The approach is implemented in the Robot Operating System (ROS) using the RViz visualizer for environment representation. This work is a first step towards the development of a general-purpose framework, to facilitate intuitive interaction and navigation across different domains.", "url": "https://arxiv.org/abs/2309.12692"}, {"metadata": {"arXiv": "2309.12825", "Date": "Fri, 22 Sep 2023 12:26:36 ", "Title": "OmniDrones: An Efficient and Flexible Platform for Reinforcement Learning in Drone Control", "Authors": ["Botian Xu", "Feng Gao", "Chao Yu", "Ruize Zhang", "Yi Wu", "Yu Wang"], "Categories": "cs.RO cs.AI", "Comments": ["Submitted to IEEE RA-L"]}, "abstract": "In this work, we introduce OmniDrones, an efficient and flexible platform tailored for reinforcement learning in drone control, built on Nvidia's Omniverse Isaac Sim. It employs a bottom-up design approach that allows users to easily design and experiment with various application scenarios on top of GPU-parallelized simulations. It also offers a range of benchmark tasks, presenting challenges ranging from single-drone hovering to over-actuated system tracking. In summary, we propose an open-sourced drone simulation platform, equipped with an extensive suite of tools for drone learning. It includes 4 drone models, 5 sensor modalities, 4 control modes, over 10 benchmark tasks, and a selection of widely used RL baselines. To showcase the capabilities of OmniDrones and to support future research, we also provide preliminary results on these benchmark tasks. We hope this platform will encourage further studies on applying RL to practical drone systems.", "url": "https://arxiv.org/abs/2309.12825"}, {"metadata": {"arXiv": "2309.13043", "Date": "Fri, 22 Sep 2023 17:59:48 ", "Title": "E(2)-Equivariant Graph Planning for Navigation", "Authors": ["Linfeng Zhao", "Hongyu Li", "Taskin Padir", "Huaizu Jiang", "Lawson L.S. Wong"], "Categories": "cs.RO cs.AI"}, "abstract": "Learning for robot navigation presents a critical and challenging task. The scarcity and costliness of real-world datasets necessitate efficient learning approaches. In this letter, we exploit Euclidean symmetry in planning for 2D navigation, which originates from Euclidean transformations between reference frames and enables parameter sharing. To address the challenges of unstructured environments, we formulate the navigation problem as planning on a geometric graph and develop an equivariant message passing network to perform value iteration. Furthermore, to handle multi-camera input, we propose a learnable equivariant layer to lift features to a desired space. We conduct comprehensive evaluations across five diverse tasks encompassing structured and unstructured environments, along with maps of known and unknown, given point goals or semantic goals. Our experiments confirm the substantial benefits on training efficiency, stability, and generalization.", "url": "https://arxiv.org/abs/2309.13043"}, {"metadata": {"arXiv": "2309.12501", "Date": "Thu, 21 Sep 2023 21:52:42 ", "Title": "Knowledge Graph Embedding: An Overview", "Authors": ["Xiou Ge", "Yun-Cheng Wang", "Bin Wang", "C.-C. Jay Kuo"], "Categories": "cs.AI cs.CL cs.LG"}, "abstract": "Many mathematical models have been leveraged to design embeddings for representing Knowledge Graph (KG) entities and relations for link prediction and many downstream tasks. These mathematically-inspired models are not only highly scalable for inference in large KGs, but also have many explainable advantages in modeling different relation patterns that can be validated through both formal proofs and empirical results. In this paper, we make a comprehensive overview of the current state of research in KG completion. In particular, we focus on two main branches of KG embedding (KGE) design: 1) distance-based methods and 2) semantic matching-based methods. We discover the connections between recently proposed models and present an underlying trend that might help researchers invent novel and more effective models. Next, we delve into CompoundE and CompoundE3D, which draw inspiration from 2D and 3D affine operations, respectively. They encompass a broad spectrum of techniques including distance-based and semantic-based methods. We will also discuss an emerging approach for KG completion which leverages pre-trained language models (PLMs) and textual descriptions of entities and relations and offer insights into the integration of KGE embedding methods with PLMs for KG completion.", "url": "https://arxiv.org/abs/2309.12501"}, {"metadata": {"arXiv": "2309.12913", "Date": "Fri, 22 Sep 2023 15:00:00 ", "Title": "A matter of attitude: Focusing on positive and active gradients to boost saliency maps", "Authors": ["Oscar Llorente", "Jaime Boal and Eugenio F. S\\'anchez-\\'Ubeda"], "Categories": "cs.AI cs.LG"}, "abstract": "Saliency maps have become one of the most widely used interpretability techniques for convolutional neural networks (CNN) due to their simplicity and the quality of the insights they provide. However, there are still some doubts about whether these insights are a trustworthy representation of what CNNs use to come up with their predictions. This paper explores how rescuing the sign of the gradients from the saliency map can lead to a deeper understanding of multi-class classification problems. Using both pretrained and trained from scratch CNNs we unveil that considering the sign and the effect not only of the correct class, but also the influence of the other classes, allows to better identify the pixels of the image that the network is really focusing on. Furthermore, how occluding or altering those pixels is expected to affect the outcome also becomes clearer.", "url": "https://arxiv.org/abs/2309.12913"}, {"metadata": {"arXiv": "2309.12708", "Date": "Fri, 22 Sep 2023 08:39:16 ", "Title": "PointSSC: A Cooperative Vehicle-Infrastructure Point Cloud Benchmark for Semantic Scene Completion", "Authors": ["Yuxiang Yan", "Boda Liu", "Jianfei Ai", "Qinbu Li", "Ru Wan", "Jian Pu"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["8 pages", "5 figures", "submitted to ICRA2024"]}, "abstract": "Semantic Scene Completion (SSC) aims to jointly generate space occupancies and semantic labels for complex 3D scenes. Most existing SSC models focus on volumetric representations, which are memory-inefficient for large outdoor spaces. Point clouds provide a lightweight alternative but existing benchmarks lack outdoor point cloud scenes with semantic labels. To address this, we introduce PointSSC, the first cooperative vehicle-infrastructure point cloud benchmark for semantic scene completion. These scenes exhibit long-range perception and minimal occlusion. We develop an automated annotation pipeline leveraging Segment Anything to efficiently assign semantics. To benchmark progress, we propose a LiDAR-based model with a Spatial-Aware Transformer for global and local feature extraction and a Completion and Segmentation Cooperative Module for joint completion and segmentation. PointSSC provides a challenging testbed to drive advances in semantic point cloud completion for real-world navigation.", "url": "https://arxiv.org/abs/2309.12708"}, {"metadata": {"arXiv": "2309.12757", "Date": "Fri, 22 Sep 2023 09:58:38 ", "Title": "Masking Improves Contrastive Self-Supervised Learning for ConvNets, and Saliency Tells You Where", "Authors": ["Zhi-Yi Chin", "Chieh-Ming Jiang", "Ching-Chun Huang", "Pin-Yu Chen", "Wei-Chen Chiu"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "While image data starts to enjoy the simple-but-effective self-supervised learning scheme built upon masking and self-reconstruction objective thanks to the introduction of tokenization procedure and vision transformer backbone, convolutional neural networks as another important and widely-adopted architecture for image data, though having contrastive-learning techniques to drive the self-supervised learning, still face the difficulty of leveraging such straightforward and general masking operation to benefit their learning process significantly. In this work, we aim to alleviate the burden of including masking operation into the contrastive-learning framework for convolutional neural networks as an extra augmentation method. In addition to the additive but unwanted edges (between masked and unmasked regions) as well as other adverse effects caused by the masking operations for ConvNets, which have been discussed by prior works, we particularly identify the potential problem where for one view in a contrastive sample-pair the randomly-sampled masking regions could be overly concentrated on important/salient objects thus resulting in misleading contrastiveness to the other view. To this end, we propose to explicitly take the saliency constraint into consideration in which the masked regions are more evenly distributed among the foreground and background for realizing the masking-based augmentation. Moreover, we introduce hard negative samples by masking larger regions of salient patches in an input image. Extensive experiments conducted on various datasets, contrastive learning mechanisms, and downstream tasks well verify the efficacy as well as the superior performance of our proposed method with respect to several state-of-the-art baselines.", "url": "https://arxiv.org/abs/2309.12757"}, {"metadata": {"arXiv": "2309.12829", "Date": "Fri, 22 Sep 2023 12:36:30 ", "Title": "Synthetic Boost: Leveraging Synthetic Data for Enhanced Vision-Language Segmentation in Echocardiography", "Authors": ["Rabin Adhikari", "Manish Dhakal", "Safal Thapaliya", "Kanchan Poudel", "Prasiddha Bhandari", "Bishesh Khanal"], "Categories": "cs.CV cs.AI cs.CL cs.LG", "Comments": ["Accepted at the 4th International Workshop of Advances in Simplifying Medical UltraSound (ASMUS)"]}, "abstract": "Accurate segmentation is essential for echocardiography-based assessment of cardiovascular diseases (CVDs). However, the variability among sonographers and the inherent challenges of ultrasound images hinder precise segmentation. By leveraging the joint representation of image and text modalities, Vision-Language Segmentation Models (VLSMs) can incorporate rich contextual information, potentially aiding in accurate and explainable segmentation. However, the lack of readily available data in echocardiography hampers the training of VLSMs. In this study, we explore using synthetic datasets from Semantic Diffusion Models (SDMs) to enhance VLSMs for echocardiography segmentation. We evaluate results for two popular VLSMs (CLIPSeg and CRIS) using seven different kinds of language prompts derived from several attributes, automatically extracted from echocardiography images, segmentation masks, and their metadata. Our results show improved metrics and faster convergence when pretraining VLSMs on SDM-generated synthetic images before finetuning on real images. The code, configs, and prompts are available at https://github.com/naamiinepal/synthetic-boost.", "url": "https://arxiv.org/abs/2309.12829"}, {"metadata": {"arXiv": "2309.13042", "Date": "Fri, 22 Sep 2023 17:59:42 ", "Title": "MosaicFusion: Diffusion Models as Data Augmenters for Large Vocabulary Instance Segmentation", "Authors": ["Jiahao Xie", "Wei Li", "Xiangtai Li", "Ziwei Liu", "Yew Soon Ong", "Chen Change Loy"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["GitHub: https://github.com/Jiahao000/MosaicFusion"]}, "abstract": "We present MosaicFusion, a simple yet effective diffusion-based data augmentation approach for large vocabulary instance segmentation. Our method is training-free and does not rely on any label supervision. Two key designs enable us to employ an off-the-shelf text-to-image diffusion model as a useful dataset generator for object instances and mask annotations. First, we divide an image canvas into several regions and perform a single round of diffusion process to generate multiple instances simultaneously, conditioning on different text prompts. Second, we obtain corresponding instance masks by aggregating cross-attention maps associated with object prompts across layers and diffusion time steps, followed by simple thresholding and edge-aware refinement processing. Without bells and whistles, our MosaicFusion can produce a significant amount of synthetic labeled data for both rare and novel categories. Experimental results on the challenging LVIS long-tailed and open-vocabulary benchmarks demonstrate that MosaicFusion can significantly improve the performance of existing instance segmentation models, especially for rare and novel categories. Code will be released at https://github.com/Jiahao000/MosaicFusion.", "url": "https://arxiv.org/abs/2309.13042"}, {"metadata": {"arXiv": "2309.12445", "Date": "Thu, 21 Sep 2023 19:38:44 ", "Title": "Ensemble Neural Networks for Remaining Useful Life (RUL) Prediction", "Authors": ["Ahbishek Srinivasan", "Juan Carlos Andresen", "Anders Holst"], "Categories": "cs.LG cs.AI", "Comments": ["6 pages", "2 figures", "2 tables", "conference proceeding"], "Journal-ref": "Proceedings of the Asia Pacific Conference of the PHM Society 2023, Vol. 4 No. 1 (2023)", "DOI": "10.36001/phmap.2023.v4i1.3611"}, "abstract": "A core part of maintenance planning is a monitoring system that provides a good prognosis on health and degradation, often expressed as remaining useful life (RUL). Most of the current data-driven approaches for RUL prediction focus on single-point prediction. These point prediction approaches do not include the probabilistic nature of the failure. The few probabilistic approaches to date either include the aleatoric uncertainty (which originates from the system), or the epistemic uncertainty (which originates from the model parameters), or both simultaneously as a total uncertainty. Here, we propose ensemble neural networks for probabilistic RUL predictions which considers both uncertainties and decouples these two uncertainties. These decoupled uncertainties are vital in knowing and interpreting the confidence of the predictions. This method is tested on NASA's turbofan jet engine CMAPSS data-set. Our results show how these uncertainties can be modeled and how to disentangle the contribution of aleatoric and epistemic uncertainty. Additionally, our approach is evaluated on different metrics and compared against the current state-of-the-art methods.", "url": "https://arxiv.org/abs/2309.12445"}, {"metadata": {"arXiv": "2309.12460", "Date": "Thu, 21 Sep 2023 20:09:22 ", "Title": "Multimodal Deep Learning for Scientific Imaging Interpretation", "Authors": ["Abdulelah S. Alshehri", "Franklin L. Lee", "Shihu Wang"], "Categories": "cs.LG cs.AI cs.CE cs.CL cs.CV", "Report-no": "NTR208745"}, "abstract": "In the domain of scientific imaging, interpreting visual data often demands an intricate combination of human expertise and deep comprehension of the subject materials. This study presents a novel methodology to linguistically emulate and subsequently evaluate human-like interactions with Scanning Electron Microscopy (SEM) images, specifically of glass materials. Leveraging a multimodal deep learning framework, our approach distills insights from both textual and visual data harvested from peer-reviewed articles, further augmented by the capabilities of GPT-4 for refined data synthesis and evaluation. Despite inherent challenges--such as nuanced interpretations and the limited availability of specialized datasets--our model (GlassLLaVA) excels in crafting accurate interpretations, identifying key features, and detecting defects in previously unseen SEM images. Moreover, we introduce versatile evaluation metrics, suitable for an array of scientific imaging applications, which allows for benchmarking against research-grounded answers. Benefiting from the robustness of contemporary Large Language Models, our model adeptly aligns with insights from research papers. This advancement not only underscores considerable progress in bridging the gap between human and machine interpretation in scientific imaging, but also hints at expansive avenues for future research and broader application.", "url": "https://arxiv.org/abs/2309.12460"}, {"metadata": {"arXiv": "2309.12482", "Date": "Thu, 21 Sep 2023 20:55:21 ", "Title": "State2Explanation: Concept-Based Explanations to Benefit Agent Learning and User Understanding", "Authors": ["Devleena Das", "Sonia Chernova", "Been Kim"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted to NeurIPS 2023"]}, "abstract": "With more complex AI systems used by non-AI experts to complete daily tasks, there is an increasing effort to develop methods that produce explanations of AI decision making understandable by non-AI experts. Towards this effort, leveraging higher-level concepts and producing concept-based explanations have become a popular method. Most concept-based explanations have been developed for classification techniques, and we posit that the few existing methods for sequential decision making are limited in scope. In this work, we first contribute a desiderata for defining \"concepts\" in sequential decision making settings. Additionally, inspired by the Protege Effect which states explaining knowledge often reinforces one's self-learning, we explore the utility of concept-based explanations providing a dual benefit to the RL agent by improving agent learning rate, and to the end-user by improving end-user understanding of agent decision making. To this end, we contribute a unified framework, State2Explanation (S2E), that involves learning a joint embedding model between state-action pairs and concept-based explanations, and leveraging such learned model to both (1) inform reward shaping during an agent's training, and (2) provide explanations to end-users at deployment for improved task performance. Our experimental validations, in Connect 4 and Lunar Lander, demonstrate the success of S2E in providing a dual-benefit, successfully informing reward shaping and improving agent learning rate, as well as significantly improving end user task performance at deployment time.", "url": "https://arxiv.org/abs/2309.12482"}, {"metadata": {"arXiv": "2309.12545", "Date": "Fri, 22 Sep 2023 00:12:09 ", "Title": "Provably Robust and Plausible Counterfactual Explanations for Neural Networks via Robust Optimisation", "Authors": ["Junqi Jiang", "Jianglin Lan", "Francesco Leofante", "Antonio Rago", "Francesca Toni"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted at ACML 2023", "camera-ready version"]}, "abstract": "Counterfactual Explanations (CEs) have received increasing interest as a major methodology for explaining neural network classifiers. Usually, CEs for an input-output pair are defined as data points with minimum distance to the input that are classified with a different label than the output. To tackle the established problem that CEs are easily invalidated when model parameters are updated (e.g. retrained), studies have proposed ways to certify the robustness of CEs under model parameter changes bounded by a norm ball. However, existing methods targeting this form of robustness are not sound or complete, and they may generate implausible CEs, i.e., outliers wrt the training dataset. In fact, no existing method simultaneously optimises for proximity and plausibility while preserving robustness guarantees. In this work, we propose Provably RObust and PLAusible Counterfactual Explanations (PROPLACE), a method leveraging on robust optimisation techniques to address the aforementioned limitations in the literature. We formulate an iterative algorithm to compute provably robust CEs and prove its convergence, soundness and completeness. Through a comparative experiment involving six baselines, five of which target robustness, we show that PROPLACE achieves state-of-the-art performances against metrics on three evaluation aspects.", "url": "https://arxiv.org/abs/2309.12545"}, {"metadata": {"arXiv": "2309.12559", "Date": "Fri, 22 Sep 2023 01:06:16 ", "Title": "Invariant Learning via Probability of Sufficient and Necessary Causes", "Authors": ["Mengyue Yang", "Zhen Fang", "Yonggang Zhang", "Yali Du", "Furui Liu", "Jean-Francois Ton", "Jun Wang"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "Out-of-distribution (OOD) generalization is indispensable for learning models in the wild, where testing distribution typically unknown and different from the training. Recent methods derived from causality have shown great potential in achieving OOD generalization. However, existing methods mainly focus on the invariance property of causes, while largely overlooking the property of \\textit{sufficiency} and \\textit{necessity} conditions. Namely, a necessary but insufficient cause (feature) is invariant to distribution shift, yet it may not have required accuracy. By contrast, a sufficient yet unnecessary cause (feature) tends to fit specific data well but may have a risk of adapting to a new domain. To capture the information of sufficient and necessary causes, we employ a classical concept, the probability of sufficiency and necessary causes (PNS), which indicates the probability of whether one is the necessary and sufficient cause. To associate PNS with OOD generalization, we propose PNS risk and formulate an algorithm to learn representation with a high PNS value. We theoretically analyze and prove the generalizability of the PNS risk. Experiments on both synthetic and real-world benchmarks demonstrate the effectiveness of the proposed method. The details of the implementation can be found at the GitHub repository: https://github.com/ymy4323460/CaSN.", "url": "https://arxiv.org/abs/2309.12559"}, {"metadata": {"arXiv": "2309.12632", "Date": "Fri, 22 Sep 2023 05:57:25 ", "Title": "Are Deep Learning Classification Results Obtained on CT Scans Fair and Interpretable?", "Authors": ["Mohamad M.A. Ashames", "Ahmet Demir", "Omer N. Gerek", "Mehmet Fidan", "M. Bilginer Gulmezoglu", "Semih Ergin", "Mehmet Koc", "Atalay Barkana", "Cuneyt Calisir"], "Categories": "cs.LG cs.AI eess.IV stat.ME", "Comments": ["This version has been submitted to CAAI Transactions on Intelligence Technology. 2023"]}, "abstract": "Following the great success of various deep learning methods in image and object classification, the biomedical image processing society is also overwhelmed with their applications to various automatic diagnosis cases. Unfortunately, most of the deep learning-based classification attempts in the literature solely focus on the aim of extreme accuracy scores, without considering interpretability, or patient-wise separation of training and test data. For example, most lung nodule classification papers using deep learning randomly shuffle data and split it into training, validation, and test sets, causing certain images from the CT scan of a person to be in the training set, while other images of the exact same person to be in the validation or testing image sets. This can result in reporting misleading accuracy rates and the learning of irrelevant features, ultimately reducing the real-life usability of these models. When the deep neural networks trained on the traditional, unfair data shuffling method are challenged with new patient images, it is observed that the trained models perform poorly. In contrast, deep neural networks trained with strict patient-level separation maintain their accuracy rates even when new patient images are tested. Heat-map visualizations of the activations of the deep neural networks trained with strict patient-level separation indicate a higher degree of focus on the relevant nodules. We argue that the research question posed in the title has a positive answer only if the deep neural networks are trained with images of patients that are strictly isolated from the validation and testing patient sets.", "url": "https://arxiv.org/abs/2309.12632"}, {"metadata": {"arXiv": "2309.12671", "Date": "Fri, 22 Sep 2023 07:27:32 ", "Title": "How to Fine-tune the Model: Unified Model Shift and Model Bias Policy Optimization", "Authors": ["Hai Zhang", "Hang Yu", "Junqiao Zhao", "Di Zhang", "ChangHuang", "Hongtu Zhou", "Xiao Zhang", "Chen Ye"], "Categories": "cs.LG cs.AI"}, "abstract": "Designing and deriving effective model-based reinforcement learning (MBRL) algorithms with a performance improvement guarantee is challenging, mainly attributed to the high coupling between model learning and policy optimization. Many prior methods that rely on return discrepancy to guide model learning ignore the impacts of model shift, which can lead to performance deterioration due to excessive model updates. Other methods use performance difference bound to explicitly consider model shift. However, these methods rely on a fixed threshold to constrain model shift, resulting in a heavy dependence on the threshold and a lack of adaptability during the training process. In this paper, we theoretically derive an optimization objective that can unify model shift and model bias and then formulate a fine-tuning process. This process adaptively adjusts the model updates to get a performance improvement guarantee while avoiding model overfitting. Based on these, we develop a straightforward algorithm USB-PO (Unified model Shift and model Bias Policy Optimization). Empirical results show that USB-PO achieves state-of-the-art performance on several challenging benchmark tasks.", "url": "https://arxiv.org/abs/2309.12671"}, {"metadata": {"arXiv": "2309.12673", "Date": "Fri, 22 Sep 2023 07:32:45 ", "Title": "On Sparse Modern Hopfield Model", "Authors": ["Jerry Yao-Chieh Hu", "Donglin Yang", "Dennis Wu", "Chenwei Xu", "Bo-Yu Chen", "Han Liu"], "Categories": "cs.LG cs.AI cs.CV stat.ML", "Comments": ["37 pages", "accepted to NeurIPS 2023"]}, "abstract": "We introduce the sparse modern Hopfield model as a sparse extension of the modern Hopfield model. Like its dense counterpart, the sparse modern Hopfield model equips a memory-retrieval dynamics whose one-step approximation corresponds to the sparse attention mechanism. Theoretically, our key contribution is a principled derivation of a closed-form sparse Hopfield energy using the convex conjugate of the sparse entropic regularizer. Building upon this, we derive the sparse memory retrieval dynamics from the sparse energy function and show its one-step approximation is equivalent to the sparse-structured attention. Importantly, we provide a sparsity-dependent memory retrieval error bound which is provably tighter than its dense analog. The conditions for the benefits of sparsity to arise are therefore identified and discussed. In addition, we show that the sparse modern Hopfield model maintains the robust theoretical properties of its dense counterpart, including rapid fixed point convergence and exponential memory capacity. Empirically, we use both synthetic and real-world datasets to demonstrate that the sparse Hopfield model outperforms its dense counterpart in many situations.", "url": "https://arxiv.org/abs/2309.12673"}, {"metadata": {"arXiv": "2309.12706", "Date": "Fri, 22 Sep 2023 08:35:38 ", "Title": "Multi-Label Noise Transition Matrix Estimation with Label Correlations: Theory and Algorithm", "Authors": ["Shikun Li", "Xiaobo Xia", "Hansong Zhang", "Shiming Ge", "Tongliang Liu"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "Noisy multi-label learning has garnered increasing attention due to the challenges posed by collecting large-scale accurate labels, making noisy labels a more practical alternative. Motivated by noisy multi-class learning, the introduction of transition matrices can help model multi-label noise and enable the development of statistically consistent algorithms for noisy multi-label learning. However, estimating multi-label noise transition matrices remains a challenging task, as most existing estimators in noisy multi-class learning rely on anchor points and accurate fitting of noisy class posteriors, which is hard to satisfy in noisy multi-label learning. In this paper, we address this problem by first investigating the identifiability of class-dependent transition matrices in noisy multi-label learning. Building upon the identifiability results, we propose a novel estimator that leverages label correlations without the need for anchor points or precise fitting of noisy class posteriors. Specifically, we first estimate the occurrence probability of two noisy labels to capture noisy label correlations. Subsequently, we employ sample selection techniques to extract information implying clean label correlations, which are then used to estimate the occurrence probability of one noisy label when a certain clean label appears. By exploiting the mismatches in label correlations implied by these occurrence probabilities, we demonstrate that the transition matrix becomes identifiable and can be acquired by solving a bilinear decomposition problem. Theoretically, we establish an estimation error bound for our multi-label transition matrix estimator and derive a generalization error bound for our statistically consistent algorithm. Empirically, we validate the effectiveness of our estimator in estimating multi-label noise transition matrices, leading to excellent classification performance.", "url": "https://arxiv.org/abs/2309.12706"}, {"metadata": {"arXiv": "2309.12716", "Date": "Fri, 22 Sep 2023 08:58:22 ", "Title": "H2O+: An Improved Framework for Hybrid Offline-and-Online RL with Dynamics Gaps", "Authors": ["Haoyi Niu", "Tianying Ji", "Bingqi Liu", "Haocheng Zhao", "Xiangyu Zhu", "Jianying Zheng", "Pengfei Huang", "Guyue Zhou", "Jianming Hu", "Xianyuan Zhan"], "Categories": "cs.LG cs.AI cs.RO"}, "abstract": "Solving real-world complex tasks using reinforcement learning (RL) without high-fidelity simulation environments or large amounts of offline data can be quite challenging. Online RL agents trained in imperfect simulation environments can suffer from severe sim-to-real issues. Offline RL approaches although bypass the need for simulators, often pose demanding requirements on the size and quality of the offline datasets. The recently emerged hybrid offline-and-online RL provides an attractive framework that enables joint use of limited offline data and imperfect simulator for transferable policy learning. In this paper, we develop a new algorithm, called H2O+, which offers great flexibility to bridge various choices of offline and online learning methods, while also accounting for dynamics gaps between the real and simulation environment. Through extensive simulation and real-world robotics experiments, we demonstrate superior performance and flexibility over advanced cross-domain online and offline RL algorithms.", "url": "https://arxiv.org/abs/2309.12716"}, {"metadata": {"arXiv": "2309.12971", "Date": "Fri, 22 Sep 2023 16:11:17 ", "Title": "Higher-order Graph Convolutional Network with Flower-Petals Laplacians on Simplicial Complexes", "Authors": ["Yiming Huang", "Yujie Zeng", "Qiang Wu", "Linyuan L\\\"u"], "Categories": "cs.LG cond-mat.stat-mech cs.AI cs.SI physics.soc-ph"}, "abstract": "Despite the recent successes of vanilla Graph Neural Networks (GNNs) on many tasks, their foundation on pairwise interaction networks inherently limits their capacity to discern latent higher-order interactions in complex systems. To bridge this capability gap, we propose a novel approach exploiting the rich mathematical theory of simplicial complexes (SCs) - a robust tool for modeling higher-order interactions. Current SC-based GNNs are burdened by high complexity and rigidity, and quantifying higher-order interaction strengths remains challenging. Innovatively, we present a higher-order Flower-Petals (FP) model, incorporating FP Laplacians into SCs. Further, we introduce a Higher-order Graph Convolutional Network (HiGCN) grounded in FP Laplacians, capable of discerning intrinsic features across varying topological scales. By employing learnable graph filters, a parameter group within each FP Laplacian domain, we can identify diverse patterns where the filters' weights serve as a quantifiable measure of higher-order interaction strengths. The theoretical underpinnings of HiGCN's advanced expressiveness are rigorously demonstrated. Additionally, our empirical investigations reveal that the proposed model accomplishes state-of-the-art (SOTA) performance on a range of graph tasks and provides a scalable and flexible solution to explore higher-order interactions in graphs.", "url": "https://arxiv.org/abs/2309.12971"}, {"metadata": {"arXiv": "2309.13005", "Date": "Fri, 22 Sep 2023 17:08:20 ", "Title": "Pursuing Counterfactual Fairness via Sequential Autoencoder Across Domains", "Authors": ["Yujie Lin", "Chen Zhao", "Minglai Shao", "Baoluo Meng", "Xujiang Zhao", "Haifeng Chen"], "Categories": "cs.LG cs.AI cs.CY"}, "abstract": "Recognizing the prevalence of domain shift as a common challenge in machine learning, various domain generalization (DG) techniques have been developed to enhance the performance of machine learning systems when dealing with out-of-distribution (OOD) data. Furthermore, in real-world scenarios, data distributions can gradually change across a sequence of sequential domains. While current methodologies primarily focus on improving model effectiveness within these new domains, they often overlook fairness issues throughout the learning process. In response, we introduce an innovative framework called Counterfactual Fairness-Aware Domain Generalization with Sequential Autoencoder (CDSAE). This approach effectively separates environmental information and sensitive attributes from the embedded representation of classification features. This concurrent separation not only greatly improves model generalization across diverse and unfamiliar domains but also effectively addresses challenges related to unfair classification. Our strategy is rooted in the principles of causal inference to tackle these dual issues. To examine the intricate relationship between semantic information, sensitive attributes, and environmental cues, we systematically categorize exogenous uncertainty factors into four latent variables: 1) semantic information influenced by sensitive attributes, 2) semantic information unaffected by sensitive attributes, 3) environmental cues influenced by sensitive attributes, and 4) environmental cues unaffected by sensitive attributes. By incorporating fairness regularization, we exclusively employ semantic information for classification purposes. Empirical validation on synthetic and real-world datasets substantiates the effectiveness of our approach, demonstrating improved accuracy levels while ensuring the preservation of fairness in the evolving landscape of continuous domains.", "url": "https://arxiv.org/abs/2309.13005"}, {"metadata": {"arXiv": "2309.13015", "Date": "Fri, 22 Sep 2023 17:26:19 ", "Title": "Efficient N:M Sparse DNN Training Using Algorithm, Architecture, and Dataflow Co-Design", "Authors": ["Chao Fang", "Wei Sun", "Aojun Zhou", "Zhongfeng Wang"], "Categories": "cs.LG cs.AI cs.AR", "Comments": ["To appear in the IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD)"], "DOI": "10.1109/TCAD.2023.3317789"}, "abstract": "Sparse training is one of the promising techniques to reduce the computational cost of DNNs while retaining high accuracy. In particular, N:M fine-grained structured sparsity, where only N out of consecutive M elements can be nonzero, has attracted attention due to its hardware-friendly pattern and capability of achieving a high sparse ratio. However, the potential to accelerate N:M sparse DNN training has not been fully exploited, and there is a lack of efficient hardware supporting N:M sparse training. To tackle these challenges, this paper presents a computation-efficient training scheme for N:M sparse DNNs using algorithm, architecture, and dataflow co-design. At the algorithm level, a bidirectional weight pruning method, dubbed BDWP, is proposed to leverage the N:M sparsity of weights during both forward and backward passes of DNN training, which can significantly reduce the computational cost while maintaining model accuracy. At the architecture level, a sparse accelerator for DNN training, namely SAT, is developed to neatly support both the regular dense operations and the computation-efficient N:M sparse operations. At the dataflow level, multiple optimization methods ranging from interleave mapping, pre-generation of N:M sparse weights, and offline scheduling, are proposed to boost the computational efficiency of SAT. Finally, the effectiveness of our training scheme is evaluated on a Xilinx VCU1525 FPGA card using various DNN models and datasets. Experimental results show the SAT accelerator with the BDWP sparse training method under 2:8 sparse ratio achieves an average speedup of 1.75x over that with the dense training, accompanied by a negligible accuracy loss of 0.56% on average. Furthermore, our proposed training scheme significantly improves the training throughput by 2.97~25.22x and the energy efficiency by 1.36~3.58x over prior FPGA-based accelerators.", "url": "https://arxiv.org/abs/2309.13015"}, {"metadata": {"arXiv": "2309.13021", "Date": "Fri, 22 Sep 2023 17:31:47 ", "Title": "A Hybrid Deep Learning-based Approach for Optimal Genotype by Environment Selection", "Authors": ["Zahra Khalilzadeh", "Motahareh Kashanian", "Saeed Khaki", "Lizhi Wang"], "Categories": "cs.LG cs.AI q-bio.QM stat.ML", "Comments": ["20 pages", "7 figures"]}, "abstract": "Precise crop yield prediction is essential for improving agricultural practices and ensuring crop resilience in varying climates. Integrating weather data across the growing season, especially for different crop varieties, is crucial for understanding their adaptability in the face of climate change. In the MLCAS2021 Crop Yield Prediction Challenge, we utilized a dataset comprising 93,028 training records to forecast yields for 10,337 test records, covering 159 locations across 28 U.S. states and Canadian provinces over 13 years (2003-2015). This dataset included details on 5,838 distinct genotypes and daily weather data for a 214-day growing season, enabling comprehensive analysis. As one of the winning teams, we developed two novel convolutional neural network (CNN) architectures: the CNN-DNN model, combining CNN and fully-connected networks, and the CNN-LSTM-DNN model, with an added LSTM layer for weather variables. Leveraging the Generalized Ensemble Method (GEM), we determined optimal model weights, resulting in superior performance compared to baseline models. The GEM model achieved lower RMSE (5.55% to 39.88%), reduced MAE (5.34% to 43.76%), and higher correlation coefficients (1.1% to 10.79%) when evaluated on test data. We applied the CNN-DNN model to identify top-performing genotypes for various locations and weather conditions, aiding genotype selection based on weather variables. Our data-driven approach is valuable for scenarios with limited testing years. Additionally, a feature importance analysis using RMSE change highlighted the significance of location, MG, year, and genotype, along with the importance of weather variables MDNI and AP.", "url": "https://arxiv.org/abs/2309.13021"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

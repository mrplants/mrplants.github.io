<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2310.15308", "Date": "Mon, 23 Oct 2023 19:21:57 ", "Title": "SAM-CLIP: Merging Vision Foundation Models towards Semantic and Spatial Understanding", "Authors": ["Haoxiang Wang", "Pavan Kumar Anasosalu Vasu", "Fartash Faghri", "Raviteja Vemulapalli", "Mehrdad Farajtabar", "Sachin Mehta", "Mohammad Rastegari", "Oncel Tuzel", "Hadi Pouransari"], "Categories": "cs.CV cs.LG"}, "abstract": "The landscape of publicly available vision foundation models (VFMs), such as CLIP and Segment Anything Model (SAM), is expanding rapidly. VFMs are endowed with distinct capabilities stemming from their pre-training objectives. For instance, CLIP excels in semantic understanding, while SAM specializes in spatial understanding for segmentation. In this work, we introduce a simple recipe to efficiently merge VFMs into a unified model that assimilates their expertise. Our proposed method integrates multi-task learning, continual learning techniques, and teacher-student distillation. This strategy entails significantly less computational cost compared to traditional multi-task training from scratch. Additionally, it only demands a small fraction of the pre-training datasets that were initially used to train individual models. By applying our method to SAM and CLIP, we derive SAM-CLIP: a unified model that amalgamates the strengths of SAM and CLIP into a single backbone, making it apt for edge device applications. We show that SAM-CLIP learns richer visual representations, equipped with both localization and semantic features, suitable for a broad range of vision tasks. SAM-CLIP obtains improved performance on several head probing tasks when compared with SAM and CLIP. We further show that SAM-CLIP not only retains the foundational strengths of its precursor models but also introduces synergistic functionalities, most notably in zero-shot semantic segmentation, where SAM-CLIP establishes new state-of-the-art results on 5 benchmarks. It outperforms previous models that are specifically designed for this task by a large margin, including +6.8% and +5.9% mean IoU improvement on Pascal-VOC and COCO-Stuff datasets, respectively.", "url": "https://arxiv.org/abs/2310.15308"}, {"metadata": {"arXiv": "2310.15325", "Date": "Mon, 23 Oct 2023 19:46:41 ", "Title": "LXMERT Model Compression for Visual Question Answering", "Authors": ["Maryam Hashemi", "Ghazaleh Mahmoudi", "Sara Kodeiri", "Hadi Sheikhi", "Sauleh Eetemadi"], "Categories": "cs.CV cs.CL cs.LG", "Comments": ["To appear in The Fourth Annual West Coast NLP (WeCNLP) Summit"]}, "abstract": "Large-scale pretrained models such as LXMERT are becoming popular for learning cross-modal representations on text-image pairs for vision-language tasks. According to the lottery ticket hypothesis, NLP and computer vision models contain smaller subnetworks capable of being trained in isolation to full performance. In this paper, we combine these observations to evaluate whether such trainable subnetworks exist in LXMERT when fine-tuned on the VQA task. In addition, we perform a model size cost-benefit analysis by investigating how much pruning can be done without significant loss in accuracy. Our experiment results demonstrate that LXMERT can be effectively pruned by 40%-60% in size with 3% loss in accuracy.", "url": "https://arxiv.org/abs/2310.15325"}, {"metadata": {"arXiv": "2310.15388", "Date": "Mon, 23 Oct 2023 22:41:04 ", "Title": "Remote Heart Rate Monitoring in Smart Environments from Videos with Self-supervised Pre-training", "Authors": ["Divij Gupta", "Ali Etemad"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted in IEEE Internet of Things Journal 2023"]}, "abstract": "Recent advances in deep learning have made it increasingly feasible to estimate heart rate remotely in smart environments by analyzing videos. However, a notable limitation of deep learning methods is their heavy reliance on extensive sets of labeled data for effective training. To address this issue, self-supervised learning has emerged as a promising avenue. Building on this, we introduce a solution that utilizes self-supervised contrastive learning for the estimation of remote photoplethysmography (PPG) and heart rate monitoring, thereby reducing the dependence on labeled data and enhancing performance. We propose the use of 3 spatial and 3 temporal augmentations for training an encoder through a contrastive framework, followed by utilizing the late-intermediate embeddings of the encoder for remote PPG and heart rate estimation. Our experiments on two publicly available datasets showcase the improvement of our proposed approach over several related works as well as supervised learning baselines, as our results approach the state-of-the-art. We also perform thorough experiments to showcase the effects of using different design choices such as the video representation learning method, the augmentations used in the pre-training stage, and others. We also demonstrate the robustness of our proposed method over the supervised learning approaches on reduced amounts of labeled data.", "url": "https://arxiv.org/abs/2310.15388"}, {"metadata": {"arXiv": "2310.15624", "Date": "Tue, 24 Oct 2023 08:45:15 ", "Title": "GUPNet++: Geometry Uncertainty Propagation Network for Monocular 3D Object Detection", "Authors": ["Yan Lu", "Xinzhu Ma", "Lei Yang", "Tianzhu Zhang", "Yating Liu", "Qi Chu", "Tong He", "Yonghui Li", "Wanli Ouyang"], "Categories": "cs.CV cs.LG", "Comments": ["18 pages", "9 figures"]}, "abstract": "Geometry plays a significant role in monocular 3D object detection. It can be used to estimate object depth by using the perspective projection between object's physical size and 2D projection in the image plane, which can introduce mathematical priors into deep models. However, this projection process also introduces error amplification, where the error of the estimated height is amplified and reflected into the projected depth. It leads to unreliable depth inferences and also impairs training stability. To tackle this problem, we propose a novel Geometry Uncertainty Propagation Network (GUPNet++) by modeling geometry projection in a probabilistic manner. This ensures depth predictions are well-bounded and associated with a reasonable uncertainty. The significance of introducing such geometric uncertainty is two-fold: (1). It models the uncertainty propagation relationship of the geometry projection during training, improving the stability and efficiency of the end-to-end model learning. (2). It can be derived to a highly reliable confidence to indicate the quality of the 3D detection result, enabling more reliable detection inference. Experiments show that the proposed approach not only obtains (state-of-the-art) SOTA performance in image-based monocular 3D detection but also demonstrates superiority in efficacy with a simplified framework.", "url": "https://arxiv.org/abs/2310.15624"}, {"metadata": {"arXiv": "2310.15999", "Date": "Tue, 24 Oct 2023 16:48:56 ", "Title": "Transitivity Recovering Decompositions: Interpretable and Robust Fine-Grained Relationships", "Authors": ["Abhra Chaudhuri", "Massimiliano Mancini", "Zeynep Akata", "Anjan Dutta"], "Categories": "cs.CV cs.LG", "Comments": ["Neural Information Processing Systems (NeurIPS) 2023"]}, "abstract": "Recent advances in fine-grained representation learning leverage local-to-global (emergent) relationships for achieving state-of-the-art results. The relational representations relied upon by such methods, however, are abstract. We aim to deconstruct this abstraction by expressing them as interpretable graphs over image views. We begin by theoretically showing that abstract relational representations are nothing but a way of recovering transitive relationships among local views. Based on this, we design Transitivity Recovering Decompositions (TRD), a graph-space search algorithm that identifies interpretable equivalents of abstract emergent relationships at both instance and class levels, and with no post-hoc computations. We additionally show that TRD is provably robust to noisy views, with empirical evidence also supporting this finding. The latter allows TRD to perform at par or even better than the state-of-the-art, while being fully interpretable. Implementation is available at https://github.com/abhrac/trd.", "url": "https://arxiv.org/abs/2310.15999"}, {"metadata": {"arXiv": "2310.16047", "Date": "Tue, 24 Oct 2023 17:58:54 ", "Title": "From Posterior Sampling to Meaningful Diversity in Image Restoration", "Authors": ["Noa Cohen", "Hila Manor", "Yuval Bahat", "Tomer Michaeli"], "Categories": "cs.CV cs.LG eess.IV", "Comments": ["Code and examples are available in https://noa-cohen.github.io/MeaningfulDiversityInIR"]}, "abstract": "Image restoration problems are typically ill-posed in the sense that each degraded image can be restored in infinitely many valid ways. To accommodate this, many works generate a diverse set of outputs by attempting to randomly sample from the posterior distribution of natural images given the degraded input. Here we argue that this strategy is commonly of limited practical value because of the heavy tail of the posterior distribution. Consider for example inpainting a missing region of the sky in an image. Since there is a high probability that the missing region contains no object but clouds, any set of samples from the posterior would be entirely dominated by (practically identical) completions of sky. However, arguably, presenting users with only one clear sky completion, along with several alternative solutions such as airships, birds, and balloons, would better outline the set of possibilities. In this paper, we initiate the study of meaningfully diverse image restoration. We explore several post-processing approaches that can be combined with any diverse image restoration method to yield semantically meaningful diversity. Moreover, we propose a practical approach for allowing diffusion based image restoration methods to generate meaningfully diverse outputs, while incurring only negligent computational overhead. We conduct extensive user studies to analyze the proposed techniques, and find the strategy of reducing similarity between outputs to be significantly favorable over posterior sampling. Code and examples are available in https://noa-cohen.github.io/MeaningfulDiversityInIR", "url": "https://arxiv.org/abs/2310.16047"}, {"metadata": {"arXiv": "2310.15189", "Date": "Fri, 20 Oct 2023 23:44:34 ", "Title": "Towards Subject Agnostic Affective Emotion Recognition", "Authors": ["Amit Kumar Jaiswal", "Haiming Liu", "and Prayag Tiwari"], "Categories": "cs.LG cs.HC cs.MM", "Comments": ["To Appear in MUWS workshop at the 32nd ACM International Conference on Information and Knowledge Management (CIKM) 2023"]}, "abstract": "This paper focuses on affective emotion recognition, aiming to perform in the subject-agnostic paradigm based on EEG signals. However, EEG signals manifest subject instability in subject-agnostic affective Brain-computer interfaces (aBCIs), which led to the problem of distributional shift. Furthermore, this problem is alleviated by approaches such as domain generalisation and domain adaptation. Typically, methods based on domain adaptation confer comparatively better results than the domain generalisation methods but demand more computational resources given new subjects. We propose a novel framework, meta-learning based augmented domain adaptation for subject-agnostic aBCIs. Our domain adaptation approach is augmented through meta-learning, which consists of a recurrent neural network, a classifier, and a distributional shift controller based on a sum-decomposable function. Also, we present that a neural network explicating a sum-decomposable function can effectively estimate the divergence between varied domains. The network setting for augmented domain adaptation follows meta-learning and adversarial learning, where the controller promptly adapts to new domains employing the target data via a few self-adaptation steps in the test phase. Our proposed approach is shown to be effective in experiments on a public aBICs dataset and achieves similar performance to state-of-the-art domain adaptation methods while avoiding the use of additional computational resources.", "url": "https://arxiv.org/abs/2310.15189"}, {"metadata": {"arXiv": "2310.15197", "Date": "Sun, 22 Oct 2023 16:29:44 ", "Title": "Can strong structural encoding reduce the importance of Message Passing?", "Authors": ["Floor Eijkelboom (1)", "Erik Bekkers (1)", "Michael Bronstein (2)", "Francesco Di Giovanni (3) ((1) University of Amsterdam", "(2) University of Oxford", "(3) University of Cambridge)"], "Categories": "cs.LG", "Journal-ref": "Proceedings of 2nd Annual Workshop on Topology, Algebra, and Geometry in Machine Learning (TAG-ML), PMLR 221:278-288, 2023"}, "abstract": "The most prevalent class of neural networks operating on graphs are message passing neural networks (MPNNs), in which the representation of a node is updated iteratively by aggregating information in the 1-hop neighborhood. Since this paradigm for computing node embeddings may prevent the model from learning coarse topological structures, the initial features are often augmented with structural information of the graph, typically in the form of Laplacian eigenvectors or Random Walk transition probabilities. In this work, we explore the contribution of message passing when strong structural encodings are provided. We introduce a novel way of modeling the interaction between feature and structural information based on their tensor product rather than the standard concatenation. The choice of interaction is compared in common scenarios and in settings where the capacity of the message-passing layer is severely reduced and ultimately the message-passing phase is removed altogether. Our results indicate that using tensor-based encodings is always at least on par with the concatenation-based encoding and that it makes the model much more robust when the message passing layers are removed, on some tasks incurring almost no drop in performance. This suggests that the importance of message passing is limited when the model can construct strong structural encodings.", "url": "https://arxiv.org/abs/2310.15197"}, {"metadata": {"arXiv": "2310.15204", "Date": "Mon, 23 Oct 2023 10:22:38 ", "Title": "Mid-Long Term Daily Electricity Consumption Forecasting Based on Piecewise Linear Regression and Dilated Causal CNN", "Authors": ["Zhou Lan", "Ben Liu", "Yi Feng", "Danhuang Dong", "Peng Zhang"], "Categories": "cs.LG", "Comments": ["Key words: Daily electricity consumption forecasting; time series decomposition; piecewise linear regression; Dilated Causal CNN"]}, "abstract": "Daily electricity consumption forecasting is a classical problem. Existing forecasting algorithms tend to have decreased accuracy on special dates like holidays. This study decomposes the daily electricity consumption series into three components: trend, seasonal, and residual, and constructs a two-stage prediction method using piecewise linear regression as a filter and Dilated Causal CNN as a predictor. The specific steps involve setting breakpoints on the time axis and fitting the piecewise linear regression model with one-hot encoded information such as month, weekday, and holidays. For the challenging prediction of the Spring Festival, distance is introduced as a variable using a third-degree polynomial form in the model. The residual sequence obtained in the previous step is modeled using Dilated Causal CNN, and the final prediction of daily electricity consumption is the sum of the two-stage predictions. Experimental results demonstrate that this method achieves higher accuracy compared to existing approaches.", "url": "https://arxiv.org/abs/2310.15204"}, {"metadata": {"arXiv": "2310.15269", "Date": "Mon, 23 Oct 2023 18:13:37 ", "Title": "GradSim: Gradient-Based Language Grouping for Effective Multilingual Training", "Authors": ["Mingyang Wang", "Heike Adel", "Lukas Lange", "Jannik Str\\\"otgen", "Hinrich Sch\\\"utze"], "Categories": "cs.LG cs.CL"}, "abstract": "Most languages of the world pose low-resource challenges to natural language processing models. With multilingual training, knowledge can be shared among languages. However, not all languages positively influence each other and it is an open research question how to select the most suitable set of languages for multilingual training and avoid negative interference among languages whose characteristics or data distributions are not compatible. In this paper, we propose GradSim, a language grouping method based on gradient similarity. Our experiments on three diverse multilingual benchmark datasets show that it leads to the largest performance gains compared to other similarity measures and it is better correlated with cross-lingual model performance. As a result, we set the new state of the art on AfriSenti, a benchmark dataset for sentiment analysis on low-resource African languages. In our extensive analysis, we further reveal that besides linguistic features, the topics of the datasets play an important role for language grouping and that lower layers of transformer models encode language-specific features while higher layers capture task-specific information.", "url": "https://arxiv.org/abs/2310.15269"}, {"metadata": {"arXiv": "2310.15275", "Date": "Mon, 23 Oct 2023 18:25:33 ", "Title": "Triple Simplex Matrix Completion for Expense Forecasting", "Authors": ["Cheng Qian and Lucas Glass and Nikos Sidiropoulos"], "Categories": "cs.LG cs.IR", "Comments": ["5 pages 2 figures"]}, "abstract": "Forecasting project expenses is a crucial step for businesses to avoid budget overruns and project failures. Traditionally, this has been done by financial analysts or data science techniques such as time-series analysis. However, these approaches can be uncertain and produce results that differ from the planned budget, especially at the start of a project with limited data points. This paper proposes a constrained non-negative matrix completion model that predicts expenses by learning the likelihood of the project correlating with certain expense patterns in the latent space. The model is constrained on three probability simplexes, two of which are on the factor matrices and the third on the missing entries. Additionally, the predicted expense values are guaranteed to meet the budget constraint without the need of post-processing. An inexact alternating optimization algorithm is developed to solve the associated optimization problem and is proven to converge to a stationary point. Results from two real datasets demonstrate the effectiveness of the proposed method in comparison to state-of-the-art algorithms.", "url": "https://arxiv.org/abs/2310.15275"}, {"metadata": {"arXiv": "2310.15290", "Date": "Mon, 23 Oct 2023 18:56:01 ", "Title": "Fast and Reliable Generation of EHR Time Series via Diffusion Models", "Authors": ["Muhang Tian", "Bernie Chen", "Allan Guo", "Shiyi Jiang", "Anru R. Zhang"], "Categories": "cs.LG"}, "abstract": "Electronic Health Records (EHRs) are rich sources of patient-level data, including laboratory tests, medications, and diagnoses, offering valuable resources for medical data analysis. However, concerns about privacy often restrict access to EHRs, hindering downstream analysis. Researchers have explored various methods for generating privacy-preserving EHR data. In this study, we introduce a new method for generating diverse and realistic synthetic EHR time series data using Denoising Diffusion Probabilistic Models (DDPM). We conducted experiments on six datasets, comparing our proposed method with seven existing methods. Our results demonstrate that our approach significantly outperforms all existing methods in terms of data utility while requiring less training effort. Our approach also enhances downstream medical data analysis by providing diverse and realistic synthetic EHR data.", "url": "https://arxiv.org/abs/2310.15290"}, {"metadata": {"arXiv": "2310.15301", "Date": "Mon, 23 Oct 2023 19:07:33 ", "Title": "ADMarker: A Multi-Modal Federated Learning System for Monitoring Digital Biomarkers of Alzheimer's Disease", "Authors": ["Xiaomin Ouyang", "Xian Shuai", "Yang Li", "Li Pan", "Xifan Zhang", "Heming Fu", "Xinyan Wang", "Shihua Cao", "Jiang Xin", "Hazel Mok", "Zhenyu Yan", "Doris Sau Fung Yu", "Timothy Kwok", "Guoliang Xing"], "Categories": "cs.LG"}, "abstract": "Alzheimer's Disease (AD) and related dementia are a growing global health challenge due to the aging population. In this paper, we present ADMarker, the first end-to-end system that integrates multi-modal sensors and new federated learning algorithms for detecting multidimensional AD digital biomarkers in natural living environments. ADMarker features a novel three-stage multi-modal federated learning architecture that can accurately detect digital biomarkers in a privacy-preserving manner. Our approach collectively addresses several major real-world challenges, such as limited data labels, data heterogeneity, and limited computing resources. We built a compact multi-modality hardware system and deployed it in a four-week clinical trial involving 91 elderly participants. The results indicate that ADMarker can accurately detect a comprehensive set of digital biomarkers with up to 93.8% accuracy and identify early AD with an average of 88.9% accuracy. ADMarker offers a new platform that can allow AD clinicians to characterize and track the complex correlation between multidimensional interpretable digital biomarkers, demographic factors of patients, and AD diagnosis in a longitudinal manner.", "url": "https://arxiv.org/abs/2310.15301"}, {"metadata": {"arXiv": "2310.15333", "Date": "Mon, 23 Oct 2023 19:59:10 ", "Title": "Estimating Trustworthy and Safe Optimal Treatment Regimes", "Authors": ["Harsh Parikh", "Quinn Lanners", "Zade Akras", "Sahar F. Zafar", "M. Brandon Westover", "Cynthia Rudin", "Alexander Volfovsky"], "Categories": "cs.LG stat.AP stat.ME"}, "abstract": "Recent statistical and reinforcement learning methods have significantly advanced patient care strategies. However, these approaches face substantial challenges in high-stakes contexts, including missing data, inherent stochasticity, and the critical requirements for interpretability and patient safety. Our work operationalizes a safe and interpretable framework to identify optimal treatment regimes. This approach involves matching patients with similar medical and pharmacological characteristics, allowing us to construct an optimal policy via interpolation. We perform a comprehensive simulation study to demonstrate the framework's ability to identify optimal policies even in complex settings. Ultimately, we operationalize our approach to study regimes for treating seizures in critically ill patients. Our findings strongly support personalized treatment strategies based on a patient's medical history and pharmacological features. Notably, we identify that reducing medication doses for patients with mild and brief seizure episodes while adopting aggressive treatment for patients in intensive care unit experiencing intense seizures leads to more favorable outcomes.", "url": "https://arxiv.org/abs/2310.15333"}, {"metadata": {"arXiv": "2310.15334", "Date": "Mon, 23 Oct 2023 20:01:06 ", "Title": "ADMM Training Algorithms for Residual Networks: Convergence, Complexity and Parallel Training", "Authors": ["Jintao Xu", "Yifei Li", "Wenxun Xing"], "Categories": "cs.LG math.OC"}, "abstract": "We design a series of serial and parallel proximal point (gradient) ADMMs for the fully connected residual networks (FCResNets) training problem by introducing auxiliary variables. Convergence of the proximal point version is proven based on a Kurdyka-Lojasiewicz (KL) property analysis framework, and we can ensure a locally R-linear or sublinear convergence rate depending on the different ranges of the Kurdyka-Lojasiewicz (KL) exponent, in which a necessary auxiliary function is constructed to realize our goal. Moreover, the advantages of the parallel implementation in terms of lower time complexity and less (per-node) memory consumption are analyzed theoretically. To the best of our knowledge, this is the first work analyzing the convergence, convergence rate, time complexity and (per-node) runtime memory requirement of the ADMM applied in the FCResNets training problem theoretically. Experiments are reported to show the high speed, better performance, robustness and potential in the deep network training tasks. Finally, we present the advantage and potential of our parallel training in large-scale problems.", "url": "https://arxiv.org/abs/2310.15334"}, {"metadata": {"arXiv": "2310.15342", "Date": "Mon, 23 Oct 2023 20:15:30 ", "Title": "Towards Hybrid-grained Feature Interaction Selection for Deep Sparse Network", "Authors": ["Fuyuan Lyu", "Xing Tang", "Dugang Liu", "Chen Ma", "Weihong Luo", "Liang Chen", "Xiuqiang He", "Xue Liu"], "Categories": "cs.LG cs.IR", "Comments": ["NeurIPS 2023 poster"]}, "abstract": "Deep sparse networks are widely investigated as a neural network architecture for prediction tasks with high-dimensional sparse features, with which feature interaction selection is a critical component. While previous methods primarily focus on how to search feature interaction in a coarse-grained space, less attention has been given to a finer granularity. In this work, we introduce a hybrid-grained feature interaction selection approach that targets both feature field and feature value for deep sparse networks. To explore such expansive space, we propose a decomposed space which is calculated on the fly. We then develop a selection algorithm called OptFeature, which efficiently selects the feature interaction from both the feature field and the feature value simultaneously. Results from experiments on three large real-world benchmark datasets demonstrate that OptFeature performs well in terms of accuracy and efficiency. Additional studies support the feasibility of our method.", "url": "https://arxiv.org/abs/2310.15342"}, {"metadata": {"arXiv": "2310.15343", "Date": "Mon, 23 Oct 2023 20:15:45 ", "Title": "Burgers' pinns with implicit euler transfer learning", "Authors": ["Vit\\'oria Biesek and Pedro Henrique de Almeida Konzen"], "Categories": "cs.LG cs.NA math.NA", "Comments": ["11 pages", "3 figures", "conference paper XXVI ENMC/XIV ECTM 2023", "Nova Friburgo", "Brazil"]}, "abstract": "The Burgers equation is a well-established test case in the computational modeling of several phenomena such as fluid dynamics, gas dynamics, shock theory, cosmology, and others. In this work, we present the application of Physics-Informed Neural Networks (PINNs) with an implicit Euler transfer learning approach to solve the Burgers equation. The proposed approach consists in seeking a time-discrete solution by a sequence of Artificial Neural Networks (ANNs). At each time step, the previous ANN transfers its knowledge to the next network model, which learns the current time solution by minimizing a loss function based on the implicit Euler approximation of the Burgers equation. The approach is tested for two benchmark problems: the first with an exact solution and the other with an alternative analytical solution. In comparison to the usual PINN models, the proposed approach has the advantage of requiring smaller neural network architectures with similar accurate results and potentially decreasing computational costs.", "url": "https://arxiv.org/abs/2310.15343"}, {"metadata": {"arXiv": "2310.15351", "Date": "Mon, 23 Oct 2023 20:30:44 ", "Title": "Random Exploration in Bayesian Optimization: Order-Optimal Regret and Computational Efficiency", "Authors": ["Sudeep Salgia", "Sattar Vakili", "Qing Zhao"], "Categories": "cs.LG stat.ML"}, "abstract": "We consider Bayesian optimization using Gaussian Process models, also referred to as kernel-based bandit optimization. We study the methodology of exploring the domain using random samples drawn from a distribution. We show that this random exploration approach achieves the optimal error rates. Our analysis is based on novel concentration bounds in an infinite dimensional Hilbert space established in this work, which may be of independent interest. We further develop an algorithm based on random exploration with domain shrinking and establish its order-optimal regret guarantees under both noise-free and noisy settings. In the noise-free setting, our analysis closes the existing gap in regret performance and thereby resolves a COLT open problem. The proposed algorithm also enjoys a computational advantage over prevailing methods due to the random exploration that obviates the expensive optimization of a non-convex acquisition function for choosing the query points at each iteration.", "url": "https://arxiv.org/abs/2310.15351"}, {"metadata": {"arXiv": "2310.15358", "Date": "Mon, 23 Oct 2023 20:43:03 ", "Title": "Learning Fair Representations with High-Confidence Guarantees", "Authors": ["Yuhong Luo", "Austin Hoag", "Philip S. Thomas"], "Categories": "cs.LG cs.CY stat.ML"}, "abstract": "Representation learning is increasingly employed to generate representations that are predictive across multiple downstream tasks. The development of representation learning algorithms that provide strong fairness guarantees is thus important because it can prevent unfairness towards disadvantaged groups for all downstream prediction tasks. To prevent unfairness towards disadvantaged groups in all downstream tasks, it is crucial to provide representation learning algorithms that provide fairness guarantees. In this paper, we formally define the problem of learning representations that are fair with high confidence. We then introduce the Fair Representation learning with high-confidence Guarantees (FRG) framework, which provides high-confidence guarantees for limiting unfairness across all downstream models and tasks, with user-defined upper bounds. After proving that FRG ensures fairness for all downstream models and tasks with high probability, we present empirical evaluations that demonstrate FRG's effectiveness at upper bounding unfairness for multiple downstream models and tasks.", "url": "https://arxiv.org/abs/2310.15358"}, {"metadata": {"arXiv": "2310.15411", "Date": "Mon, 23 Oct 2023 23:55:28 ", "Title": "Efficient Active Learning Halfspaces with Tsybakov Noise: A Non-convex Optimization Approach", "Authors": ["Yinan Li", "Chicheng Zhang"], "Categories": "cs.LG stat.ML", "Comments": ["29 pages"]}, "abstract": "We study the problem of computationally and label efficient PAC active learning $d$-dimensional halfspaces with Tsybakov Noise~\\citep{tsybakov2004optimal} under structured unlabeled data distributions. Inspired by~\\cite{diakonikolas2020learning}, we prove that any approximate first-order stationary point of a smooth nonconvex loss function yields a halfspace with a low excess error guarantee. In light of the above structural result, we design a nonconvex optimization-based algorithm with a label complexity of $\\tilde{O}(d (\\frac{1}{\\epsilon})^{\\frac{8-6\\alpha}{3\\alpha-1}})$\\footnote{In the main body of this work, we use $\\tilde{O}(\\cdot), \\tilde{\\Theta}(\\cdot)$ to hide factors of the form $\\polylog(d, \\frac{1}{\\epsilon}, \\frac{1}{\\delta})$}, under the assumption that the Tsybakov noise parameter $\\alpha \\in (\\frac13, 1]$, which narrows down the gap between the label complexities of the previously known efficient passive or active algorithms~\\citep{diakonikolas2020polynomial,zhang2021improved} and the information-theoretic lower bound in this setting.", "url": "https://arxiv.org/abs/2310.15411"}, {"metadata": {"arXiv": "2310.15433", "Date": "Tue, 24 Oct 2023 01:00:01 ", "Title": "Off-Policy Evaluation for Large Action Spaces via Policy Convolution", "Authors": ["Noveen Sachdeva", "Lequn Wang", "Dawen Liang", "Nathan Kallus", "Julian McAuley"], "Categories": "cs.LG cs.IR", "Comments": ["Under review. 36 pages", "31 figures"]}, "abstract": "Developing accurate off-policy estimators is crucial for both evaluating and optimizing for new policies. The main challenge in off-policy estimation is the distribution shift between the logging policy that generates data and the target policy that we aim to evaluate. Typically, techniques for correcting distribution shift involve some form of importance sampling. This approach results in unbiased value estimation but often comes with the trade-off of high variance, even in the simpler case of one-step contextual bandits. Furthermore, importance sampling relies on the common support assumption, which becomes impractical when the action space is large. To address these challenges, we introduce the Policy Convolution (PC) family of estimators. These methods leverage latent structure within actions -- made available through action embeddings -- to strategically convolve the logging and target policies. This convolution introduces a unique bias-variance trade-off, which can be controlled by adjusting the amount of convolution. Our experiments on synthetic and benchmark datasets demonstrate remarkable mean squared error (MSE) improvements when using PC, especially when either the action space or policy mismatch becomes large, with gains of up to 5 - 6 orders of magnitude over existing estimators.", "url": "https://arxiv.org/abs/2310.15433"}, {"metadata": {"arXiv": "2310.15450", "Date": "Tue, 24 Oct 2023 01:47:44 ", "Title": "General Identifiability and Achievability for Causal Representation Learning", "Authors": ["Burak Var{\\i}c{\\i}", "Emre Acart\\\"urk", "Karthikeyan Shanmugam", "Ali Tajer"], "Categories": "cs.LG stat.ML"}, "abstract": "This paper focuses on causal representation learning (CRL) under a general nonparametric causal latent model and a general transformation model that maps the latent data to the observational data. It establishes \\textbf{identifiability} and \\textbf{achievability} results using two hard \\textbf{uncoupled} interventions per node in the latent causal graph. Notably, one does not know which pair of intervention environments have the same node intervened (hence, uncoupled environments). For identifiability, the paper establishes that perfect recovery of the latent causal model and variables is guaranteed under uncoupled interventions. For achievability, an algorithm is designed that uses observational and interventional data and recovers the latent causal model and variables with provable guarantees for the algorithm. This algorithm leverages score variations across different environments to estimate the inverse of the transformer and, subsequently, the latent variables. The analysis, additionally, recovers the existing identifiability result for two hard \\textbf{coupled} interventions, that is when metadata about the pair of environments that have the same node intervened is known. It is noteworthy that the existing results on non-parametric identifiability require assumptions on interventions and additional faithfulness assumptions. This paper shows that when observational data is available, additional faithfulness assumptions are unnecessary.", "url": "https://arxiv.org/abs/2310.15450"}, {"metadata": {"arXiv": "2310.15454", "Date": "Tue, 24 Oct 2023 01:59:28 ", "Title": "Private Learning with Public Features", "Authors": ["Walid Krichene", "Nicolas Mayoraz", "Steffen Rendle", "Shuang Song", "Abhradeep Thakurta", "Li Zhang"], "Categories": "cs.LG cs.CR stat.ML"}, "abstract": "We study a class of private learning problems in which the data is a join of private and public features. This is often the case in private personalization tasks such as recommendation or ad prediction, in which features related to individuals are sensitive, while features related to items (the movies or songs to be recommended, or the ads to be shown to users) are publicly available and do not require protection. A natural question is whether private algorithms can achieve higher utility in the presence of public features. We give a positive answer for multi-encoder models where one of the encoders operates on public features. We develop new algorithms that take advantage of this separation by only protecting certain sufficient statistics (instead of adding noise to the gradient). This method has a guaranteed utility improvement for linear regression, and importantly, achieves the state of the art on two standard private recommendation benchmarks, demonstrating the importance of methods that adapt to the private-public feature separation.", "url": "https://arxiv.org/abs/2310.15454"}, {"metadata": {"arXiv": "2310.15466", "Date": "Tue, 24 Oct 2023 02:37:49 ", "Title": "EKGNet: A 10.96{\\mu}W Fully Analog Neural Network for Intra-Patient Arrhythmia Classification", "Authors": ["Benyamin Haghi", "Lin Ma", "Sahin Lale", "Anima Anandkumar", "Azita Emami"], "Categories": "cs.LG", "Comments": ["Accepted on IEEE Biomedical Circuits and Systems (BioCAS) 2023"]}, "abstract": "We present an integrated approach by combining analog computing and deep learning for electrocardiogram (ECG) arrhythmia classification. We propose EKGNet, a hardware-efficient and fully analog arrhythmia classification architecture that archives high accuracy with low power consumption. The proposed architecture leverages the energy efficiency of transistors operating in the subthreshold region, eliminating the need for analog-to-digital converters (ADC) and static random access memory (SRAM). The system design includes a novel analog sequential Multiply-Accumulate (MAC) circuit that mitigates process, supply voltage, and temperature variations. Experimental evaluations on PhysioNet's MIT-BIH and PTB Diagnostics datasets demonstrate the effectiveness of the proposed method, achieving average balanced accuracy of 95% and 94.25% for intra-patient arrhythmia classification and myocardial infarction (MI) classification, respectively. This innovative approach presents a promising avenue for developing low-power arrhythmia classification systems with enhanced accuracy and transferability in biomedical applications.", "url": "https://arxiv.org/abs/2310.15466"}, {"metadata": {"arXiv": "2310.15472", "Date": "Tue, 24 Oct 2023 02:56:05 ", "Title": "Interpretable Survival Analysis for Heart Failure Risk Prediction", "Authors": ["Mike Van Ness", "Tomas Bosschieter", "Natasha Din", "Andrew Ambrosy", "Alexander Sandhu", "Madeleine Udell"], "Categories": "cs.LG stat.ML"}, "abstract": "Survival analysis, or time-to-event analysis, is an important and widespread problem in healthcare research. Medical research has traditionally relied on Cox models for survival analysis, due to their simplicity and interpretability. Cox models assume a log-linear hazard function as well as proportional hazards over time, and can perform poorly when these assumptions fail. Newer survival models based on machine learning avoid these assumptions and offer improved accuracy, yet sometimes at the expense of model interpretability, which is vital for clinical use. We propose a novel survival analysis pipeline that is both interpretable and competitive with state-of-the-art survival models. Specifically, we use an improved version of survival stacking to transform a survival analysis problem to a classification problem, ControlBurn to perform feature selection, and Explainable Boosting Machines to generate interpretable predictions. To evaluate our pipeline, we predict risk of heart failure using a large-scale EHR database. Our pipeline achieves state-of-the-art performance and provides interesting and novel insights about risk factors for heart failure.", "url": "https://arxiv.org/abs/2310.15472"}, {"metadata": {"arXiv": "2310.15516", "Date": "Tue, 24 Oct 2023 04:50:32 ", "Title": "Graph Attention-based Deep Reinforcement Learning for solving the Chinese Postman Problem with Load-dependent costs", "Authors": ["Cong Dao Tran", "Truong Son Hy"], "Categories": "cs.LG"}, "abstract": "Recently, Deep reinforcement learning (DRL) models have shown promising results in solving routing problems. However, most DRL solvers are commonly proposed to solve node routing problems, such as the Traveling Salesman Problem (TSP). Meanwhile, there has been limited research on applying neural methods to arc routing problems, such as the Chinese Postman Problem (CPP), since they often feature irregular and complex solution spaces compared to TSP. To fill these gaps, this paper proposes a novel DRL framework to address the CPP with load-dependent costs (CPP-LC) (Corberan et al., 2018), which is a complex arc routing problem with load constraints. The novelty of our method is two-fold. First, we formulate the CPP-LC as a Markov Decision Process (MDP) sequential model. Subsequently, we introduce an autoregressive model based on DRL, namely Arc-DRL, consisting of an encoder and decoder to address the CPP-LC challenge effectively. Such a framework allows the DRL model to work efficiently and scalably to arc routing problems. Furthermore, we propose a new bio-inspired meta-heuristic solution based on Evolutionary Algorithm (EA) for CPP-LC. Extensive experiments show that Arc-DRL outperforms existing meta-heuristic methods such as Iterative Local Search (ILS) and Variable Neighborhood Search (VNS) proposed by (Corberan et al., 2018) on large benchmark datasets for CPP-LC regarding both solution quality and running time; while the EA gives the best solution quality with much more running time. We release our C++ implementations for metaheuristics such as EA, ILS and VNS along with the code for data generation and our generated data at https://github.com/HySonLab/Chinese_Postman_Problem", "url": "https://arxiv.org/abs/2310.15516"}, {"metadata": {"arXiv": "2310.15524", "Date": "Tue, 24 Oct 2023 05:07:31 ", "Title": "On the Inherent Privacy Properties of Discrete Denoising Diffusion Models", "Authors": ["Rongzhe Wei", "Eleonora Krea\\v{c}i\\'c", "Haoyu Wang", "Haoteng Yin", "Eli Chien", "Vamsi K. Potluru", "Pan Li"], "Categories": "cs.LG"}, "abstract": "Privacy concerns have led to a surge in the creation of synthetic datasets, with diffusion models emerging as a promising avenue. Although prior studies have performed empirical evaluations on these models, there has been a gap in providing a mathematical characterization of their privacy-preserving capabilities. To address this, we present the pioneering theoretical exploration of the privacy preservation inherent in discrete diffusion models (DDMs) for discrete dataset generation. Focusing on per-instance differential privacy (pDP), our framework elucidates the potential privacy leakage for each data point in a given training dataset, offering insights into data preprocessing to reduce privacy risks of the synthetic dataset generation via DDMs. Our bounds also show that training with $s$-sized data points leads to a surge in privacy leakage from $(\\epsilon, \\mathcal{O}(\\frac{1}{s^2\\epsilon}))$-pDP to $(\\epsilon, \\mathcal{O}(\\frac{1}{s\\epsilon}))$-pDP during the transition from the pure noise to the synthetic clean data phase, and a faster decay in diffusion coefficients amplifies the privacy guarantee. Finally, we empirically verify our theoretical findings on both synthetic and real-world datasets.", "url": "https://arxiv.org/abs/2310.15524"}, {"metadata": {"arXiv": "2310.15526", "Date": "Tue, 24 Oct 2023 05:16:52 ", "Title": "Privacy Amplification for Matrix Mechanisms", "Authors": ["Christopher A. Choquette-Choo", "Arun Ganesh", "Thomas Steinke", "Abhradeep Thakurta"], "Categories": "cs.LG cs.CR"}, "abstract": "Privacy amplification exploits randomness in data selection to provide tighter differential privacy (DP) guarantees. This analysis is key to DP-SGD's success in machine learning, but, is not readily applicable to the newer state-of-the-art algorithms. This is because these algorithms, known as DP-FTRL, use the matrix mechanism to add correlated noise instead of independent noise as in DP-SGD. In this paper, we propose \"MMCC\", the first algorithm to analyze privacy amplification via sampling for any generic matrix mechanism. MMCC is nearly tight in that it approaches a lower bound as $\\epsilon\\to0$. To analyze correlated outputs in MMCC, we prove that they can be analyzed as if they were independent, by conditioning them on prior outputs. Our \"conditional composition theorem\" has broad utility: we use it to show that the noise added to binary-tree-DP-FTRL can asymptotically match the noise added to DP-SGD with amplification. Our amplification algorithm also has practical empirical utility: we show it leads to significant improvement in the privacy-utility trade-offs for DP-FTRL algorithms on standard benchmarks.", "url": "https://arxiv.org/abs/2310.15526"}, {"metadata": {"arXiv": "2310.15543", "Date": "Tue, 24 Oct 2023 06:22:20 ", "Title": "Symmetry-preserving graph attention network to solve routing problems at multiple resolutions", "Authors": ["Cong Dao Tran", "Thong Bach", "Truong Son Hy"], "Categories": "cs.LG"}, "abstract": "Travelling Salesperson Problems (TSPs) and Vehicle Routing Problems (VRPs) have achieved reasonable improvement in accuracy and computation time with the adaptation of Machine Learning (ML) methods. However, none of the previous works completely respects the symmetries arising from TSPs and VRPs including rotation, translation, permutation, and scaling. In this work, we introduce the first-ever completely equivariant model and training to solve combinatorial problems. Furthermore, it is essential to capture the multiscale structure (i.e. from local to global information) of the input graph, especially for the cases of large and long-range graphs, while previous methods are limited to extracting only local information that can lead to a local or sub-optimal solution. To tackle the above limitation, we propose a Multiresolution scheme in combination with Equivariant Graph Attention network (mEGAT) architecture, which can learn the optimal route based on low-level and high-level graph resolutions in an efficient way. In particular, our approach constructs a hierarchy of coarse-graining graphs from the input graph, in which we try to solve the routing problems on simple low-level graphs first, then utilize that knowledge for the more complex high-level graphs. Experimentally, we have shown that our model outperforms existing baselines and proved that symmetry preservation and multiresolution are important recipes for solving combinatorial problems in a data-driven manner. Our source code is publicly available at https://github.com/HySonLab/Multires-NP-hard", "url": "https://arxiv.org/abs/2310.15543"}, {"metadata": {"arXiv": "2310.15555", "Date": "Tue, 24 Oct 2023 06:54:50 ", "Title": "Transfer learning for day-ahead load forecasting: a case study on European national electricity demand time series", "Authors": ["Alexandros-Menelaos Tzortzis", "Sotiris Pelekis", "Evangelos Spiliotis", "Spiros Mouzakitis", "John Psarras", "Dimitris Askounis"], "Categories": "cs.LG"}, "abstract": "Short-term load forecasting (STLF) is crucial for the daily operation of power grids. However, the non-linearity, non-stationarity, and randomness characterizing electricity demand time series renders STLF a challenging task. Various forecasting approaches have been proposed for improving STLF, including neural network (NN) models which are trained using data from multiple electricity demand series that may not necessary include the target series. In the present study, we investigate the performance of this special case of STLF, called transfer learning (TL), by considering a set of 27 time series that represent the national day-ahead electricity demand of indicative European countries. We employ a popular and easy-to-implement NN model and perform a clustering analysis to identify similar patterns among the series and assist TL. In this context, two different TL approaches, with and without the clustering step, are compiled and compared against each other as well as a typical NN training setup. Our results demonstrate that TL can outperform the conventional approach, especially when clustering techniques are considered.", "url": "https://arxiv.org/abs/2310.15555"}, {"metadata": {"arXiv": "2310.15578", "Date": "Tue, 24 Oct 2023 07:42:04 ", "Title": "VMAF Re-implementation on PyTorch: Some Experimental Results", "Authors": ["Kirill Aistov and Maxim Koroteev"], "Categories": "cs.LG cs.CV", "Comments": ["4 pages"]}, "abstract": "Based on the standard VMAF implementation we propose an implementation of VMAF using PyTorch framework. For this implementation comparisons with the standard (libvmaf) show the discrepancy $\\lesssim 10^{-2}$ in VMAF units. We investigate gradients computation when using VMAF as an objective function and demonstrate that training using this function does not result in ill-behaving gradients.", "url": "https://arxiv.org/abs/2310.15578"}, {"metadata": {"arXiv": "2310.15580", "Date": "Tue, 24 Oct 2023 07:46:10 ", "Title": "Identifiable Latent Polynomial Causal Models Through the Lens of Change", "Authors": ["Yuhang Liu", "Zhen Zhang", "Dong Gong", "Mingming Gong", "Biwei Huang", "Anton van den Hengel", "Kun Zhang", "Javen Qinfeng Shi"], "Categories": "cs.LG"}, "abstract": "Causal representation learning aims to unveil latent high-level causal representations from observed low-level data. One of its primary tasks is to provide reliable assurance of identifying these latent causal models, known as identifiability. A recent breakthrough explores identifiability by leveraging the change of causal influences among latent causal variables across multiple environments \\citep{liu2022identifying}. However, this progress rests on the assumption that the causal relationships among latent causal variables adhere strictly to linear Gaussian models. In this paper, we extend the scope of latent causal models to involve nonlinear causal relationships, represented by polynomial models, and general noise distributions conforming to the exponential family. Additionally, we investigate the necessity of imposing changes on all causal parameters and present partial identifiability results when part of them remains unchanged. Further, we propose a novel empirical estimation method, grounded in our theoretical finding, that enables learning consistent latent causal representations. Our experimental results, obtained from both synthetic and real-world data, validate our theoretical contributions concerning identifiability and consistency.", "url": "https://arxiv.org/abs/2310.15580"}, {"metadata": {"arXiv": "2310.15584", "Date": "Tue, 24 Oct 2023 07:49:56 ", "Title": "Accelerating Split Federated Learning over Wireless Communication Networks", "Authors": ["Ce Xu", "Jinxuan Li", "Yuan Liu", "Yushi Ling", "and Miaowen Wen"], "Categories": "cs.LG cs.NI eess.SP"}, "abstract": "The development of artificial intelligence (AI) provides opportunities for the promotion of deep neural network (DNN)-based applications. However, the large amount of parameters and computational complexity of DNN makes it difficult to deploy it on edge devices which are resource-constrained. An efficient method to address this challenge is model partition/splitting, in which DNN is divided into two parts which are deployed on device and server respectively for co-training or co-inference. In this paper, we consider a split federated learning (SFL) framework that combines the parallel model training mechanism of federated learning (FL) and the model splitting structure of split learning (SL). We consider a practical scenario of heterogeneous devices with individual split points of DNN. We formulate a joint problem of split point selection and bandwidth allocation to minimize the system latency. By using alternating optimization, we decompose the problem into two sub-problems and solve them optimally. Experiment results demonstrate the superiority of our work in latency reduction and accuracy improvement.", "url": "https://arxiv.org/abs/2310.15584"}, {"metadata": {"arXiv": "2310.15641", "Date": "Tue, 24 Oct 2023 08:59:40 ", "Title": "Guaranteed Coverage Prediction Intervals with Gaussian Process Regression", "Authors": ["Harris Papadopoulos"], "Categories": "cs.LG", "Comments": ["12 pages. This work has been submitted to IEEE Transactions on Pattern Analysis and Machine Intelligence for possible publication. Copyright may be transferred without notice", "after which this version may no longer be accessible"]}, "abstract": "Gaussian Process Regression (GPR) is a popular regression method, which unlike most Machine Learning techniques, provides estimates of uncertainty for its predictions. These uncertainty estimates however, are based on the assumption that the model is well-specified, an assumption that is violated in most practical applications, since the required knowledge is rarely available. As a result, the produced uncertainty estimates can become very misleading; for example the prediction intervals (PIs) produced for the 95\\% confidence level may cover much less than 95\\% of the true labels. To address this issue, this paper introduces an extension of GPR based on a Machine Learning framework called, Conformal Prediction (CP). This extension guarantees the production of PIs with the required coverage even when the model is completely misspecified. The proposed approach combines the advantages of GPR with the valid coverage guarantee of CP, while the performed experimental results demonstrate its superiority over existing methods.", "url": "https://arxiv.org/abs/2310.15641"}, {"metadata": {"arXiv": "2310.15653", "Date": "Tue, 24 Oct 2023 09:10:14 ", "Title": "Deceptive Fairness Attacks on Graphs via Meta Learning", "Authors": ["Jian Kang", "Yinglong Xia", "Ross Maciejewski", "Jiebo Luo", "Hanghang Tong"], "Categories": "cs.LG cs.SI stat.ML", "Comments": ["23 pages", "11 tables"]}, "abstract": "We study deceptive fairness attacks on graphs to answer the following question: How can we achieve poisoning attacks on a graph learning model to exacerbate the bias deceptively? We answer this question via a bi-level optimization problem and propose a meta learning-based framework named FATE. FATE is broadly applicable with respect to various fairness definitions and graph learning models, as well as arbitrary choices of manipulation operations. We further instantiate FATE to attack statistical parity and individual fairness on graph neural networks. We conduct extensive experimental evaluations on real-world datasets in the task of semi-supervised node classification. The experimental results demonstrate that FATE could amplify the bias of graph neural networks with or without fairness consideration while maintaining the utility on the downstream task. We hope this paper provides insights into the adversarial robustness of fair graph learning and can shed light on designing robust and fair graph learning in future studies.", "url": "https://arxiv.org/abs/2310.15653"}, {"metadata": {"arXiv": "2310.15656", "Date": "Tue, 24 Oct 2023 09:10:45 ", "Title": "Momentum Gradient-based Untargeted Attack on Hypergraph Neural Networks", "Authors": ["Yang Chen", "Stjepan Picek", "Zhonglin Ye", "Zhaoyang Wang and Haixing Zhao"], "Categories": "cs.LG"}, "abstract": "Hypergraph Neural Networks (HGNNs) have been successfully applied in various hypergraph-related tasks due to their excellent higher-order representation capabilities. Recent works have shown that deep learning models are vulnerable to adversarial attacks. Most studies on graph adversarial attacks have focused on Graph Neural Networks (GNNs), and the study of adversarial attacks on HGNNs remains largely unexplored. In this paper, we try to reduce this gap. We design a new HGNNs attack model for the untargeted attack, namely MGHGA, which focuses on modifying node features. We consider the process of HGNNs training and use a surrogate model to implement the attack before hypergraph modeling. Specifically, MGHGA consists of two parts: feature selection and feature modification. We use a momentum gradient mechanism to choose the attack node features in the feature selection module. In the feature modification module, we use two feature generation approaches (direct modification and sign gradient) to enable MGHGA to be employed on discrete and continuous datasets. We conduct extensive experiments on five benchmark datasets to validate the attack performance of MGHGA in the node and the visual object classification tasks. The results show that MGHGA improves performance by an average of 2% compared to the than the baselines.", "url": "https://arxiv.org/abs/2310.15656"}, {"metadata": {"arXiv": "2310.15662", "Date": "Tue, 24 Oct 2023 09:17:47 ", "Title": "Interactive Generalized Additive Model and Its Applications in Electric Load Forecasting", "Authors": ["Linxiao Yang and Rui Ren and Xinyue Gu and Liang Sun"], "Categories": "cs.LG"}, "abstract": "Electric load forecasting is an indispensable component of electric power system planning and management. Inaccurate load forecasting may lead to the threat of outages or a waste of energy. Accurate electric load forecasting is challenging when there is limited data or even no data, such as load forecasting in holiday, or under extreme weather conditions. As high-stakes decision-making usually follows after load forecasting, model interpretability is crucial for the adoption of forecasting models. In this paper, we propose an interactive GAM which is not only interpretable but also can incorporate specific domain knowledge in electric power industry for improved performance. This boosting-based GAM leverages piecewise linear functions and can be learned through our efficient algorithm. In both public benchmark and electricity datasets, our interactive GAM outperforms current state-of-the-art methods and demonstrates good generalization ability in the cases of extreme weather events. We launched a user-friendly web-based tool based on interactive GAM and already incorporated it into our eForecaster product, a unified AI platform for electricity forecasting.", "url": "https://arxiv.org/abs/2310.15662"}, {"metadata": {"arXiv": "2310.15681", "Date": "Tue, 24 Oct 2023 09:47:32 ", "Title": "Fixed-Budget Real-Valued Combinatorial Pure Exploration of Multi-Armed Bandit", "Authors": ["Shintaro Nakamura and Masashi Sugiyama"], "Categories": "cs.LG"}, "abstract": "We study the real-valued combinatorial pure exploration of the multi-armed bandit in the fixed-budget setting. We first introduce the Combinatorial Successive Asign (CSA) algorithm, which is the first algorithm that can identify the best action even when the size of the action class is exponentially large with respect to the number of arms. We show that the upper bound of the probability of error of the CSA algorithm matches a lower bound up to a logarithmic factor in the exponent. Then, we introduce another algorithm named the Minimax Combinatorial Successive Accepts and Rejects (Minimax-CombSAR) algorithm for the case where the size of the action class is polynomial, and show that it is optimal, which matches a lower bound. Finally, we experimentally compare the algorithms with previous methods and show that our algorithm performs better.", "url": "https://arxiv.org/abs/2310.15681"}, {"metadata": {"arXiv": "2310.15690", "Date": "Tue, 24 Oct 2023 10:01:15 ", "Title": "Physics-Informed with Power-Enhanced Residual Network for Interpolation and Inverse Problems", "Authors": ["Amir Noorizadegan", "D.L. Young", "Y.C. Hon", "C.S. Chen"], "Categories": "cs.LG cs.CV math.AP"}, "abstract": "This paper introduces a novel neural network structure called the Power-Enhancing residual network, designed to improve interpolation capabilities for both smooth and non-smooth functions in 2D and 3D settings. By adding power terms to residual elements, the architecture boosts the network's expressive power. The study explores network depth, width, and optimization methods, showing the architecture's adaptability and performance advantages. Consistently, the results emphasize the exceptional accuracy of the proposed Power-Enhancing residual network, particularly for non-smooth functions. Real-world examples also confirm its superiority over plain neural network in terms of accuracy, convergence, and efficiency. The study also looks at the impact of deeper network. Moreover, the proposed architecture is also applied to solving the inverse Burgers' equation, demonstrating superior performance. In conclusion, the Power-Enhancing residual network offers a versatile solution that significantly enhances neural network capabilities. The codes implemented are available at: \\url{https://github.com/CMMAi/ResNet_for_PINN}.", "url": "https://arxiv.org/abs/2310.15690"}, {"metadata": {"arXiv": "2310.15694", "Date": "Tue, 24 Oct 2023 10:05:32 ", "Title": "COPF: Continual Learning Human Preference through Optimal Policy Fitting", "Authors": ["Han Zhang", "Lin Gui", "Yuanzhao Zhai", "Hui Wang", "Yu Lei", "Ruifeng Xu"], "Categories": "cs.LG cs.CL"}, "abstract": "The technique of Reinforcement Learning from Human Feedback (RLHF) is a commonly employed method to improve pre-trained Language Models (LM), enhancing their ability to conform to human preferences. Nevertheless, the current RLHF-based LMs necessitate full retraining each time novel queries or feedback are introduced, which becomes a challenging task because human preferences can vary between different domains or tasks. Retraining LMs poses practical difficulties in many real-world situations due to the significant time and computational resources required, along with concerns related to data privacy. To address this limitation, we propose a new method called Continual Optimal Policy Fitting (COPF), in which we estimate a series of optimal policies using the Monte Carlo method, and then continually fit the policy sequence with the function regularization. COPF involves a single learning phase and doesn't necessitate complex reinforcement learning. Importantly, it shares the capability with RLHF to learn from unlabeled data, making it flexible for continual preference learning. Our experimental results show that COPF outperforms strong Continuous learning (CL) baselines when it comes to consistently aligning with human preferences on different tasks and domains.", "url": "https://arxiv.org/abs/2310.15694"}, {"metadata": {"arXiv": "2310.15742", "Date": "Tue, 24 Oct 2023 11:34:15 ", "Title": "Improving Diffusion Models for ECG Imputation with an Augmented Template Prior", "Authors": ["Alexander Jenkins", "Zehua Chen", "Fu Siong Ng", "Danilo Mandic"], "Categories": "cs.LG"}, "abstract": "Pulsative signals such as the electrocardiogram (ECG) are extensively collected as part of routine clinical care. However, noisy and poor-quality recordings, leading to missing values, are a major issue for signals collected using mobile health systems, decreasing the signal quality and affecting the automated downstream tasks. Recent studies have explored imputation of missing values for ECG with probabilistic time-series models. Nevertheless, in comparison with the deterministic models, their performance is still limited, as the variations across subjects and heart-beat relationships are not explicitly considered in the training objective. In this work, to improve the ECG imputation and forecasting accuracy with probabilistic models, we present an template-guided denoising diffusion probabilistic model, PulseDiff, which is conditioned an informative prior for a range of health conditions. Specifically, 1) we first extract a subject-level pulsative template from the observation as an informative prior of missing values, which captures the personal characteristics; 2) we then add beat-level stochastic shift terms on the template for prior augmentation, which considers the beat-level variance of positioning and amplitude; 3) we finally design a confidence score to consider the health condition of subject, which ensures our prior is provided in a safe way. Experiments with the PTBXL dataset reveal PulseDiff improves the performance of two strong DDPMs baseline models, CSDI and SSSD$^{S4}$, verifying our method guides the generation of DDPMs while managing the uncertainty. When combining with SSSD$^{S4}$, our PulseDiff method outperforms the leading deterministic model for short-interval missing data and is comparable for long-interval data loss.", "url": "https://arxiv.org/abs/2310.15742"}, {"metadata": {"arXiv": "2310.15766", "Date": "Tue, 24 Oct 2023 12:13:49 ", "Title": "Robust Learning via Conditional Prevalence Adjustment", "Authors": ["Minh Nguyen", "Alan Q. Wang", "Heejong Kim", "Mert R. Sabuncu"], "Categories": "cs.LG", "Comments": ["Accepted at WACV"]}, "abstract": "Healthcare data often come from multiple sites in which the correlations between confounding variables can vary widely. If deep learning models exploit these unstable correlations, they might fail catastrophically in unseen sites. Although many methods have been proposed to tackle unstable correlations, each has its limitations. For example, adversarial training forces models to completely ignore unstable correlations, but doing so may lead to poor predictive performance. Other methods (e.g. Invariant risk minimization [4]) try to learn domain-invariant representations that rely only on stable associations by assuming a causal data-generating process (input X causes class label Y ). Thus, they may be ineffective for anti-causal tasks (Y causes X), which are common in computer vision. We propose a method called CoPA (Conditional Prevalence-Adjustment) for anti-causal tasks. CoPA assumes that (1) generation mechanism is stable, i.e. label Y and confounding variable(s) Z generate X, and (2) the unstable conditional prevalence in each site E fully accounts for the unstable correlations between X and Y . Our crucial observation is that confounding variables are routinely recorded in healthcare settings and the prevalence can be readily estimated, for example, from a set of (Y, Z) samples (no need for corresponding samples of X). CoPA can work even if there is a single training site, a scenario which is often overlooked by existing methods. Our experiments on synthetic and real data show CoPA beating competitive baselines.", "url": "https://arxiv.org/abs/2310.15766"}, {"metadata": {"arXiv": "2310.15815", "Date": "Tue, 24 Oct 2023 13:09:56 ", "Title": "Good Better Best: Self-Motivated Imitation Learning for noisy Demonstrations", "Authors": ["Ye Yuan", "Xin Li", "Yong Heng", "Leiji Zhang", "MingZhong Wang"], "Categories": "cs.LG"}, "abstract": "Imitation Learning (IL) aims to discover a policy by minimizing the discrepancy between the agent's behavior and expert demonstrations. However, IL is susceptible to limitations imposed by noisy demonstrations from non-expert behaviors, presenting a significant challenge due to the lack of supplementary information to assess their expertise. In this paper, we introduce Self-Motivated Imitation LEarning (SMILE), a method capable of progressively filtering out demonstrations collected by policies deemed inferior to the current policy, eliminating the need for additional information. We utilize the forward and reverse processes of Diffusion Models to emulate the shift in demonstration expertise from low to high and vice versa, thereby extracting the noise information that diffuses expertise. Then, the noise information is leveraged to predict the diffusion steps between the current policy and demonstrators, which we theoretically demonstrate its equivalence to their expertise gap. We further explain in detail how the predicted diffusion steps are applied to filter out noisy demonstrations in a self-motivated manner and provide its theoretical grounds. Through empirical evaluations on MuJoCo tasks, we demonstrate that our method is proficient in learning the expert policy amidst noisy demonstrations, and effectively filters out demonstrations with expertise inferior to the current policy.", "url": "https://arxiv.org/abs/2310.15815"}, {"metadata": {"arXiv": "2310.15826", "Date": "Tue, 24 Oct 2023 13:25:19 ", "Title": "One or Two Things We know about Concept Drift -- A Survey on Monitoring Evolving Environments", "Authors": ["Fabian Hinder and Valerie Vaquet and Barbara Hammer"], "Categories": "cs.LG"}, "abstract": "The world surrounding us is subject to constant change. These changes, frequently described as concept drift, influence many industrial and technical processes. As they can lead to malfunctions and other anomalous behavior, which may be safety-critical in many scenarios, detecting and analyzing concept drift is crucial. In this paper, we provide a literature review focusing on concept drift in unsupervised data streams. While many surveys focus on supervised data streams, so far, there is no work reviewing the unsupervised setting. However, this setting is of particular relevance for monitoring and anomaly detection which are directly applicable to many tasks and challenges in engineering. This survey provides a taxonomy of existing work on drift detection. Besides, it covers the current state of research on drift localization in a systematic way. In addition to providing a systematic literature review, this work provides precise mathematical definitions of the considered problems and contains standardized experiments on parametric artificial datasets allowing for a direct comparison of different strategies for detection and localization. Thereby, the suitability of different schemes can be analyzed systematically and guidelines for their usage in real-world scenarios can be provided. Finally, there is a section on the emerging topic of explaining concept drift.", "url": "https://arxiv.org/abs/2310.15826"}, {"metadata": {"arXiv": "2310.15830", "Date": "Tue, 24 Oct 2023 13:33:19 ", "Title": "Localization of Small Leakages in Water Distribution Networks using Concept Drift Explanation Methods", "Authors": ["Valerie Vaquet and Fabian Hinder and Kathrin Lammers and Jonas Vaquet and Barbara Hammer"], "Categories": "cs.LG"}, "abstract": "Facing climate change the already limited availability of drinking water will decrease in the future rendering drinking water an increasingly scarce resource. Considerable amounts of it are lost through leakages in water transportation and distribution networks. Leakage detection and localization are challenging problems due to the complex interactions and changing demands in water distribution networks. Especially small leakages are hard to pinpoint yet their localization is vital to avoid water loss over long periods of time. While there exist different approaches to solving the tasks of leakage detection and localization, they are relying on various information about the system, e.g. real-time demand measurements and the precise network topology, which is an unrealistic assumption in many real-world scenarios. In contrast, this work attempts leakage localization using pressure measurements only. For this purpose, first, leakages in the water distribution network are modeled employing Bayesian networks, and the system dynamics are analyzed. We then show how the problem is connected to and can be considered through the lens of concept drift. In particular, we argue that model-based explanations of concept drift are a promising tool for localizing leakages given limited information about the network. The methodology is experimentally evaluated using realistic benchmark scenarios.", "url": "https://arxiv.org/abs/2310.15830"}, {"metadata": {"arXiv": "2310.15848", "Date": "Tue, 24 Oct 2023 14:01:53 ", "Title": "On Responsible Machine Learning Datasets with Fairness, Privacy, and Regulatory Norms", "Authors": ["Surbhi Mittal", "Kartik Thakral", "Richa Singh", "Mayank Vatsa", "Tamar Glaser", "Cristian Canton Ferrer", "Tal Hassner"], "Categories": "cs.LG cs.CV"}, "abstract": "Artificial Intelligence (AI) has made its way into various scientific fields, providing astonishing improvements over existing algorithms for a wide variety of tasks. In recent years, there have been severe concerns over the trustworthiness of AI technologies. The scientific community has focused on the development of trustworthy AI algorithms. However, machine and deep learning algorithms, popular in the AI community today, depend heavily on the data used during their development. These learning algorithms identify patterns in the data, learning the behavioral objective. Any flaws in the data have the potential to translate directly into algorithms. In this study, we discuss the importance of Responsible Machine Learning Datasets and propose a framework to evaluate the datasets through a responsible rubric. While existing work focuses on the post-hoc evaluation of algorithms for their trustworthiness, we provide a framework that considers the data component separately to understand its role in the algorithm. We discuss responsible datasets through the lens of fairness, privacy, and regulatory compliance and provide recommendations for constructing future datasets. After surveying over 100 datasets, we use 60 datasets for analysis and demonstrate that none of these datasets is immune to issues of fairness, privacy preservation, and regulatory compliance. We provide modifications to the ``datasheets for datasets\" with important additions for improved dataset documentation. With governments around the world regularizing data protection laws, the method for the creation of datasets in the scientific community requires revision. We believe this study is timely and relevant in today's era of AI.", "url": "https://arxiv.org/abs/2310.15848"}, {"metadata": {"arXiv": "2310.15865", "Date": "Tue, 24 Oct 2023 14:23:10 ", "Title": "Using Causality-Aware Graph Neural Networks to Predict Temporal Centralities in Dynamic Graphs", "Authors": ["Franziska Heeg", "Ingo Scholtes"], "Categories": "cs.LG cs.SI"}, "abstract": "Node centralities play a pivotal role in network science, social network analysis, and recommender systems. In temporal data, static path-based centralities like closeness or betweenness can give misleading results about the true importance of nodes in a temporal graph. To address this issue, temporal generalizations of betweenness and closeness have been defined that are based on the shortest time-respecting paths between pairs of nodes. However, a major issue of those generalizations is that the calculation of such paths is computationally expensive. Addressing this issue, we study the application of De Bruijn Graph Neural Networks (DBGNN), a causality-aware graph neural network architecture, to predict temporal path-based centralities in time series data. We experimentally evaluate our approach in 13 temporal graphs from biological and social systems and show that it considerably improves the prediction of both betweenness and closeness centrality compared to a static Graph Convolutional Neural Network.", "url": "https://arxiv.org/abs/2310.15865"}, {"metadata": {"arXiv": "2310.15888", "Date": "Tue, 24 Oct 2023 14:47:02 ", "Title": "State Sequences Prediction via Fourier Transform for Representation Learning", "Authors": ["Mingxuan Ye", "Yufei Kuang", "Jie Wang", "Rui Yang", "Wengang Zhou", "Houqiang Li", "Feng Wu"], "Categories": "cs.LG"}, "abstract": "While deep reinforcement learning (RL) has been demonstrated effective in solving complex control tasks, sample efficiency remains a key challenge due to the large amounts of data required for remarkable performance. Existing research explores the application of representation learning for data-efficient RL, e.g., learning predictive representations by predicting long-term future states. However, many existing methods do not fully exploit the structural information inherent in sequential state signals, which can potentially improve the quality of long-term decision-making but is difficult to discern in the time domain. To tackle this problem, we propose State Sequences Prediction via Fourier Transform (SPF), a novel method that exploits the frequency domain of state sequences to extract the underlying patterns in time series data for learning expressive representations efficiently. Specifically, we theoretically analyze the existence of structural information in state sequences, which is closely related to policy performance and signal regularity, and then propose to predict the Fourier transform of infinite-step future state sequences to extract such information. One of the appealing features of SPF is that it is simple to implement while not requiring storage of infinite-step future states as prediction targets. Experiments demonstrate that the proposed method outperforms several state-of-the-art algorithms in terms of both sample efficiency and performance.", "url": "https://arxiv.org/abs/2310.15888"}, {"metadata": {"arXiv": "2310.15890", "Date": "Tue, 24 Oct 2023 14:48:23 ", "Title": "Cross-feature Contrastive Loss for Decentralized Deep Learning on Heterogeneous Data", "Authors": ["Sai Aparna Aketi and Kaushik Roy"], "Categories": "cs.LG", "Comments": ["12 pages", "7 figures", "11 tables. arXiv admin note: text overlap with arXiv:2305.04792"], "Journal-ref": "WACV 2024"}, "abstract": "The current state-of-the-art decentralized learning algorithms mostly assume the data distribution to be Independent and Identically Distributed (IID). However, in practical scenarios, the distributed datasets can have significantly heterogeneous data distributions across the agents. In this work, we present a novel approach for decentralized learning on heterogeneous data, where data-free knowledge distillation through contrastive loss on cross-features is utilized to improve performance. Cross-features for a pair of neighboring agents are the features (i.e., last hidden layer activations) obtained from the data of an agent with respect to the model parameters of the other agent. We demonstrate the effectiveness of the proposed technique through an exhaustive set of experiments on various Computer Vision datasets (CIFAR-10, CIFAR-100, Fashion MNIST, and ImageNet), model architectures, and network topologies. Our experiments show that the proposed method achieves superior performance (0.2-4% improvement in test accuracy) compared to other existing techniques for decentralized learning on heterogeneous data.", "url": "https://arxiv.org/abs/2310.15890"}, {"metadata": {"arXiv": "2310.15903", "Date": "Tue, 24 Oct 2023 15:07:16 ", "Title": "Neural Collapse in Multi-label Learning with Pick-all-label Loss", "Authors": ["Pengyu Li", "Yutong Wang", "Xiao Li", "Qing Qu"], "Categories": "cs.LG"}, "abstract": "We study deep neural networks for the multi-label classification (MLab) task through the lens of neural collapse (NC). Previous works have been restricted to the multi-class classification setting and discovered a prevalent NC phenomenon comprising of the following properties for the last-layer features: (i) the variability of features within every class collapses to zero, (ii) the set of feature means form an equi-angular tight frame (ETF), and (iii) the last layer classifiers collapse to the feature mean upon some scaling. We generalize the study to multi-label learning, and prove for the first time that a generalized NC phenomenon holds with the \"pick-all-label'' formulation. Under the natural analog of the unconstrained feature model (UFM), we establish that the only global classifier of the pick-all-label cross entropy loss display the same ETF geometry which further collapse to multiplicity-1 feature class means. Besides, we discover a combinatorial property in generalized NC which is unique for multi-label learning that we call ``tag-wise average'' property, where the feature class-means of samples with multiple labels are scaled average of the feature class-means of single label tags. Theoretically, we establish global optimality result for the pick-all-label cross-entropy risk for the UFM. Additionally, We also provide empirical evidence to support our investigation into training deep neural networks on multi-label datasets, resulting in improved training efficiency.", "url": "https://arxiv.org/abs/2310.15903"}, {"metadata": {"arXiv": "2310.15912", "Date": "Tue, 24 Oct 2023 15:15:28 ", "Title": "Climate Change Impact on Agricultural Land Suitability: An Interpretable Machine Learning-Based Eurasia Case Study", "Authors": ["Valeriy Shevchenko", "Daria Taniushkina", "Aleksander Lukashevich", "Aleksandr Bulkin", "Roland Grinis", "Kirill Kovalev", "Veronika Narozhnaia", "Nazar Sotiriadi", "Alexander Krenke", "Yury Maximov"], "Categories": "cs.LG"}, "abstract": "The United Nations has identified improving food security and reducing hunger as essential components of its sustainable development goals. As of 2021, approximately 828 million people worldwide are experiencing hunger and malnutrition, with numerous fatalities reported. Climate change significantly impacts agricultural land suitability, potentially leading to severe food shortages and subsequent social and political conflicts. To address this pressing issue, we have developed a machine learning-based approach to predict the risk of substantial land suitability degradation and changes in irrigation patterns. Our study focuses on Central Eurasia, a region burdened with economic and social challenges. This study represents a pioneering effort in utilizing machine learning methods to assess the impact of climate change on agricultural land suitability under various carbon emissions scenarios. Through comprehensive feature importance analysis, we unveil specific climate and terrain characteristics that exert influence on land suitability. Our approach achieves remarkable accuracy, offering policymakers invaluable insights to facilitate informed decisions aimed at averting a humanitarian crisis, including strategies such as the provision of additional water and fertilizers. This research underscores the tremendous potential of machine learning in addressing global challenges, with a particular emphasis on mitigating hunger and malnutrition.", "url": "https://arxiv.org/abs/2310.15912"}, {"metadata": {"arXiv": "2310.15932", "Date": "Tue, 24 Oct 2023 15:28:43 ", "Title": "Online Robust Mean Estimation", "Authors": ["Daniel M. Kane and Ilias Diakonikolas and Hanshen Xiao and Sihan Liu"], "Categories": "cs.LG", "Comments": ["To appear in SODA2024"]}, "abstract": "We study the problem of high-dimensional robust mean estimation in an online setting. Specifically, we consider a scenario where $n$ sensors are measuring some common, ongoing phenomenon. At each time step $t=1,2,\\ldots,T$, the $i^{th}$ sensor reports its readings $x^{(i)}_t$ for that time step. The algorithm must then commit to its estimate $\\mu_t$ for the true mean value of the process at time $t$. We assume that most of the sensors observe independent samples from some common distribution $X$, but an $\\epsilon$-fraction of them may instead behave maliciously. The algorithm wishes to compute a good approximation $\\mu$ to the true mean $\\mu^\\ast := \\mathbf{E}[X]$. We note that if the algorithm is allowed to wait until time $T$ to report its estimate, this reduces to the well-studied problem of robust mean estimation. However, the requirement that our algorithm produces partial estimates as the data is coming in substantially complicates the situation. We prove two main results about online robust mean estimation in this model. First, if the uncorrupted samples satisfy the standard condition of $(\\epsilon,\\delta)$-stability, we give an efficient online algorithm that outputs estimates $\\mu_t$, $t \\in [T],$ such that with high probability it holds that $\\|\\mu-\\mu^\\ast\\|_2 = O(\\delta \\log(T))$, where $\\mu = (\\mu_t)_{t \\in [T]}$. We note that this error bound is nearly competitive with the best offline algorithms, which would achieve $\\ell_2$-error of $O(\\delta)$. Our second main result shows that with additional assumptions on the input (most notably that $X$ is a product distribution) there are inefficient algorithms whose error does not depend on $T$ at all.", "url": "https://arxiv.org/abs/2310.15932"}, {"metadata": {"arXiv": "2310.15938", "Date": "Tue, 24 Oct 2023 15:34:30 ", "Title": "ABKD: Graph Neural Network Compression with Attention-Based Knowledge Distillation", "Authors": ["Anshul Ahluwalia", "Rohit Das", "Payman Behnam", "Alind Khare", "Pan Li", "Alexey Tumanov"], "Categories": "cs.LG"}, "abstract": "Graph Neural Networks (GNNs) have proven to be quite versatile for a variety of applications, including recommendation systems, fake news detection, drug discovery, and even computer vision. Due to the expanding size of graph-structured data, GNN models have also increased in complexity, leading to substantial latency issues. This is primarily attributed to the irregular structure of graph data and its access pattern into memory. The natural solution to reduce latency is to compress large GNNs into small GNNs. One way to do this is via knowledge distillation (KD). However, most KD approaches for GNNs only consider the outputs of the last layers and do not consider the outputs of the intermediate layers of the GNNs; these layers may contain important inductive biases indicated by the graph structure. To address this shortcoming, we propose a novel KD approach to GNN compression that we call Attention-Based Knowledge Distillation (ABKD). ABKD is a KD approach that uses attention to identify important intermediate teacher-student layer pairs and focuses on aligning their outputs. ABKD enables higher compression of GNNs with a smaller accuracy dropoff compared to existing KD approaches. On average, we achieve a 1.79% increase in accuracy with a 32.3x compression ratio on OGBN-Mag, a large graph dataset, compared to state-of-the-art approaches.", "url": "https://arxiv.org/abs/2310.15938"}, {"metadata": {"arXiv": "2310.15951", "Date": "Tue, 24 Oct 2023 15:51:20 ", "Title": "Weighted Distance Nearest Neighbor Condensing", "Authors": ["Lee-Ad Gottlieb", "Timor Sharabi", "Roi Weiss"], "Categories": "cs.LG"}, "abstract": "The problem of nearest neighbor condensing has enjoyed a long history of study, both in its theoretical and practical aspects. In this paper, we introduce the problem of weighted distance nearest neighbor condensing, where one assigns weights to each point of the condensed set, and then new points are labeled based on their weighted distance nearest neighbor in the condensed set. We study the theoretical properties of this new model, and show that it can produce dramatically better condensing than the standard nearest neighbor rule, yet is characterized by generalization bounds almost identical to the latter. We then suggest a condensing heuristic for our new problem. We demonstrate Bayes consistency for this heuristic, and also show promising empirical results.", "url": "https://arxiv.org/abs/2310.15951"}, {"metadata": {"arXiv": "2310.15952", "Date": "Tue, 24 Oct 2023 15:53:07 ", "Title": "Improving Robustness and Reliability in Medical Image Classification with Latent-Guided Diffusion and Nested-Ensembles", "Authors": ["Xing Shen", "Hengguan Huang", "Brennan Nichyporuk", "Tal Arbel"], "Categories": "cs.LG cs.CV", "Comments": ["13 pages", "6 figures"]}, "abstract": "While deep learning models have achieved remarkable success across a range of medical image analysis tasks, deployment of these models in real clinical contexts requires that they be robust to variability in the acquired images. While many methods apply predefined transformations to augment the training data to enhance test-time robustness, these transformations may not ensure the model's robustness to the diverse variability seen in patient images. In this paper, we introduce a novel three-stage approach based on transformers coupled with conditional diffusion models, with the goal of improving model robustness to the kinds of imaging variability commonly encountered in practice without the need for pre-determined data augmentation strategies. To this end, multiple image encoders first learn hierarchical feature representations to build discriminative latent spaces. Next, a reverse diffusion process, guided by the latent code, acts on an informative prior and proposes prediction candidates in a generative manner. Finally, several prediction candidates are aggregated in a bi-level aggregation protocol to produce the final output. Through extensive experiments on medical imaging benchmark datasets, we show that our method improves upon state-of-the-art methods in terms of robustness and confidence calibration. Additionally, we introduce a strategy to quantify the prediction uncertainty at the instance level, increasing their trustworthiness to clinicians using them in clinical practice.", "url": "https://arxiv.org/abs/2310.15952"}, {"metadata": {"arXiv": "2310.15975", "Date": "Tue, 24 Oct 2023 16:25:13 ", "Title": "Data-driven Traffic Simulation: A Comprehensive Review", "Authors": ["Di Chen", "Meixin Zhu", "Hao Yang", "Xuesong Wang", "Yinhai Wang"], "Categories": "cs.LG", "Comments": ["18 pages", "4 figures", "4 tables"]}, "abstract": "Autonomous vehicles (AVs) have the potential to significantly revolutionize society by providing a secure and efficient mode of transportation. Recent years have witnessed notable advance-ments in autonomous driving perception and prediction, but the challenge of validating the performance of AVs remains largely unresolved. Data-driven microscopic traffic simulation has be-come an important tool for autonomous driving testing due to 1) availability of high-fidelity traffic data; 2) its advantages of ena-bling large-scale testing and scenario reproducibility; and 3) its potential in reactive and realistic traffic simulation. However, a comprehensive review of this topic is currently lacking. This pa-per aims to fill this gap by summarizing relevant studies. The primary objective of this paper is to review current research ef-forts and provide a futuristic perspective that will benefit future developments in the field. It introduces the general issues of data-driven traffic simulation and outlines key concepts and terms. After overviewing traffic simulation, various datasets and evalua-tion metrics commonly used are reviewed. The paper then offers a comprehensive evaluation of imitation learning, reinforcement learning, generative and deep learning methods, summarizing each and analyzing their advantages and disadvantages in detail. Moreover, it evaluates the state-of-the-art, existing challenges, and future research directions.", "url": "https://arxiv.org/abs/2310.15975"}, {"metadata": {"arXiv": "2310.15976", "Date": "Tue, 24 Oct 2023 16:25:13 ", "Title": "Convergence of Sign-based Random Reshuffling Algorithms for Nonconvex Optimization", "Authors": ["Zhen Qin", "Zhishuai Liu", "Pan Xu"], "Categories": "cs.LG cs.DC math.OC stat.ML", "Comments": ["45 pages", "4 figures"]}, "abstract": "signSGD is popular in nonconvex optimization due to its communication efficiency. Yet, existing analyses of signSGD rely on assuming that data are sampled with replacement in each iteration, contradicting the practical implementation where data are randomly reshuffled and sequentially fed into the algorithm. We bridge this gap by proving the first convergence result of signSGD with random reshuffling (SignRR) for nonconvex optimization. Given the dataset size $n$, the number of epochs of data passes $T$, and the variance bound of a stochastic gradient $\\sigma^2$, we show that SignRR has the same convergence rate $O(\\log(nT)/\\sqrt{nT} + \\|\\sigma\\|_1)$ as signSGD \\citep{bernstein2018signsgd}. We then present SignRVR and SignRVM, which leverage variance-reduced gradients and momentum updates respectively, both converging at $O(\\log(nT)/\\sqrt{nT})$. In contrast with the analysis of signSGD, our results do not require an extremely large batch size in each iteration to be of the same order as the total number of iterations \\citep{bernstein2018signsgd} or the signs of stochastic and true gradients match element-wise with a minimum probability of 1/2 \\citep{safaryan2021stochastic}. We also extend our algorithms to cases where data are distributed across different machines, yielding dist-SignRVR and dist-SignRVM, both converging at $O(\\log(n_0T)/\\sqrt{n_0T})$, where $n_0$ is the dataset size of a single machine. We back up our theoretical findings through experiments on simulated and real-world problems, verifying that randomly reshuffled sign methods match or surpass existing baselines.", "url": "https://arxiv.org/abs/2310.15976"}, {"metadata": {"arXiv": "2310.16005", "Date": "Tue, 24 Oct 2023 17:00:00 ", "Title": "MLFMF: Data Sets for Machine Learning for Mathematical Formalization", "Authors": ["Andrej Bauer", "Matej Petkovi\\'c", "Ljup\\v{c}o Todorovski"], "Categories": "cs.LG", "Comments": ["NeurIPS 2023"]}, "abstract": "We introduce MLFMF, a collection of data sets for benchmarking recommendation systems used to support formalization of mathematics with proof assistants. These systems help humans identify which previous entries (theorems, constructions, datatypes, and postulates) are relevant in proving a new theorem or carrying out a new construction. Each data set is derived from a library of formalized mathematics written in proof assistants Agda or Lean. The collection includes the largest Lean~4 library Mathlib, and some of the largest Agda libraries: the standard library, the library of univalent mathematics Agda-unimath, and the TypeTopology library. Each data set represents the corresponding library in two ways: as a heterogeneous network, and as a list of s-expressions representing the syntax trees of all the entries in the library. The network contains the (modular) structure of the library and the references between entries, while the s-expressions give complete and easily parsed information about every entry. We report baseline results using standard graph and word embeddings, tree ensembles, and instance-based learning algorithms. The MLFMF data sets provide solid benchmarking support for further investigation of the numerous machine learning approaches to formalized mathematics. The methodology used to extract the networks and the s-expressions readily applies to other libraries, and is applicable to other proof assistants. With more than $250\\,000$ entries in total, this is currently the largest collection of formalized mathematical knowledge in machine learnable format.", "url": "https://arxiv.org/abs/2310.16005"}, {"metadata": {"arXiv": "2310.16027", "Date": "Tue, 24 Oct 2023 17:43:16 ", "Title": "TimewarpVAE: Simultaneous Time-Warping and Representation Learning of Trajectories", "Authors": ["Travers Rhodes and Daniel D. Lee"], "Categories": "cs.LG cs.RO", "Comments": ["17 pages", "12 figures"]}, "abstract": "Human demonstrations of trajectories are an important source of training data for many machine learning problems. However, the difficulty of collecting human demonstration data for complex tasks makes learning efficient representations of those trajectories challenging. For many problems, such as for handwriting or for quasistatic dexterous manipulation, the exact timings of the trajectories should be factored from their spatial path characteristics. In this work, we propose TimewarpVAE, a fully differentiable manifold-learning algorithm that incorporates Dynamic Time Warping (DTW) to simultaneously learn both timing variations and latent factors of spatial variation. We show how the TimewarpVAE algorithm learns appropriate time alignments and meaningful representations of spatial variations in small handwriting and fork manipulation datasets. Our results have lower spatial reconstruction test error than baseline approaches and the learned low-dimensional representations can be used to efficiently generate semantically meaningful novel trajectories.", "url": "https://arxiv.org/abs/2310.16027"}, {"metadata": {"arXiv": "2310.16046", "Date": "Tue, 24 Oct 2023 17:58:26 ", "Title": "A Unified, Scalable Framework for Neural Population Decoding", "Authors": ["Mehdi Azabou", "Vinam Arora", "Venkataramana Ganesh", "Ximeng Mao", "Santosh Nachimuthu", "Michael J. Mendelson", "Blake Richards", "Matthew G. Perich", "Guillaume Lajoie", "Eva L. Dyer"], "Categories": "cs.LG q-bio.NC", "Comments": ["Accepted at NeurIPS 2023"]}, "abstract": "Our ability to use deep learning approaches to decipher neural activity would likely benefit from greater scale, in terms of both model size and datasets. However, the integration of many neural recordings into one unified model is challenging, as each recording contains the activity of different neurons from different individual animals. In this paper, we introduce a training framework and architecture designed to model the population dynamics of neural activity across diverse, large-scale neural recordings. Our method first tokenizes individual spikes within the dataset to build an efficient representation of neural events that captures the fine temporal structure of neural activity. We then employ cross-attention and a PerceiverIO backbone to further construct a latent tokenization of neural population activities. Utilizing this architecture and training framework, we construct a large-scale multi-session model trained on large datasets from seven nonhuman primates, spanning over 158 different sessions of recording from over 27,373 neural units and over 100 hours of recordings. In a number of different tasks, we demonstrate that our pretrained model can be rapidly adapted to new, unseen sessions with unspecified neuron correspondence, enabling few-shot performance with minimal labels. This work presents a powerful new approach for building deep learning tools to analyze neural data and stakes out a clear path to training at scale.", "url": "https://arxiv.org/abs/2310.16046"}, {"metadata": {"arXiv": "2310.15337", "Date": "Mon, 23 Oct 2023 20:05:37 ", "Title": "Moral Foundations of Large Language Models", "Authors": ["Marwa Abdulhai", "Gregory Serapio-Garcia", "Cl\\'ement Crepy", "Daria Valter", "John Canny", "Natasha Jaques"], "Categories": "cs.AI cs.CL cs.CY"}, "abstract": "Moral foundations theory (MFT) is a psychological assessment tool that decomposes human moral reasoning into five factors, including care/harm, liberty/oppression, and sanctity/degradation (Graham et al., 2009). People vary in the weight they place on these dimensions when making moral decisions, in part due to their cultural upbringing and political ideology. As large language models (LLMs) are trained on datasets collected from the internet, they may reflect the biases that are present in such corpora. This paper uses MFT as a lens to analyze whether popular LLMs have acquired a bias towards a particular set of moral values. We analyze known LLMs and find they exhibit particular moral foundations, and show how these relate to human moral foundations and political affiliations. We also measure the consistency of these biases, or whether they vary strongly depending on the context of how the model is prompted. Finally, we show that we can adversarially select prompts that encourage the moral to exhibit a particular set of moral foundations, and that this can affect the model's behavior on downstream tasks. These findings help illustrate the potential risks and unintended consequences of LLMs assuming a particular moral stance.", "url": "https://arxiv.org/abs/2310.15337"}, {"metadata": {"arXiv": "2310.15597", "Date": "Tue, 24 Oct 2023 08:00:20 ", "Title": "Emergent Communication in Interactive Sketch Question Answering", "Authors": ["Zixing Lei", "Yiming Zhang", "Yuxin Xiong and Siheng Chen"], "Categories": "cs.AI cs.CV", "Comments": ["Accepted by NeurIPS 2023"]}, "abstract": "Vision-based emergent communication (EC) aims to learn to communicate through sketches and demystify the evolution of human communication. Ironically, previous works neglect multi-round interaction, which is indispensable in human communication. To fill this gap, we first introduce a novel Interactive Sketch Question Answering (ISQA) task, where two collaborative players are interacting through sketches to answer a question about an image in a multi-round manner. To accomplish this task, we design a new and efficient interactive EC system, which can achieve an effective balance among three evaluation factors, including the question answering accuracy, drawing complexity and human interpretability. Our experimental results including human evaluation demonstrate that multi-round interactive mechanism facilitates targeted and efficient communication between intelligent agents with decent human interpretability.", "url": "https://arxiv.org/abs/2310.15597"}, {"metadata": {"arXiv": "2310.15705", "Date": "Tue, 24 Oct 2023 10:31:34 ", "Title": "Learning-based Scheduling for Information Accuracy and Freshness in Wireless Networks", "Authors": ["Hitesh Gudwani"], "Categories": "cs.AI cs.NI", "Comments": ["21 pages", "5 figures"]}, "abstract": "We consider a system of multiple sources, a single communication channel, and a single monitoring station. Each source measures a time-varying quantity with varying levels of accuracy and one of them sends its update to the monitoring station via the channel. The probability of success of each attempted communication is a function of the source scheduled for transmitting its update. Both the probability of correct measurement and the probability of successful transmission of all the sources are unknown to the scheduler. The metric of interest is the reward received by the system which depends on the accuracy of the last update received by the destination and the Age-of-Information (AoI) of the system. We model our scheduling problem as a variant of the multi-arm bandit problem with sources as different arms. We compare the performance of all $4$ standard bandit policies, namely, ETC, $\\epsilon$-greedy, UCB, and TS suitably adjusted to our system model via simulations. In addition, we provide analytical guarantees of $2$ of these policies, ETC, and $\\epsilon$-greedy. Finally, we characterize the lower bound on the cumulative regret achievable by any policy.", "url": "https://arxiv.org/abs/2310.15705"}, {"metadata": {"arXiv": "2310.15676", "Date": "Tue, 24 Oct 2023 09:39:05 ", "Title": "Recent Advances in Multi-modal 3D Scene Understanding: A Comprehensive Survey and Evaluation", "Authors": ["Yinjie Lei", "Zixuan Wang", "Feng Chen", "Guoqing Wang", "Peng Wang and Yang Yang"], "Categories": "cs.CV cs.AI"}, "abstract": "Multi-modal 3D scene understanding has gained considerable attention due to its wide applications in many areas, such as autonomous driving and human-computer interaction. Compared to conventional single-modal 3D understanding, introducing an additional modality not only elevates the richness and precision of scene interpretation but also ensures a more robust and resilient understanding. This becomes especially crucial in varied and challenging environments where solely relying on 3D data might be inadequate. While there has been a surge in the development of multi-modal 3D methods over past three years, especially those integrating multi-camera images (3D+2D) and textual descriptions (3D+language), a comprehensive and in-depth review is notably absent. In this article, we present a systematic survey of recent progress to bridge this gap. We begin by briefly introducing a background that formally defines various 3D multi-modal tasks and summarizes their inherent challenges. After that, we present a novel taxonomy that delivers a thorough categorization of existing methods according to modalities and tasks, exploring their respective strengths and limitations. Furthermore, comparative results of recent approaches on several benchmark datasets, together with insightful analysis, are offered. Finally, we discuss the unresolved issues and provide several potential avenues for future research.", "url": "https://arxiv.org/abs/2310.15676"}, {"metadata": {"arXiv": "2310.15764", "Date": "Tue, 24 Oct 2023 12:11:19 ", "Title": "Debiasing, calibrating, and improving Semi-supervised Learning performance via simple Ensemble Projector", "Authors": ["Khanh-Binh Nguyen"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted to WACV 2024"]}, "abstract": "Recent studies on semi-supervised learning (SSL) have achieved great success. Despite their promising performance, current state-of-the-art methods tend toward increasingly complex designs at the cost of introducing more network components and additional training procedures. In this paper, we propose a simple method named Ensemble Projectors Aided for Semi-supervised Learning (EPASS), which focuses mainly on improving the learned embeddings to boost the performance of the existing contrastive joint-training semi-supervised learning frameworks. Unlike standard methods, where the learned embeddings from one projector are stored in memory banks to be used with contrastive learning, EPASS stores the ensemble embeddings from multiple projectors in memory banks. As a result, EPASS improves generalization, strengthens feature representation, and boosts performance. For instance, EPASS improves strong baselines for semi-supervised learning by 39.47\\%/31.39\\%/24.70\\% top-1 error rate, while using only 100k/1\\%/10\\% of labeled data for SimMatch, and achieves 40.24\\%/32.64\\%/25.90\\% top-1 error rate for CoMatch on the ImageNet dataset. These improvements are consistent across methods, network architectures, and datasets, proving the general effectiveness of the proposed methods. Code is available at https://github.com/beandkay/EPASS.", "url": "https://arxiv.org/abs/2310.15764"}, {"metadata": {"arXiv": "2310.15778", "Date": "Tue, 24 Oct 2023 12:25:37 ", "Title": "3D Masked Autoencoders for Enhanced Privacy in MRI Scans", "Authors": ["Lennart Alexander Van der Goten and Kevin Smith"], "Categories": "cs.CV cs.AI"}, "abstract": "MRI scans provide valuable medical information, however they also contain sensitive and personally identifiable information (PII) that needs to be protected. Whereas MRI metadata is easily sanitized, MRI image data is a privacy risk because it contains information to render highly-realistic 3D visualizations of a patient's head, enabling malicious actors to possibly identify the subject by cross-referencing a database. Data anonymization and de-identification is concerned with ensuring the privacy and confidentiality of individuals' personal information. Traditional MRI de-identification methods remove privacy-sensitive parts (e.g. eyes, nose etc.) from a given scan. This comes at the expense of introducing a domain shift that can throw off downstream analyses. Recently, a GAN-based approach was proposed to de-identify a patient's scan by remodeling it (e.g. changing the face) rather than by removing parts. In this work, we propose CP-MAE, a model that de-identifies the face using masked autoencoders and that outperforms all previous approaches in terms of downstream task performance as well as de-identification. With our method we are able to synthesize scans of resolution up to $256^3$ (previously 128 cubic) which constitutes an eight-fold increase in the number of voxels. Using our construction we were able to design a system that exhibits a highly robust training stage, making it easy to fit the network on novel data.", "url": "https://arxiv.org/abs/2310.15778"}, {"metadata": {"arXiv": "2310.15787", "Date": "Tue, 24 Oct 2023 12:34:58 ", "Title": "SequenceMatch: Revisiting the design of weak-strong augmentations for Semi-supervised learning", "Authors": ["Khanh-Binh Nguyen"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted to WACV 2024"]}, "abstract": "Semi-supervised learning (SSL) has become popular in recent years because it allows the training of a model using a large amount of unlabeled data. However, one issue that many SSL methods face is the confirmation bias, which occurs when the model is overfitted to the small labeled training dataset and produces overconfident, incorrect predictions. To address this issue, we propose SequenceMatch, an efficient SSL method that utilizes multiple data augmentations. The key element of SequenceMatch is the inclusion of a medium augmentation for unlabeled data. By taking advantage of different augmentations and the consistency constraints between each pair of augmented examples, SequenceMatch helps reduce the divergence between the prediction distribution of the model for weakly and strongly augmented examples. In addition, SequenceMatch defines two different consistency constraints for high and low-confidence predictions. As a result, SequenceMatch is more data-efficient than ReMixMatch, and more time-efficient than both ReMixMatch ($\\times4$) and CoMatch ($\\times2$) while having higher accuracy. Despite its simplicity, SequenceMatch consistently outperforms prior methods on standard benchmarks, such as CIFAR-10/100, SVHN, and STL-10. It also surpasses prior state-of-the-art methods by a large margin on large-scale datasets such as ImageNet, with a 38.46\\% error rate. Code is available at https://github.com/beandkay/SequenceMatch.", "url": "https://arxiv.org/abs/2310.15787"}, {"metadata": {"arXiv": "2310.16052", "Date": "Tue, 24 Oct 2023 17:59:55 ", "Title": "Synthetic Data as Validation", "Authors": ["Qixin Hu", "Alan Yuille", "Zongwei Zhou"], "Categories": "cs.CV cs.AI"}, "abstract": "This study leverages synthetic data as a validation set to reduce overfitting and ease the selection of the best model in AI development. While synthetic data have been used for augmenting the training set, we find that synthetic data can also significantly diversify the validation set, offering marked advantages in domains like healthcare, where data are typically limited, sensitive, and from out-domain sources (i.e., hospitals). In this study, we illustrate the effectiveness of synthetic data for early cancer detection in computed tomography (CT) volumes, where synthetic tumors are generated and superimposed onto healthy organs, thereby creating an extensive dataset for rigorous validation. Using synthetic data as validation can improve AI robustness in both in-domain and out-domain test sets. Furthermore, we establish a new continual learning framework that continuously trains AI models on a stream of out-domain data with synthetic tumors. The AI model trained and validated in dynamically expanding synthetic data can consistently outperform models trained and validated exclusively on real-world data. Specifically, the DSC score for liver tumor segmentation improves from 26.7% (95% CI: 22.6%-30.9%) to 34.5% (30.8%-38.2%) when evaluated on an in-domain dataset and from 31.1% (26.0%-36.2%) to 35.4% (32.1%-38.7%) on an out-domain dataset. Importantly, the performance gain is particularly significant in identifying very tiny liver tumors (radius < 5mm) in CT volumes, with Sensitivity improving from 33.1% to 55.4% on an in-domain dataset and 33.9% to 52.3% on an out-domain dataset, justifying the efficacy in early detection of cancer. The application of synthetic data, from both training and validation perspectives, underlines a promising avenue to enhance AI robustness when dealing with data from varying domains.", "url": "https://arxiv.org/abs/2310.16052"}, {"metadata": {"arXiv": "2310.15274", "Date": "Mon, 23 Oct 2023 18:20:54 ", "Title": "Systematic AI Approach for AGI: Addressing Alignment, Energy, and AGI Grand Challenges", "Authors": ["Eren Kurshan"], "Categories": "cs.AI cs.LG", "Comments": ["International Journal on Semantic Computing (2024) Categories: Artificial Intelligence; AI; Artificial General Intelligence; AGI; System Design; System Architecture"]}, "abstract": "AI faces a trifecta of grand challenges the Energy Wall, the Alignment Problem and the Leap from Narrow AI to AGI. Contemporary AI solutions consume unsustainable amounts of energy during model training and daily operations.Making things worse, the amount of computation required to train each new AI model has been doubling every 2 months since 2020, directly translating to increases in energy consumption.The leap from AI to AGI requires multiple functional subsystems operating in a balanced manner, which requires a system architecture. However, the current approach to artificial intelligence lacks system design; even though system characteristics play a key role in the human brain from the way it processes information to how it makes decisions. Similarly, current alignment and AI ethics approaches largely ignore system design, yet studies show that the brains system architecture plays a critical role in healthy moral decisions.In this paper, we argue that system design is critically important in overcoming all three grand challenges. We posit that system design is the missing piece in overcoming the grand challenges.We present a Systematic AI Approach for AGI that utilizes system design principles for AGI, while providing ways to overcome the energy wall and the alignment challenges.", "url": "https://arxiv.org/abs/2310.15274"}, {"metadata": {"arXiv": "2310.15288", "Date": "Mon, 23 Oct 2023 18:54:43 ", "Title": "Active teacher selection for reinforcement learning from human feedback", "Authors": ["Rachel Freedman", "Justin Svegliato", "Kyle Wray", "Stuart Russell"], "Categories": "cs.AI cs.LG"}, "abstract": "Reinforcement learning from human feedback (RLHF) enables machine learning systems to learn objectives from human feedback. A core limitation of these systems is their assumption that all feedback comes from a single human teacher, despite querying a range of distinct teachers. We propose the Hidden Utility Bandit (HUB) framework to model differences in teacher rationality, expertise, and costliness, formalizing the problem of learning from multiple teachers. We develop a variety of solution algorithms and apply them to two real-world domains: paper recommendation systems and COVID-19 vaccine testing. We find that the Active Teacher Selection (ATS) algorithm outperforms baseline algorithms by actively selecting when and which teacher to query. The HUB framework and ATS algorithm demonstrate the importance of leveraging differences between teachers to learn accurate reward models, facilitating future research on active teacher selection for robust reward modeling.", "url": "https://arxiv.org/abs/2310.15288"}, {"metadata": {"arXiv": "2310.15414", "Date": "Tue, 24 Oct 2023 00:07:20 ", "Title": "Diverse Conventions for Human-AI Collaboration", "Authors": ["Bidipta Sarkar and Andy Shih and Dorsa Sadigh"], "Categories": "cs.AI cs.LG cs.MA", "Comments": ["25 pages", "9 figures", "37th Conference on Neural Information Processing Systems (NeurIPS 2023)"]}, "abstract": "Conventions are crucial for strong performance in cooperative multi-agent games, because they allow players to coordinate on a shared strategy without explicit communication. Unfortunately, standard multi-agent reinforcement learning techniques, such as self-play, converge to conventions that are arbitrary and non-diverse, leading to poor generalization when interacting with new partners. In this work, we present a technique for generating diverse conventions by (1) maximizing their rewards during self-play, while (2) minimizing their rewards when playing with previously discovered conventions (cross-play), stimulating conventions to be semantically different. To ensure that learned policies act in good faith despite the adversarial optimization of cross-play, we introduce \\emph{mixed-play}, where an initial state is randomly generated by sampling self-play and cross-play transitions and the player learns to maximize the self-play reward from this initial state. We analyze the benefits of our technique on various multi-agent collaborative games, including Overcooked, and find that our technique can adapt to the conventions of humans, surpassing human-level performance when paired with real users.", "url": "https://arxiv.org/abs/2310.15414"}, {"metadata": {"arXiv": "2310.15706", "Date": "Tue, 24 Oct 2023 10:35:08 ", "Title": "Solving large flexible job shop scheduling instances by generating a diverse set of scheduling policies with deep reinforcement learning", "Authors": ["Imanol Echeverria", "Maialen Murua", "Roberto Santana"], "Categories": "cs.AI cs.LG"}, "abstract": "The Flexible Job Shop Scheduling Problem (FJSSP) has been extensively studied in the literature, and multiple approaches have been proposed within the heuristic, exact, and metaheuristic methods. However, the industry's demand to be able to respond in real-time to disruptive events has generated the necessity to be able to generate new schedules within a few seconds. Among these methods, under this constraint, only dispatching rules (DRs) are capable of generating schedules, even though their quality can be improved. To improve the results, recent methods have been proposed for modeling the FJSSP as a Markov Decision Process (MDP) and employing reinforcement learning to create a policy that generates an optimal solution assigning operations to machines. Nonetheless, there is still room for improvement, particularly in the larger FJSSP instances which are common in real-world scenarios. Therefore, the objective of this paper is to propose a method capable of robustly solving large instances of the FJSSP. To achieve this, we propose a novel way of modeling the FJSSP as an MDP using graph neural networks. We also present two methods to make inference more robust: generating a diverse set of scheduling policies that can be parallelized and limiting them using DRs. We have tested our approach on synthetically generated instances and various public benchmarks and found that our approach outperforms dispatching rules and achieves better results than three other recent deep reinforcement learning methods on larger FJSSP instances.", "url": "https://arxiv.org/abs/2310.15706"}, {"metadata": {"arXiv": "2310.15797", "Date": "Tue, 24 Oct 2023 12:48:52 ", "Title": "Random Entity Quantization for Parameter-Efficient Compositional Knowledge Graph Representation", "Authors": ["Jiaang Li", "Quan Wang", "Yi Liu", "Licheng Zhang", "Zhendong Mao"], "Categories": "cs.AI cs.CL cs.LG", "Comments": ["Accepted to EMNLP 2023"]}, "abstract": "Representation Learning on Knowledge Graphs (KGs) is essential for downstream tasks. The dominant approach, KG Embedding (KGE), represents entities with independent vectors and faces the scalability challenge. Recent studies propose an alternative way for parameter efficiency, which represents entities by composing entity-corresponding codewords matched from predefined small-scale codebooks. We refer to the process of obtaining corresponding codewords of each entity as entity quantization, for which previous works have designed complicated strategies. Surprisingly, this paper shows that simple random entity quantization can achieve similar results to current strategies. We analyze this phenomenon and reveal that entity codes, the quantization outcomes for expressing entities, have higher entropy at the code level and Jaccard distance at the codeword level under random entity quantization. Therefore, different entities become more easily distinguished, facilitating effective KG representation. The above results show that current quantization strategies are not critical for KG representation, and there is still room for improvement in entity distinguishability beyond current strategies. The code to reproduce our results is available at https://github.com/JiaangL/RandomQuantization.", "url": "https://arxiv.org/abs/2310.15797"}, {"metadata": {"arXiv": "2310.15940", "Date": "Tue, 24 Oct 2023 15:35:54 ", "Title": "Combining Behaviors with the Successor Features Keyboard", "Authors": ["Wilka Carvalho", "Andre Saraiva", "Angelos Filos", "Andrew Kyle Lampinen", "Loic Matthey", "Richard L. Lewis", "Honglak Lee", "Satinder Singh", "Danilo J. Rezende", "Daniel Zoran"], "Categories": "cs.AI cs.LG", "Comments": ["NeurIPS 2023"]}, "abstract": "The Option Keyboard (OK) was recently proposed as a method for transferring behavioral knowledge across tasks. OK transfers knowledge by adaptively combining subsets of known behaviors using Successor Features (SFs) and Generalized Policy Improvement (GPI). However, it relies on hand-designed state-features and task encodings which are cumbersome to design for every new environment. In this work, we propose the \"Successor Features Keyboard\" (SFK), which enables transfer with discovered state-features and task encodings. To enable discovery, we propose the \"Categorical Successor Feature Approximator\" (CSFA), a novel learning algorithm for estimating SFs while jointly discovering state-features and task encodings. With SFK and CSFA, we achieve the first demonstration of transfer with SFs in a challenging 3D environment where all the necessary representations are discovered. We first compare CSFA against other methods for approximating SFs and show that only CSFA discovers representations compatible with SF&GPI at this scale. We then compare SFK against transfer learning baselines and show that it transfers most quickly to long-horizon tasks.", "url": "https://arxiv.org/abs/2310.15940"}, {"metadata": {"arXiv": "2310.16048", "Date": "Tue, 24 Oct 2023 17:59:04 ", "Title": "AI Alignment and Social Choice: Fundamental Limitations and Policy Implications", "Authors": ["Abhilash Mishra"], "Categories": "cs.AI cs.CL cs.CY cs.HC cs.LG", "Comments": ["10 pages", "no figures"]}, "abstract": "Aligning AI agents to human intentions and values is a key bottleneck in building safe and deployable AI applications. But whose values should AI agents be aligned with? Reinforcement learning with human feedback (RLHF) has emerged as the key framework for AI alignment. RLHF uses feedback from human reinforcers to fine-tune outputs; all widely deployed large language models (LLMs) use RLHF to align their outputs to human values. It is critical to understand the limitations of RLHF and consider policy challenges arising from these limitations. In this paper, we investigate a specific challenge in building RLHF systems that respect democratic norms. Building on impossibility results in social choice theory, we show that, under fairly broad assumptions, there is no unique voting protocol to universally align AI systems using RLHF through democratic processes. Further, we show that aligning AI agents with the values of all individuals will always violate certain private ethical preferences of an individual user i.e., universal AI alignment using RLHF is impossible. We discuss policy implications for the governance of AI systems built using RLHF: first, the need for mandating transparent voting rules to hold model builders accountable. Second, the need for model builders to focus on developing AI agents that are narrowly aligned to specific user groups.", "url": "https://arxiv.org/abs/2310.16048"}, {"metadata": {"arXiv": "2310.15827", "Date": "Tue, 24 Oct 2023 13:28:46 ", "Title": "Automatic Aorta Segmentation with Heavily Augmented, High-Resolution 3-D ResUNet: Contribution to the SEG.A Challenge", "Authors": ["Marek Wodzinski and Henning M\\\"uller"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["MICCAI 2023 - SEG.A Challenge Contribution"]}, "abstract": "Automatic aorta segmentation from 3-D medical volumes is an important yet difficult task. Several factors make the problem challenging, e.g. the possibility of aortic dissection or the difficulty with segmenting and annotating the small branches. This work presents a contribution by the MedGIFT team to the SEG.A challenge organized during the MICCAI 2023 conference. We propose a fully automated algorithm based on deep encoder-decoder architecture. The main assumption behind our work is that data preprocessing and augmentation are much more important than the deep architecture, especially in low data regimes. Therefore, the solution is based on a variant of traditional convolutional U-Net. The proposed solution achieved a Dice score above 0.9 for all testing cases with the highest stability among all participants. The method scored 1st, 4th, and 3rd in terms of the clinical evaluation, quantitative results, and volumetric meshing quality, respectively. We freely release the source code, pretrained model, and provide access to the algorithm on the Grand-Challenge platform.", "url": "https://arxiv.org/abs/2310.15827"}, {"metadata": {"arXiv": "2310.16035", "Date": "Tue, 24 Oct 2023 17:50:20 ", "Title": "What's Left? Concept Grounding with Logic-Enhanced Foundation Models", "Authors": ["Joy Hsu", "Jiayuan Mao", "Joshua B. Tenenbaum", "Jiajun Wu"], "Categories": "cs.CV cs.AI cs.CL cs.LG stat.ML", "Comments": ["NeurIPS 2023. First two authors contributed equally. Project page: https://web.stanford.edu/~joycj/projects/left_neurips_2023"]}, "abstract": "Recent works such as VisProg and ViperGPT have smartly composed foundation models for visual reasoning-using large language models (LLMs) to produce programs that can be executed by pre-trained vision-language models. However, they operate in limited domains, such as 2D images, not fully exploiting the generalization of language: abstract concepts like \"left\" can also be grounded in 3D, temporal, and action data, as in moving to your left. This limited generalization stems from these inference-only methods' inability to learn or adapt pre-trained models to a new domain. We propose the Logic-Enhanced Foundation Model (LEFT), a unified framework that learns to ground and reason with concepts across domains with a differentiable, domain-independent, first-order logic-based program executor. LEFT has an LLM interpreter that outputs a program represented in a general, logic-based reasoning language, which is shared across all domains and tasks. LEFT's executor then executes the program with trainable domain-specific grounding modules. We show that LEFT flexibly learns concepts in four domains: 2D images, 3D scenes, human motions, and robotic manipulation. It exhibits strong reasoning ability in a wide variety of tasks, including those that are complex and not seen during training, and can be easily applied to new domains.", "url": "https://arxiv.org/abs/2310.16035"}, {"metadata": {"arXiv": "2310.16045", "Date": "Tue, 24 Oct 2023 17:58:07 ", "Title": "Woodpecker: Hallucination Correction for Multimodal Large Language Models", "Authors": ["Shukang Yin", "Chaoyou Fu", "Sirui Zhao", "Tong Xu", "Hao Wang", "Dianbo Sui", "Yunhang Shen", "Ke Li", "Xing Sun and Enhong Chen"], "Categories": "cs.CV cs.AI cs.CL cs.LG", "Comments": ["16 pages", "7 figures. Code Website: https://github.com/BradyFU/Woodpecker"]}, "abstract": "Hallucination is a big shadow hanging over the rapidly evolving Multimodal Large Language Models (MLLMs), referring to the phenomenon that the generated text is inconsistent with the image content. In order to mitigate hallucinations, existing studies mainly resort to an instruction-tuning manner that requires retraining the models with specific data. In this paper, we pave a different way, introducing a training-free method named Woodpecker. Like a woodpecker heals trees, it picks out and corrects hallucinations from the generated text. Concretely, Woodpecker consists of five stages: key concept extraction, question formulation, visual knowledge validation, visual claim generation, and hallucination correction. Implemented in a post-remedy manner, Woodpecker can easily serve different MLLMs, while being interpretable by accessing intermediate outputs of the five stages. We evaluate Woodpecker both quantitatively and qualitatively and show the huge potential of this new paradigm. On the POPE benchmark, our method obtains a 30.66%/24.33% improvement in accuracy over the baseline MiniGPT-4/mPLUG-Owl. The source code is released at https://github.com/BradyFU/Woodpecker.", "url": "https://arxiv.org/abs/2310.16045"}, {"metadata": {"arXiv": "2310.15188", "Date": "Fri, 20 Oct 2023 23:33:27 ", "Title": "Deep Learning Approaches for Dynamic Mechanical Analysis of Viscoelastic Fiber Composites", "Authors": ["Victor Hoffmann (1)", "Ilias Nahmed (1)", "Parisa Rastin (1 and 2)", "Gu\\'ena\\\"el Cabanes (3)", "Julien Boisse (4) ((1) ENSMN", "(2) LORIA UMR 7503", "(3) LIPN UMR 7030", "(4) LEMTA UMR 7563)"], "Categories": "cs.LG cond-mat.mtrl-sci cs.AI", "Comments": ["12 pages", "5 figures", "https://hal.science/hal-04250557"]}, "abstract": "The increased adoption of reinforced polymer (RP) composite materials, driven by eco-design standards, calls for a fine balance between lightness, stiffness, and effective vibration control. These materials are integral to enhancing comfort, safety, and energy efficiency. Dynamic Mechanical Analysis (DMA) characterizes viscoelastic behavior, yet there's a growing interest in using Machine Learning (ML) to expedite the design and understanding of microstructures. In this paper we aim to map microstructures to their mechanical properties using deep neural networks, speeding up the process and allowing for the generation of microstructures from desired properties.", "url": "https://arxiv.org/abs/2310.15188"}, {"metadata": {"arXiv": "2310.15191", "Date": "Sat, 21 Oct 2023 10:56:32 ", "Title": "Application of deep and reinforcement learning to boundary control problems", "Authors": ["Zenin Easa Panthakkalakath", "Juraj Kardo\\v{s}", "Olaf Schenk"], "Categories": "cs.LG cs.AI math.OC"}, "abstract": "The boundary control problem is a non-convex optimization and control problem in many scientific domains, including fluid mechanics, structural engineering, and heat transfer optimization. The aim is to find the optimal values for the domain boundaries such that the enclosed domain adhering to the governing equations attains the desired state values. Traditionally, non-linear optimization methods, such as the Interior-Point method (IPM), are used to solve such problems. This project explores the possibilities of using deep learning and reinforcement learning to solve boundary control problems. We adhere to the framework of iterative optimization strategies, employing a spatial neural network to construct well-informed initial guesses, and a spatio-temporal neural network learns the iterative optimization algorithm using policy gradients. Synthetic data, generated from the problems formulated in the literature, is used for training, testing and validation. The numerical experiments indicate that the proposed method can rival the speed and accuracy of existing solvers. In our preliminary results, the network attains costs lower than IPOPT, a state-of-the-art non-linear IPM, in 51\\% cases. The overall number of floating point operations in the proposed method is similar to that of IPOPT. Additionally, the informed initial guess method and the learned momentum-like behaviour in the optimizer method are incorporated to avoid convergence to local minima.", "url": "https://arxiv.org/abs/2310.15191"}, {"metadata": {"arXiv": "2310.15195", "Date": "Sun, 22 Oct 2023 08:50:57 ", "Title": "Neural Multi-Objective Combinatorial Optimization with Diversity Enhancement", "Authors": ["Jinbiao Chen", "Zizhen Zhang", "Zhiguang Cao", "Yaoxin Wu", "Yining Ma", "Te Ye", "Jiahai Wang"], "Categories": "cs.LG cs.AI cs.NE", "Comments": ["Accepted at NeurIPS 2023"]}, "abstract": "Most of existing neural methods for multi-objective combinatorial optimization (MOCO) problems solely rely on decomposition, which often leads to repetitive solutions for the respective subproblems, thus a limited Pareto set. Beyond decomposition, we propose a novel neural heuristic with diversity enhancement (NHDE) to produce more Pareto solutions from two perspectives. On the one hand, to hinder duplicated solutions for different subproblems, we propose an indicator-enhanced deep reinforcement learning method to guide the model, and design a heterogeneous graph attention mechanism to capture the relations between the instance graph and the Pareto front graph. On the other hand, to excavate more solutions in the neighborhood of each subproblem, we present a multiple Pareto optima strategy to sample and preserve desirable solutions. Experimental results on classic MOCO problems show that our NHDE is able to generate a Pareto front with higher diversity, thereby achieving superior overall performance. Moreover, our NHDE is generic and can be applied to different neural methods for MOCO.", "url": "https://arxiv.org/abs/2310.15195"}, {"metadata": {"arXiv": "2310.15196", "Date": "Sun, 22 Oct 2023 08:59:02 ", "Title": "Efficient Meta Neural Heuristic for Multi-Objective Combinatorial Optimization", "Authors": ["Jinbiao Chen", "Jiahai Wang", "Zizhen Zhang", "Zhiguang Cao", "Te Ye", "Siyuan Chen"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted at NeurIPS 2023"]}, "abstract": "Recently, neural heuristics based on deep reinforcement learning have exhibited promise in solving multi-objective combinatorial optimization problems (MOCOPs). However, they are still struggling to achieve high learning efficiency and solution quality. To tackle this issue, we propose an efficient meta neural heuristic (EMNH), in which a meta-model is first trained and then fine-tuned with a few steps to solve corresponding single-objective subproblems. Specifically, for the training process, a (partial) architecture-shared multi-task model is leveraged to achieve parallel learning for the meta-model, so as to speed up the training; meanwhile, a scaled symmetric sampling method with respect to the weight vectors is designed to stabilize the training. For the fine-tuning process, an efficient hierarchical method is proposed to systematically tackle all the subproblems. Experimental results on the multi-objective traveling salesman problem (MOTSP), multi-objective capacitated vehicle routing problem (MOCVRP), and multi-objective knapsack problem (MOKP) show that, EMNH is able to outperform the state-of-the-art neural heuristics in terms of solution quality and learning efficiency, and yield competitive solutions to the strong traditional heuristics while consuming much shorter time.", "url": "https://arxiv.org/abs/2310.15196"}, {"metadata": {"arXiv": "2310.15318", "Date": "Mon, 23 Oct 2023 19:35:57 ", "Title": "HetGPT: Harnessing the Power of Prompt Tuning in Pre-Trained Heterogeneous Graph Neural Networks", "Authors": ["Yihong Ma", "Ning Yan", "Jiayu Li", "Masood Mortazavi and Nitesh V. Chawla"], "Categories": "cs.LG cs.AI", "Comments": ["submitted to ACM TheWebConf 2024"]}, "abstract": "Graphs have emerged as a natural choice to represent and analyze the intricate patterns and rich information of the Web, enabling applications such as online page classification and social recommendation. The prevailing \"pre-train, fine-tune\" paradigm has been widely adopted in graph machine learning tasks, particularly in scenarios with limited labeled nodes. However, this approach often exhibits a misalignment between the training objectives of pretext tasks and those of downstream tasks. This gap can result in the \"negative transfer\" problem, wherein the knowledge gained from pre-training adversely affects performance in the downstream tasks. The surge in prompt-based learning within Natural Language Processing (NLP) suggests the potential of adapting a \"pre-train, prompt\" paradigm to graphs as an alternative. However, existing graph prompting techniques are tailored to homogeneous graphs, neglecting the inherent heterogeneity of Web graphs. To bridge this gap, we propose HetGPT, a general post-training prompting framework to improve the predictive performance of pre-trained heterogeneous graph neural networks (HGNNs). The key is the design of a novel prompting function that integrates a virtual class prompt and a heterogeneous feature prompt, with the aim to reformulate downstream tasks to mirror pretext tasks. Moreover, HetGPT introduces a multi-view neighborhood aggregation mechanism, capturing the complex neighborhood structure in heterogeneous graphs. Extensive experiments on three benchmark datasets demonstrate HetGPT's capability to enhance the performance of state-of-the-art HGNNs on semi-supervised node classification.", "url": "https://arxiv.org/abs/2310.15318"}, {"metadata": {"arXiv": "2310.15329", "Date": "Mon, 23 Oct 2023 19:49:59 ", "Title": "Serverless Federated Learning with flwr-serverless", "Authors": ["Sanjeev V. Namjoshi", "Reese Green", "Krishi Sharma", "Zhangzhang Si"], "Categories": "cs.LG cs.AI", "Comments": ["Technical report for an open source machine learning python package"]}, "abstract": "Federated learning is becoming increasingly relevant and popular as we witness a surge in data collection and storage of personally identifiable information. Alongside these developments there have been many proposals from governments around the world to provide more protections for individuals' data and a heightened interest in data privacy measures. As deep learning continues to become more relevant in new and existing domains, it is vital to develop strategies like federated learning that can effectively train data from different sources, such as edge devices, without compromising security and privacy. Recently, the Flower (\\texttt{Flwr}) Python package was introduced to provide a scalable, flexible, and easy-to-use framework for implementing federated learning. However, to date, Flower is only able to run synchronous federated learning which can be costly and time-consuming to run because the process is bottlenecked by client-side training jobs that are slow or fragile. Here, we introduce \\texttt{flwr-serverless}, a wrapper around the Flower package that extends its functionality to allow for both synchronous and asynchronous federated learning with minimal modification to Flower's design paradigm. Furthermore, our approach to federated learning allows the process to run without a central server, which increases the domains of application and accessibility of its use. This paper presents the design details and usage of this approach through a series of experiments that were conducted using public datasets. Overall, we believe that our approach decreases the time and cost to run federated training and provides an easier way to implement and experiment with federated learning systems.", "url": "https://arxiv.org/abs/2310.15329"}, {"metadata": {"arXiv": "2310.15386", "Date": "Mon, 23 Oct 2023 22:36:31 ", "Title": "Course Correcting Koopman Representations", "Authors": ["Mahan Fathi and Clement Gehring and Jonathan Pilault and David Kanaa and Pierre-Luc Bacon and Ross Goroshin"], "Categories": "cs.LG cs.AI cs.RO cs.SY eess.SY"}, "abstract": "Koopman representations aim to learn features of nonlinear dynamical systems (NLDS) which lead to linear dynamics in the latent space. Theoretically, such features can be used to simplify many problems in modeling and control of NLDS. In this work we study autoencoder formulations of this problem, and different ways they can be used to model dynamics, specifically for future state prediction over long horizons. We discover several limitations of predicting future states in the latent space and propose an inference-time mechanism, which we refer to as Periodic Reencoding, for faithfully capturing long term dynamics. We justify this method both analytically and empirically via experiments in low and high dimensional NLDS.", "url": "https://arxiv.org/abs/2310.15386"}, {"metadata": {"arXiv": "2310.15393", "Date": "Mon, 23 Oct 2023 22:51:58 ", "Title": "DoGE: Domain Reweighting with Generalization Estimation", "Authors": ["Simin Fan", "Matteo Pagliardini", "Martin Jaggi"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "The coverage and composition of the pretraining data corpus significantly impacts the generalization ability of large language models. Conventionally, the pretraining corpus is composed of various source domains (e.g. CommonCrawl, Wikipedia, Github etc.) according to certain sampling probabilities (domain weights). However, current methods lack a principled way to optimize domain weights for ultimate goal for generalization. We propose DOmain reweighting with Generalization Estimation (DoGE), where we reweigh the sampling probability from each domain based on its contribution to the final generalization objective assessed by a gradient-based generalization estimation function. First, we train a small-scale proxy model with a min-max optimization to obtain the reweighted domain weights. At each step, the domain weights are updated to maximize the overall generalization gain by mirror descent. Finally we use the obtained domain weights to train a larger scale full-size language model. On SlimPajama-6B dataset, with universal generalization objective, DoGE achieves better average perplexity and zero-shot reasoning accuracy. On out-of-domain generalization tasks, DoGE reduces perplexity on the target domain by a large margin. We further apply a parameter-selection scheme which improves the efficiency of generalization estimation.", "url": "https://arxiv.org/abs/2310.15393"}, {"metadata": {"arXiv": "2310.15416", "Date": "Tue, 24 Oct 2023 00:14:57 ", "Title": "Nominality Score Conditioned Time Series Anomaly Detection by Point/Sequential Reconstruction", "Authors": ["Chih-Yu Lai", "Fan-Keng Sun", "Zhengqi Gao", "Jeffrey H. Lang", "and Duane S. Boning"], "Categories": "cs.LG cs.AI", "Comments": ["NeurIPS 2023 (https://neurips.cc/virtual/2023/poster/70582)"]}, "abstract": "Time series anomaly detection is challenging due to the complexity and variety of patterns that can occur. One major difficulty arises from modeling time-dependent relationships to find contextual anomalies while maintaining detection accuracy for point anomalies. In this paper, we propose a framework for unsupervised time series anomaly detection that utilizes point-based and sequence-based reconstruction models. The point-based model attempts to quantify point anomalies, and the sequence-based model attempts to quantify both point and contextual anomalies. Under the formulation that the observed time point is a two-stage deviated value from a nominal time point, we introduce a nominality score calculated from the ratio of a combined value of the reconstruction errors. We derive an induced anomaly score by further integrating the nominality score and anomaly score, then theoretically prove the superiority of the induced anomaly score over the original anomaly score under certain conditions. Extensive studies conducted on several public datasets show that the proposed framework outperforms most state-of-the-art baselines for time series anomaly detection.", "url": "https://arxiv.org/abs/2310.15416"}, {"metadata": {"arXiv": "2310.15418", "Date": "Tue, 24 Oct 2023 00:22:19 ", "Title": "Fractal Landscapes in Policy Optimization", "Authors": ["Tao Wang", "Sylvia Herbert and Sicun Gao"], "Categories": "cs.LG cs.AI", "Comments": ["18 pages and 28 figures"]}, "abstract": "Policy gradient lies at the core of deep reinforcement learning (RL) in continuous domains. Despite much success, it is often observed in practice that RL training with policy gradient can fail for many reasons, even on standard control problems with known solutions. We propose a framework for understanding one inherent limitation of the policy gradient approach: the optimization landscape in the policy space can be extremely non-smooth or fractal for certain classes of MDPs, such that there does not exist gradient to be estimated in the first place. We draw on techniques from chaos theory and non-smooth analysis, and analyze the maximal Lyapunov exponents and H\\\"older exponents of the policy optimization objectives. Moreover, we develop a practical method that can estimate the local smoothness of objective function from samples to identify when the training process has encountered fractal landscapes. We show experiments to illustrate how some failure cases of policy optimization can be explained by such fractal landscapes.", "url": "https://arxiv.org/abs/2310.15418"}, {"metadata": {"arXiv": "2310.15468", "Date": "Tue, 24 Oct 2023 02:45:16 ", "Title": "Empowering Distributed Solutions in Renewable Energy Systems and Grid Optimization", "Authors": ["Mohammad Mohammadi and Ali Mohammadi"], "Categories": "cs.LG cs.AI cs.SY eess.SY"}, "abstract": "This study delves into the shift from centralized to decentralized approaches in the electricity industry, with a particular focus on how machine learning (ML) advancements play a crucial role in empowering renewable energy sources and improving grid management. ML models have become increasingly important in predicting renewable energy generation and consumption, utilizing various techniques like artificial neural networks, support vector machines, and decision trees. Furthermore, data preprocessing methods, such as data splitting, normalization, decomposition, and discretization, are employed to enhance prediction accuracy. The incorporation of big data and ML into smart grids offers several advantages, including heightened energy efficiency, more effective responses to demand, and better integration of renewable energy sources. Nevertheless, challenges like handling large data volumes, ensuring cybersecurity, and obtaining specialized expertise must be addressed. The research investigates various ML applications within the realms of solar energy, wind energy, and electric distribution and storage, illustrating their potential to optimize energy systems. To sum up, this research demonstrates the evolving landscape of the electricity sector as it shifts from centralized to decentralized solutions through the application of ML innovations and distributed decision-making, ultimately shaping a more efficient and sustainable energy future.", "url": "https://arxiv.org/abs/2310.15468"}, {"metadata": {"arXiv": "2310.15511", "Date": "Tue, 24 Oct 2023 04:40:38 ", "Title": "KITAB: Evaluating LLMs on Constraint Satisfaction for Information Retrieval", "Authors": ["Marah I Abdin", "Suriya Gunasekar", "Varun Chandrasekaran", "Jerry Li", "Mert Yuksekgonul", "Rahee Ghosh Peshawaria", "Ranjita Naik", "Besmira Nushi"], "Categories": "cs.LG cs.AI cs.CL cs.IR", "Comments": ["23 pages"], "ACM-class": "I.2.7"}, "abstract": "We study the ability of state-of-the art models to answer constraint satisfaction queries for information retrieval (e.g., 'a list of ice cream shops in San Diego'). In the past, such queries were considered to be tasks that could only be solved via web-search or knowledge bases. More recently, large language models (LLMs) have demonstrated initial emergent abilities in this task. However, many current retrieval benchmarks are either saturated or do not measure constraint satisfaction. Motivated by rising concerns around factual incorrectness and hallucinations of LLMs, we present KITAB, a new dataset for measuring constraint satisfaction abilities of language models. KITAB consists of book-related data across more than 600 authors and 13,000 queries, and also offers an associated dynamic data collection and constraint verification approach for acquiring similar test data for other authors. Our extended experiments on GPT4 and GPT3.5 characterize and decouple common failure modes across dimensions such as information popularity, constraint types, and context availability. Results show that in the absence of context, models exhibit severe limitations as measured by irrelevant information, factual errors, and incompleteness, many of which exacerbate as information popularity decreases. While context availability mitigates irrelevant information, it is not helpful for satisfying constraints, identifying fundamental barriers to constraint satisfaction. We open source our contributions to foster further research on improving constraint satisfaction abilities of future models.", "url": "https://arxiv.org/abs/2310.15511"}, {"metadata": {"arXiv": "2310.15523", "Date": "Tue, 24 Oct 2023 05:06:06 ", "Title": "Generative and Contrastive Paradigms Are Complementary for Graph Self-Supervised Learning", "Authors": ["Yuxiang Wang", "Xiao Yan", "Chuang Hu", "Fangcheng Fu", "Wentao Zhang", "Hao Wang", "Shuo Shang", "Jiawei Jiang"], "Categories": "cs.LG cs.AI"}, "abstract": "For graph self-supervised learning (GSSL), masked autoencoder (MAE) follows the generative paradigm and learns to reconstruct masked graph edges or node features. Contrastive Learning (CL) maximizes the similarity between augmented views of the same graph and is widely used for GSSL. However, MAE and CL are considered separately in existing works for GSSL. We observe that the MAE and CL paradigms are complementary and propose the graph contrastive masked autoencoder (GCMAE) framework to unify them. Specifically, by focusing on local edges or node features, MAE cannot capture global information of the graph and is sensitive to particular edges and features. On the contrary, CL excels in extracting global information because it considers the relation between graphs. As such, we equip GCMAE with an MAE branch and a CL branch, and the two branches share a common encoder, which allows the MAE branch to exploit the global information extracted by the CL branch. To force GCMAE to capture global graph structures, we train it to reconstruct the entire adjacency matrix instead of only the masked edges as in existing works. Moreover, a discrimination loss is proposed for feature reconstruction, which improves the disparity between node embeddings rather than reducing the reconstruction error to tackle the feature smoothing problem of MAE. We evaluate GCMAE on four popular graph tasks (i.e., node classification, node clustering, link prediction, and graph classification) and compare with 14 state-of-the-art baselines. The results show that GCMAE consistently provides good accuracy across these tasks, and the maximum accuracy improvement is up to 3.2% compared with the best-performing baseline.", "url": "https://arxiv.org/abs/2310.15523"}, {"metadata": {"arXiv": "2310.15586", "Date": "Tue, 24 Oct 2023 07:51:29 ", "Title": "Detecting Intentional AIS Shutdown in Open Sea Maritime Surveillance Using Self-Supervised Deep Learning", "Authors": ["Pierre Bernab\\'e", "Arnaud Gotlieb", "Bruno Legeard", "Dusica Marijan", "Frank Olaf Sem-Jacobsen", "Helge Spieker"], "Categories": "cs.LG cs.AI", "Comments": ["IEEE Transactions on Intelligent Transportation Systems"], "DOI": "10.1109/TITS.2023.3322690"}, "abstract": "In maritime traffic surveillance, detecting illegal activities, such as illegal fishing or transshipment of illicit products is a crucial task of the coastal administration. In the open sea, one has to rely on Automatic Identification System (AIS) message transmitted by on-board transponders, which are captured by surveillance satellites. However, insincere vessels often intentionally shut down their AIS transponders to hide illegal activities. In the open sea, it is very challenging to differentiate intentional AIS shutdowns from missing reception due to protocol limitations, bad weather conditions or restricting satellite positions. This paper presents a novel approach for the detection of abnormal AIS missing reception based on self-supervised deep learning techniques and transformer models. Using historical data, the trained model predicts if a message should be received in the upcoming minute or not. Afterwards, the model reports on detected anomalies by comparing the prediction with what actually happens. Our method can process AIS messages in real-time, in particular, more than 500 Millions AIS messages per month, corresponding to the trajectories of more than 60 000 ships. The method is evaluated on 1-year of real-world data coming from four Norwegian surveillance satellites. Using related research results, we validated our method by rediscovering already detected intentional AIS shutdowns.", "url": "https://arxiv.org/abs/2310.15586"}, {"metadata": {"arXiv": "2310.15610", "Date": "Tue, 24 Oct 2023 08:25:49 ", "Title": "Using Slisemap to interpret physical data", "Authors": ["Lauri Sepp\\\"al\\\"ainen", "Anton Bj\\\"orklund", "Vitus Besel and Kai Puolam\\\"aki"], "Categories": "cs.LG cs.AI cs.HC", "Comments": ["17 pages", "5 + 1 figures", "1 table. The datasets and source code used in the paper are available at https://www.edahelsinki.fi/papers/slisemap_phys"]}, "abstract": "Manifold visualisation techniques are commonly used to visualise high-dimensional datasets in physical sciences. In this paper we apply a recently introduced manifold visualisation method, called Slise, on datasets from physics and chemistry. Slisemap combines manifold visualisation with explainable artificial intelligence. Explainable artificial intelligence is used to investigate the decision processes of black box machine learning models and complex simulators. With Slisemap we find an embedding such that data items with similar local explanations are grouped together. Hence, Slisemap gives us an overview of the different behaviours of a black box model. This makes Slisemap into a supervised manifold visualisation method, where the patterns in the embedding reflect a target property. In this paper we show how Slisemap can be used and evaluated on physical data and that Slisemap is helpful in finding meaningful information on classification and regression models trained on these datasets.", "url": "https://arxiv.org/abs/2310.15610"}, {"metadata": {"arXiv": "2310.15719", "Date": "Tue, 24 Oct 2023 10:51:50 ", "Title": "Recurrent Linear Transformers", "Authors": ["Subhojeet Pramanik", "Esraa Elelimy", "Marlos C. Machado", "Adam White"], "Categories": "cs.LG cs.AI", "Comments": ["transformers", "reinforcement learning", "partial observability"]}, "abstract": "The self-attention mechanism in the transformer architecture is capable of capturing long-range dependencies and it is the main reason behind its effectiveness in processing sequential data. Nevertheless, despite their success, transformers have two significant drawbacks that still limit their broader applicability: (1) In order to remember past information, the self-attention mechanism requires access to the whole history to be provided as context. (2) The inference cost in transformers is expensive. In this paper we introduce recurrent alternatives to the transformer self-attention mechanism that offer a context-independent inference cost, leverage long-range dependencies effectively, and perform well in practice. We evaluate our approaches in reinforcement learning problems where the aforementioned computational limitations make the application of transformers nearly infeasible. We quantify the impact of the different components of our architecture in a diagnostic environment and assess performance gains in 2D and 3D pixel-based partially-observable environments. When compared to a state-of-the-art architecture, GTrXL, inference in our approach is at least 40% cheaper while reducing memory use in more than 50%. Our approach either performs similarly or better than GTrXL, improving more than 37% upon GTrXL performance on harder tasks.", "url": "https://arxiv.org/abs/2310.15719"}, {"metadata": {"arXiv": "2310.15793", "Date": "Tue, 24 Oct 2023 12:44:09 ", "Title": "Improving generalization in large language models by learning prefix subspaces", "Authors": ["Louis Falissard", "Vincent Guigue", "Laure Soulier"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "This article focuses on large language models (LLMs) fine-tuning in the scarce data regime (also known as the \"few-shot\" learning setting). We propose a method to increase the generalization capabilities of LLMs based on neural network subspaces. This optimization method, recently introduced in computer vision, aims to improve model generalization by identifying wider local optima through the joint optimization of an entire simplex of models in parameter space. Its adaptation to massive, pretrained transformers, however, poses some challenges. First, their considerable number of parameters makes it difficult to train several models jointly, and second, their deterministic parameter initialization schemes make them unfit for the subspace method as originally proposed. We show in this paper that \"Parameter Efficient Fine-Tuning\" (PEFT) methods, however, are perfectly compatible with this original approach, and propose to learn entire simplex of continuous prefixes. We test our method on a variant of the GLUE benchmark adapted to the few-shot learning setting, and show that both our contributions jointly lead to a gain in average performances compared to sota methods. The implementation can be found at the following link: https://github.com/Liloulou/prefix_subspace", "url": "https://arxiv.org/abs/2310.15793"}, {"metadata": {"arXiv": "2310.15817", "Date": "Tue, 24 Oct 2023 13:14:22 ", "Title": "Discriminator Guidance for Autoregressive Diffusion Models", "Authors": ["Filip Ekstr\\\"om Kelvinius", "Fredrik Lindsten"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "We introduce discriminator guidance in the setting of Autoregressive Diffusion Models. The use of a discriminator to guide a diffusion process has previously been used for continuous diffusion models, and in this work we derive ways of using a discriminator together with a pretrained generative model in the discrete case. First, we show that using an optimal discriminator will correct the pretrained model and enable exact sampling from the underlying data distribution. Second, to account for the realistic scenario of using a sub-optimal discriminator, we derive a sequential Monte Carlo algorithm which iteratively takes the predictions from the discrimiator into account during the generation process. We test these approaches on the task of generating molecular graphs and show how the discriminator improves the generative performance over using only the pretrained model.", "url": "https://arxiv.org/abs/2310.15817"}, {"metadata": {"arXiv": "2310.15872", "Date": "Tue, 24 Oct 2023 14:28:00 ", "Title": "KirchhoffNet: A Circuit Bridging Message Passing and Continuous-Depth Models", "Authors": ["Zhengqi Gao", "Fan-Keng Sun", "Duane S. Boning"], "Categories": "cs.LG cs.AI cs.AR", "Comments": ["4 pages", "3 figures"]}, "abstract": "In this paper, we exploit a fundamental principle of analog electronic circuitry, Kirchhoff's current law, to introduce a unique class of neural network models that we refer to as KirchhoffNet. KirchhoffNet establishes close connections with message passing neural networks and continuous-depth networks. We demonstrate that even in the absence of any traditional layers (such as convolution, pooling, or linear layers), KirchhoffNet attains 98.86% test accuracy on the MNIST dataset, comparable with state of the art (SOTA) results. What makes KirchhoffNet more intriguing is its potential in the realm of hardware. Contemporary deep neural networks are conventionally deployed on GPUs. In contrast, KirchhoffNet can be physically realized by an analog electronic circuit. Moreover, we justify that irrespective of the number of parameters within a KirchhoffNet, its forward calculation can always be completed within 1/f seconds, with f representing the hardware's clock frequency. This characteristic introduces a promising technology for implementing ultra-large-scale neural networks.", "url": "https://arxiv.org/abs/2310.15872"}, {"metadata": {"arXiv": "2310.15929", "Date": "Tue, 24 Oct 2023 15:27:15 ", "Title": "E-Sparse: Boosting the Large Language Model Inference through Entropy-based N:M Sparsity", "Authors": ["Yun Li", "Lin Niu", "Xipeng Zhang", "Kai Liu", "Jianchen Zhu", "Zhanhui Kang"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "Traditional pruning methods are known to be challenging to work in Large Language Models (LLMs) for Generative AI because of their unaffordable training process and large computational demands. For the first time, we introduce the information entropy of hidden state features into a pruning metric design, namely E-Sparse, to improve the accuracy of N:M sparsity on LLM. E-Sparse employs the information richness to leverage the channel importance, and further incorporates several novel techniques to put it into effect: (1) it introduces information entropy to enhance the significance of parameter weights and input feature norms as a novel pruning metric, and performs N:M sparsity without modifying the remaining weights. (2) it designs global naive shuffle and local block shuffle to quickly optimize the information distribution and adequately cope with the impact of N:M sparsity on LLMs' accuracy. E-Sparse is implemented as a Sparse-GEMM on FasterTransformer and runs on NVIDIA Ampere GPUs. Extensive experiments on the LLaMA family and OPT models show that E-Sparse can significantly speed up the model inference over the dense model (up to 1.53X) and obtain significant memory saving (up to 43.52%), with acceptable accuracy loss.", "url": "https://arxiv.org/abs/2310.15929"}, {"metadata": {"arXiv": "2310.15978", "Date": "Tue, 24 Oct 2023 16:26:38 ", "Title": "Graph Deep Learning for Time Series Forecasting", "Authors": ["Andrea Cini", "Ivan Marisca", "Daniele Zambon", "Cesare Alippi"], "Categories": "cs.LG cs.AI"}, "abstract": "Graph-based deep learning methods have become popular tools to process collections of correlated time series. Differently from traditional multivariate forecasting methods, neural graph-based predictors take advantage of pairwise relationships by conditioning forecasts on a (possibly dynamic) graph spanning the time series collection. The conditioning can take the form of an architectural inductive bias on the neural forecasting architecture, resulting in a family of deep learning models called spatiotemporal graph neural networks. Such relational inductive biases enable the training of global forecasting models on large time-series collections, while at the same time localizing predictions w.r.t. each element in the set (i.e., graph nodes) by accounting for local correlations among them (i.e., graph edges). Indeed, recent theoretical and practical advances in graph neural networks and deep learning for time series forecasting make the adoption of such processing frameworks appealing and timely. However, most of the studies in the literature focus on proposing variations of existing neural architectures by taking advantage of modern deep learning practices, while foundational and methodological aspects have not been subject to systematic investigation. To fill the gap, this paper aims to introduce a comprehensive methodological framework that formalizes the forecasting problem and provides design principles for graph-based predictive models and methods to assess their performance. At the same time, together with an overview of the field, we provide design guidelines, recommendations, and best practices, as well as an in-depth discussion of open challenges and future research directions.", "url": "https://arxiv.org/abs/2310.15978"}, {"metadata": {"arXiv": "2310.16028", "Date": "Tue, 24 Oct 2023 17:43:29 ", "Title": "What Algorithms can Transformers Learn? A Study in Length Generalization", "Authors": ["Hattie Zhou", "Arwen Bradley", "Etai Littwin", "Noam Razin", "Omid Saremi", "Josh Susskind", "Samy Bengio", "Preetum Nakkiran"], "Categories": "cs.LG cs.AI cs.CL stat.ML", "Comments": ["Preprint"]}, "abstract": "Large language models exhibit surprising emergent generalization properties, yet also struggle on many simple reasoning tasks such as arithmetic and parity. This raises the question of if and when Transformer models can learn the true algorithm for solving a task. We study the scope of Transformers' abilities in the specific setting of length generalization on algorithmic tasks. Here, we propose a unifying framework to understand when and how Transformers can exhibit strong length generalization on a given task. Specifically, we leverage RASP (Weiss et al., 2021) -- a programming language designed for the computational model of a Transformer -- and introduce the RASP-Generalization Conjecture: Transformers tend to length generalize on a task if the task can be solved by a short RASP program which works for all input lengths. This simple conjecture remarkably captures most known instances of length generalization on algorithmic tasks. Moreover, we leverage our insights to drastically improve generalization performance on traditionally hard tasks (such as parity and addition). On the theoretical side, we give a simple example where the \"min-degree-interpolator\" model of learning from Abbe et al. (2023) does not correctly predict Transformers' out-of-distribution behavior, but our conjecture does. Overall, our work provides a novel perspective on the mechanisms of compositional generalization and the algorithmic capabilities of Transformers.", "url": "https://arxiv.org/abs/2310.16028"}, {"metadata": {"arXiv": "2310.16029", "Date": "Tue, 24 Oct 2023 17:46:12 ", "Title": "Finetuning Offline World Models in the Real World", "Authors": ["Yunhai Feng", "Nicklas Hansen", "Ziyan Xiong", "Chandramouli Rajagopalan", "Xiaolong Wang"], "Categories": "cs.LG cs.AI cs.CV cs.RO", "Comments": ["CoRL 2023 Oral; Project website: https://yunhaifeng.com/FOWM"]}, "abstract": "Reinforcement Learning (RL) is notoriously data-inefficient, which makes training on a real robot difficult. While model-based RL algorithms (world models) improve data-efficiency to some extent, they still require hours or days of interaction to learn skills. Recently, offline RL has been proposed as a framework for training RL policies on pre-existing datasets without any online interaction. However, constraining an algorithm to a fixed dataset induces a state-action distribution shift between training and inference, and limits its applicability to new tasks. In this work, we seek to get the best of both worlds: we consider the problem of pretraining a world model with offline data collected on a real robot, and then finetuning the model on online data collected by planning with the learned model. To mitigate extrapolation errors during online interaction, we propose to regularize the planner at test-time by balancing estimated returns and (epistemic) model uncertainty. We evaluate our method on a variety of visuo-motor control tasks in simulation and on a real robot, and find that our method enables few-shot finetuning to seen and unseen tasks even when offline data is limited. Videos, code, and data are available at https://yunhaifeng.com/FOWM .", "url": "https://arxiv.org/abs/2310.16029"}, {"metadata": {"arXiv": "2310.15605", "Date": "Tue, 24 Oct 2023 08:17:48 ", "Title": "tagE: Enabling an Embodied Agent to Understand Human Instructions", "Authors": ["Chayan Sarkar and Avik Mitra and Pradip Pramanick and Tapas Nayak"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["Accepted in EMNLP Findings 2023"]}, "abstract": "Natural language serves as the primary mode of communication when an intelligent agent with a physical presence engages with human beings. While a plethora of research focuses on natural language understanding (NLU), encompassing endeavors such as sentiment analysis, intent prediction, question answering, and summarization, the scope of NLU directed at situations necessitating tangible actions by an embodied agent remains limited. The inherent ambiguity and incompleteness inherent in natural language present challenges for intelligent agents striving to decipher human intention. To tackle this predicament head-on, we introduce a novel system known as task and argument grounding for Embodied agents (tagE). At its core, our system employs an inventive neural network model designed to extract a series of tasks from complex task instructions expressed in natural language. Our proposed model adopts an encoder-decoder framework enriched with nested decoding to effectively extract tasks and their corresponding arguments from these intricate instructions. These extracted tasks are then mapped (or grounded) to the robot's established collection of skills, while the arguments find grounding in objects present within the environment. To facilitate the training and evaluation of our system, we have curated a dataset featuring complex instructions. The results of our experiments underscore the prowess of our approach, as it outperforms robust baseline models.", "url": "https://arxiv.org/abs/2310.15605"}, {"metadata": {"arXiv": "2310.16014", "Date": "Tue, 24 Oct 2023 17:15:16 ", "Title": "Human-in-the-Loop Task and Motion Planning for Imitation Learning", "Authors": ["Ajay Mandlekar", "Caelan Garrett", "Danfei Xu", "Dieter Fox"], "Categories": "cs.RO cs.AI cs.CV cs.LG", "Comments": ["Conference on Robot Learning (CoRL) 2023"]}, "abstract": "Imitation learning from human demonstrations can teach robots complex manipulation skills, but is time-consuming and labor intensive. In contrast, Task and Motion Planning (TAMP) systems are automated and excel at solving long-horizon tasks, but they are difficult to apply to contact-rich tasks. In this paper, we present Human-in-the-Loop Task and Motion Planning (HITL-TAMP), a novel system that leverages the benefits of both approaches. The system employs a TAMP-gated control mechanism, which selectively gives and takes control to and from a human teleoperator. This enables the human teleoperator to manage a fleet of robots, maximizing data collection efficiency. The collected human data is then combined with an imitation learning framework to train a TAMP-gated policy, leading to superior performance compared to training on full task demonstrations. We compared HITL-TAMP to a conventional teleoperation system -- users gathered more than 3x the number of demos given the same time budget. Furthermore, proficient agents (75\\%+ success) could be trained from just 10 minutes of non-expert teleoperation data. Finally, we collected 2.1K demos with HITL-TAMP across 12 contact-rich, long-horizon tasks and show that the system often produces near-perfect agents. Videos and additional results at https://hitltamp.github.io .", "url": "https://arxiv.org/abs/2310.16014"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

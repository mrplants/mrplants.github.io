<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2311.10572", "Date": "Fri, 17 Nov 2023 15:14:40 ", "Title": "SSB: Simple but Strong Baseline for Boosting Performance of Open-Set Semi-Supervised Learning", "Authors": ["Yue Fan", "Anna Kukleva", "Dengxin Dai", "Bernt Schiele"], "Categories": "cs.CV cs.LG", "Comments": ["Paper accepted in ICCV 2023"]}, "abstract": "Semi-supervised learning (SSL) methods effectively leverage unlabeled data to improve model generalization. However, SSL models often underperform in open-set scenarios, where unlabeled data contain outliers from novel categories that do not appear in the labeled set. In this paper, we study the challenging and realistic open-set SSL setting, where the goal is to both correctly classify inliers and to detect outliers. Intuitively, the inlier classifier should be trained on inlier data only. However, we find that inlier classification performance can be largely improved by incorporating high-confidence pseudo-labeled data, regardless of whether they are inliers or outliers. Also, we propose to utilize non-linear transformations to separate the features used for inlier classification and outlier detection in the multi-task learning framework, preventing adverse effects between them. Additionally, we introduce pseudo-negative mining, which further boosts outlier detection performance. The three ingredients lead to what we call Simple but Strong Baseline (SSB) for open-set SSL. In experiments, SSB greatly improves both inlier classification and outlier detection performance, outperforming existing methods by a large margin. Our code will be released at https://github.com/YUE-FAN/SSB.", "url": "https://arxiv.org/abs/2311.10572"}, {"metadata": {"arXiv": "2311.10648", "Date": "Fri, 17 Nov 2023 17:06:59 ", "Title": "Self-trained Panoptic Segmentation", "Authors": ["Shourya Verma"], "Categories": "cs.CV cs.LG"}, "abstract": "Panoptic segmentation is an important computer vision task which combines semantic and instance segmentation. It plays a crucial role in domains of medical image analysis, self-driving vehicles, and robotics by providing a comprehensive understanding of visual environments. Traditionally, deep learning panoptic segmentation models have relied on dense and accurately annotated training data, which is expensive and time consuming to obtain. Recent advancements in self-supervised learning approaches have shown great potential in leveraging synthetic and unlabelled data to generate pseudo-labels using self-training to improve the performance of instance and semantic segmentation models. The three available methods for self-supervised panoptic segmentation use proposal-based transformer architectures which are computationally expensive, complicated and engineered for specific tasks. The aim of this work is to develop a framework to perform embedding-based self-supervised panoptic segmentation using self-training in a synthetic-to-real domain adaptation problem setting.", "url": "https://arxiv.org/abs/2311.10648"}, {"metadata": {"arXiv": "2311.10701", "Date": "Fri, 17 Nov 2023 18:45:00 ", "Title": "SpACNN-LDVAE: Spatial Attention Convolutional Latent Dirichlet Variational Autoencoder for Hyperspectral Pixel Unmixing", "Authors": ["Soham Chitnis", "Kiran Mantripragada", "Faisal Z. Qureshi"], "Categories": "cs.CV cs.LG eess.IV"}, "abstract": "The Hyperspectral Unxming problem is to find the pure spectral signal of the underlying materials (endmembers) and their proportions (abundances). The proposed method builds upon the recently proposed method, Latent Dirichlet Variational Autoencoder (LDVAE). It assumes that abundances can be encoded as Dirichlet Distributions while mixed pixels and endmembers are represented by Multivariate Normal Distributions. However, LDVAE does not leverage spatial information present in an HSI; we propose an Isotropic CNN encoder with spatial attention to solve the hyperspectral unmixing problem. We evaluated our model on Samson, Hydice Urban, Cuprite, and OnTech-HSI-Syn-21 datasets. Our model also leverages the transfer learning paradigm for Cuprite Dataset, where we train the model on synthetic data and evaluate it on real-world data. We are able to observe the improvement in the results for the endmember extraction and abundance estimation by incorporating the spatial information. Code can be found at https://github.com/faisalqureshi/cnn-ldvae", "url": "https://arxiv.org/abs/2311.10701"}, {"metadata": {"arXiv": "2311.10708", "Date": "Fri, 17 Nov 2023 18:58:16 ", "Title": "SelfEval: Leveraging the discriminative nature of generative models for evaluation", "Authors": ["Sai Saketh Rambhatla", "Ishan Misra"], "Categories": "cs.CV cs.LG"}, "abstract": "In this work, we show that text-to-image generative models can be 'inverted' to assess their own text-image understanding capabilities in a completely automated manner. Our method, called SelfEval, uses the generative model to compute the likelihood of real images given text prompts, making the generative model directly applicable to discriminative tasks. Using SelfEval, we repurpose standard datasets created for evaluating multimodal text-image discriminative models to evaluate generative models in a fine-grained manner: assessing their performance on attribute binding, color recognition, counting, shape recognition, spatial understanding. To the best of our knowledge SelfEval is the first automated metric to show a high degree of agreement for measuring text-faithfulness with the gold-standard human evaluations across multiple models and benchmarks. Moreover, SelfEval enables us to evaluate generative models on challenging tasks such as Winoground image-score where they demonstrate competitive performance to discriminative models. We also show severe drawbacks of standard automated metrics such as CLIP-score to measure text faithfulness on benchmarks such as DrawBench, and how SelfEval sidesteps these issues. We hope SelfEval enables easy and reliable automated evaluation for diffusion models.", "url": "https://arxiv.org/abs/2311.10708"}, {"metadata": {"arXiv": "2311.10156", "Date": "Thu, 16 Nov 2023 19:24:20 ", "Title": "Algebraic Topological Networks via the Persistent Local Homology Sheaf", "Authors": ["Gabriele Cesa", "Arash Behboodi"], "Categories": "cs.LG math.AT", "Comments": ["Symmetry and Geometry in Neural Representations - NeurReps Workshop @ NeurIPS 2023"]}, "abstract": "In this work, we introduce a novel approach based on algebraic topology to enhance graph convolution and attention modules by incorporating local topological properties of the data. To do so, we consider the framework of sheaf neural networks, which has been previously leveraged to incorporate additional structure into graph neural networks' features and construct more expressive, non-isotropic messages. Specifically, given an input simplicial complex (e.g. generated by the cliques of a graph or the neighbors in a point cloud), we construct its local homology sheaf, which assigns to each node the vector space of its local homology. The intermediate features of our networks live in these vector spaces and we leverage the associated sheaf Laplacian to construct more complex linear messages between them. Moreover, we extend this approach by considering the persistent version of local homology associated with a weighted simplicial complex (e.g., built from pairwise distances of nodes embeddings). This i) solves the problem of the lack of a natural choice of basis for the local homology vector spaces and ii) makes the sheaf itself differentiable, which enables our models to directly optimize the topology of their intermediate features.", "url": "https://arxiv.org/abs/2311.10156"}, {"metadata": {"arXiv": "2311.10170", "Date": "Thu, 16 Nov 2023 19:53:35 ", "Title": "Improving Unimodal Inference with Multimodal Transformers", "Authors": ["Kateryna Chumachenko", "Alexandros Iosifidis", "Moncef Gabbouj"], "Categories": "cs.LG"}, "abstract": "This paper proposes an approach for improving performance of unimodal models with multimodal training. Our approach involves a multi-branch architecture that incorporates unimodal models with a multimodal transformer-based branch. By co-training these branches, the stronger multimodal branch can transfer its knowledge to the weaker unimodal branches through a multi-task objective, thereby improving the performance of the resulting unimodal models. We evaluate our approach on tasks of dynamic hand gesture recognition based on RGB and Depth, audiovisual emotion recognition based on speech and facial video, and audio-video-text based sentiment analysis. Our approach outperforms the conventionally trained unimodal counterparts. Interestingly, we also observe that optimization of the unimodal branches improves the multimodal branch, compared to a similar multimodal model trained from scratch.", "url": "https://arxiv.org/abs/2311.10170"}, {"metadata": {"arXiv": "2311.10203", "Date": "Thu, 16 Nov 2023 21:22:47 ", "Title": "Adaptive Optimization Algorithms for Machine Learning", "Authors": ["Slavom\\'ir Hanzely"], "Categories": "cs.LG math.OC", "Comments": ["Dissertation thesis"]}, "abstract": "Machine learning assumes a pivotal role in our data-driven world. The increasing scale of models and datasets necessitates quick and reliable algorithms for model training. This dissertation investigates adaptivity in machine learning optimizers. The ensuing chapters are dedicated to various facets of adaptivity, including: 1. personalization and user-specific models via personalized loss, 2. provable post-training model adaptations via meta-learning, 3. learning unknown hyperparameters in real time via hyperparameter variance reduction, 4. fast O(1/k^2) global convergence of second-order methods via stepsized Newton method regardless of the initialization and choice basis, 5. fast and scalable second-order methods via low-dimensional updates. This thesis contributes novel insights, introduces new algorithms with improved convergence guarantees, and improves analyses of popular practical algorithms.", "url": "https://arxiv.org/abs/2311.10203"}, {"metadata": {"arXiv": "2311.10223", "Date": "Thu, 16 Nov 2023 22:28:38 ", "Title": "Asymptotically Fair Participation in Machine Learning Models: an Optimal Control Perspective", "Authors": ["Zhuotong Chen and Qianxiao Li and Zheng Zhang"], "Categories": "cs.LG", "Comments": ["34 pages"]}, "abstract": "The performance of state-of-the-art machine learning models often deteriorates when testing on demographics that are under-represented in the training dataset. This problem has predominately been studied in a supervised learning setting where the data distribution is static. However, real-world applications often involve distribution shifts caused by the deployed models. For instance, the performance disparity against monitory users can lead to a high customer churn rate, thus the available data provided by active users are skewed due to the lack of minority users. This feedback effect further exacerbates the disparity among different demographic groups in future steps. To address this issue, we propose asymptotically fair participation as a condition to maintain long-term model performance over all demographic groups. In this work, we aim to address the problem of achieving asymptotically fair participation via optimal control formulation. Moreover, we design a surrogate retention system based on existing literature on evolutionary population dynamics to approximate the dynamics of distribution shifts on active user counts, from which the objective of achieving asymptotically fair participation is formulated as an optimal control problem, and the control variables are considered as the model parameters. We apply an efficient implementation of Pontryagin's maximum principle to estimate the optimal control solution. To evaluate the effectiveness of the proposed method, we design a generic simulation environment that simulates the population dynamics of the feedback effect between user retention and model performance. When we deploy the resulting models to the simulation environment, the optimal control solution accounts for long-term planning and leads to superior performance compared with existing baseline methods.", "url": "https://arxiv.org/abs/2311.10223"}, {"metadata": {"arXiv": "2311.10255", "Date": "Fri, 17 Nov 2023 00:53:09 ", "Title": "FREE: The Foundational Semantic Recognition for Modeling Environmental Ecosystems", "Authors": ["Shiyuan Luo", "Juntong Ni", "Shengyu Chen", "Runlong Yu", "Yiqun Xie", "Licheng Liu", "Zhenong Jin", "Huaxiu Yao", "Xiaowei Jia"], "Categories": "cs.LG q-bio.PE"}, "abstract": "Modeling environmental ecosystems is critical for the sustainability of our planet, but is extremely challenging due to the complex underlying processes driven by interactions amongst a large number of physical variables. As many variables are difficult to measure at large scales, existing works often utilize a combination of observable features and locally available measurements or modeled values as input to build models for a specific study region and time period. This raises a fundamental question in advancing the modeling of environmental ecosystems: how to build a general framework for modeling the complex relationships amongst various environmental data over space and time? In this paper, we introduce a new framework, FREE, which maps available environmental data into a text space and then converts the traditional predictive modeling task in environmental science to the semantic recognition problem. The proposed FREE framework leverages recent advances in Large Language Models (LLMs) to supplement the original input features with natural language descriptions. This facilitates capturing the data semantics and also allows harnessing the irregularities of input features. When used for long-term prediction, FREE has the flexibility to incorporate newly collected observations to enhance future prediction. The efficacy of FREE is evaluated in the context of two societally important real-world applications, predicting stream water temperature in the Delaware River Basin and predicting annual corn yield in Illinois and Iowa. Beyond the superior predictive performance over multiple baseline methods, FREE is shown to be more data- and computation-efficient as it can be pre-trained on simulated data generated by physics-based models.", "url": "https://arxiv.org/abs/2311.10255"}, {"metadata": {"arXiv": "2311.10263", "Date": "Fri, 17 Nov 2023 01:14:24 ", "Title": "Stable Differentiable Causal Discovery", "Authors": ["Achille Nazaret", "Justin Hong", "Elham Azizi", "David Blei"], "Categories": "cs.LG stat.ME"}, "abstract": "Inferring causal relationships as directed acyclic graphs (DAGs) is an important but challenging problem. Differentiable Causal Discovery (DCD) is a promising approach to this problem, framing the search as a continuous optimization. But existing DCD methods are numerically unstable, with poor performance beyond tens of variables. In this paper, we propose Stable Differentiable Causal Discovery (SDCD), a new method that improves previous DCD methods in two ways: (1) It employs an alternative constraint for acyclicity; this constraint is more stable, both theoretically and empirically, and fast to compute. (2) It uses a training procedure tailored for sparse causal graphs, which are common in real-world scenarios. We first derive SDCD and prove its stability and correctness. We then evaluate it with both observational and interventional data and on both small-scale and large-scale settings. We find that SDCD outperforms existing methods in both convergence speed and accuracy and can scale to thousands of variables.", "url": "https://arxiv.org/abs/2311.10263"}, {"metadata": {"arXiv": "2311.10270", "Date": "Fri, 17 Nov 2023 01:30:43 ", "Title": "Multiscale Hodge Scattering Networks for Data Analysis", "Authors": ["Naoki Saito and Stefan C. Schonsheck and Eugene Shvarts"], "Categories": "cs.LG cs.NA cs.SI eess.SP math.NA stat.ML", "Comments": ["20 Pages", "Comments Welcome"]}, "abstract": "We propose new scattering networks for signals measured on simplicial complexes, which we call \\emph{Multiscale Hodge Scattering Networks} (MHSNs). Our construction is based on multiscale basis dictionaries on simplicial complexes, i.e., the $\\kappa$-GHWT and $\\kappa$-HGLET, which we recently developed for simplices of dimension $\\kappa \\in \\N$ in a given simplicial complex by generalizing the node-based Generalized Haar-Walsh Transform (GHWT) and Hierarchical Graph Laplacian Eigen Transform (HGLET). The $\\kappa$-GHWT and the $\\kk$-HGLET both form redundant sets (i.e., dictionaries) of multiscale basis vectors and the corresponding expansion coefficients of a given signal. Our MHSNs use a layered structure analogous to a convolutional neural network (CNN) to cascade the moments of the modulus of the dictionary coefficients. The resulting features are invariant to reordering of the simplices (i.e., node permutation of the underlying graphs). Importantly, the use of multiscale basis dictionaries in our MHSNs admits a natural pooling operation that is akin to local pooling in CNNs, and which may be performed either locally or per-scale. These pooling operations are harder to define in both traditional scattering networks based on Morlet wavelets, and geometric scattering networks based on Diffusion Wavelets. As a result, we are able to extract a rich set of descriptive yet robust features that can be used along with very simple machine learning methods (i.e., logistic regression or support vector machines) to achieve high-accuracy classification systems with far fewer parameters to train than most modern graph neural networks. Finally, we demonstrate the usefulness of our MHSNs in three distinct types of problems: signal classification, domain (i.e., graph/simplex) classification, and molecular dynamics prediction.", "url": "https://arxiv.org/abs/2311.10270"}, {"metadata": {"arXiv": "2311.10277", "Date": "Fri, 17 Nov 2023 01:48:07 ", "Title": "Sobol Sequence Optimization for Hardware-Efficient Vector Symbolic Architectures", "Authors": ["Sercan Aygun", "M. Hassan Najafi"], "Categories": "cs.LG cs.ET", "Comments": ["9 pages", "7 figures"]}, "abstract": "Hyperdimensional computing (HDC) is an emerging computing paradigm with significant promise for efficient and robust learning. In HDC, objects are encoded with high-dimensional vector symbolic sequences called hypervectors. The quality of hypervectors, defined by their distribution and independence, directly impacts the performance of HDC systems. Despite a large body of work on the processing parts of HDC systems, little to no attention has been paid to data encoding and the quality of hypervectors. Most prior studies have generated hypervectors using inherent random functions, such as MATLAB`s or Python`s random function. This work introduces an optimization technique for generating hypervectors by employing quasi-random sequences. These sequences have recently demonstrated their effectiveness in achieving accurate and low-discrepancy data encoding in stochastic computing systems. The study outlines the optimization steps for utilizing Sobol sequences to produce high-quality hypervectors in HDC systems. An optimization algorithm is proposed to select the most suitable Sobol sequences for generating minimally correlated hypervectors, particularly in applications related to symbol-oriented architectures. The performance of the proposed technique is evaluated in comparison to two traditional approaches of generating hypervectors based on linear-feedback shift registers and MATLAB random function. The evaluation is conducted for two applications: (i) language and (ii) headline classification. Our experimental results demonstrate accuracy improvements of up to 10.79%, depending on the vector size. Additionally, the proposed encoding hardware exhibits reduced energy consumption and a superior area-delay product.", "url": "https://arxiv.org/abs/2311.10277"}, {"metadata": {"arXiv": "2311.10291", "Date": "Fri, 17 Nov 2023 02:37:10 ", "Title": "Leveraging Function Space Aggregation for Federated Learning at Scale", "Authors": ["Nikita Dhawan", "Nicole Mitchell", "Zachary Charles", "Zachary Garrett", "Gintare Karolina Dziugaite"], "Categories": "cs.LG", "Comments": ["20 pages", "7 figures"]}, "abstract": "The federated learning paradigm has motivated the development of methods for aggregating multiple client updates into a global server model, without sharing client data. Many federated learning algorithms, including the canonical Federated Averaging (FedAvg), take a direct (possibly weighted) average of the client parameter updates, motivated by results in distributed optimization. In this work, we adopt a function space perspective and propose a new algorithm, FedFish, that aggregates local approximations to the functions learned by clients, using an estimate based on their Fisher information. We evaluate FedFish on realistic, large-scale cross-device benchmarks. While the performance of FedAvg can suffer as client models drift further apart, we demonstrate that FedFish is more robust to longer local training. Our evaluation across several settings in image and language benchmarks shows that FedFish outperforms FedAvg as local training epochs increase. Further, FedFish results in global networks that are more amenable to efficient personalization via local fine-tuning on the same or shifted data distributions. For instance, federated pretraining on the C4 dataset, followed by few-shot personalization on Stack Overflow, results in a 7% improvement in next-token prediction by FedFish over FedAvg.", "url": "https://arxiv.org/abs/2311.10291"}, {"metadata": {"arXiv": "2311.10293", "Date": "Fri, 17 Nov 2023 02:48:20 ", "Title": "Hierarchical Pruning of Deep Ensembles with Focal Diversity", "Authors": ["Yanzhao Wu", "Ka-Ho Chow", "Wenqi Wei", "Ling Liu"], "Categories": "cs.LG cs.CV", "Comments": ["To appear on ACM Transactions on Intelligent Systems and Technology"], "DOI": "10.1145/3633286"}, "abstract": "Deep neural network ensembles combine the wisdom of multiple deep neural networks to improve the generalizability and robustness over individual networks. It has gained increasing popularity to study deep ensemble techniques in the deep learning community. Some mission-critical applications utilize a large number of deep neural networks to form deep ensembles to achieve desired accuracy and resilience, which introduces high time and space costs for ensemble execution. However, it still remains a critical challenge whether a small subset of the entire deep ensemble can achieve the same or better generalizability and how to effectively identify these small deep ensembles for improving the space and time efficiency of ensemble execution. This paper presents a novel deep ensemble pruning approach, which can efficiently identify smaller deep ensembles and provide higher ensemble accuracy than the entire deep ensemble of a large number of member networks. Our hierarchical ensemble pruning approach (HQ) leverages three novel ensemble pruning techniques. First, we show that the focal diversity metrics can accurately capture the complementary capacity of the member networks of an ensemble, which can guide ensemble pruning. Second, we design a focal diversity based hierarchical pruning approach, which will iteratively find high quality deep ensembles with low cost and high accuracy. Third, we develop a focal diversity consensus method to integrate multiple focal diversity metrics to refine ensemble pruning results, where smaller deep ensembles can be effectively identified to offer high accuracy, high robustness and high efficiency. Evaluated using popular benchmark datasets, we demonstrate that the proposed hierarchical ensemble pruning approach can effectively identify high quality deep ensembles with better generalizability while being more time and space efficient in ensemble decision making.", "url": "https://arxiv.org/abs/2311.10293"}, {"metadata": {"arXiv": "2311.10309", "Date": "Fri, 17 Nov 2023 03:41:22 ", "Title": "Imagination-augmented Hierarchical Reinforcement Learning for Safe and Interactive Autonomous Driving in Urban Environments", "Authors": ["Sang-Hyun Lee", "Yoonjae Jung", "Seung-Woo Seo"], "Categories": "cs.LG cs.RO", "Comments": ["11 pages", "8 figures"]}, "abstract": "Hierarchical reinforcement learning (HRL) has led to remarkable achievements in diverse fields. However, existing HRL algorithms still cannot be applied to real-world navigation tasks. These tasks require an agent to perform safety-aware behaviors and interact with surrounding objects in dynamic environments. In addition, an agent in these tasks should perform consistent and structured exploration as they are long-horizon and have complex structures with diverse objects and task-specific rules. Designing HRL agents that can handle these challenges in real-world navigation tasks is an open problem. In this paper, we propose imagination-augmented HRL (IAHRL), a new and general navigation algorithm that allows an agent to learn safe and interactive behaviors in real-world navigation tasks. Our key idea is to train a hierarchical agent in which a high-level policy infers interactions by interpreting behaviors imagined with low-level policies. Specifically, the high-level policy is designed with a permutation-invariant attention mechanism to determine which low-level policy generates the most interactive behavior, and the low-level policies are implemented with an optimization-based behavior planner to generate safe and structured behaviors following task-specific rules. To evaluate our algorithm, we introduce five complex urban driving tasks, which are among the most challenging real-world navigation tasks. The experimental results indicate that our hierarchical agent performs safety-aware behaviors and properly interacts with surrounding vehicles, achieving higher success rates and lower average episode steps than baselines in urban driving tasks.", "url": "https://arxiv.org/abs/2311.10309"}, {"metadata": {"arXiv": "2311.10316", "Date": "Fri, 17 Nov 2023 03:59:50 ", "Title": "Graph Sparsifications using Neural Network Assisted Monte Carlo Tree Search", "Authors": ["Alvin Chiu", "Mithun Ghosh", "Reyan Ahmed", "Kwang-Sung Jun", "Stephen Kobourov", "Michael T. Goodrich"], "Categories": "cs.LG", "Comments": ["arXiv admin note: substantial text overlap with arXiv:2305.00535"]}, "abstract": "Graph neural networks have been successful for machine learning, as well as for combinatorial and graph problems such as the Subgraph Isomorphism Problem and the Traveling Salesman Problem. We describe an approach for computing graph sparsifiers by combining a graph neural network and Monte Carlo Tree Search. We first train a graph neural network that takes as input a partial solution and proposes a new node to be added as output. This neural network is then used in a Monte Carlo search to compute a sparsifier. The proposed method consistently outperforms several standard approximation algorithms on different types of graphs and often finds the optimal solution.", "url": "https://arxiv.org/abs/2311.10316"}, {"metadata": {"arXiv": "2311.10318", "Date": "Fri, 17 Nov 2023 04:04:11 ", "Title": "Nonparametric Teaching for Multiple Learners", "Authors": ["Chen Zhang", "Xiaofeng Cao", "Weiyang Liu", "Ivor Tsang", "James Kwok"], "Categories": "cs.LG cs.CV", "Comments": ["NeurIPS 2023 (31 pages", "20 figures)"]}, "abstract": "We study the problem of teaching multiple learners simultaneously in the nonparametric iterative teaching setting, where the teacher iteratively provides examples to the learner for accelerating the acquisition of a target concept. This problem is motivated by the gap between current single-learner teaching setting and the real-world scenario of human instruction where a teacher typically imparts knowledge to multiple students. Under the new problem formulation, we introduce a novel framework -- Multi-learner Nonparametric Teaching (MINT). In MINT, the teacher aims to instruct multiple learners, with each learner focusing on learning a scalar-valued target model. To achieve this, we frame the problem as teaching a vector-valued target model and extend the target model space from a scalar-valued reproducing kernel Hilbert space used in single-learner scenarios to a vector-valued space. Furthermore, we demonstrate that MINT offers significant teaching speed-up over repeated single-learner teaching, particularly when the multiple learners can communicate with each other. Lastly, we conduct extensive experiments to validate the practicality and efficiency of MINT.", "url": "https://arxiv.org/abs/2311.10318"}, {"metadata": {"arXiv": "2311.10370", "Date": "Fri, 17 Nov 2023 07:49:20 ", "Title": "Few-shot Message-Enhanced Contrastive Learning for Graph Anomaly Detection", "Authors": ["Fan Xu", "Nan Wang", "Xuezhi Wen", "Meiqi Gao", "Chaoqun Guo", "Xibin Zhao"], "Categories": "cs.LG"}, "abstract": "Graph anomaly detection plays a crucial role in identifying exceptional instances in graph data that deviate significantly from the majority. It has gained substantial attention in various domains of information security, including network intrusion, financial fraud, and malicious comments, et al. Existing methods are primarily developed in an unsupervised manner due to the challenge in obtaining labeled data. For lack of guidance from prior knowledge in unsupervised manner, the identified anomalies may prove to be data noise or individual data instances. In real-world scenarios, a limited batch of labeled anomalies can be captured, making it crucial to investigate the few-shot problem in graph anomaly detection. Taking advantage of this potential, we propose a novel few-shot Graph Anomaly Detection model called FMGAD (Few-shot Message-Enhanced Contrastive-based Graph Anomaly Detector). FMGAD leverages a self-supervised contrastive learning strategy within and across views to capture intrinsic and transferable structural representations. Furthermore, we propose the Deep-GNN message-enhanced reconstruction module, which extensively exploits the few-shot label information and enables long-range propagation to disseminate supervision signals to deeper unlabeled nodes. This module in turn assists in the training of self-supervised contrastive learning. Comprehensive experimental results on six real-world datasets demonstrate that FMGAD can achieve better performance than other state-of-the-art methods, regardless of artificially injected anomalies or domain-organic anomalies.", "url": "https://arxiv.org/abs/2311.10370"}, {"metadata": {"arXiv": "2311.10385", "Date": "Fri, 17 Nov 2023 08:23:17 ", "Title": "Delete My Account: Impact of Data Deletion on Machine Learning Classifiers", "Authors": ["Tobias Dam and Maximilian Henzl and Lukas Daniel Klausner"], "Categories": "cs.LG cs.CY", "Comments": ["14 pages", "14 figures"]}, "abstract": "Users are more aware than ever of the importance of their own data, thanks to reports about security breaches and leaks of private, often sensitive data in recent years. Additionally, the GDPR has been in effect in the European Union for over three years and many people have encountered its effects in one way or another. Consequently, more and more users are actively protecting their personal data. One way to do this is to make of the right to erasure guaranteed in the GDPR, which has potential implications for a number of different fields, such as big data and machine learning. Our paper presents an in-depth analysis about the impact of the use of the right to erasure on the performance of machine learning models on classification tasks. We conduct various experiments utilising different datasets as well as different machine learning algorithms to analyse a variety of deletion behaviour scenarios. Due to the lack of credible data on actual user behaviour, we make reasonable assumptions for various deletion modes and biases and provide insight into the effects of different plausible scenarios for right to erasure usage on data quality of machine learning. Our results show that the impact depends strongly on the amount of data deleted, the particular characteristics of the dataset and the bias chosen for deletion and assumptions on user behaviour.", "url": "https://arxiv.org/abs/2311.10385"}, {"metadata": {"arXiv": "2311.10421", "Date": "Fri, 17 Nov 2023 09:54:35 ", "Title": "Maintenance Techniques for Anomaly Detection AIOps Solutions", "Authors": ["Lorena Poenaru-Olaru", "Natalia Karpova", "Luis Cruz", "Jan Rellermeyer", "Arie van Deursen"], "Categories": "cs.LG cs.SE"}, "abstract": "Anomaly detection techniques are essential in automating the monitoring of IT systems and operations. These techniques imply that machine learning algorithms are trained on operational data corresponding to a specific period of time and that they are continuously evaluated on newly emerging data. Operational data is constantly changing over time, which affects the performance of deployed anomaly detection models. Therefore, continuous model maintenance is required to preserve the performance of anomaly detectors over time. In this work, we analyze two different anomaly detection model maintenance techniques in terms of the model update frequency, namely blind model retraining and informed model retraining. We further investigate the effects of updating the model by retraining it on all the available data (full-history approach) and on only the newest data (sliding window approach). Moreover, we investigate whether a data change monitoring tool is capable of determining when the anomaly detection model needs to be updated through retraining.", "url": "https://arxiv.org/abs/2311.10421"}, {"metadata": {"arXiv": "2311.10448", "Date": "Fri, 17 Nov 2023 11:03:13 ", "Title": "DeepClean: Machine Unlearning on the Cheap by Resetting Privacy Sensitive Weights using the Fisher Diagonal", "Authors": ["Jiaeli Shi", "Najah Ghalyan", "Kostis Gourgoulias", "John Buford", "Sean Moran"], "Categories": "cs.LG cs.CR cs.CV"}, "abstract": "Machine learning models trained on sensitive or private data can inadvertently memorize and leak that information. Machine unlearning seeks to retroactively remove such details from model weights to protect privacy. We contribute a lightweight unlearning algorithm that leverages the Fisher Information Matrix (FIM) for selective forgetting. Prior work in this area requires full retraining or large matrix inversions, which are computationally expensive. Our key insight is that the diagonal elements of the FIM, which measure the sensitivity of log-likelihood to changes in weights, contain sufficient information for effective forgetting. Specifically, we compute the FIM diagonal over two subsets -- the data to retain and forget -- for all trainable weights. This diagonal representation approximates the complete FIM while dramatically reducing computation. We then use it to selectively update weights to maximize forgetting of the sensitive subset while minimizing impact on the retained subset. Experiments show that our algorithm can successfully forget any randomly selected subsets of training data across neural network architectures. By leveraging the FIM diagonal, our approach provides an interpretable, lightweight, and efficient solution for machine unlearning with practical privacy benefits.", "url": "https://arxiv.org/abs/2311.10448"}, {"metadata": {"arXiv": "2311.10512", "Date": "Fri, 17 Nov 2023 13:31:19 ", "Title": "Causal Fairness-Guided Dataset Reweighting using Neural Networks", "Authors": ["Xuan Zhao and Klaus Broelemann and Salvatore Ruggieri and Gjergji Kasneci"], "Categories": "cs.LG", "Comments": ["To be published in the proceedings of 2023 IEEE International Conference on Big Data (IEEE BigData 2023)"]}, "abstract": "The importance of achieving fairness in machine learning models cannot be overstated. Recent research has pointed out that fairness should be examined from a causal perspective, and several fairness notions based on the on Pearl's causal framework have been proposed. In this paper, we construct a reweighting scheme of datasets to address causal fairness. Our approach aims at mitigating bias by considering the causal relationships among variables and incorporating them into the reweighting process. The proposed method adopts two neural networks, whose structures are intentionally used to reflect the structures of a causal graph and of an interventional graph. The two neural networks can approximate the causal model of the data, and the causal model of interventions. Furthermore, reweighting guided by a discriminator is applied to achieve various fairness notions. Experiments on real-world datasets show that our method can achieve causal fairness on the data while remaining close to the original data for downstream tasks.", "url": "https://arxiv.org/abs/2311.10512"}, {"metadata": {"arXiv": "2311.10517", "Date": "Fri, 17 Nov 2023 13:40:10 ", "Title": "Mind the map! Accounting for existing map information when estimating online HDMaps from sensor data", "Authors": ["R\\'emy Sun", "Li Yang", "Diane Lingrand", "Fr\\'ed\\'eric Precioso"], "Categories": "cs.LG cs.CV", "Comments": ["12 pages", "4 figures", "7 tables"]}, "abstract": "Online High Definition Map (HDMap) estimation from sensors offers a low-cost alternative to manually acquired HDMaps. As such, it promises to lighten costs for already HDMap-reliant Autonomous Driving systems, and potentially even spread their use to new systems. In this paper, we propose to improve online HDMap estimation by accounting for already existing maps. We identify 3 reasonable types of useful existing maps (minimalist, noisy, and outdated). We also introduce MapEX, a novel online HDMap estimation framework that accounts for existing maps. MapEX achieves this by encoding map elements into query tokens and by refining the matching algorithm used to train classic query based map estimation models. We demonstrate that MapEX brings significant improvements on the nuScenes dataset. For instance, MapEX - given noisy maps - improves by 38% over the MapTRv2 detector it is based on and by 16% over the current SOTA.", "url": "https://arxiv.org/abs/2311.10517"}, {"metadata": {"arXiv": "2311.10525", "Date": "Fri, 17 Nov 2023 13:45:31 ", "Title": "Utilizing VQ-VAE for End-to-End Health Indicator Generation in Predicting Rolling Bearing RUL", "Authors": ["Junliang Wang", "Qinghua Zhang", "Guanhua Zhu and Guoxi Sun"], "Categories": "cs.LG cs.SY eess.SY", "Comments": ["17 figures"]}, "abstract": "The prediction of the remaining useful life (RUL) of rolling bearings is a pivotal issue in industrial production. A crucial approach to tackling this issue involves transforming vibration signals into health indicators (HI) to aid model training. This paper presents an end-to-end HI construction method, vector quantised variational autoencoder (VQ-VAE), which addresses the need for dimensionality reduction of latent variables in traditional unsupervised learning methods such as autoencoder. Moreover, concerning the inadequacy of traditional statistical metrics in reflecting curve fluctuations accurately, two novel statistical metrics, mean absolute distance (MAD) and mean variance (MV), are introduced. These metrics accurately depict the fluctuation patterns in the curves, thereby indicating the model's accuracy in discerning similar features. On the PMH2012 dataset, methods employing VQ-VAE for label construction achieved lower values for MAD and MV. Furthermore, the ASTCN prediction model trained with VQ-VAE labels demonstrated commendable performance, attaining the lowest values for MAD and MV.", "url": "https://arxiv.org/abs/2311.10525"}, {"metadata": {"arXiv": "2311.10579", "Date": "Fri, 17 Nov 2023 15:30:12 ", "Title": "Graph Neural Networks for Pressure Estimation in Water Distribution Systems", "Authors": ["Huy Truong", "Andr\\'es Tello", "Alexander Lazovik", "Victoria Degeler"], "Categories": "cs.LG", "Comments": ["submitted to Water Resources Research. Huy Truong and Andr\\'es Tello contributed equally to this work"]}, "abstract": "Pressure and flow estimation in Water Distribution Networks (WDN) allows water management companies to optimize their control operations. For many years, mathematical simulation tools have been the most common approach to reconstructing an estimate of the WDN hydraulics. However, pure physics-based simulations involve several challenges, e.g. partially observable data, high uncertainty, and extensive manual configuration. Thus, data-driven approaches have gained traction to overcome such limitations. In this work, we combine physics-based modeling and Graph Neural Networks (GNN), a data-driven approach, to address the pressure estimation problem. First, we propose a new data generation method using a mathematical simulation but not considering temporal patterns and including some control parameters that remain untouched in previous works; this contributes to a more diverse training data. Second, our training strategy relies on random sensor placement making our GNN-based estimation model robust to unexpected sensor location changes. Third, a realistic evaluation protocol considers real temporal patterns and additionally injects the uncertainties intrinsic to real-world scenarios. Finally, a multi-graph pre-training strategy allows the model to be reused for pressure estimation in unseen target WDNs. Our GNN-based model estimates the pressure of a large-scale WDN in The Netherlands with a MAE of 1.94mH$_2$O and a MAPE of 7%, surpassing the performance of previous studies. Likewise, it outperformed previous approaches on other WDN benchmarks, showing a reduction of absolute error up to approximately 52% in the best cases.", "url": "https://arxiv.org/abs/2311.10579"}, {"metadata": {"arXiv": "2311.10580", "Date": "Fri, 17 Nov 2023 15:30:44 ", "Title": "Implicit Maximum a Posteriori Filtering via Adaptive Optimization", "Authors": ["Gianluca M. Bencomo", "Jake C. Snell", "Thomas L. Griffiths"], "Categories": "cs.LG cs.SY eess.SY stat.ML", "Comments": ["Under review at ICLR 2024"]}, "abstract": "Bayesian filtering approximates the true underlying behavior of a time-varying system by inverting an explicit generative model to convert noisy measurements into state estimates. This process typically requires either storage, inversion, and multiplication of large matrices or Monte Carlo estimation, neither of which are practical in high-dimensional state spaces such as the weight spaces of artificial neural networks. Here, we frame the standard Bayesian filtering problem as optimization over a time-varying objective. Instead of maintaining matrices for the filtering equations or simulating particles, we specify an optimizer that defines the Bayesian filter implicitly. In the linear-Gaussian setting, we show that every Kalman filter has an equivalent formulation using K steps of gradient descent. In the nonlinear setting, our experiments demonstrate that our framework results in filters that are effective, robust, and scalable to high-dimensional systems, comparing well against the standard toolbox of Bayesian filtering solutions. We suggest that it is easier to fine-tune an optimizer than it is to specify the correct filtering equations, making our framework an attractive option for high-dimensional filtering problems.", "url": "https://arxiv.org/abs/2311.10580"}, {"metadata": {"arXiv": "2311.10609", "Date": "Fri, 17 Nov 2023 16:04:27 ", "Title": "Scaling TabPFN: Sketching and Feature Selection for Tabular Prior-Data Fitted Networks", "Authors": ["Benjamin Feuer", "Chinmay Hegde", "Niv Cohen"], "Categories": "cs.LG cs.DB", "Comments": ["2nd Table Representation Learning Workshop: 37th Conference on Neural Information Processing Systems (NeurIPS 2023)"]}, "abstract": "Tabular classification has traditionally relied on supervised algorithms, which estimate the parameters of a prediction model using its training data. Recently, Prior-Data Fitted Networks (PFNs) such as TabPFN have successfully learned to classify tabular data in-context: the model parameters are designed to classify new samples based on labelled training samples given after the model training. While such models show great promise, their applicability to real-world data remains limited due to the computational scale needed. Here we study the following question: given a pre-trained PFN for tabular data, what is the best way to summarize the labelled training samples before feeding them to the model? We conduct an initial investigation of sketching and feature-selection methods for TabPFN, and note certain key differences between it and conventionally fitted tabular models.", "url": "https://arxiv.org/abs/2311.10609"}, {"metadata": {"arXiv": "2311.10610", "Date": "Fri, 17 Nov 2023 16:04:31 ", "Title": "A Poincar\\'e Inequality and Consistency Results for Signal Sampling on Large Graphs", "Authors": ["Thien Le", "Luana Ruiz", "Stefanie Jegelka"], "Categories": "cs.LG stat.ML", "Comments": ["23 pages"]}, "abstract": "Large-scale graph machine learning is challenging as the complexity of learning models scales with the graph size. Subsampling the graph is a viable alternative, but sampling on graphs is nontrivial as graphs are non-Euclidean. Existing graph sampling techniques require not only computing the spectra of large matrices but also repeating these computations when the graph changes, e.g., grows. In this paper, we introduce a signal sampling theory for a type of graph limit -- the graphon. We prove a Poincar\\'e inequality for graphon signals and show that complements of node subsets satisfying this inequality are unique sampling sets for Paley-Wiener spaces of graphon signals. Exploiting connections with spectral clustering and Gaussian elimination, we prove that such sampling sets are consistent in the sense that unique sampling sets on a convergent graph sequence converge to unique sampling sets on the graphon. We then propose a related graphon signal sampling algorithm for large graphs, and demonstrate its good empirical performance on graph machine learning tasks.", "url": "https://arxiv.org/abs/2311.10610"}, {"metadata": {"arXiv": "2311.10633", "Date": "Fri, 17 Nov 2023 16:41:35 ", "Title": "Predicting the Probability of Collision of a Satellite with Space Debris: A Bayesian Machine Learning Approach", "Authors": ["Jo\\~ao Sim\\~oes Catulo", "Cl\\'audia Soares", "Marta Guimar\\~aes"], "Categories": "cs.LG"}, "abstract": "Space is becoming more crowded in Low Earth Orbit due to increased space activity. Such a dense space environment increases the risk of collisions between space objects endangering the whole space population. Therefore, the need to consider collision avoidance as part of routine operations is evident to satellite operators. Current procedures rely on the analysis of multiple collision warnings by human analysts. However, with the continuous growth of the space population, this manual approach may become unfeasible, highlighting the importance of automation in risk assessment. In 2019, ESA launched a competition to study the feasibility of applying machine learning in collision risk estimation and released a dataset that contained sequences of Conjunction Data Messages (CDMs) in support of real close encounters. The competition results showed that the naive forecast and its variants are strong predictors for this problem, which suggests that the CDMs may follow the Markov property. The proposed work investigates this theory by benchmarking Hidden Markov Models (HMM) in predicting the risk of collision between two resident space objects by using one feature of the entire dataset: the sequence of the probability in the CDMs. In addition, Bayesian statistics are used to infer a joint distribution for the parameters of the models, which allows the development of robust and reliable probabilistic predictive models that can incorporate physical or prior knowledge about the problem within a rigorous theoretical framework and provides prediction uncertainties that nicely reflect the accuracy of the predicted risk. This work shows that the implemented HMM outperforms the naive solution in some metrics, which further adds to the idea that the collision warnings may be Markovian and suggests that this is a powerful method to be further explored.", "url": "https://arxiv.org/abs/2311.10633"}, {"metadata": {"arXiv": "2311.10665", "Date": "Fri, 17 Nov 2023 17:36:26 ", "Title": "Online Calibration of Deep Learning Sub-Models for Hybrid Numerical Modeling Systems", "Authors": ["Said Ouala", "Bertrand Chapron", "Fabrice Collard", "Lucile Gaultier", "Ronan Fablet"], "Categories": "cs.LG cs.NA math.NA physics.comp-ph"}, "abstract": "Artificial intelligence and deep learning are currently reshaping numerical simulation frameworks by introducing new modeling capabilities. These frameworks are extensively investigated in the context of model correction and parameterization where they demonstrate great potential and often outperform traditional physical models. Most of these efforts in defining hybrid dynamical systems follow {offline} learning strategies in which the neural parameterization (called here sub-model) is trained to output an ideal correction. Yet, these hybrid models can face hard limitations when defining what should be a relevant sub-model response that would translate into a good forecasting performance. End-to-end learning schemes, also referred to as online learning, could address such a shortcoming by allowing the deep learning sub-models to train on historical data. However, defining end-to-end training schemes for the calibration of neural sub-models in hybrid systems requires working with an optimization problem that involves the solver of the physical equations. Online learning methodologies thus require the numerical model to be differentiable, which is not the case for most modeling systems. To overcome this difficulty and bypass the differentiability challenge of physical models, we present an efficient and practical online learning approach for hybrid systems. The method, called EGA for Euler Gradient Approximation, assumes an additive neural correction to the physical model, and an explicit Euler approximation of the gradients. We demonstrate that the EGA converges to the exact gradients in the limit of infinitely small time steps. Numerical experiments are performed on various case studies, including prototypical ocean-atmosphere dynamics. Results show significant improvements over offline learning, highlighting the potential of end-to-end online learning for hybrid modeling.", "url": "https://arxiv.org/abs/2311.10665"}, {"metadata": {"arXiv": "2311.10707", "Date": "Fri, 17 Nov 2023 18:57:40 ", "Title": "Multimodal Representation Learning by Alternating Unimodal Adaptation", "Authors": ["Xiaohui Zhang", "Jaehong Yoon", "Mohit Bansal", "Huaxiu Yao"], "Categories": "cs.LG cs.CV"}, "abstract": "Multimodal learning, which integrates data from diverse sensory modes, plays a pivotal role in artificial intelligence. However, existing multimodal learning methods often struggle with challenges where some modalities appear more dominant than others during multimodal learning, resulting in suboptimal performance. To address this challenge, we propose MLA (Multimodal Learning with Alternating Unimodal Adaptation). MLA reframes the conventional joint multimodal learning process by transforming it into an alternating unimodal learning process, thereby minimizing interference between modalities. Simultaneously, it captures cross-modal interactions through a shared head, which undergoes continuous optimization across different modalities. This optimization process is controlled by a gradient modification mechanism to prevent the shared head from losing previously acquired information. During the inference phase, MLA utilizes a test-time uncertainty-based model fusion mechanism to integrate multimodal information. Extensive experiments are conducted on five diverse datasets, encompassing scenarios with complete modalities and scenarios with missing modalities. These experiments demonstrate the superiority of MLA over competing prior approaches.", "url": "https://arxiv.org/abs/2311.10707"}, {"metadata": {"arXiv": "2311.10653", "Date": "Fri, 17 Nov 2023 17:14:42 ", "Title": "Learning Realistic Joint Space Boundaries for Range of Motion Analysis of Healthy and Impaired Human Arms", "Authors": ["Shafagh Keyvanian", "Michelle J. Johnson", "Nadia Figueroa"], "Categories": "cs.RO cs.LG"}, "abstract": "A realistic human kinematic model that satisfies anatomical constraints is essential for human-robot interaction, biomechanics and robot-assisted rehabilitation. Modeling realistic joint constraints, however, is challenging as human arm motion is constrained by joint limits, inter- and intra-joint dependencies, self-collisions, individual capabilities and muscular or neurological constraints which are difficult to represent. Hence, physicians and researchers have relied on simple box-constraints, ignoring important anatomical factors. In this paper, we propose a data-driven method to learn realistic anatomically constrained upper-limb range of motion (RoM) boundaries from motion capture data. This is achieved by fitting a one-class support vector machine to a dataset of upper-limb joint space exploration motions with an efficient hyper-parameter tuning scheme. Our approach outperforms similar works focused on valid RoM learning. Further, we propose an impairment index (II) metric that offers a quantitative assessment of capability/impairment when comparing healthy and impaired arms. We validate the metric on healthy subjects physically constrained to emulate hemiplegia and different disability levels as stroke patients.", "url": "https://arxiv.org/abs/2311.10653"}, {"metadata": {"arXiv": "2311.10097", "Date": "Tue, 31 Oct 2023 12:31:32 ", "Title": "Investigating AI's Challenges in Reasoning and Explanation from a Historical Perspective", "Authors": ["Benji Alwis"], "Categories": "cs.AI"}, "abstract": "This paper provides an overview of the intricate relationship between social dynamics, technological advancements, and pioneering figures in the fields of cybernetics and artificial intelligence. It explores the impact of collaboration and interpersonal relationships among key scientists, such as McCulloch, Wiener, Pitts, and Rosenblatt, on the development of cybernetics and neural networks. It also discusses the contested attribution of credit for important innovations like the backpropagation algorithm and the potential consequences of unresolved debates within emerging scientific domains. It emphasizes how interpretive flexibility, public perception, and the influence of prominent figures can shape the trajectory of a new field. It highlights the role of funding, media attention, and alliances in determining the success and recognition of various research approaches. Additionally, it points out the missed opportunities for collaboration and integration between symbolic AI and neural network researchers, suggesting that a more unified approach may be possible in today's era without the historical baggage of past debates.", "url": "https://arxiv.org/abs/2311.10097"}, {"metadata": {"arXiv": "2311.10098", "Date": "Tue, 31 Oct 2023 17:44:04 ", "Title": "Automated Parliaments: A Solution to Decision Uncertainty and Misalignment in Language Models", "Authors": ["Thomas Forster", "Jonathan Ouwerx", "Shak Ragoler"], "Categories": "cs.AI", "Comments": ["39 pages", "4 figures"]}, "abstract": "As AI takes on a greater role in the modern world, it is essential to ensure that AI models can overcome decision uncertainty and remain aligned with human morality and interests. This research paper proposes a method for improving the decision-making of language models (LMs) via Automated Parliaments (APs) - constructs made of AI delegates each representing a certain perspective. Delegates themselves consist of three AI models: generators, modifiers, and evaluators. We specify two mechanisms for producing optimal solutions: the Simultaneous Modification mechanism for response creation and an evaluation mechanism for fairly assessing solutions. The overall process begins when each generator creates a response aligned with its delegate's theory. The modifiers alter all other responses to make them more self-aligned. The evaluators collectively assess the best end response. Finally, the modifiers and generators learn from feedback from the evaluators. In our research, we tested the evaluation mechanism, comparing the use of single-value zero-shot prompting and AP few-shot prompting in evaluating morally contentious scenarios. We found that the AP architecture saw a 57.3% reduction in its loss value compared to the baseline. We conclude by discussing some potential applications of APs and specifically their potential impact when implemented as Automated Moral Parliaments.", "url": "https://arxiv.org/abs/2311.10098"}, {"metadata": {"arXiv": "2311.10104", "Date": "Mon, 13 Nov 2023 12:31:46 ", "Title": "A Framework of Defining, Modeling, and Analyzing Cognition Mechanisms", "Authors": ["Amir Fayezioghani"], "Categories": "cs.AI", "Comments": ["A paper on cognition mechanisms as a basis for development of foundational models/architectures of cognitive/intelligent systems"]}, "abstract": "Cognition is a core part of and a common topic among philosophy of mind, psychology, neuroscience, AI, and cognitive science. Through a mechanistic lens, I propose a framework of defining, modeling, and analyzing cognition mechanisms. Firstly, appropriate terms are introduced and used in explanations related to the framework and within the definition of a mechanism. I implicitly contend that this terminology essentially characterizes a conceptual world required for discussions in this paper. Secondly, a mathematical model of a mechanism based on directed graphs is proposed. Thirdly, the definition of a base necessary for a mechanism to be classified as a cognition mechanism is proposed. I argue that the cognition base has the features of the cognition self of humans. Fourthly, three ways to mechanistically look at mechanisms is defined and specific instances of them are suggested. Fifthly, standards for visualization and presentation of mechanisms, cognition mechanisms, and the instances to mechanistically look at them are suggested and used to analyze cognition mechanisms through appropriate examples. Finally, the features of this paper are discussed and prospects of further development of the proposed framework are briefly expressed.", "url": "https://arxiv.org/abs/2311.10104"}, {"metadata": {"arXiv": "2311.10227", "Date": "Thu, 16 Nov 2023 22:49:27 ", "Title": "Think Twice: Perspective-Taking Improves Large Language Models' Theory-of-Mind Capabilities", "Authors": ["Alex Wilf", "Sihyun Shawn Lee", "Paul Pu Liang", "Louis-Philippe Morency"], "Categories": "cs.AI cs.CL"}, "abstract": "Human interactions are deeply rooted in the interplay of thoughts, beliefs, and desires made possible by Theory of Mind (ToM): our cognitive ability to understand the mental states of ourselves and others. Although ToM may come naturally to us, emulating it presents a challenge to even the most advanced Large Language Models (LLMs). Recent improvements to LLMs' reasoning capabilities from simple yet effective prompting techniques such as Chain-of-Thought have seen limited applicability to ToM. In this paper, we turn to the prominent cognitive science theory \"Simulation Theory\" to bridge this gap. We introduce SimToM, a novel two-stage prompting framework inspired by Simulation Theory's notion of perspective-taking. To implement this idea on current ToM benchmarks, SimToM first filters context based on what the character in question knows before answering a question about their mental state. Our approach, which requires no additional training and minimal prompt-tuning, shows substantial improvement over existing methods, and our analysis reveals the importance of perspective-taking to Theory-of-Mind capabilities. Our findings suggest perspective-taking as a promising direction for future research into improving LLMs' ToM capabilities.", "url": "https://arxiv.org/abs/2311.10227"}, {"metadata": {"arXiv": "2311.10228", "Date": "Thu, 16 Nov 2023 22:58:57 ", "Title": "A Graphical Model of Hurricane Evacuation Behaviors", "Authors": ["Hui Sophie Wang", "Nutchanon Yongsatianchot and Stacy Marsella"], "Categories": "cs.AI stat.AP"}, "abstract": "Natural disasters such as hurricanes are increasing and causing widespread devastation. People's decisions and actions regarding whether to evacuate or not are critical and have a large impact on emergency planning and response. Our interest lies in computationally modeling complex relationships among various factors influencing evacuation decisions. We conducted a study on the evacuation of Hurricane Irma of the 2017 Atlantic hurricane season. The study was guided by the Protection motivation theory (PMT), a widely-used framework to understand people's responses to potential threats. Graphical models were constructed to represent the complex relationships among the factors involved and the evacuation decision. We evaluated different graphical structures based on conditional independence tests using Irma data. The final model largely aligns with PMT. It shows that both risk perception (threat appraisal) and difficulties in evacuation (coping appraisal) influence evacuation decisions directly and independently. Certain information received from media was found to influence risk perception, and through it influence evacuation behaviors indirectly. In addition, several variables were found to influence both risk perception and evacuation behaviors directly, including family and friends' suggestions, neighbors' evacuation behaviors, and evacuation notices from officials.", "url": "https://arxiv.org/abs/2311.10228"}, {"metadata": {"arXiv": "2311.10505", "Date": "Fri, 17 Nov 2023 13:10:58 ", "Title": "CNL2ASP: converting controlled natural language sentences into ASP", "Authors": ["Simone Caruso", "Carmine Dodaro", "Marco Maratea", "Marco Mochi", "Francesco Riccio"], "Categories": "cs.AI cs.CL cs.LO", "Comments": ["Under consideration in Theory and Practice of Logic Programming (TPLP)"]}, "abstract": "Answer Set Programming (ASP) is a popular declarative programming language for solving hard combinatorial problems. Although ASP has gained widespread acceptance in academic and industrial contexts, there are certain user groups who may find it more advantageous to employ a higher-level language that closely resembles natural language when specifying ASP programs. In this paper, we propose a novel tool, called CNL2ASP, for translating English sentences expressed in a controlled natural language (CNL) form into ASP. In particular, we first provide a definition of the type of sentences allowed by our CNL and their translation as ASP rules, and then exemplify the usage of the CNL for the specification of both synthetic and real-world combinatorial problems. Finally, we report the results of an experimental analysis conducted on the real-world problems to compare the performance of automatically generated encodings with the ones written by ASP practitioners, showing that our tool can obtain satisfactory performance on these benchmarks. Under consideration in Theory and Practice of Logic Programming (TPLP).", "url": "https://arxiv.org/abs/2311.10505"}, {"metadata": {"arXiv": "2311.10538", "Date": "Fri, 17 Nov 2023 14:06:05 ", "Title": "Testing Language Model Agents Safely in the Wild", "Authors": ["Silen Naihin", "David Atkinson", "Marc Green", "Merwane Hamadi", "Craig Swift", "Douglas Schonholtz", "Adam Tauman Kalai", "David Bau"], "Categories": "cs.AI"}, "abstract": "A prerequisite for safe autonomy-in-the-wild is safe testing-in-the-wild. Yet real-world autonomous tests face several unique safety challenges, both due to the possibility of causing harm during a test, as well as the risk of encountering new unsafe agent behavior through interactions with real-world and potentially malicious actors. We propose a framework for conducting safe autonomous agent tests on the open internet: agent actions are audited by a context-sensitive monitor that enforces a stringent safety boundary to stop an unsafe test, with suspect behavior ranked and logged to be examined by humans. We a design a basic safety monitor that is flexible enough to monitor existing LLM agents, and, using an adversarial simulated agent, we measure its ability to identify and stop unsafe situations. Then we apply the safety monitor on a battery of real-world tests of AutoGPT, and we identify several limitations and challenges that will face the creation of safe in-the-wild tests as autonomous agents grow more capable.", "url": "https://arxiv.org/abs/2311.10538"}, {"metadata": {"arXiv": "2311.10099", "Date": "Fri, 03 Nov 2023 05:30:13 ", "Title": "Smart Traffic Management of Vehicles using Faster R-CNN based Deep Learning Method", "Authors": ["Arindam Chaudhuri"], "Categories": "cs.CV cs.AI eess.IV", "Comments": ["Book Chapter"]}, "abstract": "With constant growth of civilization and modernization of cities all across the world since past few centuries smart traffic management of vehicles is one of the most sorted after problem by research community. It is a challenging problem in computer vision and artificial intelligence domain. Smart traffic management basically involves segmentation of vehicles, estimation of traffic density and tracking of vehicles. The vehicle segmentation from traffic videos helps realization of niche applications such as monitoring of speed and estimation of traffic. When occlusions, background with clutters and traffic with density variations are present, this problem becomes more intractable in nature. Keeping this motivation in this research work, we investigate Faster R-CNN based deep learning method towards segmentation of vehicles. This problem is addressed in four steps viz minimization with adaptive background model, Faster R-CNN based subnet operation, Faster R-CNN initial refinement and result optimization with extended topological active nets. The computational framework uses ideas of adaptive background modeling. It also addresses shadow and illumination related issues. Higher segmentation accuracy is achieved through topological active net deformable models. The topological and extended topological active nets help to achieve stated deformations. Mesh deformation is achieved with minimization of energy. The segmentation accuracy is improved with modified version of extended topological active net. The experimental results demonstrate superiority of this computational framework", "url": "https://arxiv.org/abs/2311.10099"}, {"metadata": {"arXiv": "2311.10234", "Date": "Thu, 16 Nov 2023 23:49:05 ", "Title": "The Analysis and Extraction of Structure from Organizational Charts", "Authors": ["Nikhil Manali", "David Doermann", "and Mahesh Desai"], "Categories": "cs.CV cs.AI"}, "abstract": "Organizational charts, also known as org charts, are critical representations of an organization's structure and the hierarchical relationships between its components and positions. However, manually extracting information from org charts can be error-prone and time-consuming. To solve this, we present an automated and end-to-end approach that uses computer vision, deep learning, and natural language processing techniques. Additionally, we propose a metric to evaluate the completeness and hierarchical accuracy of the extracted information. This approach has the potential to improve organizational restructuring and resource utilization by providing a clear and concise representation of the organizational structure. Our study lays a foundation for further research on the topic of hierarchical chart analysis.", "url": "https://arxiv.org/abs/2311.10234"}, {"metadata": {"arXiv": "2311.10269", "Date": "Fri, 17 Nov 2023 01:29:16 ", "Title": "Interpretable pap smear cell representation for cervical cancer screening", "Authors": ["Yu Ando and Nora Jee-Young Park and", "Gun Oh Chong and Seokhwan Ko and Donghyeon Lee and Junghwan Cho and Hyungsoo Han"], "Categories": "cs.CV cs.AI", "Comments": ["20 pages", "6 figures"]}, "abstract": "Screening is critical for prevention and early detection of cervical cancer but it is time-consuming and laborious. Supervised deep convolutional neural networks have been developed to automate pap smear screening and the results are promising. However, the interest in using only normal samples to train deep neural networks has increased owing to class imbalance problems and high-labeling costs that are both prevalent in healthcare. In this study, we introduce a method to learn explainable deep cervical cell representations for pap smear cytology images based on one class classification using variational autoencoders. Findings demonstrate that a score can be calculated for cell abnormality without training models with abnormal samples and localize abnormality to interpret our results with a novel metric based on absolute difference in cross entropy in agglomerative clustering. The best model that discriminates squamous cell carcinoma (SCC) from normals gives 0.908 +- 0.003 area under operating characteristic curve (AUC) and one that discriminates high-grade epithelial lesion (HSIL) 0.920 +- 0.002 AUC. Compared to other clustering methods, our method enhances the V-measure and yields higher homogeneity scores, which more effectively isolate different abnormality regions, aiding in the interpretation of our results. Evaluation using in-house and additional open dataset show that our model can discriminate abnormality without the need of additional training of deep models.", "url": "https://arxiv.org/abs/2311.10269"}, {"metadata": {"arXiv": "2311.10319", "Date": "Fri, 17 Nov 2023 04:04:29 ", "Title": "Shifting to Machine Supervision: Annotation-Efficient Semi and Self-Supervised Learning for Automatic Medical Image Segmentation and Classification", "Authors": ["Pranav Singh", "Raviteja Chukkapalli", "Shravan Chaudhari", "Luoyao Chen", "Mei Chen", "Jinqian Pan", "Craig Smuda and Jacopo Cirrone"], "Categories": "cs.CV cs.AI", "Comments": ["Seventeen pages (incl. references)", "five figures", "and one table. (Under Review)"]}, "abstract": "Advancements in clinical treatment and research are limited by supervised learning techniques that rely on large amounts of annotated data, an expensive task requiring many hours of clinical specialists' time. In this paper, we propose using self-supervised and semi-supervised learning. These techniques perform an auxiliary task that is label-free, scaling up machine-supervision is easier compared with fully-supervised techniques. This paper proposes S4MI (Self-Supervision and Semi-Supervision for Medical Imaging), our pipeline to leverage advances in self and semi-supervision learning. We benchmark them on three medical imaging datasets to analyze their efficacy for classification and segmentation. This advancement in self-supervised learning with 10% annotation performed better than 100% annotation for the classification of most datasets. The semi-supervised approach yielded favorable outcomes for segmentation, outperforming the fully-supervised approach by using 50% fewer labels in all three datasets.", "url": "https://arxiv.org/abs/2311.10319"}, {"metadata": {"arXiv": "2311.10329", "Date": "Fri, 17 Nov 2023 05:03:53 ", "Title": "High-fidelity Person-centric Subject-to-Image Synthesis", "Authors": ["Yibin Wang and Weizhong Zhang and Jianwei Zheng and Cheng Jin"], "Categories": "cs.CV cs.AI"}, "abstract": "Current subject-driven image generation methods encounter significant challenges in person-centric image generation. The reason is that they learn the semantic scene and person generation by fine-tuning a common pre-trained diffusion, which involves an irreconcilable training imbalance. Precisely, to generate realistic persons, they need to sufficiently tune the pre-trained model, which inevitably causes the model to forget the rich semantic scene prior and makes scene generation over-fit to the training data. Moreover, even with sufficient fine-tuning, these methods can still not generate high-fidelity persons since joint learning of the scene and person generation also lead to quality compromise. In this paper, we propose Face-diffuser, an effective collaborative generation pipeline to eliminate the above training imbalance and quality compromise. Specifically, we first develop two specialized pre-trained diffusion models, i.e., Text-driven Diffusion Model (TDM) and Subject-augmented Diffusion Model (SDM), for scene and person generation, respectively. The sampling process is divided into three sequential stages, i.e., semantic scene construction, subject-scene fusion, and subject enhancement. The first and last stages are performed by TDM and SDM respectively. The subject-scene fusion stage, that is the collaboration achieved through a novel and highly effective mechanism, Saliency-adaptive Noise Fusion (SNF). Specifically, it is based on our key observation that there exists a robust link between classifier-free guidance responses and the saliency of generated images. In each time step, SNF leverages the unique strengths of each model and allows for the spatial blending of predicted noises from both models automatically in a saliency-aware manner. Extensive experiments confirm the impressive effectiveness and robustness of the Face-diffuser.", "url": "https://arxiv.org/abs/2311.10329"}, {"metadata": {"arXiv": "2311.10365", "Date": "Fri, 17 Nov 2023 07:37:41 ", "Title": "Dates Fruit Disease Recognition using Machine Learning", "Authors": ["Ghassen Ben Brahim", "Jaafar Alghazo", "Ghazanfar Latif", "Khalid Alnujaidi"], "Categories": "cs.CV cs.AI"}, "abstract": "Many countries such as Saudi Arabia, Morocco and Tunisia are among the top exporters and consumers of palm date fruits. Date fruit production plays a major role in the economies of the date fruit exporting countries. Date fruits are susceptible to disease just like any fruit and early detection and intervention can end up saving the produce. However, with the vast farming lands, it is nearly impossible for farmers to observe date trees on a frequent basis for early disease detection. In addition, even with human observation the process is prone to human error and increases the date fruit cost. With the recent advances in computer vision, machine learning, drone technology, and other technologies; an integrated solution can be proposed for the automatic detection of date fruit disease. In this paper, a hybrid features based method with the standard classifiers is proposed based on the extraction of L*a*b color features, statistical features, and Discrete Wavelet Transform (DWT) texture features for the early detection and classification of date fruit disease. A dataset was developed for this work consisting of 871 images divided into the following classes; Healthy date, Initial stage of disease, Malnourished date, and Parasite infected. The extracted features were input to common classifiers such as the Random Forest (RF), Multilayer Perceptron (MLP), Na\\\"ive Bayes (NB), and Fuzzy Decision Trees (FDT). The highest average accuracy was achieved when combining the L*a*b, Statistical, and DWT Features.", "url": "https://arxiv.org/abs/2311.10365"}, {"metadata": {"arXiv": "2311.10522", "Date": "Fri, 17 Nov 2023 13:43:43 ", "Title": "Enhancing Object Coherence in Layout-to-Image Synthesis", "Authors": ["Yibin Wang and Weizhong Zhang and Jianwei Zheng and Cheng Jin"], "Categories": "cs.CV cs.AI"}, "abstract": "Layout-to-image synthesis is an emerging technique in conditional image generation. It aims to generate complex scenes, where users require fine control over the layout of the objects in a scene. However, it remains challenging to control the object coherence, including semantic coherence (e.g., the cat looks at the flowers or not) and physical coherence (e.g., the hand and the racket should not be misaligned). In this paper, we propose a novel diffusion model with effective global semantic fusion (GSF) and self-similarity feature enhancement modules to guide the object coherence for this task. For semantic coherence, we argue that the image caption contains rich information for defining the semantic relationship within the objects in the images. Instead of simply employing cross-attention between captions and generated images, which addresses the highly relevant layout restriction and semantic coherence separately and thus leads to unsatisfying results shown in our experiments, we develop GSF to fuse the supervision from the layout restriction and semantic coherence requirement and exploit it to guide the image synthesis process. Moreover, to improve the physical coherence, we develop a Self-similarity Coherence Attention (SCA) module to explicitly integrate local contextual physical coherence into each pixel's generation process. Specifically, we adopt a self-similarity map to encode the coherence restrictions and employ it to extract coherent features from text embedding. Through visualization of our self-similarity map, we explore the essence of SCA, revealing that its effectiveness is not only in capturing reliable physical coherence patterns but also in enhancing complex texture generation. Extensive experiments demonstrate the superiority of our proposed method in both image generation quality and controllability.", "url": "https://arxiv.org/abs/2311.10522"}, {"metadata": {"arXiv": "2311.10591", "Date": "Fri, 17 Nov 2023 15:46:09 ", "Title": "FOCAL: A Cost-Aware Video Dataset for Active Learning", "Authors": ["Kiran Kokilepersaud", "Yash-Yee Logan", "Ryan Benkert", "Chen Zhou", "Mohit Prabhushankar", "Ghassan AlRegib", "Enrique Corona", "Kunjan Singh", "Mostafa Parchami"], "Categories": "cs.CV cs.AI", "Comments": ["This paper was accepted as a main conference paper at the IEEE International Conference on Big Data"]}, "abstract": "In this paper, we introduce the FOCAL (Ford-OLIVES Collaboration on Active Learning) dataset which enables the study of the impact of annotation-cost within a video active learning setting. Annotation-cost refers to the time it takes an annotator to label and quality-assure a given video sequence. A practical motivation for active learning research is to minimize annotation-cost by selectively labeling informative samples that will maximize performance within a given budget constraint. However, previous work in video active learning lacks real-time annotation labels for accurately assessing cost minimization and instead operates under the assumption that annotation-cost scales linearly with the amount of data to annotate. This assumption does not take into account a variety of real-world confounding factors that contribute to a nonlinear cost such as the effect of an assistive labeling tool and the variety of interactions within a scene such as occluded objects, weather, and motion of objects. FOCAL addresses this discrepancy by providing real annotation-cost labels for 126 video sequences across 69 unique city scenes with a variety of weather, lighting, and seasonal conditions. We also introduce a set of conformal active learning algorithms that take advantage of the sequential structure of video data in order to achieve a better trade-off between annotation-cost and performance while also reducing floating point operations (FLOPS) overhead by at least 77.67%. We show how these approaches better reflect how annotations on videos are done in practice through a sequence selection framework. We further demonstrate the advantage of these approaches by introducing two performance-cost metrics and show that the best conformal active learning method is cheaper than the best traditional active learning method by 113 hours.", "url": "https://arxiv.org/abs/2311.10591"}, {"metadata": {"arXiv": "2311.10112", "Date": "Wed, 15 Nov 2023 21:25:15 ", "Title": "Zero-Shot Relational Learning on Temporal Knowledge Graphs with Large Language Models", "Authors": ["Zifeng Ding", "Heling Cai", "Jingpei Wu", "Yunpu Ma", "Ruotong Liao", "Bo Xiong", "Volker Tresp"], "Categories": "cs.AI cs.CL cs.LG"}, "abstract": "In recent years, modeling evolving knowledge over temporal knowledge graphs (TKGs) has become a heated topic. Various methods have been proposed to forecast links on TKGs. Most of them are embedding-based, where hidden representations are learned to represent knowledge graph (KG) entities and relations based on the observed graph contexts. Although these methods show strong performance on traditional TKG forecasting (TKGF) benchmarks, they naturally face a strong challenge when they are asked to model the unseen zero-shot relations that has no prior graph context. In this paper, we try to mitigate this problem as follows. We first input the text descriptions of KG relations into large language models (LLMs) for generating relation representations, and then introduce them into embedding-based TKGF methods. LLM-empowered representations can capture the semantic information in the relation descriptions. This makes the relations, whether seen or unseen, with similar semantic meanings stay close in the embedding space, enabling TKGF models to recognize zero-shot relations even without any observed graph context. Experimental results show that our approach helps TKGF models to achieve much better performance in forecasting the facts with previously unseen relations, while still maintaining their ability in link forecasting regarding seen relations.", "url": "https://arxiv.org/abs/2311.10112"}, {"metadata": {"arXiv": "2311.10117", "Date": "Thu, 16 Nov 2023 07:42:46 ", "Title": "Automatic Engineering of Long Prompts", "Authors": ["Cho-Jui Hsieh", "Si Si", "Felix X. Yu", "Inderjit S. Dhillon"], "Categories": "cs.AI cs.LG"}, "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in solving complex open-domain tasks, guided by comprehensive instructions and demonstrations provided in the form of prompts. However, these prompts can be lengthy, often comprising hundreds of lines and thousands of tokens, and their design often requires considerable human effort. Recent research has explored automatic prompt engineering for short prompts, typically consisting of one or a few sentences. However, the automatic design of long prompts remains a challenging problem due to its immense search space. In this paper, we investigate the performance of greedy algorithms and genetic algorithms for automatic long prompt engineering. We demonstrate that a simple greedy approach with beam search outperforms other methods in terms of search efficiency. Moreover, we introduce two novel techniques that utilize search history to enhance the effectiveness of LLM-based mutation in our search algorithm. Our results show that the proposed automatic long prompt engineering algorithm achieves an average of 9.2% accuracy gain on eight tasks in Big Bench Hard, highlighting the significance of automating prompt designs to fully harness the capabilities of LLMs.", "url": "https://arxiv.org/abs/2311.10117"}, {"metadata": {"arXiv": "2311.10127", "Date": "Thu, 16 Nov 2023 16:53:17 ", "Title": "Learning interactions to boost human creativity with bandits and GPT-4", "Authors": ["Ara Vartanian", "Xiaoxi Sun", "Yun-Shiuan Chuang", "Siddharth Suresh", "Xiaojin Zhu", "Timothy T. Rogers"], "Categories": "cs.AI cs.HC cs.LG"}, "abstract": "This paper considers how interactions with AI algorithms can boost human creative thought. We employ a psychological task that demonstrates limits on human creativity, namely semantic feature generation: given a concept name, respondents must list as many of its features as possible. Human participants typically produce only a fraction of the features they know before getting \"stuck.\" In experiments with humans and with a language AI (GPT-4) we contrast behavior in the standard task versus a variant in which participants can ask for algorithmically-generated hints. Algorithm choice is administered by a multi-armed bandit whose reward indicates whether the hint helped generating more features. Humans and the AI show similar benefits from hints, and remarkably, bandits learning from AI responses prefer the same prompting strategy as those learning from human behavior. The results suggest that strategies for boosting human creativity via computer interactions can be learned by bandits run on groups of simulated participants.", "url": "https://arxiv.org/abs/2311.10127"}, {"metadata": {"arXiv": "2311.10111", "Date": "Wed, 15 Nov 2023 19:51:57 ", "Title": "VideoCon: Robust Video-Language Alignment via Contrast Captions", "Authors": ["Hritik Bansal", "Yonatan Bitton", "Idan Szpektor", "Kai-Wei Chang", "Aditya Grover"], "Categories": "cs.CV cs.AI cs.CL cs.LG", "Comments": ["22 pages", "19 Figures", "7 Tables"]}, "abstract": "Despite being (pre)trained on a massive amount of data, state-of-the-art video-language alignment models are not robust to semantically-plausible contrastive changes in the video captions. Our work addresses this by identifying a broad spectrum of contrast misalignments, such as replacing entities, actions, and flipping event order, which alignment models should be robust against. To this end, we introduce the VideoCon, a video-language alignment dataset constructed by a large language model that generates plausible contrast video captions and explanations for differences between original and contrast video captions. Then, a generative video-language model is finetuned with VideoCon to assess video-language entailment and generate explanations. Our VideoCon-based alignment model significantly outperforms current models. It exhibits a 12-point increase in AUC for the video-language alignment task on human-generated contrast captions. Finally, our model sets new state of the art zero-shot performance in temporally-extensive video-language tasks such as text-to-video retrieval (SSv2-Temporal) and video question answering (ATP-Hard). Moreover, our model shows superior performance on novel videos and human-crafted captions and explanations. Our code and data are available at https://github.com/Hritikbansal/videocon.", "url": "https://arxiv.org/abs/2311.10111"}, {"metadata": {"arXiv": "2311.10709", "Date": "Fri, 17 Nov 2023 18:59:04 ", "Title": "Emu Video: Factorizing Text-to-Video Generation by Explicit Image Conditioning", "Authors": ["Rohit Girdhar", "Mannat Singh", "Andrew Brown", "Quentin Duval", "Samaneh Azadi", "Sai Saketh Rambhatla", "Akbar Shah", "Xi Yin", "Devi Parikh", "Ishan Misra"], "Categories": "cs.CV cs.AI cs.GR cs.LG cs.MM", "Comments": ["Project page: https://emu-video.metademolab.com"]}, "abstract": "We present Emu Video, a text-to-video generation model that factorizes the generation into two steps: first generating an image conditioned on the text, and then generating a video conditioned on the text and the generated image. We identify critical design decisions--adjusted noise schedules for diffusion, and multi-stage training--that enable us to directly generate high quality and high resolution videos, without requiring a deep cascade of models as in prior work. In human evaluations, our generated videos are strongly preferred in quality compared to all prior work--81% vs. Google's Imagen Video, 90% vs. Nvidia's PYOCO, and 96% vs. Meta's Make-A-Video. Our model outperforms commercial solutions such as RunwayML's Gen2 and Pika Labs. Finally, our factorizing approach naturally lends itself to animating images based on a user's text prompt, where our generations are preferred 96% over prior work.", "url": "https://arxiv.org/abs/2311.10709"}, {"metadata": {"arXiv": "2311.10119", "Date": "Thu, 16 Nov 2023 09:22:48 ", "Title": "Accommodating Missing Modalities in Time-Continuous Multimodal Emotion Recognition", "Authors": ["Juan Vazquez-Rodriguez (M-PSI)", "Gr\\'egoire Lefebvre", "Julien Cumin", "James L. Crowley (M-PSI)"], "Categories": "cs.LG cs.AI stat.ML", "Journal-ref": "Affective Computing and Intelligent Interaction (ACII), Sep 2023, Cambridge (MA), United States"}, "abstract": "Decades of research indicate that emotion recognition is more effective when drawing information from multiple modalities. But what if some modalities are sometimes missing? To address this problem, we propose a novel Transformer-based architecture for recognizing valence and arousal in a time-continuous manner even with missing input modalities. We use a coupling of cross-attention and self-attention mechanisms to emphasize relationships between modalities during time and enhance the learning process on weak salient inputs. Experimental results on the Ulm-TSST dataset show that our model exhibits an improvement of the concordance correlation coefficient evaluation of 37% when predicting arousal values and 30% when predicting valence values, compared to a late-fusion baseline approach.", "url": "https://arxiv.org/abs/2311.10119"}, {"metadata": {"arXiv": "2311.10177", "Date": "Thu, 16 Nov 2023 20:09:47 ", "Title": "Towards Improving Robustness Against Common Corruptions using Mixture of Class Specific Experts", "Authors": ["Shashank Kotyan and Danilo Vasconcellos Vargas"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["arXiv admin note: substantial text overlap with arXiv:2311.07928; text overlap with arXiv:1903.12261 by other authors"]}, "abstract": "Neural networks have demonstrated significant accuracy across various domains, yet their vulnerability to subtle input alterations remains a persistent challenge. Conventional methods like data augmentation, while effective to some extent, fall short in addressing unforeseen corruptions, limiting the adaptability of neural networks in real-world scenarios. In response, this paper introduces a novel paradigm known as the Mixture of Class-Specific Expert Architecture. The approach involves disentangling feature learning for individual classes, offering a nuanced enhancement in scalability and overall performance. By training dedicated network segments for each class and subsequently aggregating their outputs, the proposed architecture aims to mitigate vulnerabilities associated with common neural network structures. The study underscores the importance of comprehensive evaluation methodologies, advocating for the incorporation of benchmarks like the common corruptions benchmark. This inclusion provides nuanced insights into the vulnerabilities of neural networks, especially concerning their generalization capabilities and robustness to unforeseen distortions. The research aligns with the broader objective of advancing the development of highly robust learning systems capable of nuanced reasoning across diverse and challenging real-world scenarios. Through this contribution, the paper aims to foster a deeper understanding of neural network limitations and proposes a practical approach to enhance their resilience in the face of evolving and unpredictable conditions.", "url": "https://arxiv.org/abs/2311.10177"}, {"metadata": {"arXiv": "2311.10206", "Date": "Thu, 16 Nov 2023 21:39:54 ", "Title": "Bayes in the age of intelligent machines", "Authors": ["Thomas L. Griffiths", "Jian-Qiao Zhu", "Erin Grant and R. Thomas McCoy"], "Categories": "cs.LG cs.AI"}, "abstract": "The success of methods based on artificial neural networks in creating intelligent machines seems like it might pose a challenge to explanations of human cognition in terms of Bayesian inference. We argue that this is not the case, and that in fact these systems offer new opportunities for Bayesian modeling. Specifically, we argue that Bayesian models of cognition and artificial neural networks lie at different levels of analysis and are complementary modeling approaches, together offering a way to understand human cognition that spans these levels. We also argue that the same perspective can be applied to intelligent machines, where a Bayesian approach may be uniquely valuable in understanding the behavior of large, opaque artificial neural networks that are trained on proprietary data.", "url": "https://arxiv.org/abs/2311.10206"}, {"metadata": {"arXiv": "2311.10242", "Date": "Fri, 17 Nov 2023 00:08:19 ", "Title": "Advancements in Generative AI: A Comprehensive Review of GANs, GPT, Autoencoders, Diffusion Model, and Transformers", "Authors": ["Staphord Bengesi", "Hoda El-Sayed", "Md Kamruzzaman Sarker", "Yao Houkpati", "John Irungu", "Timothy Oladunni"], "Categories": "cs.LG cs.AI"}, "abstract": "The launch of ChatGPT has garnered global attention, marking a significant milestone in the field of Generative Artificial Intelligence. While Generative AI has been in effect for the past decade, the introduction of ChatGPT has ignited a new wave of research and innovation in the AI domain. This surge in interest has led to the development and release of numerous cutting-edge tools, such as Bard, Stable Diffusion, DALL-E, Make-A-Video, Runway ML, and Jukebox, among others. These tools exhibit remarkable capabilities, encompassing tasks ranging from text generation and music composition, image creation, video production, code generation, and even scientific work. They are built upon various state-of-the-art models, including Stable Diffusion, transformer models like GPT-3 (recent GPT-4), variational autoencoders, and generative adversarial networks. This advancement in Generative AI presents a wealth of exciting opportunities and, simultaneously, unprecedented challenges. Throughout this paper, we have explored these state-of-the-art models, the diverse array of tasks they can accomplish, the challenges they pose, and the promising future of Generative Artificial Intelligence.", "url": "https://arxiv.org/abs/2311.10242"}, {"metadata": {"arXiv": "2311.10246", "Date": "Fri, 17 Nov 2023 00:35:38 ", "Title": "Surprisal Driven $k$-NN for Robust and Interpretable Nonparametric Learning", "Authors": ["Amartya Banerjee", "Christopher J. Hazard", "Jacob Beel", "Cade Mack", "Jack Xia", "Michael Resnick", "Will Goddin"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "Nonparametric learning is a fundamental concept in machine learning that aims to capture complex patterns and relationships in data without making strong assumptions about the underlying data distribution. Owing to simplicity and familiarity, one of the most well-known algorithms under this paradigm is the $k$-nearest neighbors ($k$-NN) algorithm. Driven by the usage of machine learning in safety-critical applications, in this work, we shed new light on the traditional nearest neighbors algorithm from the perspective of information theory and propose a robust and interpretable framework for tasks such as classification, regression, and anomaly detection using a single model. Instead of using a traditional distance measure which needs to be scaled and contextualized, we use a novel formulation of \\textit{surprisal} (amount of information required to explain the difference between the observed and expected result). Finally, we demonstrate this architecture's capability to perform at-par or above the state-of-the-art on classification, regression, and anomaly detection tasks using a single model with enhanced interpretability by providing novel concepts for characterizing data and predictions.", "url": "https://arxiv.org/abs/2311.10246"}, {"metadata": {"arXiv": "2311.10248", "Date": "Fri, 17 Nov 2023 00:39:59 ", "Title": "FedTruth: Byzantine-Robust and Backdoor-Resilient Federated Learning Framework", "Authors": ["Sheldon C. Ebron Jr. and Kan Yang"], "Categories": "cs.LG cs.AI cs.CR cs.DC"}, "abstract": "Federated Learning (FL) enables collaborative machine learning model training across multiple parties without sharing raw data. However, FL's distributed nature allows malicious clients to impact model training through Byzantine or backdoor attacks, using erroneous model updates. Existing defenses measure the deviation of each update from a 'ground-truth model update.' They often rely on a benign root dataset on the server or use trimmed mean or median for clipping, both methods having limitations. We introduce FedTruth, a robust defense against model poisoning in FL. FedTruth doesn't assume specific data distributions nor requires a benign root dataset. It estimates a global model update with dynamic aggregation weights, considering contributions from all benign clients. Empirical studies demonstrate FedTruth's efficacy in mitigating the impacts of poisoned updates from both Byzantine and backdoor attacks.", "url": "https://arxiv.org/abs/2311.10248"}, {"metadata": {"arXiv": "2311.10278", "Date": "Fri, 17 Nov 2023 01:55:15 ", "Title": "Physics-Enhanced Multi-fidelity Learning for Optical Surface Imprint", "Authors": ["Yongchao Chen"], "Categories": "cs.LG cs.AI cs.CV physics.app-ph", "Comments": ["8 pages", "4 figures", "NeurIPS 2023 Workshop on Adaptive Experimental Design and Active Learning in the Real World"], "Journal-ref": "NeurIPS 2023 Workshop on Adaptive Experimental Design and Active Learning in the Real World"}, "abstract": "Human fingerprints serve as one unique and powerful characteristic for each person, from which policemen can recognize the identity. Similar to humans, many natural bodies and intrinsic mechanical qualities can also be uniquely identified from surface characteristics. To measure the elasto-plastic properties of one material, one formally sharp indenter is pushed into the measured body under constant force and retracted, leaving a unique residual imprint of the minute size from several micrometers to nanometers. However, one great challenge is how to map the optical image of this residual imprint into the real wanted mechanical properties, i.e., the tensile force curve. In this paper, we propose a novel method to use multi-fidelity neural networks (MFNN) to solve this inverse problem. We first actively train the NN model via pure simulation data, and then bridge the sim-to-real gap via transfer learning. The most innovative part is that we use NN to dig out the unknown physics and also implant the known physics into the transfer learning framework, thus highly improving the model stability and decreasing the data requirement. This work serves as one great example of applying machine learning into the real experimental research, especially under the constraints of data limitation and fidelity variance.", "url": "https://arxiv.org/abs/2311.10278"}, {"metadata": {"arXiv": "2311.10300", "Date": "Fri, 17 Nov 2023 03:18:55 ", "Title": "Supervised structure learning", "Authors": ["Karl J. Friston", "Lancelot Da Costa", "Alexander Tschantz", "Alex Kiefer", "Tommaso Salvatori", "Victorita Neacsu", "Magnus Koudahl", "Conor Heins", "Noor Sajid", "Dimitrije Markovic", "Thomas Parr", "Tim Verbelen", "Christopher L Buckley"], "Categories": "cs.LG cs.AI"}, "abstract": "This paper concerns structure learning or discovery of discrete generative models. It focuses on Bayesian model selection and the assimilation of training data or content, with a special emphasis on the order in which data are ingested. A key move - in the ensuing schemes - is to place priors on the selection of models, based upon expected free energy. In this setting, expected free energy reduces to a constrained mutual information, where the constraints inherit from priors over outcomes (i.e., preferred outcomes). The resulting scheme is first used to perform image classification on the MNIST dataset to illustrate the basic idea, and then tested on a more challenging problem of discovering models with dynamics, using a simple sprite-based visual disentanglement paradigm and the Tower of Hanoi (cf., blocks world) problem. In these examples, generative models are constructed autodidactically to recover (i.e., disentangle) the factorial structure of latent states - and their characteristic paths or dynamics.", "url": "https://arxiv.org/abs/2311.10300"}, {"metadata": {"arXiv": "2311.10341", "Date": "Fri, 17 Nov 2023 06:03:56 ", "Title": "Federated Knowledge Graph Completion via Latent Embedding Sharing and Tensor Factorization", "Authors": ["Maolin Wang", "Dun Zeng", "Zenglin Xu", "Ruocheng Guo", "Xiangyu Zhao"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted by ICDM 2023"]}, "abstract": "Knowledge graphs (KGs), which consist of triples, are inherently incomplete and always require completion procedure to predict missing triples. In real-world scenarios, KGs are distributed across clients, complicating completion tasks due to privacy restrictions. Many frameworks have been proposed to address the issue of federated knowledge graph completion. However, the existing frameworks, including FedE, FedR, and FEKG, have certain limitations. = FedE poses a risk of information leakage, FedR's optimization efficacy diminishes when there is minimal overlap among relations, and FKGE suffers from computational costs and mode collapse issues. To address these issues, we propose a novel method, i.e., Federated Latent Embedding Sharing Tensor factorization (FLEST), which is a novel approach using federated tensor factorization for KG completion. FLEST decompose the embedding matrix and enables sharing of latent dictionary embeddings to lower privacy risks. Empirical results demonstrate FLEST's effectiveness and efficiency, offering a balanced solution between performance and privacy. FLEST expands the application of federated tensor factorization in KG completion tasks.", "url": "https://arxiv.org/abs/2311.10341"}, {"metadata": {"arXiv": "2311.10456", "Date": "Fri, 17 Nov 2023 11:21:09 ", "Title": "Accurate and Fast Fischer-Tropsch Reaction Microkinetics using PINNs", "Authors": ["Harshil Patel", "Aniruddha Panda", "Tymofii Nikolaienko", "Stanislav Jaso", "Alejandro Lopez", "Kaushic Kalyanaraman"], "Categories": "cs.LG cs.AI physics.chem-ph physics.comp-ph"}, "abstract": "Microkinetics allows detailed modelling of chemical transformations occurring in many industrially relevant reactions. Traditional way of solving the microkinetics model for Fischer-Tropsch synthesis (FTS) becomes inefficient when it comes to more advanced real-time applications. In this work, we address these challenges by using physics-informed neural networks(PINNs) for modelling FTS microkinetics. We propose a computationally efficient and accurate method, enabling the ultra-fast solution of the existing microkinetics models in realistic process conditions. The proposed PINN model computes the fraction of vacant catalytic sites, a key quantity in FTS microkinetics, with median relative error (MRE) of 0.03%, and the FTS product formation rates with MRE of 0.1%. Compared to conventional equation solvers, the model achieves up to 1E+06 times speed-up when running on GPUs, thus being fast enough for multi-scale and multi-physics reactor modelling and enabling its applications in real-time process control and optimization.", "url": "https://arxiv.org/abs/2311.10456"}, {"metadata": {"arXiv": "2311.10468", "Date": "Fri, 17 Nov 2023 11:48:10 ", "Title": "Using Cooperative Game Theory to Prune Neural Networks", "Authors": ["Mauricio Diaz-Ortiz Jr", "Benjamin Kempinski", "Daphne Cornelisse", "Yoram Bachrach", "Tal Kachman"], "Categories": "cs.LG cs.AI cs.CE cs.GT cs.MA"}, "abstract": "We show how solution concepts from cooperative game theory can be used to tackle the problem of pruning neural networks. The ever-growing size of deep neural networks (DNNs) increases their performance, but also their computational requirements. We introduce a method called Game Theory Assisted Pruning (GTAP), which reduces the neural network's size while preserving its predictive accuracy. GTAP is based on eliminating neurons in the network based on an estimation of their joint impact on the prediction quality through game theoretic solutions. Specifically, we use a power index akin to the Shapley value or Banzhaf index, tailored using a procedure similar to Dropout (commonly used to tackle overfitting problems in machine learning). Empirical evaluation of both feedforward networks and convolutional neural networks shows that this method outperforms existing approaches in the achieved tradeoff between the number of parameters and model accuracy.", "url": "https://arxiv.org/abs/2311.10468"}, {"metadata": {"arXiv": "2311.10471", "Date": "Fri, 17 Nov 2023 11:55:11 ", "Title": "Regions are Who Walk Them: a Large Pre-trained Spatiotemporal Model Based on Human Mobility for Ubiquitous Urban Sensing", "Authors": ["Ruixing Zhang", "Liangzhe Han", "Leilei Sun", "Yunqi Liu", "Jibin Wang", "Weifeng Lv"], "Categories": "cs.LG cs.AI", "Comments": ["8 pages"], "MSC-class": "68T30"}, "abstract": "User profiling and region analysis are two tasks of significant commercial value. However, in practical applications, modeling different features typically involves four main steps: data preparation, data processing, model establishment, evaluation, and optimization. This process is time-consuming and labor-intensive. Repeating this workflow for each feature results in abundant development time for tasks and a reduced overall volume of task development. Indeed, human mobility data contains a wealth of information. Several successful cases suggest that conducting in-depth analysis of population movement data could potentially yield meaningful profiles about users and areas. Nonetheless, most related works have not thoroughly utilized the semantic information within human mobility data and trained on a fixed number of the regions. To tap into the rich information within population movement, based on the perspective that Regions Are Who walk them, we propose a large spatiotemporal model based on trajectories (RAW). It possesses the following characteristics: 1) Tailored for trajectory data, introducing a GPT-like structure with a parameter count of up to 1B; 2) Introducing a spatiotemporal fine-tuning module, interpreting trajectories as collection of users to derive arbitrary region embedding. This framework allows rapid task development based on the large spatiotemporal model. We conducted extensive experiments to validate the effectiveness of our proposed large spatiotemporal model. It's evident that our proposed method, relying solely on human mobility data without additional features, exhibits a certain level of relevance in user profiling and region analysis. Moreover, our model showcases promising predictive capabilities in trajectory generation tasks based on the current state, offering the potential for further innovative work utilizing this large spatiotemporal model.", "url": "https://arxiv.org/abs/2311.10471"}, {"metadata": {"arXiv": "2311.10500", "Date": "Fri, 17 Nov 2023 13:01:09 ", "Title": "From Principle to Practice: Vertical Data Minimization for Machine Learning", "Authors": ["Robin Staab", "Nikola Jovanovi\\'c", "Mislav Balunovi\\'c", "Martin Vechev"], "Categories": "cs.LG cs.AI cs.CR", "Comments": ["Accepted at IEEE S&P 2024"]}, "abstract": "Aiming to train and deploy predictive models, organizations collect large amounts of detailed client data, risking the exposure of private information in the event of a breach. To mitigate this, policymakers increasingly demand compliance with the data minimization (DM) principle, restricting data collection to only that data which is relevant and necessary for the task. Despite regulatory pressure, the problem of deploying machine learning models that obey DM has so far received little attention. In this work, we address this challenge in a comprehensive manner. We propose a novel vertical DM (vDM) workflow based on data generalization, which by design ensures that no full-resolution client data is collected during training and deployment of models, benefiting client privacy by reducing the attack surface in case of a breach. We formalize and study the corresponding problem of finding generalizations that both maximize data utility and minimize empirical privacy risk, which we quantify by introducing a diverse set of policy-aligned adversarial scenarios. Finally, we propose a range of baseline vDM algorithms, as well as Privacy-aware Tree (PAT), an especially effective vDM algorithm that outperforms all baselines across several settings. We plan to release our code as a publicly available library, helping advance the standardization of DM for machine learning. Overall, we believe our work can help lay the foundation for further exploration and adoption of DM principles in real-world applications.", "url": "https://arxiv.org/abs/2311.10500"}, {"metadata": {"arXiv": "2311.10590", "Date": "Fri, 17 Nov 2023 15:45:00 ", "Title": "EduGym: An Environment Suite for Reinforcement Learning Education", "Authors": ["Thomas M. Moerland", "Matthias M\\\"uller-Brockhausen", "Zhao Yang", "Andrius Bernatavicius", "Koen Ponse", "Tom Kouwenhoven", "Andreas Sauter", "Michiel van der Meer", "Bram Renting", "Aske Plaat"], "Categories": "cs.LG cs.AI cs.CY stat.ML"}, "abstract": "Due to the empirical success of reinforcement learning, an increasing number of students study the subject. However, from our practical teaching experience, we see students entering the field (bachelor, master and early PhD) often struggle. On the one hand, textbooks and (online) lectures provide the fundamentals, but students find it hard to translate between equations and code. On the other hand, public codebases do provide practical examples, but the implemented algorithms tend to be complex, and the underlying test environments contain multiple reinforcement learning challenges at once. Although this is realistic from a research perspective, it often hinders educational conceptual understanding. To solve this issue we introduce EduGym, a set of educational reinforcement learning environments and associated interactive notebooks tailored for education. Each EduGym environment is specifically designed to illustrate a certain aspect/challenge of reinforcement learning (e.g., exploration, partial observability, stochasticity, etc.), while the associated interactive notebook explains the challenge and its possible solution approaches, connecting equations and code in a single document. An evaluation among RL students and researchers shows 86% of them think EduGym is a useful tool for reinforcement learning education. All notebooks are available from https://sites.google.com/view/edu-gym/home, while the full software package can be installed from https://github.com/RLG-Leiden/edugym.", "url": "https://arxiv.org/abs/2311.10590"}, {"metadata": {"arXiv": "2311.10638", "Date": "Fri, 17 Nov 2023 16:50:00 ", "Title": "Concept-free Causal Disentanglement with Variational Graph Auto-Encoder", "Authors": ["Jingyun Feng", "Lin Zhang", "Lili Yang"], "Categories": "cs.LG cs.AI stat.ME"}, "abstract": "In disentangled representation learning, the goal is to achieve a compact representation that consists of all interpretable generative factors in the observational data. Learning disentangled representations for graphs becomes increasingly important as graph data rapidly grows. Existing approaches often rely on Variational Auto-Encoder (VAE) or its causal structure learning-based refinement, which suffer from sub-optimality in VAEs due to the independence factor assumption and unavailability of concept labels, respectively. In this paper, we propose an unsupervised solution, dubbed concept-free causal disentanglement, built on a theoretically provable tight upper bound approximating the optimal factor. This results in an SCM-like causal structure modeling that directly learns concept structures from data. Based on this idea, we propose Concept-free Causal VGAE (CCVGAE) by incorporating a novel causal disentanglement layer into Variational Graph Auto-Encoder. Furthermore, we prove concept consistency under our concept-free causal disentanglement framework, hence employing it to enhance the meta-learning framework, called concept-free causal Meta-Graph (CC-Meta-Graph). We conduct extensive experiments to demonstrate the superiority of the proposed models: CCVGAE and CC-Meta-Graph, reaching up to $29\\%$ and $11\\%$ absolute improvements over baselines in terms of AUC, respectively.", "url": "https://arxiv.org/abs/2311.10638"}, {"metadata": {"arXiv": "2311.10671", "Date": "Fri, 17 Nov 2023 17:43:11 ", "Title": "Fuse It or Lose It: Deep Fusion for Multimodal Simulation-Based Inference", "Authors": ["Marvin Schmitt", "Stefan T. Radev", "Paul-Christian B\\\"urkner"], "Categories": "cs.LG cs.AI"}, "abstract": "We present multimodal neural posterior estimation (MultiNPE), a method to integrate heterogeneous data from different sources in simulation-based inference with neural networks. Inspired by advances in attention-based deep fusion learning, it empowers researchers to analyze data from different domains and infer the parameters of complex mathematical models with increased accuracy. We formulate different multimodal fusion approaches for MultiNPE (early, late, and hybrid) and evaluate their performance in three challenging numerical experiments. MultiNPE not only outperforms na\\\"ive baselines on a benchmark model, but also achieves superior inference on representative scientific models from neuroscience and cardiology. In addition, we systematically investigate the impact of partially missing data on the different fusion strategies. Across our different experiments, late and hybrid fusion techniques emerge as the methods of choice for practical applications of multimodal simulation-based inference.", "url": "https://arxiv.org/abs/2311.10671"}, {"metadata": {"arXiv": "2311.10699", "Date": "Fri, 17 Nov 2023 18:43:32 ", "Title": "Using linear initialisation to improve speed of convergence and fully-trained error in Autoencoders", "Authors": ["Marcel Marais", "Mate Hartstein", "George Cevora"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "Good weight initialisation is an important step in successful training of Artificial Neural Networks. Over time a number of improvements have been proposed to this process. In this paper we introduce a novel weight initialisation technique called the Straddled Matrix Initialiser. This initialisation technique is motivated by our assumption that major, global-scale relationships in data are linear with only smaller effects requiring complex non-linearities. Combination of Straddled Matrix and ReLU activation function initialises a Neural Network as a de facto linear model, which we postulate should be a better starting point for optimisation given our assumptions. We test this by training autoencoders on three datasets using Straddled Matrix and seven other state-of-the-art weight initialisation techniques. In all our experiments the Straddeled Matrix Initialiser clearly outperforms all other methods.", "url": "https://arxiv.org/abs/2311.10699"}, {"metadata": {"arXiv": "2311.10678", "Date": "Fri, 17 Nov 2023 18:00:20 ", "Title": "Distilling and Retrieving Generalizable Knowledge for Robot Manipulation via Language Corrections", "Authors": ["Lihan Zha", "Yuchen Cui", "Li-Heng Lin", "Minae Kwon", "Montserrat Gonzalez Arenas", "Andy Zeng", "Fei Xia", "Dorsa Sadigh"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["8 pages", "4 figures", "videos and code links on website https://sites.google.com/stanford.edu/droc"]}, "abstract": "Today's robot policies exhibit subpar performance when faced with the challenge of generalizing to novel environments. Human corrective feedback is a crucial form of guidance to enable such generalization. However, adapting to and learning from online human corrections is a non-trivial endeavor: not only do robots need to remember human feedback over time to retrieve the right information in new settings and reduce the intervention rate, but also they would need to be able to respond to feedback that can be arbitrary corrections about high-level human preferences to low-level adjustments to skill parameters. In this work, we present Distillation and Retrieval of Online Corrections (DROC), a large language model (LLM)-based system that can respond to arbitrary forms of language feedback, distill generalizable knowledge from corrections, and retrieve relevant past experiences based on textual and visual similarity for improving performance in novel settings. DROC is able to respond to a sequence of online language corrections that address failures in both high-level task plans and low-level skill primitives. We demonstrate that DROC effectively distills the relevant information from the sequence of online corrections in a knowledge base and retrieves that knowledge in settings with new task or object instances. DROC outperforms other techniques that directly generate robot code via LLMs by using only half of the total number of corrections needed in the first round and requires little to no corrections after two iterations. We show further results, videos, prompts and code on https://sites.google.com/stanford.edu/droc .", "url": "https://arxiv.org/abs/2311.10678"}, {"metadata": {"arXiv": "2311.10322", "Date": "Fri, 17 Nov 2023 04:24:52 ", "Title": "Clustering Techniques for Stable Linear Dynamical Systems with applications to Hard Disk Drives", "Authors": ["Nikhil Potu Surya Prakash", "Joohwan Seo", "Jongeun Choi and Roberto Horowitz"], "Categories": "eess.SY cs.AI cs.LG cs.SY math.DS math.OC", "Comments": ["6 pages", "4 figures"]}, "abstract": "In Robust Control and Data Driven Robust Control design methodologies, multiple plant transfer functions or a family of transfer functions are considered and a common controller is designed such that all the plants that fall into this family are stabilized. Though the plants are stabilized, the controller might be sub-optimal for each of the plants when the variations in the plants are large. This paper presents a way of clustering stable linear dynamical systems for the design of robust controllers within each of the clusters such that the controllers are optimal for each of the clusters. First a k-medoids algorithm for hard clustering will be presented for stable Linear Time Invariant (LTI) systems and then a Gaussian Mixture Models (GMM) clustering for a special class of LTI systems, common for Hard Disk Drive plants, will be presented.", "url": "https://arxiv.org/abs/2311.10322"}, {"metadata": {"arXiv": "2311.10607", "Date": "Fri, 17 Nov 2023 16:03:04 ", "Title": "Active Inference on the Edge: A Design Study", "Authors": ["Boris Sedlak", "Victor Casamayor Pujol", "Praveen Kumar Donta", "Schahram Dustdar"], "Categories": "eess.SY cs.AI cs.DC cs.LG cs.SY"}, "abstract": "Machine Learning (ML) is a common tool to interpret and predict the behavior of distributed computing systems, e.g., to optimize the task distribution between devices. As more and more data is created by Internet of Things (IoT) devices, data processing and ML training are carried out by edge devices in close proximity. To ensure Quality of Service (QoS) throughout these operations, systems are supervised and dynamically adapted with the help of ML. However, as long as ML models are not retrained, they fail to capture gradual shifts in the variable distribution, leading to an inaccurate view of the system state. Moreover, as the prediction accuracy decreases, the reporting device should actively resolve uncertainties to improve the model's precision. Such a level of self-determination could be provided by Active Inference (ACI) -- a concept from neuroscience that describes how the brain constantly predicts and evaluates sensory information to decrease long-term surprise. We encompassed these concepts in a single action-perception cycle, which we implemented for distributed agents in a smart manufacturing use case. As a result, we showed how our ACI agent was able to quickly and traceably solve an optimization problem while fulfilling QoS requirements.", "url": "https://arxiv.org/abs/2311.10607"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

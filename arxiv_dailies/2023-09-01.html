<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2308.16271", "Date": "Wed, 30 Aug 2023 19:02:17 ", "Title": "Emergence of Segmentation with Minimalistic White-Box Transformers", "Authors": ["Yaodong Yu", "Tianzhe Chu", "Shengbang Tong", "Ziyang Wu", "Druv Pai", "Sam Buchanan", "Yi Ma"], "Categories": "cs.CV cs.LG", "Comments": ["Code: https://github.com/Ma-Lab-Berkeley/CRATE"]}, "abstract": "Transformer-like models for vision tasks have recently proven effective for a wide range of downstream applications such as segmentation and detection. Previous works have shown that segmentation properties emerge in vision transformers (ViTs) trained using self-supervised methods such as DINO, but not in those trained on supervised classification tasks. In this study, we probe whether segmentation emerges in transformer-based models solely as a result of intricate self-supervised learning mechanisms, or if the same emergence can be achieved under much broader conditions through proper design of the model architecture. Through extensive experimental results, we demonstrate that when employing a white-box transformer-like architecture known as CRATE, whose design explicitly models and pursues low-dimensional structures in the data distribution, segmentation properties, at both the whole and parts levels, already emerge with a minimalistic supervised training recipe. Layer-wise finer-grained analysis reveals that the emergent properties strongly corroborate the designed mathematical functions of the white-box network. Our results suggest a path to design white-box foundation models that are simultaneously highly performant and mathematically fully interpretable. Code is at \\url{https://github.com/Ma-Lab-Berkeley/CRATE}.", "url": "https://arxiv.org/abs/2308.16271"}, {"metadata": {"arXiv": "2308.16274", "Date": "Wed, 30 Aug 2023 19:04:34 ", "Title": "Learning Diverse Features in Vision Transformers for Improved Generalization", "Authors": ["Armand Mihai Nicolicioiu", "Andrei Liviu Nicolicioiu", "Bogdan Alexe", "Damien Teney"], "Categories": "cs.CV cs.LG", "Comments": ["2023 ICML Workshop on Spurious Correlations", "Invariance and Stability"], "Report-no": "R01"}, "abstract": "Deep learning models often rely only on a small set of features even when there is a rich set of predictive signals in the training data. This makes models brittle and sensitive to distribution shifts. In this work, we first examine vision transformers (ViTs) and find that they tend to extract robust and spurious features with distinct attention heads. As a result of this modularity, their performance under distribution shifts can be significantly improved at test time by pruning heads corresponding to spurious features, which we demonstrate using an \"oracle selection\" on validation data. Second, we propose a method to further enhance the diversity and complementarity of the learned features by encouraging orthogonality of the attention heads' input gradients. We observe improved out-of-distribution performance on diagnostic benchmarks (MNIST-CIFAR, Waterbirds) as a consequence of the enhanced diversity of features and the pruning of undesirable heads.", "url": "https://arxiv.org/abs/2308.16274"}, {"metadata": {"arXiv": "2308.16454", "Date": "Thu, 31 Aug 2023 04:46:12 ", "Title": "Adversarial Finetuning with Latent Representation Constraint to Mitigate Accuracy-Robustness Tradeoff", "Authors": ["Satoshi Suzuki", "Shin'ya Yamaguchi", "Shoichiro Takeda", "Sekitoshi Kanai", "Naoki Makishima", "Atsushi Ando", "Ryo Masumura"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted by International Conference on Computer Vision (ICCV) 2023"]}, "abstract": "This paper addresses the tradeoff between standard accuracy on clean examples and robustness against adversarial examples in deep neural networks (DNNs). Although adversarial training (AT) improves robustness, it degrades the standard accuracy, thus yielding the tradeoff. To mitigate this tradeoff, we propose a novel AT method called ARREST, which comprises three components: (i) adversarial finetuning (AFT), (ii) representation-guided knowledge distillation (RGKD), and (iii) noisy replay (NR). AFT trains a DNN on adversarial examples by initializing its parameters with a DNN that is standardly pretrained on clean examples. RGKD and NR respectively entail a regularization term and an algorithm to preserve latent representations of clean examples during AFT. RGKD penalizes the distance between the representations of the standardly pretrained and AFT DNNs. NR switches input adversarial examples to nonadversarial ones when the representation changes significantly during AFT. By combining these components, ARREST achieves both high standard accuracy and robustness. Experimental results demonstrate that ARREST mitigates the tradeoff more effectively than previous AT-based methods do.", "url": "https://arxiv.org/abs/2308.16454"}, {"metadata": {"arXiv": "2308.16528", "Date": "Thu, 31 Aug 2023 08:19:26 ", "Title": "SA6D: Self-Adaptive Few-Shot 6D Pose Estimator for Novel and Occluded Objects", "Authors": ["Ning Gao", "Ngo Anh Vien", "Hanna Ziesche", "Gerhard Neumann"], "Categories": "cs.CV cs.LG cs.RO", "Journal-ref": "Conference on Robot Learning (CoRL), 2023"}, "abstract": "To enable meaningful robotic manipulation of objects in the real-world, 6D pose estimation is one of the critical aspects. Most existing approaches have difficulties to extend predictions to scenarios where novel object instances are continuously introduced, especially with heavy occlusions. In this work, we propose a few-shot pose estimation (FSPE) approach called SA6D, which uses a self-adaptive segmentation module to identify the novel target object and construct a point cloud model of the target object using only a small number of cluttered reference images. Unlike existing methods, SA6D does not require object-centric reference images or any additional object information, making it a more generalizable and scalable solution across categories. We evaluate SA6D on real-world tabletop object datasets and demonstrate that SA6D outperforms existing FSPE methods, particularly in cluttered scenes with occlusions, while requiring fewer reference images.", "url": "https://arxiv.org/abs/2308.16528"}, {"metadata": {"arXiv": "2308.16571", "Date": "Thu, 31 Aug 2023 09:12:34 ", "Title": "Document Layout Analysis on BaDLAD Dataset: A Comprehensive MViTv2 Based Approach", "Authors": ["Ashrafur Rahman Khan", "Asif Azad"], "Categories": "cs.CV cs.LG"}, "abstract": "In the rapidly evolving digital era, the analysis of document layouts plays a pivotal role in automated information extraction and interpretation. In our work, we have trained MViTv2 transformer model architecture with cascaded mask R-CNN on BaDLAD dataset to extract text box, paragraphs, images and tables from a document. After training on 20365 document images for 36 epochs in a 3 phase cycle, we achieved a training loss of 0.2125 and a mask loss of 0.19. Our work extends beyond training, delving into the exploration of potential enhancement avenues. We investigate the impact of rotation and flip augmentation, the effectiveness of slicing input images pre-inference, the implications of varying the resolution of the transformer backbone, and the potential of employing a dual-pass inference to uncover missed text-boxes. Through these explorations, we observe a spectrum of outcomes, where some modifications result in tangible performance improvements, while others offer unique insights for future endeavors.", "url": "https://arxiv.org/abs/2308.16571"}, {"metadata": {"arXiv": "2308.16648", "Date": "Thu, 31 Aug 2023 11:44:40 ", "Title": "Generate Your Own Scotland: Satellite Image Generation Conditioned on Maps", "Authors": ["Miguel Espinosa", "Elliot J. Crowley"], "Categories": "cs.CV cs.LG", "Comments": ["13 pages", "6 figures. preprint"]}, "abstract": "Despite recent advancements in image generation, diffusion models still remain largely underexplored in Earth Observation. In this paper we show that state-of-the-art pretrained diffusion models can be conditioned on cartographic data to generate realistic satellite images. We provide two large datasets of paired OpenStreetMap images and satellite views over the region of Mainland Scotland and the Central Belt. We train a ControlNet model and qualitatively evaluate the results, demonstrating that both image quality and map fidelity are possible. Finally, we provide some insights on the opportunities and challenges of applying these models for remote sensing. Our model weights and code for creating the dataset are publicly available at https://github.com/miquel-espinosa/map-sat.", "url": "https://arxiv.org/abs/2308.16648"}, {"metadata": {"arXiv": "2308.16847", "Date": "Thu, 31 Aug 2023 16:26:17 ", "Title": "Diffusion Models for Interferometric Satellite Aperture Radar", "Authors": ["Alexandre Tuel and Thomas Kerdreux and Claudia Hulbert and Bertrand Rouet-Leduc"], "Categories": "cs.CV cs.LG eess.IV"}, "abstract": "Probabilistic Diffusion Models (PDMs) have recently emerged as a very promising class of generative models, achieving high performance in natural image generation. However, their performance relative to non-natural images, like radar-based satellite data, remains largely unknown. Generating large amounts of synthetic (and especially labelled) satellite data is crucial to implement deep-learning approaches for the processing and analysis of (interferometric) satellite aperture radar data. Here, we leverage PDMs to generate several radar-based satellite image datasets. We show that PDMs succeed in generating images with complex and realistic structures, but that sampling time remains an issue. Indeed, accelerated sampling strategies, which work well on simple image datasets like MNIST, fail on our radar datasets. We provide a simple and versatile open-source https://github.com/thomaskerdreux/PDM_SAR_InSAR_generation to train, sample and evaluate PDMs using any dataset on a single GPU.", "url": "https://arxiv.org/abs/2308.16847"}, {"metadata": {"arXiv": "2308.16207", "Date": "Wed, 30 Aug 2023 04:49:24 ", "Title": "MASA-TCN: Multi-anchor Space-aware Temporal Convolutional Neural Networks for Continuous and Discrete EEG Emotion Recognition", "Authors": ["Yi Ding", "Su Zhang", "Chuangao Tang", "Cuntai Guan"], "Categories": "cs.LG", "Comments": ["11 pages", "4 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice", "after which this version may no longer be accessible"]}, "abstract": "Emotion recognition using electroencephalogram (EEG) mainly has two scenarios: classification of the discrete labels and regression of the continuously tagged labels. Although many algorithms were proposed for classification tasks, there are only a few methods for regression tasks. For emotion regression, the label is continuous in time. A natural method is to learn the temporal dynamic patterns. In previous studies, long short-term memory (LSTM) and temporal convolutional neural networks (TCN) were utilized to learn the temporal contextual information from feature vectors of EEG. However, the spatial patterns of EEG were not effectively extracted. To enable the spatial learning ability of TCN towards better regression and classification performances, we propose a novel unified model, named MASA-TCN, for EEG emotion regression and classification tasks. The space-aware temporal layer enables TCN to additionally learn from spatial relations among EEG electrodes. Besides, a novel multi-anchor block with attentive fusion is proposed to learn dynamic temporal dependencies. Experiments on two publicly available datasets show MASA-TCN achieves higher results than the state-of-the-art methods for both EEG emotion regression and classification tasks. The code is available at https://github.com/yi-ding-cs/MASA-TCN.", "url": "https://arxiv.org/abs/2308.16207"}, {"metadata": {"arXiv": "2308.16210", "Date": "Wed, 30 Aug 2023 09:08:46 ", "Title": "Deep Inductive Logic Programming meets Reinforcement Learning", "Authors": ["Andreas Bueff (University of Edinburgh)", "Vaishak Belle (University of Edinburgh)"], "Categories": "cs.LG cs.LO cs.SC", "Comments": ["In Proceedings ICLP 2023", "arXiv:2308.14898"], "Journal-ref": "EPTCS 385, 2023, pp. 339-352", "DOI": "10.4204/EPTCS.385.37"}, "abstract": "One approach to explaining the hierarchical levels of understanding within a machine learning model is the symbolic method of inductive logic programming (ILP), which is data efficient and capable of learning first-order logic rules that can entail data behaviour. A differentiable extension to ILP, so-called differentiable Neural Logic (dNL) networks, are able to learn Boolean functions as their neural architecture includes symbolic reasoning. We propose an application of dNL in the field of Relational Reinforcement Learning (RRL) to address dynamic continuous environments. This represents an extension of previous work in applying dNL-based ILP in RRL settings, as our proposed model updates the architecture to enable it to solve problems in continuous RL environments. The goal of this research is to improve upon current ILP methods for use in RRL by incorporating non-linear continuous predicates, allowing RRL agents to reason and make decisions in dynamic and continuous environments.", "url": "https://arxiv.org/abs/2308.16210"}, {"metadata": {"arXiv": "2308.16259", "Date": "Wed, 30 Aug 2023 18:34:55 ", "Title": "Materials Informatics Transformer: A Language Model for Interpretable Materials Properties Prediction", "Authors": ["Hongshuo Huang", "Rishikesh Magar", "Changwen Xu and Amir Bariti Farimani"], "Categories": "cs.LG cond-mat.mtrl-sci physics.chem-ph"}, "abstract": "Recently, the remarkable capabilities of large language models (LLMs) have been illustrated across a variety of research domains such as natural language processing, computer vision, and molecular modeling. We extend this paradigm by utilizing LLMs for material property prediction by introducing our model Materials Informatics Transformer (MatInFormer). Specifically, we introduce a novel approach that involves learning the grammar of crystallography through the tokenization of pertinent space group information. We further illustrate the adaptability of MatInFormer by incorporating task-specific data pertaining to Metal-Organic Frameworks (MOFs). Through attention visualization, we uncover the key features that the model prioritizes during property prediction. The effectiveness of our proposed model is empirically validated across 14 distinct datasets, hereby underscoring its potential for high throughput screening through accurate material property prediction.", "url": "https://arxiv.org/abs/2308.16259"}, {"metadata": {"arXiv": "2308.16279", "Date": "Wed, 30 Aug 2023 19:13:10 ", "Title": "Classification of Anomalies in Telecommunication Network KPI Time Series", "Authors": ["Korantin Bordeau-Aubert", "Justin Whatley", "Sylvain Nadeau", "Tristan Glatard", "Brigitte Jaumard"], "Categories": "cs.LG"}, "abstract": "The increasing complexity and scale of telecommunication networks have led to a growing interest in automated anomaly detection systems. However, the classification of anomalies detected on network Key Performance Indicators (KPI) has received less attention, resulting in a lack of information about anomaly characteristics and classification processes. To address this gap, this paper proposes a modular anomaly classification framework. The framework assumes separate entities for the anomaly classifier and the detector, allowing for a distinct treatment of anomaly detection and classification tasks on time series. The objectives of this study are (1) to develop a time series simulator that generates synthetic time series resembling real-world network KPI behavior, (2) to build a detection model to identify anomalies in the time series, (3) to build classification models that accurately categorize detected anomalies into predefined classes (4) to evaluate the classification framework performance on simulated and real-world network KPI time series. This study has demonstrated the good performance of the anomaly classification models trained on simulated anomalies when applied to real-world network time series data.", "url": "https://arxiv.org/abs/2308.16279"}, {"metadata": {"arXiv": "2308.16316", "Date": "Wed, 30 Aug 2023 20:46:45 ", "Title": "Ten Years of Generative Adversarial Nets (GANs): A survey of the state-of-the-art", "Authors": ["Tanujit Chakraborty", "Ujjwal Reddy K S", "Shraddha M. Naik", "Madhurima Panja", "Bayapureddy Manvitha"], "Categories": "cs.LG cs.CV"}, "abstract": "Since their inception in 2014, Generative Adversarial Networks (GANs) have rapidly emerged as powerful tools for generating realistic and diverse data across various domains, including computer vision and other applied areas. Consisting of a discriminative network and a generative network engaged in a Minimax game, GANs have revolutionized the field of generative modeling. In February 2018, GAN secured the leading spot on the ``Top Ten Global Breakthrough Technologies List'' issued by the Massachusetts Science and Technology Review. Over the years, numerous advancements have been proposed, leading to a rich array of GAN variants, such as conditional GAN, Wasserstein GAN, CycleGAN, and StyleGAN, among many others. This survey aims to provide a general overview of GANs, summarizing the latent architecture, validation metrics, and application areas of the most widely recognized variants. We also delve into recent theoretical developments, exploring the profound connection between the adversarial principle underlying GAN and Jensen-Shannon divergence, while discussing the optimality characteristics of the GAN framework. The efficiency of GAN variants and their model architectures will be evaluated along with training obstacles as well as training solutions. In addition, a detailed discussion will be provided, examining the integration of GANs with newly developed deep learning frameworks such as Transformers, Physics-Informed Neural Networks, Large Language models, and Diffusion models. Finally, we reveal several issues as well as future research outlines in this field.", "url": "https://arxiv.org/abs/2308.16316"}, {"metadata": {"arXiv": "2308.16369", "Date": "Thu, 31 Aug 2023 00:03:02 ", "Title": "SARATHI: Efficient LLM Inference by Piggybacking Decodes with Chunked Prefills", "Authors": ["Amey Agrawal", "Ashish Panwar", "Jayashree Mohan", "Nipun Kwatra", "Bhargav S. Gulavani", "Ramachandran Ramjee"], "Categories": "cs.LG cs.DC"}, "abstract": "Large Language Model (LLM) inference consists of two distinct phases - prefill phase which processes the input prompt and decode phase which generates output tokens autoregressively. While the prefill phase effectively saturates GPU compute at small batch sizes, the decode phase results in low compute utilization as it generates one token at a time per request. The varying prefill and decode times also lead to imbalance across micro-batches when using pipeline parallelism, resulting in further inefficiency due to bubbles. We present SARATHI to address these challenges. SARATHI employs chunked-prefills, which splits a prefill request into equal sized chunks, and decode-maximal batching, which constructs a batch using a single prefill chunk and populates the remaining slots with decodes. During inference, the prefill chunk saturates GPU compute, while the decode requests 'piggyback' and cost up to an order of magnitude less compared to a decode-only batch. Chunked-prefills allows constructing multiple decode-maximal batches from a single prefill request, maximizing coverage of decodes that can piggyback. Furthermore, the uniform compute design of these batches ameliorates the imbalance between micro-batches, significantly reducing pipeline bubbles. Our techniques yield significant improvements in inference performance across models and hardware. For the LLaMA-13B model on A6000 GPU, SARATHI improves decode throughput by up to 10x, and accelerates end-to-end throughput by up to 1.33x. For LLaMa-33B on A100 GPU, we achieve 1.25x higher end-to-end-throughput and up to 4.25x higher decode throughput. When used with pipeline parallelism on GPT-3, SARATHI reduces bubbles by 6.29x, resulting in an end-to-end throughput improvement of 1.91x.", "url": "https://arxiv.org/abs/2308.16369"}, {"metadata": {"arXiv": "2308.16379", "Date": "Thu, 31 Aug 2023 00:47:58 ", "Title": "Multi-Objective Decision Transformers for Offline Reinforcement Learning", "Authors": ["Abdelghani Ghanem", "Philippe Ciblat", "Mounir Ghogho"], "Categories": "cs.LG cs.RO"}, "abstract": "Offline Reinforcement Learning (RL) is structured to derive policies from static trajectory data without requiring real-time environment interactions. Recent studies have shown the feasibility of framing offline RL as a sequence modeling task, where the sole aim is to predict actions based on prior context using the transformer architecture. However, the limitation of this single task learning approach is its potential to undermine the transformer model's attention mechanism, which should ideally allocate varying attention weights across different tokens in the input context for optimal prediction. To address this, we reformulate offline RL as a multi-objective optimization problem, where the prediction is extended to states and returns. We also highlight a potential flaw in the trajectory representation used for sequence modeling, which could generate inaccuracies when modeling the state and return distributions. This is due to the non-smoothness of the action distribution within the trajectory dictated by the behavioral policy. To mitigate this issue, we introduce action space regions to the trajectory representation. Our experiments on D4RL benchmark locomotion tasks reveal that our propositions allow for more effective utilization of the attention mechanism in the transformer model, resulting in performance that either matches or outperforms current state-of-the art methods.", "url": "https://arxiv.org/abs/2308.16379"}, {"metadata": {"arXiv": "2308.16406", "Date": "Thu, 31 Aug 2023 02:20:25 ", "Title": "CktGNN: Circuit Graph Neural Network for Electronic Design Automation", "Authors": ["Zehao Dong", "Weidong Cao", "Muhan Zhang", "Dacheng Tao", "Yixin Chen", "Xuan Zhang"], "Categories": "cs.LG", "Comments": ["Accepted by ICLR (International Conference on Learning Representations) 2023"]}, "abstract": "The electronic design automation of analog circuits has been a longstanding challenge in the integrated circuit field due to the huge design space and complex design trade-offs among circuit specifications. In the past decades, intensive research efforts have mostly been paid to automate the transistor sizing with a given circuit topology. By recognizing the graph nature of circuits, this paper presents a Circuit Graph Neural Network (CktGNN) that simultaneously automates the circuit topology generation and device sizing based on the encoder-dependent optimization subroutines. Particularly, CktGNN encodes circuit graphs using a two-level GNN framework (of nested GNN) where circuits are represented as combinations of subgraphs in a known subgraph basis. In this way, it significantly improves design efficiency by reducing the number of subgraphs to perform message passing. Nonetheless, another critical roadblock to advancing learning-assisted circuit design automation is a lack of public benchmarks to perform canonical assessment and reproducible research. To tackle the challenge, we introduce Open Circuit Benchmark (OCB), an open-sourced dataset that contains $10$K distinct operational amplifiers with carefully-extracted circuit specifications. OCB is also equipped with communicative circuit generation and evaluation capabilities such that it can help to generalize CktGNN to design various analog circuits by producing corresponding datasets. Experiments on OCB show the extraordinary advantages of CktGNN through representation-based optimization frameworks over other recent powerful GNN baselines and human experts' manual designs. Our work paves the way toward a learning-based open-sourced design automation for analog circuits. Our source code is available at \\url{https://github.com/zehao-dong/CktGNN}.", "url": "https://arxiv.org/abs/2308.16406"}, {"metadata": {"arXiv": "2308.16425", "Date": "Thu, 31 Aug 2023 03:28:43 ", "Title": "On the Equivalence between Implicit and Explicit Neural Networks: A High-dimensional Viewpoint", "Authors": ["Zenan Ling", "Zhenyu Liao", "Robert C. Qiu"], "Categories": "cs.LG stat.ML", "Comments": ["Accepted by Workshop on High-dimensional Learning Dynamics", "ICML 2023", "Honolulu", "Hawaii"]}, "abstract": "Implicit neural networks have demonstrated remarkable success in various tasks. However, there is a lack of theoretical analysis of the connections and differences between implicit and explicit networks. In this paper, we study high-dimensional implicit neural networks and provide the high dimensional equivalents for the corresponding conjugate kernels and neural tangent kernels. Built upon this, we establish the equivalence between implicit and explicit networks in high dimensions.", "url": "https://arxiv.org/abs/2308.16425"}, {"metadata": {"arXiv": "2308.16470", "Date": "Thu, 31 Aug 2023 05:26:08 ", "Title": "Domain-adaptive Message Passing Graph Neural Network", "Authors": ["Xiao Shen", "Shirui Pan", "Kup-Sze Choi", "Xi Zhou"], "Categories": "cs.LG", "Journal-ref": "Neural Networks 164 (2023): 439-454", "DOI": "10.1016/j.neunet.2023.04.038"}, "abstract": "Cross-network node classification (CNNC), which aims to classify nodes in a label-deficient target network by transferring the knowledge from a source network with abundant labels, draws increasing attention recently. To address CNNC, we propose a domain-adaptive message passing graph neural network (DM-GNN), which integrates graph neural network (GNN) with conditional adversarial domain adaptation. DM-GNN is capable of learning informative representations for node classification that are also transferrable across networks. Firstly, a GNN encoder is constructed by dual feature extractors to separate ego-embedding learning from neighbor-embedding learning so as to jointly capture commonality and discrimination between connected nodes. Secondly, a label propagation node classifier is proposed to refine each node's label prediction by combining its own prediction and its neighbors' prediction. In addition, a label-aware propagation scheme is devised for the labeled source network to promote intra-class propagation while avoiding inter-class propagation, thus yielding label-discriminative source embeddings. Thirdly, conditional adversarial domain adaptation is performed to take the neighborhood-refined class-label information into account during adversarial domain adaptation, so that the class-conditional distributions across networks can be better matched. Comparisons with eleven state-of-the-art methods demonstrate the effectiveness of the proposed DM-GNN.", "url": "https://arxiv.org/abs/2308.16470"}, {"metadata": {"arXiv": "2308.16541", "Date": "Thu, 31 Aug 2023 08:30:26 ", "Title": "Scalable Incomplete Multi-View Clustering with Structure Alignment", "Authors": ["Yi Wen", "Siwei Wang", "Ke Liang", "Weixuan Liang", "Xinhang Wan", "Xinwang Liu", "Suyuan Liu", "Jiyuan Liu", "En Zhu"], "Categories": "cs.LG", "DOI": "10.1145/3581783.3611981"}, "abstract": "The success of existing multi-view clustering (MVC) relies on the assumption that all views are complete. However, samples are usually partially available due to data corruption or sensor malfunction, which raises the research of incomplete multi-view clustering (IMVC). Although several anchor-based IMVC methods have been proposed to process the large-scale incomplete data, they still suffer from the following drawbacks: i) Most existing approaches neglect the inter-view discrepancy and enforce cross-view representation to be consistent, which would corrupt the representation capability of the model; ii) Due to the samples disparity between different views, the learned anchor might be misaligned, which we referred as the Anchor-Unaligned Problem for Incomplete data (AUP-ID). Such the AUP-ID would cause inaccurate graph fusion and degrades clustering performance. To tackle these issues, we propose a novel incomplete anchor graph learning framework termed Scalable Incomplete Multi-View Clustering with Structure Alignment (SIMVC-SA). Specially, we construct the view-specific anchor graph to capture the complementary information from different views. In order to solve the AUP-ID, we propose a novel structure alignment module to refine the cross-view anchor correspondence. Meanwhile, the anchor graph construction and alignment are jointly optimized in our unified framework to enhance clustering quality. Through anchor graph construction instead of full graphs, the time and space complexity of the proposed SIMVC-SA is proven to be linearly correlated with the number of samples. Extensive experiments on seven incomplete benchmark datasets demonstrate the effectiveness and efficiency of our proposed method. Our code is publicly available at https://github.com/wy1019/SIMVC-SA.", "url": "https://arxiv.org/abs/2308.16541"}, {"metadata": {"arXiv": "2308.16544", "Date": "Thu, 31 Aug 2023 08:34:20 ", "Title": "Forecasting Emergency Department Crowding with Advanced Machine Learning Models and Multivariable Input", "Authors": ["Jalmari Tuominen", "Eetu Pulkkinen", "Jaakko Peltonen", "Juho Kanniainen", "Niku Oksala", "Ari Palom\\\"aki", "Antti Roine"], "Categories": "cs.LG stat.ML"}, "abstract": "Emergency department (ED) crowding is a significant threat to patient safety and it has been repeatedly associated with increased mortality. Forecasting future service demand has the potential patient outcomes. Despite active research on the subject, several gaps remain: 1) proposed forecasting models have become outdated due to quick influx of advanced machine learning models (ML), 2) amount of multivariable input data has been limited and 3) discrete performance metrics have been rarely reported. In this study, we document the performance of a set of advanced ML models in forecasting ED occupancy 24 hours ahead. We use electronic health record data from a large, combined ED with an extensive set of explanatory variables, including the availability of beds in catchment area hospitals, traffic data from local observation stations, weather variables, etc. We show that N-BEATS and LightGBM outpeform benchmarks with 11 % and 9 % respective improvements and that DeepAR predicts next day crowding with an AUC of 0.76 (95 % CI 0.69-0.84). To the best of our knowledge, this is the first study to document the superiority of LightGBM and N-BEATS over statistical benchmarks in the context of ED forecasting.", "url": "https://arxiv.org/abs/2308.16544"}, {"metadata": {"arXiv": "2308.16585", "Date": "Thu, 31 Aug 2023 09:30:06 ", "Title": "Development and validation of an interpretable machine learning-based calculator for predicting 5-year weight trajectories after bariatric surgery: a multinational retrospective cohort SOPHIA study", "Authors": ["Patrick Saux (Scool", "CRIStAL)", "Pierre Bauvin", "Violeta Raverdy", "Julien Teigny (Scool)", "H\\'el\\`ene Verkindt", "Tomy Soumphonphakdy (Scool)", "Maxence Debert (Scool)", "Anne Jacobs", "Daan Jacobs", "Valerie Monpellier", "Phong Ching Lee", "Chin Hong Lim", "Johanna C Andersson-Assarsson", "Lena Carlsson", "Per-Arne Svensson", "Florence Galtier", "Guelareh Dezfoulian", "Mihaela Moldovanu", "Severine Andrieux", "Julien Couster", "Marie Lepage", "Erminia Lembo", "Ornella Verrastro", "Maud Robert", "Paulina Salminen", "Geltrude Mingrone", "Ralph Peterli", "Ricardo V Cohen", "Carlos Zerrweck", "David Nocca", "Carel W Le Roux", "Robert Caiazzo", "Philippe Preux (Scool", "CRIStAL)", "Fran\\c{c}ois Pattou"], "Categories": "cs.LG stat.AP", "Comments": ["The Lancet Digital Health", "2023"], "DOI": "10.1016/S2589-7500(23)00135-8"}, "abstract": "Background Weight loss trajectories after bariatric surgery vary widely between individuals, and predicting weight loss before the operation remains challenging. We aimed to develop a model using machine learning to provide individual preoperative prediction of 5-year weight loss trajectories after surgery. Methods In this multinational retrospective observational study we enrolled adult participants (aged $\\ge$18 years) from ten prospective cohorts (including ABOS [NCT01129297], BAREVAL [NCT02310178], the Swedish Obese Subjects study, and a large cohort from the Dutch Obesity Clinic [Nederlandse Obesitas Kliniek]) and two randomised trials (SleevePass [NCT00793143] and SM-BOSS [NCT00356213]) in Europe, the Americas, and Asia, with a 5 year followup after Roux-en-Y gastric bypass, sleeve gastrectomy, or gastric band. Patients with a previous history of bariatric surgery or large delays between scheduled and actual visits were excluded. The training cohort comprised patients from two centres in France (ABOS and BAREVAL). The primary outcome was BMI at 5 years. A model was developed using least absolute shrinkage and selection operator to select variables and the classification and regression trees algorithm to build interpretable regression trees. The performances of the model were assessed through the median absolute deviation (MAD) and root mean squared error (RMSE) of BMI. Findings10 231 patients from 12 centres in ten countries were included in the analysis, corresponding to 30 602 patient-years. Among participants in all 12 cohorts, 7701 (75$\\bullet$3%) were female, 2530 (24$\\bullet$7%) were male. Among 434 baseline attributes available in the training cohort, seven variables were selected: height, weight, intervention type, age, diabetes status, diabetes duration, and smoking status. At 5 years, across external testing cohorts the overall mean MAD BMI was 2$\\bullet$8 kg/m${}^2$ (95% CI 2$\\bullet$6-3$\\bullet$0) and mean RMSE BMI was 4$\\bullet$7 kg/m${}^2$ (4$\\bullet$4-5$\\bullet$0), and the mean difference between predicted and observed BMI was-0$\\bullet$3 kg/m${}^2$ (SD 4$\\bullet$7). This model is incorporated in an easy to use and interpretable web-based prediction tool to help inform clinical decision before surgery. InterpretationWe developed a machine learning-based model, which is internationally validated, for predicting individual 5-year weight loss trajectories after three common bariatric interventions.", "url": "https://arxiv.org/abs/2308.16585"}, {"metadata": {"arXiv": "2308.16599", "Date": "Thu, 31 Aug 2023 09:57:52 ", "Title": "A Causal Discovery Approach To Learn How Urban Form Shapes Sustainable Mobility Across Continents", "Authors": ["Felix Wagner and Florian Nachtigall and Lukas Franken and Nikola Milojevic-Dupont and Rafael H.M. Pereira and Nicolas Koch and Jakob Runge and Marta Gonzalez and Felix Creutzig"], "Categories": "cs.LG physics.soc-ph", "Comments": ["22 pages", "13 figures", "4 tables"]}, "abstract": "Global sustainability requires low-carbon urban transport systems, shaped by adequate infrastructure, deployment of low-carbon transport modes and shifts in travel behavior. To adequately implement alterations in infrastructure, it's essential to grasp the location-specific cause-and-effect mechanisms that the constructed environment has on travel. Yet, current research falls short in representing causal relationships between the 6D urban form variables and travel, generalizing across different regions, and modeling urban form effects at high spatial resolution. Here, we address all three gaps by utilizing a causal discovery and an explainable machine learning framework to detect urban form effects on intra-city travel based on high-resolution mobility data of six cities across three continents. We show that both distance to city center, demographics and density indirectly affect other urban form features. By considering the causal relationships, we find that location-specific influences align across cities, yet vary in magnitude. In addition, the spread of the city and the coverage of jobs across the city are the strongest determinants of travel-related emissions, highlighting the benefits of compact development and associated benefits. Differences in urban form effects across the cities call for a more holistic definition of 6D measures. Our work is a starting point for location-specific analysis of urban form effects on mobility behavior using causal discovery approaches, which is highly relevant for city planners and municipalities across continents.", "url": "https://arxiv.org/abs/2308.16599"}, {"metadata": {"arXiv": "2308.16671", "Date": "Thu, 31 Aug 2023 12:22:40 ", "Title": "Communication-Efficient Decentralized Federated Learning via One-Bit Compressive Sensing", "Authors": ["Shenglong Zhou", "Kaidi Xu", "Geoffrey Ye Li"], "Categories": "cs.LG"}, "abstract": "Decentralized federated learning (DFL) has gained popularity due to its practicality across various applications. Compared to the centralized version, training a shared model among a large number of nodes in DFL is more challenging, as there is no central server to coordinate the training process. Especially when distributed nodes suffer from limitations in communication or computational resources, DFL will experience extremely inefficient and unstable training. Motivated by these challenges, in this paper, we develop a novel algorithm based on the framework of the inexact alternating direction method (iADM). On one hand, our goal is to train a shared model with a sparsity constraint. This constraint enables us to leverage one-bit compressive sensing (1BCS), allowing transmission of one-bit information among neighbour nodes. On the other hand, communication between neighbour nodes occurs only at certain steps, reducing the number of communication rounds. Therefore, the algorithm exhibits notable communication efficiency. Additionally, as each node selects only a subset of neighbours to participate in the training, the algorithm is robust against stragglers. Additionally, complex items are computed only once for several consecutive steps and subproblems are solved inexactly using closed-form solutions, resulting in high computational efficiency. Finally, numerical experiments showcase the algorithm's effectiveness in both communication and computation.", "url": "https://arxiv.org/abs/2308.16671"}, {"metadata": {"arXiv": "2308.16718", "Date": "Thu, 31 Aug 2023 13:37:28 ", "Title": "Robust Representation Learning for Unreliable Partial Label Learning", "Authors": ["Yu Shi", "Dong-Dong Wu", "Xin Geng", "Min-Ling Zhang"], "Categories": "cs.LG"}, "abstract": "Partial Label Learning (PLL) is a type of weakly supervised learning where each training instance is assigned a set of candidate labels, but only one label is the ground-truth. However, this idealistic assumption may not always hold due to potential annotation inaccuracies, meaning the ground-truth may not be present in the candidate label set. This is known as Unreliable Partial Label Learning (UPLL) that introduces an additional complexity due to the inherent unreliability and ambiguity of partial labels, often resulting in a sub-optimal performance with existing methods. To address this challenge, we propose the Unreliability-Robust Representation Learning framework (URRL) that leverages unreliability-robust contrastive learning to help the model fortify against unreliable partial labels effectively. Concurrently, we propose a dual strategy that combines KNN-based candidate label set correction and consistency-regularization-based label disambiguation to refine label quality and enhance the ability of representation learning within the URRL framework. Extensive experiments demonstrate that the proposed method outperforms state-of-the-art PLL methods on various datasets with diverse degrees of unreliability and ambiguity. Furthermore, we provide a theoretical analysis of our approach from the perspective of the expectation maximization (EM) algorithm. Upon acceptance, we pledge to make the code publicly accessible.", "url": "https://arxiv.org/abs/2308.16718"}, {"metadata": {"arXiv": "2308.16759", "Date": "Thu, 31 Aug 2023 14:27:36 ", "Title": "Constructing Indoor Region-based Radio Map without Location Labels", "Authors": ["Zheng Xing and Junting Chen"], "Categories": "cs.LG eess.SP"}, "abstract": "Radio map construction requires a large amount of radio measurement data with location labels, which imposes a high deployment cost. This paper develops a region-based radio map from received signal strength (RSS) measurements without location labels. The construction is based on a set of blindly collected RSS measurement data from a device that visits each region in an indoor area exactly once, where the footprints and timestamps are not recorded. The main challenge is to cluster the RSS data and match clusters with the physical regions. Classical clustering algorithms fail to work as the RSS data naturally appears as non-clustered due to multipaths and noise. In this paper, a signal subspace model with a sequential prior is constructed for the RSS data, and an integrated segmentation and clustering algorithm is developed, which is shown to find the globally optimal solution in a special case. Furthermore, the clustered data is matched with the physical regions using a graph-based approach. Based on real measurements from an office space, the proposed scheme reduces the region localization error by roughly 50% compared to a weighted centroid localization (WCL) baseline, and it even outperforms some supervised localization schemes, including k-nearest neighbor (KNN), support vector machine (SVM), and deep neural network (DNN), which require labeled data for training.", "url": "https://arxiv.org/abs/2308.16759"}, {"metadata": {"arXiv": "2308.16835", "Date": "Thu, 31 Aug 2023 16:10:22 ", "Title": "FedDD: Toward Communication-efficient Federated Learning with Differential Parameter Dropout", "Authors": ["Zhiying Feng", "Xu Chen", "Qiong Wu", "Wen Wu", "Xiaoxi Zhang", "and Qianyi Huang"], "Categories": "cs.LG cs.DC"}, "abstract": "Federated Learning (FL) requires frequent exchange of model parameters, which leads to long communication delay, especially when the network environments of clients vary greatly. Moreover, the parameter server needs to wait for the slowest client (i.e., straggler, which may have the largest model size, lowest computing capability or worst network condition) to upload parameters, which may significantly degrade the communication efficiency. Commonly-used client selection methods such as partial client selection would lead to the waste of computing resources and weaken the generalization of the global model. To tackle this problem, along a different line, in this paper, we advocate the approach of model parameter dropout instead of client selection, and accordingly propose a novel framework of Federated learning scheme with Differential parameter Dropout (FedDD). FedDD consists of two key modules: dropout rate allocation and uploaded parameter selection, which will optimize the model parameter uploading ratios tailored to different clients' heterogeneous conditions and also select the proper set of important model parameters for uploading subject to clients' dropout rate constraints. Specifically, the dropout rate allocation is formulated as a convex optimization problem, taking system heterogeneity, data heterogeneity, and model heterogeneity among clients into consideration. The uploaded parameter selection strategy prioritizes on eliciting important parameters for uploading to speedup convergence. Furthermore, we theoretically analyze the convergence of the proposed FedDD scheme. Extensive performance evaluations demonstrate that the proposed FedDD scheme can achieve outstanding performances in both communication efficiency and model convergence, and also possesses a strong generalization capability to data of rare classes.", "url": "https://arxiv.org/abs/2308.16835"}, {"metadata": {"arXiv": "2308.16858", "Date": "Thu, 31 Aug 2023 17:03:16 ", "Title": "Majorization-Minimization for sparse SVMs", "Authors": ["Alessandro Benfenati", "Emilie Chouzenoux", "Giorgia Franchini", "Salla Latva-Aijo", "Dominik Narnhofer", "Jean-Christophe Pesquet", "Sebastian J. Scott", "Mahsa Yousefi"], "Categories": "cs.LG math.OC"}, "abstract": "Several decades ago, Support Vector Machines (SVMs) were introduced for performing binary classification tasks, under a supervised framework. Nowadays, they often outperform other supervised methods and remain one of the most popular approaches in the machine learning arena. In this work, we investigate the training of SVMs through a smooth sparse-promoting-regularized squared hinge loss minimization. This choice paves the way to the application of quick training methods built on majorization-minimization approaches, benefiting from the Lipschitz differentiabililty of the loss function. Moreover, the proposed approach allows us to handle sparsity-preserving regularizers promoting the selection of the most significant features, so enhancing the performance. Numerical tests and comparisons conducted on three different datasets demonstrate the good performance of the proposed methodology in terms of qualitative metrics (accuracy, precision, recall, and F 1 score) as well as computational cost.", "url": "https://arxiv.org/abs/2308.16858"}, {"metadata": {"arXiv": "2308.16889", "Date": "Thu, 31 Aug 2023 17:50:54 ", "Title": "Federated Learning in UAV-Enhanced Networks: Joint Coverage and Convergence Time Optimization", "Authors": ["Mariam Yahya", "Setareh Maghsudi", "and Slawomir Stanczak"], "Categories": "cs.LG cs.NI"}, "abstract": "Federated learning (FL) involves several devices that collaboratively train a shared model without transferring their local data. FL reduces the communication overhead, making it a promising learning method in UAV-enhanced wireless networks with scarce energy resources. Despite the potential, implementing FL in UAV-enhanced networks is challenging, as conventional UAV placement methods that maximize coverage increase the FL delay significantly. Moreover, the uncertainty and lack of a priori information about crucial variables, such as channel quality, exacerbate the problem. In this paper, we first analyze the statistical characteristics of a UAV-enhanced wireless sensor network (WSN) with energy harvesting. We then develop a model and solution based on the multi-objective multi-armed bandit theory to maximize the network coverage while minimizing the FL delay. Besides, we propose another solution that is particularly useful with large action sets and strict energy constraints at the UAVs. Our proposal uses a scalarized best-arm identification algorithm to find the optimal arms that maximize the ratio of the expected reward to the expected energy cost by sequentially eliminating one or more arms in each round. Then, we derive the upper bound on the error probability of our multi-objective and cost-aware algorithm. Numerical results show the effectiveness of our approach.", "url": "https://arxiv.org/abs/2308.16889"}, {"metadata": {"arXiv": "2308.16900", "Date": "Thu, 31 Aug 2023 17:58:28 ", "Title": "Learning to Taste: A Multimodal Wine Dataset", "Authors": ["Thoranna Bender", "Simon M{\\o}e S{\\o}rensen", "Alireza Kashani", "K. Eldjarn Hjorleifsson", "Grethe Hyldig", "S{\\o}ren Hauberg", "Serge Belongie and Frederik Warburg"], "Categories": "cs.LG"}, "abstract": "We present WineSensed, a large multimodal wine dataset for studying the relations between visual perception, language, and flavor. The dataset encompasses 897k images of wine labels and 824k reviews of wines curated from the Vivino platform. It has over 350k unique vintages, annotated with year, region, rating, alcohol percentage, price, and grape composition. We obtained fine-grained flavor annotations on a subset by conducting a wine-tasting experiment with 256 participants who were asked to rank wines based on their similarity in flavor, resulting in more than 5k pairwise flavor distances. We propose a low-dimensional concept embedding algorithm that combines human experience with automatic machine similarity kernels. We demonstrate that this shared concept embedding space improves upon separate embedding spaces for coarse flavor classification (alcohol percentage, country, grape, price, rating) and aligns with the intricate human perception of flavor.", "url": "https://arxiv.org/abs/2308.16900"}, {"metadata": {"arXiv": "2308.16471", "Date": "Thu, 31 Aug 2023 05:26:14 ", "Title": "A Policy Adaptation Method for Implicit Multitask Reinforcement Learning Problems", "Authors": ["Satoshi Yamamori", "Jun Morimoto"], "Categories": "cs.RO cs.LG", "Comments": ["12 pages", "9 figures"]}, "abstract": "In dynamic motion generation tasks, including contact and collisions, small changes in policy parameters can lead to extremely different returns. For example, in soccer, the ball can fly in completely different directions with a similar heading motion by slightly changing the hitting position or the force applied to the ball or when the friction of the ball varies. However, it is difficult to imagine that completely different skills are needed for heading a ball in different directions. In this study, we proposed a multitask reinforcement learning algorithm for adapting a policy to implicit changes in goals or environments in a single motion category with different reward functions or physical parameters of the environment. We evaluated the proposed method on the ball heading task using a monopod robot model. The results showed that the proposed method can adapt to implicit changes in the goal positions or the coefficients of restitution of the ball, whereas the standard domain randomization approach cannot cope with different task settings.", "url": "https://arxiv.org/abs/2308.16471"}, {"metadata": {"arXiv": "2308.16891", "Date": "Thu, 31 Aug 2023 17:52:10 ", "Title": "GNFactor: Multi-Task Real Robot Learning with Generalizable Neural Feature Fields", "Authors": ["Yanjie Ze", "Ge Yan", "Yueh-Hua Wu", "Annabella Macaluso", "Yuying Ge", "Jianglong Ye", "Nicklas Hansen", "Li Erran Li", "Xiaolong Wang"], "Categories": "cs.RO cs.CV cs.LG", "Comments": ["CoRL 2023 Oral. Website: https://yanjieze.com/GNFactor/"]}, "abstract": "It is a long-standing problem in robotics to develop agents capable of executing diverse manipulation tasks from visual observations in unstructured real-world environments. To achieve this goal, the robot needs to have a comprehensive understanding of the 3D structure and semantics of the scene. In this work, we present $\\textbf{GNFactor}$, a visual behavior cloning agent for multi-task robotic manipulation with $\\textbf{G}$eneralizable $\\textbf{N}$eural feature $\\textbf{F}$ields. GNFactor jointly optimizes a generalizable neural field (GNF) as a reconstruction module and a Perceiver Transformer as a decision-making module, leveraging a shared deep 3D voxel representation. To incorporate semantics in 3D, the reconstruction module utilizes a vision-language foundation model ($\\textit{e.g.}$, Stable Diffusion) to distill rich semantic information into the deep 3D voxel. We evaluate GNFactor on 3 real robot tasks and perform detailed ablations on 10 RLBench tasks with a limited number of demonstrations. We observe a substantial improvement of GNFactor over current state-of-the-art methods in seen and unseen tasks, demonstrating the strong generalization ability of GNFactor. Our project website is https://yanjieze.com/GNFactor/ .", "url": "https://arxiv.org/abs/2308.16891"}, {"metadata": {"arXiv": "2308.16262", "Date": "Wed, 30 Aug 2023 18:43:11 ", "Title": "Causal Strategic Learning with Competitive Selection", "Authors": ["Kiet Q. H. Vo", "Muneeb Aadil", "Siu Lun Chau", "Krikamol Muandet"], "Categories": "cs.AI"}, "abstract": "We study the problem of agent selection in causal strategic learning under multiple decision makers and address two key challenges that come with it. Firstly, while much of prior work focuses on studying a fixed pool of agents that remains static regardless of their evaluations, we consider the impact of selection procedure by which agents are not only evaluated, but also selected. When each decision maker unilaterally selects agents by maximising their own utility, we show that the optimal selection rule is a trade-off between selecting the best agents and providing incentives to maximise the agents' improvement. Furthermore, this optimal selection rule relies on incorrect predictions of agents' outcomes. Hence, we study the conditions under which a decision maker's optimal selection rule will not lead to deterioration of agents' outcome nor cause unjust reduction in agents' selection chance. To that end, we provide an analytical form of the optimal selection rule and a mechanism to retrieve the causal parameters from observational data, under certain assumptions on agents' behaviour. Secondly, when there are multiple decision makers, the interference between selection rules introduces another source of biases in estimating the underlying causal parameters. To address this problem, we provide a cooperative protocol which all decision makers must collectively adopt to recover the true causal parameters. Lastly, we complement our theoretical results with simulation studies. Our results highlight not only the importance of causal modeling as a strategy to mitigate the effect of gaming, as suggested by previous work, but also the need of a benevolent regulator to enable it.", "url": "https://arxiv.org/abs/2308.16262"}, {"metadata": {"arXiv": "2308.16328", "Date": "Wed, 30 Aug 2023 21:25:31 ", "Title": "Debunking Disinformation: Revolutionizing Truth with NLP in Fake News Detection", "Authors": ["Li He", "Siyi Hu", "Ailun Pei"], "Categories": "cs.AI", "Comments": ["11 pages"]}, "abstract": "The Internet and social media have altered how individuals access news in the age of instantaneous information distribution. While this development has increased access to information, it has also created a significant problem: the spread of fake news and information. Fake news is rapidly spreading on digital platforms, which has a negative impact on the media ecosystem, public opinion, decision-making, and social cohesion. Natural Language Processing(NLP), which offers a variety of approaches to identify content as authentic, has emerged as a potent weapon in the growing war against disinformation. This paper takes an in-depth look at how NLP technology can be used to detect fake news and reveals the challenges and opportunities it presents.", "url": "https://arxiv.org/abs/2308.16328"}, {"metadata": {"arXiv": "2308.16361", "Date": "Wed, 30 Aug 2023 23:28:43 ", "Title": "Large Language Models as Data Preprocessors", "Authors": ["Haochen Zhang", "Yuyang Dong", "Chuan Xiao", "Masafumi Oyamada"], "Categories": "cs.AI cs.DB"}, "abstract": "Large Language Models (LLMs), typified by OpenAI's GPT series and Meta's LLaMA variants, have marked a significant advancement in artificial intelligence. Trained on vast amounts of text data, LLMs are capable of understanding and generating human-like text across a diverse range of topics. This study expands on the applications of LLMs, exploring their potential in data preprocessing, a critical stage in data mining and analytics applications. We delve into the applicability of state-of-the-art LLMs such as GPT-3.5, GPT-4, and Vicuna-13B for error detection, data imputation, schema matching, and entity matching tasks. Alongside showcasing the inherent capabilities of LLMs, we highlight their limitations, particularly in terms of computational expense and inefficiency. We propose an LLM-based framework for data preprocessing, which integrates cutting-edge prompt engineering techniques, coupled with traditional methods like contextualization and feature selection, to improve the performance and efficiency of these models. The effectiveness of LLMs in data preprocessing is evaluated through an experimental study spanning 12 datasets. GPT-4 emerged as a standout, achieving 100\\% accuracy or F1 score on 4 datasets, suggesting LLMs' immense potential in these tasks. Despite certain limitations, our study underscores the promise of LLMs in this domain and anticipates future developments to overcome current hurdles.", "url": "https://arxiv.org/abs/2308.16361"}, {"metadata": {"arXiv": "2308.16364", "Date": "Wed, 30 Aug 2023 23:42:07 ", "Title": "Strengthening the EU AI Act: Defining Key Terms on AI Manipulation", "Authors": ["Matija Franklin", "Philip Moreira Tomei", "Rebecca Gorman"], "Categories": "cs.AI", "Comments": ["10 pages"]}, "abstract": "The European Union's Artificial Intelligence Act aims to regulate manipulative and harmful uses of AI, but lacks precise definitions for key concepts. This paper provides technical recommendations to improve the Act's conceptual clarity and enforceability. We review psychological models to define \"personality traits,\" arguing the Act should protect full \"psychometric profiles.\" We urge expanding \"behavior\" to include \"preferences\" since preferences causally influence and are influenced by behavior. Clear definitions are provided for \"subliminal,\" \"manipulative,\" and \"deceptive\" techniques, considering incentives, intent, and covertness. We distinguish \"exploiting individuals\" from \"exploiting groups,\" emphasising different policy needs. An \"informed decision\" is defined by four facets: comprehension, accurate information, no manipulation, and understanding AI's influence. We caution the Act's therapeutic use exemption given the lack of regulation of digital therapeutics by the EMA. Overall, the recommendations strengthen definitions of vague concepts in the EU AI Act, enhancing precise applicability to regulate harmful AI manipulation.", "url": "https://arxiv.org/abs/2308.16364"}, {"metadata": {"arXiv": "2308.16441", "Date": "Thu, 31 Aug 2023 04:04:09 ", "Title": "Contrastive Representation Learning Based on Multiple Node-centered Subgraphs", "Authors": ["Dong Li", "Wenjun Wang", "Minglai Shao", "Chen Zhao"], "Categories": "cs.AI", "Comments": ["CIKM 2023"]}, "abstract": "As the basic element of graph-structured data, node has been recognized as the main object of study in graph representation learning. A single node intuitively has multiple node-centered subgraphs from the whole graph (e.g., one person in a social network has multiple social circles based on his different relationships). We study this intuition under the framework of graph contrastive learning, and propose a multiple node-centered subgraphs contrastive representation learning method to learn node representation on graphs in a self-supervised way. Specifically, we carefully design a series of node-centered regional subgraphs of the central node. Then, the mutual information between different subgraphs of the same node is maximized by contrastive loss. Experiments on various real-world datasets and different downstream tasks demonstrate that our model has achieved state-of-the-art results.", "url": "https://arxiv.org/abs/2308.16441"}, {"metadata": {"arXiv": "2308.16493", "Date": "Thu, 31 Aug 2023 06:53:55 ", "Title": "Expanding Frozen Vision-Language Models without Retraining: Towards Improved Robot Perception", "Authors": ["Riley Tavassoli", "Mani Amani", "Reza Akhavian"], "Categories": "cs.AI cs.RO", "Comments": ["Preprint submitted to Information Fusion"]}, "abstract": "Vision-language models (VLMs) have shown powerful capabilities in visual question answering and reasoning tasks by combining visual representations with the abstract skill set large language models (LLMs) learn during pretraining. Vision, while the most popular modality to augment LLMs with, is only one representation of a scene. In human-robot interaction scenarios, robot perception requires accurate scene understanding by the robot. In this paper, we define and demonstrate a method of aligning the embedding spaces of different modalities (in this case, inertial measurement unit (IMU) data) to the vision embedding space through a combination of supervised and contrastive training, enabling the VLM to understand and reason about these additional modalities without retraining. We opt to give the model IMU embeddings directly over using a separate human activity recognition model that feeds directly into the prompt to allow for any nonlinear interactions between the query, image, and IMU signal that would be lost by mapping the IMU data to a discrete activity label. Further, we demonstrate our methodology's efficacy through experiments involving human activity recognition using IMU data and visual inputs. Our results show that using multiple modalities as input improves the VLM's scene understanding and enhances its overall performance in various tasks, thus paving the way for more versatile and capable language models in multi-modal contexts.", "url": "https://arxiv.org/abs/2308.16493"}, {"metadata": {"arXiv": "2308.16538", "Date": "Thu, 31 Aug 2023 08:30:09 ", "Title": "The AI Revolution: Opportunities and Challenges for the Finance Sector", "Authors": ["Carsten Maple", "Lukasz Szpruch", "Gregory Epiphaniou", "Kalina Staykova", "Simran Singh", "William Penwarden", "Yisi Wen", "Zijian Wang", "Jagdish Hariharan", "Pavle Avramovic"], "Categories": "cs.AI"}, "abstract": "This report examines Artificial Intelligence (AI) in the financial sector, outlining its potential to revolutionise the industry and identify its challenges. It underscores the criticality of a well-rounded understanding of AI, its capabilities, and its implications to effectively leverage its potential while mitigating associated risks. The potential of AI potential extends from augmenting existing operations to paving the way for novel applications in the finance sector. The application of AI in the financial sector is transforming the industry. Its use spans areas from customer service enhancements, fraud detection, and risk management to credit assessments and high-frequency trading. However, along with these benefits, AI also presents several challenges. These include issues related to transparency, interpretability, fairness, accountability, and trustworthiness. The use of AI in the financial sector further raises critical questions about data privacy and security. A further issue identified in this report is the systemic risk that AI can introduce to the financial sector. Being prone to errors, AI can exacerbate existing systemic risks, potentially leading to financial crises. Regulation is crucial to harnessing the benefits of AI while mitigating its potential risks. Despite the global recognition of this need, there remains a lack of clear guidelines or legislation for AI use in finance. This report discusses key principles that could guide the formation of effective AI regulation in the financial sector, including the need for a risk-based approach, the inclusion of ethical considerations, and the importance of maintaining a balance between innovation and consumer protection. The report provides recommendations for academia, the finance industry, and regulators.", "url": "https://arxiv.org/abs/2308.16538"}, {"metadata": {"arXiv": "2308.16596", "Date": "Thu, 31 Aug 2023 09:56:40 ", "Title": "The Quest of Finding the Antidote to Sparse Double Descent", "Authors": ["Victor Qu\\'etu and Marta Milovanovi\\'c"], "Categories": "cs.AI"}, "abstract": "In energy-efficient schemes, finding the optimal size of deep learning models is very important and has a broad impact. Meanwhile, recent studies have reported an unexpected phenomenon, the sparse double descent: as the model's sparsity increases, the performance first worsens, then improves, and finally deteriorates. Such a non-monotonic behavior raises serious questions about the optimal model's size to maintain high performance: the model needs to be sufficiently over-parametrized, but having too many parameters wastes training resources. In this paper, we aim to find the best trade-off efficiently. More precisely, we tackle the occurrence of the sparse double descent and present some solutions to avoid it. Firstly, we show that a simple $\\ell_2$ regularization method can help to mitigate this phenomenon but sacrifices the performance/sparsity compromise. To overcome this problem, we then introduce a learning scheme in which distilling knowledge regularizes the student model. Supported by experimental results achieved using typical image classification setups, we show that this approach leads to the avoidance of such a phenomenon.", "url": "https://arxiv.org/abs/2308.16596"}, {"metadata": {"arXiv": "2308.16615", "Date": "Thu, 31 Aug 2023 10:21:24 ", "Title": "High Accuracy Location Information Extraction from Social Network Texts Using Natural Language Processing", "Authors": ["Lossan Bonde", "Severin Dembele"], "Categories": "cs.AI", "Journal-ref": "International Journal on Natural Language Computing (IJNLC) Vol.12, No.4, August 2023", "DOI": "10.5121/ijnlc.2023.12401"}, "abstract": "Terrorism has become a worldwide plague with severe consequences for the development of nations. Besides killing innocent people daily and preventing educational activities from taking place, terrorism is also hindering economic growth. Machine Learning (ML) and Natural Language Processing (NLP) can contribute to fighting terrorism by predicting in real-time future terrorist attacks if accurate data is available. This paper is part of a research project that uses text from social networks to extract necessary information to build an adequate dataset for terrorist attack prediction. We collected a set of 3000 social network texts about terrorism in Burkina Faso and used a subset to experiment with existing NLP solutions. The experiment reveals that existing solutions have poor accuracy for location recognition, which our solution resolves. We will extend the solution to extract dates and action information to achieve the project's goal.", "url": "https://arxiv.org/abs/2308.16615"}, {"metadata": {"arXiv": "2308.16622", "Date": "Thu, 31 Aug 2023 10:31:19 ", "Title": "Developing a Scalable Benchmark for Assessing Large Language Models in Knowledge Graph Engineering", "Authors": ["Lars-Peter Meyer", "Johannes Frey", "Kurt Junghanns", "Felix Brei", "Kirill Bulert", "Sabine Gr\\\"under-Fahrer", "Michael Martin"], "Categories": "cs.AI cs.CL cs.DB", "Comments": ["To be published in SEMANTICS 2023 poster track proceedings. SEMANTICS 2023 EU: 19th International Conference on Semantic Systems", "September 20-22", "2023", "Leipzig", "Germany"]}, "abstract": "As the field of Large Language Models (LLMs) evolves at an accelerated pace, the critical need to assess and monitor their performance emerges. We introduce a benchmarking framework focused on knowledge graph engineering (KGE) accompanied by three challenges addressing syntax and error correction, facts extraction and dataset generation. We show that while being a useful tool, LLMs are yet unfit to assist in knowledge graph generation with zero-shot prompting. Consequently, our LLM-KG-Bench framework provides automatic evaluation and storage of LLM responses as well as statistical data and visualization tools to support tracking of prompt engineering and model performance.", "url": "https://arxiv.org/abs/2308.16622"}, {"metadata": {"arXiv": "2308.16741", "Date": "Thu, 31 Aug 2023 13:59:35 ", "Title": "Socratis: Are large multimodal models emotionally aware?", "Authors": ["Katherine Deng", "Arijit Ray", "Reuben Tan", "Saadia Gabriel", "Bryan A. Plummer", "Kate Saenko"], "Categories": "cs.AI cs.CV", "Comments": ["ICCV 2023 WECIA"]}, "abstract": "Existing emotion prediction benchmarks contain coarse emotion labels which do not consider the diversity of emotions that an image and text can elicit in humans due to various reasons. Learning diverse reactions to multimodal content is important as intelligent machines take a central role in generating and delivering content to society. To address this gap, we propose Socratis, a \\underline{soc}ietal \\underline{r}e\\underline{a}c\\underline{ti}on\\underline{s} benchmark, where each image-caption (IC) pair is annotated with multiple emotions and the reasons for feeling them. Socratis contains 18K free-form reactions for 980 emotions on 2075 image-caption pairs from 5 widely-read news and image-caption (IC) datasets. We benchmark the capability of state-of-the-art multimodal large language models to generate the reasons for feeling an emotion given an IC pair. Based on a preliminary human study, we observe that humans prefer human-written reasons over 2 times more often than machine-generated ones. This shows our task is harder than standard generation tasks because it starkly contrasts recent findings where humans cannot tell apart machine vs human-written news articles, for instance. We further see that current captioning metrics based on large vision-language models also fail to correlate with human preferences. We hope that these findings and our benchmark will inspire further research on training emotionally aware models.", "url": "https://arxiv.org/abs/2308.16741"}, {"metadata": {"arXiv": "2308.16785", "Date": "Thu, 31 Aug 2023 15:02:01 ", "Title": "Agent Teaming Situation Awareness (ATSA): A Situation Awareness Framework for Human-AI Teaming", "Authors": ["Qi Gao", "Wei Xu", "Mowei Shen", "Zaifeng Gao"], "Categories": "cs.AI cs.HC", "Comments": ["52 pages,5 figures", "1 table"]}, "abstract": "The rapid advancements in artificial intelligence (AI) have led to a growing trend of human-AI teaming (HAT) in various fields. As machines continue to evolve from mere automation to a state of autonomy, they are increasingly exhibiting unexpected behaviors and human-like cognitive/intelligent capabilities, including situation awareness (SA). This shift has the potential to enhance the performance of mixed human-AI teams over all-human teams, underscoring the need for a better understanding of the dynamic SA interactions between humans and machines. To this end, we provide a review of leading SA theoretical models and a new framework for SA in the HAT context based on the key features and processes of HAT. The Agent Teaming Situation Awareness (ATSA) framework unifies human and AI behavior, and involves bidirectional, and dynamic interaction. The framework is based on the individual and team SA models and elaborates on the cognitive mechanisms for modeling HAT. Similar perceptual cycles are adopted for the individual (including both human and AI) and the whole team, which is tailored to the unique requirements of the HAT context. ATSA emphasizes cohesive and effective HAT through structures and components, including teaming understanding, teaming control, and the world, as well as adhesive transactive part. We further propose several future research directions to expand on the distinctive contributions of ATSA and address the specific and pressing next steps.", "url": "https://arxiv.org/abs/2308.16785"}, {"metadata": {"arXiv": "2308.16879", "Date": "Thu, 31 Aug 2023 17:36:57 ", "Title": "Adaptation Speed Analysis for Fairness-aware Causal Models", "Authors": ["Yujie Lin", "Chen Zhao", "Minglai Shao", "Xujiang Zhao", "Haifeng Chen"], "Categories": "cs.AI", "Comments": ["CIKM 2023"]}, "abstract": "For example, in machine translation tasks, to achieve bidirectional translation between two languages, the source corpus is often used as the target corpus, which involves the training of two models with opposite directions. The question of which one can adapt most quickly to a domain shift is of significant importance in many fields. Specifically, consider an original distribution p that changes due to an unknown intervention, resulting in a modified distribution p*. In aligning p with p*, several factors can affect the adaptation rate, including the causal dependencies between variables in p. In real-life scenarios, however, we have to consider the fairness of the training process, and it is particularly crucial to involve a sensitive variable (bias) present between a cause and an effect variable. To explore this scenario, we examine a simple structural causal model (SCM) with a cause-bias-effect structure, where variable A acts as a sensitive variable between cause (X) and effect (Y). The two models, respectively, exhibit consistent and contrary cause-effect directions in the cause-bias-effect SCM. After conducting unknown interventions on variables within the SCM, we can simulate some kinds of domain shifts for analysis. We then compare the adaptation speeds of two models across four shift scenarios. Additionally, we prove the connection between the adaptation speeds of the two models across all interventions.", "url": "https://arxiv.org/abs/2308.16879"}, {"metadata": {"arXiv": "2308.16725", "Date": "Thu, 31 Aug 2023 13:41:34 ", "Title": "Terrain Diffusion Network: Climatic-Aware Terrain Generation with Geological Sketch Guidance", "Authors": ["Zexin Hu", "Kun Hu", "Clinton Mo", "Lei Pan", "Zhiyong Wang"], "Categories": "cs.CV cs.AI cs.MM"}, "abstract": "Sketch-based terrain generation seeks to create realistic landscapes for virtual environments in various applications such as computer games, animation and virtual reality. Recently, deep learning based terrain generation has emerged, notably the ones based on generative adversarial networks (GAN). However, these methods often struggle to fulfill the requirements of flexible user control and maintain generative diversity for realistic terrain. Therefore, we propose a novel diffusion-based method, namely terrain diffusion network (TDN), which actively incorporates user guidance for enhanced controllability, taking into account terrain features like rivers, ridges, basins, and peaks. Instead of adhering to a conventional monolithic denoising process, which often compromises the fidelity of terrain details or the alignment with user control, a multi-level denoising scheme is proposed to generate more realistic terrains by taking into account fine-grained details, particularly those related to climatic patterns influenced by erosion and tectonic activities. Specifically, three terrain synthesisers are designed for structural, intermediate, and fine-grained level denoising purposes, which allow each synthesiser concentrate on a distinct terrain aspect. Moreover, to maximise the efficiency of our TDN, we further introduce terrain and sketch latent spaces for the synthesizers with pre-trained terrain autoencoders. Comprehensive experiments on a new dataset constructed from NASA Topology Images clearly demonstrate the effectiveness of our proposed method, achieving the state-of-the-art performance. Our code and dataset will be publicly available.", "url": "https://arxiv.org/abs/2308.16725"}, {"metadata": {"arXiv": "2308.16735", "Date": "Thu, 31 Aug 2023 13:52:28 ", "Title": "Post-Deployment Adaptation with Access to Source Data via Federated Learning and Source-Target Remote Gradient Alignment", "Authors": ["Felix Wagner", "Zeju Li", "Pramit Saha", "Konstantinos Kamnitsas"], "Categories": "cs.CV cs.AI", "Comments": ["This version was accepted for the Machine Learning in Medical Imaging (MLMI 2023) workshop at MICCAI 2023"]}, "abstract": "Deployment of Deep Neural Networks in medical imaging is hindered by distribution shift between training data and data processed after deployment, causing performance degradation. Post-Deployment Adaptation (PDA) addresses this by tailoring a pre-trained, deployed model to the target data distribution using limited labelled or entirely unlabelled target data, while assuming no access to source training data as they cannot be deployed with the model due to privacy concerns and their large size. This makes reliable adaptation challenging due to limited learning signal. This paper challenges this assumption and introduces FedPDA, a novel adaptation framework that brings the utility of learning from remote data from Federated Learning into PDA. FedPDA enables a deployed model to obtain information from source data via remote gradient exchange, while aiming to optimize the model specifically for the target domain. Tailored for FedPDA, we introduce a novel optimization method StarAlign (Source-Target Remote Gradient Alignment) that aligns gradients between source-target domain pairs by maximizing their inner product, to facilitate learning a target-specific model. We demonstrate the method's effectiveness using multi-center databases for the tasks of cancer metastases detection and skin lesion classification, where our method compares favourably to previous work. Code is available at: https://github.com/FelixWag/StarAlign", "url": "https://arxiv.org/abs/2308.16735"}, {"metadata": {"arXiv": "2308.16905", "Date": "Thu, 31 Aug 2023 17:59:08 ", "Title": "InterDiff: Generating 3D Human-Object Interactions with Physics-Informed Diffusion", "Authors": ["Sirui Xu", "Zhengyuan Li", "Yu-Xiong Wang", "Liang-Yan Gui"], "Categories": "cs.CV cs.AI cs.GR", "Comments": ["ICCV 2023; Project Page: https://sirui-xu.github.io/InterDiff/"]}, "abstract": "This paper addresses a novel task of anticipating 3D human-object interactions (HOIs). Most existing research on HOI synthesis lacks comprehensive whole-body interactions with dynamic objects, e.g., often limited to manipulating small or static objects. Our task is significantly more challenging, as it requires modeling dynamic objects with various shapes, capturing whole-body motion, and ensuring physically valid interactions. To this end, we propose InterDiff, a framework comprising two key steps: (i) interaction diffusion, where we leverage a diffusion model to encode the distribution of future human-object interactions; (ii) interaction correction, where we introduce a physics-informed predictor to correct denoised HOIs in a diffusion step. Our key insight is to inject prior knowledge that the interactions under reference with respect to contact points follow a simple pattern and are easily predictable. Experiments on multiple human-object interaction datasets demonstrate the effectiveness of our method for this task, capable of producing realistic, vivid, and remarkably long-term 3D HOI predictions.", "url": "https://arxiv.org/abs/2308.16905"}, {"metadata": {"arXiv": "2308.16909", "Date": "Thu, 31 Aug 2023 17:59:33 ", "Title": "StyleInV: A Temporal Style Modulated Inversion Network for Unconditional Video Generation", "Authors": ["Yuhan Wang", "Liming Jiang", "Chen Change Loy"], "Categories": "cs.CV cs.AI", "Comments": ["ICCV 2023. Code: https://github.com/johannwyh/StyleInV Project page: https://www.mmlab-ntu.com/project/styleinv/index.html"]}, "abstract": "Unconditional video generation is a challenging task that involves synthesizing high-quality videos that are both coherent and of extended duration. To address this challenge, researchers have used pretrained StyleGAN image generators for high-quality frame synthesis and focused on motion generator design. The motion generator is trained in an autoregressive manner using heavy 3D convolutional discriminators to ensure motion coherence during video generation. In this paper, we introduce a novel motion generator design that uses a learning-based inversion network for GAN. The encoder in our method captures rich and smooth priors from encoding images to latents, and given the latent of an initially generated frame as guidance, our method can generate smooth future latent by modulating the inversion encoder temporally. Our method enjoys the advantage of sparse training and naturally constrains the generation space of our motion generator with the inversion network guided by the initial frame, eliminating the need for heavy discriminators. Moreover, our method supports style transfer with simple fine-tuning when the encoder is paired with a pretrained StyleGAN generator. Extensive experiments conducted on various benchmarks demonstrate the superiority of our method in generating long and high-resolution videos with decent single-frame quality and temporal consistency.", "url": "https://arxiv.org/abs/2308.16909"}, {"metadata": {"arXiv": "2308.16911", "Date": "Thu, 31 Aug 2023 17:59:46 ", "Title": "PointLLM: Empowering Large Language Models to Understand Point Clouds", "Authors": ["Runsen Xu", "Xiaolong Wang", "Tai Wang", "Yilun Chen", "Jiangmiao Pang", "Dahua Lin"], "Categories": "cs.CV cs.AI cs.CL", "Comments": ["19 pages. Empowering large language models with 3D point cloud understanding", "accompanied by a novel dataset and carefully designed benchmarks. Project page: https://runsenxu.com/projects/PointLLM"]}, "abstract": "The unprecedented advancements in Large Language Models (LLMs) have created a profound impact on natural language processing but are yet to fully embrace the realm of 3D understanding. This paper introduces PointLLM, a preliminary effort to fill this gap, thereby enabling LLMs to understand point clouds and offering a new avenue beyond 2D visual data. PointLLM processes colored object point clouds with human instructions and generates contextually appropriate responses, illustrating its grasp of point clouds and common sense. Specifically, it leverages a point cloud encoder with a powerful LLM to effectively fuse geometric, appearance, and linguistic information. We collect a novel dataset comprising 660K simple and 70K complex point-text instruction pairs to enable a two-stage training strategy: initially aligning latent spaces and subsequently instruction-tuning the unified model. To rigorously evaluate our model's perceptual abilities and its generalization capabilities, we establish two benchmarks: Generative 3D Object Classification and 3D Object Captioning, assessed through three different methods, including human evaluation, GPT-4/ChatGPT evaluation, and traditional metrics. Experiment results show that PointLLM demonstrates superior performance over existing 2D baselines. Remarkably, in human-evaluated object captioning tasks, PointLLM outperforms human annotators in over 50% of the samples. Codes, datasets, and benchmarks are available at https://github.com/OpenRobotLab/PointLLM .", "url": "https://arxiv.org/abs/2308.16911"}, {"metadata": {"arXiv": "2308.16501", "Date": "Thu, 31 Aug 2023 07:18:37 ", "Title": "Individually Rational Collaborative Vehicle Routing through Give-And-Take Exchanges", "Authors": ["Paul Mingzheng Tang", "Ba Phong Tran", "Hoong Chuin Lau"], "Categories": "cs.MA cs.AI", "Comments": ["7 pages 4 figures This paper was presented in the IJCAI 2023 First International Workshop on Search and Planning with Complex Objectives (WoSePCO) http://idm-lab.org/wiki/complex-objective"]}, "abstract": "In this paper, we are concerned with the automated exchange of orders between logistics companies in a marketplace platform to optimize total revenues. We introduce a novel multi-agent approach to this problem, focusing on the Collaborative Vehicle Routing Problem (CVRP) through the lens of individual rationality. Our proposed algorithm applies the principles of Vehicle Routing Problem (VRP) to pairs of vehicles from different logistics companies, optimizing the overall routes while considering standard VRP constraints plus individual rationality constraints. By facilitating cooperation among competing logistics agents through a Give-and-Take approach, we show that it is possible to reduce travel distance and increase operational efficiency system-wide. More importantly, our approach ensures individual rationality and faster convergence, which are important properties of ensuring the long-term sustainability of the marketplace platform. We demonstrate the efficacy of our approach through extensive experiments using real-world test data from major logistics companies. The results reveal our algorithm's ability to rapidly identify numerous optimal solutions, underscoring its practical applicability and potential to transform the logistics industry.", "url": "https://arxiv.org/abs/2308.16501"}, {"metadata": {"arXiv": "2308.16529", "Date": "Thu, 31 Aug 2023 08:20:04 ", "Title": "Developing Social Robots with Empathetic Non-Verbal Cues Using Large Language Models", "Authors": ["Yoon Kyung Lee", "Yoonwon Jung", "Gyuyi Kang", "Sowon Hahn"], "Categories": "cs.RO cs.AI cs.HC", "Journal-ref": "In Proceedings of 2023 IEEE International Conference on Robot & Human Interactive Communication (RO-MAN)"}, "abstract": "We propose augmenting the empathetic capacities of social robots by integrating non-verbal cues. Our primary contribution is the design and labeling of four types of empathetic non-verbal cues, abbreviated as SAFE: Speech, Action (gesture), Facial expression, and Emotion, in a social robot. These cues are generated using a Large Language Model (LLM). We developed an LLM-based conversational system for the robot and assessed its alignment with social cues as defined by human counselors. Preliminary results show distinct patterns in the robot's responses, such as a preference for calm and positive social emotions like 'joy' and 'lively', and frequent nodding gestures. Despite these tendencies, our approach has led to the development of a social robot capable of context-aware and more authentic interactions. Our work lays the groundwork for future studies on human-robot interactions, emphasizing the essential role of both verbal and non-verbal cues in creating social and empathetic robots.", "url": "https://arxiv.org/abs/2308.16529"}, {"metadata": {"arXiv": "2308.16870", "Date": "Thu, 31 Aug 2023 17:18:15 ", "Title": "Learning Driver Models for Automated Vehicles via Knowledge Sharing and Personalization", "Authors": ["Wissam Kontar", "Xinzhi Zhong", "Soyoung Ahn"], "Categories": "cs.RO cs.AI cs.SY eess.SY", "Comments": ["10 pages", "8 figures"]}, "abstract": "This paper describes a framework for learning Automated Vehicles (AVs) driver models via knowledge sharing between vehicles and personalization. The innate variability in the transportation system makes it exceptionally challenging to expose AVs to all possible driving scenarios during empirical experimentation or testing. Consequently, AVs could be blind to certain encounters that are deemed detrimental to their safe and efficient operation. It is then critical to share knowledge across AVs that increase exposure to driving scenarios occurring in the real world. This paper explores a method to collaboratively train a driver model by sharing knowledge and borrowing strength across vehicles while retaining a personalized model tailored to the vehicle's unique conditions and properties. Our model brings a federated learning approach to collaborate between multiple vehicles while circumventing the need to share raw data between them. We showcase our method's performance in experimental simulations. Such an approach to learning finds several applications across transportation engineering including intelligent transportation systems, traffic management, and vehicle-to-vehicle communication. Code and sample dataset are made available at the project page https://github.com/wissamkontar.", "url": "https://arxiv.org/abs/2308.16870"}, {"metadata": {"arXiv": "2308.16781", "Date": "Thu, 31 Aug 2023 14:59:32 ", "Title": "StratMed: Relevance Stratification for Low-resource Medication Recommendation", "Authors": ["Xiang Li"], "Categories": "cs.AI cs.LG"}, "abstract": "With the growing imbalance between limited medical resources and escalating demands, AI-based clinical tasks have become paramount. Medication recommendation, as a sub-domain, aims to amalgamate longitudinal patient history with medical knowledge, assisting physicians in prescribing safer and more accurate medication combinations. Existing methods overlook the inherent long-tail distribution in medical data, lacking balanced representation between head and tail data, which leads to sub-optimal model performance. To address this challenge, we introduce StratMed, a model that incorporates an innovative relevance stratification mechanism. It harmonizes discrepancies in data long-tail distribution and strikes a balance between the safety and accuracy of medication combinations. Specifically, we first construct a pre-training method using deep learning networks to obtain entity representation. After that, we design a pyramid-like data stratification method to obtain more generalized entity relationships by reinforcing the features of unpopular entities. Based on this relationship, we designed two graph structures to express medication precision and safety at the same level to obtain visit representations. Finally, the patient's historical clinical information is fitted to generate medication combinations for the current health condition. Experiments on the MIMIC-III dataset demonstrate that our method has outperformed current state-of-the-art methods in four evaluation metrics (including safety and accuracy).", "url": "https://arxiv.org/abs/2308.16781"}, {"metadata": {"arXiv": "2308.16481", "Date": "Thu, 31 Aug 2023 06:32:11 ", "Title": "Point-TTA: Test-Time Adaptation for Point Cloud Registration Using Multitask Meta-Auxiliary Learning", "Authors": ["Ahmed Hatem", "Yiming Qian", "Yang Wang"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "We present Point-TTA, a novel test-time adaptation framework for point cloud registration (PCR) that improves the generalization and the performance of registration models. While learning-based approaches have achieved impressive progress, generalization to unknown testing environments remains a major challenge due to the variations in 3D scans. Existing methods typically train a generic model and the same trained model is applied on each instance during testing. This could be sub-optimal since it is difficult for the same model to handle all the variations during testing. In this paper, we propose a test-time adaptation approach for PCR. Our model can adapt to unseen distributions at test-time without requiring any prior knowledge of the test data. Concretely, we design three self-supervised auxiliary tasks that are optimized jointly with the primary PCR task. Given a test instance, we adapt our model using these auxiliary tasks and the updated model is used to perform the inference. During training, our model is trained using a meta-auxiliary learning approach, such that the adapted model via auxiliary tasks improves the accuracy of the primary task. Experimental results demonstrate the effectiveness of our approach in improving generalization of point cloud registration and outperforming other state-of-the-art approaches.", "url": "https://arxiv.org/abs/2308.16481"}, {"metadata": {"arXiv": "2308.16484", "Date": "Thu, 31 Aug 2023 06:44:59 ", "Title": "Test-Time Adaptation for Point Cloud Upsampling Using Meta-Learning", "Authors": ["Ahmed Hatem", "Yiming Qian", "Yang Wang"], "Categories": "cs.CV cs.AI cs.LG cs.RO"}, "abstract": "Affordable 3D scanners often produce sparse and non-uniform point clouds that negatively impact downstream applications in robotic systems. While existing point cloud upsampling architectures have demonstrated promising results on standard benchmarks, they tend to experience significant performance drops when the test data have different distributions from the training data. To address this issue, this paper proposes a test-time adaption approach to enhance model generality of point cloud upsampling. The proposed approach leverages meta-learning to explicitly learn network parameters for test-time adaption. Our method does not require any prior information about the test data. During meta-training, the model parameters are learned from a collection of instance-level tasks, each of which consists of a sparse-dense pair of point clouds from the training data. During meta-testing, the trained model is fine-tuned with a few gradient updates to produce a unique set of network parameters for each test instance. The updated model is then used for the final prediction. Our framework is generic and can be applied in a plug-and-play manner with existing backbone networks in point cloud upsampling. Extensive experiments demonstrate that our approach improves the performance of state-of-the-art models.", "url": "https://arxiv.org/abs/2308.16484"}, {"metadata": {"arXiv": "2308.16490", "Date": "Thu, 31 Aug 2023 06:52:43 ", "Title": "Latent Painter", "Authors": ["Shih-Chieh Su"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Latent diffusers revolutionized the generative AI and inspired creative art. When denoising the latent, the predicted original image at each step collectively animates the formation. However, the animation is limited by the denoising nature of the diffuser, and only renders a sharpening process. This work presents Latent Painter, which uses the latent as the canvas, and the diffuser predictions as the plan, to generate painting animation. Latent Painter also transits one generated image to another, which can happen between images from two different sets of checkpoints.", "url": "https://arxiv.org/abs/2308.16490"}, {"metadata": {"arXiv": "2308.16572", "Date": "Thu, 31 Aug 2023 09:13:30 ", "Title": "CL-MAE: Curriculum-Learned Masked Autoencoders", "Authors": ["Neelu Madan", "Nicolae-Catalin Ristea", "Kamal Nasrollahi", "Thomas B. Moeslund", "Radu Tudor Ionescu"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Masked image modeling has been demonstrated as a powerful pretext task for generating robust representations that can be effectively generalized across multiple downstream tasks. Typically, this approach involves randomly masking patches (tokens) in input images, with the masking strategy remaining unchanged during training. In this paper, we propose a curriculum learning approach that updates the masking strategy to continually increase the complexity of the self-supervised reconstruction task. We conjecture that, by gradually increasing the task complexity, the model can learn more sophisticated and transferable representations. To facilitate this, we introduce a novel learnable masking module that possesses the capability to generate masks of different complexities, and integrate the proposed module into masked autoencoders (MAE). Our module is jointly trained with the MAE, while adjusting its behavior during training, transitioning from a partner to the MAE (optimizing the same reconstruction loss) to an adversary (optimizing the opposite loss), while passing through a neutral state. The transition between these behaviors is smooth, being regulated by a factor that is multiplied with the reconstruction loss of the masking module. The resulting training procedure generates an easy-to-hard curriculum. We train our Curriculum-Learned Masked Autoencoder (CL-MAE) on ImageNet and show that it exhibits superior representation learning capabilities compared to MAE. The empirical results on five downstream tasks confirm our conjecture, demonstrating that curriculum learning can be successfully used to self-supervise masked autoencoders.", "url": "https://arxiv.org/abs/2308.16572"}, {"metadata": {"arXiv": "2308.16896", "Date": "Thu, 31 Aug 2023 17:57:17 ", "Title": "PointOcc: Cylindrical Tri-Perspective View for Point-based 3D Semantic Occupancy Prediction", "Authors": ["Sicheng Zuo", "Wenzhao Zheng", "Yuanhui Huang", "Jie Zhou", "Jiwen Lu"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Code is available at https://github.com/wzzheng/PointOcc"]}, "abstract": "Semantic segmentation in autonomous driving has been undergoing an evolution from sparse point segmentation to dense voxel segmentation, where the objective is to predict the semantic occupancy of each voxel in the concerned 3D space. The dense nature of the prediction space has rendered existing efficient 2D-projection-based methods (e.g., bird's eye view, range view, etc.) ineffective, as they can only describe a subspace of the 3D scene. To address this, we propose a cylindrical tri-perspective view to represent point clouds effectively and comprehensively and a PointOcc model to process them efficiently. Considering the distance distribution of LiDAR point clouds, we construct the tri-perspective view in the cylindrical coordinate system for more fine-grained modeling of nearer areas. We employ spatial group pooling to maintain structural details during projection and adopt 2D backbones to efficiently process each TPV plane. Finally, we obtain the features of each point by aggregating its projected features on each of the processed TPV planes without the need for any post-processing. Extensive experiments on both 3D occupancy prediction and LiDAR segmentation benchmarks demonstrate that the proposed PointOcc achieves state-of-the-art performance with much faster speed. Specifically, despite only using LiDAR, PointOcc significantly outperforms all other methods, including multi-modal methods, with a large margin on the OpenOccupancy benchmark. Code: https://github.com/wzzheng/PointOcc.", "url": "https://arxiv.org/abs/2308.16896"}, {"metadata": {"arXiv": "2308.16198", "Date": "Fri, 25 Aug 2023 21:30:16 ", "Title": "Learning Collaborative Information Dissemination with Graph-based Multi-Agent Reinforcement Learning", "Authors": ["Raffaele Galliera", "Kristen Brent Venable", "Matteo Bassani", "Niranjan Suri"], "Categories": "cs.LG cs.AI cs.MA cs.NI", "Comments": ["13 pages (4 of Supplementary Materials)", "6 figures", "3 tables"]}, "abstract": "In modern communication systems, efficient and reliable information dissemination is crucial for supporting critical operations across domains like disaster response, autonomous vehicles, and sensor networks. This paper introduces a Multi-Agent Reinforcement Learning (MARL) approach as a significant step forward in achieving more decentralized, efficient, and collaborative solutions. We propose a Decentralized-POMDP formulation for information dissemination, empowering each agent to independently decide on message forwarding. This constitutes a significant paradigm shift from traditional heuristics based on Multi-Point Relay (MPR) selection. Our approach harnesses Graph Convolutional Reinforcement Learning, employing Graph Attention Networks (GAT) with dynamic attention to capture essential network features. We propose two approaches, L-DGN and HL-DGN, which differ in the information that is exchanged among agents. We evaluate the performance of our decentralized approaches, by comparing them with a widely-used MPR heuristic, and we show that our trained policies are able to efficiently cover the network while bypassing the MPR set selection process. Our approach promises a first step toward bolstering the resilience of real-world broadcast communication infrastructures via learned, collaborative information dissemination.", "url": "https://arxiv.org/abs/2308.16198"}, {"metadata": {"arXiv": "2308.16245", "Date": "Wed, 30 Aug 2023 18:06:57 ", "Title": "Calibrated Explanations for Regression", "Authors": ["Tuwe L\\\"ofstr\\\"om", "Helena L\\\"ofstr\\\"om", "Ulf Johansson", "Cecilia S\\\"onstr\\\"od"], "Categories": "cs.LG cs.AI stat.ML", "Comments": ["30 pages", "11 figures"], "MSC-class": "68-04, 68W99"}, "abstract": "Artificial Intelligence (AI) is often an integral part of modern decision support systems (DSSs). The best-performing predictive models used in AI-based DSSs lack transparency. Explainable Artificial Intelligence (XAI) aims to create AI systems that can explain their rationale to human users. Local explanations in XAI can provide information about the causes of individual predictions in terms of feature importance. However, a critical drawback of existing local explanation methods is their inability to quantify the uncertainty associated with a feature's importance. This paper introduces an extension of a feature importance explanation method, Calibrated Explanations (CE), previously only supporting classification, with support for standard regression and probabilistic regression, i.e., the probability that the target is above an arbitrary threshold. The extension for regression keeps all the benefits of CE, such as calibration of the prediction from the underlying model with confidence intervals, uncertainty quantification of feature importance, and allows both factual and counterfactual explanations. CE for standard regression provides fast, reliable, stable, and robust explanations. CE for probabilistic regression provides an entirely new way of creating probabilistic explanations from any ordinary regression model and with a dynamic selection of thresholds. The performance of CE for probabilistic regression regarding stability and speed is comparable to LIME. The method is model agnostic with easily understood conditional rules. An implementation in Python is freely available on GitHub and for installation using pip making the results in this paper easily replicable.", "url": "https://arxiv.org/abs/2308.16245"}, {"metadata": {"arXiv": "2308.16375", "Date": "Thu, 31 Aug 2023 00:31:08 ", "Title": "A Survey on Privacy in Graph Neural Networks: Attacks, Preservation, and Applications", "Authors": ["Yi Zhang", "Yuying Zhao", "Zhaoqing Li", "Xueqi Cheng", "Yu Wang", "Olivera Kotevska", "Philip S. Yu", "Tyler Derr"], "Categories": "cs.LG cs.AI cs.CR"}, "abstract": "Graph Neural Networks (GNNs) have gained significant attention owing to their ability to handle graph-structured data and the improvement in practical applications. However, many of these models prioritize high utility performance, such as accuracy, with a lack of privacy consideration, which is a major concern in modern society where privacy attacks are rampant. To address this issue, researchers have started to develop privacy-preserving GNNs. Despite this progress, there is a lack of a comprehensive overview of the attacks and the techniques for preserving privacy in the graph domain. In this survey, we aim to address this gap by summarizing the attacks on graph data according to the targeted information, categorizing the privacy preservation techniques in GNNs, and reviewing the datasets and applications that could be used for analyzing/solving privacy issues in GNNs. We also outline potential directions for future research in order to build better privacy-preserving GNNs.", "url": "https://arxiv.org/abs/2308.16375"}, {"metadata": {"arXiv": "2308.16385", "Date": "Thu, 31 Aug 2023 01:03:27 ", "Title": "BenchTemp: A General Benchmark for Evaluating Temporal Graph Neural Networks", "Authors": ["Qiang Huang", "Jiawei Jiang", "Xi Susie Rao", "Ce Zhang", "Zhichao Han", "Zitao Zhang", "Xin Wang", "Yongjun He", "Quanqing Xu", "Yang Zhao", "Chuang Hu", "Shuo Shang", "Bo Du"], "Categories": "cs.LG cs.AI", "Comments": ["28 pages", "23 figures", "27 tables. Submitted to the Conference on Neural Information Processing Systems 2023 Track on Datasets and Benchmarks"]}, "abstract": "To handle graphs in which features or connectivities are evolving over time, a series of temporal graph neural networks (TGNNs) have been proposed. Despite the success of these TGNNs, the previous TGNN evaluations reveal several limitations regarding four critical issues: 1) inconsistent datasets, 2) inconsistent evaluation pipelines, 3) lacking workload diversity, and 4) lacking efficient comparison. Overall, there lacks an empirical study that puts TGNN models onto the same ground and compares them comprehensively. To this end, we propose BenchTemp, a general benchmark for evaluating TGNN models on various workloads. BenchTemp provides a set of benchmark datasets so that different TGNN models can be fairly compared. Further, BenchTemp engineers a standard pipeline that unifies the TGNN evaluation. With BenchTemp, we extensively compare the representative TGNN models on different tasks (e.g., link prediction and node classification) and settings (transductive and inductive), w.r.t. both effectiveness and efficiency metrics. We have made BenchTemp publicly available at https://github.com/qianghuangwhu/benchtemp.", "url": "https://arxiv.org/abs/2308.16385"}, {"metadata": {"arXiv": "2308.16458", "Date": "Thu, 31 Aug 2023 04:52:58 ", "Title": "BioCoder: A Benchmark for Bioinformatics Code Generation with Contextual Pragmatic Knowledge", "Authors": ["Xiangru Tang", "Bill Qian", "Rick Gao", "Jiakang Chen", "Xinyun Chen", "Mark Gerstein"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "Pre-trained language models like ChatGPT have significantly improved code generation. As these models scale up, there is an increasing need for the output to handle more intricate tasks. Moreover, in bioinformatics, generating functional programs poses additional notable challenges due to the amount of domain knowledge, the need for complicated data operations, and intricate functional dependencies between the operations. Here, we present BioCoder, a benchmark developed to evaluate existing pre-trained models in generating bioinformatics code. In relation to function-code generation, BioCoder covers potential package dependencies, class declarations, and global variables. It incorporates 1026 functions and 1243 methods in Python and Java from GitHub and 253 examples from the Rosalind Project. BioCoder incorporates a fuzz-testing framework for evaluation, and we have applied it to evaluate many models including InCoder, CodeGen, CodeGen2, SantaCoder, StarCoder, StarCoder+, InstructCodeT5+, and ChatGPT. Our detailed analysis of these models emphasizes the importance of domain knowledge, pragmatic code generation, and contextual understanding. Our dataset, benchmark, Docker images, and scripts required for testing are all available at https://github.com/gersteinlab/biocoder.", "url": "https://arxiv.org/abs/2308.16458"}, {"metadata": {"arXiv": "2308.16516", "Date": "Thu, 31 Aug 2023 08:00:08 ", "Title": "Curvature-based Pooling within Graph Neural Networks", "Authors": ["Cedric Sanders", "Andreas Roth", "Thomas Liebig"], "Categories": "cs.LG cs.AI", "Comments": ["ECMLPKDD 2023 - Workshop on Mining and Learning with Graphs"]}, "abstract": "Over-squashing and over-smoothing are two critical issues, that limit the capabilities of graph neural networks (GNNs). While over-smoothing eliminates the differences between nodes making them indistinguishable, over-squashing refers to the inability of GNNs to propagate information over long distances, as exponentially many node states are squashed into fixed-size representations. Both phenomena share similar causes, as both are largely induced by the graph topology. To mitigate these problems in graph classification tasks, we propose CurvPool, a novel pooling method. CurvPool exploits the notion of curvature of a graph to adaptively identify structures responsible for both over-smoothing and over-squashing. By clustering nodes based on the Balanced Forman curvature, CurvPool constructs a graph with a more suitable structure, allowing deeper models and the combination of distant information. We compare it to other state-of-the-art pooling approaches and establish its competitiveness in terms of classification accuracy, computational complexity, and flexibility. CurvPool outperforms several comparable methods across all considered tasks. The most consistent results are achieved by pooling densely connected clusters using the sum aggregation, as this allows additional information about the size of each pool.", "url": "https://arxiv.org/abs/2308.16516"}, {"metadata": {"arXiv": "2308.16534", "Date": "Thu, 31 Aug 2023 08:25:47 ", "Title": "Conditioning Score-Based Generative Models by Neuro-Symbolic Constraints", "Authors": ["Davide Scassola", "Sebastiano Saccani", "Ginevra Carbone", "Luca Bortolussi"], "Categories": "cs.LG cs.AI"}, "abstract": "Score-based and diffusion models have emerged as effective approaches for both conditional and unconditional generation. Still conditional generation is based on either a specific training of a conditional model or classifier guidance, which requires training a noise-dependent classifier, even when the classifier for uncorrupted data is given. We propose an approach to sample from unconditional score-based generative models enforcing arbitrary logical constraints, without any additional training. Firstly, we show how to manipulate the learned score in order to sample from an un-normalized distribution conditional on a user-defined constraint. Then, we define a flexible and numerically stable neuro-symbolic framework for encoding soft logical constraints. Combining these two ingredients we obtain a general, but approximate, conditional sampling algorithm. We further developed effective heuristics aimed at improving the approximation. Finally, we show the effectiveness of our approach for various types of constraints and data: tabular data, images and time series.", "url": "https://arxiv.org/abs/2308.16534"}, {"metadata": {"arXiv": "2308.16609", "Date": "Thu, 31 Aug 2023 10:12:32 ", "Title": "Towards Long-Tailed Recognition for Graph Classification via Collaborative Experts", "Authors": ["Siyu Yi", "Zhengyang Mao", "Wei Ju", "Yongdao Zhou", "Luchen Liu", "Xiao Luo", "and Ming Zhang"], "Categories": "cs.LG cs.AI cs.IR cs.SI", "Comments": ["Accepted by IEEE Transactions on Big Data (TBD 2024)"]}, "abstract": "Graph classification, aiming at learning the graph-level representations for effective class assignments, has received outstanding achievements, which heavily relies on high-quality datasets that have balanced class distribution. In fact, most real-world graph data naturally presents a long-tailed form, where the head classes occupy much more samples than the tail classes, it thus is essential to study the graph-level classification over long-tailed data while still remaining largely unexplored. However, most existing long-tailed learning methods in visions fail to jointly optimize the representation learning and classifier training, as well as neglect the mining of the hard-to-classify classes. Directly applying existing methods to graphs may lead to sub-optimal performance, since the model trained on graphs would be more sensitive to the long-tailed distribution due to the complex topological characteristics. Hence, in this paper, we propose a novel long-tailed graph-level classification framework via Collaborative Multi-expert Learning (CoMe) to tackle the problem. To equilibrate the contributions of head and tail classes, we first develop balanced contrastive learning from the view of representation learning, and then design an individual-expert classifier training based on hard class mining. In addition, we execute gated fusion and disentangled knowledge distillation among the multiple experts to promote the collaboration in a multi-expert framework. Comprehensive experiments are performed on seven widely-used benchmark datasets to demonstrate the superiority of our method CoMe over state-of-the-art baselines.", "url": "https://arxiv.org/abs/2308.16609"}, {"metadata": {"arXiv": "2308.16737", "Date": "Thu, 31 Aug 2023 13:54:37 ", "Title": "Robust Networked Federated Learning for Localization", "Authors": ["Reza Mirzaeifard", "Naveen K. D. Venkategowda", "Stefan Werner"], "Categories": "cs.LG cs.AI"}, "abstract": "This paper addresses the problem of localization, which is inherently non-convex and non-smooth in a federated setting where the data is distributed across a multitude of devices. Due to the decentralized nature of federated environments, distributed learning becomes essential for scalability and adaptability. Moreover, these environments are often plagued by outlier data, which presents substantial challenges to conventional methods, particularly in maintaining estimation accuracy and ensuring algorithm convergence. To mitigate these challenges, we propose a method that adopts an $L_1$-norm robust formulation within a distributed sub-gradient framework, explicitly designed to handle these obstacles. Our approach addresses the problem in its original form, without resorting to iterative simplifications or approximations, resulting in enhanced computational efficiency and improved estimation accuracy. We demonstrate that our method converges to a stationary point, highlighting its effectiveness and reliability. Through numerical simulations, we confirm the superior performance of our approach, notably in outlier-rich environments, which surpasses existing state-of-the-art localization methods.", "url": "https://arxiv.org/abs/2308.16737"}, {"metadata": {"arXiv": "2308.16775", "Date": "Thu, 31 Aug 2023 14:54:06 ", "Title": "Efficacy of Neural Prediction-Based NAS for Zero-Shot NAS Paradigm", "Authors": ["Minh Le", "Nhan Nguyen", "and Ngoc Hoang Luong"], "Categories": "cs.LG cs.AI", "Comments": ["12 pages", "6 figures"], "ACM-class": "I.2.6"}, "abstract": "In prediction-based Neural Architecture Search (NAS), performance indicators derived from graph convolutional networks have shown significant success. These indicators, achieved by representing feed-forward structures as component graphs through one-hot encoding, face a limitation: their inability to evaluate architecture performance across varying search spaces. In contrast, handcrafted performance indicators (zero-shot NAS), which use the same architecture with random initialization, can generalize across multiple search spaces. Addressing this limitation, we propose a novel approach for zero-shot NAS using deep learning. Our method employs Fourier sum of sines encoding for convolutional kernels, enabling the construction of a computational feed-forward graph with a structure similar to the architecture under evaluation. These encodings are learnable and offer a comprehensive view of the architecture's topological information. An accompanying multi-layer perceptron (MLP) then ranks these architectures based on their encodings. Experimental results show that our approach surpasses previous methods using graph convolutional networks in terms of correlation on the NAS-Bench-201 dataset and exhibits a higher convergence rate. Moreover, our extracted feature representation trained on each NAS-Benchmark is transferable to other NAS-Benchmarks, showing promising generalizability across multiple search spaces. The code is available at: https://github.com/minh1409/DFT-NPZS-NAS", "url": "https://arxiv.org/abs/2308.16775"}, {"metadata": {"arXiv": "2308.16800", "Date": "Thu, 31 Aug 2023 15:22:31 ", "Title": "Rank Collapse Causes Over-Smoothing and Over-Correlation in Graph Neural Networks", "Authors": ["Andreas Roth", "Thomas Liebig"], "Categories": "cs.LG cs.AI"}, "abstract": "Our study reveals new theoretical insights into over-smoothing and feature over-correlation in deep graph neural networks. We show the prevalence of invariant subspaces, demonstrating a fixed relative behavior that is unaffected by feature transformations. Our work clarifies recent observations related to convergence to a constant state and a potential over-separation of node states, as the amplification of subspaces only depends on the spectrum of the aggregation function. In linear scenarios, this leads to node representations being dominated by a low-dimensional subspace with an asymptotic convergence rate independent of the feature transformations. This causes a rank collapse of the node representations, resulting in over-smoothing when smooth vectors span this subspace, and over-correlation even when over-smoothing is avoided. Guided by our theory, we propose a sum of Kronecker products as a beneficial property that can provably prevent over-smoothing, over-correlation, and rank collapse. We empirically extend our insights to the non-linear case, demonstrating the inability of existing models to capture linearly independent features.", "url": "https://arxiv.org/abs/2308.16800"}, {"metadata": {"arXiv": "2308.16818", "Date": "Thu, 31 Aug 2023 15:49:21 ", "Title": "Irregular Traffic Time Series Forecasting Based on Asynchronous Spatio-Temporal Graph Convolutional Network", "Authors": ["Weijia Zhang", "Le Zhang", "Jindong Han", "Hao Liu", "Jingbo Zhou", "Yu Mei", "Hui Xiong"], "Categories": "cs.LG cs.AI"}, "abstract": "Accurate traffic forecasting at intersections governed by intelligent traffic signals is critical for the advancement of an effective intelligent traffic signal control system. However, due to the irregular traffic time series produced by intelligent intersections, the traffic forecasting task becomes much more intractable and imposes three major new challenges: 1) asynchronous spatial dependency, 2) irregular temporal dependency among traffic data, and 3) variable-length sequence to be predicted, which severely impede the performance of current traffic forecasting methods. To this end, we propose an Asynchronous Spatio-tEmporal graph convolutional nEtwoRk (ASeer) to predict the traffic states of the lanes entering intelligent intersections in a future time window. Specifically, by linking lanes via a traffic diffusion graph, we first propose an Asynchronous Graph Diffusion Network to model the asynchronous spatial dependency between the time-misaligned traffic state measurements of lanes. After that, to capture the temporal dependency within irregular traffic state sequence, a learnable personalized time encoding is devised to embed the continuous time for each lane. Then we propose a Transformable Time-aware Convolution Network that learns meta-filters to derive time-aware convolution filters with transformable filter sizes for efficient temporal convolution on the irregular sequence. Furthermore, a Semi-Autoregressive Prediction Network consisting of a state evolution unit and a semiautoregressive predictor is designed to effectively and efficiently predict variable-length traffic state sequences. Extensive experiments on two real-world datasets demonstrate the effectiveness of ASeer in six metrics.", "url": "https://arxiv.org/abs/2308.16818"}, {"metadata": {"arXiv": "2308.16822", "Date": "Thu, 31 Aug 2023 15:52:35 ", "Title": "Latent Variable Multi-output Gaussian Processes for Hierarchical Datasets", "Authors": ["Chunchao Ma", "Arthur Leroy", "Mauricio Alvarez"], "Categories": "cs.LG cs.AI", "Comments": ["29 pages"]}, "abstract": "Multi-output Gaussian processes (MOGPs) have been introduced to deal with multiple tasks by exploiting the correlations between different outputs. Generally, MOGPs models assume a flat correlation structure between the outputs. However, such a formulation does not account for more elaborate relationships, for instance, if several replicates were observed for each output (which is a typical setting in biological experiments). This paper proposes an extension of MOGPs for hierarchical datasets (i.e. datasets for which the relationships between observations can be represented within a tree structure). Our model defines a tailored kernel function accounting for hierarchical structures in the data to capture different levels of correlations while leveraging the introduction of latent variables to express the underlying dependencies between outputs through a dedicated kernel. This latter feature is expected to significantly improve scalability as the number of tasks increases. An extensive experimental study involving both synthetic and real-world data from genomics and motion capture is proposed to support our claims.", "url": "https://arxiv.org/abs/2308.16822"}, {"metadata": {"arXiv": "2308.16898", "Date": "Thu, 31 Aug 2023 17:57:50 ", "Title": "Transformers as Support Vector Machines", "Authors": ["Davoud Ataee Tarzanagh", "Yingcong Li", "Christos Thrampoulidis", "Samet Oymak"], "Categories": "cs.LG cs.AI cs.CL math.OC"}, "abstract": "Since its inception in \"Attention Is All You Need\", transformer architecture has led to revolutionary advancements in NLP. The attention layer within the transformer admits a sequence of input tokens $X$ and makes them interact through pairwise similarities computed as softmax$(XQK^\\top X^\\top)$, where $(K,Q)$ are the trainable key-query parameters. In this work, we establish a formal equivalence between the optimization geometry of self-attention and a hard-margin SVM problem that separates optimal input tokens from non-optimal tokens using linear constraints on the outer-products of token pairs. This formalism allows us to characterize the implicit bias of 1-layer transformers optimized with gradient descent: (1) Optimizing the attention layer with vanishing regularization, parameterized by $(K,Q)$, converges in direction to an SVM solution minimizing the nuclear norm of the combined parameter $W=KQ^\\top$. Instead, directly parameterizing by $W$ minimizes a Frobenius norm objective. We characterize this convergence, highlighting that it can occur toward locally-optimal directions rather than global ones. (2) Complementing this, we prove the local/global directional convergence of gradient descent under suitable geometric conditions. Importantly, we show that over-parameterization catalyzes global convergence by ensuring the feasibility of the SVM problem and by guaranteeing a benign optimization landscape devoid of stationary points. (3) While our theory applies primarily to linear prediction heads, we propose a more general SVM equivalence that predicts the implicit bias with nonlinear heads. Our findings are applicable to arbitrary datasets and their validity is verified via experiments. We also introduce several open problems and research directions. We believe these findings inspire the interpretation of transformers as a hierarchy of SVMs that separates and selects optimal tokens.", "url": "https://arxiv.org/abs/2308.16898"}, {"metadata": {"arXiv": "2308.16539", "Date": "Thu, 31 Aug 2023 08:30:11 ", "Title": "On a Connection between Differential Games, Optimal Control, and Energy-based Models for Multi-Agent Interactions", "Authors": ["Christopher Diehl and Tobias Klosek and Martin Kr\\\"uger and Nils Murzyn and Torsten Bertram"], "Categories": "cs.RO cs.AI cs.GT cs.LG cs.MA", "Comments": ["International Conference on Machine Learning", "Workshop on New Frontiers in Learning", "Control", "and Dynamical Systems (ICML 2023 Frontiers4LCD)"]}, "abstract": "Game theory offers an interpretable mathematical framework for modeling multi-agent interactions. However, its applicability in real-world robotics applications is hindered by several challenges, such as unknown agents' preferences and goals. To address these challenges, we show a connection between differential games, optimal control, and energy-based models and demonstrate how existing approaches can be unified under our proposed Energy-based Potential Game formulation. Building upon this formulation, this work introduces a new end-to-end learning application that combines neural networks for game-parameter inference with a differentiable game-theoretic optimization layer, acting as an inductive bias. The experiments using simulated mobile robot pedestrian interactions and real-world automated driving data provide empirical evidence that the game-theoretic layer improves the predictive performance of various neural network backbones.", "url": "https://arxiv.org/abs/2308.16539"}, {"metadata": {"arXiv": "2308.16893", "Date": "Thu, 31 Aug 2023 17:56:13 ", "Title": "Language-Conditioned Path Planning", "Authors": ["Amber Xie", "Youngwoon Lee", "Pieter Abbeel", "Stephen James"], "Categories": "cs.RO cs.AI cs.CV cs.LG", "Comments": ["Conference on Robot Learning", "2023"]}, "abstract": "Contact is at the core of robotic manipulation. At times, it is desired (e.g. manipulation and grasping), and at times, it is harmful (e.g. when avoiding obstacles). However, traditional path planning algorithms focus solely on collision-free paths, limiting their applicability in contact-rich tasks. To address this limitation, we propose the domain of Language-Conditioned Path Planning, where contact-awareness is incorporated into the path planning problem. As a first step in this domain, we propose Language-Conditioned Collision Functions (LACO) a novel approach that learns a collision function using only a single-view image, language prompt, and robot configuration. LACO predicts collisions between the robot and the environment, enabling flexible, conditional path planning without the need for manual object annotations, point cloud data, or ground-truth object meshes. In both simulation and the real world, we demonstrate that LACO can facilitate complex, nuanced path plans that allow for interaction with objects that are safe to collide, rather than prohibiting any collision.", "url": "https://arxiv.org/abs/2308.16893"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

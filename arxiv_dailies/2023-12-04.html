<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2312.00055", "Date": "Wed, 29 Nov 2023 04:25:52 ", "Title": "LEAP: LLM-Generation of Egocentric Action Programs", "Authors": ["Eadom Dessalene", "Michael Maynord", "Cornelia Ferm\\\"uller", "and Yiannis Aloimonos"], "Categories": "cs.CV cs.LG cs.RO", "Comments": ["Dataset: https://drive.google.com/drive/folders/1Cpkw_TI1IIxXdzor0pOXG3rWJWuKU5Ex?usp=drive_link"]}, "abstract": "We introduce LEAP (illustrated in Figure 1), a novel method for generating video-grounded action programs through use of a Large Language Model (LLM). These action programs represent the motoric, perceptual, and structural aspects of action, and consist of sub-actions, pre- and post-conditions, and control flows. LEAP's action programs are centered on egocentric video and employ recent developments in LLMs both as a source for program knowledge and as an aggregator and assessor of multimodal video information. We apply LEAP over a majority (87\\%) of the training set of the EPIC Kitchens dataset, and release the resulting action programs as a publicly available dataset here (https://drive.google.com/drive/folders/1Cpkw_TI1IIxXdzor0pOXG3rWJWuKU5Ex?usp=drive_link). We employ LEAP as a secondary source of supervision, using its action programs in a loss term applied to action recognition and anticipation networks. We demonstrate sizable improvements in performance in both tasks due to training with the LEAP dataset. Our method achieves 1st place on the EPIC Kitchens Action Recognition leaderboard as of November 17 among the networks restricted to RGB-input (see Supplementary Materials).", "url": "https://arxiv.org/abs/2312.00055"}, {"metadata": {"arXiv": "2312.00083", "Date": "Thu, 30 Nov 2023 07:16:11 ", "Title": "BAM-DETR: Boundary-Aligned Moment Detection Transformer for Temporal Sentence Grounding in Videos", "Authors": ["Pilhyeon Lee", "Hyeran Byun"], "Categories": "cs.CV cs.LG", "Comments": ["Technical report"]}, "abstract": "Temporal sentence grounding aims to localize moments relevant to a language description. Recently, DETR-like approaches have shown notable progress by decoding the center and length of a target moment from learnable queries. However, they suffer from the issue of center misalignment raised by the inherent ambiguity of moment centers, leading to inaccurate predictions. To remedy this problem, we introduce a novel boundary-oriented moment formulation. In our paradigm, the model no longer needs to find the precise center but instead suffices to predict any anchor point within the interval, from which the onset and offset are directly estimated. Based on this idea, we design a Boundary-Aligned Moment Detection Transformer (BAM-DETR), equipped with a dual-pathway decoding process. Specifically, it refines the anchor and boundaries within parallel pathways using global and boundary-focused attention, respectively. This separate design allows the model to focus on desirable regions, enabling precise refinement of moment predictions. Further, we propose a quality-based ranking method, ensuring that proposals with high localization qualities are prioritized over incomplete ones. Extensive experiments verify the advantages of our methods, where our model records new state-of-the-art results on three benchmarks. Code is at https://github.com/Pilhyeon/BAM-DETR.", "url": "https://arxiv.org/abs/2312.00083"}, {"metadata": {"arXiv": "2312.00093", "Date": "Thu, 30 Nov 2023 18:59:58 ", "Title": "GraphDreamer: Compositional 3D Scene Synthesis from Scene Graphs", "Authors": ["Gege Gao", "Weiyang Liu", "Anpei Chen", "Andreas Geiger", "Bernhard Sch\\\"olkopf"], "Categories": "cs.CV cs.GR cs.LG", "Comments": ["Technical Report (18 pages", "11 figures", "https://graphdreamer.github.io/)"]}, "abstract": "As pretrained text-to-image diffusion models become increasingly powerful, recent efforts have been made to distill knowledge from these text-to-image pretrained models for optimizing a text-guided 3D model. Most of the existing methods generate a holistic 3D model from a plain text input. This can be problematic when the text describes a complex scene with multiple objects, because the vectorized text embeddings are inherently unable to capture a complex description with multiple entities and relationships. Holistic 3D modeling of the entire scene further prevents accurate grounding of text entities and concepts. To address this limitation, we propose GraphDreamer, a novel framework to generate compositional 3D scenes from scene graphs, where objects are represented as nodes and their interactions as edges. By exploiting node and edge information in scene graphs, our method makes better use of the pretrained text-to-image diffusion model and is able to fully disentangle different objects without image-level supervision. To facilitate modeling of object-wise relationships, we use signed distance fields as representation and impose a constraint to avoid inter-penetration of objects. To avoid manual scene graph creation, we design a text prompt for ChatGPT to generate scene graphs based on text inputs. We conduct both qualitative and quantitative experiments to validate the effectiveness of GraphDreamer in generating high-fidelity compositional 3D scenes with disentangled object entities.", "url": "https://arxiv.org/abs/2312.00093"}, {"metadata": {"arXiv": "2312.00105", "Date": "Thu, 30 Nov 2023 17:15:58 ", "Title": "Improving the Robustness of Quantized Deep Neural Networks to White-Box Attacks using Stochastic Quantization and Information-Theoretic Ensemble Training", "Authors": ["Saurabh Farkya", "Aswin Raghavan", "Avi Ziskind"], "Categories": "cs.CV cs.CR cs.LG", "Comments": ["9 pages", "9 figures", "4 tables"]}, "abstract": "Most real-world applications that employ deep neural networks (DNNs) quantize them to low precision to reduce the compute needs. We present a method to improve the robustness of quantized DNNs to white-box adversarial attacks. We first tackle the limitation of deterministic quantization to fixed ``bins'' by introducing a differentiable Stochastic Quantizer (SQ). We explore the hypothesis that different quantizations may collectively be more robust than each quantized DNN. We formulate a training objective to encourage different quantized DNNs to learn different representations of the input image. The training objective captures diversity and accuracy via mutual information between ensemble members. Through experimentation, we demonstrate substantial improvement in robustness against $L_\\infty$ attacks even if the attacker is allowed to backpropagate through SQ (e.g., > 50\\% accuracy to PGD(5/255) on CIFAR10 without adversarial training), compared to vanilla DNNs as well as existing ensembles of quantized DNNs. We extend the method to detect attacks and generate robustness profiles in the adversarial information plane (AIP), towards a unified analysis of different threat models by correlating the MI and accuracy.", "url": "https://arxiv.org/abs/2312.00105"}, {"metadata": {"arXiv": "2312.00116", "Date": "Thu, 30 Nov 2023 18:59:49 ", "Title": "S2ST: Image-to-Image Translation in the Seed Space of Latent Diffusion", "Authors": ["Or Greenberg", "Eran Kishon", "Dani Lischinski"], "Categories": "cs.CV cs.GR cs.LG", "Comments": ["17 pages", "15 figures"]}, "abstract": "Image-to-image translation (I2IT) refers to the process of transforming images from a source domain to a target domain while maintaining a fundamental connection in terms of image content. In the past few years, remarkable advancements in I2IT were achieved by Generative Adversarial Networks (GANs), which nevertheless struggle with translations requiring high precision. Recently, Diffusion Models have established themselves as the engine of choice for image generation. In this paper we introduce S2ST, a novel framework designed to accomplish global I2IT in complex photorealistic images, such as day-to-night or clear-to-rain translations of automotive scenes. S2ST operates within the seed space of a Latent Diffusion Model, thereby leveraging the powerful image priors learned by the latter. We show that S2ST surpasses state-of-the-art GAN-based I2IT methods, as well as diffusion-based approaches, for complex automotive scenes, improving fidelity while respecting the target domain's appearance across a variety of domains. Notably, S2ST obviates the necessity for training domain-specific translation networks.", "url": "https://arxiv.org/abs/2312.00116"}, {"metadata": {"arXiv": "2312.00206", "Date": "Thu, 30 Nov 2023 21:38:22 ", "Title": "SparseGS: Real-Time 360{\\deg} Sparse View Synthesis using Gaussian Splatting", "Authors": ["Haolin Xiong and Sairisheek Muttukuru and Rishi Upadhyay and Pradyumna Chari and Achuta Kadambi"], "Categories": "cs.CV cs.LG eess.IV", "Comments": ["The main text spans eight pages", "followed by two pages of references and four pages of supplementary materials"]}, "abstract": "The problem of novel view synthesis has grown significantly in popularity recently with the introduction of Neural Radiance Fields (NeRFs) and other implicit scene representation methods. A recent advance, 3D Gaussian Splatting (3DGS), leverages an explicit representation to achieve real-time rendering with high-quality results. However, 3DGS still requires an abundance of training views to generate a coherent scene representation. In few shot settings, similar to NeRF, 3DGS tends to overfit to training views, causing background collapse and excessive floaters, especially as the number of training views are reduced. We propose a method to enable training coherent 3DGS-based radiance fields of 360 scenes from sparse training views. We find that using naive depth priors is not sufficient and integrate depth priors with generative and explicit constraints to reduce background collapse, remove floaters, and enhance consistency from unseen viewpoints. Experiments show that our method outperforms base 3DGS by up to 30.5% and NeRF-based methods by up to 15.6% in LPIPS on the MipNeRF-360 dataset with substantially less training and inference cost.", "url": "https://arxiv.org/abs/2312.00206"}, {"metadata": {"arXiv": "2312.00252", "Date": "Thu, 30 Nov 2023 23:52:46 ", "Title": "PyNeRF: Pyramidal Neural Radiance Fields", "Authors": ["Haithem Turki", "Michael Zollh\\\"ofer", "Christian Richardt", "Deva Ramanan"], "Categories": "cs.CV cs.GR cs.LG", "Comments": ["Neurips 2023 Project page: https://haithemturki.com/pynerf/"]}, "abstract": "Neural Radiance Fields (NeRFs) can be dramatically accelerated by spatial grid representations. However, they do not explicitly reason about scale and so introduce aliasing artifacts when reconstructing scenes captured at different camera distances. Mip-NeRF and its extensions propose scale-aware renderers that project volumetric frustums rather than point samples but such approaches rely on positional encodings that are not readily compatible with grid methods. We propose a simple modification to grid-based models by training model heads at different spatial grid resolutions. At render time, we simply use coarser grids to render samples that cover larger volumes. Our method can be easily applied to existing accelerated NeRF methods and significantly improves rendering quality (reducing error rates by 20-90% across synthetic and unbounded real-world scenes) while incurring minimal performance overhead (as each model head is quick to evaluate). Compared to Mip-NeRF, we reduce error rates by 20% while training over 60x faster.", "url": "https://arxiv.org/abs/2312.00252"}, {"metadata": {"arXiv": "2312.00313", "Date": "Fri, 01 Dec 2023 03:12:04 ", "Title": "Improving Normalization with the James-Stein Estimator", "Authors": ["Seyedalireza Khoshsirat and Chandra Kambhamettu"], "Categories": "cs.CV cs.LG"}, "abstract": "Stein's paradox holds considerable sway in high-dimensional statistics, highlighting that the sample mean, traditionally considered the de facto estimator, might not be the most efficacious in higher dimensions. To address this, the James-Stein estimator proposes an enhancement by steering the sample means toward a more centralized mean vector. In this paper, first, we establish that normalization layers in deep learning use inadmissible estimators for mean and variance. Next, we introduce a novel method to employ the James-Stein estimator to improve the estimation of mean and variance within normalization layers. We evaluate our method on different computer vision tasks: image classification, semantic segmentation, and 3D object classification. Through these evaluations, it is evident that our improved normalization layers consistently yield superior accuracy across all tasks without extra computational burden. Moreover, recognizing that a plethora of shrinkage estimators surpass the traditional estimator in performance, we study two other prominent shrinkage estimators: Ridge and LASSO. Additionally, we provide visual representations to intuitively demonstrate the impact of shrinkage on the estimated layer statistics. Finally, we study the effect of regularization and batch size on our modified batch normalization. The studies show that our method is less sensitive to batch size and regularization, improving accuracy under various setups.", "url": "https://arxiv.org/abs/2312.00313"}, {"metadata": {"arXiv": "2312.00362", "Date": "Fri, 01 Dec 2023 05:59:08 ", "Title": "Dancing with Images: Video Distillation via Static-Dynamic Disentanglement", "Authors": ["Ziyu Wang", "Yue Xu", "Cewu Lu", "Yong-Lu Li"], "Categories": "cs.CV cs.LG"}, "abstract": "Recently, dataset distillation has paved the way towards efficient machine learning, especially for image datasets. However, the distillation for videos, characterized by an exclusive temporal dimension, remains an underexplored domain. In this work, we provide the first systematic study of video distillation and introduce a taxonomy to categorize temporal compression. Our investigation reveals that the temporal information is usually not well learned during distillation , and the temporal dimension of synthetic data contributes little. The observations motivate our unified framework of disentangling the dynamic and static information in the videos. It first distills the videos into still images as static memory and then compensates the dynamic and motion information with a learnable dynamic memory block. Our method achieves state-of-the-art on video datasets at different scales, with notably smaller storage expenditure. Our code will be publicly available.", "url": "https://arxiv.org/abs/2312.00362"}, {"metadata": {"arXiv": "2312.00454", "Date": "Fri, 01 Dec 2023 09:34:28 ", "Title": "An Encoding Framework for Binarized Images using HyperDimensional Computing", "Authors": ["Laura Smets", "Werner Van Leekwijck", "Ing Jyh Tsang", "and Steven Latr\\'e"], "Categories": "cs.CV cs.LG"}, "abstract": "Hyperdimensional Computing (HDC) is a brain-inspired and light-weight machine learning method. It has received significant attention in the literature as a candidate to be applied in the wearable internet of things, near-sensor artificial intelligence applications and on-device processing. HDC is computationally less complex than traditional deep learning algorithms and typically achieves moderate to good classification performance. A key aspect that determines the performance of HDC is the encoding of the input data to the hyperdimensional (HD) space. This article proposes a novel light-weight approach relying only on native HD arithmetic vector operations to encode binarized images that preserves similarity of patterns at nearby locations by using point of interest selection and local linear mapping. The method reaches an accuracy of 97.35% on the test set for the MNIST data set and 84.12% for the Fashion-MNIST data set. These results outperform other studies using baseline HDC with different encoding approaches and are on par with more complex hybrid HDC models. The proposed encoding approach also demonstrates a higher robustness to noise and blur compared to the baseline encoding.", "url": "https://arxiv.org/abs/2312.00454"}, {"metadata": {"arXiv": "2312.00639", "Date": "Fri, 01 Dec 2023 14:59:43 ", "Title": "EvE: Exploiting Generative Priors for Radiance Field Enrichment", "Authors": ["Karim Kassab", "Antoine Schnepf", "Jean-Yves Franceschi", "Laurent Caraffa", "Jeremie Mary", "Val\\'erie Gouet-Brunet"], "Categories": "cs.CV cs.LG"}, "abstract": "Modeling large-scale scenes from unconstrained image collections in-the-wild has proven to be a major challenge in computer vision. Existing methods tackling in-the-wild neural rendering operate in a closed-world setting, where knowledge is limited to a scene's captured images within a training set. We propose EvE, which is, to the best of our knowledge, the first method leveraging generative priors to improve in-the-wild scene modeling. We employ pre-trained generative networks to enrich K-Planes representations with extrinsic knowledge. To this end, we define an alternating training procedure to conduct optimization guidance of K-Planes trained on the training set. We carry out extensive experiments and verify the merit of our method on synthetic data as well as real tourism photo collections. EvE enhances rendered scenes with richer details and outperforms the state of the art on the task of novel view synthesis in-the-wild. Our project page can be found at https://eve-nvs.github.io .", "url": "https://arxiv.org/abs/2312.00639"}, {"metadata": {"arXiv": "2312.00671", "Date": "Fri, 01 Dec 2023 15:50:20 ", "Title": "CellMixer: Annotation-free Semantic Cell Segmentation of Heterogeneous Cell Populations", "Authors": ["Mehdi Naouar", "Gabriel Kalweit", "Anusha Klett", "Yannick Vogt", "Paula Silvestrini", "Diana Laura Infante Ramirez", "Roland Mertelsmann", "Joschka Boedecker", "Maria Kalweit"], "Categories": "cs.CV cs.LG", "Comments": ["Medical Imaging Meets NeurIPS 2023"]}, "abstract": "In recent years, several unsupervised cell segmentation methods have been presented, trying to omit the requirement of laborious pixel-level annotations for the training of a cell segmentation model. Most if not all of these methods handle the instance segmentation task by focusing on the detection of different cell instances ignoring their type. While such models prove adequate for certain tasks, like cell counting, other applications require the identification of each cell's type. In this paper, we present CellMixer, an innovative annotation-free approach for the semantic segmentation of heterogeneous cell populations. Our augmentation-based method enables the training of a segmentation model from image-level labels of homogeneous cell populations. Our results show that CellMixer can achieve competitive segmentation performance across multiple cell types and imaging modalities, demonstrating the method's scalability and potential for broader applications in medical imaging, cellular biology, and diagnostics.", "url": "https://arxiv.org/abs/2312.00671"}, {"metadata": {"arXiv": "2312.00694", "Date": "Fri, 01 Dec 2023 16:27:48 ", "Title": "Object Detector Differences when using Synthetic and Real Training Data", "Authors": ["Martin Georg Ljungqvist", "Otto Nordander", "Markus Skans", "Arvid Mildner", "Tony Liu", "Pierre Nugues"], "Categories": "cs.CV cs.LG", "Comments": ["27 pages. The Version of Record of this article is published in Springer Nature Computer Science 2023", "and is available online at https://doi.org/10.1007/s42979-023-01704-5"], "ACM-class": "I.4.0; I.2.10; I.5.0", "Journal-ref": "SN COMPUT. SCI. 4, 302 (2023)", "DOI": "10.1007/s42979-023-01704-5"}, "abstract": "To train well-performing generalizing neural networks, sufficiently large and diverse datasets are needed. Collecting data while adhering to privacy legislation becomes increasingly difficult and annotating these large datasets is both a resource-heavy and time-consuming task. An approach to overcome these difficulties is to use synthetic data since it is inherently scalable and can be automatically annotated. However, how training on synthetic data affects the layers of a neural network is still unclear. In this paper, we train the YOLOv3 object detector on real and synthetic images from city environments. We perform a similarity analysis using Centered Kernel Alignment (CKA) to explore the effects of training on synthetic data on a layer-wise basis. The analysis captures the architecture of the detector while showing both different and similar patterns between different models. With this similarity analysis we want to give insights on how training synthetic data affects each layer and to give a better understanding of the inner workings of complex neural networks. The results show that the largest similarity between a detector trained on real data and a detector trained on synthetic data was in the early layers, and the largest difference was in the head part. The results also show that no major difference in performance or similarity could be seen between frozen and unfrozen backbone.", "url": "https://arxiv.org/abs/2312.00694"}, {"metadata": {"arXiv": "2312.00700", "Date": "Fri, 01 Dec 2023 16:33:57 ", "Title": "GIFT: Generative Interpretable Fine-Tuning Transformers", "Authors": ["Chinmay Savadikar", "Xi Song", "Tianfu Wu"], "Categories": "cs.CV cs.LG", "Comments": ["18 pages", "12 figures"]}, "abstract": "We present GIFT (Generative Interpretable Fine-tuning Transformers) for fine-tuning pretrained (often large) Transformer models at downstream tasks in a parameter-efficient way with built-in interpretability. Our GIFT is a deep parameter-residual learning method, which addresses two problems in fine-tuning a pretrained Transformer model: Where to apply the parameter-efficient fine-tuning (PEFT) to be extremely lightweight yet sufficiently expressive, and How to learn the PEFT to better exploit the knowledge of the pretrained model in a direct way? For the former, we select the final projection (linear) layer in the multi-head self-attention of a Transformer model, and verify its effectiveness. For the latter, in contrast to the prior art that directly introduce new model parameters (often in low-rank approximation form) to be learned in fine-tuning with downstream data, we propose a method for learning to generate the fine-tuning parameters. Our GIFT is a hyper-Transformer which take as input the pretrained parameters of the projection layer to generate its fine-tuning parameters using a proposed Parameter-to-Cluster Attention (PaCa). The PaCa results in a simple clustering-based forward explainer that plays the role of semantic segmentation in testing. In experiments, our proposed GIFT is tested on the VTAB benchmark and the fine-grained visual classification (FGVC) benchmark. It obtains significantly better performance than the prior art. Our code is available at https://github.com/savadikarc/gift", "url": "https://arxiv.org/abs/2312.00700"}, {"metadata": {"arXiv": "2312.00066", "Date": "Wed, 29 Nov 2023 19:44:52 ", "Title": "Exploring Factors Affecting Pedestrian Crash Severity Using TabNet: A Deep Learning Approach", "Authors": ["Amir Rafe and Patrick A. Singleton"], "Categories": "cs.LG"}, "abstract": "This study presents the first investigation of pedestrian crash severity using the TabNet model, a novel tabular deep learning method exceptionally suited for analyzing the tabular data inherent in transportation safety research. Through the application of TabNet to a comprehensive dataset from Utah covering the years 2010 to 2022, we uncover intricate factors contributing to pedestrian crash severity. The TabNet model, capitalizing on its compatibility with structured data, demonstrates remarkable predictive accuracy, eclipsing that of traditional models. It identifies critical variables, such as pedestrian age, involvement in left or right turns, lighting conditions, and alcohol consumption, which significantly influence crash outcomes. The utilization of SHapley Additive exPlanations (SHAP) enhances our ability to interpret the TabNet model's predictions, ensuring transparency and understandability in our deep learning approach. The insights derived from our analysis provide a valuable compass for transportation safety engineers and policymakers, enabling the identification of pivotal factors that affect pedestrian crash severity. Such knowledge is instrumental in formulating precise, data-driven interventions aimed at bolstering pedestrian safety across diverse urban and rural settings.", "url": "https://arxiv.org/abs/2312.00066"}, {"metadata": {"arXiv": "2312.00076", "Date": "Thu, 30 Nov 2023 00:34:09 ", "Title": "Towards A Foundation Model For Trajectory Intelligence", "Authors": ["Alameen Najjar"], "Categories": "cs.LG cs.CY cs.SI", "Comments": ["Accepted to the 2023 IEEE International Conference on Data Mining Workshops (ICDMW)"]}, "abstract": "We present the results of training a large trajectory model using real-world user check-in data. Our approach follows a pre-train and fine-tune paradigm, where a base model is pre-trained via masked trajectory modeling and then adapted through fine-tuning for various downstream tasks. To address challenges posed by noisy data and large spatial vocabularies, we propose a novel spatial tokenization block. Our empirical analysis utilizes a comprehensive dataset of over 2 billion check-ins generated by more than 6 million users. Through fine-tuning on 3 downstream tasks we demonstrate that our base model has effectively learned valuable underlying patterns in raw data, enabling its application in meaningful trajectory intelligence tasks. Despite some limitations, we believe this work represents an important step forward in the realization of a foundation model for trajectory intelligence.", "url": "https://arxiv.org/abs/2312.00076"}, {"metadata": {"arXiv": "2312.00088", "Date": "Thu, 30 Nov 2023 07:49:33 ", "Title": "Anomaly Detection via Learning-Based Sequential Controlled Sensing", "Authors": ["Geethu Joseph", "Chen Zhong", "M. Cenk Gursoy", "Senem Velipasalar", "and Pramod K. Varshney"], "Categories": "cs.LG cs.SY eess.SP eess.SY"}, "abstract": "In this paper, we address the problem of detecting anomalies among a given set of binary processes via learning-based controlled sensing. Each process is parameterized by a binary random variable indicating whether the process is anomalous. To identify the anomalies, the decision-making agent is allowed to observe a subset of the processes at each time instant. Also, probing each process has an associated cost. Our objective is to design a sequential selection policy that dynamically determines which processes to observe at each time with the goal to minimize the delay in making the decision and the total sensing cost. We cast this problem as a sequential hypothesis testing problem within the framework of Markov decision processes. This formulation utilizes both a Bayesian log-likelihood ratio-based reward and an entropy-based reward. The problem is then solved using two approaches: 1) a deep reinforcement learning-based approach where we design both deep Q-learning and policy gradient actor-critic algorithms; and 2) a deep active inference-based approach. Using numerical experiments, we demonstrate the efficacy of our algorithms and show that our algorithms adapt to any unknown statistical dependence pattern of the processes.", "url": "https://arxiv.org/abs/2312.00088"}, {"metadata": {"arXiv": "2312.00090", "Date": "Thu, 30 Nov 2023 08:47:37 ", "Title": "Tree-based Forecasting of Day-ahead Solar Power Generation from Granular Meteorological Features", "Authors": ["Nick Berlanger", "Noah van Ophoven", "Tim Verdonck", "Ines Wilms"], "Categories": "cs.LG stat.AP"}, "abstract": "Accurate forecasts for day-ahead photovoltaic (PV) power generation are crucial to support a high PV penetration rate in the local electricity grid and to assure stability in the grid. We use state-of-the-art tree-based machine learning methods to produce such forecasts and, unlike previous studies, we hereby account for (i) the effects various meteorological as well as astronomical features have on PV power production, and this (ii) at coarse as well as granular spatial locations. To this end, we use data from Belgium and forecast day-ahead PV power production at an hourly resolution. The insights from our study can assist utilities, decision-makers, and other stakeholders in optimizing grid operations, economic dispatch, and in facilitating the integration of distributed PV power into the electricity grid.", "url": "https://arxiv.org/abs/2312.00090"}, {"metadata": {"arXiv": "2312.00095", "Date": "Thu, 30 Nov 2023 13:17:22 ", "Title": "Textual-Knowledge-Guided Numerical Feature Discovery Method for Power Demand Forecasting", "Authors": ["Zifan Ning", "Min Jin"], "Categories": "cs.LG", "Comments": ["12 pages", "12 figures"]}, "abstract": "Power demand forecasting is a crucial and challenging task for new power system and integrated energy system. However, as public feature databases and the theoretical mechanism of power demand changes are unavailable, the known features of power demand fluctuation are much limited. Recently, multimodal learning approaches have shown great vitality in machine learning and AIGC. In this paper, we interact two modal data and propose a textual-knowledge-guided numerical feature discovery (TKNFD) method for short-term power demand forecasting. TKNFD extensively accumulates qualitative textual knowledge, expands it into a candidate feature-type set, collects numerical data of these features, and eventually builds four-dimensional multivariate source-tracking databases (4DM-STDs). Next, TKNFD presents a two-level quantitative feature identification strategy independent of forecasting models, finds 43-48 features, and systematically analyses feature contribution and dependency correlation. Benchmark experiments in two different regions around the world demonstrate that the forecasting accuracy of TKNFD-discovered features reliably outperforms that of SoTA feature schemes by 16.84% to 36.36% MAPE. In particular, TKNFD reveals many unknown features, especially several dominant features in the unknown energy and astronomical dimensions, which extend the knowledge on the origin of strong randomness and non-linearity in power demand fluctuation. Besides, 4DM-STDs can serve as public baseline databases.", "url": "https://arxiv.org/abs/2312.00095"}, {"metadata": {"arXiv": "2312.00103", "Date": "Thu, 30 Nov 2023 16:54:36 ", "Title": "DeepEn2023: Energy Datasets for Edge Artificial Intelligence", "Authors": ["Xiaolong Tu", "Anik Mallik", "Haoxin Wang", "Jiang Xie"], "Categories": "cs.LG cs.PF", "Comments": ["arXiv admin note: text overlap with arXiv:2310.18329"]}, "abstract": "Climate change poses one of the most significant challenges to humanity. As a result of these climatic changes, the frequency of weather, climate, and water-related disasters has multiplied fivefold over the past 50 years, resulting in over 2 million deaths and losses exceeding $3.64 trillion USD. Leveraging AI-powered technologies for sustainable development and combating climate change is a promising avenue. Numerous significant publications are dedicated to using AI to improve renewable energy forecasting, enhance waste management, and monitor environmental changes in real time. However, very few research studies focus on making AI itself environmentally sustainable. This oversight regarding the sustainability of AI within the field might be attributed to a mindset gap and the absence of comprehensive energy datasets. In addition, with the ubiquity of edge AI systems and applications, especially on-device learning, there is a pressing need to measure, analyze, and optimize their environmental sustainability, such as energy efficiency. To this end, in this paper, we propose large-scale energy datasets for edge AI, named DeepEn2023, covering a wide range of kernels, state-of-the-art deep neural network models, and popular edge AI applications. We anticipate that DeepEn2023 will improve transparency in sustainability in on-device deep learning across a range of edge AI systems and applications. For more information, including access to the dataset and code, please visit https://amai-gsu.github.io/DeepEn2023.", "url": "https://arxiv.org/abs/2312.00103"}, {"metadata": {"arXiv": "2312.00111", "Date": "Thu, 30 Nov 2023 18:35:29 ", "Title": "Multimodal Learning for Crystalline Materials", "Authors": ["Viggo Moro", "Charlotte Loh", "Rumen Dangovski", "Ali Ghorashi", "Andrew Ma", "Zhuo Chen", "Peter Y. Lu", "Thomas Christensen", "Marin Solja\\v{c}i\\'c"], "Categories": "cs.LG cond-mat.mtrl-sci", "Comments": ["11 pages", "3 figures"]}, "abstract": "Artificial intelligence (AI) has revolutionized the field of materials science by improving the prediction of properties and accelerating the discovery of novel materials. In recent years, publicly available material data repositories containing data for various material properties have grown rapidly. In this work, we introduce Multimodal Learning for Crystalline Materials (MLCM), a new method for training a foundation model for crystalline materials via multimodal alignment, where high-dimensional material properties (i.e. modalities) are connected in a shared latent space to produce highly useful material representations. We show the utility of MLCM on multiple axes: (i) MLCM achieves state-of-the-art performance for material property prediction on the challenging Materials Project database; (ii) MLCM enables a novel, highly accurate method for inverse design, allowing one to screen for stable material with desired properties; and (iii) MLCM allows the extraction of interpretable emergent features that may provide insight to material scientists. Further, we explore several novel methods for aligning an arbitrary number of modalities, improving upon prior art in multimodal learning that focuses on bimodal alignment. Our work brings innovations from the ongoing AI revolution into the domain of materials science and identifies materials as a testbed for the next generation of AI.", "url": "https://arxiv.org/abs/2312.00111"}, {"metadata": {"arXiv": "2312.00157", "Date": "Thu, 30 Nov 2023 19:37:47 ", "Title": "Universal Backdoor Attacks", "Authors": ["Benjamin Schneider", "Nils Lukas", "Florian Kerschbaum"], "Categories": "cs.LG cs.CR cs.CV"}, "abstract": "Web-scraped datasets are vulnerable to data poisoning, which can be used for backdooring deep image classifiers during training. Since training on large datasets is expensive, a model is trained once and re-used many times. Unlike adversarial examples, backdoor attacks often target specific classes rather than any class learned by the model. One might expect that targeting many classes through a naive composition of attacks vastly increases the number of poison samples. We show this is not necessarily true and more efficient, universal data poisoning attacks exist that allow controlling misclassifications from any source class into any target class with a small increase in poison samples. Our idea is to generate triggers with salient characteristics that the model can learn. The triggers we craft exploit a phenomenon we call inter-class poison transferability, where learning a trigger from one class makes the model more vulnerable to learning triggers for other classes. We demonstrate the effectiveness and robustness of our universal backdoor attacks by controlling models with up to 6,000 classes while poisoning only 0.15% of the training dataset.", "url": "https://arxiv.org/abs/2312.00157"}, {"metadata": {"arXiv": "2312.00170", "Date": "Thu, 30 Nov 2023 20:02:25 ", "Title": "Non-uniform Online Learning: Towards Understanding Induction", "Authors": ["Zhou Lu"], "Categories": "cs.LG", "Comments": ["A manuscript. Comments are most welcome!"]}, "abstract": "Can a physicist make only finite errors in the endless pursuit of the law of nature? This millennium-old question of inductive inference is a fundamental, yet mysterious problem in philosophy, lacking rigorous justifications. While classic online learning theory and inductive inference share a similar sequential decision-making spirit, the former's reliance on an adaptive adversary and worst-case error bounds limits its applicability to the latter. In this work, we introduce the concept of non-uniform online learning, which we argue aligns more closely with the principles of inductive reasoning. This setting assumes a predetermined ground-truth hypothesis and considers non-uniform, hypothesis-wise error bounds. In the realizable setting, we provide a complete characterization of learnability with finite error: a hypothesis class is non-uniform learnable if and only if it's a countable union of Littlestone classes, no matter the observations are adaptively chosen or iid sampled. Additionally, we propose a necessary condition for the weaker criterion of consistency which we conjecture to be tight. To further promote our theory, we extend our result to the more realistic agnostic setting, showing that any countable union of Littlestone classes can be learnt with regret $\\tilde{O}(\\sqrt{T})$. We hope this work could offer a new perspective of interpreting the power of induction from an online learning viewpoint.", "url": "https://arxiv.org/abs/2312.00170"}, {"metadata": {"arXiv": "2312.00192", "Date": "Thu, 30 Nov 2023 21:07:26 ", "Title": "Benchmarking and Enhancing Disentanglement in Concept-Residual Models", "Authors": ["Renos Zabounidis", "Ini Oguntola", "Konghao Zhao", "Joseph Campbell", "Simon Stepputtis", "Katia Sycara"], "Categories": "cs.LG cs.CV"}, "abstract": "Concept bottleneck models (CBMs) are interpretable models that first predict a set of semantically meaningful features, i.e., concepts, from observations that are subsequently used to condition a downstream task. However, the model's performance strongly depends on the engineered features and can severely suffer from incomplete sets of concepts. Prior works have proposed a side channel -- a residual -- that allows for unconstrained information flow to the downstream task, thus improving model performance but simultaneously introducing information leakage, which is undesirable for interpretability. This work proposes three novel approaches to mitigate information leakage by disentangling concepts and residuals, investigating the critical balance between model performance and interpretability. Through extensive empirical analysis on the CUB, OAI, and CIFAR 100 datasets, we assess the performance of each disentanglement method and provide insights into when they work best. Further, we show how each method impacts the ability to intervene over the concepts and their subsequent impact on task performance.", "url": "https://arxiv.org/abs/2312.00192"}, {"metadata": {"arXiv": "2312.00194", "Date": "Thu, 30 Nov 2023 21:10:44 ", "Title": "Robust Concept Erasure via Kernelized Rate-Distortion Maximization", "Authors": ["Somnath Basu Roy Chowdhury", "Nicholas Monath", "Avinava Dubey", "Amr Ahmed", "Snigdha Chaturvedi"], "Categories": "cs.LG cs.CL", "Comments": ["NeurIPS 2023"]}, "abstract": "Distributed representations provide a vector space that captures meaningful relationships between data instances. The distributed nature of these representations, however, entangles together multiple attributes or concepts of data instances (e.g., the topic or sentiment of a text, characteristics of the author (age, gender, etc), etc). Recent work has proposed the task of concept erasure, in which rather than making a concept predictable, the goal is to remove an attribute from distributed representations while retaining other information from the original representation space as much as possible. In this paper, we propose a new distance metric learning-based objective, the Kernelized Rate-Distortion Maximizer (KRaM), for performing concept erasure. KRaM fits a transformation of representations to match a specified distance measure (defined by a labeled concept to erase) using a modified rate-distortion function. Specifically, KRaM's objective function aims to make instances with similar concept labels dissimilar in the learned representation space while retaining other information. We find that optimizing KRaM effectively erases various types of concepts: categorical, continuous, and vector-valued variables from data representations across diverse domains. We also provide a theoretical analysis of several properties of KRaM's objective. To assess the quality of the learned representations, we propose an alignment score to evaluate their similarity with the original representation space. Additionally, we conduct experiments to showcase KRaM's efficacy in various settings, from erasing binary gender variables in word embeddings to vector-valued variables in GPT-3 representations.", "url": "https://arxiv.org/abs/2312.00194"}, {"metadata": {"arXiv": "2312.00198", "Date": "Thu, 30 Nov 2023 21:21:47 ", "Title": "Optimal Attack and Defense for Reinforcement Learning", "Authors": ["Jeremy McMahan", "Young Wu", "Xiaojin Zhu", "Qiaomin Xie"], "Categories": "cs.LG cs.CR cs.GT"}, "abstract": "To ensure the usefulness of Reinforcement Learning (RL) in real systems, it is crucial to ensure they are robust to noise and adversarial attacks. In adversarial RL, an external attacker has the power to manipulate the victim agent's interaction with the environment. We study the full class of online manipulation attacks, which include (i) state attacks, (ii) observation attacks (which are a generalization of perceived-state attacks), (iii) action attacks, and (iv) reward attacks. We show the attacker's problem of designing a stealthy attack that maximizes its own expected reward, which often corresponds to minimizing the victim's value, is captured by a Markov Decision Process (MDP) that we call a meta-MDP since it is not the true environment but a higher level environment induced by the attacked interaction. We show that the attacker can derive optimal attacks by planning in polynomial time or learning with polynomial sample complexity using standard RL techniques. We argue that the optimal defense policy for the victim can be computed as the solution to a stochastic Stackelberg game, which can be further simplified into a partially-observable turn-based stochastic game (POTBSG). Neither the attacker nor the victim would benefit from deviating from their respective optimal policies, thus such solutions are truly robust. Although the defense problem is NP-hard, we show that optimal Markovian defenses can be computed (learned) in polynomial time (sample complexity) in many scenarios.", "url": "https://arxiv.org/abs/2312.00198"}, {"metadata": {"arXiv": "2312.00234", "Date": "Thu, 30 Nov 2023 22:34:57 ", "Title": "Deep Equilibrium Based Neural Operators for Steady-State PDEs", "Authors": ["Tanya Marwah", "Ashwini Pokle", "J. Zico Kolter", "Zachary C. Lipton", "Jianfeng Lu", "Andrej Risteski"], "Categories": "cs.LG cs.NA math.NA stat.ML", "Comments": ["NeurIPS 2023"]}, "abstract": "Data-driven machine learning approaches are being increasingly used to solve partial differential equations (PDEs). They have shown particularly striking successes when training an operator, which takes as input a PDE in some family, and outputs its solution. However, the architectural design space, especially given structural knowledge of the PDE family of interest, is still poorly understood. We seek to remedy this gap by studying the benefits of weight-tied neural network architectures for steady-state PDEs. To achieve this, we first demonstrate that the solution of most steady-state PDEs can be expressed as a fixed point of a non-linear operator. Motivated by this observation, we propose FNO-DEQ, a deep equilibrium variant of the FNO architecture that directly solves for the solution of a steady-state PDE as the infinite-depth fixed point of an implicit operator layer using a black-box root solver and differentiates analytically through this fixed point resulting in $\\mathcal{O}(1)$ training memory. Our experiments indicate that FNO-DEQ-based architectures outperform FNO-based baselines with $4\\times$ the number of parameters in predicting the solution to steady-state PDEs such as Darcy Flow and steady-state incompressible Navier-Stokes. Finally, we show FNO-DEQ is more robust when trained with datasets with more noisy observations than the FNO-based baselines, demonstrating the benefits of using appropriate inductive biases in architectural design for different neural network based PDE solvers. Further, we show a universal approximation result that demonstrates that FNO-DEQ can approximate the solution to any steady-state PDE that can be written as a fixed point equation.", "url": "https://arxiv.org/abs/2312.00234"}, {"metadata": {"arXiv": "2312.00246", "Date": "Thu, 30 Nov 2023 23:24:45 ", "Title": "Curvature Explains Loss of Plasticity", "Authors": ["Alex Lewandowski", "Haruto Tanaka", "Dale Schuurmans", "Marlos C. Machado"], "Categories": "cs.LG"}, "abstract": "Loss of plasticity is a phenomenon in which neural networks lose their ability to learn from new experience. Despite being empirically observed in several problem settings, little is understood about the mechanisms that lead to loss of plasticity. In this paper, we offer a consistent explanation for plasticity loss, based on an assertion that neural networks lose directions of curvature during training and that plasticity loss can be attributed to this reduction in curvature. To support such a claim, we provide a systematic empirical investigation of plasticity loss across several continual supervised learning problems. Our findings illustrate that curvature loss coincides with and sometimes precedes plasticity loss, while also showing that previous explanations are insufficient to explain loss of plasticity in all settings. Lastly, we show that regularizers which mitigate loss of plasticity also preserve curvature, motivating a simple distributional regularizer that proves to be effective across the problem settings considered.", "url": "https://arxiv.org/abs/2312.00246"}, {"metadata": {"arXiv": "2312.00271", "Date": "Fri, 01 Dec 2023 01:11:16 ", "Title": "Towards Clinical Prediction with Transparency: An Explainable AI Approach to Survival Modelling in Residential Aged Care", "Authors": ["Teo Susnjak", "Elise Griffin", "Mitchell McCutcheon", "Kathleen Potter"], "Categories": "cs.LG"}, "abstract": "Background: Accurate survival time estimates aid end-of-life medical decision-making. Objectives: Develop an interpretable survival model for elderly residential aged care residents using advanced machine learning. Setting: A major Australasian residential aged care provider. Participants: Residents aged 65+ admitted for long-term care from July 2017 to August 2023. Sample size: 11,944 residents across 40 facilities. Predictors: Factors include age, gender, health status, co-morbidities, cognitive function, mood, nutrition, mobility, smoking, sleep, skin integrity, and continence. Outcome: Probability of survival post-admission, specifically calibrated for 6-month survival estimates. Statistical Analysis: Tested CoxPH, EN, RR, Lasso, GB, XGB, and RF models in 20 experiments with a 90/10 train/test split. Evaluated accuracy using C-index, Harrell's C-index, dynamic AUROC, IBS, and calibrated ROC. Chose XGB for its performance and calibrated it for 1, 3, 6, and 12-month predictions using Platt scaling. Employed SHAP values to analyze predictor impacts. Results: GB, XGB, and RF models showed the highest C-Index values (0.714, 0.712, 0.712). The optimal XGB model demonstrated a 6-month survival prediction AUROC of 0.746 (95% CI 0.744-0.749). Key mortality predictors include age, male gender, mobility, health status, pressure ulcer risk, and appetite. Conclusions: The study successfully applies machine learning to create a survival model for aged care, aligning with clinical insights on mortality risk factors and enhancing model interpretability and clinical utility through explainable AI.", "url": "https://arxiv.org/abs/2312.00271"}, {"metadata": {"arXiv": "2312.00276", "Date": "Fri, 01 Dec 2023 01:25:04 ", "Title": "Automating Continual Learning", "Authors": ["Kazuki Irie", "R\\'obert Csord\\'as", "J\\\"urgen Schmidhuber"], "Categories": "cs.LG"}, "abstract": "General-purpose learning systems should improve themselves in open-ended fashion in ever-changing environments. Conventional learning algorithms for neural networks, however, suffer from catastrophic forgetting (CF) -- previously acquired skills are forgotten when a new task is learned. Instead of hand-crafting new algorithms for avoiding CF, we propose Automated Continual Learning (ACL) to train self-referential neural networks to meta-learn their own in-context continual (meta-)learning algorithms. ACL encodes all desiderata -- good performance on both old and new tasks -- into its meta-learning objectives. Our experiments demonstrate that ACL effectively solves \"in-context catastrophic forgetting\"; our ACL-learned algorithms outperform hand-crafted ones, e.g., on the Split-MNIST benchmark in the replay-free setting, and enables continual learning of diverse tasks consisting of multiple few-shot and standard image classification datasets.", "url": "https://arxiv.org/abs/2312.00276"}, {"metadata": {"arXiv": "2312.00277", "Date": "Fri, 01 Dec 2023 01:26:38 ", "Title": "Text Attribute Control via Closed-Loop Disentanglement", "Authors": ["Lei Sha", "Thomas Lukasiewicz"], "Categories": "cs.LG cs.CL", "Comments": ["accepted by TACL 2023"]}, "abstract": "Changing an attribute of a text without changing the content usually requires to first disentangle the text into irrelevant attributes and content representations. After that, in the inference phase, the representation of one attribute is tuned to a different value, expecting that the corresponding attribute of the text can also be changed accordingly. The usual way of disentanglement is to add some constraints on the latent space of an encoder-decoder architecture, including adversarial-based constraints and mutual-information-based constraints. However, the previous semi-supervised processes of attribute change are usually not enough to guarantee the success of attribute change and content preservation. In this paper, we propose a novel approach to achieve a robust control of attributes while enhancing content preservation. In this approach, we use a semi-supervised contrastive learning method to encourage the disentanglement of attributes in latent spaces. Differently from previous works, we re-disentangle the reconstructed sentence and compare the re-disentangled latent space with the original latent space, which makes a closed-loop disentanglement process. This also helps content preservation. In addition, the contrastive learning method is also able to replace the role of minimizing mutual information and adversarial training in the disentanglement process, which alleviates the computation cost. We conducted experiments on three text datasets, including the Yelp Service review dataset, the Amazon Product review dataset, and the GoEmotions dataset. The experimental results show the effectiveness of our model.", "url": "https://arxiv.org/abs/2312.00277"}, {"metadata": {"arXiv": "2312.00279", "Date": "Fri, 01 Dec 2023 01:30:49 ", "Title": "Age-Based Scheduling for Mobile Edge Computing: A Deep Reinforcement Learning Approach", "Authors": ["Xingqiu He", "Chaoqun You", "Tony Q. S. Quek"], "Categories": "cs.LG cs.NI"}, "abstract": "With the rapid development of Mobile Edge Computing (MEC), various real-time applications have been deployed to benefit people's daily lives. The performance of these applications relies heavily on the freshness of collected environmental information, which can be quantified by its Age of Information (AoI). In the traditional definition of AoI, it is assumed that the status information can be actively sampled and directly used. However, for many MEC-enabled applications, the desired status information is updated in an event-driven manner and necessitates data processing. To better serve these applications, we propose a new definition of AoI and, based on the redefined AoI, we formulate an online AoI minimization problem for MEC systems. Notably, the problem can be interpreted as a Markov Decision Process (MDP), thus enabling its solution through Reinforcement Learning (RL) algorithms. Nevertheless, the traditional RL algorithms are designed for MDPs with completely unknown system dynamics and hence usually suffer long convergence times. To accelerate the learning process, we introduce Post-Decision States (PDSs) to exploit the partial knowledge of the system's dynamics. We also combine PDSs with deep RL to further improve the algorithm's applicability, scalability, and robustness. Numerical results demonstrate that our algorithm outperforms the benchmarks under various scenarios.", "url": "https://arxiv.org/abs/2312.00279"}, {"metadata": {"arXiv": "2312.00290", "Date": "Fri, 01 Dec 2023 02:09:18 ", "Title": "Learning to forecast diagnostic parameters using pre-trained weather embedding", "Authors": ["Peetak P. Mitra", "Vivek Ramavajjala"], "Categories": "cs.LG", "Comments": ["Accepted as a spotlight paper at the NeurIPS 2023 workshop on Tackling Climate Change with Machine Learning"]}, "abstract": "Data-driven weather prediction (DDWP) models are increasingly becoming popular for weather forecasting. However, while operational weather forecasts predict a wide variety of weather variables, DDWPs currently forecast a specific set of key prognostic variables. Non-prognostic (\"diagnostic\") variables are sometimes modeled separately as dependent variables of the prognostic variables (c.f. FourCastNet), or by including the diagnostic variable as a target in the DDWP. However, the cost of training and deploying bespoke models for each diagnostic variable can increase dramatically with more diagnostic variables, and limit the operational use of such models. Likewise, retraining an entire DDWP each time a new diagnostic variable is added is also cost-prohibitive. We present an two-stage approach that allows new diagnostic variables to be added to an end-to-end DDWP model without the expensive retraining. In the first stage, we train an autoencoder that learns to embed prognostic variables into a latent space. In the second stage, the autoencoder is frozen and \"downstream\" models are trained to predict diagnostic variables using only the latent representations of prognostic variables as input. Our experiments indicate that models trained using the two-stage approach offer accuracy comparable to training bespoke models, while leading to significant reduction in resource utilization during training and inference. This approach allows for new \"downstream\" models to be developed as needed, without affecting existing models and thus reducing the friction in operationalizing new models.", "url": "https://arxiv.org/abs/2312.00290"}, {"metadata": {"arXiv": "2312.00296", "Date": "Fri, 01 Dec 2023 02:24:07 ", "Title": "Towards Aligned Canonical Correlation Analysis: Preliminary Formulation and Proof-of-Concept Results", "Authors": ["Biqian Cheng", "Evangelos E. Papalexakis", "Jia Chen"], "Categories": "cs.LG stat.ML", "Comments": ["4 pages", "7 figures", "MLG 2023"]}, "abstract": "Canonical Correlation Analysis (CCA) has been widely applied to jointly embed multiple views of data in a maximally correlated latent space. However, the alignment between various data perspectives, which is required by traditional approaches, is unclear in many practical cases. In this work we propose a new framework Aligned Canonical Correlation Analysis (ACCA), to address this challenge by iteratively solving the alignment and multi-view embedding.", "url": "https://arxiv.org/abs/2312.00296"}, {"metadata": {"arXiv": "2312.00304", "Date": "Fri, 01 Dec 2023 02:47:00 ", "Title": "Developmental Pretraining (DPT) for Image Classification Networks", "Authors": ["Niranjan Rajesh and Debayan Gupta"], "Categories": "cs.LG cs.CV", "Comments": ["7 pages", "4 figures"]}, "abstract": "In the backdrop of increasing data requirements of Deep Neural Networks for object recognition that is growing more untenable by the day, we present Developmental PreTraining (DPT) as a possible solution. DPT is designed as a curriculum-based pre-training approach designed to rival traditional pre-training techniques that are data-hungry. These training approaches also introduce unnecessary features that could be misleading when the network is employed in a downstream classification task where the data is sufficiently different from the pre-training data and is scarce. We design the curriculum for DPT by drawing inspiration from human infant visual development. DPT employs a phased approach where carefully-selected primitive and universal features like edges and shapes are taught to the network participating in our pre-training regime. A model that underwent the DPT regime is tested against models with randomised weights to evaluate the viability of DPT.", "url": "https://arxiv.org/abs/2312.00304"}, {"metadata": {"arXiv": "2312.00336", "Date": "Fri, 01 Dec 2023 04:10:00 ", "Title": "Hypergraph Node Representation Learning with One-Stage Message Passing", "Authors": ["Shilin Qu", "Weiqing Wang", "Yuan-Fang Li", "Xin Zhou", "Fajie Yuan"], "Categories": "cs.LG cs.IR", "Comments": ["11 pages"]}, "abstract": "Hypergraphs as an expressive and general structure have attracted considerable attention from various research domains. Most existing hypergraph node representation learning techniques are based on graph neural networks, and thus adopt the two-stage message passing paradigm (i.e. node -> hyperedge -> node). This paradigm only focuses on local information propagation and does not effectively take into account global information, resulting in less optimal representations. Our theoretical analysis of representative two-stage message passing methods shows that, mathematically, they model different ways of local message passing through hyperedges, and can be unified into one-stage message passing (i.e. node -> node). However, they still only model local information. Motivated by this theoretical analysis, we propose a novel one-stage message passing paradigm to model both global and local information propagation for hypergraphs. We integrate this paradigm into HGraphormer, a Transformer-based framework for hypergraph node representation learning. HGraphormer injects the hypergraph structure information (local information) into Transformers (global information) by combining the attention matrix and hypergraph Laplacian. Extensive experiments demonstrate that HGraphormer outperforms recent hypergraph learning methods on five representative benchmark datasets on the semi-supervised hypernode classification task, setting new state-of-the-art performance, with accuracy improvements between 2.52% and 6.70%. Our code and datasets are available.", "url": "https://arxiv.org/abs/2312.00336"}, {"metadata": {"arXiv": "2312.00359", "Date": "Fri, 01 Dec 2023 05:38:17 ", "Title": "Temperature Balancing, Layer-wise Weight Analysis, and Neural Network Training", "Authors": ["Yefan Zhou", "Tianyu Pang", "Keqin Liu", "Charles H. Martin", "Michael W. Mahoney", "Yaoqing Yang"], "Categories": "cs.LG stat.ML", "Comments": ["NeurIPS 2023 Spotlight", "first two authors contributed equally"]}, "abstract": "Regularization in modern machine learning is crucial, and it can take various forms in algorithmic design: training set, model family, error function, regularization terms, and optimizations. In particular, the learning rate, which can be interpreted as a temperature-like parameter within the statistical mechanics of learning, plays a crucial role in neural network training. Indeed, many widely adopted training strategies basically just define the decay of the learning rate over time. This process can be interpreted as decreasing a temperature, using either a global learning rate (for the entire model) or a learning rate that varies for each parameter. This paper proposes TempBalance, a straightforward yet effective layer-wise learning rate method. TempBalance is based on Heavy-Tailed Self-Regularization (HT-SR) Theory, an approach which characterizes the implicit self-regularization of different layers in trained models. We demonstrate the efficacy of using HT-SR-motivated metrics to guide the scheduling and balancing of temperature across all network layers during model training, resulting in improved performance during testing. We implement TempBalance on CIFAR10, CIFAR100, SVHN, and TinyImageNet datasets using ResNets, VGGs, and WideResNets with various depths and widths. Our results show that TempBalance significantly outperforms ordinary SGD and carefully-tuned spectral norm regularization. We also show that TempBalance outperforms a number of state-of-the-art optimizers and learning rate schedulers.", "url": "https://arxiv.org/abs/2312.00359"}, {"metadata": {"arXiv": "2312.00364", "Date": "Fri, 01 Dec 2023 06:11:14 ", "Title": "Benchmarking Multi-Domain Active Learning on Image Classification", "Authors": ["Jiayi Li", "Rohan Taori", "Tatsunori B. Hashimoto"], "Categories": "cs.LG cs.CV"}, "abstract": "Active learning aims to enhance model performance by strategically labeling informative data points. While extensively studied, its effectiveness on large-scale, real-world datasets remains underexplored. Existing research primarily focuses on single-source data, ignoring the multi-domain nature of real-world data. We introduce a multi-domain active learning benchmark to bridge this gap. Our benchmark demonstrates that traditional single-domain active learning strategies are often less effective than random selection in multi-domain scenarios. We also introduce CLIP-GeoYFCC, a novel large-scale image dataset built around geographical domains, in contrast to existing genre-based domain datasets. Analysis on our benchmark shows that all multi-domain strategies exhibit significant tradeoffs, with no strategy outperforming across all datasets or all metrics, emphasizing the need for future research.", "url": "https://arxiv.org/abs/2312.00364"}, {"metadata": {"arXiv": "2312.00373", "Date": "Fri, 01 Dec 2023 06:33:39 ", "Title": "Streaming Bayesian Modeling for predicting Fat-Tailed Customer Lifetime Value", "Authors": ["Alexey V. Calabourdin", "Konstantin A. Aksenov"], "Categories": "cs.LG stat.AP stat.ME", "Comments": ["Work in progress"], "MSC-class": "62C10, 62F15"}, "abstract": "We develop an online learning MCMC approach applicable for hierarchical bayesian models and GLMS. We also develop a fat-tailed LTV model that generalizes over several kinds of fat and thin tails. We demonstrate both developments on commercial LTV data from a large mobile app.", "url": "https://arxiv.org/abs/2312.00373"}, {"metadata": {"arXiv": "2312.00379", "Date": "Fri, 01 Dec 2023 06:57:11 ", "Title": "Optimal Sample Complexity of Contrastive Learning", "Authors": ["Noga Alon", "Dmitrii Avdiukhin", "Dor Elboim", "Orr Fischer", "Grigory Yaroslavtsev"], "Categories": "cs.LG stat.ML"}, "abstract": "Contrastive learning is a highly successful technique for learning representations of data from labeled tuples, specifying the distance relations within the tuple. We study the sample complexity of contrastive learning, i.e. the minimum number of labeled tuples sufficient for getting high generalization accuracy. We give tight bounds on the sample complexity in a variety of settings, focusing on arbitrary distance functions, both general $\\ell_p$-distances, and tree metrics. Our main result is an (almost) optimal bound on the sample complexity of learning $\\ell_p$-distances for integer $p$. For any $p \\ge 1$ we show that $\\tilde \\Theta(\\min(nd,n^2))$ labeled tuples are necessary and sufficient for learning $d$-dimensional representations of $n$-point datasets. Our results hold for an arbitrary distribution of the input samples and are based on giving the corresponding bounds on the Vapnik-Chervonenkis/Natarajan dimension of the associated problems. We further show that the theoretical bounds on sample complexity obtained via VC/Natarajan dimension can have strong predictive power for experimental results, in contrast with the folklore belief about a substantial gap between the statistical learning theory and the practice of deep learning.", "url": "https://arxiv.org/abs/2312.00379"}, {"metadata": {"arXiv": "2312.00388", "Date": "Fri, 01 Dec 2023 07:19:42 ", "Title": "LinguaLinked: A Distributed Large Language Model Inference System for Mobile Devices", "Authors": ["Junchen Zhao", "Yurun Song", "Simeng Liu", "Ian G. Harris", "Sangeetha Abdu Jyothi"], "Categories": "cs.LG cs.DC cs.NI", "Comments": ["16 pages", "8 figures"]}, "abstract": "Deploying Large Language Models (LLMs) locally on mobile devices presents a significant challenge due to their extensive memory requirements. In this paper, we introduce LinguaLinked, a system for decentralized, distributed LLM inference on mobile devices. LinguaLinked enables collaborative execution of the inference task across multiple trusted devices. LinguaLinked ensures data privacy by processing information locally. LinguaLinked uses three key strategies. First, an optimized model assignment technique segments LLMs and uses linear optimization to align segments with each device's capabilities. Second, an optimized data transmission mechanism ensures efficient and structured data flow between model segments while also maintaining the integrity of the original model structure. Finally, LinguaLinked incorporates a runtime load balancer that actively monitors and redistributes tasks among mobile devices to prevent bottlenecks, enhancing the system's overall efficiency and responsiveness. We demonstrate that LinguaLinked facilitates efficient LLM inference while maintaining consistent throughput and minimal latency through extensive testing across various mobile devices, from high-end to low-end Android devices. In our evaluations, compared to the baseline, LinguaLinked achieves an inference performance acceleration of $1.11\\times$ to $1.61\\times$ in single-threaded settings, $1.73\\times$ to $2.65\\times$ with multi-threading. Additionally, runtime load balancing yields an overall inference acceleration of $1.29\\times$ to $1.32\\times$.", "url": "https://arxiv.org/abs/2312.00388"}, {"metadata": {"arXiv": "2312.00396", "Date": "Fri, 01 Dec 2023 07:38:05 ", "Title": "GFN-SR: Symbolic Regression with Generative Flow Networks", "Authors": ["Sida Li", "Ioana Marinescu", "Sebastian Musslick"], "Categories": "cs.LG stat.ML", "Comments": ["Accepted by the NeurIPS 2023 AI4Science Workshop"]}, "abstract": "Symbolic regression (SR) is an area of interpretable machine learning that aims to identify mathematical expressions, often composed of simple functions, that best fit in a given set of covariates $X$ and response $y$. In recent years, deep symbolic regression (DSR) has emerged as a popular method in the field by leveraging deep reinforcement learning to solve the complicated combinatorial search problem. In this work, we propose an alternative framework (GFN-SR) to approach SR with deep learning. We model the construction of an expression tree as traversing through a directed acyclic graph (DAG) so that GFlowNet can learn a stochastic policy to generate such trees sequentially. Enhanced with an adaptive reward baseline, our method is capable of generating a diverse set of best-fitting expressions. Notably, we observe that GFN-SR outperforms other SR algorithms in noisy data regimes, owing to its ability to learn a distribution of rewards over a space of candidate solutions.", "url": "https://arxiv.org/abs/2312.00396"}, {"metadata": {"arXiv": "2312.00404", "Date": "Fri, 01 Dec 2023 07:54:07 ", "Title": "A Causality-Aware Pattern Mining Scheme for Group Activity Recognition in a Pervasive Sensor Space", "Authors": ["Hyunju Kim", "Heesuk Son", "Dongman Lee"], "Categories": "cs.LG cs.DB"}, "abstract": "Human activity recognition (HAR) is a key challenge in pervasive computing and its solutions have been presented based on various disciplines. Specifically, for HAR in a smart space without privacy and accessibility issues, data streams generated by deployed pervasive sensors are leveraged. In this paper, we focus on a group activity by which a group of users perform a collaborative task without user identification and propose an efficient group activity recognition scheme which extracts causality patterns from pervasive sensor event sequences generated by a group of users to support as good recognition accuracy as the state-of-the-art graphical model. To filter out irrelevant noise events from a given data stream, a set of rules is leveraged to highlight causally related events. Then, a pattern-tree algorithm extracts frequent causal patterns by means of a growing tree structure. Based on the extracted patterns, a weighted sum-based pattern matching algorithm computes the likelihoods of stored group activities to the given test event sequence by means of matched event pattern counts for group activity recognition. We evaluate the proposed scheme using the data collected from our testbed and CASAS datasets where users perform their tasks on a daily basis and validate its effectiveness in a real environment. Experiment results show that the proposed scheme performs higher recognition accuracy and with a small amount of runtime overhead than the existing schemes.", "url": "https://arxiv.org/abs/2312.00404"}, {"metadata": {"arXiv": "2312.00411", "Date": "Fri, 01 Dec 2023 08:21:05 ", "Title": "A framework for mining lifestyle profiles through multi-dimensional and high-order mobility feature clustering", "Authors": ["Yeshuo Shu", "Gangcheng Zhang", "Keyi Liu", "Jintong Tang", "Liyan Xu"], "Categories": "cs.LG"}, "abstract": "Human mobility demonstrates a high degree of regularity, which facilitates the discovery of lifestyle profiles. Existing research has yet to fully utilize the regularities embedded in high-order features extracted from human mobility records in such profiling. This study proposes a progressive feature extraction strategy that mines high-order mobility features from users' moving trajectory records from the spatial, temporal, and semantic dimensions. Specific features are extracted such as travel motifs, rhythms decomposed by discrete Fourier transform (DFT) of mobility time series, and vectorized place semantics by word2vec, respectively to the three dimensions, and they are further clustered to reveal the users' lifestyle characteristics. An experiment using a trajectory dataset of over 500k users in Shenzhen, China yields seven user clusters with different lifestyle profiles that can be well interpreted by common sense. The results suggest the possibility of fine-grained user profiling through cross-order trajectory feature engineering and clustering.", "url": "https://arxiv.org/abs/2312.00411"}, {"metadata": {"arXiv": "2312.00477", "Date": "Fri, 01 Dec 2023 10:18:50 ", "Title": "Interpretable Meta-Learning of Physical Systems", "Authors": ["Matthieu Blanke and Marc Lelarge"], "Categories": "cs.LG stat.ML"}, "abstract": "Machine learning methods can be a valuable aid in the scientific process, but they need to face challenging settings where data come from inhomogeneous experimental conditions. Recent meta-learning methods have made significant progress in multi-task learning, but they rely on black-box neural networks, resulting in high computational costs and limited interpretability. Leveraging the structure of the learning problem, we argue that multi-environment generalization can be achieved using a simpler learning model, with an affine structure with respect to the learning task. Crucially, we prove that this architecture can identify the physical parameters of the system, enabling interpreable learning. We demonstrate the competitive generalization performance and the low computational cost of our method by comparing it to state-of-the-art algorithms on physical systems, ranging from toy models to complex, non-analytical systems. The interpretability of our method is illustrated with original applications to physical-parameter-induced adaptation and to adaptive control.", "url": "https://arxiv.org/abs/2312.00477"}, {"metadata": {"arXiv": "2312.00484", "Date": "Fri, 01 Dec 2023 10:33:16 ", "Title": "MultiView Independent Component Analysis with Delays", "Authors": ["Ambroise Heurtebise", "Pierre Ablin", "Alexandre Gramfort"], "Categories": "cs.LG eess.SP"}, "abstract": "Linear Independent Component Analysis (ICA) is a blind source separation technique that has been used in various domains to identify independent latent sources from observed signals. In order to obtain a higher signal-to-noise ratio, the presence of multiple views of the same sources can be used. In this work, we present MultiView Independent Component Analysis with Delays (MVICAD). This algorithm builds on the MultiView ICA model by allowing sources to be delayed versions of some shared sources: sources are shared across views up to some unknown latencies that are view- and source-specific. Using simulations, we demonstrate that MVICAD leads to better unmixing of the sources. Moreover, as ICA is often used in neuroscience, we show that latencies are age-related when applied to Cam-CAN, a large-scale magnetoencephalography (MEG) dataset. These results demonstrate that the MVICAD model can reveal rich effects on neural signals without human supervision.", "url": "https://arxiv.org/abs/2312.00484"}, {"metadata": {"arXiv": "2312.00485", "Date": "Fri, 01 Dec 2023 10:34:03 ", "Title": "Backbone-based Dynamic Graph Spatio-Temporal Network for Epidemic Forecasting", "Authors": ["Junkai Mao", "Yuexing Han", "Gouhei Tanaka and Bing Wang"], "Categories": "cs.LG q-bio.PE"}, "abstract": "Accurate epidemic forecasting is a critical task in controlling disease transmission. Many deep learning-based models focus only on static or dynamic graphs when constructing spatial information, ignoring their relationship. Additionally, these models often rely on recurrent structures, which can lead to error accumulation and computational time consumption. To address the aforementioned problems, we propose a novel model called Backbone-based Dynamic Graph Spatio-Temporal Network (BDGSTN). Intuitively, the continuous and smooth changes in graph structure, make adjacent graph structures share a basic pattern. To capture this property, we use adaptive methods to generate static backbone graphs containing the primary information and temporal models to generate dynamic temporal graphs of epidemic data, fusing them to generate a backbone-based dynamic graph. To overcome potential limitations associated with recurrent structures, we introduce a linear model DLinear to handle temporal dependencies and combine it with dynamic graph convolution for epidemic forecasting. Extensive experiments on two datasets demonstrate that BDGSTN outperforms baseline models and ablation comparison further verifies the effectiveness of model components. Furthermore, we analyze and measure the significance of backbone and temporal graphs by using information metrics from different aspects. Finally, we compare model parameter volume and training time to confirm the superior complexity and efficiency of BDGSTN.", "url": "https://arxiv.org/abs/2312.00485"}, {"metadata": {"arXiv": "2312.00486", "Date": "Fri, 01 Dec 2023 10:34:22 ", "Title": "REDUCR: Robust Data Downsampling Using Class Priority Reweighting", "Authors": ["William Bankes", "George Hughes", "Ilija Bogunovic and Zi Wang"], "Categories": "cs.LG", "Comments": ["Preprint"]}, "abstract": "Modern machine learning models are becoming increasingly expensive to train for real-world image and text classification tasks, where massive web-scale data is collected in a streaming fashion. To reduce the training cost, online batch selection techniques have been developed to choose the most informative datapoints. However, these techniques can suffer from poor worst-class generalization performance due to class imbalance and distributional shifts. This work introduces REDUCR, a robust and efficient data downsampling method that uses class priority reweighting. REDUCR reduces the training data while preserving worst-class generalization performance. REDUCR assigns priority weights to datapoints in a class-aware manner using an online learning algorithm. We demonstrate the data efficiency and robust performance of REDUCR on vision and text classification tasks. On web-scraped datasets with imbalanced class distributions, REDUCR significantly improves worst-class test accuracy (and average accuracy), surpassing state-of-the-art methods by around 15%.", "url": "https://arxiv.org/abs/2312.00486"}, {"metadata": {"arXiv": "2312.00502", "Date": "Fri, 01 Dec 2023 11:06:00 ", "Title": "On the Out-Of-Distribution Robustness of Self-Supervised Representation Learning for Phonocardiogram Signals", "Authors": ["Aristotelis Ballas", "Vasileios Papapanagiotou and Christos Diou"], "Categories": "cs.LG cs.SD q-bio.QM", "Comments": ["PREPRINT Manuscript under review"]}, "abstract": "Objective: Despite the recent increase in research activity, deep-learning models have not yet been widely accepted in medicine. The shortage of high-quality annotated data often hinders the development of robust and generalizable models, which do not suffer from degraded effectiveness when presented with newly-collected, out-of-distribution (OOD) datasets. Methods: Contrastive Self-Supervised Learning (SSL) offers a potential solution to the scarcity of labeled data as it takes advantage of unlabeled data to increase model effectiveness and robustness. In this research, we propose applying contrastive SSL for detecting abnormalities in phonocardiogram (PCG) samples by learning a generalized representation of the signal. Specifically, we perform an extensive comparative evaluation of a wide range of audio-based augmentations and evaluate trained classifiers on multiple datasets across different downstream tasks. Results: We experimentally demonstrate that, depending on its training distribution, the effectiveness of a fully-supervised model can degrade up to 32% when evaluated on unseen data, while SSL models only lose up to 10% or even improve in some cases. Conclusions: Contrastive SSL pretraining can assist in providing robust classifiers which can generalize to unseen, OOD data, without relying on time- and labor-intensive annotation processes by medical experts. Furthermore, the proposed extensive evaluation protocol sheds light on the most promising and appropriate augmentations for robust PCG signal processing. Significance: We provide researchers and practitioners with a roadmap towards producing robust models for PCG classification, in addition to an open-source codebase for developing novel approaches.", "url": "https://arxiv.org/abs/2312.00502"}, {"metadata": {"arXiv": "2312.00516", "Date": "Fri, 01 Dec 2023 11:43:49 ", "Title": "Spatio-Temporal-Decoupled Masked Pre-training for Traffic Forecasting", "Authors": ["Haotian Gao", "Renhe Jiang", "Zheng Dong", "Jinliang Deng", "Xuan Song"], "Categories": "cs.LG"}, "abstract": "Accurate forecasting of multivariate traffic flow time series remains challenging due to substantial spatio-temporal heterogeneity and complex long-range correlative patterns. To address this, we propose Spatio-Temporal-Decoupled Masked Pre-training (STD-MAE), a novel framework that employs masked autoencoders to learn and encode complex spatio-temporal dependencies via pre-training. Specifically, we use two decoupled masked autoencoders to reconstruct the traffic data along spatial and temporal axes using a self-supervised pre-training approach. These mask reconstruction mechanisms capture the long-range correlations in space and time separately. The learned hidden representations are then used to augment the downstream spatio-temporal traffic predictor. A series of quantitative and qualitative evaluations on four widely-used traffic benchmarks (PEMS03, PEMS04, PEMS07, and PEMS08) are conducted to verify the state-of-the-art performance, with STD-MAE explicitly enhancing the downstream spatio-temporal models' ability to capture long-range intricate spatial and temporal patterns. Codes are available at https://github.com/Jimmy-7664/STD_MAE.", "url": "https://arxiv.org/abs/2312.00516"}, {"metadata": {"arXiv": "2312.00548", "Date": "Fri, 01 Dec 2023 12:48:41 ", "Title": "Domain Adaptive Imitation Learning with Visual Observation", "Authors": ["Sungho Choi", "Seungyul Han", "Woojun Kim", "Jongseong Chae", "Whiyoung Jung", "Youngchul Sung"], "Categories": "cs.LG cs.CV cs.RO", "Comments": ["Accepted to NeurIPS 2023"]}, "abstract": "In this paper, we consider domain-adaptive imitation learning with visual observation, where an agent in a target domain learns to perform a task by observing expert demonstrations in a source domain. Domain adaptive imitation learning arises in practical scenarios where a robot, receiving visual sensory data, needs to mimic movements by visually observing other robots from different angles or observing robots of different shapes. To overcome the domain shift in cross-domain imitation learning with visual observation, we propose a novel framework for extracting domain-independent behavioral features from input observations that can be used to train the learner, based on dual feature extraction and image reconstruction. Empirical results demonstrate that our approach outperforms previous algorithms for imitation learning from visual observation with domain shift.", "url": "https://arxiv.org/abs/2312.00548"}, {"metadata": {"arXiv": "2312.00561", "Date": "Fri, 01 Dec 2023 13:16:39 ", "Title": "Interior Point Constrained Reinforcement Learning with Global Convergence Guarantees", "Authors": ["Tingting Ni", "Maryam Kamgarpour"], "Categories": "cs.LG math.OC", "Comments": ["34 pages", "no figures"]}, "abstract": "We consider discounted infinite horizon constrained Markov decision processes (CMDPs) where the goal is to find an optimal policy that maximizes the expected cumulative reward subject to expected cumulative constraints. Motivated by the application of CMDPs in online learning of safety-critical systems, we focus on developing an algorithm that ensures constraint satisfaction during learning. To this end, we develop a zeroth-order interior point approach based on the log barrier function of the CMDP. Under the commonly assumed conditions of Fisher non-degeneracy and bounded transfer error of the policy parameterization, we establish the theoretical properties of the algorithm. In particular, in contrast to existing CMDP approaches that ensure policy feasibility only upon convergence, our algorithm guarantees feasibility of the policies during the learning process and converges to the optimal policy with a sample complexity of $O(\\varepsilon^{-6})$. In comparison to the state-of-the-art policy gradient-based algorithm, C-NPG-PDA, our algorithm requires an additional $O(\\varepsilon^{-2})$ samples to ensure policy feasibility during learning with same Fisher-non-degenerate parameterization.", "url": "https://arxiv.org/abs/2312.00561"}, {"metadata": {"arXiv": "2312.00581", "Date": "Fri, 01 Dec 2023 13:45:42 ", "Title": "Pathway to a fully data-driven geotechnics: lessons from materials informatics", "Authors": ["Stephen Wu", "Yu Otake", "Yosuke Higo", "Ikumasa Yoshida"], "Categories": "cs.LG stat.ML"}, "abstract": "This paper elucidates the challenges and opportunities inherent in integrating data-driven methodologies into geotechnics, drawing inspiration from the success of materials informatics. Highlighting the intricacies of soil complexity, heterogeneity, and the lack of comprehensive data, the discussion underscores the pressing need for community-driven database initiatives and open science movements. By leveraging the transformative power of deep learning, particularly in feature extraction from high-dimensional data and the potential of transfer learning, we envision a paradigm shift towards a more collaborative and innovative geotechnics field. The paper concludes with a forward-looking stance, emphasizing the revolutionary potential brought about by advanced computational tools like large language models in reshaping geotechnics informatics.", "url": "https://arxiv.org/abs/2312.00581"}, {"metadata": {"arXiv": "2312.00592", "Date": "Fri, 01 Dec 2023 13:56:28 ", "Title": "Tracking Object Positions in Reinforcement Learning: A Metric for Keypoint Detection (extended version)", "Authors": ["Emma Cramer", "Jonas Reiher", "Sebastian Trimpe"], "Categories": "cs.LG cs.CV cs.RO"}, "abstract": "Reinforcement learning (RL) for robot control typically requires a detailed representation of the environment state, including information about task-relevant objects not directly measurable. Keypoint detectors, such as spatial autoencoders (SAEs), are a common approach to extracting a low-dimensional representation from high-dimensional image data. SAEs aim at spatial features such as object positions, which are often useful representations in robotic RL. However, whether an SAE is actually able to track objects in the scene and thus yields a spatial state representation well suited for RL tasks has rarely been examined due to a lack of established metrics. In this paper, we propose to assess the performance of an SAE instance by measuring how well keypoints track ground truth objects in images. We present a computationally lightweight metric and use it to evaluate common baseline SAE architectures on image data from a simulated robot task. We find that common SAEs differ substantially in their spatial extraction capability. Furthermore, we validate that SAEs that perform well in our metric achieve superior performance when used in downstream RL. Thus, our metric is an effective and lightweight indicator of RL performance before executing expensive RL training. Building on these insights, we identify three key modifications of SAE architectures to improve tracking performance. We make our code available at anonymous.4open.science/r/sae-rl.", "url": "https://arxiv.org/abs/2312.00592"}, {"metadata": {"arXiv": "2312.00600", "Date": "Fri, 01 Dec 2023 14:06:28 ", "Title": "Improving Plasticity in Online Continual Learning via Collaborative Learning", "Authors": ["Maorong Wang", "Nicolas Michel", "Ling Xiao", "Toshihiko Yamasaki"], "Categories": "cs.LG", "Comments": ["Under review"]}, "abstract": "Online Continual Learning (CL) solves the problem of learning the ever-emerging new classification tasks from a continuous data stream. Unlike its offline counterpart, in online CL, the training data can only be seen once. Most existing online CL research regards catastrophic forgetting (i.e., model stability) as almost the only challenge. In this paper, we argue that the model's capability to acquire new knowledge (i.e., model plasticity) is another challenge in online CL. While replay-based strategies have been shown to be effective in alleviating catastrophic forgetting, there is a notable gap in research attention toward improving model plasticity. To this end, we propose Collaborative Continual Learning (CCL), a collaborative learning based strategy to improve the model's capability in acquiring new concepts. Additionally, we introduce Distillation Chain (DC), a novel collaborative learning scheme to boost the training of the models. We adapted CCL-DC to existing representative online CL works. Extensive experiments demonstrate that even if the learners are well-trained with state-of-the-art online CL methods, our strategy can still improve model plasticity dramatically, and thereby improve the overall performance by a large margin.", "url": "https://arxiv.org/abs/2312.00600"}, {"metadata": {"arXiv": "2312.00616", "Date": "Fri, 01 Dec 2023 14:28:37 ", "Title": "Investigating a domain adaptation approach for integrating different measurement instruments in a longitudinal clinical registry", "Authors": ["Maren Hackenberg", "Michelle Pfaffenlehner", "Max Behrens", "Astrid Pechmann", "Janbernd Kirschner", "Harald Binder"], "Categories": "cs.LG stat.ME stat.ML", "Comments": ["18 pages", "4 figures"]}, "abstract": "In a longitudinal clinical registry, different measurement instruments might have been used for assessing individuals at different time points. To combine them, we investigate deep learning techniques for obtaining a joint latent representation, to which the items of different measurement instruments are mapped. This corresponds to domain adaptation, an established concept in computer science for image data. Using the proposed approach as an example, we evaluate the potential of domain adaptation in a longitudinal cohort setting with a rather small number of time points, motivated by an application with different motor function measurement instruments in a registry of spinal muscular atrophy (SMA) patients. There, we model trajectories in the latent representation by ordinary differential equations (ODEs), where person-specific ODE parameters are inferred from baseline characteristics. The goodness of fit and complexity of the ODE solutions then allows to judge the measurement instrument mappings. We subsequently explore how alignment can be improved by incorporating corresponding penalty terms into model fitting. To systematically investigate the effect of differences between measurement instruments, we consider several scenarios based on modified SMA data, including scenarios where a mapping should be feasible in principle and scenarios where no perfect mapping is available. While misalignment increases in more complex scenarios, some structure is still recovered, even if the availability of measurement instruments depends on patient state. A reasonable mapping is feasible also in the more complex real SMA dataset. These results indicate that domain adaptation might be more generally useful in statistical modeling for longitudinal registry data.", "url": "https://arxiv.org/abs/2312.00616"}, {"metadata": {"arXiv": "2312.00622", "Date": "Fri, 01 Dec 2023 14:39:11 ", "Title": "Practical Path-based Bayesian Optimization", "Authors": ["Jose Pablo Folch", "James Odgers", "Shiqiang Zhang", "Robert M Lee", "Behrang Shafei", "David Walz", "Calvin Tsay", "Mark van der Wilk", "Ruth Misener"], "Categories": "cs.LG math.OC stat.ME", "Comments": ["6 main pages", "12 with references and appendix. 4 figures", "2 tables. To appear in NeurIPS 2023 Workshop on Adaptive Experimental Design and Active Learning in the Real World"], "Journal-ref": "NeurIPS 2023 Workshop on Adaptive Experimental Design and Active Learning in the Real World"}, "abstract": "There has been a surge in interest in data-driven experimental design with applications to chemical engineering and drug manufacturing. Bayesian optimization (BO) has proven to be adaptable to such cases, since we can model the reactions of interest as expensive black-box functions. Sometimes, the cost of this black-box functions can be separated into two parts: (a) the cost of the experiment itself, and (b) the cost of changing the input parameters. In this short paper, we extend the SnAKe algorithm to deal with both types of costs simultaneously. We further propose extensions to the case of a maximum allowable input change, as well as to the multi-objective setting.", "url": "https://arxiv.org/abs/2312.00622"}, {"metadata": {"arXiv": "2312.00626", "Date": "Fri, 01 Dec 2023 14:42:37 ", "Title": "Forecasting Trends in Food Security: a Reservoir Computing Approach", "Authors": ["Joschka Herteux", "Christoph R\\\"ath", "Amine Baha", "Giulia Martini", "Duccio Piovani"], "Categories": "cs.LG physics.soc-ph stat.ML", "Comments": ["22 pages", "11 figures"]}, "abstract": "Early warning systems are an essential tool for effective humanitarian action. Advance warnings on impending disasters facilitate timely and targeted response which help save lives, livelihoods, and scarce financial resources. In this work we present a new quantitative methodology to forecast levels of food consumption for 60 consecutive days, at the sub-national level, in four countries: Mali, Nigeria, Syria, and Yemen. The methodology is built on publicly available data from the World Food Programme's integrated global hunger monitoring system which collects, processes, and displays daily updates on key food security metrics, conflict, weather events, and other drivers of food insecurity across 90 countries (https://hungermap.wfp.org/). In this study, we assessed the performance of various models including ARIMA, XGBoost, LSTMs, CNNs, and Reservoir Computing (RC), by comparing their Root Mean Squared Error (RMSE) metrics. This comprehensive analysis spanned classical statistical, machine learning, and deep learning approaches. Our findings highlight Reservoir Computing as a particularly well-suited model in the field of food security given both its notable resistance to over-fitting on limited data samples and its efficient training capabilities. The methodology we introduce establishes the groundwork for a global, data-driven early warning system designed to anticipate and detect food insecurity.", "url": "https://arxiv.org/abs/2312.00626"}, {"metadata": {"arXiv": "2312.00645", "Date": "Fri, 01 Dec 2023 15:16:00 ", "Title": "Hashmarks: Privacy-Preserving Benchmarks for High-Stakes AI Evaluation", "Authors": ["Paul Bricman"], "Categories": "cs.LG cs.CR cs.SE"}, "abstract": "There is a growing need to gain insight into language model capabilities that relate to sensitive topics, such as bioterrorism or cyberwarfare. However, traditional open source benchmarks are not fit for the task, due to the associated practice of publishing the correct answers in human-readable form. At the same time, enforcing mandatory closed-quarters evaluations might stifle development and erode trust. In this context, we propose hashmarking, a protocol for evaluating language models in the open without having to disclose the correct answers. In its simplest form, a hashmark is a benchmark whose reference solutions have been cryptographically hashed prior to publication. Following an overview of the proposed evaluation protocol, we go on to assess its resilience against traditional attack vectors (e.g. rainbow table attacks), as well as against failure modes unique to increasingly capable generative models.", "url": "https://arxiv.org/abs/2312.00645"}, {"metadata": {"arXiv": "2312.00655", "Date": "Fri, 01 Dec 2023 15:30:43 ", "Title": "Machine Learning for Health symposium 2023 -- Findings track", "Authors": ["Stefan Hegselmann", "Antonio Parziale", "Divya Shanmugam", "Shengpu Tang", "Mercy Nyamewaa Asiedu", "Serina Chang", "Thomas Hartvigsen", "Harvineet Singh"], "Categories": "cs.LG", "MSC-class": "68Txx", "ACM-class": "I.2; J.3; I.6; I.4"}, "abstract": "A collection of the accepted Findings papers that were presented at the 3rd Machine Learning for Health symposium (ML4H 2023), which was held on December 10, 2023, in New Orleans, Louisiana, USA. ML4H 2023 invited high-quality submissions on relevant problems in a variety of health-related disciplines including healthcare, biomedicine, and public health. Two submission tracks were offered: the archival Proceedings track, and the non-archival Findings track. Proceedings were targeted at mature work with strong technical sophistication and a high impact to health. The Findings track looked for new ideas that could spark insightful discussion, serve as valuable resources for the community, or could enable new collaborations. Submissions to the Proceedings track, if not accepted, were automatically considered for the Findings track. All the manuscripts submitted to ML4H Symposium underwent a double-blind peer-review process.", "url": "https://arxiv.org/abs/2312.00655"}, {"metadata": {"arXiv": "2312.00662", "Date": "Fri, 01 Dec 2023 15:40:30 ", "Title": "Nonparametric Variational Regularisation of Pretrained Transformers", "Authors": ["Fabio Fehr", "James Henderson"], "Categories": "cs.LG cs.CL"}, "abstract": "The current paradigm of large-scale pre-training and fine-tuning Transformer large language models has lead to significant improvements across the board in natural language processing. However, such large models are susceptible to overfitting to their training data, and as a result the models perform poorly when the domain changes. Also, due to the model's scale, the cost of fine-tuning the model to the new domain is large. Nonparametric Variational Information Bottleneck (NVIB) has been proposed as a regulariser for training cross-attention in Transformers, potentially addressing the overfitting problem. We extend the NVIB framework to replace all types of attention functions in Transformers, and show that existing pretrained Transformers can be reinterpreted as Nonparametric Variational (NV) models using a proposed identity initialisation. We then show that changing the initialisation introduces a novel, information-theoretic post-training regularisation in the attention mechanism, which improves out-of-domain generalisation without any training. This success supports the hypothesis that pretrained Transformers are implicitly NV Bayesian models.", "url": "https://arxiv.org/abs/2312.00662"}, {"metadata": {"arXiv": "2312.00710", "Date": "Fri, 01 Dec 2023 16:42:57 ", "Title": "SpaCE: The Spatial Confounding Environment", "Authors": ["Mauricio Tec", "Ana Trisovic", "Michelle Audirac", "Sophie Woodward", "Naeem Khoshnevis", "Francesca Dominici"], "Categories": "cs.LG stat.ME stat.ML"}, "abstract": "Spatial confounding poses a significant challenge in scientific studies involving spatial data, where unobserved spatial variables can influence both treatment and outcome, possibly leading to spurious associations. To address this problem, we introduce SpaCE: The Spatial Confounding Environment, the first toolkit to provide realistic benchmark datasets and tools for systematically evaluating causal inference methods designed to alleviate spatial confounding. Each dataset includes training data, true counterfactuals, a spatial graph with coordinates, and smoothness and confounding scores characterizing the effect of a missing spatial confounder. It also includes realistic semi-synthetic outcomes and counterfactuals, generated using state-of-the-art machine learning ensembles, following best practices for causal inference benchmarks. The datasets cover real treatment and covariates from diverse domains, including climate, health and social sciences. SpaCE facilitates an automated end-to-end pipeline, simplifying data loading, experimental setup, and evaluating machine learning and causal inference models. The SpaCE project provides several dozens of datasets of diverse sizes and spatial complexity. It is publicly available as a Python package, encouraging community feedback and contributions.", "url": "https://arxiv.org/abs/2312.00710"}, {"metadata": {"arXiv": "2312.00765", "Date": "Fri, 01 Dec 2023 18:40:37 ", "Title": "Explaining Knock-on Effects of Bias Mitigation", "Authors": ["Svetoslav Nizhnichenkov", "Rahul Nair", "Elizabeth Daly", "Brian Mac Namee"], "Categories": "cs.LG cs.CY", "Comments": ["This paper was accepted at NeurIPS 2023 workshop"]}, "abstract": "In machine learning systems, bias mitigation approaches aim to make outcomes fairer across privileged and unprivileged groups. Bias mitigation methods work in different ways and have known \"waterfall\" effects, e.g., mitigating bias at one place may manifest bias elsewhere. In this paper, we aim to characterise impacted cohorts when mitigation interventions are applied. To do so, we treat intervention effects as a classification task and learn an explainable meta-classifier to identify cohorts that have altered outcomes. We examine a range of bias mitigation strategies that work at various stages of the model life cycle. We empirically demonstrate that our meta-classifier is able to uncover impacted cohorts. Further, we show that all tested mitigation strategies negatively impact a non-trivial fraction of cases, i.e., people who receive unfavourable outcomes solely on account of mitigation efforts. This is despite improvement in fairness metrics. We use these results as a basis to argue for more careful audits of static mitigation interventions that go beyond aggregate metrics.", "url": "https://arxiv.org/abs/2312.00765"}, {"metadata": {"arXiv": "2312.00344", "Date": "Fri, 01 Dec 2023 04:40:47 ", "Title": "TRC: Trust Region Conditional Value at Risk for Safe Reinforcement Learning", "Authors": ["Dohyeong Kim and Songhwai Oh"], "Categories": "cs.RO cs.LG", "Comments": ["RA-L and ICRA 2022"], "Journal-ref": "IEEE Robotics and Automation Letters, vol. 7, no. 2, pp. 2621-2628, April 2022", "DOI": "10.1109/LRA.2022.3141829"}, "abstract": "As safety is of paramount importance in robotics, reinforcement learning that reflects safety, called safe RL, has been studied extensively. In safe RL, we aim to find a policy which maximizes the desired return while satisfying the defined safety constraints. There are various types of constraints, among which constraints on conditional value at risk (CVaR) effectively lower the probability of failures caused by high costs since CVaR is a conditional expectation obtained above a certain percentile. In this paper, we propose a trust region-based safe RL method with CVaR constraints, called TRC. We first derive the upper bound on CVaR and then approximate the upper bound in a differentiable form in a trust region. Using this approximation, a subproblem to get policy gradients is formulated, and policies are trained by iteratively solving the subproblem. TRC is evaluated through safe navigation tasks in simulations with various robots and a sim-to-real environment with a Jackal robot from Clearpath. Compared to other safe RL methods, the performance is improved by 1.93 times while the constraints are satisfied in all experiments.", "url": "https://arxiv.org/abs/2312.00344"}, {"metadata": {"arXiv": "2312.00775", "Date": "Fri, 01 Dec 2023 18:54:12 ", "Title": "Towards Generalizable Zero-Shot Manipulation via Translating Human Interaction Plans", "Authors": ["Homanga Bharadhwaj", "Abhinav Gupta", "Vikash Kumar", "Shubham Tulsiani"], "Categories": "cs.RO cs.CV cs.LG", "Comments": ["Preprint. Under Review"]}, "abstract": "We pursue the goal of developing robots that can interact zero-shot with generic unseen objects via a diverse repertoire of manipulation skills and show how passive human videos can serve as a rich source of data for learning such generalist robots. Unlike typical robot learning approaches which directly learn how a robot should act from interaction data, we adopt a factorized approach that can leverage large-scale human videos to learn how a human would accomplish a desired task (a human plan), followed by translating this plan to the robots embodiment. Specifically, we learn a human plan predictor that, given a current image of a scene and a goal image, predicts the future hand and object configurations. We combine this with a translation module that learns a plan-conditioned robot manipulation policy, and allows following humans plans for generic manipulation tasks in a zero-shot manner with no deployment-time training. Importantly, while the plan predictor can leverage large-scale human videos for learning, the translation module only requires a small amount of in-domain data, and can generalize to tasks not seen during training. We show that our learned system can perform over 16 manipulation skills that generalize to 40 objects, encompassing 100 real-world tasks for table-top manipulation and diverse in-the-wild manipulation. https://homangab.github.io/hopman/", "url": "https://arxiv.org/abs/2312.00775"}, {"metadata": {"arXiv": "2312.00326", "Date": "Fri, 01 Dec 2023 03:44:54 ", "Title": "Agent-OM: Leveraging Large Language Models for Ontology Matching", "Authors": ["Zhangcheng Qiang", "Weiqing Wang", "Kerry Taylor"], "Categories": "cs.AI cs.CL cs.IR", "Comments": ["14 pages", "10 figures", "7 tables"]}, "abstract": "Ontology matching (OM) enables semantic interoperability between different ontologies and resolves their conceptual heterogeneity by aligning related entities. OM systems currently have two prevailing design paradigms: conventional knowledge-based expert systems and newer machine learning-based predictive systems. While large language models (LLMs) and LLM-based agents have become revolutionary in data engineering and have been applied creatively in various domains, their potential for OM remains underexplored. This study introduces a novel agent-powered LLM-based design paradigm for OM systems. With thoughtful consideration of several specific challenges to leverage LLMs for OM, we propose a generic framework, namely Agent-OM, consisting of two Siamese agents for retrieval and matching, with a set of simple prompt-based OM tools. Our framework is implemented in a proof-of-concept system. Evaluations of three Ontology Alignment Evaluation Initiative (OAEI) tracks over state-of-the-art OM systems show that our system can achieve very close results to the best long-standing performance on simple OM tasks and significantly improve the performance on complex and few-shot OM tasks.", "url": "https://arxiv.org/abs/2312.00326"}, {"metadata": {"arXiv": "2312.00332", "Date": "Fri, 01 Dec 2023 03:56:29 ", "Title": "Matching Weak Informative Ontologies", "Authors": ["Peng Wang"], "Categories": "cs.AI"}, "abstract": "Most existing ontology matching methods utilize the literal information to discover alignments. However, some literal information in ontologies may be opaque and some ontologies may not have sufficient literal information. In this paper, these ontologies are named as weak informative ontologies (WIOs) and it is challenging for existing methods to matching WIOs. On one hand, string-based and linguistic-based matching methods cannot work well for WIOs. On the other hand, some matching methods use external resources to improve their performance, but collecting and processing external resources is still time-consuming. To address this issue, this paper proposes a practical method for matching WIOs by employing the ontology structure information to discover alignments. First, the semantic subgraphs are extracted from the ontology graph to capture the precise meanings of ontology elements. Then, a new similarity propagation model is designed for matching WIOs. Meanwhile, in order to avoid meaningless propagation, the similarity propagation is constrained by semantic subgraphs and other conditions. Consequently, the similarity propagation model ensures a balance between efficiency and quality during matching. Finally, the similarity propagation model uses a few credible alignments as seeds to find more alignments, and some useful strategies are adopted to improve the performance. This matching method for WIOs has been implemented in the ontology matching system Lily. Experimental results on public OAEI benchmark datasets demonstrate that Lily significantly outperforms most of the state-of-the-art works in both WIO matching tasks and general ontology matching tasks. In particular, Lily increases the recall by a large margin, while it still obtains high precision of matching results.", "url": "https://arxiv.org/abs/2312.00332"}, {"metadata": {"arXiv": "2312.00333", "Date": "Fri, 01 Dec 2023 04:04:37 ", "Title": "Green Edge AI: A Contemporary Survey", "Authors": ["Yuyi Mao and Xianghao Yu and Kaibin Huang and Ying-Jun Angela Zhang and Jun Zhang"], "Categories": "cs.AI cs.IT cs.NI math.IT", "Comments": ["26 pages", "7 figures", "5 tables", "submitted to IEEE for possible publication"]}, "abstract": "Artificial intelligence (AI) technologies have emerged as pivotal enablers across a multitude of industries, including consumer electronics, healthcare, and manufacturing, largely due to their resurgence over the past decade. The transformative power of AI is primarily derived from the utilization of deep neural networks (DNNs), which require extensive data for training and substantial computational resources for processing. Consequently, DNN models are typically trained and deployed on resource-rich cloud servers. However, due to potential latency issues associated with cloud communications, deep learning (DL) workflows are increasingly being transitioned to wireless edge networks near end-user devices (EUDs). This shift is designed to support latency-sensitive applications and has given rise to a new paradigm of edge AI, which will play a critical role in upcoming 6G networks to support ubiquitous AI applications. Despite its potential, edge AI faces substantial challenges, mostly due to the dichotomy between the resource limitations of wireless edge networks and the resource-intensive nature of DL. Specifically, the acquisition of large-scale data, as well as the training and inference processes of DNNs, can rapidly deplete the battery energy of EUDs. This necessitates an energy-conscious approach to edge AI to ensure both optimal and sustainable performance. In this paper, we present a contemporary survey on green edge AI. We commence by analyzing the principal energy consumption components of edge AI systems to identify the fundamental design principles of green edge AI. Guided by these principles, we then explore energy-efficient design methodologies for the three critical tasks in edge AI systems, including training data acquisition, edge training, and edge inference. Finally, we underscore potential future research directions to further enhance the energy efficiency of edge AI.", "url": "https://arxiv.org/abs/2312.00333"}, {"metadata": {"arXiv": "2312.00380", "Date": "Fri, 01 Dec 2023 07:09:21 ", "Title": "Enhancing Explainability in Mobility Data Science through a combination of methods", "Authors": ["Georgios Makridis", "Vasileios Koukos", "Georgios Fatouros", "Dimosthenis Kyriazis"], "Categories": "cs.AI"}, "abstract": "In the domain of Mobility Data Science, the intricate task of interpreting models trained on trajectory data, and elucidating the spatio-temporal movement of entities, has persistently posed significant challenges. Conventional XAI techniques, although brimming with potential, frequently overlook the distinct structure and nuances inherent within trajectory data. Observing this deficiency, we introduced a comprehensive framework that harmonizes pivotal XAI techniques: LIME (Local Interpretable Model-agnostic Explanations), SHAP (SHapley Additive exPlanations), Saliency maps, attention mechanisms, direct trajectory visualization, and Permutation Feature Importance (PFI). Unlike conventional strategies that deploy these methods singularly, our unified approach capitalizes on the collective efficacy of these techniques, yielding deeper and more granular insights for models reliant on trajectory data. In crafting this synthesis, we effectively address the multifaceted essence of trajectories, achieving not only amplified interpretability but also a nuanced, contextually rich comprehension of model decisions. To validate and enhance our framework, we undertook a survey to gauge preferences and reception among various user demographics. Our findings underscored a dichotomy: professionals with academic orientations, particularly those in roles like Data Scientist, IT Expert, and ML Engineer, showcased a profound, technical understanding and often exhibited a predilection for amalgamated methods for interpretability. Conversely, end-users or individuals less acquainted with AI and Data Science showcased simpler inclinations, such as bar plots indicating timestep significance or visual depictions pinpointing pivotal segments of a vessel's trajectory.", "url": "https://arxiv.org/abs/2312.00380"}, {"metadata": {"arXiv": "2312.00746", "Date": "Fri, 01 Dec 2023 17:33:57 ", "Title": "Deciphering Digital Detectives: Understanding LLM Behaviors and Capabilities in Multi-Agent Mystery Games", "Authors": ["Dekun Wu", "Haochen Shi", "Zhiyuan Sun", "Bang Liu"], "Categories": "cs.AI", "ACM-class": "I.2.0; I.2.1; I.2.7"}, "abstract": "In this study, we explore the application of Large Language Models (LLMs) in \"Jubensha\" (Chinese murder mystery role-playing games), a novel area in AI-driven gaming. We introduce the first Chinese dataset specifically for Jubensha, including character scripts and game rules, to foster AI agent development in this complex narrative environment. Our work also presents a unique multi-agent interaction framework using LLMs, allowing AI agents to autonomously engage in the game, enhancing the dynamics of Jubensha gameplay. To evaluate these AI agents, we developed specialized methods targeting their mastery of case information and reasoning skills. Furthermore, we incorporated the latest advancements in in-context learning to improve the agents' performance in critical aspects like information gathering, murderer detection, and logical reasoning. The experimental results validate the effectiveness of our proposed methods. This work aims to offer a fresh perspective on understanding LLM capabilities and establish a new benchmark for evaluating large language model-based agents to researchers in the field.", "url": "https://arxiv.org/abs/2312.00746"}, {"metadata": {"arXiv": "2312.00094", "Date": "Thu, 30 Nov 2023 13:07:19 ", "Title": "Fast ODE-based Sampling for Diffusion Models in Around 5 Steps", "Authors": ["Zhenyu Zhou", "Defang Chen", "Can Wang", "Chun Chen"], "Categories": "cs.CV cs.AI"}, "abstract": "Sampling from diffusion models can be treated as solving the corresponding ordinary differential equations (ODEs), with the aim of obtaining an accurate solution with as few number of function evaluations (NFE) as possible. Recently, various fast samplers utilizing higher-order ODE solvers have emerged and achieved better performance than the initial first-order one. However, these numerical methods inherently result in certain approximation errors, which significantly degrades sample quality with extremely small NFE (e.g., around 5). In contrast, based on the geometric observation that each sampling trajectory almost lies in a two-dimensional subspace embedded in the ambient space, we propose Approximate MEan-Direction Solver (AMED-Solver) that eliminates truncation errors by directly learning the mean direction for fast diffusion sampling. Besides, our method can be easily used as a plugin to further improve existing ODE-based samplers. Extensive experiments on image synthesis with the resolution ranging from 32 to 256 demonstrate the effectiveness of our method. With only 5 NFE, we achieve 7.14 FID on CIFAR-10, 13.75 FID on ImageNet 64$\\times$64, and 12.79 FID on LSUN Bedroom. Our code is available at https://github.com/zhyzhouu/amed-solver.", "url": "https://arxiv.org/abs/2312.00094"}, {"metadata": {"arXiv": "2312.00151", "Date": "Thu, 30 Nov 2023 19:16:11 ", "Title": "Which way is `right'?: Uncovering limitations of Vision-and-Language Navigation model", "Authors": ["Meera Hahn", "Amit Raj", "James M. Rehg"], "Categories": "cs.CV cs.AI"}, "abstract": "The challenging task of Vision-and-Language Navigation (VLN) requires embodied agents to follow natural language instructions to reach a goal location or object (e.g. `walk down the hallway and turn left at the piano'). For agents to complete this task successfully, they must be able to ground objects referenced into the instruction (e.g.`piano') into the visual scene as well as ground directional phrases (e.g.`turn left') into actions. In this work we ask the following question -- to what degree are spatial and directional language cues informing the navigation model's decisions? We propose a series of simple masking experiments to inspect the model's reliance on different parts of the instruction. Surprisingly we uncover that certain top performing models rely only on the noun tokens of the instructions. We propose two training methods to alleviate this concerning limitation.", "url": "https://arxiv.org/abs/2312.00151"}, {"metadata": {"arXiv": "2312.00210", "Date": "Thu, 30 Nov 2023 21:44:39 ", "Title": "DREAM: Diffusion Rectification and Estimation-Adaptive Models", "Authors": ["Jinxin Zhou", "Tianyu Ding", "Tianyi Chen", "Jiachen Jiang", "Ilya Zharkov", "Zhihui Zhu and Luming Liang"], "Categories": "cs.CV cs.AI", "Comments": ["16 pages", "22 figures", "5 tables; the first two authors contributed to this work equally"]}, "abstract": "We present DREAM, a novel training framework representing Diffusion Rectification and Estimation-Adaptive Models, requiring minimal code changes (just three lines) yet significantly enhancing the alignment of training with sampling in diffusion models. DREAM features two components: diffusion rectification, which adjusts training to reflect the sampling process, and estimation adaptation, which balances perception against distortion. When applied to image super-resolution (SR), DREAM adeptly navigates the tradeoff between minimizing distortion and preserving high image quality. Experiments demonstrate DREAM's superiority over standard diffusion-based SR methods, showing a $2$ to $3\\times $ faster training convergence and a $10$ to $20\\times$ reduction in necessary sampling steps to achieve comparable or superior results. We hope DREAM will inspire a rethinking of diffusion model training paradigms.", "url": "https://arxiv.org/abs/2312.00210"}, {"metadata": {"arXiv": "2312.00224", "Date": "Thu, 30 Nov 2023 22:08:06 ", "Title": "Unsupervised textile defect detection using convolutional neural networks", "Authors": ["Imane Koulali", "M. Taner Eskil"], "Categories": "cs.CV cs.AI", "Journal-ref": "Applied Soft Computing, Volume 113, Part A, 2021, 107913, ISSN 1568-4946", "DOI": "10.1016/j.asoc.2021.107913"}, "abstract": "In this study, we propose a novel motif-based approach for unsupervised textile anomaly detection that combines the benefits of traditional convolutional neural networks with those of an unsupervised learning paradigm. It consists of five main steps: preprocessing, automatic pattern period extraction, patch extraction, features selection and anomaly detection. This proposed approach uses a new dynamic and heuristic method for feature selection which avoids the drawbacks of initialization of the number of filters (neurons) and their weights, and those of the backpropagation mechanism such as the vanishing gradients, which are common practice in the state-of-the-art methods. The design and training of the network are performed in a dynamic and input domain-based manner and, thus, no ad-hoc configurations are required. Before building the model, only the number of layers and the stride are defined. We do not initialize the weights randomly nor do we define the filter size or number of filters as conventionally done in CNN-based approaches. This reduces effort and time spent on hyperparameter initialization and fine-tuning. Only one defect-free sample is required for training and no further labeled data is needed. The trained network is then used to detect anomalies on defective fabric samples. We demonstrate the effectiveness of our approach on the Patterned Fabrics benchmark dataset. Our algorithm yields reliable and competitive results (on recall, precision, accuracy and f1- measure) compared to state-of-the-art unsupervised approaches, in less time, with efficient training in a single epoch and a lower computational cost.", "url": "https://arxiv.org/abs/2312.00224"}, {"metadata": {"arXiv": "2312.00330", "Date": "Fri, 01 Dec 2023 03:53:21 ", "Title": "StyleCrafter: Enhancing Stylized Text-to-Video Generation with Style Adapter", "Authors": ["Gongye Liu", "Menghan Xia", "Yong Zhang", "Haoxin Chen", "Jinbo Xing", "Xintao Wang", "Yujiu Yang", "Ying Shan"], "Categories": "cs.CV cs.AI", "Comments": ["Project page: https://gongyeliu.github.io/StyleCrafter.github.io/ ; GitHub repository: https://github.com/GongyeLiu/StyleCrafter"]}, "abstract": "Text-to-video (T2V) models have shown remarkable capabilities in generating diverse videos. However, they struggle to produce user-desired stylized videos due to (i) text's inherent clumsiness in expressing specific styles and (ii) the generally degraded style fidelity. To address these challenges, we introduce StyleCrafter, a generic method that enhances pre-trained T2V models with a style control adapter, enabling video generation in any style by providing a reference image. Considering the scarcity of stylized video datasets, we propose to first train a style control adapter using style-rich image datasets, then transfer the learned stylization ability to video generation through a tailor-made finetuning paradigm. To promote content-style disentanglement, we remove style descriptions from the text prompt and extract style information solely from the reference image using a decoupling learning strategy. Additionally, we design a scale-adaptive fusion module to balance the influences of text-based content features and image-based style features, which helps generalization across various text and style combinations. StyleCrafter efficiently generates high-quality stylized videos that align with the content of the texts and resemble the style of the reference images. Experiments demonstrate that our approach is more flexible and efficient than existing competitors.", "url": "https://arxiv.org/abs/2312.00330"}, {"metadata": {"arXiv": "2312.00377", "Date": "Fri, 01 Dec 2023 06:48:03 ", "Title": "SynFundus: Generating a synthetic fundus images dataset with millions of samples and multi-disease annotations", "Authors": ["Fangxin Shang", "Jie Fu", "Yehui Yang", "Lei Ma"], "Categories": "cs.CV cs.AI"}, "abstract": "In the field of medical imaging, the scarcity of large-scale datasets due to privacy restrictions stands as a significant barrier to develop large models for medical. To address this issue, we introduce SynFundus-1M, a high-quality synthetic dataset with over 1 million retinal fundus images and extensive disease and pathologies annotations, which is generated by a Denoising Diffusion Probabilistic Model. The SynFundus-Generator and SynFundus-1M achieve superior Frechet Inception Distance (FID) scores compared to existing methods on main-stream public real datasets. Furthermore, the ophthalmologists evaluation validate the difficulty in discerning these synthetic images from real ones, confirming the SynFundus-1M's authenticity. Through extensive experiments, we demonstrate that both CNN and ViT can benifit from SynFundus-1M by pretraining or training directly. Compared to datasets like ImageNet or EyePACS, models train on SynFundus-1M not only achieve better performance but also faster convergence on various downstream tasks.", "url": "https://arxiv.org/abs/2312.00377"}, {"metadata": {"arXiv": "2312.00591", "Date": "Fri, 01 Dec 2023 13:56:01 ", "Title": "Less is More: Learning Reference Knowledge Using No-Reference Image Quality Assessment", "Authors": ["Xudong Li", "Jingyuan Zheng", "Xiawu Zheng", "Runze Hu", "Enwei Zhang", "Yuting Gao", "Yunhang Shen", "Ke Li", "Yutao Liu", "Pingyang Dai", "Yan Zhang", "Rongrong Ji"], "Categories": "cs.CV cs.AI"}, "abstract": "Image Quality Assessment (IQA) with reference images have achieved great success by imitating the human vision system, in which the image quality is effectively assessed by comparing the query image with its pristine reference image. However, for the images in the wild, it is quite difficult to access accurate reference images. We argue that it is possible to learn reference knowledge under the No-Reference Image Quality Assessment (NR-IQA) setting, which is effective and efficient empirically. Concretely, by innovatively introducing a novel feature distillation method in IQA, we propose a new framework to learn comparative knowledge from non-aligned reference images. And then, to achieve fast convergence and avoid overfitting, we further propose an inductive bias regularization. Such a framework not only solves the congenital defects of NR-IQA but also improves the feature extraction framework, enabling it to express more abundant quality information. Surprisingly, our method utilizes less input while obtaining a more significant improvement compared to the teacher models. Extensive experiments on eight standard NR-IQA datasets demonstrate the superior performance to the state-of-the-art NR-IQA methods, i.e., achieving the PLCC values of 0.917 (vs. 0.884 in LIVEC) and 0.686 (vs. 0.661 in LIVEFB).", "url": "https://arxiv.org/abs/2312.00591"}, {"metadata": {"arXiv": "2312.00596", "Date": "Fri, 01 Dec 2023 14:01:48 ", "Title": "BCN: Batch Channel Normalization for Image Classification", "Authors": ["Afifa Khaled", "Chao Li", "Jia Ning", "Kun He"], "Categories": "cs.CV cs.AI"}, "abstract": "Normalization techniques have been widely used in the field of deep learning due to their capability of enabling higher learning rates and are less careful in initialization. However, the effectiveness of popular normalization technologies is typically limited to specific areas. Unlike the standard Batch Normalization (BN) and Layer Normalization (LN), where BN computes the mean and variance along the (N,H,W) dimensions and LN computes the mean and variance along the (C,H,W) dimensions (N, C, H and W are the batch, channel, spatial height and width dimension, respectively), this paper presents a novel normalization technique called Batch Channel Normalization (BCN). To exploit both the channel and batch dependence and adaptively and combine the advantages of BN and LN based on specific datasets or tasks, BCN separately normalizes inputs along the (N, H, W) and (C, H, W) axes, then combines the normalized outputs based on adaptive parameters. As a basic block, BCN can be easily integrated into existing models for various applications in the field of computer vision. Empirical results show that the proposed technique can be seamlessly applied to various versions of CNN or Vision Transformer architecture. The code is publicly available at https://github.com/AfifaKhaled/BatchChannel-Normalization", "url": "https://arxiv.org/abs/2312.00596"}, {"metadata": {"arXiv": "2312.00598", "Date": "Fri, 01 Dec 2023 14:03:30 ", "Title": "Learning from One Continuous Video Stream", "Authors": ["Jo\\~ao Carreira", "Michael King", "Viorica P\\u{a}tr\\u{a}ucean", "Dilara Gokay", "C\\u{a}t\\u{a}lin Ionescu", "Yi Yang", "Daniel Zoran", "Joseph Heyward", "Carl Doersch", "Yusuf Aytar", "Dima Damen", "Andrew Zisserman"], "Categories": "cs.CV cs.AI"}, "abstract": "We introduce a framework for online learning from a single continuous video stream -- the way people and animals learn, without mini-batches, data augmentation or shuffling. This poses great challenges given the high correlation between consecutive video frames and there is very little prior work on it. Our framework allows us to do a first deep dive into the topic and includes a collection of streams and tasks composed from two existing video datasets, plus methodology for performance evaluation that considers both adaptation and generalization. We employ pixel-to-pixel modelling as a practical and flexible way to switch between pre-training and single-stream evaluation as well as between arbitrary tasks, without ever requiring changes to models and always using the same pixel loss. Equipped with this framework we obtained large single-stream learning gains from pre-training with a novel family of future prediction tasks, found that momentum hurts, and that the pace of weight updates matters. The combination of these insights leads to matching the performance of IID learning with batch size 1, when using the same architecture and without costly replay buffers.", "url": "https://arxiv.org/abs/2312.00598"}, {"metadata": {"arXiv": "2312.00633", "Date": "Fri, 01 Dec 2023 14:52:59 ", "Title": "Towards Efficient 3D Object Detection in Bird's-Eye-View Space for Autonomous Driving: A Convolutional-Only Approach", "Authors": ["Yuxin Li", "Qiang Han", "Mengying Yu", "Yuxin Jiang", "Chaikiat Yeo", "Yiheng Li", "Zihang Huang", "Nini Liu", "Hsuanhan Chen", "Xiaojun Wu"], "Categories": "cs.CV cs.AI"}, "abstract": "3D object detection in Bird's-Eye-View (BEV) space has recently emerged as a prevalent approach in the field of autonomous driving. Despite the demonstrated improvements in accuracy and velocity estimation compared to perspective view methods, the deployment of BEV-based techniques in real-world autonomous vehicles remains challenging. This is primarily due to their reliance on vision-transformer (ViT) based architectures, which introduce quadratic complexity with respect to the input resolution. To address this issue, we propose an efficient BEV-based 3D detection framework called BEVENet, which leverages a convolutional-only architectural design to circumvent the limitations of ViT models while maintaining the effectiveness of BEV-based methods. Our experiments show that BEVENet is 3$\\times$ faster than contemporary state-of-the-art (SOTA) approaches on the NuScenes challenge, achieving a mean average precision (mAP) of 0.456 and a nuScenes detection score (NDS) of 0.555 on the NuScenes validation dataset, with an inference speed of 47.6 frames per second. To the best of our knowledge, this study stands as the first to achieve such significant efficiency improvements for BEV-based methods, highlighting their enhanced feasibility for real-world autonomous driving applications.", "url": "https://arxiv.org/abs/2312.00633"}, {"metadata": {"arXiv": "2312.00651", "Date": "Fri, 01 Dec 2023 15:24:38 ", "Title": "TrackDiffusion: Multi-object Tracking Data Generation via Diffusion Models", "Authors": ["Pengxiang Li", "Zhili Liu", "Kai Chen", "Lanqing Hong", "Yunzhi Zhuge", "Dit-Yan Yeung", "Huchuan Lu", "Xu Jia"], "Categories": "cs.CV cs.AI"}, "abstract": "Diffusion models have gained prominence in generating data for perception tasks such as image classification and object detection. However, the potential in generating high-quality tracking sequences, a crucial aspect in the field of video perception, has not been fully investigated. To address this gap, we propose TrackDiffusion, a novel architecture designed to generate continuous video sequences from the tracklets. TrackDiffusion represents a significant departure from the traditional layout-to-image (L2I) generation and copy-paste synthesis focusing on static image elements like bounding boxes by empowering image diffusion models to encompass dynamic and continuous tracking trajectories, thereby capturing complex motion nuances and ensuring instance consistency among video frames. For the first time, we demonstrate that the generated video sequences can be utilized for training multi-object tracking (MOT) systems, leading to significant improvement in tracker performance. Experimental results show that our model significantly enhances instance consistency in generated video sequences, leading to improved perceptual metrics. Our approach achieves an improvement of 8.7 in TrackAP and 11.8 in TrackAP$_{50}$ on the YTVIS dataset, underscoring its potential to redefine the standards of video data generation for MOT tasks and beyond.", "url": "https://arxiv.org/abs/2312.00651"}, {"metadata": {"arXiv": "2312.00732", "Date": "Fri, 01 Dec 2023 17:09:31 ", "Title": "Gaussian Grouping: Segment and Edit Anything in 3D Scenes", "Authors": ["Mingqiao Ye", "Martin Danelljan", "Fisher Yu and Lei Ke"], "Categories": "cs.CV cs.AI", "Comments": ["We propose Gaussian Grouping", "which extends Gaussian Splatting to fine-grained open-world 3D scene understanding. Github: https://github.com/lkeab/gaussian-grouping"]}, "abstract": "The recent Gaussian Splatting achieves high-quality and real-time novel-view synthesis of the 3D scenes. However, it is solely concentrated on the appearance and geometry modeling, while lacking in fine-grained object-level scene understanding. To address this issue, we propose Gaussian Grouping, which extends Gaussian Splatting to jointly reconstruct and segment anything in open-world 3D scenes. We augment each Gaussian with a compact Identity Encoding, allowing the Gaussians to be grouped according to their object instance or stuff membership in the 3D scene. Instead of resorting to expensive 3D labels, we supervise the Identity Encodings during the differentiable rendering by leveraging the 2D mask predictions by SAM, along with introduced 3D spatial consistency regularization. Comparing to the implicit NeRF representation, we show that the discrete and grouped 3D Gaussians can reconstruct, segment and edit anything in 3D with high visual quality, fine granularity and efficiency. Based on Gaussian Grouping, we further propose a local Gaussian Editing scheme, which shows efficacy in versatile scene editing applications, including 3D object removal, inpainting, colorization and scene recomposition. Our code and models will be at https://github.com/lkeab/gaussian-grouping.", "url": "https://arxiv.org/abs/2312.00732"}, {"metadata": {"arXiv": "2312.00766", "Date": "Fri, 01 Dec 2023 18:41:22 ", "Title": "Automated Material Properties Extraction For Enhanced Beauty Product Discovery and Makeup Virtual Try-on", "Authors": ["Fatemeh Taheri Dezaki", "Himanshu Arora", "Rahul Suresh", "Amin Banitalebi-Dehkordi"], "Categories": "cs.CV cs.AI", "Comments": ["Presented in Fifth Workshop on Recommender Systems in Fashion(fashionxrecsys) of ACM Conference on Recommender Systems"]}, "abstract": "The multitude of makeup products available can make it challenging to find the ideal match for desired attributes. An intelligent approach for product discovery is required to enhance the makeup shopping experience to make it more convenient and satisfying. However, enabling accurate and efficient product discovery requires extracting detailed attributes like color and finish type. Our work introduces an automated pipeline that utilizes multiple customized machine learning models to extract essential material attributes from makeup product images. Our pipeline is versatile and capable of handling various makeup products. To showcase the efficacy of our pipeline, we conduct extensive experiments on eyeshadow products (both single and multi-shade ones), a challenging makeup product known for its diverse range of shapes, colors, and finish types. Furthermore, we demonstrate the applicability of our approach by successfully extending it to other makeup categories like lipstick and foundation, showcasing its adaptability and effectiveness across different beauty products. Additionally, we conduct ablation experiments to demonstrate the superiority of our machine learning pipeline over human labeling methods in terms of reliability. Our proposed method showcases its effectiveness in cross-category product discovery, specifically in recommending makeup products that perfectly match a specified outfit. Lastly, we also demonstrate the application of these material attributes in enabling virtual-try-on experiences which makes makeup shopping experience significantly more engaging.", "url": "https://arxiv.org/abs/2312.00766"}, {"metadata": {"arXiv": "2312.00215", "Date": "Thu, 30 Nov 2023 21:54:42 ", "Title": "Learning active tactile perception through belief-space control", "Authors": ["Jean-Fran\\c{c}ois Tremblay", "David Meger", "Francois Hogan", "Gregory Dudek"], "Categories": "cs.RO cs.AI", "Comments": ["10 pages + references", "6 figures"]}, "abstract": "Robots operating in an open world will encounter novel objects with unknown physical properties, such as mass, friction, or size. These robots will need to sense these properties through interaction prior to performing downstream tasks with the objects. We propose a method that autonomously learns tactile exploration policies by developing a generative world model that is leveraged to 1) estimate the object's physical parameters using a differentiable Bayesian filtering algorithm and 2) develop an exploration policy using an information-gathering model predictive controller. We evaluate our method on three simulated tasks where the goal is to estimate a desired object property (mass, height or toppling height) through physical interaction. We find that our method is able to discover policies that efficiently gather information about the desired property in an intuitive manner. Finally, we validate our method on a real robot system for the height estimation task, where our method is able to successfully learn and execute an information-gathering policy from scratch.", "url": "https://arxiv.org/abs/2312.00215"}, {"metadata": {"arXiv": "2312.00597", "Date": "Fri, 01 Dec 2023 14:02:16 ", "Title": "UAVs and Birds: Enhancing Short-Range Navigation through Budgerigar Flight Studies", "Authors": ["Md. Mahmudur Rahman", "Sajid Islam", "Showren Chowdhury", "Sadia Jahan Zeba and Debajyoti Karmaker"], "Categories": "cs.RO cs.AI cs.CV", "Comments": ["26 pages", "10 figures"]}, "abstract": "This study delves into the flight behaviors of Budgerigars (Melopsittacus undulatus) to gain insights into their flight trajectories and movements. Using 3D reconstruction from stereo video camera recordings, we closely examine the velocity and acceleration patterns during three flight motion takeoff, flying and landing. The findings not only contribute to our understanding of bird behaviors but also hold significant implications for the advancement of algorithms in Unmanned Aerial Vehicles (UAVs). The research aims to bridge the gap between biological principles observed in birds and the application of these insights in developing more efficient and autonomous UAVs. In the context of the increasing use of drones, this study focuses on the biologically inspired principles drawn from bird behaviors, particularly during takeoff, flying and landing flight, to enhance UAV capabilities. The dataset created for this research sheds light on Budgerigars' takeoff, flying, and landing techniques, emphasizing their ability to control speed across different situations and surfaces. The study underscores the potential of incorporating these principles into UAV algorithms, addressing challenges related to short-range navigation, takeoff, flying, and landing.", "url": "https://arxiv.org/abs/2312.00597"}, {"metadata": {"arXiv": "2312.00455", "Date": "Fri, 01 Dec 2023 09:40:27 ", "Title": "Meta-Diversity Search in Complex Systems, A Recipe for Artificial Open-Endedness ?", "Authors": ["Mayalen Etcheverry (Flowers)", "Bert Wang-Chak Chan", "Cl\\'ement Moulin-Frier (Flowers)", "Pierre-Yves Oudeyer (Flowers)"], "Categories": "cs.AI cs.LG nlin.CG"}, "abstract": "Can we build an artificial system that would be able to generate endless surprises if ran \"forever\" in Minecraft? While there is not a single path toward solving that grand challenge, this article presents what we believe to be some working ingredients for the endless generation of novel increasingly complex artifacts in Minecraft. Our framework for an open-ended system includes two components: a complex system used to recursively grow and complexify artifacts over time, and a discovery algorithm that leverages the concept of meta-diversity search. Since complex systems have shown to enable the emergence of considerable complexity from set of simple rules, we believe them to be great candidates to generate all sort of artifacts in Minecraft. Yet, the space of possible artifacts that can be generated by these systems is often unknown, challenging to characterize and explore. Therefore automating the long-term discovery of novel and increasingly complex artifacts in these systems is an exciting research field. To approach these challenges, we formulate the problem of meta-diversity search where an artificial \"discovery assistant\" incrementally learns a diverse set of representations to characterize behaviors and searches to discover diverse patterns within each of them. A successful discovery assistant should continuously seek for novel sources of diversities while being able to quickly specialize the search toward a new unknown type of diversity. To implement those ideas in the Minecraft environment, we simulate an artificial \"chemistry\" system based on Lenia continuous cellular automaton for generating artifacts, as well as an artificial \"discovery assistant\" (called Holmes) for the artifact-discovery process. Holmes incrementally learns a hierarchy of modular representations to characterize divergent sources of diversity and uses a goal-based intrinsically-motivated exploration as the diversity search strategy.", "url": "https://arxiv.org/abs/2312.00455"}, {"metadata": {"arXiv": "2312.00079", "Date": "Thu, 30 Nov 2023 02:33:29 ", "Title": "HiFi Tuner: High-Fidelity Subject-Driven Fine-Tuning for Diffusion Models", "Authors": ["Zhonghao Wang", "Wei Wei", "Yang Zhao", "Zhisheng Xiao", "Mark Hasegawa-Johnson", "Humphrey Shi", "Tingbo Hou"], "Categories": "cs.CV cs.AI cs.CL cs.LG"}, "abstract": "This paper explores advancements in high-fidelity personalized image generation through the utilization of pre-trained text-to-image diffusion models. While previous approaches have made significant strides in generating versatile scenes based on text descriptions and a few input images, challenges persist in maintaining the subject fidelity within the generated images. In this work, we introduce an innovative algorithm named HiFi Tuner to enhance the appearance preservation of objects during personalized image generation. Our proposed method employs a parameter-efficient fine-tuning framework, comprising a denoising process and a pivotal inversion process. Key enhancements include the utilization of mask guidance, a novel parameter regularization technique, and the incorporation of step-wise subject representations to elevate the sample fidelity. Additionally, we propose a reference-guided generation approach that leverages the pivotal inversion of a reference image to mitigate unwanted subject variations and artifacts. We further extend our method to a novel image editing task: substituting the subject in an image through textual manipulations. Experimental evaluations conducted on the DreamBooth dataset using the Stable Diffusion model showcase promising results. Fine-tuning solely on textual embeddings improves CLIP-T score by 3.6 points and improves DINO score by 9.6 points over Textual Inversion. When fine-tuning all parameters, HiFi Tuner improves CLIP-T score by 1.2 points and improves DINO score by 1.2 points over DreamBooth, establishing a new state of the art.", "url": "https://arxiv.org/abs/2312.00079"}, {"metadata": {"arXiv": "2312.00101", "Date": "Thu, 30 Nov 2023 15:57:55 ", "Title": "Towards Unsupervised Representation Learning: Learning, Evaluating and Transferring Visual Representations", "Authors": ["Bonifaz Stuhr"], "Categories": "cs.CV cs.AI cs.GR cs.LG", "Comments": ["PhD Thesis", "223 pages", "Abstract in English", "Spanish and Catalan", "4 appendices"], "ACM-class": "I.2; I.3; I.4; I.5; I.6"}, "abstract": "Unsupervised representation learning aims at finding methods that learn representations from data without annotation-based signals. Abstaining from annotations not only leads to economic benefits but may - and to some extent already does - result in advantages regarding the representation's structure, robustness, and generalizability to different tasks. In the long run, unsupervised methods are expected to surpass their supervised counterparts due to the reduction of human intervention and the inherently more general setup that does not bias the optimization towards an objective originating from specific annotation-based signals. While major advantages of unsupervised representation learning have been recently observed in natural language processing, supervised methods still dominate in vision domains for most tasks. In this dissertation, we contribute to the field of unsupervised (visual) representation learning from three perspectives: (i) Learning representations: We design unsupervised, backpropagation-free Convolutional Self-Organizing Neural Networks (CSNNs) that utilize self-organization- and Hebbian-based learning rules to learn convolutional kernels and masks to achieve deeper backpropagation-free models. (ii) Evaluating representations: We build upon the widely used (non-)linear evaluation protocol to define pretext- and target-objective-independent metrics for measuring and investigating the objective function mismatch between various unsupervised pretext tasks and target tasks. (iii) Transferring representations: We contribute CARLANE, the first 3-way sim-to-real domain adaptation benchmark for 2D lane detection, and a method based on prototypical self-supervised learning. Finally, we contribute a content-consistent unpaired image-to-image translation method that utilizes masks, global and local discriminators, and similarity sampling to mitigate content inconsistencies.", "url": "https://arxiv.org/abs/2312.00101"}, {"metadata": {"arXiv": "2312.00784", "Date": "Fri, 01 Dec 2023 18:59:56 ", "Title": "Making Large Multimodal Models Understand Arbitrary Visual Prompts", "Authors": ["Mu Cai", "Haotian Liu", "Siva Karthik Mustikovela", "Gregory P. Meyer", "Yuning Chai", "Dennis Park", "Yong Jae Lee"], "Categories": "cs.CV cs.AI cs.CL cs.LG", "Comments": ["Project page: https://vip-llava.github.io/"]}, "abstract": "While existing large vision-language multimodal models focus on whole image understanding, there is a prominent gap in achieving region-specific comprehension. Current approaches that use textual coordinates or spatial encodings often fail to provide a user-friendly interface for visual prompting. To address this challenge, we introduce a novel multimodal model capable of decoding arbitrary visual prompts. This allows users to intuitively mark images and interact with the model using natural cues like a \"red bounding box\" or \"pointed arrow\". Our simple design directly overlays visual markers onto the RGB image, eliminating the need for complex region encodings, yet achieves state-of-the-art performance on region-understanding tasks like Visual7W, PointQA, and Visual Commonsense Reasoning benchmark. Furthermore, we present ViP-Bench, a comprehensive benchmark to assess the capability of models in understanding visual prompts across multiple dimensions, enabling future research in this domain. Code, data, and model are publicly available.", "url": "https://arxiv.org/abs/2312.00784"}, {"metadata": {"arXiv": "2312.00003", "Date": "Sat, 29 Jul 2023 12:42:03 ", "Title": "Transport Equation based Physics Informed Neural Network to predict the Yield Strength of Architected Materials", "Authors": ["Akshansh Mishra"], "Categories": "cs.LG cs.AI cs.CE math.OC"}, "abstract": "In this research, the application of the Physics-Informed Neural Network (PINN) model is explored to solve transport equation-based Partial Differential Equations (PDEs). The primary objective is to analyze the impact of different activation functions incorporated within the PINN model on its predictive performance, specifically assessing the Mean Squared Error (MSE) and Mean Absolute Error (MAE). The dataset used in the study consists of a varied set of input parameters related to strut diameter, unit cell size, and the corresponding yield stress values. Through this investigation the aim is to understand the effectiveness of the PINN model and the significance of choosing appropriate activation functions for solving complex PDEs in real-world applications. The outcomes suggest that the choice of activation function may have minimal influence on the model's predictive accuracy for this particular problem. The PINN model showcases exceptional generalization capabilities, indicating its capacity to avoid overfitting with the provided dataset. The research underscores the importance of striking a balance between performance and computational efficiency while selecting an activation function for specific real-world applications. These valuable findings contribute to advancing the understanding and potential adoption of PINN as an effective tool for solving challenging PDEs in diverse scientific and engineering domains.", "url": "https://arxiv.org/abs/2312.00003"}, {"metadata": {"arXiv": "2312.00102", "Date": "Thu, 30 Nov 2023 16:01:51 ", "Title": "FedEmb: A Vertical and Hybrid Federated Learning Algorithm using Network And Feature Embedding Aggregation", "Authors": ["Fanfei Meng", "Lele Zhang", "Yu Chen", "Yuxin Wang"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted by Proceedings on Engineering Sciences"], "Journal-ref": "Proceedings on Engineering Sciences, 2620-2832, 2023/10"}, "abstract": "Federated learning (FL) is an emerging paradigm for decentralized training of machine learning models on distributed clients, without revealing the data to the central server. The learning scheme may be horizontal, vertical or hybrid (both vertical and horizontal). Most existing research work with deep neural network (DNN) modelling is focused on horizontal data distributions, while vertical and hybrid schemes are much less studied. In this paper, we propose a generalized algorithm FedEmb, for modelling vertical and hybrid DNN-based learning. The idea of our algorithm is characterised by higher inference accuracy, stronger privacy-preserving properties, and lower client-server communication bandwidth demands as compared with existing work. The experimental results show that FedEmb is an effective method to tackle both split feature & subject space decentralized problems, shows 0.3% to 4.2% inference accuracy improvement with limited privacy revealing for datasets stored in local clients, and reduces 88.9 % time complexity over vertical baseline method.", "url": "https://arxiv.org/abs/2312.00102"}, {"metadata": {"arXiv": "2312.00189", "Date": "Thu, 30 Nov 2023 20:55:57 ", "Title": "HeTriNet: Heterogeneous Graph Triplet Attention Network for Drug-Target-Disease Interaction", "Authors": ["Farhan Tanvir", "Khaled Mohammed Saifuddin", "Tanvir Hossain", "Arunkumar Bagavathi and Esra Akbas"], "Categories": "cs.LG cs.AI q-bio.BM", "Comments": ["13 pages", "3 figures", "6 tables"]}, "abstract": "Modeling the interactions between drugs, targets, and diseases is paramount in drug discovery and has significant implications for precision medicine and personalized treatments. Current approaches frequently consider drug-target or drug-disease interactions individually, ignoring the interdependencies among all three entities. Within human metabolic systems, drugs interact with protein targets in cells, influencing target activities and subsequently impacting biological pathways to promote healthy functions and treat diseases. Moving beyond binary relationships and exploring tighter triple relationships is essential to understanding drugs' mechanism of action (MoAs). Moreover, identifying the heterogeneity of drugs, targets, and diseases, along with their distinct characteristics, is critical to model these complex interactions appropriately. To address these challenges, we effectively model the interconnectedness of all entities in a heterogeneous graph and develop a novel Heterogeneous Graph Triplet Attention Network (\\texttt{HeTriNet}). \\texttt{HeTriNet} introduces a novel triplet attention mechanism within this heterogeneous graph structure. Beyond pairwise attention as the importance of an entity for the other one, we define triplet attention to model the importance of pairs for entities in the drug-target-disease triplet prediction problem. Experimental results on real-world datasets show that \\texttt{HeTriNet} outperforms several baselines, demonstrating its remarkable proficiency in uncovering novel drug-target-disease relationships.", "url": "https://arxiv.org/abs/2312.00189"}, {"metadata": {"arXiv": "2312.00209", "Date": "Thu, 30 Nov 2023 21:42:15 ", "Title": "On the Interplay Between Stepsize Tuning and Progressive Sharpening", "Authors": ["Vincent Roulet", "Atish Agarwala", "Fabian Pedregosa"], "Categories": "cs.LG cs.AI math.OC", "Comments": ["Presented at the NeurIPS 2023 OPT Wokshop"]}, "abstract": "Recent empirical work has revealed an intriguing property of deep learning models by which the sharpness (largest eigenvalue of the Hessian) increases throughout optimization until it stabilizes around a critical value at which the optimizer operates at the edge of stability, given a fixed stepsize (Coehn et al, 2022). We investigate empirically how the sharpness evolves when using stepsize-tuners, the Armijo linesearch and Polyak stepsizes, that adapt the stepsize along the iterations to local quantities such as, implicitly, the sharpness itself. We find that the surprisingly poor performance of a classical Armijo linesearch may be well explained by its tendency to ever-increase the sharpness of the objective in the full or large batch regimes. On the other hand, we observe that Polyak stepsizes operate generally at the edge of stability or even slightly beyond, while outperforming its Armijo and constant stepsizes counterparts. We conclude with an analysis that suggests unlocking stepsize tuners requires an understanding of the joint dynamics of the step size and the sharpness.", "url": "https://arxiv.org/abs/2312.00209"}, {"metadata": {"arXiv": "2312.00232", "Date": "Thu, 30 Nov 2023 22:32:24 ", "Title": "Uncertainty in Graph Contrastive Learning with Bayesian Neural Networks", "Authors": ["Alexander M\\\"ollers", "Alexander Immer", "Elvin Isufi", "Vincent Fortuin"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "Graph contrastive learning has shown great promise when labeled data is scarce, but large unlabeled datasets are available. However, it often does not take uncertainty estimation into account. We show that a variational Bayesian neural network approach can be used to improve not only the uncertainty estimates but also the downstream performance on semi-supervised node-classification tasks. Moreover, we propose a new measure of uncertainty for contrastive learning, that is based on the disagreement in likelihood due to different positive samples.", "url": "https://arxiv.org/abs/2312.00232"}, {"metadata": {"arXiv": "2312.00237", "Date": "Thu, 30 Nov 2023 22:43:50 ", "Title": "Negotiated Representations to Prevent Forgetting in Machine Learning Applications", "Authors": ["Nuri Korhan", "Ceren \\\"Oner"], "Categories": "cs.LG cs.AI", "Comments": ["19 pages", "9 figures", "1 table. arXiv admin note: text overlap with arXiv:2010.15277", "arXiv:2102.09517", "arXiv:2201.00766 by other authors"]}, "abstract": "Catastrophic forgetting is a significant challenge in the field of machine learning, particularly in neural networks. When a neural network learns to perform well on a new task, it often forgets its previously acquired knowledge or experiences. This phenomenon occurs because the network adjusts its weights and connections to minimize the loss on the new task, which can inadvertently overwrite or disrupt the representations that were crucial for the previous tasks. As a result, the the performance of the network on earlier tasks deteriorates, limiting its ability to learn and adapt to a sequence of tasks. In this paper, we propose a novel method for preventing catastrophic forgetting in machine learning applications, specifically focusing on neural networks. Our approach aims to preserve the knowledge of the network across multiple tasks while still allowing it to learn new information effectively. We demonstrate the effectiveness of our method by conducting experiments on various benchmark datasets, including Split MNIST, Split CIFAR10, Split Fashion MNIST, and Split CIFAR100. These datasets are created by dividing the original datasets into separate, non overlapping tasks, simulating a continual learning scenario where the model needs to learn multiple tasks sequentially without forgetting the previous ones. Our proposed method tackles the catastrophic forgetting problem by incorporating negotiated representations into the learning process, which allows the model to maintain a balance between retaining past experiences and adapting to new tasks. By evaluating our method on these challenging datasets, we aim to showcase its potential for addressing catastrophic forgetting and improving the performance of neural networks in continual learning settings.", "url": "https://arxiv.org/abs/2312.00237"}, {"metadata": {"arXiv": "2312.00267", "Date": "Fri, 01 Dec 2023 00:54:02 ", "Title": "Sample Efficient Reinforcement Learning from Human Feedback via Active Exploration", "Authors": ["Viraj Mehta and Vikramjeet Das and Ojash Neopane and Yijia Dai and Ilija Bogunovic and Jeff Schneider and Willie Neiswanger"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "Preference-based feedback is important for many applications in reinforcement learning where direct evaluation of a reward function is not feasible. A notable recent example arises in reinforcement learning from human feedback (RLHF) on large language models. For many applications of RLHF, the cost of acquiring the human feedback can be substantial. In this work, we take advantage of the fact that one can often choose contexts at which to obtain human feedback in order to most efficiently identify a good policy, and formalize this as an offline contextual dueling bandit problem. We give an upper-confidence-bound style algorithm for this problem and prove a polynomial worst-case regret bound. We then provide empirical confirmation in a synthetic setting that our approach outperforms existing methods. After, we extend the setting and methodology for practical use in RLHF training of large language models. Here, our method is able to reach better performance with fewer samples of human preferences than multiple baselines on three real-world datasets.", "url": "https://arxiv.org/abs/2312.00267"}, {"metadata": {"arXiv": "2312.00268", "Date": "Fri, 01 Dec 2023 01:01:04 ", "Title": "Academic competitions", "Authors": ["Hugo Jair Escalante and Aleksandra Kruchinina"], "Categories": "cs.LG cs.AI"}, "abstract": "Academic challenges comprise effective means for (i) advancing the state of the art, (ii) putting in the spotlight of a scientific community specific topics and problems, as well as (iii) closing the gap for under represented communities in terms of accessing and participating in the shaping of research fields. Competitions can be traced back for centuries and their achievements have had great influence in our modern world. Recently, they (re)gained popularity, with the overwhelming amounts of data that is being generated in different domains, as well as the need of pushing the barriers of existing methods, and available tools to handle such data. This chapter provides a survey of academic challenges in the context of machine learning and related fields. We review the most influential competitions in the last few years and analyze challenges per area of knowledge. The aims of scientific challenges, their goals, major achievements and expectations for the next few years are reviewed.", "url": "https://arxiv.org/abs/2312.00268"}, {"metadata": {"arXiv": "2312.00342", "Date": "Fri, 01 Dec 2023 04:29:19 ", "Title": "Efficient Off-Policy Safe Reinforcement Learning Using Trust Region Conditional Value at Risk", "Authors": ["Dohyeong Kim and Songhwai Oh"], "Categories": "cs.LG cs.AI", "Comments": ["RA-L and IROS 2022"], "Journal-ref": "IEEE Robotics and Automation Letters, vol. 7, no. 3, pp. 7644-7651, July 2022", "DOI": "10.1109/LRA.2022.3184793"}, "abstract": "This paper aims to solve a safe reinforcement learning (RL) problem with risk measure-based constraints. As risk measures, such as conditional value at risk (CVaR), focus on the tail distribution of cost signals, constraining risk measures can effectively prevent a failure in the worst case. An on-policy safe RL method, called TRC, deals with a CVaR-constrained RL problem using a trust region method and can generate policies with almost zero constraint violations with high returns. However, to achieve outstanding performance in complex environments and satisfy safety constraints quickly, RL methods are required to be sample efficient. To this end, we propose an off-policy safe RL method with CVaR constraints, called off-policy TRC. If off-policy data from replay buffers is directly used to train TRC, the estimation error caused by the distributional shift results in performance degradation. To resolve this issue, we propose novel surrogate functions, in which the effect of the distributional shift can be reduced, and introduce an adaptive trust-region constraint to ensure a policy not to deviate far from replay buffers. The proposed method has been evaluated in simulation and real-world environments and satisfied safety constraints within a few steps while achieving high returns even in complex robotic tasks.", "url": "https://arxiv.org/abs/2312.00342"}, {"metadata": {"arXiv": "2312.00434", "Date": "Fri, 01 Dec 2023 09:06:06 ", "Title": "PEFTDebias : Capturing debiasing information using PEFTs", "Authors": ["Sumit Agarwal", "Aditya Srikanth Veerubhotla", "Srijan Bansal"], "Categories": "cs.LG cs.AI cs.CY", "Comments": ["EMNLP 2023"]}, "abstract": "The increasing use of foundation models highlights the urgent need to address and eliminate implicit biases present in them that arise during pretraining. In this paper, we introduce PEFTDebias, a novel approach that employs parameter-efficient fine-tuning (PEFT) to mitigate the biases within foundation models. PEFTDebias consists of two main phases: an upstream phase for acquiring debiasing parameters along a specific bias axis, and a downstream phase where these parameters are incorporated into the model and frozen during the fine-tuning process. By evaluating on four datasets across two bias axes namely gender and race, we find that downstream biases can be effectively reduced with PEFTs. In addition, we show that these parameters possess axis-specific debiasing characteristics, enabling their effective transferability in mitigating biases in various downstream tasks. To ensure reproducibility, we release the code to do our experiments.", "url": "https://arxiv.org/abs/2312.00434"}, {"metadata": {"arXiv": "2312.00471", "Date": "Fri, 01 Dec 2023 10:10:18 ", "Title": "A Bayesian approach for prompt optimization in pre-trained language models", "Authors": ["Antonio Sabbatella", "Andrea Ponti", "Antonio Candelieri", "Ilaria Giordani", "Francesco Archetti"], "Categories": "cs.LG cs.AI"}, "abstract": "A prompt is a sequence of symbol or tokens, selected from a vocabulary according to some rule, which is prepended/concatenated to a textual query. A key problem is how to select the sequence of tokens: in this paper we formulate it as a combinatorial optimization problem. The high dimensionality of the token space com-pounded by the length of the prompt sequence requires a very efficient solution. In this paper we propose a Bayesian optimization method, executed in a continuous em-bedding of the combinatorial space. In this paper we focus on hard prompt tuning (HPT) which directly searches for discrete tokens to be added to the text input with-out requiring access to the large language model (LLM) and can be used also when LLM is available only as a black-box. This is critically important if LLMs are made available in the Model as a Service (MaaS) manner as in GPT-4. The current manu-script is focused on the optimization of discrete prompts for classification tasks. The discrete prompts give rise to difficult combinatorial optimization problem which easily become intractable given the dimension of the token space in realistic applications. The optimization method considered in this paper is Bayesian optimization (BO) which has become the dominant approach in black-box optimization for its sample efficiency along with its modular structure and versatility. In this paper we use BoTorch, a library for Bayesian optimization research built on top of pyTorch. Albeit preliminary and obtained using a 'vanilla' version of BO, the experiments on RoB-ERTa on six benchmarks, show a good performance across a variety of tasks and enable an analysis of the tradeoff between size of the search space, accuracy and wall clock time.", "url": "https://arxiv.org/abs/2312.00471"}, {"metadata": {"arXiv": "2312.00540", "Date": "Fri, 01 Dec 2023 12:35:18 ", "Title": "Target-agnostic Source-free Domain Adaptation for Regression Tasks", "Authors": ["Tianlang He", "Zhiqiu Xia", "Jierun Chen", "Haoliang Li", "S.-H. Gary Chan"], "Categories": "cs.LG cs.AI stat.ML", "Comments": ["Accepted by ICDE 2024"]}, "abstract": "Unsupervised domain adaptation (UDA) seeks to bridge the domain gap between the target and source using unlabeled target data. Source-free UDA removes the requirement for labeled source data at the target to preserve data privacy and storage. However, work on source-free UDA assumes knowledge of domain gap distribution, and hence is limited to either target-aware or classification task. To overcome it, we propose TASFAR, a novel target-agnostic source-free domain adaptation approach for regression tasks. Using prediction confidence, TASFAR estimates a label density map as the target label distribution, which is then used to calibrate the source model on the target domain. We have conducted extensive experiments on four regression tasks with various domain gaps, namely, pedestrian dead reckoning for different users, image-based people counting in different scenes, housing-price prediction at different districts, and taxi-trip duration prediction from different departure points. TASFAR is shown to substantially outperform the state-of-the-art source-free UDA approaches by averagely reducing 22% errors for the four tasks and achieve notably comparable accuracy as source-based UDA without using source data.", "url": "https://arxiv.org/abs/2312.00540"}, {"metadata": {"arXiv": "2312.00586", "Date": "Fri, 01 Dec 2023 13:50:55 ", "Title": "Explainable Fraud Detection with Deep Symbolic Classification", "Authors": ["Samantha Visbeek", "Erman Acar", "Floris den Hengst"], "Categories": "cs.LG cs.AI", "Comments": ["12 pages", "3 figures", "To be published in the 3rd International Workshop on Explainable AI in Finance of the 4th ACM International Conference on AI in Finance (ICAIF", "https://ai-finance.org/)"]}, "abstract": "There is a growing demand for explainable, transparent, and data-driven models within the domain of fraud detection. Decisions made by fraud detection models need to be explainable in the event of a customer dispute. Additionally, the decision-making process in the model must be transparent to win the trust of regulators and business stakeholders. At the same time, fraud detection solutions can benefit from data due to the noisy, dynamic nature of fraud and the availability of large historical data sets. Finally, fraud detection is notorious for its class imbalance: there are typically several orders of magnitude more legitimate transactions than fraudulent ones. In this paper, we present Deep Symbolic Classification (DSC), an extension of the Deep Symbolic Regression framework to classification problems. DSC casts classification as a search problem in the space of all analytic functions composed of a vocabulary of variables, constants, and operations and optimizes for an arbitrary evaluation metric directly. The search is guided by a deep neural network trained with reinforcement learning. Because the functions are mathematical expressions that are in closed-form and concise, the model is inherently explainable both at the level of a single classification decision and the model's decision process. Furthermore, the class imbalance problem is successfully addressed by optimizing for metrics that are robust to class imbalance such as the F1 score. This eliminates the need for oversampling and undersampling techniques that plague traditional approaches. Finally, the model allows to explicitly balance between the prediction accuracy and the explainability. An evaluation on the PaySim data set demonstrates competitive predictive performance with state-of-the-art models, while surpassing them in terms of explainability. This establishes DSC as a promising model for fraud detection systems.", "url": "https://arxiv.org/abs/2312.00586"}, {"metadata": {"arXiv": "2312.00656", "Date": "Fri, 01 Dec 2023 15:30:54 ", "Title": "Simple Transferability Estimation for Regression Tasks", "Authors": ["Cuong N. Nguyen", "Phong Tran", "Lam Si Tung Ho", "Vu Dinh", "Anh T. Tran", "Tal Hassner", "Cuong V. Nguyen"], "Categories": "cs.LG cs.AI stat.ML", "Comments": ["23 pages", "This paper published at The 39th Conference on Uncertainty in Artificial Intelligence (UAI2023)"]}, "abstract": "We consider transferability estimation, the problem of estimating how well deep learning models transfer from a source to a target task. We focus on regression tasks, which received little previous attention, and propose two simple and computationally efficient approaches that estimate transferability based on the negative regularized mean squared error of a linear regression model. We prove novel theoretical results connecting our approaches to the actual transferability of the optimal target models obtained from the transfer learning process. Despite their simplicity, our approaches significantly outperform existing state-of-the-art regression transferability estimators in both accuracy and efficiency. On two large-scale keypoint regression benchmarks, our approaches yield 12% to 36% better results on average while being at least 27% faster than previous state-of-the-art methods.", "url": "https://arxiv.org/abs/2312.00656"}, {"metadata": {"arXiv": "2312.00660", "Date": "Fri, 01 Dec 2023 15:39:24 ", "Title": "Resource-constrained knowledge diffusion processes inspired by human peer learning", "Authors": ["Ehsan Beikihassan", "Amy K.Hoover", "Ioannis Koutis", "Ali Parviz", "Niloofar Aghaieabiane"], "Categories": "cs.LG cs.AI"}, "abstract": "We consider a setting where a population of artificial learners is given, and the objective is to optimize aggregate measures of performance, under constraints on training resources. The problem is motivated by the study of peer learning in human educational systems. In this context, we study natural knowledge diffusion processes in networks of interacting artificial learners. By `natural', we mean processes that reflect human peer learning where the students' internal state and learning process is mostly opaque, and the main degree of freedom lies in the formation of peer learning groups by a coordinator who can potentially evaluate the learners before assigning them to peer groups. Among else, we empirically show that such processes indeed make effective use of the training resources, and enable the design of modular neural models that have the capacity to generalize without being prone to overfitting noisy labels.", "url": "https://arxiv.org/abs/2312.00660"}, {"metadata": {"arXiv": "2312.00718", "Date": "Fri, 01 Dec 2023 16:53:15 ", "Title": "Removing Biases from Molecular Representations via Information Maximization", "Authors": ["Chenyu Wang", "Sharut Gupta", "Caroline Uhler", "Tommi Jaakkola"], "Categories": "cs.LG cs.AI q-bio.BM"}, "abstract": "High-throughput drug screening -- using cell imaging or gene expression measurements as readouts of drug effect -- is a critical tool in biotechnology to assess and understand the relationship between the chemical structure and biological activity of a drug. Since large-scale screens have to be divided into multiple experiments, a key difficulty is dealing with batch effects, which can introduce systematic errors and non-biological associations in the data. We propose InfoCORE, an Information maximization approach for COnfounder REmoval, to effectively deal with batch effects and obtain refined molecular representations. InfoCORE establishes a variational lower bound on the conditional mutual information of the latent representations given a batch identifier. It adaptively reweighs samples to equalize their implied batch distribution. Extensive experiments on drug screening data reveal InfoCORE's superior performance in a multitude of tasks including molecular property prediction and molecule-phenotype retrieval. Additionally, we show results for how InfoCORE offers a versatile framework and resolves general distribution shifts and issues of data fairness by minimizing correlation with spurious features or removing sensitive attributes. The code is available at https://github.com/uhlerlab/InfoCORE.", "url": "https://arxiv.org/abs/2312.00718"}, {"metadata": {"arXiv": "2312.00727", "Date": "Fri, 01 Dec 2023 17:01:37 ", "Title": "Safe Reinforcement Learning in Tensor Reproducing Kernel Hilbert Space", "Authors": ["Xiaoyuan Cheng", "Boli Chen", "Liz Varga", "Yukun Hu"], "Categories": "cs.LG cs.AI cs.SY eess.SY"}, "abstract": "This paper delves into the problem of safe reinforcement learning (RL) in a partially observable environment with the aim of achieving safe-reachability objectives. In traditional partially observable Markov decision processes (POMDP), ensuring safety typically involves estimating the belief in latent states. However, accurately estimating an optimal Bayesian filter in POMDP to infer latent states from observations in a continuous state space poses a significant challenge, largely due to the intractable likelihood. To tackle this issue, we propose a stochastic model-based approach that guarantees RL safety almost surely in the face of unknown system dynamics and partial observation environments. We leveraged the Predictive State Representation (PSR) and Reproducing Kernel Hilbert Space (RKHS) to represent future multi-step observations analytically, and the results in this context are provable. Furthermore, we derived essential operators from the kernel Bayes' rule, enabling the recursive estimation of future observations using various operators. Under the assumption of \\textit{undercompleness}, a polynomial sample complexity is established for the RL algorithm for the infinite size of observation and action spaces, ensuring an $\\epsilon-$suboptimal safe policy guarantee.", "url": "https://arxiv.org/abs/2312.00727"}, {"metadata": {"arXiv": "2312.00752", "Date": "Fri, 01 Dec 2023 18:01:34 ", "Title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces", "Authors": ["Albert Gu", "Tri Dao"], "Categories": "cs.LG cs.AI"}, "abstract": "Foundation models, now powering most of the exciting applications in deep learning, are almost universally based on the Transformer architecture and its core attention module. Many subquadratic-time architectures such as linear attention, gated convolution and recurrent models, and structured state space models (SSMs) have been developed to address Transformers' computational inefficiency on long sequences, but they have not performed as well as attention on important modalities such as language. We identify that a key weakness of such models is their inability to perform content-based reasoning, and make several improvements. First, simply letting the SSM parameters be functions of the input addresses their weakness with discrete modalities, allowing the model to selectively propagate or forget information along the sequence length dimension depending on the current token. Second, even though this change prevents the use of efficient convolutions, we design a hardware-aware parallel algorithm in recurrent mode. We integrate these selective SSMs into a simplified end-to-end neural network architecture without attention or even MLP blocks (Mamba). Mamba enjoys fast inference (5$\\times$ higher throughput than Transformers) and linear scaling in sequence length, and its performance improves on real data up to million-length sequences. As a general sequence model backbone, Mamba achieves state-of-the-art performance across several modalities such as language, audio, and genomics. On language modeling, our Mamba-3B model outperforms Transformers of the same size and matches Transformers twice its size, both in pretraining and downstream evaluation.", "url": "https://arxiv.org/abs/2312.00752"}, {"metadata": {"arXiv": "2312.00761", "Date": "Fri, 01 Dec 2023 18:29:08 ", "Title": "Deep Unlearning: Fast and Efficient Training-free Approach to Controlled Forgetting", "Authors": ["Sangamesh Kodge", "Gobinda Saha and Kaushik Roy"], "Categories": "cs.LG cs.AI cs.CV stat.ML"}, "abstract": "Machine unlearning has emerged as a prominent and challenging area of interest, driven in large part by the rising regulatory demands for industries to delete user data upon request and the heightened awareness of privacy. Existing approaches either retrain models from scratch or use several finetuning steps for every deletion request, often constrained by computational resource limitations and restricted access to the original training data. In this work, we introduce a novel class unlearning algorithm designed to strategically eliminate an entire class or a group of classes from the learned model. To that end, our algorithm first estimates the Retain Space and the Forget Space, representing the feature or activation spaces for samples from classes to be retained and unlearned, respectively. To obtain these spaces, we propose a novel singular value decomposition-based technique that requires layer wise collection of network activations from a few forward passes through the network. We then compute the shared information between these spaces and remove it from the forget space to isolate class-discriminatory feature space for unlearning. Finally, we project the model weights in the orthogonal direction of the class-discriminatory space to obtain the unlearned model. We demonstrate our algorithm's efficacy on ImageNet using a Vision Transformer with only $\\sim$1.5% drop in retain accuracy compared to the original model while maintaining under 1% accuracy on the unlearned class samples. Further, our algorithm consistently performs well when subject to Membership Inference Attacks showing 7.8% improvement on average across a variety of image classification datasets and network architectures, as compared to other baselines while being $\\sim$6x more computationally efficient.", "url": "https://arxiv.org/abs/2312.00761"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

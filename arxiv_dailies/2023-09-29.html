<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2309.15954", "Date": "Wed, 27 Sep 2023 19:10:43 ", "Title": "The Devil is in the Details: A Deep Dive into the Rabbit Hole of Data Filtering", "Authors": ["Haichao Yu", "Yu Tian", "Sateesh Kumar", "Linjie Yang", "Heng Wang"], "Categories": "cs.CV cs.LG", "Comments": ["12 pages", "10 figures"]}, "abstract": "The quality of pre-training data plays a critical role in the performance of foundation models. Popular foundation models often design their own recipe for data filtering, which makes it hard to analyze and compare different data filtering approaches. DataComp is a new benchmark dedicated to evaluating different methods for data filtering. This paper describes our learning and solution when participating in the DataComp challenge. Our filtering strategy includes three stages: single-modality filtering, cross-modality filtering, and data distribution alignment. We integrate existing methods and propose new solutions, such as computing CLIP score on horizontally flipped images to mitigate the interference of scene text, using vision and language models to retrieve training samples for target downstream tasks, rebalancing the data distribution to improve the efficiency of allocating the computational budget, etc. We slice and dice our design choices, provide in-depth analysis, and discuss open questions. Our approach outperforms the best method from the DataComp paper by over 4% on the average performance of 38 tasks and by over 2% on ImageNet.", "url": "https://arxiv.org/abs/2309.15954"}, {"metadata": {"arXiv": "2309.16020", "Date": "Wed, 27 Sep 2023 20:54:56 ", "Title": "GeoCLIP: Clip-Inspired Alignment between Locations and Images for Effective Worldwide Geo-localization", "Authors": ["Vicente Vivanco Cepeda", "Gaurav Kumar Nayak", "Mubarak Shah"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted at NeurIPS 2023"]}, "abstract": "Worldwide Geo-localization aims to pinpoint the precise location of images taken anywhere on Earth. This task has considerable challenges due to immense variation in geographic landscapes. The image-to-image retrieval-based approaches fail to solve this problem on a global scale as it is not feasible to construct a large gallery of images covering the entire world. Instead, existing approaches divide the globe into discrete geographic cells, transforming the problem into a classification task. However, their performance is limited by the predefined classes and often results in inaccurate localizations when an image's location significantly deviates from its class center. To overcome these limitations, we propose GeoCLIP, a novel CLIP-inspired Image-to-GPS retrieval approach that enforces alignment between the image and its corresponding GPS locations. GeoCLIP's location encoder models the Earth as a continuous function by employing positional encoding through random Fourier features and constructing a hierarchical representation that captures information at varying resolutions to yield a semantically rich high-dimensional feature suitable to use even beyond geo-localization. To the best of our knowledge, this is the first work employing GPS encoding for geo-localization. We demonstrate the efficacy of our method via extensive experiments and ablations on benchmark datasets. We achieve competitive performance with just 20% of training data, highlighting its effectiveness even in limited-data settings. Furthermore, we qualitatively demonstrate geo-localization using a text query by leveraging CLIP backbone of our image encoder.", "url": "https://arxiv.org/abs/2309.16020"}, {"metadata": {"arXiv": "2309.16139", "Date": "Thu, 28 Sep 2023 03:40:30 ", "Title": "Two-Step Active Learning for Instance Segmentation with Uncertainty and Diversity Sampling", "Authors": ["Ke Yu", "Stephen Albro", "Giulia DeSalvo", "Suraj Kothawade", "Abdullah Rashwan", "Sasan Tavakkol", "Kayhan Batmanghelich", "Xiaoqi Yin"], "Categories": "cs.CV cs.LG", "Comments": ["UNCV ICCV 2023"]}, "abstract": "Training high-quality instance segmentation models requires an abundance of labeled images with instance masks and classifications, which is often expensive to procure. Active learning addresses this challenge by striving for optimum performance with minimal labeling cost by selecting the most informative and representative images for labeling. Despite its potential, active learning has been less explored in instance segmentation compared to other tasks like image classification, which require less labeling. In this study, we propose a post-hoc active learning algorithm that integrates uncertainty-based sampling with diversity-based sampling. Our proposed algorithm is not only simple and easy to implement, but it also delivers superior performance on various datasets. Its practical application is demonstrated on a real-world overhead imagery dataset, where it increases the labeling efficiency fivefold.", "url": "https://arxiv.org/abs/2309.16139"}, {"metadata": {"arXiv": "2309.16495", "Date": "Thu, 28 Sep 2023 14:59:53 ", "Title": "Deep Single Models vs. Ensembles: Insights for a Fast Deployment of Parking Monitoring Systems", "Authors": ["Andre Gustavo Hochuli", "Jean Paul Barddal", "Gillian Cezar Palhano", "Leonardo Matheus Mendes", "Paulo Ricardo Lisboa de Almeida"], "Categories": "cs.CV cs.LG", "Comments": ["An improved version of this manuscript was submitted to IEEE ICMLA 2023 (Dec/23)"]}, "abstract": "Searching for available parking spots in high-density urban centers is a stressful task for drivers that can be mitigated by systems that know in advance the nearest parking space available. To this end, image-based systems offer cost advantages over other sensor-based alternatives (e.g., ultrasonic sensors), requiring less physical infrastructure for installation and maintenance. Despite recent deep learning advances, deploying intelligent parking monitoring is still a challenge since most approaches involve collecting and labeling large amounts of data, which is laborious and time-consuming. Our study aims to uncover the challenges in creating a global framework, trained using publicly available labeled parking lot images, that performs accurately across diverse scenarios, enabling the parking space monitoring as a ready-to-use system to deploy in a new environment. Through exhaustive experiments involving different datasets and deep learning architectures, including fusion strategies and ensemble methods, we found that models trained on diverse datasets can achieve 95\\% accuracy without the burden of data annotation and model training on the target parking lot", "url": "https://arxiv.org/abs/2309.16495"}, {"metadata": {"arXiv": "2309.16592", "Date": "Thu, 28 Sep 2023 16:55:52 ", "Title": "Tensor Factorization for Leveraging Cross-Modal Knowledge in Data-Constrained Infrared Object Detection", "Authors": ["Manish Sharma", "Moitreya Chatterjee", "Kuan-Chuan Peng", "Suhas Lohit", "Michael Jones"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted to ICCV 2023", "LIMIT Workshop. The first two authors contributed equally"]}, "abstract": "The primary bottleneck towards obtaining good recognition performance in IR images is the lack of sufficient labeled training data, owing to the cost of acquiring such data. Realizing that object detection methods for the RGB modality are quite robust (at least for some commonplace classes, like person, car, etc.), thanks to the giant training sets that exist, in this work we seek to leverage cues from the RGB modality to scale object detectors to the IR modality, while preserving model performance in the RGB modality. At the core of our method, is a novel tensor decomposition method called TensorFact which splits the convolution kernels of a layer of a Convolutional Neural Network (CNN) into low-rank factor matrices, with fewer parameters than the original CNN. We first pretrain these factor matrices on the RGB modality, for which plenty of training data are assumed to exist and then augment only a few trainable parameters for training on the IR modality to avoid over-fitting, while encouraging them to capture complementary cues from those trained only on the RGB modality. We validate our approach empirically by first assessing how well our TensorFact decomposed network performs at the task of detecting objects in RGB images vis-a-vis the original network and then look at how well it adapts to IR images of the FLIR ADAS v1 dataset. For the latter, we train models under scenarios that pose challenges stemming from data paucity. From the experiments, we observe that: (i) TensorFact shows performance gains on RGB images; (ii) further, this pre-trained model, when fine-tuned, outperforms a standard state-of-the-art object detector on the FLIR ADAS v1 dataset by about 4% in terms of mAP 50 score.", "url": "https://arxiv.org/abs/2309.16592"}, {"metadata": {"arXiv": "2309.16656", "Date": "Thu, 28 Sep 2023 17:55:24 ", "Title": "Visual In-Context Learning for Few-Shot Eczema Segmentation", "Authors": ["Neelesh Kumar", "Oya Aran", "Venugopal Vasudevan"], "Categories": "cs.CV cs.LG"}, "abstract": "Automated diagnosis of eczema from digital camera images is crucial for developing applications that allow patients to self-monitor their recovery. An important component of this is the segmentation of eczema region from such images. Current methods for eczema segmentation rely on deep neural networks such as convolutional (CNN)-based U-Net or transformer-based Swin U-Net. While effective, these methods require high volume of annotated data, which can be difficult to obtain. Here, we investigate the capabilities of visual in-context learning that can perform few-shot eczema segmentation with just a handful of examples and without any need for retraining models. Specifically, we propose a strategy for applying in-context learning for eczema segmentation with a generalist vision model called SegGPT. When benchmarked on a dataset of annotated eczema images, we show that SegGPT with just 2 representative example images from the training dataset performs better (mIoU: 36.69) than a CNN U-Net trained on 428 images (mIoU: 32.60). We also discover that using more number of examples for SegGPT may in fact be harmful to its performance. Our result highlights the importance of visual in-context learning in developing faster and better solutions to skin imaging tasks. Our result also paves the way for developing inclusive solutions that can cater to minorities in the demographics who are typically heavily under-represented in the training data.", "url": "https://arxiv.org/abs/2309.16656"}, {"metadata": {"arXiv": "2309.16662", "Date": "Thu, 28 Sep 2023 17:58:19 ", "Title": "Geodesic Regression Characterizes 3D Shape Changes in the Female Brain During Menstruation", "Authors": ["Adele Myers", "Caitlin Taylor", "Emily Jacobs", "Nina Miolane"], "Categories": "cs.CV cs.LG", "Comments": ["In Proceedings of the ICCV Conference Workshop: Computer Vision for Automated Medical Diagnosis. Institute of Electrical and Electronics Engineers Inc. (2023)"]}, "abstract": "Women are at higher risk of Alzheimer's and other neurological diseases after menopause, and yet research connecting female brain health to sex hormone fluctuations is limited. We seek to investigate this connection by developing tools that quantify 3D shape changes that occur in the brain during sex hormone fluctuations. Geodesic regression on the space of 3D discrete surfaces offers a principled way to characterize the evolution of a brain's shape. However, in its current form, this approach is too computationally expensive for practical use. In this paper, we propose approximation schemes that accelerate geodesic regression on shape spaces of 3D discrete surfaces. We also provide rules of thumb for when each approximation can be used. We test our approach on synthetic data to quantify the speed-accuracy trade-off of these approximations and show that practitioners can expect very significant speed-up while only sacrificing little accuracy. Finally, we apply the method to real brain shape data and produce the first characterization of how the female hippocampus changes shape during the menstrual cycle as a function of progesterone: a characterization made (practically) possible by our approximation schemes. Our work paves the way for comprehensive, practical shape analyses in the fields of bio-medicine and computer vision. Our implementation is publicly available on GitHub: https://github.com/bioshape-lab/my28brains.", "url": "https://arxiv.org/abs/2309.16662"}, {"metadata": {"arXiv": "2309.16672", "Date": "Thu, 28 Sep 2023 17:59:58 ", "Title": "Learning to Transform for Generalizable Instance-wise Invariance", "Authors": ["Utkarsh Singhal and Carlos Esteves and Ameesh Makadia and Stella X. Yu"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted to ICCV 2023"]}, "abstract": "Computer vision research has long aimed to build systems that are robust to spatial transformations found in natural data. Traditionally, this is done using data augmentation or hard-coding invariances into the architecture. However, too much or too little invariance can hurt, and the correct amount is unknown a priori and dependent on the instance. Ideally, the appropriate invariance would be learned from data and inferred at test-time. We treat invariance as a prediction problem. Given any image, we use a normalizing flow to predict a distribution over transformations and average the predictions over them. Since this distribution only depends on the instance, we can align instances before classifying them and generalize invariance across classes. The same distribution can also be used to adapt to out-of-distribution poses. This normalizing flow is trained end-to-end and can learn a much larger range of transformations than Augerino and InstaAug. When used as data augmentation, our method shows accuracy and robustness gains on CIFAR 10, CIFAR10-LT, and TinyImageNet.", "url": "https://arxiv.org/abs/2309.16672"}, {"metadata": {"arXiv": "2309.15867", "Date": "Tue, 26 Sep 2023 20:46:40 ", "Title": "Identifying factors associated with fast visual field progression in patients with ocular hypertension based on unsupervised machine learning", "Authors": ["Xiaoqin Huang", "Asma Poursoroush", "Jian Sun", "Michael V. Boland", "Chris Johnson", "and Siamak Yousefi"], "Categories": "cs.LG eess.IV q-bio.QM"}, "abstract": "Purpose: To identify ocular hypertension (OHT) subtypes with different trends of visual field (VF) progression based on unsupervised machine learning and to discover factors associated with fast VF progression. Participants: A total of 3133 eyes of 1568 ocular hypertension treatment study (OHTS) participants with at least five follow-up VF tests were included in the study. Methods: We used a latent class mixed model (LCMM) to identify OHT subtypes using standard automated perimetry (SAP) mean deviation (MD) trajectories. We characterized the subtypes based on demographic, clinical, ocular, and VF factors at the baseline. We then identified factors driving fast VF progression using generalized estimating equation (GEE) and justified findings qualitatively and quantitatively. Results: The LCMM model discovered four clusters (subtypes) of eyes with different trajectories of MD worsening. The number of eyes in clusters were 794 (25%), 1675 (54%), 531 (17%) and 133 (4%). We labelled the clusters as Improvers, Stables, Slow progressors, and Fast progressors based on their mean of MD decline, which were 0.08, -0.06, -0.21, and -0.45 dB/year, respectively. Eyes with fast VF progression had higher baseline age, intraocular pressure (IOP), pattern standard deviation (PSD) and refractive error (RE), but lower central corneal thickness (CCT). Fast progression was associated with calcium channel blockers, being male, heart disease history, diabetes history, African American race, stroke history, and migraine headaches.", "url": "https://arxiv.org/abs/2309.15867"}, {"metadata": {"arXiv": "2309.15871", "Date": "Tue, 26 Sep 2023 22:42:25 ", "Title": "Telescope: An Automated Hybrid Forecasting Approach on a Level-Playing Field", "Authors": ["Andr\\'e Bauer and Mark Leznik and Michael Stenger and Robert Leppich and Nikolas Herbst", "Samuel Kounev and Ian Foster"], "Categories": "cs.LG"}, "abstract": "In many areas of decision-making, forecasting is an essential pillar. Consequently, many different forecasting methods have been proposed. From our experience, recently presented forecasting methods are computationally intensive, poorly automated, tailored to a particular data set, or they lack a predictable time-to-result. To this end, we introduce Telescope, a novel machine learning-based forecasting approach that automatically retrieves relevant information from a given time series and splits it into parts, handling each of them separately. In contrast to deep learning methods, our approach doesn't require parameterization or the need to train and fit a multitude of parameters. It operates with just one time series and provides forecasts within seconds without any additional setup. Our experiments show that Telescope outperforms recent methods by providing accurate and reliable forecasts while making no assumptions about the analyzed time series.", "url": "https://arxiv.org/abs/2309.15871"}, {"metadata": {"arXiv": "2309.15886", "Date": "Wed, 27 Sep 2023 14:28:48 ", "Title": "Projection based fuzzy least squares twin support vector machine for class imbalance problems", "Authors": ["M. Tanveer", "Ritik Mishra", "Bharat Richhariya"], "Categories": "cs.LG"}, "abstract": "Class imbalance is a major problem in many real world classification tasks. Due to the imbalance in the number of samples, the support vector machine (SVM) classifier gets biased toward the majority class. Furthermore, these samples are often observed with a certain degree of noise. Therefore, to remove these problems we propose a novel fuzzy based approach to deal with class imbalanced as well noisy datasets. We propose two approaches to address these problems. The first approach is based on the intuitionistic fuzzy membership, termed as robust energy-based intuitionistic fuzzy least squares twin support vector machine (IF-RELSTSVM). Furthermore, we introduce the concept of hyperplane-based fuzzy membership in our second approach, where the final classifier is termed as robust energy-based fuzzy least square twin support vector machine (F-RELSTSVM). By using this technique, the membership values are based on a projection based approach, where the data points are projected on the hyperplanes. The performance of the proposed algorithms is evaluated on several benchmark and synthetic datasets. The experimental results show that the proposed IF-RELSTSVM and F-RELSTSVM models outperform the baseline algorithms. Statistical tests are performed to check the significance of the proposed algorithms. The results show the applicability of the proposed algorithms on noisy as well as imbalanced datasets.", "url": "https://arxiv.org/abs/2309.15886"}, {"metadata": {"arXiv": "2309.15963", "Date": "Wed, 30 Aug 2023 17:13:30 ", "Title": "An Uncertainty-Aware Pseudo-Label Selection Framework using Regularized Conformal Prediction", "Authors": ["Matin Moezzi"], "Categories": "cs.LG"}, "abstract": "Consistency regularization-based methods are prevalent in semi-supervised learning (SSL) algorithms due to their exceptional performance. However, they mainly depend on domain-specific data augmentations, which are not usable in domains where data augmentations are less practicable. On the other hand, Pseudo-labeling (PL) is a general and domain-agnostic SSL approach that, unlike consistency regularization-based methods, does not rely on the domain. PL underperforms due to the erroneous high-confidence predictions from poorly calibrated models. This paper proposes an uncertainty-aware pseudo-label selection framework that employs uncertainty sets yielded by the conformal regularization algorithm to fix the poor calibration neural networks, reducing noisy training data. The codes of this work are available at: https://github.com/matinmoezzi/ups conformal classification", "url": "https://arxiv.org/abs/2309.15963"}, {"metadata": {"arXiv": "2309.15965", "Date": "Wed, 27 Sep 2023 19:24:57 ", "Title": "TraCE: Trajectory Counterfactual Explanation Scores", "Authors": ["Jeffrey N. Clark", "Edward A. Small", "Nawid Keshtmand", "Michelle W.L. Wan", "Elena Fillola Mayoral", "Enrico Werner", "Christopher P. Bourdeaux", "Raul Santos-Rodriguez"], "Categories": "cs.LG cs.CY math.MG", "Comments": ["7 pages", "4 figures", "appendix"]}, "abstract": "Counterfactual explanations, and their associated algorithmic recourse, are typically leveraged to understand, explain, and potentially alter a prediction coming from a black-box classifier. In this paper, we propose to extend the use of counterfactuals to evaluate progress in sequential decision making tasks. To this end, we introduce a model-agnostic modular framework, TraCE (Trajectory Counterfactual Explanation) scores, which is able to distill and condense progress in highly complex scenarios into a single value. We demonstrate TraCE's utility across domains by showcasing its main properties in two case studies spanning healthcare and climate change.", "url": "https://arxiv.org/abs/2309.15965"}, {"metadata": {"arXiv": "2309.15985", "Date": "Wed, 27 Sep 2023 20:07:26 ", "Title": "Open Source Infrastructure for Differentiable Density Functional Theory", "Authors": ["Advika Vidhyadhiraja", "Arun Pa Thiagarajan", "Shang Zhu", "Venkat Viswanathan", "Bharath Ramsundar"], "Categories": "cs.LG"}, "abstract": "Learning exchange correlation functionals, used in quantum chemistry calculations, from data has become increasingly important in recent years, but training such a functional requires sophisticated software infrastructure. For this reason, we build open source infrastructure to train neural exchange correlation functionals. We aim to standardize the processing pipeline by adapting state-of-the-art techniques from work done by multiple groups. We have open sourced the model in the DeepChem library to provide a platform for additional research on differentiable quantum chemistry methods.", "url": "https://arxiv.org/abs/2309.15985"}, {"metadata": {"arXiv": "2309.15990", "Date": "Wed, 27 Sep 2023 20:12:19 ", "Title": "Machine Learning Based Analytics for the Significance of Gait Analysis in Monitoring and Managing Lower Extremity Injuries", "Authors": ["Mostafa Rezapour", "Rachel B. Seymour", "Stephen H. Sims", "Madhav A. Karunakar", "Nahir Habet", "Metin Nafi Gurcan"], "Categories": "cs.LG", "Comments": ["13 pages", "6 figures"]}, "abstract": "This study explored the potential of gait analysis as a tool for assessing post-injury complications, e.g., infection, malunion, or hardware irritation, in patients with lower extremity fractures. The research focused on the proficiency of supervised machine learning models predicting complications using consecutive gait datasets. We identified patients with lower extremity fractures at an academic center. Patients underwent gait analysis with a chest-mounted IMU device. Using software, raw gait data was preprocessed, emphasizing 12 essential gait variables. Machine learning models including XGBoost, Logistic Regression, SVM, LightGBM, and Random Forest were trained, tested, and evaluated. Attention was given to class imbalance, addressed using SMOTE. We introduced a methodology to compute the Rate of Change (ROC) for gait variables, independent of the time difference between gait analyses. XGBoost was the optimal model both before and after applying SMOTE. Prior to SMOTE, the model achieved an average test AUC of 0.90 (95% CI: [0.79, 1.00]) and test accuracy of 86% (95% CI: [75%, 97%]). Feature importance analysis attributed importance to the duration between injury and gait analysis. Data patterns showed early physiological compensations, followed by stabilization phases, emphasizing prompt gait analysis. This study underscores the potential of machine learning, particularly XGBoost, in gait analysis for orthopedic care. Predicting post-injury complications, early gait assessment becomes vital, revealing intervention points. The findings support a shift in orthopedics towards a data-informed approach, enhancing patient outcomes.", "url": "https://arxiv.org/abs/2309.15990"}, {"metadata": {"arXiv": "2309.15995", "Date": "Wed, 27 Sep 2023 20:18:02 ", "Title": "Digital Twin-based Anomaly Detection with Curriculum Learning in Cyber-physical Systems", "Authors": ["Qinghua Xu", "Shaukat Ali and Tao Yue"], "Categories": "cs.LG cs.CR cs.SE", "Journal-ref": "ACM Trans. Softw. Eng. Methodol. 32, 5, Article 113 (July 2023), 32 pages", "DOI": "10.1145/3582571"}, "abstract": "Anomaly detection is critical to ensure the security of cyber-physical systems (CPS). However, due to the increasing complexity of attacks and CPS themselves, anomaly detection in CPS is becoming more and more challenging. In our previous work, we proposed a digital twin-based anomaly detection method, called ATTAIN, which takes advantage of both historical and real-time data of CPS. However, such data vary significantly in terms of difficulty. Therefore, similar to human learning processes, deep learning models (e.g., ATTAIN) can benefit from an easy-to-difficult curriculum. To this end, in this paper, we present a novel approach, named digitaL twin-based Anomaly deTecTion wIth Curriculum lEarning (LATTICE), which extends ATTAIN by introducing curriculum learning to optimize its learning paradigm. LATTICE attributes each sample with a difficulty score, before being fed into a training scheduler. The training scheduler samples batches of training data based on these difficulty scores such that learning from easy to difficult data can be performed. To evaluate LATTICE, we use five publicly available datasets collected from five real-world CPS testbeds. We compare LATTICE with ATTAIN and two other state-of-the-art anomaly detectors. Evaluation results show that LATTICE outperforms the three baselines and ATTAIN by 0.906%-2.367% in terms of the F1 score. LATTICE also, on average, reduces the training time of ATTAIN by 4.2% on the five datasets and is on par with the baselines in terms of detection delay time.", "url": "https://arxiv.org/abs/2309.15995"}, {"metadata": {"arXiv": "2309.16014", "Date": "Wed, 27 Sep 2023 20:42:02 ", "Title": "Graph-level Representation Learning with Joint-Embedding Predictive Architectures", "Authors": ["Geri Skenderi", "Hang Li", "Jiliang Tang", "Marco Cristani"], "Categories": "cs.LG", "Comments": ["Preprint. Under Review"]}, "abstract": "Joint-Embedding Predictive Architectures (JEPAs) have recently emerged as a novel and powerful technique for self-supervised representation learning. They aim to learn an energy-based model by predicting the latent representation of a target signal $y$ from a context signal $x$. JEPAs bypass the need for data augmentation and negative samples, which are typically required by contrastive learning, while avoiding the overfitting issues associated with generative-based pretraining. In this paper, we show that graph-level representations can be effectively modeled using this paradigm and propose Graph-JEPA, the first JEPA for the graph domain. In particular, we employ masked modeling to learn embeddings for different subgraphs of the input graph. To endow the representations with the implicit hierarchy that is often present in graph-level concepts, we devise an alternative training objective that consists of predicting the coordinates of the encoded subgraphs on the unit hyperbola in the 2D plane. Extensive validation shows that Graph-JEPA can learn representations that are expressive and competitive in both graph classification and regression problems.", "url": "https://arxiv.org/abs/2309.16014"}, {"metadata": {"arXiv": "2309.16022", "Date": "Wed, 27 Sep 2023 20:58:33 ", "Title": "GNNHLS: Evaluating Graph Neural Network Inference via High-Level Synthesis", "Authors": ["Chenfeng Zhao", "Zehao Dong", "Yixin Chen", "Xuan Zhang", "Roger D. Chamberlain"], "Categories": "cs.LG cs.AR cs.PF"}, "abstract": "With the ever-growing popularity of Graph Neural Networks (GNNs), efficient GNN inference is gaining tremendous attention. Field-Programming Gate Arrays (FPGAs) are a promising execution platform due to their fine-grained parallelism, low-power consumption, reconfigurability, and concurrent execution. Even better, High-Level Synthesis (HLS) tools bridge the gap between the non-trivial FPGA development efforts and rapid emergence of new GNN models. In this paper, we propose GNNHLS, an open-source framework to comprehensively evaluate GNN inference acceleration on FPGAs via HLS, containing a software stack for data generation and baseline deployment, and FPGA implementations of 6 well-tuned GNN HLS kernels. We evaluate GNNHLS on 4 graph datasets with distinct topologies and scales. The results show that GNNHLS achieves up to 50.8x speedup and 423x energy reduction relative to the CPU baselines. Compared with the GPU baselines, GNNHLS achieves up to 5.16x speedup and 74.5x energy reduction.", "url": "https://arxiv.org/abs/2309.16022"}, {"metadata": {"arXiv": "2309.16032", "Date": "Wed, 27 Sep 2023 21:25:26 ", "Title": "Learning Dissipative Neural Dynamical Systems", "Authors": ["Yuezhu Xu and S. Sivaranjani"], "Categories": "cs.LG cs.SY eess.SY math.OC", "Comments": ["6 pages"]}, "abstract": "Consider an unknown nonlinear dynamical system that is known to be dissipative. The objective of this paper is to learn a neural dynamical model that approximates this system, while preserving the dissipativity property in the model. In general, imposing dissipativity constraints during neural network training is a hard problem for which no known techniques exist. In this work, we address the problem of learning a dissipative neural dynamical system model in two stages. First, we learn an unconstrained neural dynamical model that closely approximates the system dynamics. Next, we derive sufficient conditions to perturb the weights of the neural dynamical model to ensure dissipativity, followed by perturbation of the biases to retain the fit of the model to the trajectories of the nonlinear system. We show that these two perturbation problems can be solved independently to obtain a neural dynamical model that is guaranteed to be dissipative while closely approximating the nonlinear system.", "url": "https://arxiv.org/abs/2309.16032"}, {"metadata": {"arXiv": "2309.16044", "Date": "Wed, 27 Sep 2023 21:54:52 ", "Title": "Improving Adaptive Online Learning Using Refined Discretization", "Authors": ["Zhiyu Zhang", "Heng Yang", "Ashok Cutkosky", "Ioannis Ch. Paschalidis"], "Categories": "cs.LG stat.ML"}, "abstract": "We study unconstrained Online Linear Optimization with Lipschitz losses. The goal is to simultaneously achieve ($i$) second order gradient adaptivity; and ($ii$) comparator norm adaptivity also known as \"parameter freeness\" in the literature. Existing regret bounds (Cutkosky and Orabona, 2018; Mhammedi and Koolen, 2020; Jacobsen and Cutkosky, 2022) have the suboptimal $O(\\sqrt{V_T\\log V_T})$ dependence on the gradient variance $V_T$, while the present work improves it to the optimal rate $O(\\sqrt{V_T})$ using a novel continuous-time-inspired algorithm, without any impractical doubling trick. This result can be extended to the setting with unknown Lipschitz constant, eliminating the range ratio problem from prior works (Mhammedi and Koolen, 2020). Concretely, we first show that the aimed simultaneous adaptivity can be achieved fairly easily in a continuous time analogue of the problem, where the environment is modeled by an arbitrary continuous semimartingale. Then, our key innovation is a new discretization argument that preserves such adaptivity in the discrete time adversarial setting. This refines a non-gradient-adaptive discretization argument from (Harvey et al., 2023), both algorithmically and analytically, which could be of independent interest.", "url": "https://arxiv.org/abs/2309.16044"}, {"metadata": {"arXiv": "2309.16055", "Date": "Wed, 27 Sep 2023 22:30:11 ", "Title": "Identifying Risk Factors for Post-COVID-19 Mental Health Disorders: A Machine Learning Perspective", "Authors": ["Maitham G. Yousif", "Fadhil G. Al-Amran", "Hector J. Castro"], "Categories": "cs.LG cs.CY q-bio.BM"}, "abstract": "In this study, we leveraged machine learning techniques to identify risk factors associated with post-COVID-19 mental health disorders. Our analysis, based on data collected from 669 patients across various provinces in Iraq, yielded valuable insights. We found that age, gender, and geographical region of residence were significant demographic factors influencing the likelihood of developing mental health disorders in post-COVID-19 patients. Additionally, comorbidities and the severity of COVID-19 illness were important clinical predictors. Psychosocial factors, such as social support, coping strategies, and perceived stress levels, also played a substantial role. Our findings emphasize the complex interplay of multiple factors in the development of mental health disorders following COVID-19 recovery. Healthcare providers and policymakers should consider these risk factors when designing targeted interventions and support systems for individuals at risk. Machine learning-based approaches can provide a valuable tool for predicting and preventing adverse mental health outcomes in post-COVID-19 patients. Further research and prospective studies are needed to validate these findings and enhance our understanding of the long-term psychological impact of the COVID-19 pandemic. This study contributes to the growing body of knowledge regarding the mental health consequences of the COVID-19 pandemic and underscores the importance of a multidisciplinary approach to address the diverse needs of individuals on the path to recovery. Keywords: COVID-19, mental health, risk factors, machine learning, Iraq", "url": "https://arxiv.org/abs/2309.16055"}, {"metadata": {"arXiv": "2309.16058", "Date": "Wed, 27 Sep 2023 22:50:51 ", "Title": "AnyMAL: An Efficient and Scalable Any-Modality Augmented Language Model", "Authors": ["Seungwhan Moon", "Andrea Madotto", "Zhaojiang Lin", "Tushar Nagarajan", "Matt Smith", "Shashank Jain", "Chun-Fu Yeh", "Prakash Murugesan", "Peyman Heidari", "Yue Liu", "Kavya Srinet", "Babak Damavandi", "Anuj Kumar"], "Categories": "cs.LG cs.CL cs.CV"}, "abstract": "We present Any-Modality Augmented Language Model (AnyMAL), a unified model that reasons over diverse input modality signals (i.e. text, image, video, audio, IMU motion sensor), and generates textual responses. AnyMAL inherits the powerful text-based reasoning abilities of the state-of-the-art LLMs including LLaMA-2 (70B), and converts modality-specific signals to the joint textual space through a pre-trained aligner module. To further strengthen the multimodal LLM's capabilities, we fine-tune the model with a multimodal instruction set manually collected to cover diverse topics and tasks beyond simple QAs. We conduct comprehensive empirical analysis comprising both human and automatic evaluations, and demonstrate state-of-the-art performance on various multimodal tasks.", "url": "https://arxiv.org/abs/2309.16058"}, {"metadata": {"arXiv": "2309.16059", "Date": "Wed, 27 Sep 2023 22:52:08 ", "Title": "Predicting Cardiovascular Complications in Post-COVID-19 Patients Using Data-Driven Machine Learning Models", "Authors": ["Maitham G. Yousif", "Hector J. Castro"], "Categories": "cs.LG q-bio.BM q-bio.QM stat.AP"}, "abstract": "The COVID-19 pandemic has globally posed numerous health challenges, notably the emergence of post-COVID-19 cardiovascular complications. This study addresses this by utilizing data-driven machine learning models to predict such complications in 352 post-COVID-19 patients from Iraq. Clinical data, including demographics, comorbidities, lab results, and imaging, were collected and used to construct predictive models. These models, leveraging various machine learning algorithms, demonstrated commendable performance in identifying patients at risk. Early detection through these models promises timely interventions and improved outcomes. In conclusion, this research underscores the potential of data-driven machine learning for predicting post-COVID-19 cardiovascular complications, emphasizing the need for continued validation and research in diverse clinical settings.", "url": "https://arxiv.org/abs/2309.16059"}, {"metadata": {"arXiv": "2309.16066", "Date": "Wed, 27 Sep 2023 23:17:58 ", "Title": "Label Augmentation Method for Medical Landmark Detection in Hip Radiograph Images", "Authors": ["Yehyun Suh", "Peter Chan", "J.Ryan Martin", "Daniel Moyer"], "Categories": "cs.LG"}, "abstract": "This work reports the empirical performance of an automated medical landmark detection method for predict clinical markers in hip radiograph images. Notably, the detection method was trained using a label-only augmentation scheme; our results indicate that this form of augmentation outperforms traditional data augmentation and produces highly sample efficient estimators. We train a generic U-Net-based architecture under a curriculum consisting of two phases: initially relaxing the landmarking task by enlarging the label points to regions, then gradually eroding these label regions back to the base task. We measure the benefits of this approach on six datasets of radiographs with gold-standard expert annotations.", "url": "https://arxiv.org/abs/2309.16066"}, {"metadata": {"arXiv": "2309.16109", "Date": "Thu, 28 Sep 2023 02:23:32 ", "Title": "Feature Normalization Prevents Collapse of Non-contrastive Learning Dynamics", "Authors": ["Han Bao"], "Categories": "cs.LG stat.ML"}, "abstract": "Contrastive learning is a self-supervised representation learning framework, where two positive views generated through data augmentation are made similar by an attraction force in a data representation space, while a repulsive force makes them far from negative examples. Non-contrastive learning, represented by BYOL and SimSiam, further gets rid of negative examples and improves computational efficiency. While learned representations may collapse into a single point due to the lack of the repulsive force at first sight, Tian et al. (2021) revealed through the learning dynamics analysis that the representations can avoid collapse if data augmentation is sufficiently stronger than regularization. However, their analysis does not take into account commonly-used feature normalization, a normalizer before measuring the similarity of representations, and hence excessively strong regularization may collapse the dynamics, which is an unnatural behavior under the presence of feature normalization. Therefore, we extend the previous theory based on the L2 loss by considering the cosine loss, which involves feature normalization. We show that the cosine loss induces sixth-order dynamics (while the L2 loss induces a third-order one), in which a stable equilibrium dynamically emerges even if there are only collapsed solutions with given initial parameters. Thus, we offer a new understanding that feature normalization plays an important role in robustly preventing the dynamics collapse.", "url": "https://arxiv.org/abs/2309.16109"}, {"metadata": {"arXiv": "2309.16115", "Date": "Thu, 28 Sep 2023 02:46:53 ", "Title": "Compositional Sculpting of Iterative Generative Processes", "Authors": ["Timur Garipov", "Sebastiaan De Peuter", "Ge Yang", "Vikas Garg", "Samuel Kaski", "Tommi Jaakkola"], "Categories": "cs.LG", "Comments": ["Extended version of NeurIPS 2023 paper"]}, "abstract": "High training costs of generative models and the need to fine-tune them for specific tasks have created a strong interest in model reuse and composition. A key challenge in composing iterative generative processes, such as GFlowNets and diffusion models, is that to realize the desired target distribution, all steps of the generative process need to be coordinated, and satisfy delicate balance conditions. In this work, we propose Compositional Sculpting: a general approach for defining compositions of iterative generative processes. We then introduce a method for sampling from these compositions built on classifier guidance. We showcase ways to accomplish compositional sculpting in both GFlowNets and diffusion models. We highlight two binary operations $\\unicode{x2014}$ the harmonic mean ($p_1 \\otimes p_2$) and the contrast ($p_1 \\unicode{x25D1}\\,p_2$) between pairs, and the generalization of these operations to multiple component distributions. We offer empirical results on image and molecular generation tasks.", "url": "https://arxiv.org/abs/2309.16115"}, {"metadata": {"arXiv": "2309.16131", "Date": "Thu, 28 Sep 2023 03:22:49 ", "Title": "A Spectral Approach for Learning Spatiotemporal Neural Differential Equations", "Authors": ["Mingtao Xia", "Xiangting Li", "Qijing Shen", "Tom Chou"], "Categories": "cs.LG cs.NE math.SP", "Comments": ["21 pages", "5 figures"]}, "abstract": "Rapidly developing machine learning methods has stimulated research interest in computationally reconstructing differential equations (DEs) from observational data which may provide additional insight into underlying causative mechanisms. In this paper, we propose a novel neural-ODE based method that uses spectral expansions in space to learn spatiotemporal DEs. The major advantage of our spectral neural DE learning approach is that it does not rely on spatial discretization, thus allowing the target spatiotemporal equations to contain long range, nonlocal spatial interactions that act on unbounded spatial domains. Our spectral approach is shown to be as accurate as some of the latest machine learning approaches for learning PDEs operating on bounded domains. By developing a spectral framework for learning both PDEs and integro-differential equations, we extend machine learning methods to apply to unbounded DEs and a larger class of problems.", "url": "https://arxiv.org/abs/2309.16131"}, {"metadata": {"arXiv": "2309.16173", "Date": "Thu, 28 Sep 2023 05:09:14 ", "Title": "Distill to Delete: Unlearning in Graph Networks with Knowledge Distillation", "Authors": ["Yash Sinha", "Murari Mandal", "Mohan Kankanhalli"], "Categories": "cs.LG"}, "abstract": "Graph unlearning has emerged as a pivotal method to delete information from a pre-trained graph neural network (GNN). One may delete nodes, a class of nodes, edges, or a class of edges. An unlearning method enables the GNN model to comply with data protection regulations (i.e., the right to be forgotten), adapt to evolving data distributions, and reduce the GPU-hours carbon footprint by avoiding repetitive retraining. Existing partitioning and aggregation-based methods have limitations due to their poor handling of local graph dependencies and additional overhead costs. More recently, GNNDelete offered a model-agnostic approach that alleviates some of these issues. Our work takes a novel approach to address these challenges in graph unlearning through knowledge distillation, as it distills to delete in GNN (D2DGN). It is a model-agnostic distillation framework where the complete graph knowledge is divided and marked for retention and deletion. It performs distillation with response-based soft targets and feature-based node embedding while minimizing KL divergence. The unlearned model effectively removes the influence of deleted graph elements while preserving knowledge about the retained graph elements. D2DGN surpasses the performance of existing methods when evaluated on various real-world graph datasets by up to $43.1\\%$ (AUC) in edge and node unlearning tasks. Other notable advantages include better efficiency, better performance in removing target elements, preservation of performance for the retained elements, and zero overhead costs. Notably, our D2DGN surpasses the state-of-the-art GNNDelete in AUC by $2.4\\%$, improves membership inference ratio by $+1.3$, requires $10.2\\times10^6$ fewer FLOPs per forward pass and up to $\\mathbf{3.2}\\times$ faster.", "url": "https://arxiv.org/abs/2309.16173"}, {"metadata": {"arXiv": "2309.16200", "Date": "Thu, 28 Sep 2023 06:49:25 ", "Title": "Max-Sliced Mutual Information", "Authors": ["Dor Tsur", "Ziv Goldfeld and Kristjan Greenewald"], "Categories": "cs.LG cs.IT math.IT", "Comments": ["Accepted at NeurIPS 2023"]}, "abstract": "Quantifying the dependence between high-dimensional random variables is central to statistical learning and inference. Two classical methods are canonical correlation analysis (CCA), which identifies maximally correlated projected versions of the original variables, and Shannon's mutual information, which is a universal dependence measure that also captures high-order dependencies. However, CCA only accounts for linear dependence, which may be insufficient for certain applications, while mutual information is often infeasible to compute/estimate in high dimensions. This work proposes a middle ground in the form of a scalable information-theoretic generalization of CCA, termed max-sliced mutual information (mSMI). mSMI equals the maximal mutual information between low-dimensional projections of the high-dimensional variables, which reduces back to CCA in the Gaussian case. It enjoys the best of both worlds: capturing intricate dependencies in the data while being amenable to fast computation and scalable estimation from samples. We show that mSMI retains favorable structural properties of Shannon's mutual information, like variational forms and identification of independence. We then study statistical estimation of mSMI, propose an efficiently computable neural estimator, and couple it with formal non-asymptotic error bounds. We present experiments that demonstrate the utility of mSMI for several tasks, encompassing independence testing, multi-view representation learning, algorithmic fairness, and generative modeling. We observe that mSMI consistently outperforms competing methods with little-to-no computational overhead.", "url": "https://arxiv.org/abs/2309.16200"}, {"metadata": {"arXiv": "2309.16318", "Date": "Thu, 28 Sep 2023 10:15:30 ", "Title": "DeepPCR: Parallelizing Sequential Operations in Neural Networks", "Authors": ["Federico Danieli", "Miguel Sarabia", "Xavier Suau", "Pau Rodr\\'iguez", "Luca Zappella"], "Categories": "cs.LG"}, "abstract": "Parallelization techniques have become ubiquitous for accelerating inference and training of deep neural networks. Despite this, several operations are still performed in a sequential manner. For instance, the forward and backward passes are executed layer-by-layer, and the output of diffusion models is produced by applying a sequence of denoising steps. This sequential approach results in a computational cost proportional to the number of steps involved, presenting a potential bottleneck as the number of steps increases. In this work, we introduce DeepPCR, a novel algorithm which parallelizes typically sequential operations used in inference and training of neural networks. DeepPCR is based on interpreting a sequence of $L$ steps as the solution of a specific system of equations, which we recover using the Parallel Cyclic Reduction algorithm. This reduces the complexity of computing the sequential operations from $\\mathcal{O}(L)$ to $\\mathcal{O}(\\log_2L)$, thus yielding a speedup for large $L$. To verify the theoretical lower complexity of the algorithm, and to identify regimes for speedup, we test the effectiveness of DeepPCR in parallelizing the forward and backward pass in multi-layer perceptrons, and reach speedups of up to $30\\times$ for forward and $200\\times$ for backward pass. We additionally showcase the flexibility of DeepPCR by parallelizing training of ResNets with as many as 1024 layers, and generation in diffusion models, enabling up to $7\\times$ faster training and $11\\times$ faster generation, respectively, when compared to the sequential approach.", "url": "https://arxiv.org/abs/2309.16318"}, {"metadata": {"arXiv": "2309.16338", "Date": "Thu, 28 Sep 2023 10:51:12 ", "Title": "EFFL: Egalitarian Fairness in Federated Learning for Mitigating Matthew Effect", "Authors": ["Jiashi Gao", "Changwu Huang", "Ming Tang", "Shin Hwei Tan", "Xin Yao", "Xuetao Wei"], "Categories": "cs.LG"}, "abstract": "Recent advances in federated learning (FL) enable collaborative training of machine learning (ML) models from large-scale and widely dispersed clients while protecting their privacy. However, when different clients' datasets are heterogeneous, traditional FL mechanisms produce a global model that does not adequately represent the poorer clients with limited data resources, resulting in lower accuracy and higher bias on their local data. According to the Matthew effect, which describes how the advantaged gain more advantage and the disadvantaged lose more over time, deploying such a global model in client applications may worsen the resource disparity among the clients and harm the principles of social welfare and fairness. To mitigate the Matthew effect, we propose Egalitarian Fairness Federated Learning (EFFL), where egalitarian fairness refers to the global model learned from FL has: (1) equal accuracy among clients; (2) equal decision bias among clients. Besides achieving egalitarian fairness among the clients, EFFL also aims for performance optimality, minimizing the empirical risk loss and the bias for each client; both are essential for any ML model training, whether centralized or decentralized. We formulate EFFL as a constrained multi-constrained multi-objectives optimization (MCMOO) problem, with the decision bias and egalitarian fairness as constraints and the minimization of the empirical risk losses on all clients as multiple objectives to be optimized. We propose a gradient-based three-stage algorithm to obtain the Pareto optimal solutions within the constraint space. Extensive experiments demonstrate that EFFL outperforms other state-of-the-art FL algorithms in achieving a high-performance global model with enhanced egalitarian fairness among all clients.", "url": "https://arxiv.org/abs/2309.16338"}, {"metadata": {"arXiv": "2309.16342", "Date": "Thu, 28 Sep 2023 11:03:23 ", "Title": "LagrangeBench: A Lagrangian Fluid Mechanics Benchmarking Suite", "Authors": ["Artur P. Toshev", "Gianluca Galletti", "Fabian Fritz", "Stefan Adami", "Nikolaus A. Adams"], "Categories": "cs.LG physics.flu-dyn", "Comments": ["Accepted at 37th Conference on Neural Information Processing Systems (NeurIPS 2023) Track on Datasets and Benchmarks"]}, "abstract": "Machine learning has been successfully applied to grid-based PDE modeling in various scientific applications. However, learned PDE solvers based on Lagrangian particle discretizations, which are the preferred approach to problems with free surfaces or complex physics, remain largely unexplored. We present LagrangeBench, the first benchmarking suite for Lagrangian particle problems, focusing on temporal coarse-graining. In particular, our contribution is: (a) seven new fluid mechanics datasets (four in 2D and three in 3D) generated with the Smoothed Particle Hydrodynamics (SPH) method including the Taylor-Green vortex, lid-driven cavity, reverse Poiseuille flow, and dam break, each of which includes different physics like solid wall interactions or free surface, (b) efficient JAX-based API with various recent training strategies and neighbors search routine, and (c) JAX implementation of established Graph Neural Networks (GNNs) like GNS and SEGNN with baseline results. Finally, to measure the performance of learned surrogates we go beyond established position errors and introduce physical metrics like kinetic energy MSE and Sinkhorn distance for the particle distribution. Our codebase is available under the URL: https://github.com/tumaer/lagrangebench", "url": "https://arxiv.org/abs/2309.16342"}, {"metadata": {"arXiv": "2309.16353", "Date": "Thu, 28 Sep 2023 11:25:02 ", "Title": "ShapeDBA: Generating Effective Time Series Prototypes using ShapeDTW Barycenter Averaging", "Authors": ["Ali Ismail-Fawaz", "Hassan Ismail Fawaz", "Fran\\c{c}ois Petitjean", "Maxime Devanne", "Jonathan Weber", "Stefano Berretti", "Geoffrey I. Webb", "Germain Forestier"], "Categories": "cs.LG", "Comments": ["Published in AALTD workshop at ECML/PKDD 2023"]}, "abstract": "Time series data can be found in almost every domain, ranging from the medical field to manufacturing and wireless communication. Generating realistic and useful exemplars and prototypes is a fundamental data analysis task. In this paper, we investigate a novel approach to generating realistic and useful exemplars and prototypes for time series data. Our approach uses a new form of time series average, the ShapeDTW Barycentric Average. We therefore turn our attention to accurately generating time series prototypes with a novel approach. The existing time series prototyping approaches rely on the Dynamic Time Warping (DTW) similarity measure such as DTW Barycentering Average (DBA) and SoftDBA. These last approaches suffer from a common problem of generating out-of-distribution artifacts in their prototypes. This is mostly caused by the DTW variant used and its incapability of detecting neighborhood similarities, instead it detects absolute similarities. Our proposed method, ShapeDBA, uses the ShapeDTW variant of DTW, that overcomes this issue. We chose time series clustering, a popular form of time series analysis to evaluate the outcome of ShapeDBA compared to the other prototyping approaches. Coupled with the k-means clustering algorithm, and evaluated on a total of 123 datasets from the UCR archive, our proposed averaging approach is able to achieve new state-of-the-art results in terms of Adjusted Rand Index.", "url": "https://arxiv.org/abs/2309.16353"}, {"metadata": {"arXiv": "2309.16354", "Date": "Thu, 28 Sep 2023 11:26:52 ", "Title": "Transformer-VQ: Linear-Time Transformers via Vector Quantization", "Authors": ["Lucas D. Lingle"], "Categories": "cs.LG cs.CL cs.CV", "Comments": ["Under review as a conference paper at ICLR 2024. Please do not distribute"]}, "abstract": "We introduce Transformer-VQ, a decoder-only transformer computing softmax-based dense self-attention in linear time. Transformer-VQ's efficient attention is enabled by vector-quantized keys and a novel caching mechanism. In large-scale experiments, Transformer-VQ is shown highly competitive in quality, with strong results on Enwik8 (0.99 bpb), PG-19 (26.6 ppl), and ImageNet64 (3.16 bpb). Code: https://github.com/transformer-vq/transformer_vq", "url": "https://arxiv.org/abs/2309.16354"}, {"metadata": {"arXiv": "2309.16357", "Date": "Thu, 28 Sep 2023 11:43:49 ", "Title": "Leveraging Pre-trained Language Models for Time Interval Prediction in Text-Enhanced Temporal Knowledge Graphs", "Authors": ["Duygu Sezen Islakoglu", "Mel Chekol", "Yannis Velegrakis"], "Categories": "cs.LG", "Comments": ["10 pages", "3 figures"]}, "abstract": "Most knowledge graph completion (KGC) methods learn latent representations of entities and relations of a given graph by mapping them into a vector space. Although the majority of these methods focus on static knowledge graphs, a large number of publicly available KGs contain temporal information stating the time instant/period over which a certain fact has been true. Such graphs are often known as temporal knowledge graphs. Furthermore, knowledge graphs may also contain textual descriptions of entities and relations. Both temporal information and textual descriptions are not taken into account during representation learning by static KGC methods, and only structural information of the graph is leveraged. Recently, some studies have used temporal information to improve link prediction, yet they do not exploit textual descriptions and do not support inductive inference (prediction on entities that have not been seen in training). We propose a novel framework called TEMT that exploits the power of pre-trained language models (PLMs) for text-enhanced temporal knowledge graph completion. The knowledge stored in the parameters of a PLM allows TEMT to produce rich semantic representations of facts and to generalize on previously unseen entities. TEMT leverages textual and temporal information available in a KG, treats them separately, and fuses them to get plausibility scores of facts. Unlike previous approaches, TEMT effectively captures dependencies across different time points and enables predictions on unseen entities. To assess the performance of TEMT, we carried out several experiments including time interval prediction, both in transductive and inductive settings, and triple classification. The experimental results show that TEMT is competitive with the state-of-the-art.", "url": "https://arxiv.org/abs/2309.16357"}, {"metadata": {"arXiv": "2309.16374", "Date": "Thu, 28 Sep 2023 12:19:43 ", "Title": "MHG-GNN: Combination of Molecular Hypergraph Grammar with Graph Neural Network", "Authors": ["Akihiro Kishimoto", "Hiroshi Kajino", "Masataka Hirose", "Junta Fuchiwaki", "Indra Priyadarsini", "Lisa Hamada", "Hajime Shinohara", "Daiju Nakano and Seiji Takeda"], "Categories": "cs.LG", "Comments": ["8 pages", "1 figure"]}, "abstract": "Property prediction plays an important role in material discovery. As an initial step to eventually develop a foundation model for material science, we introduce a new autoencoder called the MHG-GNN, which combines graph neural network (GNN) with Molecular Hypergraph Grammar (MHG). Results on a variety of property prediction tasks with diverse materials show that MHG-GNN is promising.", "url": "https://arxiv.org/abs/2309.16374"}, {"metadata": {"arXiv": "2309.16398", "Date": "Thu, 28 Sep 2023 12:44:59 ", "Title": "Recent Advances of Differential Privacy in Centralized Deep Learning: A Systematic Survey", "Authors": ["Lea Demelius", "Roman Kern", "Andreas Tr\\\"ugler"], "Categories": "cs.LG", "Comments": ["35 pages", "2 figures"]}, "abstract": "Differential Privacy has become a widely popular method for data protection in machine learning, especially since it allows formulating strict mathematical privacy guarantees. This survey provides an overview of the state-of-the-art of differentially private centralized deep learning, thorough analyses of recent advances and open problems, as well as a discussion of potential future developments in the field. Based on a systematic literature review, the following topics are addressed: auditing and evaluation methods for private models, improvements of privacy-utility trade-offs, protection against a broad range of threats and attacks, differentially private generative models, and emerging application domains.", "url": "https://arxiv.org/abs/2309.16398"}, {"metadata": {"arXiv": "2309.16452", "Date": "Thu, 28 Sep 2023 13:59:50 ", "Title": "On the Trade-offs between Adversarial Robustness and Actionable Explanations", "Authors": ["Satyapriya Krishna", "Chirag Agarwal", "Himabindu Lakkaraju"], "Categories": "cs.LG"}, "abstract": "As machine learning models are increasingly being employed in various high-stakes settings, it becomes important to ensure that predictions of these models are not only adversarially robust, but also readily explainable to relevant stakeholders. However, it is unclear if these two notions can be simultaneously achieved or if there exist trade-offs between them. In this work, we make one of the first attempts at studying the impact of adversarially robust models on actionable explanations which provide end users with a means for recourse. We theoretically and empirically analyze the cost (ease of implementation) and validity (probability of obtaining a positive model prediction) of recourses output by state-of-the-art algorithms when the underlying models are adversarially robust vs. non-robust. More specifically, we derive theoretical bounds on the differences between the cost and the validity of the recourses generated by state-of-the-art algorithms for adversarially robust vs. non-robust linear and non-linear models. Our empirical results with multiple real-world datasets validate our theoretical results and show the impact of varying degrees of model robustness on the cost and validity of the resulting recourses. Our analyses demonstrate that adversarially robust models significantly increase the cost and reduce the validity of the resulting recourses, thus shedding light on the inherent trade-offs between adversarial robustness and actionable explanations", "url": "https://arxiv.org/abs/2309.16452"}, {"metadata": {"arXiv": "2309.16456", "Date": "Thu, 28 Sep 2023 14:06:17 ", "Title": "Resisting Backdoor Attacks in Federated Learning via Bidirectional Elections and Individual Perspective", "Authors": ["Zhen Qin", "Feiyi Chen", "Chen Zhi", "Xueqiang Yan", "Shuiguang Deng"], "Categories": "cs.LG"}, "abstract": "Existing approaches defend against backdoor attacks in federated learning (FL) mainly through a) mitigating the impact of infected models, or b) excluding infected models. The former negatively impacts model accuracy, while the latter usually relies on globally clear boundaries between benign and infected model updates. However, model updates are easy to be mixed and scattered throughout in reality due to the diverse distributions of local data. This work focuses on excluding infected models in FL. Unlike previous perspectives from a global view, we propose Snowball, a novel anti-backdoor FL framework through bidirectional elections from an individual perspective inspired by one principle deduced by us and two principles in FL and deep learning. It is characterized by a) bottom-up election, where each candidate model update votes to several peer ones such that a few model updates are elected as selectees for aggregation; and b) top-down election, where selectees progressively enlarge themselves through picking up from the candidates. We compare Snowball with state-of-the-art defenses to backdoor attacks in FL on five real-world datasets, demonstrating its superior resistance to backdoor attacks and slight impact on the accuracy of the global model.", "url": "https://arxiv.org/abs/2309.16456"}, {"metadata": {"arXiv": "2309.16457", "Date": "Thu, 28 Sep 2023 14:06:34 ", "Title": "Universal Sleep Decoder: Aligning awake and sleep neural representation across subjects", "Authors": ["Hui Zheng", "Zhongtao Chen", "Haiteng Wang", "Jianyang Zhou", "Lin Zheng", "Yunzhe Liu"], "Categories": "cs.LG eess.SP q-bio.NC"}, "abstract": "Decoding memory content from brain activity during sleep has long been a goal in neuroscience. While spontaneous reactivation of memories during sleep in rodents is known to support memory consolidation and offline learning, capturing memory replay in humans is challenging due to the absence of well-annotated sleep datasets and the substantial differences in neural patterns between wakefulness and sleep. To address these challenges, we designed a novel cognitive neuroscience experiment and collected a comprehensive, well-annotated electroencephalography (EEG) dataset from 52 subjects during both wakefulness and sleep. Leveraging this benchmark dataset, we developed the Universal Sleep Decoder (USD) to align neural representations between wakefulness and sleep across subjects. Our model achieves up to 16.6% top-1 zero-shot accuracy on unseen subjects, comparable to decoding performances using individual sleep data. Furthermore, fine-tuning USD on test subjects enhances decoding accuracy to 25.9% top-1 accuracy, a substantial improvement over the baseline chance of 6.7%. Model comparison and ablation analyses reveal that our design choices, including the use of (i) an additional contrastive objective to integrate awake and sleep neural signals and (ii) the pretrain-finetune paradigm to incorporate different subjects, significantly contribute to these performances. Collectively, our findings and methodologies represent a significant advancement in the field of sleep decoding.", "url": "https://arxiv.org/abs/2309.16457"}, {"metadata": {"arXiv": "2309.16467", "Date": "Thu, 28 Sep 2023 14:33:20 ", "Title": "Compositional Program Generation for Systematic Generalization", "Authors": ["Tim Klinger and Luke Liu and Soham Dan and Maxwell Crouse and Parikshit Ram and Alexander Gray"], "Categories": "cs.LG", "Comments": ["7 pages of text with 1 page of references"]}, "abstract": "Compositional generalization is a key ability of humans that enables us to learn new concepts from only a handful examples. Machine learning models, including the now ubiquitous transformers, struggle to generalize in this way, and typically require thousands of examples of a concept during training in order to generalize meaningfully. This difference in ability between humans and artificial neural architectures, motivates this study on a neuro-symbolic architecture called the Compositional Program Generator (CPG). CPG has three key features: modularity, type abstraction, and recursive composition, that enable it to generalize both systematically to new concepts in a few-shot manner, as well as productively by length on various sequence-to-sequence language tasks. For each input, CPG uses a grammar of the input domain and a parser to generate a type hierarchy in which each grammar rule is assigned its own unique semantic module, a probabilistic copy or substitution program. Instances with the same hierarchy are processed with the same composed program, while those with different hierarchies may be processed with different programs. CPG learns parameters for the semantic modules and is able to learn the semantics for new types incrementally. Given a context-free grammar of the input language and a dictionary mapping each word in the source language to its interpretation in the output language, CPG can achieve perfect generalization on the SCAN and COGS benchmarks, in both standard and extreme few-shot settings.", "url": "https://arxiv.org/abs/2309.16467"}, {"metadata": {"arXiv": "2309.16487", "Date": "Thu, 28 Sep 2023 14:51:20 ", "Title": "Towards Poisoning Fair Representations", "Authors": ["Tianci Liu", "Haoyu Wang", "Feijie Wu", "Hengtong Zhang", "Pan Li", "Lu Su", "Jing Gao"], "Categories": "cs.LG"}, "abstract": "Fair machine learning seeks to mitigate model prediction bias against certain demographic subgroups such as elder and female. Recently, fair representation learning (FRL) trained by deep neural networks has demonstrated superior performance, whereby representations containing no demographic information are inferred from the data and then used as the input to classification or other downstream tasks. Despite the development of FRL methods, their vulnerability under data poisoning attack, a popular protocol to benchmark model robustness under adversarial scenarios, is under-explored. Data poisoning attacks have been developed for classical fair machine learning methods which incorporate fairness constraints into shallow-model classifiers. Nonetheless, these attacks fall short in FRL due to notably different fairness goals and model architectures. This work proposes the first data poisoning framework attacking FRL. We induce the model to output unfair representations that contain as much demographic information as possible by injecting carefully crafted poisoning samples into the training data. This attack entails a prohibitive bilevel optimization, wherefore an effective approximated solution is proposed. A theoretical analysis on the needed number of poisoning samples is derived and sheds light on defending against the attack. Experiments on benchmark fairness datasets and state-of-the-art fair representation learning models demonstrate the superiority of our attack.", "url": "https://arxiv.org/abs/2309.16487"}, {"metadata": {"arXiv": "2309.16519", "Date": "Thu, 28 Sep 2023 15:25:17 ", "Title": "AtomSurf : Surface Representation for Learning on Protein Structures", "Authors": ["Vincent Mallet", "Souhaib Attaiki and Maks Ovsjanikov"], "Categories": "cs.LG q-bio.BM", "Comments": ["10 pages"]}, "abstract": "Recent advancements in Cryo-EM and protein structure prediction algorithms have made large-scale protein structures accessible, paving the way for machine learning-based functional annotations.The field of geometric deep learning focuses on creating methods working on geometric data. An essential aspect of learning from protein structures is representing these structures as a geometric object (be it a grid, graph, or surface) and applying a learning method tailored to this representation. The performance of a given approach will then depend on both the representation and its corresponding learning method. In this paper, we investigate representing proteins as $\\textit{3D mesh surfaces}$ and incorporate them into an established representation benchmark. Our first finding is that despite promising preliminary results, the surface representation alone does not seem competitive with 3D grids. Building on this, we introduce a synergistic approach, combining surface representations with graph-based methods, resulting in a general framework that incorporates both representations in learning. We show that using this combination, we are able to obtain state-of-the-art results across $\\textit{all tested tasks}$. Our code and data can be found online: https://github.com/Vincentx15/atom2D .", "url": "https://arxiv.org/abs/2309.16519"}, {"metadata": {"arXiv": "2309.16546", "Date": "Thu, 28 Sep 2023 15:57:18 ", "Title": "Correcting for heterogeneity in real-time epidemiological indicators", "Authors": ["Aaron Rumack", "Roni Rosenfeld", "F. William Townes"], "Categories": "cs.LG"}, "abstract": "Auxiliary data sources have become increasingly important in epidemiological surveillance, as they are often available at a finer spatial and temporal resolution, larger coverage, and lower latency than traditional surveillance signals. We describe the problem of spatial and temporal heterogeneity in these signals derived from these data sources, where spatial and/or temporal biases are present. We present a method to use a ``guiding'' signal to correct for these biases and produce a more reliable signal that can be used for modeling and forecasting. The method assumes that the heterogeneity can be approximated by a low-rank matrix and that the temporal heterogeneity is smooth over time. We also present a hyperparameter selection algorithm to choose the parameters representing the matrix rank and degree of temporal smoothness of the corrections. In the absence of ground truth, we use maps and plots to argue that this method does indeed reduce heterogeneity. Reducing heterogeneity from auxiliary data sources greatly increases their utility in modeling and forecasting epidemics.", "url": "https://arxiv.org/abs/2309.16546"}, {"metadata": {"arXiv": "2309.16571", "Date": "Thu, 28 Sep 2023 16:27:07 ", "Title": "Review of Machine Learning Methods for Additive Manufacturing of Functionally Graded Materials", "Authors": ["Mohammad Karimzadeh", "Aleksandar Vakanski", "Fei Xu", "Xinchang Zhang"], "Categories": "cs.LG", "Comments": ["11 pages"]}, "abstract": "Additive manufacturing has revolutionized the manufacturing of complex parts by enabling direct material joining and offers several advantages such as cost-effective manufacturing of complex parts, reducing manufacturing waste, and opening new possibilities for manufacturing automation. One group of materials for which additive manufacturing holds great potential for enhancing component performance and properties is Functionally Graded Materials (FGMs). FGMs are advanced composite materials that exhibit smoothly varying properties making them desirable for applications in aerospace, automobile, biomedical, and defense industries. Such composition differs from traditional composite materials, since the location-dependent composition changes gradually in FGMs, leading to enhanced properties. Recently, machine learning techniques have emerged as a promising means for fabrication of FGMs through optimizing processing parameters, improving product quality, and detecting manufacturing defects. This paper first provides a brief literature review of works related to FGM fabrication, followed by reviewing works on employing machine learning in additive manufacturing, Afterward, we provide an overview of published works in the literature related to the application of machine learning methods in Directed Energy Deposition and for fabrication of FGMs.", "url": "https://arxiv.org/abs/2309.16571"}, {"metadata": {"arXiv": "2309.16577", "Date": "Wed, 20 Sep 2023 10:11:07 ", "Title": "Compilation as a Defense: Enhancing DL Model Attack Robustness via Tensor Optimization", "Authors": ["Stefan Trawicki", "William Hackett", "Lewis Birch", "Neeraj Suri", "Peter Garraghan"], "Categories": "cs.LG cs.CR", "Comments": ["2 pages", "1 figure", "CAMLIS 2023 Fast Abstract"]}, "abstract": "Adversarial Machine Learning (AML) is a rapidly growing field of security research, with an often overlooked area being model attacks through side-channels. Previous works show such attacks to be serious threats, though little progress has been made on efficient remediation strategies that avoid costly model re-engineering. This work demonstrates a new defense against AML side-channel attacks using model compilation techniques, namely tensor optimization. We show relative model attack effectiveness decreases of up to 43% using tensor optimization, discuss the implications, and direction of future work.", "url": "https://arxiv.org/abs/2309.16577"}, {"metadata": {"arXiv": "2309.16630", "Date": "Thu, 28 Sep 2023 17:35:26 ", "Title": "On Learning with LAD", "Authors": ["C. A. Jothishwaran", "Biplav Srivastava", "Jitin Singla", "Sugata Gangopadhyay"], "Categories": "cs.LG"}, "abstract": "The logical analysis of data, LAD, is a technique that yields two-class classifiers based on Boolean functions having disjunctive normal form (DNF) representation. Although LAD algorithms employ optimization techniques, the resulting binary classifiers or binary rules do not lead to overfitting. We propose a theoretical justification for the absence of overfitting by estimating the Vapnik-Chervonenkis dimension (VC dimension) for LAD models where hypothesis sets consist of DNFs with a small number of cubic monomials. We illustrate and confirm our observations empirically.", "url": "https://arxiv.org/abs/2309.16630"}, {"metadata": {"arXiv": "2309.16631", "Date": "Thu, 28 Sep 2023 17:37:01 ", "Title": "Robust Offline Reinforcement Learning - Certify the Confidence Interval", "Authors": ["Jiarui Yao and Simon Shaolei Du"], "Categories": "cs.LG"}, "abstract": "Currently, reinforcement learning (RL), especially deep RL, has received more and more attention in the research area. However, the security of RL has been an obvious problem due to the attack manners becoming mature. In order to defend against such adversarial attacks, several practical approaches are developed, such as adversarial training, data filtering, etc. However, these methods are mostly based on empirical algorithms and experiments, without rigorous theoretical analysis of the robustness of the algorithms. In this paper, we develop an algorithm to certify the robustness of a given policy offline with random smoothing, which could be proven and conducted as efficiently as ones without random smoothing. Experiments on different environments confirm the correctness of our algorithm.", "url": "https://arxiv.org/abs/2309.16631"}, {"metadata": {"arXiv": "2309.16645", "Date": "Thu, 28 Sep 2023 17:51:02 ", "Title": "Reusability report: Prostate cancer stratification with diverse biologically-informed neural architectures", "Authors": ["Christian Pedersen", "Tiberiu Tesileanu", "Tinghui Wu", "Siavash Golkar", "Miles Cranmer", "Zijun Zhang", "Shirley Ho"], "Categories": "cs.LG", "Comments": ["9 pages", "3 figures. Submitted to Nature Machine Intelligence: Matters Arising"]}, "abstract": "In, Elmarakeby et al., \"Biologically informed deep neural network for prostate cancer discovery\", a feedforward neural network with biologically informed, sparse connections (P-NET) was presented to model the state of prostate cancer. We verified the reproducibility of the study conducted by Elmarakeby et al., using both their original codebase, and our own re-implementation using more up-to-date libraries. We quantified the contribution of network sparsification by Reactome biological pathways, and confirmed its importance to P-NET's superior performance. Furthermore, we explored alternative neural architectures and approaches to incorporating biological information into the networks. We experimented with three types of graph neural networks on the same training data, and investigated the clinical prediction agreement between different models. Our analyses demonstrated that deep neural networks with distinct architectures make incorrect predictions for individual patient that are persistent across different initializations of a specific neural architecture. This suggests that different neural architectures are sensitive to different aspects of the data, an important yet under-explored challenge for clinical prediction tasks.", "url": "https://arxiv.org/abs/2309.16645"}, {"metadata": {"arXiv": "2309.16584", "Date": "Thu, 28 Sep 2023 16:44:18 ", "Title": "A Design Toolbox for the Development of Collaborative Distributed Machine Learning Systems", "Authors": ["David Jin", "Niclas Kannengie{\\ss}er", "Sascha Rank", "Ali Sunyaev"], "Categories": "cs.MA cs.ET cs.LG cs.SE"}, "abstract": "To leverage training data for the sufficient training of ML models from multiple parties in a confidentiality-preserving way, various collaborative distributed machine learning (CDML) system designs have been developed, for example, to perform assisted learning, federated learning, and split learning. CDML system designs show different traits, for example, high agent autonomy, machine learning (ML) model confidentiality, and fault tolerance. Facing a wide variety of CDML system designs with different traits, it is difficult for developers to design CDML systems with traits that match use case requirements in a targeted way. However, inappropriate CDML system designs may result in CDML systems failing their envisioned purposes. We developed a CDML design toolbox that can guide the development of CDML systems. Based on the CDML design toolbox, we present CDML system archetypes with distinct key traits that can support the design of CDML systems to meet use case requirements.", "url": "https://arxiv.org/abs/2309.16584"}, {"metadata": {"arXiv": "2309.16074", "Date": "Thu, 28 Sep 2023 00:11:06 ", "Title": "Infer and Adapt: Bipedal Locomotion Reward Learning from Demonstrations via Inverse Reinforcement Learning", "Authors": ["Feiyang Wu", "Zhaoyuan Gu", "Hanran Wu", "Anqi Wu", "Ye Zhao"], "Categories": "cs.RO cs.LG"}, "abstract": "Enabling bipedal walking robots to learn how to maneuver over highly uneven, dynamically changing terrains is challenging due to the complexity of robot dynamics and interacted environments. Recent advancements in learning from demonstrations have shown promising results for robot learning in complex environments. While imitation learning of expert policies has been well-explored, the study of learning expert reward functions is largely under-explored in legged locomotion. This paper brings state-of-the-art Inverse Reinforcement Learning (IRL) techniques to solving bipedal locomotion problems over complex terrains. We propose algorithms for learning expert reward functions, and we subsequently analyze the learned functions. Through nonlinear function approximation, we uncover meaningful insights into the expert's locomotion strategies. Furthermore, we empirically demonstrate that training a bipedal locomotion policy with the inferred reward functions enhances its walking performance on unseen terrains, highlighting the adaptability offered by reward learning.", "url": "https://arxiv.org/abs/2309.16074"}, {"metadata": {"arXiv": "2309.16077", "Date": "Thu, 28 Sep 2023 00:27:07 ", "Title": "Task-Oriented Koopman-Based Control with Contrastive Encoder", "Authors": ["Xubo Lyu", "Hanyang Hu", "Seth Siriya", "Ye Pu", "Mo Chen"], "Categories": "cs.RO cs.LG cs.SY eess.SY", "Comments": ["Accepted by the 7th Annual Conference on Robot Learning (CoRL)", "2023 (oral spotlight)"]}, "abstract": "We present task-oriented Koopman-based control that utilizes end-to-end reinforcement learning and contrastive encoder to simultaneously learn the Koopman latent embedding, operator and associated linear controller within an iterative loop. By prioritizing the task cost as main objective for controller learning, we reduce the reliance of controller design on a well-identified model, which extends Koopman control beyond low-dimensional systems to high-dimensional, complex nonlinear systems, including pixel-based scenarios.", "url": "https://arxiv.org/abs/2309.16077"}, {"metadata": {"arXiv": "2309.16114", "Date": "Thu, 28 Sep 2023 02:45:14 ", "Title": "Comparing Active Learning Performance Driven by Gaussian Processes or Bayesian Neural Networks for Constrained Trajectory Exploration", "Authors": ["Sapphira Akins", "Frances Zhu"], "Categories": "cs.RO cs.LG", "Comments": ["AIAA ASCEND 2023", "15 pages"]}, "abstract": "Robots with increasing autonomy progress our space exploration capabilities, particularly for in-situ exploration and sampling to stand in for human explorers. Currently, humans drive robots to meet scientific objectives, but depending on the robot's location, the exchange of information and driving commands between the human operator and robot may cause undue delays in mission fulfillment. An autonomous robot encoded with a scientific objective and an exploration strategy incurs no communication delays and can fulfill missions more quickly. Active learning algorithms offer this capability of intelligent exploration, but the underlying model structure varies the performance of the active learning algorithm in accurately forming an understanding of the environment. In this paper, we investigate the performance differences between active learning algorithms driven by Gaussian processes or Bayesian neural networks for exploration strategies encoded on agents that are constrained in their trajectories, like planetary surface rovers. These two active learning strategies were tested in a simulation environment against science-blind strategies to predict the spatial distribution of a variable of interest along multiple datasets. The performance metrics of interest are model accuracy in root mean squared (RMS) error, training time, model convergence, total distance traveled until convergence, and total samples until convergence. Active learning strategies encoded with Gaussian processes require less computation to train, converge to an accurate model more quickly, and propose trajectories of shorter distance, except in a few complex environments in which Bayesian neural networks achieve a more accurate model in the large data regime due to their more expressive functional bases. The paper concludes with advice on when and how to implement either exploration strategy for future space missions.", "url": "https://arxiv.org/abs/2309.16114"}, {"metadata": {"arXiv": "2309.16118", "Date": "Thu, 28 Sep 2023 02:50:16 ", "Title": "D$^3$Fields: Dynamic 3D Descriptor Fields for Zero-Shot Generalizable Robotic Manipulation", "Authors": ["Yixuan Wang", "Zhuoran Li", "Mingtong Zhang", "Katherine Driggs-Campbell", "Jiajun Wu", "Li Fei-Fei", "Yunzhu Li"], "Categories": "cs.RO cs.CV cs.LG"}, "abstract": "Scene representation has been a crucial design choice in robotic manipulation systems. An ideal representation should be 3D, dynamic, and semantic to meet the demands of diverse manipulation tasks. However, previous works often lack all three properties simultaneously. In this work, we introduce D$^3$Fields - dynamic 3D descriptor fields. These fields capture the dynamics of the underlying 3D environment and encode both semantic features and instance masks. Specifically, we project arbitrary 3D points in the workspace onto multi-view 2D visual observations and interpolate features derived from foundational models. The resulting fused descriptor fields allow for flexible goal specifications using 2D images with varied contexts, styles, and instances. To evaluate the effectiveness of these descriptor fields, we apply our representation to a wide range of robotic manipulation tasks in a zero-shot manner. Through extensive evaluation in both real-world scenarios and simulations, we demonstrate that D$^3$Fields are both generalizable and effective for zero-shot robotic manipulation tasks. In quantitative comparisons with state-of-the-art dense descriptors, such as Dense Object Nets and DINO, D$^3$Fields exhibit significantly better generalization abilities and manipulation accuracy.", "url": "https://arxiv.org/abs/2309.16118"}, {"metadata": {"arXiv": "2309.16299", "Date": "Thu, 28 Sep 2023 09:53:05 ", "Title": "CasIL: Cognizing and Imitating Skills via a Dual Cognition-Action Architecture", "Authors": ["Zixuan Chen", "Ze Ji", "Shuyang Liu", "Jing Huo", "Yiyu Chen", "Yang Gao"], "Categories": "cs.RO cs.HC cs.LG"}, "abstract": "Enabling robots to effectively imitate expert skills in longhorizon tasks such as locomotion, manipulation, and more, poses a long-standing challenge. Existing imitation learning (IL) approaches for robots still grapple with sub-optimal performance in complex tasks. In this paper, we consider how this challenge can be addressed within the human cognitive priors. Heuristically, we extend the usual notion of action to a dual Cognition (high-level)-Action (low-level) architecture by introducing intuitive human cognitive priors, and propose a novel skill IL framework through human-robot interaction, called Cognition-Action-based Skill Imitation Learning (CasIL), for the robotic agent to effectively cognize and imitate the critical skills from raw visual demonstrations. CasIL enables both cognition and action imitation, while high-level skill cognition explicitly guides low-level primitive actions, providing robustness and reliability to the entire skill IL process. We evaluated our method on MuJoCo and RLBench benchmarks, as well as on the obstacle avoidance and point-goal navigation tasks for quadrupedal robot locomotion. Experimental results show that our CasIL consistently achieves competitive and robust skill imitation capability compared to other counterparts in a variety of long-horizon robotic tasks.", "url": "https://arxiv.org/abs/2309.16299"}, {"metadata": {"arXiv": "2309.16347", "Date": "Thu, 28 Sep 2023 11:14:52 ", "Title": "Intrinsic Language-Guided Exploration for Complex Long-Horizon Robotic Manipulation Tasks", "Authors": ["Eleftherios Triantafyllidis", "Filippos Christianos and Zhibin Li"], "Categories": "cs.RO cs.CL cs.LG", "Comments": ["8 pages", "3 figures"]}, "abstract": "Current reinforcement learning algorithms struggle in sparse and complex environments, most notably in long-horizon manipulation tasks entailing a plethora of different sequences. In this work, we propose the Intrinsically Guided Exploration from Large Language Models (IGE-LLMs) framework. By leveraging LLMs as an assistive intrinsic reward, IGE-LLMs guides the exploratory process in reinforcement learning to address intricate long-horizon with sparse rewards robotic manipulation tasks. We evaluate our framework and related intrinsic learning methods in an environment challenged with exploration, and a complex robotic manipulation task challenged by both exploration and long-horizons. Results show IGE-LLMs (i) exhibit notably higher performance over related intrinsic methods and the direct use of LLMs in decision-making, (ii) can be combined and complement existing learning methods highlighting its modularity, (iii) are fairly insensitive to different intrinsic scaling parameters, and (iv) maintain robustness against increased levels of uncertainty and horizons.", "url": "https://arxiv.org/abs/2309.16347"}, {"metadata": {"arXiv": "2309.16663", "Date": "Thu, 28 Sep 2023 17:58:26 ", "Title": "HyperPPO: A scalable method for finding small policies for robotic control", "Authors": ["Shashank Hegde", "Zhehui Huang and Gaurav S. Sukhatme"], "Categories": "cs.RO cs.LG", "Comments": ["Website: https://sites.google.com/usc.edu/hyperppo"]}, "abstract": "Models with fewer parameters are necessary for the neural control of memory-limited, performant robots. Finding these smaller neural network architectures can be time-consuming. We propose HyperPPO, an on-policy reinforcement learning algorithm that utilizes graph hypernetworks to estimate the weights of multiple neural architectures simultaneously. Our method estimates weights for networks that are much smaller than those in common-use networks yet encode highly performant policies. We obtain multiple trained policies at the same time while maintaining sample efficiency and provide the user the choice of picking a network architecture that satisfies their computational constraints. We show that our method scales well - more training resources produce faster convergence to higher-performing architectures. We demonstrate that the neural policies estimated by HyperPPO are capable of decentralized control of a Crazyflie2.1 quadrotor. Website: https://sites.google.com/usc.edu/hyperppo", "url": "https://arxiv.org/abs/2309.16663"}, {"metadata": {"arXiv": "2309.16428", "Date": "Thu, 28 Sep 2023 13:26:20 ", "Title": "Nonlinear MPC design for incrementally ISS systems with application to GRU networks", "Authors": ["Fabio Bonassi", "Alessio La Bella", "Marcello Farina", "Riccardo Scattolini"], "Categories": "eess.SY cs.LG cs.SY", "Comments": ["{\\copyright} 2023. This manuscript version is made available under the CC-BY-NC-ND 4.0 license (https://creativecommons.org/licenses/by-nc-nd/4.0/). This manuscript has been accepted for publication at Elsevier Automatica. Please cite the published article instead of this manuscript. DOI will be included as soon as available"]}, "abstract": "This brief addresses the design of a Nonlinear Model Predictive Control (NMPC) strategy for exponentially incremental Input-to-State Stable (ISS) systems. In particular, a novel formulation is devised, which does not necessitate the onerous computation of terminal ingredients, but rather relies on the explicit definition of a minimum prediction horizon ensuring closed-loop stability. The designed methodology is particularly suited for the control of systems learned by Recurrent Neural Networks (RNNs), which are known for their enhanced modeling capabilities and for which the incremental ISS properties can be studied thanks to simple algebraic conditions. The approach is applied to Gated Recurrent Unit (GRU) networks, providing also a method for the design of a tailored state observer with convergence guarantees. The resulting control architecture is tested on a benchmark system, demonstrating its good control performances and efficient applicability.", "url": "https://arxiv.org/abs/2309.16428"}, {"metadata": {"arXiv": "2309.15942", "Date": "Wed, 27 Sep 2023 18:39:46 ", "Title": "Towards Efficient and Trustworthy AI Through Hardware-Algorithm-Communication Co-Design", "Authors": ["Bipin Rajendran", "Osvaldo Simeone", "and Bashir M. Al-Hashimi"], "Categories": "cs.AI cs.ET cs.IT math.IT"}, "abstract": "Artificial intelligence (AI) algorithms based on neural networks have been designed for decades with the goal of maximising some measure of accuracy. This has led to two undesired effects. First, model complexity has risen exponentially when measured in terms of computation and memory requirements. Second, state-of-the-art AI models are largely incapable of providing trustworthy measures of their uncertainty, possibly `hallucinating' their answers and discouraging their adoption for decision-making in sensitive applications. With the goal of realising efficient and trustworthy AI, in this paper we highlight research directions at the intersection of hardware and software design that integrate physical insights into computational substrates, neuroscientific principles concerning efficient information processing, information-theoretic results on optimal uncertainty quantification, and communication-theoretic guidelines for distributed processing. Overall, the paper advocates for novel design methodologies that target not only accuracy but also uncertainty quantification, while leveraging emerging computing hardware architectures that move beyond the traditional von Neumann digital computing paradigm to embrace in-memory, neuromorphic, and quantum computing technologies. An important overarching principle of the proposed approach is to view the stochasticity inherent in the computational substrate and in the communication channels between processors as a resource to be leveraged for the purpose of representing and processing classical and quantum uncertainty.", "url": "https://arxiv.org/abs/2309.15942"}, {"metadata": {"arXiv": "2309.15979", "Date": "Wed, 27 Sep 2023 19:54:07 ", "Title": "Clinical Trial Recommendations Using Semantics-Based Inductive Inference and Knowledge Graph Embeddings", "Authors": ["Murthy V. Devarakonda", "Smita Mohanty", "Raja Rao Sunkishala", "Nag Mallampalli", "and Xiong Liu"], "Categories": "cs.AI q-bio.QM", "Comments": ["13 pages (w/o bibliography)", "4 Figures", "6 Tables"]}, "abstract": "Designing a new clinical trial entails many decisions, such as defining a cohort and setting the study objectives to name a few, and therefore can benefit from recommendations based on exhaustive mining of past clinical trial records. Here, we propose a novel recommendation methodology, based on neural embeddings trained on a first-of-a-kind knowledge graph of clinical trials. We addressed several important research questions in this context, including designing a knowledge graph (KG) for clinical trial data, effectiveness of various KG embedding (KGE) methods for it, a novel inductive inference using KGE, and its use in generating recommendations for clinical trial design. We used publicly available data from clinicaltrials.gov for the study. Results show that our recommendations approach achieves relevance scores of 70%-83%, measured as the text similarity to actual clinical trial elements, and the most relevant recommendation can be found near the top of list. Our study also suggests potential improvement in training KGE using node semantics.", "url": "https://arxiv.org/abs/2309.15979"}, {"metadata": {"arXiv": "2309.16090", "Date": "Thu, 28 Sep 2023 01:18:53 ", "Title": "TPE: Towards Better Compositional Reasoning over Conceptual Tools with Multi-persona Collaboration", "Authors": ["Hongru Wang", "Huimin Wang", "Lingzhi Wang", "Minda Hu", "Rui Wang", "Boyang Xue", "Hongyuan Lu", "Fei Mi", "Kam-Fai Wong"], "Categories": "cs.AI cs.CL"}, "abstract": "Large language models (LLMs) have demonstrated exceptional performance in planning the use of various functional tools, such as calculators and retrievers, particularly in question-answering tasks. In this paper, we expand the definition of these tools, centering on conceptual tools within the context of dialogue systems. A conceptual tool specifies a cognitive concept that aids systematic or investigative thought. These conceptual tools play important roles in practice, such as multiple psychological or tutoring strategies being dynamically applied in a single turn to compose helpful responses. To further enhance the reasoning and planning capability of LLMs with these conceptual tools, we introduce a multi-persona collaboration framework: Think-Plan-Execute (TPE). This framework decouples the response generation process into three distinct roles: Thinker, Planner, and Executor. Specifically, the Thinker analyzes the internal status exhibited in the dialogue context, such as user emotions and preferences, to formulate a global guideline. The Planner then generates executable plans to call different conceptual tools (e.g., sources or strategies), while the Executor compiles all intermediate results into a coherent response. This structured approach not only enhances the explainability and controllability of responses but also reduces token redundancy. We demonstrate the effectiveness of TPE across various dialogue response generation tasks, including multi-source (FoCus) and multi-strategy interactions (CIMA and PsyQA). This reveals its potential to handle real-world dialogue interactions that require more complicated tool learning beyond just functional tools. The full code and data will be released for reproduction.", "url": "https://arxiv.org/abs/2309.16090"}, {"metadata": {"arXiv": "2309.16102", "Date": "Thu, 28 Sep 2023 01:57:40 ", "Title": "Discovering Utility-driven Interval Rules", "Authors": ["Chunkai Zhang", "Maohua Lyu", "Huaijin Hao", "Wensheng Gan", "Philip S. Yu"], "Categories": "cs.AI cs.DB", "Comments": ["Preprint. 11 figures", "5 tables"]}, "abstract": "For artificial intelligence, high-utility sequential rule mining (HUSRM) is a knowledge discovery method that can reveal the associations between events in the sequences. Recently, abundant methods have been proposed to discover high-utility sequence rules. However, the existing methods are all related to point-based sequences. Interval events that persist for some time are common. Traditional interval-event sequence knowledge discovery tasks mainly focus on pattern discovery, but patterns cannot reveal the correlation between interval events well. Moreover, the existing HUSRM algorithms cannot be directly applied to interval-event sequences since the relation in interval-event sequences is much more intricate than those in point-based sequences. In this work, we propose a utility-driven interval rule mining (UIRMiner) algorithm that can extract all utility-driven interval rules (UIRs) from the interval-event sequence database to solve the problem. In UIRMiner, we first introduce a numeric encoding relation representation, which can save much time on relation computation and storage on relation representation. Furthermore, to shrink the search space, we also propose a complement pruning strategy, which incorporates the utility upper bound with the relation. Finally, plentiful experiments implemented on both real-world and synthetic datasets verify that UIRMiner is an effective and efficient algorithm.", "url": "https://arxiv.org/abs/2309.16102"}, {"metadata": {"arXiv": "2309.16146", "Date": "Thu, 28 Sep 2023 03:51:49 ", "Title": "T-COL: Generating Counterfactual Explanations for General User Preferences on Variable Machine Learning Systems", "Authors": ["Ming Wang", "Daling Wang", "Wenfang Wu", "Shi Feng", "Yifei Zhang"], "Categories": "cs.AI"}, "abstract": "Machine learning (ML) based systems have been suffering a lack of interpretability. To address this problem, counterfactual explanations (CEs) have been proposed. CEs are unique as they provide workable suggestions to users, in addition to explaining why a certain outcome was predicted. However, the application of CEs has been hindered by two main challenges, namely general user preferences and variable ML systems. User preferences, in particular, tend to be general rather than specific feature values. Additionally, CEs need to be customized to suit the variability of ML models, while also maintaining robustness even when these validation models change. To overcome these challenges, we propose several possible general user preferences that have been validated by user research and map them to the properties of CEs. We also introduce a new method called \\uline{T}ree-based \\uline{C}onditions \\uline{O}ptional \\uline{L}inks (T-COL), which has two optional structures and several groups of conditions for generating CEs that can be adapted to general user preferences. Meanwhile, a group of conditions lead T-COL to generate more robust CEs that have higher validity when the ML model is replaced. We compared the properties of CEs generated by T-COL experimentally under different user preferences and demonstrated that T-COL is better suited for accommodating user preferences and variable ML systems compared to baseline methods including Large Language Models.", "url": "https://arxiv.org/abs/2309.16146"}, {"metadata": {"arXiv": "2309.16166", "Date": "Thu, 28 Sep 2023 04:43:39 ", "Title": "CoinRun: Solving Goal Misgeneralisation", "Authors": ["Stuart Armstrong and Alexandre Maranh\\~ao and Oliver Daniels-Koch and Patrick Leask and Rebecca Gorman"], "Categories": "cs.AI"}, "abstract": "Goal misgeneralisation is a key challenge in AI alignment -- the task of getting powerful Artificial Intelligences to align their goals with human intentions and human morality. In this paper, we show how the ACE (Algorithm for Concept Extrapolation) agent can solve one of the key standard challenges in goal misgeneralisation: the CoinRun challenge. It uses no new reward information in the new environment. This points to how autonomous agents could be trusted to act in human interests, even in novel and critical situations.", "url": "https://arxiv.org/abs/2309.16166"}, {"metadata": {"arXiv": "2309.16180", "Date": "Thu, 28 Sep 2023 05:47:52 ", "Title": "A More General Theory of Diagnosis from First Principles", "Authors": ["Alban Grastien and Patrik Haslum and Sylvie Thi\\'ebaux"], "Categories": "cs.AI"}, "abstract": "Model-based diagnosis has been an active research topic in different communities including artificial intelligence, formal methods, and control. This has led to a set of disparate approaches addressing different classes of systems and seeking different forms of diagnoses. In this paper, we resolve such disparities by generalising Reiter's theory to be agnostic to the types of systems and diagnoses considered. This more general theory of diagnosis from first principles defines the minimal diagnosis as the set of preferred diagnosis candidates in a search space of hypotheses. Computing the minimal diagnosis is achieved by exploring the space of diagnosis hypotheses, testing sets of hypotheses for consistency with the system's model and the observation, and generating conflicts that rule out successors and other portions of the search space. Under relatively mild assumptions, our algorithms correctly compute the set of preferred diagnosis candidates. The main difficulty here is that the search space is no longer a powerset as in Reiter's theory, and that, as consequence, many of the implicit properties (such as finiteness of the search space) no longer hold. The notion of conflict also needs to be generalised and we present such a more general notion. We present two implementations of these algorithms, using test solvers based on satisfiability and heuristic search, respectively, which we evaluate on instances from two real world discrete event problems. Despite the greater generality of our theory, these implementations surpass the special purpose algorithms designed for discrete event systems, and enable solving instances that were out of reach of existing diagnosis approaches.", "url": "https://arxiv.org/abs/2309.16180"}, {"metadata": {"arXiv": "2309.16344", "Date": "Thu, 28 Sep 2023 11:08:37 ", "Title": "Epistemic Logic Programs: a study of some properties", "Authors": ["Stefania Costantini", "Andrea Formisano"], "Categories": "cs.AI", "Comments": ["Under consideration in Theory and Practice of Logic Programming (TPLP)"]}, "abstract": "Epistemic Logic Programs (ELPs), extend Answer Set Programming (ASP) with epistemic operators. The semantics of such programs is provided in terms of world views, which are sets of belief sets, i.e., syntactically, sets of sets of atoms. Different semantic approaches propose different characterizations of world views. Recent work has introduced semantic properties that should be met by any semantics for ELPs, like the Epistemic Splitting Property, that, if satisfied, allows to modularly compute world views in a bottom-up fashion, analogously to ``traditional'' ASP. We analyze the possibility of changing the perspective, shifting from a bottom-up to a top-down approach to splitting. We propose a basic top-down approach, which we prove to be equivalent to the bottom-up one. We then propose an extended approach, where our new definition: (i) is provably applicable to many of the existing semantics; (ii) operates similarly to ``traditional'' ASP; (iii) provably coincides under any semantics with the bottom-up notion of splitting at least on the class of Epistemically Stratified Programs (which are, intuitively, those where the use of epistemic operators is stratified); (iv) better adheres to common ASP programming methodology.", "url": "https://arxiv.org/abs/2309.16344"}, {"metadata": {"arXiv": "2309.16436", "Date": "Thu, 28 Sep 2023 13:40:50 ", "Title": "Neuro Symbolic Reasoning for Planning: Counterexample Guided Inductive Synthesis using Large Language Models and Satisfiability Solving", "Authors": ["Sumit Kumar Jha", "Susmit Jha", "Patrick Lincoln", "Nathaniel D. Bastian", "Alvaro Velasquez", "Rickard Ewetz", "Sandeep Neema"], "Categories": "cs.AI cs.LO", "Comments": ["25 pages", "7 figures"]}, "abstract": "Generative large language models (LLMs) with instruct training such as GPT-4 can follow human-provided instruction prompts and generate human-like responses to these prompts. Apart from natural language responses, they have also been found to be effective at generating formal artifacts such as code, plans, and logical specifications from natural language prompts. Despite their remarkably improved accuracy, these models are still known to produce factually incorrect or contextually inappropriate results despite their syntactic coherence - a phenomenon often referred to as hallucination. This limitation makes it difficult to use these models to synthesize formal artifacts that are used in safety-critical applications. Unlike tasks such as text summarization and question-answering, bugs in code, plan, and other formal artifacts produced by LLMs can be catastrophic. We posit that we can use the satisfiability modulo theory (SMT) solvers as deductive reasoning engines to analyze the generated solutions from the LLMs, produce counterexamples when the solutions are incorrect, and provide that feedback to the LLMs exploiting the dialog capability of instruct-trained LLMs. This interaction between inductive LLMs and deductive SMT solvers can iteratively steer the LLM to generate the correct response. In our experiments, we use planning over the domain of blocks as our synthesis task for evaluating our approach. We use GPT-4, GPT3.5 Turbo, Davinci, Curie, Babbage, and Ada as the LLMs and Z3 as the SMT solver. Our method allows the user to communicate the planning problem in natural language; even the formulation of queries to SMT solvers is automatically generated from natural language. Thus, the proposed technique can enable non-expert users to describe their problems in natural language, and the combination of LLMs and SMT solvers can produce provably correct solutions.", "url": "https://arxiv.org/abs/2309.16436"}, {"metadata": {"arXiv": "2309.16573", "Date": "Thu, 28 Sep 2023 16:29:52 ", "Title": "The ARRT of Language-Models-as-a-Service: Overview of a New Paradigm and its Challenges", "Authors": ["Emanuele La Malfa", "Aleksandar Petrov", "Simon Frieder", "Christoph Weinhuber", "Ryan Burnell", "Anthony G. Cohn", "Nigel Shadbolt", "Michael Wooldridge"], "Categories": "cs.AI cs.CL cs.CY"}, "abstract": "Some of the most powerful language models currently are proprietary systems, accessible only via (typically restrictive) web or software programming interfaces. This is the Language-Models-as-a-Service (LMaaS) paradigm. Contrasting with scenarios where full model access is available, as in the case of open-source models, such closed-off language models create specific challenges for evaluating, benchmarking, and testing them. This paper has two goals: on the one hand, we delineate how the aforementioned challenges act as impediments to the accessibility, replicability, reliability, and trustworthiness (ARRT) of LMaaS. We systematically examine the issues that arise from a lack of information about language models for each of these four aspects. We shed light on current solutions, provide some recommendations, and highlight the directions for future advancements. On the other hand, it serves as a one-stop-shop for the extant knowledge about current, major LMaaS, offering a synthesized overview of the licences and capabilities their interfaces offer.", "url": "https://arxiv.org/abs/2309.16573"}, {"metadata": {"arXiv": "2309.16211", "Date": "Thu, 28 Sep 2023 07:37:18 ", "Title": "VDC: Versatile Data Cleanser for Detecting Dirty Samples via Visual-Linguistic Inconsistency", "Authors": ["Zihao Zhu", "Mingda Zhang", "Shaokui Wei", "Bingzhe Wu", "Baoyuan Wu"], "Categories": "cs.CV cs.AI", "Comments": ["22 pages,5 figures,17 tables"]}, "abstract": "The role of data in building AI systems has recently been emphasized by the emerging concept of data-centric AI. Unfortunately, in the real-world, datasets may contain dirty samples, such as poisoned samples from backdoor attack, noisy labels in crowdsourcing, and even hybrids of them. The presence of such dirty samples makes the DNNs vunerable and unreliable.Hence, it is critical to detect dirty samples to improve the quality and realiability of dataset. Existing detectors only focus on detecting poisoned samples or noisy labels, that are often prone to weak generalization when dealing with dirty samples from other domains.In this paper, we find a commonality of various dirty samples is visual-linguistic inconsistency between images and associated labels. To capture the semantic inconsistency between modalities, we propose versatile data cleanser (VDC) leveraging the surpassing capabilities of multimodal large language models (MLLM) in cross-modal alignment and reasoning.It consists of three consecutive modules: the visual question generation module to generate insightful questions about the image; the visual question answering module to acquire the semantics of the visual content by answering the questions with MLLM; followed by the visual answer evaluation module to evaluate the inconsistency.Extensive experiments demonstrate its superior performance and generalization to various categories and types of dirty samples.", "url": "https://arxiv.org/abs/2309.16211"}, {"metadata": {"arXiv": "2309.16257", "Date": "Thu, 28 Sep 2023 08:50:19 ", "Title": "Nondestructive chicken egg fertility detection using CNN-transfer learning algorithms", "Authors": ["Shoffan Saifullah", "Rafal Drezewski", "Anton Yudhana", "Andri Pranolo", "Wilis Kaswijanti", "Andiko Putro Suryotomo", "Seno Aji Putra", "Alin Khaliduzzaman", "Anton Satria Prabuwono", "Nathalie Japkowicz"], "Categories": "cs.CV cs.AI eess.IV", "Comments": ["18 pages", "9 figures", "1 table", "journal article published"], "MSC-class": "CS-Class: 68T07, 68T45, 68U10, ICT-Class: 94A08", "ACM-class": "I.2; I.4; I.5", "Journal-ref": "Jurnal Ilmiah Teknik Elektro Komputer dan Informatika (JITEKI), Vol 9, No 3 (2023)", "DOI": "10.26555/jiteki.v9i3.26722"}, "abstract": "This study explored the application of CNN-Transfer Learning for nondestructive chicken egg fertility detection for precision poultry hatchery practices. Four models, VGG16, ResNet50, InceptionNet, and MobileNet, were trained and evaluated on a dataset (200 single egg images) using augmented images (rotation, flip, scale, translation, and reflection). Although the training results demonstrated that all models achieved high accuracy, indicating their ability to accurately learn and classify chicken eggs' fertility state, when evaluated on the testing set, variations in accuracy and performance were observed. InceptionNet exhibited the best overall performance, accurately classifying fertile and non-fertile eggs. It demonstrated excellent performance in both training and testing sets in all parameters of the evaluation metrics. In testing set, it achieved an accuracy of 0.98, a sensitivity of 1 for detecting fertile eggs, and a specificity of 0.96 for identifying non-fertile eggs. The higher performance is attributed to its unique architecture efficiently capturing features at different scales leading to improved accuracy and robustness. Further optimization and fine-tuning of the models might necessary to address the limitations in accurately detecting fertile and non-fertile eggs in case of other models. This study highlighted the potential of CNN-Transfer Learning for nondestructive fertility detection and emphasizes the need for further research to enhance the models' capabilities and ensure accurate classification.", "url": "https://arxiv.org/abs/2309.16257"}, {"metadata": {"arXiv": "2309.16511", "Date": "Thu, 28 Sep 2023 15:18:35 ", "Title": "Toloka Visual Question Answering Benchmark", "Authors": ["Dmitry Ustalov and Nikita Pavlichenko and Sergey Koshelev and Daniil Likhobaba and Alisa Smirnova"], "Categories": "cs.CV cs.AI cs.CL cs.HC", "Comments": ["16 pages; see https://toloka.ai/challenges/wsdm2023/ for more details"], "MSC-class": "68-11", "ACM-class": "C.4"}, "abstract": "In this paper, we present Toloka Visual Question Answering, a new crowdsourced dataset allowing comparing performance of machine learning systems against human level of expertise in the grounding visual question answering task. In this task, given an image and a textual question, one has to draw the bounding box around the object correctly responding to that question. Every image-question pair contains the response, with only one correct response per image. Our dataset contains 45,199 pairs of images and questions in English, provided with ground truth bounding boxes, split into train and two test subsets. Besides describing the dataset and releasing it under a CC BY license, we conducted a series of experiments on open source zero-shot baseline models and organized a multi-phase competition at WSDM Cup that attracted 48 participants worldwide. However, by the time of paper submission, no machine learning model outperformed the non-expert crowdsourcing baseline according to the intersection over union evaluation score.", "url": "https://arxiv.org/abs/2309.16511"}, {"metadata": {"arXiv": "2309.16661", "Date": "Thu, 28 Sep 2023 17:58:05 ", "Title": "SA2-Net: Scale-aware Attention Network for Microscopic Image Segmentation", "Authors": ["Mustansar Fiaz", "Moein Heidari", "Rao Muhammad Anwer", "Hisham Cholakkal"], "Categories": "cs.CV cs.AI", "Comments": ["BMVC 2023 accepted as oral"]}, "abstract": "Microscopic image segmentation is a challenging task, wherein the objective is to assign semantic labels to each pixel in a given microscopic image. While convolutional neural networks (CNNs) form the foundation of many existing frameworks, they often struggle to explicitly capture long-range dependencies. Although transformers were initially devised to address this issue using self-attention, it has been proven that both local and global features are crucial for addressing diverse challenges in microscopic images, including variations in shape, size, appearance, and target region density. In this paper, we introduce SA2-Net, an attention-guided method that leverages multi-scale feature learning to effectively handle diverse structures within microscopic images. Specifically, we propose scale-aware attention (SA2) module designed to capture inherent variations in scales and shapes of microscopic regions, such as cells, for accurate segmentation. This module incorporates local attention at each level of multi-stage features, as well as global attention across multiple resolutions. Furthermore, we address the issue of blurred region boundaries (e.g., cell boundaries) by introducing a novel upsampling strategy called the Adaptive Up-Attention (AuA) module. This module enhances the discriminative ability for improved localization of microscopic regions using an explicit attention mechanism. Extensive experiments on five challenging datasets demonstrate the benefits of our SA2-Net model. Our source code is publicly available at \\url{https://github.com/mustansarfiaz/SA2-Net}.", "url": "https://arxiv.org/abs/2309.16661"}, {"metadata": {"arXiv": "2309.16263", "Date": "Thu, 28 Sep 2023 08:57:01 ", "Title": "Cooperation Dynamics in Multi-Agent Systems: Exploring Game-Theoretic Scenarios with Mean-Field Equilibria", "Authors": ["Vaigarai Sathi", "Sabahat Shaik", "Jaswanth Nidamanuri"], "Categories": "cs.GT cs.AI", "Comments": ["Submitted to MADGames: Multi-Agent Dynamic Games Workshop at IROS 2023"]}, "abstract": "Cooperation is fundamental in Multi-Agent Systems (MAS) and Multi-Agent Reinforcement Learning (MARL), often requiring agents to balance individual gains with collective rewards. In this regard, this paper aims to investigate strategies to invoke cooperation in game-theoretic scenarios, namely the Iterated Prisoner's Dilemma, where agents must optimize both individual and group outcomes. Existing cooperative strategies are analyzed for their effectiveness in promoting group-oriented behavior in repeated games. Modifications are proposed where encouraging group rewards will also result in a higher individual gain, addressing real-world dilemmas seen in distributed systems. The study extends to scenarios with exponentially growing agent populations ($N \\longrightarrow +\\infty$), where traditional computation and equilibrium determination are challenging. Leveraging mean-field game theory, equilibrium solutions and reward structures are established for infinitely large agent sets in repeated games. Finally, practical insights are offered through simulations using the Multi Agent-Posthumous Credit Assignment trainer, and the paper explores adapting simulation algorithms to create scenarios favoring cooperation for group rewards. These practical implementations bridge theoretical concepts with real-world applications.", "url": "https://arxiv.org/abs/2309.16263"}, {"metadata": {"arXiv": "2309.16161", "Date": "Thu, 28 Sep 2023 04:26:06 ", "Title": "Leveraging Untrustworthy Commands for Multi-Robot Coordination in Unpredictable Environments: A Bandit Submodular Maximization Approach", "Authors": ["Zirui Xu", "Xiaofeng Lin", "Vasileios Tzoumas"], "Categories": "eess.SY cs.AI cs.MA cs.RO cs.SY math.OC", "Comments": ["arXiv admin note: text overlap with arXiv:2305.12795"]}, "abstract": "We study the problem of multi-agent coordination in unpredictable and partially-observable environments with untrustworthy external commands. The commands are actions suggested to the robots, and are untrustworthy in that their performance guarantees, if any, are unknown. Such commands may be generated by human operators or machine learning algorithms and, although untrustworthy, can often increase the robots' performance in complex multi-robot tasks. We are motivated by complex multi-robot tasks such as target tracking, environmental mapping, and area monitoring. Such tasks are often modeled as submodular maximization problems due to the information overlap among the robots. We provide an algorithm, Meta Bandit Sequential Greedy (MetaBSG), which enjoys performance guarantees even when the external commands are arbitrarily bad. MetaBSG leverages a meta-algorithm to learn whether the robots should follow the commands or a recently developed submodular coordination algorithm, Bandit Sequential Greedy (BSG) [1], which has performance guarantees even in unpredictable and partially-observable environments. Particularly, MetaBSG asymptotically can achieve the better performance out of the commands and the BSG algorithm, quantifying its suboptimality against the optimal time-varying multi-robot actions in hindsight. Thus, MetaBSG can be interpreted as robustifying the untrustworthy commands. We validate our algorithm in simulated scenarios of multi-target tracking.", "url": "https://arxiv.org/abs/2309.16161"}, {"metadata": {"arXiv": "2309.16223", "Date": "Thu, 28 Sep 2023 07:56:10 ", "Title": "GInX-Eval: Towards In-Distribution Evaluation of Graph Neural Network Explanations", "Authors": ["Kenza Amara and Mennatallah El-Assady and Rex Ying"], "Categories": "cs.AI cs.LG", "Comments": ["Preprint", "Submitted to ICLR2024"]}, "abstract": "Diverse explainability methods of graph neural networks (GNN) have recently been developed to highlight the edges and nodes in the graph that contribute the most to the model predictions. However, it is not clear yet how to evaluate the correctness of those explanations, whether it is from a human or a model perspective. One unaddressed bottleneck in the current evaluation procedure is the problem of out-of-distribution explanations, whose distribution differs from those of the training data. This important issue affects existing evaluation metrics such as the popular faithfulness or fidelity score. In this paper, we show the limitations of faithfulness metrics. We propose GInX-Eval (Graph In-distribution eXplanation Evaluation), an evaluation procedure of graph explanations that overcomes the pitfalls of faithfulness and offers new insights on explainability methods. Using a retraining strategy, the GInX score measures how informative removed edges are for the model and the EdgeRank score evaluates if explanatory edges are correctly ordered by their importance. GInX-Eval verifies if ground-truth explanations are instructive to the GNN model. In addition, it shows that many popular methods, including gradient-based methods, produce explanations that are not better than a random designation of edges as important subgraphs, challenging the findings of current works in the area. Results with GInX-Eval are consistent across multiple datasets and align with human evaluation.", "url": "https://arxiv.org/abs/2309.16223"}, {"metadata": {"arXiv": "2309.16382", "Date": "Thu, 28 Sep 2023 12:30:37 ", "Title": "RLLTE: Long-Term Evolution Project of Reinforcement Learning", "Authors": ["Mingqi Yuan", "Zequn Zhang", "Yang Xu", "Shihao Luo", "Bo Li", "Xin Jin", "Wenjun Zeng"], "Categories": "cs.AI cs.LG", "Comments": ["22 pages", "15 figures"]}, "abstract": "We present RLLTE: a long-term evolution, extremely modular, and open-source framework for reinforcement learning (RL) research and application. Beyond delivering top-notch algorithm implementations, RLLTE also serves as a toolkit for developing algorithms. More specifically, RLLTE decouples the RL algorithms completely from the exploitation-exploration perspective, providing a large number of components to accelerate algorithm development and evolution. In particular, RLLTE is the first RL framework to build a complete and luxuriant ecosystem, which includes model training, evaluation, deployment, benchmark hub, and large language model (LLM)-empowered copilot. RLLTE is expected to set standards for RL engineering practice and be highly stimulative for industry and academia.", "url": "https://arxiv.org/abs/2309.16382"}, {"metadata": {"arXiv": "2309.16593", "Date": "Thu, 28 Sep 2023 16:57:03 ", "Title": "Navigating Healthcare Insights: A Birds Eye View of Explainability with Knowledge Graphs", "Authors": ["Satvik Garg", "Shivam Parikh", "Somya Garg"], "Categories": "cs.AI cs.LG", "Comments": ["IEEE AIKE 2023", "8 Pages"]}, "abstract": "Knowledge graphs (KGs) are gaining prominence in Healthcare AI, especially in drug discovery and pharmaceutical research as they provide a structured way to integrate diverse information sources, enhancing AI system interpretability. This interpretability is crucial in healthcare, where trust and transparency matter, and eXplainable AI (XAI) supports decision making for healthcare professionals. This overview summarizes recent literature on the impact of KGs in healthcare and their role in developing explainable AI models. We cover KG workflow, including construction, relationship extraction, reasoning, and their applications in areas like Drug-Drug Interactions (DDI), Drug Target Interactions (DTI), Drug Development (DD), Adverse Drug Reactions (ADR), and bioinformatics. We emphasize the importance of making KGs more interpretable through knowledge-infused learning in healthcare. Finally, we highlight research challenges and provide insights for future directions.", "url": "https://arxiv.org/abs/2309.16593"}, {"metadata": {"arXiv": "2309.16064", "Date": "Wed, 27 Sep 2023 23:11:35 ", "Title": "Masked autoencoders are scalable learners of cellular morphology", "Authors": ["Oren Kraus", "Kian Kenyon-Dean", "Saber Saberian", "Maryam Fallah", "Peter McLean", "Jess Leung", "Vasudev Sharma", "Ayla Khan", "Jia Balakrishnan", "Safiye Celik", "Maciej Sypetkowski", "Chi Vicky Cheng", "Kristen Morse", "Maureen Makes", "Ben Mabey", "Berton Earnshaw"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["4 pages", "4 figures"]}, "abstract": "Inferring biological relationships from cellular phenotypes in high-content microscopy screens provides significant opportunity and challenge in biological research. Prior results have shown that deep vision models can capture biological signal better than hand-crafted features. This work explores how weakly supervised and self-supervised deep learning approaches scale when training larger models on larger datasets. Our results show that both CNN- and ViT-based masked autoencoders significantly outperform weakly supervised models. At the high-end of our scale, a ViT-L/8 trained on over 3.5-billion unique crops sampled from 95-million microscopy images achieves relative improvements as high as 28% over our best weakly supervised models at inferring known biological relationships curated from public databases.", "url": "https://arxiv.org/abs/2309.16064"}, {"metadata": {"arXiv": "2309.16108", "Date": "Thu, 28 Sep 2023 02:20:59 ", "Title": "Channel Vision Transformers: An Image Is Worth C x 16 x 16 Words", "Authors": ["Yujia Bao", "Srinivasan Sivanandan", "Theofanis Karaletsos"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Vision Transformer (ViT) has emerged as a powerful architecture in the realm of modern computer vision. However, its application in certain imaging fields, such as microscopy and satellite imaging, presents unique challenges. In these domains, images often contain multiple channels, each carrying semantically distinct and independent information. Furthermore, the model must demonstrate robustness to sparsity in input channels, as they may not be densely available during training or testing. In this paper, we propose a modification to the ViT architecture that enhances reasoning across the input channels and introduce Hierarchical Channel Sampling (HCS) as an additional regularization technique to ensure robustness when only partial channels are presented during test time. Our proposed model, ChannelViT, constructs patch tokens independently from each input channel and utilizes a learnable channel embedding that is added to the patch tokens, similar to positional embeddings. We evaluate the performance of ChannelViT on ImageNet, JUMP-CP (microscopy cell imaging), and So2Sat (satellite imaging). Our results show that ChannelViT outperforms ViT on classification tasks and generalizes well, even when a subset of input channels is used during testing. Across our experiments, HCS proves to be a powerful regularizer, independent of the architecture employed, suggesting itself as a straightforward technique for robust ViT training. Lastly, we find that ChannelViT generalizes effectively even when there is limited access to all channels during training, highlighting its potential for multi-channel imaging under real-world conditions with sparse sensors.", "url": "https://arxiv.org/abs/2309.16108"}, {"metadata": {"arXiv": "2309.16414", "Date": "Thu, 28 Sep 2023 13:08:08 ", "Title": "AutoCLIP: Auto-tuning Zero-Shot Classifiers for Vision-Language Models", "Authors": ["Jan Hendrik Metzen", "Piyapat Saranrittichai", "Chaithanya Kumar Mummadi"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Classifiers built upon vision-language models such as CLIP have shown remarkable zero-shot performance across a broad range of image classification tasks. Prior work has studied different ways of automatically creating descriptor sets for every class based on prompt templates, ranging from manually engineered templates over templates obtained from a large language model to templates built from random words and characters. In contrast, deriving zero-shot classifiers from the respective encoded class descriptors has remained nearly unchanged, that is: classify to the class that maximizes the cosine similarity between its averaged encoded class descriptors and the encoded image. However, weighting all class descriptors equally can be suboptimal when certain descriptors match visual clues on a given image better than others. In this work, we propose AutoCLIP, a method for auto-tuning zero-shot classifiers. AutoCLIP assigns to each prompt template per-image weights, which are derived from statistics of class descriptor-image similarities at inference time. AutoCLIP is fully unsupervised, has very low overhead, and can be easily implemented in few lines of code. We show that for a broad range of vision-language models, datasets, and prompt templates, AutoCLIP outperforms baselines consistently and by up to 3 percent point accuracy.", "url": "https://arxiv.org/abs/2309.16414"}, {"metadata": {"arXiv": "2309.16534", "Date": "Thu, 28 Sep 2023 15:46:25 ", "Title": "MotionLM: Multi-Agent Motion Forecasting as Language Modeling", "Authors": ["Ari Seff", "Brian Cera", "Dian Chen", "Mason Ng", "Aurick Zhou", "Nigamaa Nayakanti", "Khaled S. Refaat", "Rami Al-Rfou", "Benjamin Sapp"], "Categories": "cs.CV cs.AI cs.LG cs.RO", "Comments": ["To appear at the International Conference on Computer Vision (ICCV) 2023"]}, "abstract": "Reliable forecasting of the future behavior of road agents is a critical component to safe planning in autonomous vehicles. Here, we represent continuous trajectories as sequences of discrete motion tokens and cast multi-agent motion prediction as a language modeling task over this domain. Our model, MotionLM, provides several advantages: First, it does not require anchors or explicit latent variable optimization to learn multimodal distributions. Instead, we leverage a single standard language modeling objective, maximizing the average log probability over sequence tokens. Second, our approach bypasses post-hoc interaction heuristics where individual agent trajectory generation is conducted prior to interactive scoring. Instead, MotionLM produces joint distributions over interactive agent futures in a single autoregressive decoding process. In addition, the model's sequential factorization enables temporally causal conditional rollouts. The proposed approach establishes new state-of-the-art performance for multi-agent motion prediction on the Waymo Open Motion Dataset, ranking 1st on the interactive challenge leaderboard.", "url": "https://arxiv.org/abs/2309.16534"}, {"metadata": {"arXiv": "2309.16561", "Date": "Thu, 28 Sep 2023 16:16:08 ", "Title": "Voting Network for Contour Levee Farmland Segmentation and Classification", "Authors": ["Abolfazl Meyarian and Xiaohui Yuan"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "High-resolution aerial imagery allows fine details in the segmentation of farmlands. However, small objects and features introduce distortions to the delineation of object boundaries, and larger contextual views are needed to mitigate class confusion. In this work, we present an end-to-end trainable network for segmenting farmlands with contour levees from high-resolution aerial imagery. A fusion block is devised that includes multiple voting blocks to achieve image segmentation and classification. We integrate the fusion block with a backbone and produce both semantic predictions and segmentation slices. The segmentation slices are used to perform majority voting on the predictions. The network is trained to assign the most likely class label of a segment to its pixels, learning the concept of farmlands rather than analyzing constitutive pixels separately. We evaluate our method using images from the National Agriculture Imagery Program. Our method achieved an average accuracy of 94.34\\%. Compared to the state-of-the-art methods, the proposed method obtains an improvement of 6.96% and 2.63% in the F1 score on average.", "url": "https://arxiv.org/abs/2309.16561"}, {"metadata": {"arXiv": "2309.16668", "Date": "Thu, 28 Sep 2023 17:59:29 ", "Title": "RealFill: Reference-Driven Generation for Authentic Image Completion", "Authors": ["Luming Tang", "Nataniel Ruiz", "Qinghao Chu", "Yuanzhen Li", "Aleksander Holynski", "David E. Jacobs", "Bharath Hariharan", "Yael Pritch", "Neal Wadhwa", "Kfir Aberman", "Michael Rubinstein"], "Categories": "cs.CV cs.AI cs.GR cs.LG", "Comments": ["Project page: https://realfill.github.io"]}, "abstract": "Recent advances in generative imagery have brought forth outpainting and inpainting models that can produce high-quality, plausible image content in unknown regions, but the content these models hallucinate is necessarily inauthentic, since the models lack sufficient context about the true scene. In this work, we propose RealFill, a novel generative approach for image completion that fills in missing regions of an image with the content that should have been there. RealFill is a generative inpainting model that is personalized using only a few reference images of a scene. These reference images do not have to be aligned with the target image, and can be taken with drastically varying viewpoints, lighting conditions, camera apertures, or image styles. Once personalized, RealFill is able to complete a target image with visually compelling contents that are faithful to the original scene. We evaluate RealFill on a new image completion benchmark that covers a set of diverse and challenging scenarios, and find that it outperforms existing approaches by a large margin. See more results on our project page: https://realfill.github.io", "url": "https://arxiv.org/abs/2309.16668"}, {"metadata": {"arXiv": "2309.15875", "Date": "Wed, 27 Sep 2023 05:15:02 ", "Title": "STAG: Enabling Low Latency and Low Staleness of GNN-based Services with Dynamic Graphs", "Authors": ["Jiawen Wang", "Quan Chen", "Deze Zeng", "Zhuo Song", "Chen Chen and Minyi Guo"], "Categories": "cs.LG cs.AI"}, "abstract": "Many emerging user-facing services adopt Graph Neural Networks (GNNs) to improve serving accuracy. When the graph used by a GNN model changes, representations (embedding) of nodes in the graph should be updated accordingly. However, the node representation update is too slow, resulting in either long response latency of user queries (the inference is performed after the update completes) or high staleness problem (the inference is performed based on stale data). Our in-depth analysis shows that the slow update is mainly due to neighbor explosion problem in graphs and duplicated computation. Based on such findings, we propose STAG, a GNN serving framework that enables low latency and low staleness of GNN-based services. It comprises a collaborative serving mechanism and an additivity-based incremental propagation strategy. With the collaborative serving mechanism, only part of node representations are updated during the update phase, and the final representations are calculated in the inference phase. It alleviates the neighbor explosion problem. The additivity-based incremental propagation strategy reuses intermediate data during the update phase, eliminating duplicated computation problem. Experimental results show that STAG accelerates the update phase by 1.3x~90.1x, and greatly reduces staleness time with a slight increase in response latency.", "url": "https://arxiv.org/abs/2309.15875"}, {"metadata": {"arXiv": "2309.15877", "Date": "Wed, 27 Sep 2023 05:50:05 ", "Title": "Neuro-Inspired Hierarchical Multimodal Learning", "Authors": ["Xiongye Xiao", "Gengshuo Liu", "Gaurav Gupta", "Defu Cao", "Shixuan Li", "Yaxing Li", "Tianqing Fang", "Mingxi Cheng", "Paul Bogdan"], "Categories": "cs.LG cs.AI"}, "abstract": "Integrating and processing information from various sources or modalities are critical for obtaining a comprehensive and accurate perception of the real world. Drawing inspiration from neuroscience, we develop the Information-Theoretic Hierarchical Perception (ITHP) model, which utilizes the concept of information bottleneck. Distinct from most traditional fusion models that aim to incorporate all modalities as input, our model designates the prime modality as input, while the remaining modalities act as detectors in the information pathway. Our proposed perception model focuses on constructing an effective and compact information flow by achieving a balance between the minimization of mutual information between the latent state and the input modal state, and the maximization of mutual information between the latent states and the remaining modal states. This approach leads to compact latent state representations that retain relevant information while minimizing redundancy, thereby substantially enhancing the performance of downstream tasks. Experimental evaluations on both the MUStARD and CMU-MOSI datasets demonstrate that our model consistently distills crucial information in multimodal learning scenarios, outperforming state-of-the-art benchmarks.", "url": "https://arxiv.org/abs/2309.15877"}, {"metadata": {"arXiv": "2309.15881", "Date": "Wed, 27 Sep 2023 09:32:10 ", "Title": "Enhancing Cross-Category Learning in Recommendation Systems with Multi-Layer Embedding Training", "Authors": ["Zihao Deng", "Benjamin Ghaemmaghami", "Ashish Kumar Singh", "Benjamin Cho", "Leo Orshansky", "Mattan Erez", "Michael Orshansky"], "Categories": "cs.LG cs.AI", "Comments": ["This is the preprint of our paper accepted at ACML 2023"]}, "abstract": "Modern DNN-based recommendation systems rely on training-derived embeddings of sparse features. Input sparsity makes obtaining high-quality embeddings for rarely-occurring categories harder as their representations are updated infrequently. We demonstrate a training-time technique to produce superior embeddings via effective cross-category learning and theoretically explain its surprising effectiveness. The scheme, termed the multi-layer embeddings training (MLET), trains embeddings using factorization of the embedding layer, with an inner dimension higher than the target embedding dimension. For inference efficiency, MLET converts the trained two-layer embedding into a single-layer one thus keeping inference-time model size unchanged. Empirical superiority of MLET is puzzling as its search space is not larger than that of the single-layer embedding. The strong dependence of MLET on the inner dimension is even more surprising. We develop a theory that explains both of these behaviors by showing that MLET creates an adaptive update mechanism modulated by the singular vectors of embeddings. When tested on multiple state-of-the-art recommendation models for click-through rate (CTR) prediction tasks, MLET consistently produces better models, especially for rare items. At constant model quality, MLET allows embedding dimension, and model size, reduction by up to 16x, and 5.8x on average, across the models.", "url": "https://arxiv.org/abs/2309.15881"}, {"metadata": {"arXiv": "2309.15946", "Date": "Wed, 27 Sep 2023 18:59:00 ", "Title": "Unified Long-Term Time-Series Forecasting Benchmark", "Authors": ["Jacek Cyranka", "Szymon Haponiuk"], "Categories": "cs.LG cs.AI cs.NE math.DS"}, "abstract": "In order to support the advancement of machine learning methods for predicting time-series data, we present a comprehensive dataset designed explicitly for long-term time-series forecasting. We incorporate a collection of datasets obtained from diverse, dynamic systems and real-life records. Each dataset is standardized by dividing it into training and test trajectories with predetermined lookback lengths. We include trajectories of length up to $2000$ to ensure a reliable evaluation of long-term forecasting capabilities. To determine the most effective model in diverse scenarios, we conduct an extensive benchmarking analysis using classical and state-of-the-art models, namely LSTM, DeepAR, NLinear, N-Hits, PatchTST, and LatentODE. Our findings reveal intriguing performance comparisons among these models, highlighting the dataset-dependent nature of model effectiveness. Notably, we introduce a custom latent NLinear model and enhance DeepAR with a curriculum learning phase. Both consistently outperform their vanilla counterparts.", "url": "https://arxiv.org/abs/2309.15946"}, {"metadata": {"arXiv": "2309.16025", "Date": "Wed, 27 Sep 2023 21:03:45 ", "Title": "Symbolic Imitation Learning: From Black-Box to Explainable Driving Policies", "Authors": ["Iman Sharifi and Saber Fallah"], "Categories": "cs.LG cs.AI cs.RO", "Comments": ["12 pages", "2 figures", "2 tables"]}, "abstract": "Current methods of imitation learning (IL), primarily based on deep neural networks, offer efficient means for obtaining driving policies from real-world data but suffer from significant limitations in interpretability and generalizability. These shortcomings are particularly concerning in safety-critical applications like autonomous driving. In this paper, we address these limitations by introducing Symbolic Imitation Learning (SIL), a groundbreaking method that employs Inductive Logic Programming (ILP) to learn driving policies which are transparent, explainable and generalisable from available datasets. Utilizing the real-world highD dataset, we subject our method to a rigorous comparative analysis against prevailing neural-network-based IL methods. Our results demonstrate that SIL not only enhances the interpretability of driving policies but also significantly improves their applicability across varied driving situations. Hence, this work offers a novel pathway to more reliable and safer autonomous driving systems, underscoring the potential of integrating ILP into the domain of IL.", "url": "https://arxiv.org/abs/2309.16025"}, {"metadata": {"arXiv": "2309.16042", "Date": "Wed, 27 Sep 2023 21:53:56 ", "Title": "Towards Best Practices of Activation Patching in Language Models: Metrics and Methods", "Authors": ["Fred Zhang and Neel Nanda"], "Categories": "cs.LG cs.AI cs.CL", "Comments": ["27 pages"]}, "abstract": "Mechanistic interpretability seeks to understand the internal mechanisms of machine learning models, where localization -- identifying the important model components -- is a key step. Activation patching, also known as causal tracing or interchange intervention, is a standard technique for this task (Vig et al., 2020), but the literature contains many variants with little consensus on the choice of hyperparameters or methodology. In this work, we systematically examine the impact of methodological details in activation patching, including evaluation metrics and corruption methods. In several settings of localization and circuit discovery in language models, we find that varying these hyperparameters could lead to disparate interpretability results. Backed by empirical observations, we give conceptual arguments for why certain metrics or methods may be preferred. Finally, we provide recommendations for the best practices of activation patching going forwards.", "url": "https://arxiv.org/abs/2309.16042"}, {"metadata": {"arXiv": "2309.16096", "Date": "Thu, 28 Sep 2023 01:39:47 ", "Title": "Adversarial Examples Might be Avoidable: The Role of Data Concentration in Adversarial Robustness", "Authors": ["Ambar Pal", "Jeremias Sulam", "Ren\\'e Vidal"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted to Neural Information Processing Systems (NeurIPS) 2023"]}, "abstract": "The susceptibility of modern machine learning classifiers to adversarial examples has motivated theoretical results suggesting that these might be unavoidable. However, these results can be too general to be applicable to natural data distributions. Indeed, humans are quite robust for tasks involving vision. This apparent conflict motivates a deeper dive into the question: Are adversarial examples truly unavoidable? In this work, we theoretically demonstrate that a key property of the data distribution -- concentration on small-volume subsets of the input space -- determines whether a robust classifier exists. We further demonstrate that, for a data distribution concentrated on a union of low-dimensional linear subspaces, exploiting data structure naturally leads to classifiers that enjoy good robustness guarantees, improving upon methods for provable certification in certain regimes.", "url": "https://arxiv.org/abs/2309.16096"}, {"metadata": {"arXiv": "2309.16117", "Date": "Thu, 28 Sep 2023 02:48:13 ", "Title": "E2Net: Resource-Efficient Continual Learning with Elastic Expansion Network", "Authors": ["RuiQi Liu", "Boyu Diao", "Libo Huang", "Zhulin An and Yongjun Xu"], "Categories": "cs.LG cs.AI"}, "abstract": "Continual Learning methods are designed to learn new tasks without erasing previous knowledge. However, Continual Learning often requires massive computational power and storage capacity for satisfactory performance. In this paper, we propose a resource-efficient continual learning method called the Elastic Expansion Network (E2Net). Leveraging core subnet distillation and precise replay sample selection, E2Net achieves superior average accuracy and diminished forgetting within the same computational and storage constraints, all while minimizing processing time. In E2Net, we propose Representative Network Distillation to identify the representative core subnet by assessing parameter quantity and output similarity with the working network, distilling analogous subnets within the working network to mitigate reliance on rehearsal buffers and facilitating knowledge transfer across previous tasks. To enhance storage resource utilization, we then propose Subnet Constraint Experience Replay to optimize rehearsal efficiency through a sample storage strategy based on the structures of representative networks. Extensive experiments conducted predominantly on cloud environments with diverse datasets and also spanning the edge environment demonstrate that E2Net consistently outperforms state-of-the-art methods. In addition, our method outperforms competitors in terms of both storage and computational requirements.", "url": "https://arxiv.org/abs/2309.16117"}, {"metadata": {"arXiv": "2309.16119", "Date": "Thu, 28 Sep 2023 02:55:01 ", "Title": "ModuLoRA: Finetuning 3-Bit LLMs on Consumer GPUs by Integrating with Modular Quantizers", "Authors": ["Junjie Yin", "Jiahao Dong", "Yingheng Wang", "Christopher De Sa", "Volodymyr Kuleshov"], "Categories": "cs.LG cs.AI"}, "abstract": "We propose a memory-efficient finetuning algorithm for large language models (LLMs) that supports finetuning LLMs with 65B parameters in 3-bit or 4-bit precision on as little as one 48GB GPU. Our method, modular low-rank adaptation (ModuLoRA), integrates any user-specified weight quantizer with finetuning via low-rank adapters (LoRAs). Our approach relies on a simple quantization-agnostic backward pass that adaptively materializes low-precision LLM weights from a custom black-box quantization module. This approach enables finetuning 3-bit LLMs for the first time--leveraging state-of-the-art 3-bit OPTQ quantization often outperforms finetuning that relies on less sophisticated 4-bit and 8-bit methods. In our experiments, ModuLoRA attains competitive performance on text classification, natural language infernece, and instruction following tasks using significantly less memory than existing approaches, and we also surpass the state-of-the-art ROUGE score on a popular summarization task. We release ModuLoRA together with a series of low-precision models--including the first family of 3-bit instruction following Alpaca LLMs--as part of LLMTOOLS, a user-friendly library for quantizing, running, and finetuning LLMs on consumer GPUs.", "url": "https://arxiv.org/abs/2309.16119"}, {"metadata": {"arXiv": "2309.16143", "Date": "Thu, 28 Sep 2023 03:47:26 ", "Title": "Generative Semi-supervised Learning with Meta-Optimized Synthetic Samples", "Authors": ["Shin'ya Yamaguchi"], "Categories": "cs.LG cs.AI cs.CV stat.ML", "Comments": ["Accepted to the 15th Asian Conference on Machine Learning (ACML2023); a preprint of the camera-ready version"]}, "abstract": "Semi-supervised learning (SSL) is a promising approach for training deep classification models using labeled and unlabeled datasets. However, existing SSL methods rely on a large unlabeled dataset, which may not always be available in many real-world applications due to legal constraints (e.g., GDPR). In this paper, we investigate the research question: Can we train SSL models without real unlabeled datasets? Instead of using real unlabeled datasets, we propose an SSL method using synthetic datasets generated from generative foundation models trained on datasets containing millions of samples in diverse domains (e.g., ImageNet). Our main concepts are identifying synthetic samples that emulate unlabeled samples from generative foundation models and training classifiers using these synthetic samples. To achieve this, our method is formulated as an alternating optimization problem: (i) meta-learning of generative foundation models and (ii) SSL of classifiers using real labeled and synthetic unlabeled samples. For (i), we propose a meta-learning objective that optimizes latent variables to generate samples that resemble real labeled samples and minimize the validation loss. For (ii), we propose a simple unsupervised loss function that regularizes the feature extractors of classifiers to maximize the performance improvement obtained from synthetic samples. We confirm that our method outperforms baselines using generative foundation models on SSL. We also demonstrate that our methods outperform SSL using real unlabeled datasets in scenarios with extremely small amounts of labeled datasets. This suggests that synthetic samples have the potential to provide improvement gains more efficiently than real unlabeled data.", "url": "https://arxiv.org/abs/2309.16143"}, {"metadata": {"arXiv": "2309.16220", "Date": "Thu, 28 Sep 2023 07:52:01 ", "Title": "Unmasking the Chameleons: A Benchmark for Out-of-Distribution Detection in Medical Tabular Data", "Authors": ["Mohammad Azizmalayeri", "Ameen Abu-Hanna", "Giovanni Cin\\'a"], "Categories": "cs.LG cs.AI"}, "abstract": "Despite their success, Machine Learning (ML) models do not generalize effectively to data not originating from the training distribution. To reliably employ ML models in real-world healthcare systems and avoid inaccurate predictions on out-of-distribution (OOD) data, it is crucial to detect OOD samples. Numerous OOD detection approaches have been suggested in other fields - especially in computer vision - but it remains unclear whether the challenge is resolved when dealing with medical tabular data. To answer this pressing need, we propose an extensive reproducible benchmark to compare different methods across a suite of tests including both near and far OODs. Our benchmark leverages the latest versions of eICU and MIMIC-IV, two public datasets encompassing tens of thousands of ICU patients in several hospitals. We consider a wide array of density-based methods and SOTA post-hoc detectors across diverse predictive architectures, including MLP, ResNet, and Transformer. Our findings show that i) the problem appears to be solved for far-OODs, but remains open for near-OODs; ii) post-hoc methods alone perform poorly, but improve substantially when coupled with distance-based mechanisms; iii) the transformer architecture is far less overconfident compared to MLP and ResNet.", "url": "https://arxiv.org/abs/2309.16220"}, {"metadata": {"arXiv": "2309.16240", "Date": "Thu, 28 Sep 2023 08:29:44 ", "Title": "Beyond Reverse KL: Generalizing Direct Preference Optimization with Diverse Divergence Constraints", "Authors": ["Chaoqi Wang", "Yibo Jiang", "Chenghao Yang", "Han Liu", "Yuxin Chen"], "Categories": "cs.LG cs.AI stat.ML", "Comments": ["Preprint"]}, "abstract": "The increasing capabilities of large language models (LLMs) raise opportunities for artificial general intelligence but concurrently amplify safety concerns, such as potential misuse of AI systems, necessitating effective AI alignment. Reinforcement Learning from Human Feedback (RLHF) has emerged as a promising pathway towards AI alignment but brings forth challenges due to its complexity and dependence on a separate reward model. Direct Preference Optimization (DPO) has been proposed as an alternative, and it remains equivalent to RLHF under the reverse KL regularization constraint. This paper presents $f$-DPO, a generalized approach to DPO by incorporating diverse divergence constraints. We show that under certain $f$-divergences, including Jensen-Shannon divergence, forward KL divergences and $\\alpha$-divergences, the complex relationship between the reward and optimal policy can also be simplified by addressing the Karush-Kuhn-Tucker conditions. This eliminates the need for estimating the normalizing constant in the Bradley-Terry model and enables a tractable mapping between the reward function and the optimal policy. Our approach optimizes LLMs to align with human preferences in a more efficient and supervised manner under a broad set of divergence constraints. Empirically, adopting these divergences ensures a balance between alignment performance and generation diversity. Importantly, $f$-DPO outperforms PPO-based methods in divergence efficiency, and divergence constraints directly influence expected calibration error (ECE).", "url": "https://arxiv.org/abs/2309.16240"}, {"metadata": {"arXiv": "2309.16286", "Date": "Thu, 28 Sep 2023 09:32:27 ", "Title": "Generalizable Heterogeneous Federated Cross-Correlation and Instance Similarity Learning", "Authors": ["Wenke Huang", "Mang Ye", "Zekun Shi", "Bo Du"], "Categories": "cs.LG cs.AI"}, "abstract": "Federated learning is an important privacy-preserving multi-party learning paradigm, involving collaborative learning with others and local updating on private data. Model heterogeneity and catastrophic forgetting are two crucial challenges, which greatly limit the applicability and generalizability. This paper presents a novel FCCL+, federated correlation and similarity learning with non-target distillation, facilitating the both intra-domain discriminability and inter-domain generalization. For heterogeneity issue, we leverage irrelevant unlabeled public data for communication between the heterogeneous participants. We construct cross-correlation matrix and align instance similarity distribution on both logits and feature levels, which effectively overcomes the communication barrier and improves the generalizable ability. For catastrophic forgetting in local updating stage, FCCL+ introduces Federated Non Target Distillation, which retains inter-domain knowledge while avoiding the optimization conflict issue, fulling distilling privileged inter-domain information through depicting posterior classes relation. Considering that there is no standard benchmark for evaluating existing heterogeneous federated learning under the same setting, we present a comprehensive benchmark with extensive representative methods under four domain shift scenarios, supporting both heterogeneous and homogeneous federated settings. Empirical results demonstrate the superiority of our method and the efficiency of modules on various scenarios.", "url": "https://arxiv.org/abs/2309.16286"}, {"metadata": {"arXiv": "2309.16291", "Date": "Thu, 28 Sep 2023 09:38:27 ", "Title": "Efficiency Separation between RL Methods: Model-Free, Model-Based and Goal-Conditioned", "Authors": ["Brieuc Pinon", "Rapha\\\"el Jungers", "Jean-Charles Delvenne"], "Categories": "cs.LG cs.AI"}, "abstract": "We prove a fundamental limitation on the efficiency of a wide class of Reinforcement Learning (RL) algorithms. This limitation applies to model-free RL methods as well as a broad range of model-based methods, such as planning with tree search. Under an abstract definition of this class, we provide a family of RL problems for which these methods suffer a lower bound exponential in the horizon for their interactions with the environment to find an optimal behavior. However, there exists a method, not tailored to this specific family of problems, which can efficiently solve the problems in the family. In contrast, our limitation does not apply to several types of methods proposed in the literature, for instance, goal-conditioned methods or other algorithms that construct an inverse dynamics model.", "url": "https://arxiv.org/abs/2309.16291"}, {"metadata": {"arXiv": "2309.16335", "Date": "Thu, 28 Sep 2023 10:47:40 ", "Title": "End-to-end Risk Prediction of Atrial Fibrillation from the 12-Lead ECG by Deep Neural Networks", "Authors": ["Theogene Habineza", "Ant\\^onio H. Ribeiro", "Daniel Gedon", "Joachim A. Behar", "Antonio Luiz P. Ribeiro", "Thomas B. Sch\\\"on"], "Categories": "cs.LG cs.AI q-bio.QM stat.AP", "Comments": ["16 pages with 7 figures"], "Journal-ref": "@article{HABINEZA2023193, journal = {Journal of Electrocardiology}, volume = {81}, pages = {193-200}, year = {2023}, issn = {0022-0736}}", "DOI": "10.1016/j.jelectrocard.2023.09.011"}, "abstract": "Background: Atrial fibrillation (AF) is one of the most common cardiac arrhythmias that affects millions of people each year worldwide and it is closely linked to increased risk of cardiovascular diseases such as stroke and heart failure. Machine learning methods have shown promising results in evaluating the risk of developing atrial fibrillation from the electrocardiogram. We aim to develop and evaluate one such algorithm on a large CODE dataset collected in Brazil. Results: The deep neural network model identified patients without indication of AF in the presented ECG but who will develop AF in the future with an AUC score of 0.845. From our survival model, we obtain that patients in the high-risk group (i.e. with the probability of a future AF case being greater than 0.7) are 50% more likely to develop AF within 40 weeks, while patients belonging to the minimal-risk group (i.e. with the probability of a future AF case being less than or equal to 0.1) have more than 85% chance of remaining AF free up until after seven years. Conclusion: We developed and validated a model for AF risk prediction. If applied in clinical practice, the model possesses the potential of providing valuable and useful information in decision-making and patient management processes.", "url": "https://arxiv.org/abs/2309.16335"}, {"metadata": {"arXiv": "2309.16391", "Date": "Thu, 28 Sep 2023 12:38:47 ", "Title": "Differential 2D Copula Approximating Transforms via Sobolev Training: 2-Cats Networks", "Authors": ["Flavio Figueiredo", "Jos\\'e Geraldo Fernandes", "Jackson Silva", "Renato M. Assun\\c{c}\\~ao"], "Categories": "cs.LG cs.AI"}, "abstract": "Copulas are a powerful statistical tool that captures dependencies across data dimensions. When applying Copulas, we can estimate multivariate distribution functions by initially estimating independent marginals, an easy task, and then a single copulating function, $C$, to connect the marginals, a hard task. For two-dimensional data, a copula is a two-increasing function of the form $C: (u,v)\\in \\mathbf{I}^2 \\rightarrow \\mathbf{I}$, where $\\mathbf{I} = [0, 1]$. In this paper, we show how Neural Networks (NNs) can approximate any two-dimensional copula non-parametrically. Our approach, denoted as 2-Cats, is inspired by the Physics-Informed Neural Networks and Sobolev Training literature. Not only do we show that we can estimate the output of a 2d Copula better than the state-of-the-art, our approach is non-parametric and respects the mathematical properties of a Copula $C$.", "url": "https://arxiv.org/abs/2309.16391"}, {"metadata": {"arXiv": "2309.16397", "Date": "Thu, 28 Sep 2023 12:44:51 ", "Title": "Uncertainty-Aware Decision Transformer for Stochastic Driving Environments", "Authors": ["Zenan Li", "Fan Nie", "Qiao Sun", "Fang Da", "Hang Zhao"], "Categories": "cs.LG cs.AI"}, "abstract": "Offline Reinforcement Learning (RL) has emerged as a promising framework for learning policies without active interactions, making it especially appealing for autonomous driving tasks. Recent successes of Transformers inspire casting offline RL as sequence modeling, which performs well in long-horizon tasks. However, they are overly optimistic in stochastic environments with incorrect assumptions that the same goal can be consistently achieved by identical actions. In this paper, we introduce an UNcertainty-awaRE deciSion Transformer (UNREST) for planning in stochastic driving environments without introducing additional transition or complex generative models. Specifically, UNREST estimates state uncertainties by the conditional mutual information between transitions and returns, and segments sequences accordingly. Discovering the `uncertainty accumulation' and `temporal locality' properties of driving environments, UNREST replaces the global returns in decision transformers with less uncertain truncated returns, to learn from true outcomes of agent actions rather than environment transitions. We also dynamically evaluate environmental uncertainty during inference for cautious planning. Extensive experimental results demonstrate UNREST's superior performance in various driving scenarios and the power of our uncertainty estimation strategy.", "url": "https://arxiv.org/abs/2309.16397"}, {"metadata": {"arXiv": "2309.16429", "Date": "Thu, 28 Sep 2023 13:26:26 ", "Title": "Diverse and Aligned Audio-to-Video Generation via Text-to-Video Model Adaptation", "Authors": ["Guy Yariv", "Itai Gat", "Sagie Benaim", "Lior Wolf", "Idan Schwartz", "Yossi Adi"], "Categories": "cs.LG cs.AI", "Comments": ["9 pages", "6 figures"]}, "abstract": "We consider the task of generating diverse and realistic videos guided by natural audio samples from a wide variety of semantic classes. For this task, the videos are required to be aligned both globally and temporally with the input audio: globally, the input audio is semantically associated with the entire output video, and temporally, each segment of the input audio is associated with a corresponding segment of that video. We utilize an existing text-conditioned video generation model and a pre-trained audio encoder model. The proposed method is based on a lightweight adaptor network, which learns to map the audio-based representation to the input representation expected by the text-to-video generation model. As such, it also enables video generation conditioned on text, audio, and, for the first time as far as we can ascertain, on both text and audio. We validate our method extensively on three datasets demonstrating significant semantic diversity of audio-video samples and further propose a novel evaluation metric (AV-Align) to assess the alignment of generated videos with input audio samples. AV-Align is based on the detection and comparison of energy peaks in both modalities. In comparison to recent state-of-the-art approaches, our method generates videos that are better aligned with the input sound, both with respect to content and temporal axis. We also show that videos produced by our method present higher visual quality and are more diverse.", "url": "https://arxiv.org/abs/2309.16429"}, {"metadata": {"arXiv": "2309.16512", "Date": "Thu, 28 Sep 2023 15:19:30 ", "Title": "From Complexity to Clarity: Analytical Expressions of Deep Neural Network Weights via Clifford's Geometric Algebra and Convexity", "Authors": ["Mert Pilanci"], "Categories": "cs.LG cs.AI cs.NE math.OC stat.ML"}, "abstract": "In this paper, we introduce a novel analysis of neural networks based on geometric (Clifford) algebra and convex optimization. We show that optimal weights of deep ReLU neural networks are given by the wedge product of training samples when trained with standard regularized loss. Furthermore, the training problem reduces to convex optimization over wedge product features, which encode the geometric structure of the training dataset. This structure is given in terms of signed volumes of triangles and parallelotopes generated by data vectors. The convex problem finds a small subset of samples via $\\ell_1$ regularization to discover only relevant wedge product features. Our analysis provides a novel perspective on the inner workings of deep neural networks and sheds light on the role of the hidden layers.", "url": "https://arxiv.org/abs/2309.16512"}, {"metadata": {"arXiv": "2309.16564", "Date": "Thu, 28 Sep 2023 16:21:40 ", "Title": "Augment to Interpret: Unsupervised and Inherently Interpretable Graph Embeddings", "Authors": ["Gregory Scafarto and Madalina Ciortan and Simon Tihon and Quentin Ferre"], "Categories": "cs.LG cs.AI"}, "abstract": "Unsupervised learning allows us to leverage unlabelled data, which has become abundantly available, and to create embeddings that are usable on a variety of downstream tasks. However, the typical lack of interpretability of unsupervised representation learning has become a limiting factor with regard to recent transparent-AI regulations. In this paper, we study graph representation learning and we show that data augmentation that preserves semantics can be learned and used to produce interpretations. Our framework, which we named INGENIOUS, creates inherently interpretable embeddings and eliminates the need for costly additional post-hoc analysis. We also introduce additional metrics addressing the lack of formalism and metrics in the understudied area of unsupervised-representation learning interpretability. Our results are supported by an experimental study applied to both graph-level and node-level tasks and show that interpretable embeddings provide state-of-the-art performance on subsequent downstream tasks.", "url": "https://arxiv.org/abs/2309.16564"}, {"metadata": {"arXiv": "2309.16595", "Date": "Thu, 28 Sep 2023 16:58:37 ", "Title": "Can LLMs Effectively Leverage Structural Information for Graph Learning: When and Why", "Authors": ["Jin Huang", "Xingjian Zhang", "Qiaozhu Mei", "Jiaqi Ma"], "Categories": "cs.LG cs.AI"}, "abstract": "This paper studies Large Language Models (LLMs) for structured data--particularly graphs--a crucial data modality that remains underexplored in the LLM literature. We aim to understand when and why the incorporation of structural information inherent in graph data can improve the prediction performance of LLMs on node classification tasks. To address the ``when'' question, we examine a variety of prompting methods for encoding structural information, in settings where textual node features are either rich or scarce. For the ``why'' questions, we probe into two potential contributing factors to the LLM performance: data leakage and homophily. Our exploration of these questions reveals that (i) LLMs can benefit from structural information, especially when textual node features are scarce; (ii) there is no substantial evidence indicating that the performance of LLMs is significantly attributed to data leakage; and (iii) the performance of LLMs on a target node is strongly positively related to the local homophily ratio of the node.", "url": "https://arxiv.org/abs/2309.16595"}, {"metadata": {"arXiv": "2309.16597", "Date": "Thu, 28 Sep 2023 17:01:43 ", "Title": "Transfer Learning for Bayesian Optimization on Heterogeneous Search Spaces", "Authors": ["Zhou Fan", "Xinran Han", "Zi Wang"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "Bayesian optimization (BO) is a popular black-box function optimization method, which makes sequential decisions based on a Bayesian model, typically a Gaussian process (GP), of the function. To ensure the quality of the model, transfer learning approaches have been developed to automatically design GP priors by learning from observations on \"training\" functions. These training functions are typically required to have the same domain as the \"test\" function (black-box function to be optimized). In this paper, we introduce MPHD, a model pre-training method on heterogeneous domains, which uses a neural net mapping from domain-specific contexts to specifications of hierarchical GPs. MPHD can be seamlessly integrated with BO to transfer knowledge across heterogeneous search spaces. Our theoretical and empirical results demonstrate the validity of MPHD and its superior performance on challenging black-box function optimization tasks.", "url": "https://arxiv.org/abs/2309.16597"}, {"metadata": {"arXiv": "2309.16633", "Date": "Thu, 28 Sep 2023 17:38:59 ", "Title": "Mixup Your Own Pairs", "Authors": ["Yilei Wu", "Zijian Dong", "Chongyao Chen", "Wangchunshu Zhou", "Juan Helen Zhou"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["The first two authors equally contributed to this work"]}, "abstract": "In representation learning, regression has traditionally received less attention than classification. Directly applying representation learning techniques designed for classification to regression often results in fragmented representations in the latent space, yielding sub-optimal performance. In this paper, we argue that the potential of contrastive learning for regression has been overshadowed due to the neglect of two crucial aspects: ordinality-awareness and hardness. To address these challenges, we advocate \"mixup your own contrastive pairs for supervised contrastive regression\", instead of relying solely on real/augmented samples. Specifically, we propose Supervised Contrastive Learning for Regression with Mixup (SupReMix). It takes anchor-inclusive mixtures (mixup of the anchor and a distinct negative sample) as hard negative pairs and anchor-exclusive mixtures (mixup of two distinct negative samples) as hard positive pairs at the embedding level. This strategy formulates harder contrastive pairs by integrating richer ordinal information. Through extensive experiments on six regression datasets including 2D images, volumetric images, text, tabular data, and time-series signals, coupled with theoretical analysis, we demonstrate that SupReMix pre-training fosters continuous ordered representations of regression data, resulting in significant improvement in regression performance. Furthermore, SupReMix is superior to other approaches in a range of regression challenges including transfer learning, imbalanced training data, and scenarios with fewer training samples.", "url": "https://arxiv.org/abs/2309.16633"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2308.13712", "Date": "Fri, 25 Aug 2023 23:54:15 ", "Title": "Residual Denoising Diffusion Models", "Authors": ["Jiawei Liu", "Qiang Wang", "Huijie Fan", "Yinong Wang", "Yandong Tang", "Liangqiong Qu"], "Categories": "cs.CV cs.LG"}, "abstract": "Current diffusion-based image restoration methods feed degraded input images as conditions into the noise estimation network. However, interpreting this diffusion process is challenging since it essentially generates the target image from the noise. To establish a unified and more interpretable model for image generation and restoration, we propose residual denoising diffusion models (RDDM). In contrast to existing diffusion models (e.g., DDPM or DDIM) that focus solely on noise estimation, our RDDM predicts residuals to represent directional diffusion from the target domain to the input domain, while concurrently estimating noise to account for random perturbations in the diffusion process. The introduction of residuals allows us to redefine the forward diffusion process, wherein the target image progressively diffuses into a purely noisy image or a noise-carrying input image, thus unifying image generation and restoration. We demonstrate that our sampling process is consistent with that of DDPM and DDIM through coefficient transformation, and propose a partially path-independent generation process to better understand the reverse process. Notably, with native support for conditional inputs, our RDDM enables a generic UNet, trained with only an $\\ell _1$ loss and a batch size of 1, to compete with state-of-the-art image restoration methods. We provide code and pre-trained models to encourage further exploration, application, and development of our innovative framework (https://github.com/nachifur/RDDM).", "url": "https://arxiv.org/abs/2308.13712"}, {"metadata": {"arXiv": "2308.13769", "Date": "Sat, 26 Aug 2023 05:29:09 ", "Title": "Bengali Document Layout Analysis with Detectron2", "Authors": ["Md Ataullha and Mahedi Hassan Rabby and Mushfiqur Rahman and Tahsina Bintay Azam"], "Categories": "cs.CV cs.LG", "Comments": ["DL Sprint 2.0 - BUET CSE Fest 2023", "4 pages", "2 figures", "2 tables"], "ACM-class": "I.4; I.4.6; I.7"}, "abstract": "Document digitization is vital for preserving historical records, efficient document management, and advancing OCR (Optical Character Recognition) research. Document Layout Analysis (DLA) involves segmenting documents into meaningful units like text boxes, paragraphs, images, and tables. Challenges arise when dealing with diverse layouts, historical documents, and unique scripts like Bengali, hindered by the lack of comprehensive Bengali DLA datasets. We improved the accuracy of the DLA model for Bengali documents by utilizing advanced Mask R-CNN models available in the Detectron2 library. Our evaluation involved three variants: Mask R-CNN R-50, R-101, and X-101, both with and without pretrained weights from PubLayNet, on the BaDLAD dataset, which contains human-annotated Bengali documents in four categories: text boxes, paragraphs, images, and tables. Results show the effectiveness of these models in accurately segmenting Bengali documents. We discuss speed-accuracy tradeoffs and underscore the significance of pretrained weights. Our findings expand the applicability of Mask R-CNN in document layout analysis, efficient document management, and OCR research while suggesting future avenues for fine-tuning and data augmentation.", "url": "https://arxiv.org/abs/2308.13769"}, {"metadata": {"arXiv": "2308.13888", "Date": "Sat, 26 Aug 2023 14:12:19 ", "Title": "Neural Implicit Morphing of Face Images", "Authors": ["Guilherme Schardong", "Tiago Novello", "Daniel Perazzo", "Hallison Paz", "Iurii Medvedev", "Luiz Velho", "Nuno Gon\\c{c}alves"], "Categories": "cs.CV cs.LG", "Comments": ["17 pages", "11 figures"], "ACM-class": "I.4.8; I.4.10"}, "abstract": "Face morphing is one of the seminal problems in computer graphics, with numerous artistic and forensic applications. It is notoriously challenging due to pose, lighting, gender, and ethnicity variations. Generally, this task consists of a warping for feature alignment and a blending for a seamless transition between the warped images. We propose to leverage coordinate-based neural networks to represent such warpings and blendings of face images. During training, we exploit the smoothness and flexibility of such networks, by combining energy functionals employed in classical approaches without discretizations. Additionally, our method is time-dependent, allowing a continuous warping, and blending of the target images. During warping inference, we need both direct and inverse transformations of the time-dependent warping. The first is responsible for morphing the target image into the source image, while the inverse is used for morphing in the opposite direction. Our neural warping stores those maps in a single network due to its inversible property, dismissing the hard task of inverting them. The results of our experiments indicate that our method is competitive with both classical and data-based neural techniques under the lens of face-morphing detection approaches. Aesthetically, the resulting images present a seamless blending of diverse faces not yet usual in the literature.", "url": "https://arxiv.org/abs/2308.13888"}, {"metadata": {"arXiv": "2308.13900", "Date": "Sat, 26 Aug 2023 15:02:00 ", "Title": "Semi-Supervised Semantic Segmentation via Marginal Contextual Information", "Authors": ["Moshe Kimhi", "Shai Kimhi", "Evgenii Zheltonozhskii", "Or Litany", "Chaim Baskin"], "Categories": "cs.CV cs.LG"}, "abstract": "We present a novel confidence refinement scheme that enhances pseudo-labels in semi-supervised semantic segmentation. Unlike current leading methods, which filter pixels with low-confidence predictions in isolation, our approach leverages the spatial correlation of labels in segmentation maps by grouping neighboring pixels and considering their pseudo-labels collectively. With this contextual information, our method, named S4MC, increases the amount of unlabeled data used during training while maintaining the quality of the pseudo-labels, all with negligible computational overhead. Through extensive experiments on standard benchmarks, we demonstrate that S4MC outperforms existing state-of-the-art semi-supervised learning approaches, offering a promising solution for reducing the cost of acquiring dense annotations. For example, S4MC achieves a 1.29 mIoU improvement over the prior state-of-the-art method on PASCAL VOC 12 with 366 annotated images. The code to reproduce our experiments is available at https://s4mcontext.github.io/", "url": "https://arxiv.org/abs/2308.13900"}, {"metadata": {"arXiv": "2308.13991", "Date": "Sun, 27 Aug 2023 02:59:59 ", "Title": "JL-lemma derived Optimal Projections for Discriminative Dictionary Learning", "Authors": ["G.Madhuri", "Atul Negi"], "Categories": "cs.CV cs.LG eess.SP"}, "abstract": "To overcome difficulties in classifying large dimensionality data with a large number of classes, we propose a novel approach called JLSPCADL. This paper uses the Johnson-Lindenstrauss (JL) Lemma to select the dimensionality of a transformed space in which a discriminative dictionary can be learned for signal classification. Rather than reducing dimensionality via random projections, as is often done with JL, we use a projection transformation matrix derived from Modified Supervised PC Analysis (M-SPCA) with the JL-prescribed dimension. JLSPCADL provides a heuristic to deduce suitable distortion levels and the corresponding Suitable Description Length (SDL) of dictionary atoms to derive an optimal feature space and thus the SDL of dictionary atoms for better classification. Unlike state-of-the-art dimensionality reduction-based dictionary learning methods, a projection transformation matrix derived in a single step from M-SPCA provides maximum feature-label consistency of the transformed space while preserving the cluster structure of the original data. Despite confusing pairs, the dictionary for the transformed space generates discriminative sparse coefficients, with fewer training samples. Experimentation demonstrates that JLSPCADL scales well with an increasing number of classes and dimensionality. Improved label consistency of features due to M-SPCA helps to classify better. Further, the complexity of training a discriminative dictionary is significantly reduced by using SDL. Experimentation on OCR and face recognition datasets shows relatively better classification performance than other supervised dictionary learning algorithms.", "url": "https://arxiv.org/abs/2308.13991"}, {"metadata": {"arXiv": "2308.14030", "Date": "Sun, 27 Aug 2023 07:47:38 ", "Title": "Forensic Histopathological Recognition via a Context-Aware MIL Network Powered by Self-Supervised Contrastive Learning", "Authors": ["Chen Shen and Jun Zhang and Xinggong Liang and Zeyi Hao and Kehan Li and Fan Wang and Zhenyuan Wang and Chunfeng Lian"], "Categories": "cs.CV cs.LG", "Comments": ["11 pages", "2 figures"]}, "abstract": "Forensic pathology is critical in analyzing death manner and time from the microscopic aspect to assist in the establishment of reliable factual bases for criminal investigation. In practice, even the manual differentiation between different postmortem organ tissues is challenging and relies on expertise, considering that changes like putrefaction and autolysis could significantly change typical histopathological appearance. Developing AI-based computational pathology techniques to assist forensic pathologists is practically meaningful, which requires reliable discriminative representation learning to capture tissues' fine-grained postmortem patterns. To this end, we propose a framework called FPath, in which a dedicated self-supervised contrastive learning strategy and a context-aware multiple-instance learning (MIL) block are designed to learn discriminative representations from postmortem histopathological images acquired at varying magnification scales. Our self-supervised learning step leverages multiple complementary contrastive losses and regularization terms to train a double-tier backbone for fine-grained and informative patch/instance embedding. Thereafter, the context-aware MIL adaptively distills from the local instances a holistic bag/image-level representation for the recognition task. On a large-scale database of $19,607$ experimental rat postmortem images and $3,378$ real-world human decedent images, our FPath led to state-of-the-art accuracy and promising cross-domain generalization in recognizing seven different postmortem tissues. The source code will be released on \\href{https://github.com/ladderlab-xjtu/forensic_pathology}{https://github.com/ladderlab-xjtu/forensic\\_pathology}.", "url": "https://arxiv.org/abs/2308.14030"}, {"metadata": {"arXiv": "2308.14119", "Date": "Sun, 27 Aug 2023 14:25:07 ", "Title": "Semi-Supervised Learning in the Few-Shot Zero-Shot Scenario", "Authors": ["Noam Fluss", "Guy Hacohen", "Daphna Weinshall"], "Categories": "cs.CV cs.LG"}, "abstract": "Semi-Supervised Learning (SSL) leverages both labeled and unlabeled data to improve model performance. Traditional SSL methods assume that labeled and unlabeled data share the same label space. However, in real-world applications, especially when the labeled training set is small, there may be classes that are missing from the labeled set. Existing frameworks aim to either reject all unseen classes (open-set SSL) or to discover unseen classes by partitioning an unlabeled set during training (open-world SSL). In our work, we construct a classifier for points from both seen and unseen classes. Our approach is based on extending an existing SSL method, such as FlexMatch, by incorporating an additional entropy loss. This enhancement allows our method to improve the performance of any existing SSL method in the classification of both seen and unseen classes. We demonstrate large improvement gains over state-of-the-art SSL, open-set SSL, and open-world SSL methods, on two benchmark image classification data sets, CIFAR-100 and STL-10. The gains are most pronounced when the labeled data is severely limited (1-25 labeled examples per class).", "url": "https://arxiv.org/abs/2308.14119"}, {"metadata": {"arXiv": "2308.14400", "Date": "Mon, 28 Aug 2023 08:33:45 ", "Title": "Semi-Supervised Semantic Depth Estimation using Symbiotic Transformer and NearFarMix Augmentation", "Authors": ["Md Awsafur Rahman and Shaikh Anowarul Fattah"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted at WACV 2024"]}, "abstract": "In computer vision, depth estimation is crucial for domains like robotics, autonomous vehicles, augmented reality, and virtual reality. Integrating semantics with depth enhances scene understanding through reciprocal information sharing. However, the scarcity of semantic information in datasets poses challenges. Existing convolutional approaches with limited local receptive fields hinder the full utilization of the symbiotic potential between depth and semantics. This paper introduces a dataset-invariant semi-supervised strategy to address the scarcity of semantic information. It proposes the Depth Semantics Symbiosis module, leveraging the Symbiotic Transformer for achieving comprehensive mutual awareness by information exchange within both local and global contexts. Additionally, a novel augmentation, NearFarMix is introduced to combat overfitting and compensate both depth-semantic tasks by strategically merging regions from two images, generating diverse and structurally consistent samples with enhanced control. Extensive experiments on NYU-Depth-V2 and KITTI datasets demonstrate the superiority of our proposed techniques in indoor and outdoor environments.", "url": "https://arxiv.org/abs/2308.14400"}, {"metadata": {"arXiv": "2308.14409", "Date": "Mon, 28 Aug 2023 08:47:06 ", "Title": "Steerable Conditional Diffusion for Out-of-Distribution Adaptation in Imaging Inverse Problems", "Authors": ["Riccardo Barbano", "Alexander Denker", "Hyungjin Chung", "Tae Hoon Roh", "Simon Arrdige", "Peter Maass", "Bangti Jin", "Jong Chul Ye"], "Categories": "cs.CV cs.LG"}, "abstract": "Denoising diffusion models have emerged as the go-to framework for solving inverse problems in imaging. A critical concern regarding these models is their performance on out-of-distribution (OOD) tasks, which remains an under-explored challenge. Realistic reconstructions inconsistent with the measured data can be generated, hallucinating image features that are uniquely present in the training dataset. To simultaneously enforce data-consistency and leverage data-driven priors, we introduce a novel sampling framework called Steerable Conditional Diffusion. This framework adapts the denoising network specifically to the available measured data. Utilising our proposed method, we achieve substantial enhancements in OOD performance across diverse imaging modalities, advancing the robust deployment of denoising diffusion models in real-world applications.", "url": "https://arxiv.org/abs/2308.14409"}, {"metadata": {"arXiv": "2308.14596", "Date": "Mon, 28 Aug 2023 14:08:42 ", "Title": "LatentDR: Improving Model Generalization Through Sample-Aware Latent Degradation and Restoration", "Authors": ["Ran Liu", "Sahil Khose", "Jingyun Xiao", "Lakshmi Sathidevi", "Keerthan Ramnath", "Zsolt Kira", "Eva L. Dyer"], "Categories": "cs.CV cs.LG"}, "abstract": "Despite significant advances in deep learning, models often struggle to generalize well to new, unseen domains, especially when training data is limited. To address this challenge, we propose a novel approach for distribution-aware latent augmentation that leverages the relationships across samples to guide the augmentation procedure. Our approach first degrades the samples stochastically in the latent space, mapping them to augmented labels, and then restores the samples from their corrupted versions during training. This process confuses the classifier in the degradation step and restores the overall class distribution of the original samples, promoting diverse intra-class/cross-domain variability. We extensively evaluate our approach on a diverse set of datasets and tasks, including domain generalization benchmarks and medical imaging datasets with strong domain shift, where we show our approach achieves significant improvements over existing methods for latent space augmentation. We further show that our method can be flexibly adapted to long-tail recognition tasks, demonstrating its versatility in building more generalizable models. Code is available at https://github.com/nerdslab/LatentDR.", "url": "https://arxiv.org/abs/2308.14596"}, {"metadata": {"arXiv": "2308.14597", "Date": "Mon, 28 Aug 2023 14:09:02 ", "Title": "Adversarial Attacks on Foundational Vision Models", "Authors": ["Nathan Inkawhich", "Gwendolyn McDonald", "Ryan Luley"], "Categories": "cs.CV cs.CR cs.LG"}, "abstract": "Rapid progress is being made in developing large, pretrained, task-agnostic foundational vision models such as CLIP, ALIGN, DINOv2, etc. In fact, we are approaching the point where these models do not have to be finetuned downstream, and can simply be used in zero-shot or with a lightweight probing head. Critically, given the complexity of working at this scale, there is a bottleneck where relatively few organizations in the world are executing the training then sharing the models on centralized platforms such as HuggingFace and torch.hub. The goal of this work is to identify several key adversarial vulnerabilities of these models in an effort to make future designs more robust. Intuitively, our attacks manipulate deep feature representations to fool an out-of-distribution (OOD) detector which will be required when using these open-world-aware models to solve closed-set downstream tasks. Our methods reliably make in-distribution (ID) images (w.r.t. a downstream task) be predicted as OOD and vice versa while existing in extremely low-knowledge-assumption threat models. We show our attacks to be potent in whitebox and blackbox settings, as well as when transferred across foundational model types (e.g., attack DINOv2 with CLIP)! This work is only just the beginning of a long journey towards adversarially robust foundational vision models.", "url": "https://arxiv.org/abs/2308.14597"}, {"metadata": {"arXiv": "2308.14666", "Date": "Thu, 24 Aug 2023 17:47:32 ", "Title": "Learning to predict 3D rotational dynamics from images of a rigid body with unknown mass distribution", "Authors": ["Justice Mason", "Christine Allen-Blanchette", "Nicholas Zolman", "Elizabeth Davison", "Naomi Ehrich Leonard"], "Categories": "cs.CV cs.CE cs.LG", "Comments": ["Previously appeared as arXiv:2209.11355v2", "which was submitted as a replacement by accident. arXiv admin note: text overlap with arXiv:2209.11355"]}, "abstract": "In many real-world settings, image observations of freely rotating 3D rigid bodies, may be available when low-dimensional measurements are not. However, the high-dimensionality of image data precludes the use of classical estimation techniques to learn the dynamics. The usefulness of standard deep learning methods is also limited because an image of a rigid body reveals nothing about the distribution of mass inside the body, which, together with initial angular velocity, is what determines how the body will rotate. We present a physics-informed neural network model to estimate and predict 3D rotational dynamics from image sequences. We achieve this using a multi-stage prediction pipeline that maps individual images to a latent representation homeomorphic to $\\mathbf{SO}(3)$, computes angular velocities from latent pairs, and predicts future latent states using the Hamiltonian equations of motion. We demonstrate the efficacy of our approach on new rotating rigid-body datasets of sequences of synthetic images of rotating objects, including cubes, prisms and satellites, with unknown uniform and non-uniform mass distributions.", "url": "https://arxiv.org/abs/2308.14666"}, {"metadata": {"arXiv": "2308.14740", "Date": "Mon, 28 Aug 2023 17:41:14 ", "Title": "Total Selfie: Generating Full-Body Selfies", "Authors": ["Bowei Chen", "Brian Curless", "Ira Kemelmacher-Shlizerman", "Steve Seitz"], "Categories": "cs.CV cs.GR cs.LG", "Comments": ["Project page: https://homes.cs.washington.edu/~boweiche/project_page/totalselfie/"]}, "abstract": "We present a method to generate full-body selfies -- photos that you take of yourself, but capturing your whole body as if someone else took the photo of you from a few feet away. Our approach takes as input a pre-captured video of your body, a target pose photo, and a selfie + background pair for each location. We introduce a novel diffusion-based approach to combine all of this information into high quality, well-composed photos of you with the desired pose and background.", "url": "https://arxiv.org/abs/2308.14740"}, {"metadata": {"arXiv": "2308.14753", "Date": "Mon, 28 Aug 2023 17:59:47 ", "Title": "Efficient Discovery and Effective Evaluation of Visual Perceptual Similarity: A Benchmark and Beyond", "Authors": ["Oren Barkan", "Tal Reiss", "Jonathan Weill", "Ori Katz", "Roy Hirsch", "Itzik Malkiel", "Noam Koenigstein"], "Categories": "cs.CV cs.LG", "Comments": ["ICCV 2023"]}, "abstract": "Visual similarities discovery (VSD) is an important task with broad e-commerce applications. Given an image of a certain object, the goal of VSD is to retrieve images of different objects with high perceptual visual similarity. Although being a highly addressed problem, the evaluation of proposed methods for VSD is often based on a proxy of an identification-retrieval task, evaluating the ability of a model to retrieve different images of the same object. We posit that evaluating VSD methods based on identification tasks is limited, and faithful evaluation must rely on expert annotations. In this paper, we introduce the first large-scale fashion visual similarity benchmark dataset, consisting of more than 110K expert-annotated image pairs. Besides this major contribution, we share insight from the challenges we faced while curating this dataset. Based on these insights, we propose a novel and efficient labeling procedure that can be applied to any dataset. Our analysis examines its limitations and inductive biases, and based on these findings, we propose metrics to mitigate those limitations. Though our primary focus lies on visual similarity, the methodologies we present have broader applications for discovering and evaluating perceptual similarity across various domains.", "url": "https://arxiv.org/abs/2308.14753"}, {"metadata": {"arXiv": "2308.13559", "Date": "Thu, 24 Aug 2023 17:27:01 ", "Title": "Machine Unlearning for Causal Inference", "Authors": ["Vikas Ramachandra and Mohit Sethi"], "Categories": "cs.LG"}, "abstract": "Machine learning models play a vital role in making predictions and deriving insights from data and are being increasingly used for causal inference. To preserve user privacy, it is important to enable the model to forget some of its learning/captured information about a given user (machine unlearning). This paper introduces the concept of machine unlearning for causal inference, particularly propensity score matching and treatment effect estimation, which aims to refine and improve the performance of machine learning models for causal analysis given the above unlearning requirements. The paper presents a methodology for machine unlearning using a neural network-based propensity score model. The dataset used in the study is the Lalonde dataset, a widely used dataset for evaluating the effectiveness i.e. the treatment effect of job training programs. The methodology involves training an initial propensity score model on the original dataset and then creating forget sets by selectively removing instances, as well as matched instance pairs. based on propensity score matching. These forget sets are used to evaluate the retrained model, allowing for the elimination of unwanted associations. The actual retraining of the model is performed using the retain set. The experimental results demonstrate the effectiveness of the machine unlearning approach. The distribution and histogram analysis of propensity scores before and after unlearning provide insights into the impact of the unlearning process on the data. This study represents the first attempt to apply machine unlearning techniques to causal inference.", "url": "https://arxiv.org/abs/2308.13559"}, {"metadata": {"arXiv": "2308.13646", "Date": "Fri, 25 Aug 2023 19:34:21 ", "Title": "GRASP: A Rehearsal Policy for Efficient Online Continual Learning", "Authors": ["Md Yousuf Harun", "Jhair Gallardo", "Christopher Kanan"], "Categories": "cs.LG cs.CL cs.CV"}, "abstract": "Continual learning (CL) in deep neural networks (DNNs) involves incrementally accumulating knowledge in a DNN from a growing data stream. A major challenge in CL is that non-stationary data streams cause catastrophic forgetting of previously learned abilities. Rehearsal is a popular and effective way to mitigate this problem, which is storing past observations in a buffer and mixing them with new observations during learning. This leads to a question: Which stored samples should be selected for rehearsal? Choosing samples that are best for learning, rather than simply selecting them at random, could lead to significantly faster learning. For class incremental learning, prior work has shown that a simple class balanced random selection policy outperforms more sophisticated methods. Here, we revisit this question by exploring a new sample selection policy called GRASP. GRASP selects the most prototypical (class representative) samples first and then gradually selects less prototypical (harder) examples to update the DNN. GRASP has little additional compute or memory overhead compared to uniform selection, enabling it to scale to large datasets. We evaluate GRASP and other policies by conducting CL experiments on the large-scale ImageNet-1K and Places-LT image classification datasets. GRASP outperforms all other rehearsal policies. Beyond vision, we also demonstrate that GRASP is effective for CL on five text classification datasets.", "url": "https://arxiv.org/abs/2308.13646"}, {"metadata": {"arXiv": "2308.13654", "Date": "Fri, 25 Aug 2023 19:58:17 ", "Title": "Pretty darn good control: when are approximate solutions better than approximate models", "Authors": ["Felipe Montealegre-Mora", "Marcus Lapeyrolerie", "Melissa Chapman", "Abigail G. Keller", "Carl Boettiger"], "Categories": "cs.LG", "Comments": ["24 pages", "14 figures. Accepted to the Bulletin of Mathematical Biology"], "MSC-class": "92-08, 92-04"}, "abstract": "Existing methods for optimal control struggle to deal with the complexity commonly encountered in real-world systems, including dimensionality, process error, model bias and data heterogeneity. Instead of tackling these system complexities directly, researchers have typically sought to simplify models to fit optimal control methods. But when is the optimal solution to an approximate, stylized model better than an approximate solution to a more accurate model? While this question has largely gone unanswered owing to the difficulty of finding even approximate solutions for complex models, recent algorithmic and computational advances in deep reinforcement learning (DRL) might finally allow us to address these questions. DRL methods have to date been applied primarily in the context of games or robotic mechanics, which operate under precisely known rules. Here, we demonstrate the ability for DRL algorithms using deep neural networks to successfully approximate solutions (the \"policy function\" or control rule) in a non-linear three-variable model for a fishery without knowing or ever attempting to infer a model for the process itself. We find that the reinforcement learning agent discovers an effective simplification of the problem to obtain an interpretable control rule. We show that the policy obtained with DRL is both more profitable and more sustainable than any constant mortality policy -- the standard family of policies considered in fishery management.", "url": "https://arxiv.org/abs/2308.13654"}, {"metadata": {"arXiv": "2308.13661", "Date": "Fri, 25 Aug 2023 20:30:20 ", "Title": "Go Beyond Imagination: Maximizing Episodic Reachability with World Models", "Authors": ["Yao Fu", "Run Peng", "Honglak Lee"], "Categories": "cs.LG", "Comments": ["Published in the 40th International Conference on Machine Learning"]}, "abstract": "Efficient exploration is a challenging topic in reinforcement learning, especially for sparse reward tasks. To deal with the reward sparsity, people commonly apply intrinsic rewards to motivate agents to explore the state space efficiently. In this paper, we introduce a new intrinsic reward design called GoBI - Go Beyond Imagination, which combines the traditional lifelong novelty motivation with an episodic intrinsic reward that is designed to maximize the stepwise reachability expansion. More specifically, we apply learned world models to generate predicted future states with random actions. States with more unique predictions that are not in episodic memory are assigned high intrinsic rewards. Our method greatly outperforms previous state-of-the-art methods on 12 of the most challenging Minigrid navigation tasks and improves the sample efficiency on locomotion tasks from DeepMind Control Suite.", "url": "https://arxiv.org/abs/2308.13661"}, {"metadata": {"arXiv": "2308.13662", "Date": "Fri, 25 Aug 2023 20:33:30 ", "Title": "Resource-Efficient Federated Learning for Heterogenous and Resource-Constrained Environments", "Authors": ["Humaid Ahmed Desai", "Amr Hilal", "Hoda Eldardiry"], "Categories": "cs.LG cs.DC", "Comments": ["9 pages", "6 figures"]}, "abstract": "Federated Learning (FL) is a privacy-enforcing sub-domain of machine learning that brings the model to the user's device for training, avoiding the need to share personal data with a central server. While existing works address data heterogeneity, they overlook other challenges in FL, such as device heterogeneity and communication efficiency. In this paper, we propose RE-FL, a novel approach that tackles computational and communication challenges in resource-constrained devices. Our variable pruning technique optimizes resource utilization by adapting pruning to each client's computational capabilities. We also employ knowledge distillation to reduce bandwidth consumption and communication rounds. Experimental results on image classification tasks demonstrate the effectiveness of our approach in resource-constrained environments, maintaining data privacy and performance while accommodating heterogeneous model architectures.", "url": "https://arxiv.org/abs/2308.13662"}, {"metadata": {"arXiv": "2308.13663", "Date": "Fri, 25 Aug 2023 20:35:45 ", "Title": "Network Embedding Using Sparse Approximations of Random Walks", "Authors": ["Paula Mercurio and Di Liu"], "Categories": "cs.LG", "Comments": ["20 pages", "4 figures"], "MSC-class": "05C81 (Primary) 68R10, 05C62 (Secondary)"}, "abstract": "In this paper, we propose an efficient numerical implementation of Network Embedding based on commute times, using sparse approximation of a diffusion process on the network obtained by a modified version of the diffusion wavelet algorithm. The node embeddings are computed by optimizing the cross entropy loss via the stochastic gradient descent method with sampling of low-dimensional representations of green functions. We demonstrate the efficacy of this method for data clustering and multi-label classification through several examples, and compare its performance over existing methods in terms of efficiency and accuracy. Theoretical issues justifying the scheme are also discussed.", "url": "https://arxiv.org/abs/2308.13663"}, {"metadata": {"arXiv": "2308.13670", "Date": "Fri, 25 Aug 2023 20:59:51 ", "Title": "Linear Oscillation: The Aesthetics of Confusion for Vision Transformer", "Authors": ["Juyoung Yun"], "Categories": "cs.LG cs.CV cs.NE"}, "abstract": "Activation functions are the linchpins of deep learning, profoundly influencing both the representational capacity and training dynamics of neural networks. They shape not only the nature of representations but also optimize convergence rates and enhance generalization potential. Appreciating this critical role, we present the Linear Oscillation (LoC) activation function, defined as $f(x) = x \\times \\sin(\\alpha x + \\beta)$. Distinct from conventional activation functions which primarily introduce non-linearity, LoC seamlessly blends linear trajectories with oscillatory deviations. The nomenclature ``Linear Oscillation'' is a nod to its unique attribute of infusing linear activations with harmonious oscillations, capturing the essence of the 'Importance of Confusion'. This concept of ``controlled confusion'' within network activations is posited to foster more robust learning, particularly in contexts that necessitate discerning subtle patterns. Our empirical studies reveal that, when integrated into diverse neural architectures, the LoC activation function consistently outperforms established counterparts like ReLU and Sigmoid. The stellar performance exhibited by the avant-garde Vision Transformer model using LoC further validates its efficacy. This study illuminates the remarkable benefits of the LoC over other prominent activation functions. It champions the notion that intermittently introducing deliberate complexity or ``confusion'' during training can spur more profound and nuanced learning. This accentuates the pivotal role of judiciously selected activation functions in shaping the future of neural network training.", "url": "https://arxiv.org/abs/2308.13670"}, {"metadata": {"arXiv": "2308.13703", "Date": "Fri, 25 Aug 2023 23:21:53 ", "Title": "PAITS: Pretraining and Augmentation for Irregularly-Sampled Time Series", "Authors": ["Nicasia Beebe-Wang", "Sayna Ebrahimi", "Jinsung Yoon", "Sercan O. Arik", "Tomas Pfister"], "Categories": "cs.LG", "Comments": ["Code: \\url{https://github.com/google-research/google-research/tree/master/irregular_timeseries_pretraining}"]}, "abstract": "Real-world time series data that commonly reflect sequential human behavior are often uniquely irregularly sampled and sparse, with highly nonuniform sampling over time and entities. Yet, commonly-used pretraining and augmentation methods for time series are not specifically designed for such scenarios. In this paper, we present PAITS (Pretraining and Augmentation for Irregularly-sampled Time Series), a framework for identifying suitable pretraining strategies for sparse and irregularly sampled time series datasets. PAITS leverages a novel combination of NLP-inspired pretraining tasks and augmentations, and a random search to identify an effective strategy for a given dataset. We demonstrate that different datasets benefit from different pretraining choices. Compared with prior methods, our approach is better able to consistently improve pretraining across multiple datasets and domains. Our code is available at \\url{https://github.com/google-research/google-research/tree/master/irregular_timeseries_pretraining}.", "url": "https://arxiv.org/abs/2308.13703"}, {"metadata": {"arXiv": "2308.13714", "Date": "Sat, 26 Aug 2023 00:19:44 ", "Title": "Uncovering Promises and Challenges of Federated Learning to Detect Cardiovascular Diseases: A Scoping Literature Review", "Authors": ["Sricharan Donkada", "Seyedamin Pouriyeh", "Reza M. Parizi", "Meng Han", "Nasrin Dehbozorgi", "Nazmus Sakib", "Quan Z. Sheng"], "Categories": "cs.LG cs.CR cs.CY"}, "abstract": "Cardiovascular diseases (CVD) are the leading cause of death globally, and early detection can significantly improve outcomes for patients. Machine learning (ML) models can help diagnose CVDs early, but their performance is limited by the data available for model training. Privacy concerns in healthcare make it harder to acquire data to train accurate ML models. Federated learning (FL) is an emerging approach to machine learning that allows models to be trained on data from multiple sources without compromising the privacy of the individual data owners. This survey paper provides an overview of the current state-of-the-art in FL for CVD detection. We review the different FL models proposed in various papers and discuss their advantages and challenges. We also compare FL with traditional centralized learning approaches and highlight the differences in terms of model accuracy, privacy, and data distribution handling capacity. Finally, we provide a critical analysis of FL's current challenges and limitations for CVD detection and discuss potential avenues for future research. Overall, this survey paper aims to provide a comprehensive overview of the current state-of-the-art in FL for CVD detection and to highlight its potential for improving the accuracy and privacy of CVD detection models.", "url": "https://arxiv.org/abs/2308.13714"}, {"metadata": {"arXiv": "2308.13722", "Date": "Sat, 26 Aug 2023 01:15:32 ", "Title": "Time-to-Pattern: Information-Theoretic Unsupervised Learning for Scalable Time Series Summarization", "Authors": ["Alireza Ghods", "Trong Nghia Hoang", "and Diane Cook"], "Categories": "cs.LG"}, "abstract": "Data summarization is the process of generating interpretable and representative subsets from a dataset. Existing time series summarization approaches often search for recurring subsequences using a set of manually devised similarity functions to summarize the data. However, such approaches are fraught with limitations stemming from an exhaustive search coupled with a heuristic definition of series similarity. Such approaches affect the diversity and comprehensiveness of the generated data summaries. To mitigate these limitations, we introduce an approach to time series summarization, called Time-to-Pattern (T2P), which aims to find a set of diverse patterns that together encode the most salient information, following the notion of minimum description length. T2P is implemented as a deep generative model that learns informative embeddings of the discrete time series on a latent space specifically designed to be interpretable. Our synthetic and real-world experiments reveal that T2P discovers informative patterns, even in noisy and complex settings. Furthermore, our results also showcase the improved performance of T2P over previous work in pattern diversity and processing scalability, which conclusively demonstrate the algorithm's effectiveness for time series summarization.", "url": "https://arxiv.org/abs/2308.13722"}, {"metadata": {"arXiv": "2308.13730", "Date": "Sat, 26 Aug 2023 02:04:10 ", "Title": "Muffin: A Framework Toward Multi-Dimension AI Fairness by Uniting Off-the-Shelf Models", "Authors": ["Yi Sheng", "Junhuan Yang", "Lei Yang", "Yiyu Shi", "Jingtongf Hu", "Weiwen Jiang"], "Categories": "cs.LG cs.CY"}, "abstract": "Model fairness (a.k.a., bias) has become one of the most critical problems in a wide range of AI applications. An unfair model in autonomous driving may cause a traffic accident if corner cases (e.g., extreme weather) cannot be fairly regarded; or it will incur healthcare disparities if the AI model misdiagnoses a certain group of people (e.g., brown and black skin). In recent years, there have been emerging research works on addressing unfairness, and they mainly focus on a single unfair attribute, like skin tone; however, real-world data commonly have multiple attributes, among which unfairness can exist in more than one attribute, called 'multi-dimensional fairness'. In this paper, we first reveal a strong correlation between the different unfair attributes, i.e., optimizing fairness on one attribute will lead to the collapse of others. Then, we propose a novel Multi-Dimension Fairness framework, namely Muffin, which includes an automatic tool to unite off-the-shelf models to improve the fairness on multiple attributes simultaneously. Case studies on dermatology datasets with two unfair attributes show that the existing approach can achieve 21.05% fairness improvement on the first attribute while it makes the second attribute unfair by 1.85%. On the other hand, the proposed Muffin can unite multiple models to achieve simultaneously 26.32% and 20.37% fairness improvement on both attributes; meanwhile, it obtains 5.58% accuracy gain.", "url": "https://arxiv.org/abs/2308.13730"}, {"metadata": {"arXiv": "2308.13778", "Date": "Sat, 26 Aug 2023 06:12:33 ", "Title": "Large-scale gradient-based training of Mixtures of Factor Analyzers", "Authors": ["Alexander Gepperth"], "Categories": "cs.LG"}, "abstract": "Gaussian Mixture Models (GMMs) are a standard tool in data analysis. However, they face problems when applied to high-dimensional data (e.g., images) due to the size of the required full covariance matrices (CMs), whereas the use of diagonal or spherical CMs often imposes restrictions that are too severe. The Mixture of Factor analyzers (MFA) model is an important extension of GMMs, which allows to smoothly interpolate between diagonal and full CMs based on the number of \\textit{factor loadings} $l$. MFA has successfully been applied for modeling high-dimensional image data. This article contributes both a theoretical analysis as well as a new method for efficient high-dimensional MFA training by stochastic gradient descent, starting from random centroid initializations. This greatly simplifies the training and initialization process, and avoids problems of batch-type algorithms such Expectation-Maximization (EM) when training with huge amounts of data. In addition, by exploiting the properties of the matrix determinant lemma, we prove that MFA training and inference/sampling can be performed based on precision matrices, which does not require matrix inversions after training is completed. At training time, the methods requires the inversion of $l\\times l$ matrices only. Besides the theoretical analysis and proofs, we apply MFA to typical image datasets such as SVHN and MNIST, and demonstrate the ability to perform sample generation and outlier detection.", "url": "https://arxiv.org/abs/2308.13778"}, {"metadata": {"arXiv": "2308.13792", "Date": "Sat, 26 Aug 2023 07:35:16 ", "Title": "Out-of-distribution detection using normalizing flows on the data manifold", "Authors": ["Seyedeh Fatemeh Razavi", "Mohammad Mahdi Mehmanchi", "Reshad Hosseini", "Mostafa Tavassolipour"], "Categories": "cs.LG cs.CV"}, "abstract": "A common approach for out-of-distribution detection involves estimating an underlying data distribution, which assigns a lower likelihood value to out-of-distribution data. Normalizing flows are likelihood-based generative models providing a tractable density estimation via dimension-preserving invertible transformations. Conventional normalizing flows are prone to fail in out-of-distribution detection, because of the well-known curse of dimensionality problem of the likelihood-based models. According to the manifold hypothesis, real-world data often lie on a low-dimensional manifold. This study investigates the effect of manifold learning using normalizing flows on out-of-distribution detection. We proceed by estimating the density on a low-dimensional manifold, coupled with measuring the distance from the manifold, as criteria for out-of-distribution detection. However, individually, each of them is insufficient for this task. The extensive experimental results show that manifold learning improves the out-of-distribution detection ability of a class of likelihood-based models known as normalizing flows. This improvement is achieved without modifying the model structure or using auxiliary out-of-distribution data during training.", "url": "https://arxiv.org/abs/2308.13792"}, {"metadata": {"arXiv": "2308.13797", "Date": "Sat, 26 Aug 2023 07:45:41 ", "Title": "DeLELSTM: Decomposition-based Linear Explainable LSTM to Capture Instantaneous and Long-term Effects in Time Series", "Authors": ["Chaoqun Wang", "Yijun Li", "Xiangqian Sun", "Qi Wu", "Dongdong Wang and Zhixiang Huang"], "Categories": "cs.LG"}, "abstract": "Time series forecasting is prevalent in various real-world applications. Despite the promising results of deep learning models in time series forecasting, especially the Recurrent Neural Networks (RNNs), the explanations of time series models, which are critical in high-stakes applications, have received little attention. In this paper, we propose a Decomposition-based Linear Explainable LSTM (DeLELSTM) to improve the interpretability of LSTM. Conventionally, the interpretability of RNNs only concentrates on the variable importance and time importance. We additionally distinguish between the instantaneous influence of new coming data and the long-term effects of historical data. Specifically, DeLELSTM consists of two components, i.e., standard LSTM and tensorized LSTM. The tensorized LSTM assigns each variable with a unique hidden state making up a matrix $\\mathbf{h}_t$, and the standard LSTM models all the variables with a shared hidden state $\\mathbf{H}_t$. By decomposing the $\\mathbf{H}_t$ into the linear combination of past information $\\mathbf{h}_{t-1}$ and the fresh information $\\mathbf{h}_{t}-\\mathbf{h}_{t-1}$, we can get the instantaneous influence and the long-term effect of each variable. In addition, the advantage of linear regression also makes the explanation transparent and clear. We demonstrate the effectiveness and interpretability of DeLELSTM on three empirical datasets. Extensive experiments show that the proposed method achieves competitive performance against the baseline methods and provides a reliable explanation relative to domain knowledge.", "url": "https://arxiv.org/abs/2308.13797"}, {"metadata": {"arXiv": "2308.13815", "Date": "Sat, 26 Aug 2023 08:39:16 ", "Title": "SyMOT-Flow: Learning optimal transport flow for two arbitrary distributions with maximum mean discrepancy", "Authors": ["Zhe Xiong", "Qiaoqiao Ding", "Xiaoqun Zhang"], "Categories": "cs.LG", "Comments": ["14 pages article", "3 pages supplementary"]}, "abstract": "Finding a transformation between two unknown probability distributions from samples is crucial for modeling complex data distributions and perform tasks such as density estimation, sample generation, and statistical inference. One powerful framework for such transformations is normalizing flow, which transforms an unknown distribution into a standard normal distribution using an invertible network. In this paper, we introduce a novel model called SyMOT-Flow that trains an invertible transformation by minimizing the symmetric maximum mean discrepancy between samples from two unknown distributions, and we incorporate an optimal transport cost as regularization to obtain a short-distance and interpretable transformation. The resulted transformation leads to more stable and accurate sample generation. We establish several theoretical results for the proposed model and demonstrate its effectiveness with low-dimensional illustrative examples as well as high-dimensional generative samples obtained through the forward and reverse flows.", "url": "https://arxiv.org/abs/2308.13815"}, {"metadata": {"arXiv": "2308.13819", "Date": "Sat, 26 Aug 2023 09:00:31 ", "Title": "Guaranteed Stable Quadratic Models and their applications in SINDy and Operator Inference", "Authors": ["Pawan Goyal and Igor Pontes Duff and Peter Benner"], "Categories": "cs.LG cs.NA math.DS math.NA"}, "abstract": "Scientific machine learning for learning dynamical systems is a powerful tool that combines data-driven modeling models, physics-based modeling, and empirical knowledge. It plays an essential role in an engineering design cycle and digital twinning. In this work, we primarily focus on an operator inference methodology that builds dynamical models, preferably in low-dimension, with a prior hypothesis on the model structure, often determined by known physics or given by experts. Then, for inference, we aim to learn the operators of a model by setting up an appropriate optimization problem. One of the critical properties of dynamical systems is{stability. However, such a property is not guaranteed by the inferred models. In this work, we propose inference formulations to learn quadratic models, which are stable by design. Precisely, we discuss the parameterization of quadratic systems that are locally and globally stable. Moreover, for quadratic systems with no stable point yet bounded (e.g., Chaotic Lorenz model), we discuss an attractive trapping region philosophy and a parameterization of such systems. Using those parameterizations, we set up inference problems, which are then solved using a gradient-based optimization method. Furthermore, to avoid numerical derivatives and still learn continuous systems, we make use of an integration form of differential equations. We present several numerical examples, illustrating the preservation of stability and discussing its comparison with the existing state-of-the-art approach to infer operators. By means of numerical examples, we also demonstrate how proposed methods are employed to discover governing equations and energy-preserving models.", "url": "https://arxiv.org/abs/2308.13819"}, {"metadata": {"arXiv": "2308.13838", "Date": "Sat, 26 Aug 2023 10:09:46 ", "Title": "Price-Discrimination Game for Distributed Resource Management in Federated Learning", "Authors": ["Han Zhang", "Halvin Yang and Guopeng Zhang"], "Categories": "cs.LG cs.GT"}, "abstract": "In vanilla federated learning (FL) such as FedAvg, the parameter server (PS) and multiple distributed clients can form a typical buyer's market, where the number of PS/buyers of FL services is far less than the number of clients/sellers. In order to improve the performance of FL and reduce the cost of motivating clients to participate in FL, this paper proposes to differentiate the pricing for services provided by different clients rather than simply providing the same service pricing for different clients. The price is differentiated based on the performance improvements brought to FL and their heterogeneity in computing and communication capabilities. To this end, a price-discrimination game (PDG) is formulated to comprehensively address the distributed resource management problems in FL, including multi-objective trade-off, client selection, and incentive mechanism. As the PDG is a mixed-integer nonlinear programming (MINLP) problem, a distributed semi-heuristic algorithm with low computational complexity and low communication overhead is designed to solve it. The simulation result verifies the effectiveness of the proposed approach.", "url": "https://arxiv.org/abs/2308.13838"}, {"metadata": {"arXiv": "2308.13862", "Date": "Sat, 26 Aug 2023 12:43:25 ", "Title": "Late Stopping: Avoiding Confidently Learning from Mislabeled Examples", "Authors": ["Suqin Yuan", "Lei Feng", "Tongliang Liu"], "Categories": "cs.LG cs.CV", "Comments": ["Accepted by ICCV 2023"]}, "abstract": "Sample selection is a prevalent method in learning with noisy labels, where small-loss data are typically considered as correctly labeled data. However, this method may not effectively identify clean hard examples with large losses, which are critical for achieving the model's close-to-optimal generalization performance. In this paper, we propose a new framework, Late Stopping, which leverages the intrinsic robust learning ability of DNNs through a prolonged training process. Specifically, Late Stopping gradually shrinks the noisy dataset by removing high-probability mislabeled examples while retaining the majority of clean hard examples in the training set throughout the learning process. We empirically observe that mislabeled and clean examples exhibit differences in the number of epochs required for them to be consistently and correctly classified, and thus high-probability mislabeled examples can be removed. Experimental results on benchmark-simulated and real-world noisy datasets demonstrate that the proposed method outperforms state-of-the-art counterparts.", "url": "https://arxiv.org/abs/2308.13862"}, {"metadata": {"arXiv": "2308.13876", "Date": "Sat, 26 Aug 2023 13:26:13 ", "Title": "Class Binarization to NeuroEvolution for Multiclass Classification", "Authors": ["Gongjin Lan", "Zhenyu Gao", "Lingyao Tong", "Ting Liu"], "Categories": "cs.LG cs.NE", "Comments": ["14 pages", "17 figures"], "DOI": "10.1007/s00521-022-07525-6"}, "abstract": "Multiclass classification is a fundamental and challenging task in machine learning. The existing techniques of multiclass classification can be categorized as (i) decomposition into binary (ii) extension from binary and (iii) hierarchical classification. Decomposing multiclass classification into a set of binary classifications that can be efficiently solved by using binary classifiers, called class binarization, which is a popular technique for multiclass classification. Neuroevolution, a general and powerful technique for evolving the structure and weights of neural networks, has been successfully applied to binary classification. In this paper, we apply class binarization techniques to a neuroevolution algorithm, NeuroEvolution of Augmenting Topologies (NEAT), that is used to generate neural networks for multiclass classification. We propose a new method that applies Error-Correcting Output Codes (ECOC) to design the class binarization strategies on the neuroevolution for multiclass classification. The ECOC strategies are compared with the class binarization strategies of One-vs-One and One-vs-All on three well-known datasets Digit, Satellite, and Ecoli. We analyse their performance from four aspects of multiclass classification degradation, accuracy, evolutionary efficiency, and robustness. The results show that the NEAT with ECOC performs high accuracy with low variance. Specifically, it shows significant benefits in a flexible number of binary classifiers and strong robustness.", "url": "https://arxiv.org/abs/2308.13876"}, {"metadata": {"arXiv": "2308.13891", "Date": "Sat, 26 Aug 2023 14:24:41 ", "Title": "Drug Interaction Vectors Neural Network: DrIVeNN", "Authors": ["Natalie Wang", "Casey Overby Taylor"], "Categories": "cs.LG q-bio.QM", "Comments": ["8 pages", "3 figures"]}, "abstract": "Polypharmacy, the concurrent use of multiple drugs to treat a single condition, is common in patients managing multiple or complex conditions. However, as more drugs are added to the treatment plan, the risk of adverse drug events (ADEs) rises rapidly. Many serious ADEs associated with polypharmacy only become known after the drugs are in use. It is impractical to test every possible drug combination during clinical trials. This issue is particularly prevalent among older adults with cardiovascular disease (CVD) where polypharmacy and ADEs are commonly observed. In this research, our primary objective was to identify key drug features to build and evaluate a model for modeling polypharmacy ADEs. Our secondary objective was to assess our model on a domain-specific case study. We developed a two-layer neural network that incorporated drug features such as molecular structure, drug-protein interactions, and mono drug side effects (DrIVeNN). We assessed DrIVeNN using publicly available side effect databases and determined Principal Component Analysis (PCA) with a variance threshold of 0.95 as the most effective feature selection method. DrIVeNN performed moderately better than state-of-the-art models like RESCAL, DEDICOM, DeepWalk, Decagon, DeepDDI, KGDDI, and KGNN in terms of AUROC for the drug-drug interaction prediction task. We also conducted a domain-specific case study centered on the treatment of cardiovascular disease (CVD). When the best performing model architecture was applied to the CVD treatment cohort, there was a significant increase in performance from the general model. We observed an average AUROC for CVD drug pair prediction increasing from 0.826 (general model) to 0.975 (CVD specific model). Our findings indicate the strong potential of domain-specific models for improving the accuracy of drug-drug interaction predictions.", "url": "https://arxiv.org/abs/2308.13891"}, {"metadata": {"arXiv": "2308.13898", "Date": "Sat, 26 Aug 2023 14:52:02 ", "Title": "Memory-aware Scheduling for Complex Wired Networks with Iterative Graph Optimization", "Authors": ["Shuzhang Zhong", "Meng Li", "Yun Liang", "Runsheng Wang", "Ru Huang"], "Categories": "cs.LG cs.DC"}, "abstract": "Memory-aware network scheduling is becoming increasingly important for deep neural network (DNN) inference on resource-constrained devices. However, due to the complex cell-level and network-level topologies, memory-aware scheduling becomes very challenging. While previous algorithms all suffer from poor scalability, in this paper, we propose an efficient memory-aware scheduling framework based on iterative computation graph optimization. Our framework features an iterative graph fusion algorithm that simplifies the computation graph while preserving the scheduling optimality. We further propose an integer linear programming formulation together with topology-aware variable pruning to schedule the simplified graph efficiently. We evaluate our method against prior-art algorithms on different networks and demonstrate that our method outperforms existing techniques in all the benchmarks, reducing the peak memory footprint by 13.4%, and achieving better scalability for networks with complex network-level topologies.", "url": "https://arxiv.org/abs/2308.13898"}, {"metadata": {"arXiv": "2308.13960", "Date": "Sat, 26 Aug 2023 21:32:13 ", "Title": "Sparse Models for Machine Learning", "Authors": ["Jianyi Lin"], "Categories": "cs.LG cs.CV", "Comments": ["42 pages"], "ACM-class": "I.5.4; I.2.6; G.1.3", "DOI": "10.1201/9781003283980-5"}, "abstract": "The sparse modeling is an evident manifestation capturing the parsimony principle just described, and sparse models are widespread in statistics, physics, information sciences, neuroscience, computational mathematics, and so on. In statistics the many applications of sparse modeling span regression, classification tasks, graphical model selection, sparse M-estimators and sparse dimensionality reduction. It is also particularly effective in many statistical and machine learning areas where the primary goal is to discover predictive patterns from data which would enhance our understanding and control of underlying physical, biological, and other natural processes, beyond just building accurate outcome black-box predictors. Common examples include selecting biomarkers in biological procedures, finding relevant brain activity locations which are predictive about brain states and processes based on fMRI data, and identifying network bottlenecks best explaining end-to-end performance. Moreover, the research and applications of efficient recovery of high-dimensional sparse signals from a relatively small number of observations, which is the main focus of compressed sensing or compressive sensing, have rapidly grown and became an extremely intense area of study beyond classical signal processing. Likewise interestingly, sparse modeling is directly related to various artificial vision tasks, such as image denoising, segmentation, restoration and superresolution, object or face detection and recognition in visual scenes, and action recognition. In this manuscript, we provide a brief introduction of the basic theory underlying sparse representation and compressive sensing, and then discuss some methods for recovering sparse solutions to optimization problems in effective way, together with some applications of sparse recovery in a machine learning problem known as sparse dictionary learning.", "url": "https://arxiv.org/abs/2308.13960"}, {"metadata": {"arXiv": "2308.13968", "Date": "Sat, 26 Aug 2023 22:47:46 ", "Title": "Multivariate time series classification with dual attention network", "Authors": ["Mojtaba A. Farahani", "Tara Eslaminokandeh"], "Categories": "cs.LG"}, "abstract": "One of the topics in machine learning that is becoming more and more relevant is multivariate time series classification. Current techniques concentrate on identifying the local important sequence segments or establishing the global long-range dependencies. They frequently disregard the merged data from both global and local features, though. Using dual attention, we explore a novel network (DA-Net) in this research to extract local and global features for multivariate time series classification. The two distinct layers that make up DA-Net are the Squeeze-Excitation Window Attention (SEWA) layer and the Sparse Self-Attention within Windows (SSAW) layer. DA- Net can mine essential local sequence fragments that are necessary for establishing global long-range dependencies based on the two expanded layers.", "url": "https://arxiv.org/abs/2308.13968"}, {"metadata": {"arXiv": "2308.13982", "Date": "Sun, 27 Aug 2023 01:19:19 ", "Title": "Universal Graph Continual Learning", "Authors": ["Thanh Duc Hoang", "Do Viet Tung", "Duy-Hung Nguyen", "Bao-Sinh Nguyen", "Huy Hoang Nguyen", "Hung Le"], "Categories": "cs.LG", "Comments": ["16 pages"]}, "abstract": "We address catastrophic forgetting issues in graph learning as incoming data transits from one to another graph distribution. Whereas prior studies primarily tackle one setting of graph continual learning such as incremental node classification, we focus on a universal approach wherein each data point in a task can be a node or a graph, and the task varies from node to graph classification. We propose a novel method that enables graph neural networks to excel in this universal setting. Our approach perseveres knowledge about past tasks through a rehearsal mechanism that maintains local and global structure consistency across the graphs. We benchmark our method against various continual learning baselines in real-world graph datasets and achieve significant improvement in average performance and forgetting across tasks.", "url": "https://arxiv.org/abs/2308.13982"}, {"metadata": {"arXiv": "2308.13996", "Date": "Sun, 27 Aug 2023 03:24:37 ", "Title": "Improve in-situ life prediction and classification performance by capturing both the present state and evolution rate of battery aging", "Authors": ["Mingyuan Zhao", "Yongzhi Zhang"], "Categories": "cs.LG cs.SY eess.SY"}, "abstract": "This study develops a methodology by capturing both the battery aging state and degradation rate for improved life prediction performance. The aging state is indicated by six physical features of an equivalent circuit model that are extracted from the voltage relaxation data. And the degradation rate is captured by two features extracted from the differences between the voltage relaxation curves within a moving window (for life prediction), or the differences between the capacity vs. voltage curves at different cycles (for life classification). Two machine learning models, which are constructed based on Gaussian Processes, are used to describe the relationships between these physical features and battery lifetimes for the life prediction and classification, respectively. The methodology is validated with the aging data of 74 battery cells of three different types. Experimental results show that based on only 3-12 minutes' sampling data, the method with novel features predicts accurate battery lifetimes, with the prediction accuracy improved by up to 67.09% compared with the benchmark method. And the batteries are classified into three groups (long, medium, and short) with an overall accuracy larger than 90% based on only two adjacent cycles' information, enabling the highly efficient regrouping of retired batteries.", "url": "https://arxiv.org/abs/2308.13996"}, {"metadata": {"arXiv": "2308.14020", "Date": "Sun, 27 Aug 2023 06:39:46 ", "Title": "A Comparison of Neural Networks for Wireless Channel Prediction", "Authors": ["Oscar Stenhammar", "Gabor Fodor", "Carlo Fischione"], "Categories": "cs.LG cs.NI eess.SP"}, "abstract": "The performance of modern wireless communications systems depends critically on the quality of the available channel state information (CSI) at the transmitter and receiver. Several previous works have proposed concepts and algorithms that help maintain high quality CSI even in the presence of high mobility and channel aging, such as temporal prediction schemes that employ neural networks. However, it is still unclear which neural network-based scheme provides the best performance in terms of prediction quality, training complexity and practical feasibility. To investigate such a question, this paper first provides an overview of state-of-the-art neural networks applicable to channel prediction and compares their performance in terms of prediction quality. Next, a new comparative analysis is proposed for four promising neural networks with different prediction horizons. The well-known tapped delay channel model recommended by the Third Generation Partnership Program is used for a standardized comparison among the neural networks. Based on this comparative evaluation, the advantages and disadvantages of each neural network are discussed and guidelines for selecting the best-suited neural network in channel prediction applications are given.", "url": "https://arxiv.org/abs/2308.14020"}, {"metadata": {"arXiv": "2308.14104", "Date": "Sun, 27 Aug 2023 13:22:50 ", "Title": "Towards Generalizable Neural Solvers for Vehicle Routing Problems via Ensemble with Transferrable Local Policy", "Authors": ["Chengrui Gao", "Haopu Shang", "Ke Xue", "Dong Li", "Chao Qian"], "Categories": "cs.LG"}, "abstract": "Machine learning has been adapted to help solve NP-hard combinatorial optimization problems. One prevalent way is learning to construct solutions by deep neural networks, which has been receiving more and more attention due to the high efficiency and less requirement for expert knowledge. However, many neural construction methods for Vehicle Routing Problems (VRPs) focus on synthetic problem instances with limited scales and specified node distributions, leading to poor performance on real-world problems which usually involve large scales together with complex and unknown node distributions. To make neural VRP solvers more practical in real-world scenarios, we design an auxiliary policy that learns from the local transferable topological features, named local policy, and integrate it with a typical constructive policy (which learns from the global information of VRP instances) to form an ensemble policy. With joint training, the aggregated policies perform cooperatively and complementarily to boost generalization. The experimental results on two well-known benchmarks, TSPLIB and CVRPLIB, of travelling salesman problem and capacitated VRP show that the ensemble policy consistently achieves better generalization than state-of-the-art construction methods and even works well on real-world problems with several thousand nodes.", "url": "https://arxiv.org/abs/2308.14104"}, {"metadata": {"arXiv": "2308.14114", "Date": "Sun, 27 Aug 2023 14:13:29 ", "Title": "Hybrid Transformer-RNN Architecture for Household Occupancy Detection Using Low-Resolution Smart Meter Data", "Authors": ["Xinyu Liang", "Hao Wang"], "Categories": "cs.LG", "Comments": ["IEEE IECON 2023 (The 49th Annual Conference of the IEEE Industrial Electronics Society)"]}, "abstract": "Residential occupancy detection has become an enabling technology in today's urbanized world for various smart home applications, such as building automation, energy management, and improved security and comfort. Digitalization of the energy system provides smart meter data that can be used for occupancy detection in a non-intrusive manner without causing concerns regarding privacy and data security. In particular, deep learning techniques make it possible to infer occupancy from low-resolution smart meter data, such that the need for accurate occupancy detection with privacy preservation can be achieved. Our work is thus motivated to develop a privacy-aware and effective model for residential occupancy detection in contemporary living environments. Our model aims to leverage the advantages of both recurrent neural networks (RNNs), which are adept at capturing local temporal dependencies, and transformers, which are effective at handling global temporal dependencies. Our designed hybrid transformer-RNN model detects residential occupancy using hourly smart meter data, achieving an accuracy of nearly 92\\% across households with diverse profiles. We validate the effectiveness of our method using a publicly accessible dataset and demonstrate its performance by comparing it with state-of-the-art models, including attention-based occupancy detection methods.", "url": "https://arxiv.org/abs/2308.14114"}, {"metadata": {"arXiv": "2308.14129", "Date": "Sun, 27 Aug 2023 15:11:44 ", "Title": "SPEED: Streaming Partition and Parallel Acceleration for Temporal Interaction Graph Embedding", "Authors": ["Xi Chen", "Yongxiang Liao", "Yun Xiong", "Yao Zhang", "Siwei Zhang", "Jiawei Zhang", "Yiheng Sun"], "Categories": "cs.LG cs.DC cs.SI", "Comments": ["13 pages", "8 figures"]}, "abstract": "Temporal Interaction Graphs (TIGs) are widely employed to model intricate real-world systems such as financial systems and social networks. To capture the dynamism and interdependencies of nodes, existing TIG embedding models need to process edges sequentially and chronologically. However, this requirement prevents it from being processed in parallel and struggle to accommodate burgeoning data volumes to GPU. Consequently, many large-scale temporal interaction graphs are confined to CPU processing. Furthermore, a generalized GPU scaling and acceleration approach remains unavailable. To facilitate large-scale TIGs' implementation on GPUs for acceleration, we introduce a novel training approach namely Streaming Edge Partitioning and Parallel Acceleration for Temporal Interaction Graph Embedding (SPEED). The SPEED is comprised of a Streaming Edge Partitioning Component (SEP) which addresses space overhead issue by assigning fewer nodes to each GPU, and a Parallel Acceleration Component (PAC) which enables simultaneous training of different sub-graphs, addressing time overhead issue. Our method can achieve a good balance in computing resources, computing time, and downstream task performance. Empirical validation across 7 real-world datasets demonstrates the potential to expedite training speeds by a factor of up to 19.29x. Simultaneously, resource consumption of a single-GPU can be diminished by up to 69%, thus enabling the multiple GPU-based training and acceleration encompassing millions of nodes and billions of edges. Furthermore, our approach also maintains its competitiveness in downstream tasks.", "url": "https://arxiv.org/abs/2308.14129"}, {"metadata": {"arXiv": "2308.14144", "Date": "Sun, 27 Aug 2023 15:57:08 ", "Title": "Learning end-to-end inversion of circular Radon transforms in the partial radial setup", "Authors": ["Deep Ray and Souvik Roy"], "Categories": "cs.LG eess.IV", "MSC-class": "45Q05, 68T07"}, "abstract": "We present a deep learning-based computational algorithm for inversion of circular Radon transforms in the partial radial setup, arising in photoacoustic tomography. We first demonstrate that the truncated singular value decomposition-based method, which is the only traditional algorithm available to solve this problem, leads to severe artifacts which renders the reconstructed field as unusable. With the objective of overcoming this computational bottleneck, we train a ResBlock based U-Net to recover the inferred field that directly operates on the measured data. Numerical results with augmented Shepp-Logan phantoms, in the presence of noisy full and limited view data, demonstrate the superiority of the proposed algorithm.", "url": "https://arxiv.org/abs/2308.14144"}, {"metadata": {"arXiv": "2308.14175", "Date": "Sun, 27 Aug 2023 18:38:09 ", "Title": "Leveraging Linear Independence of Component Classifiers: Optimizing Size and Prediction Accuracy for Online Ensembles", "Authors": ["Enes Bektas and Fazli Can"], "Categories": "cs.LG"}, "abstract": "Ensembles, which employ a set of classifiers to enhance classification accuracy collectively, are crucial in the era of big data. However, although there is general agreement that the relation between ensemble size and its prediction accuracy, the exact nature of this relationship is still unknown. We introduce a novel perspective, rooted in the linear independence of classifier's votes, to analyze the interplay between ensemble size and prediction accuracy. This framework reveals a theoretical link, consequently proposing an ensemble size based on this relationship. Our study builds upon a geometric framework and develops a series of theorems. These theorems clarify the role of linear dependency in crafting ensembles. We present a method to determine the minimum ensemble size required to ensure a target probability of linearly independent votes among component classifiers. Incorporating real and synthetic datasets, our empirical results demonstrate a trend: increasing the number of classifiers enhances accuracy, as predicted by our theoretical insights. However, we also identify a point of diminishing returns, beyond which additional classifiers provide diminishing improvements in accuracy. Surprisingly, the calculated ideal ensemble size deviates from empirical results for certain datasets, emphasizing the influence of other factors. This study opens avenues for deeper investigations into the complex dynamics governing ensemble design and offers guidance for constructing efficient and effective ensembles in practical scenarios.", "url": "https://arxiv.org/abs/2308.14175"}, {"metadata": {"arXiv": "2308.14215", "Date": "Sun, 27 Aug 2023 22:27:57 ", "Title": "TimeTrail: Unveiling Financial Fraud Patterns through Temporal Correlation Analysis", "Authors": ["Sushrut Ghimire"], "Categories": "cs.LG q-fin.ST"}, "abstract": "In the field of financial fraud detection, understanding the underlying patterns and dynamics is important to ensure effective and reliable systems. This research introduces a new technique, \"TimeTrail,\" which employs advanced temporal correlation analysis to explain complex financial fraud patterns. The technique leverages time-related insights to provide transparent and interpretable explanations for fraud detection decisions, enhancing accountability and trust. The \"TimeTrail\" methodology consists of three key phases: temporal data enrichment, dynamic correlation analysis, and interpretable pattern visualization. Initially, raw financial transaction data is enriched with temporal attributes. Dynamic correlations between these attributes are then quantified using innovative statistical measures. Finally, a unified visualization framework presents these correlations in an interpretable manner. To validate the effectiveness of \"TimeTrail,\" a study is conducted on a diverse financial dataset, surrounding various fraud scenarios. Results demonstrate the technique's capability to uncover hidden temporal correlations and patterns, performing better than conventional methods in both accuracy and interpretability. Moreover, a case study showcasing the application of \"TimeTrail\" in real-world scenarios highlights its utility for fraud detection.", "url": "https://arxiv.org/abs/2308.14215"}, {"metadata": {"arXiv": "2308.14216", "Date": "Sun, 27 Aug 2023 22:34:10 ", "Title": "Machine Learning for Administrative Health Records: A Systematic Review of Techniques and Applications", "Authors": ["Adrian Caruana", "Madhushi Bandara", "Katarzyna Musial", "Daniel Catchpoole", "Paul J. Kennedy"], "Categories": "cs.LG", "DOI": "10.1016/j.artmed.2023.102642"}, "abstract": "Machine learning provides many powerful and effective techniques for analysing heterogeneous electronic health records (EHR). Administrative Health Records (AHR) are a subset of EHR collected for administrative purposes, and the use of machine learning on AHRs is a growing subfield of EHR analytics. Existing reviews of EHR analytics emphasise that the data-modality of the EHR limits the breadth of suitable machine learning techniques, and pursuable healthcare applications. Despite emphasising the importance of data modality, the literature fails to analyse which techniques and applications are relevant to AHRs. AHRs contain uniquely well-structured, categorically encoded records which are distinct from other data-modalities captured by EHRs, and they can provide valuable information pertaining to how patients interact with the healthcare system. This paper systematically reviews AHR-based research, analysing 70 relevant studies and spanning multiple databases. We identify and analyse which machine learning techniques are applied to AHRs and which health informatics applications are pursued in AHR-based research. We also analyse how these techniques are applied in pursuit of each application, and identify the limitations of these approaches. We find that while AHR-based studies are disconnected from each other, the use of AHRs in health informatics research is substantial and accelerating. Our synthesis of these studies highlights the utility of AHRs for pursuing increasingly complex and diverse research objectives despite a number of pervading data- and technique-based limitations. Finally, through our findings, we propose a set of future research directions that can enhance the utility of AHR data and machine learning techniques for health informatics research.", "url": "https://arxiv.org/abs/2308.14216"}, {"metadata": {"arXiv": "2308.14220", "Date": "Sun, 27 Aug 2023 22:42:31 ", "Title": "On Active Learning for Gaussian Process-based Global Sensitivity Analysis", "Authors": ["Mohit Chauhan", "Mariel Ojeda-Tuz", "Ryan Catarelli", "Kurtis Gurley", "Dimitrios Tsapetis", "Michael D. Shields"], "Categories": "cs.LG", "Comments": ["31 pages", "16 figures"]}, "abstract": "This paper explores the application of active learning strategies to adaptively learn Sobol indices for global sensitivity analysis. We demonstrate that active learning for Sobol indices poses unique challenges due to the definition of the Sobol index as a ratio of variances estimated from Gaussian process surrogates. Consequently, learning strategies must either focus on convergence in the numerator or the denominator of this ratio. However, rapid convergence in either one does not guarantee convergence in the Sobol index. We propose a novel strategy for active learning that focuses on resolving the main effects of the Gaussian process (associated with the numerator of the Sobol index) and compare this with existing strategies based on convergence in the total variance (the denominator of the Sobol index). The new strategy, implemented through a new learning function termed the MUSIC (minimize uncertainty in Sobol index convergence), generally converges in Sobol index error more rapidly than the existing strategies based on the Expected Improvement for Global Fit (EIGF) and the Variance Improvement for Global Fit (VIGF). Both strategies are compared with simple sequential random sampling and the MUSIC learning function generally converges most rapidly for low-dimensional problems. However, for high-dimensional problems, the performance is comparable to random sampling. The new learning strategy is demonstrated for a practical case of adaptive experimental design for large-scale Boundary Layer Wind Tunnel experiments.", "url": "https://arxiv.org/abs/2308.14220"}, {"metadata": {"arXiv": "2308.14245", "Date": "Mon, 28 Aug 2023 01:21:22 ", "Title": "A Comparison of Personalized and Generalized Approaches to Emotion Recognition Using Consumer Wearable Devices: Machine Learning Study", "Authors": ["Joe Li", "Peter Washington"], "Categories": "cs.LG cs.CY cs.HC eess.SP"}, "abstract": "Background: Studies have shown the potential adverse health effects, ranging from headaches to cardiovascular disease, associated with long-term negative emotions and chronic stress. Since many indicators of stress are imperceptible to observers, the early detection and intervention of stress remains a pressing medical need. Physiological signals offer a non-invasive method of monitoring emotions and are easily collected by smartwatches. Existing research primarily focuses on developing generalized machine learning-based models for emotion classification. Objective: We aim to study the differences between personalized and generalized machine learning models for three-class emotion classification (neutral, stress, and amusement) using wearable biosignal data. Methods: We developed a convolutional encoder for the three-class emotion classification problem using data from WESAD, a multimodal dataset with physiological signals for 15 subjects. We compared the results between a subject-exclusive generalized, subject-inclusive generalized, and personalized model. Results: For the three-class classification problem, our personalized model achieved an average accuracy of 95.06% and F1-score of 91.71, our subject-inclusive generalized model achieved an average accuracy of 66.95% and F1-score of 42.50, and our subject-exclusive generalized model achieved an average accuracy of 67.65% and F1-score of 43.05. Conclusions: Our results emphasize the need for increased research in personalized emotion recognition models given that they outperform generalized models in certain contexts. We also demonstrate that personalized machine learning models for emotion classification are viable and can achieve high performance.", "url": "https://arxiv.org/abs/2308.14245"}, {"metadata": {"arXiv": "2308.14258", "Date": "Mon, 28 Aug 2023 02:25:11 ", "Title": "Breaking Boundaries: Distributed Domain Decomposition with Scalable Physics-Informed Neural PDE Solvers", "Authors": ["Arthur Feeney", "Zitong Li", "Ramin Bostanabad", "Aparna Chandramowlishwaran"], "Categories": "cs.LG cs.DC"}, "abstract": "Mosaic Flow is a novel domain decomposition method designed to scale physics-informed neural PDE solvers to large domains. Its unique approach leverages pre-trained networks on small domains to solve partial differential equations on large domains purely through inference, resulting in high reusability. This paper presents an end-to-end parallelization of Mosaic Flow, combining data parallel training and domain parallelism for inference on large-scale problems. By optimizing the network architecture and data parallel training, we significantly reduce the training time for learning the Laplacian operator to minutes on 32 GPUs. Moreover, our distributed domain decomposition algorithm enables scalable inferences for solving the Laplace equation on domains 4096 times larger than the training domain, demonstrating strong scaling while maintaining accuracy on 32 GPUs. The reusability of Mosaic Flow, combined with the improved performance achieved through the distributed-memory algorithms, makes it a promising tool for modeling complex physical phenomena and accelerating scientific discovery.", "url": "https://arxiv.org/abs/2308.14258"}, {"metadata": {"arXiv": "2308.14267", "Date": "Mon, 28 Aug 2023 02:49:07 ", "Title": "Unleash Model Potential: Bootstrapped Meta Self-supervised Learning", "Authors": ["Jingyao Wang", "Zeen Song", "Wenwen Qiang", "Changwen Zheng"], "Categories": "cs.LG cs.CV", "Comments": ["submitted to NIPS"]}, "abstract": "The long-term goal of machine learning is to learn general visual representations from a small amount of data without supervision, mimicking three advantages of human cognition: i) no need for labels, ii) robustness to data scarcity, and iii) learning from experience. Self-supervised learning and meta-learning are two promising techniques to achieve this goal, but they both only partially capture the advantages and fail to address all the problems. Self-supervised learning struggles to overcome the drawbacks of data scarcity, while ignoring prior knowledge that can facilitate learning and generalization. Meta-learning relies on supervised information and suffers from a bottleneck of insufficient learning. To address these issues, we propose a novel Bootstrapped Meta Self-Supervised Learning (BMSSL) framework that aims to simulate the human learning process. We first analyze the close relationship between meta-learning and self-supervised learning. Based on this insight, we reconstruct tasks to leverage the strengths of both paradigms, achieving advantages i and ii. Moreover, we employ a bi-level optimization framework that alternates between solving specific tasks with a learned ability (first level) and improving this ability (second level), attaining advantage iii. To fully harness its power, we introduce a bootstrapped target based on meta-gradient to make the model its own teacher. We validate the effectiveness of our approach with comprehensive theoretical and empirical study.", "url": "https://arxiv.org/abs/2308.14267"}, {"metadata": {"arXiv": "2308.14304", "Date": "Mon, 28 Aug 2023 04:37:38 ", "Title": "Solving Attention Kernel Regression Problem via Pre-conditioner", "Authors": ["Zhao Song", "Junze Yin", "Lichen Zhang"], "Categories": "cs.LG"}, "abstract": "Large language models have shown impressive performance in many tasks. One of the major features from the computation perspective is computing the attention matrix. Previous works [Zandieh, Han, Daliri, and Karba 2023, Alman and Song 2023] have formally studied the possibility and impossibility of approximating the attention matrix. In this work, we define and study a new problem which is called the attention kernel regression problem. We show how to solve the attention kernel regression in the input sparsity time of the data matrix.", "url": "https://arxiv.org/abs/2308.14304"}, {"metadata": {"arXiv": "2308.14322", "Date": "Mon, 28 Aug 2023 06:05:23 ", "Title": "Machine Unlearning Methodology base on Stochastic Teacher Network", "Authors": ["Xulong Zhang", "Jianzong Wang", "Ning Cheng", "Yifu Sun", "Chuanyao Zhang", "Jing Xiao"], "Categories": "cs.LG cs.CV", "Comments": ["Accepted by 19th International Conference on Advanced Data Mining and Applications. (ADMA 2023)"]}, "abstract": "The rise of the phenomenon of the \"right to be forgotten\" has prompted research on machine unlearning, which grants data owners the right to actively withdraw data that has been used for model training, and requires the elimination of the contribution of that data to the model. A simple method to achieve this is to use the remaining data to retrain the model, but this is not acceptable for other data owners who continue to participate in training. Existing machine unlearning methods have been found to be ineffective in quickly removing knowledge from deep learning models. This paper proposes using a stochastic network as a teacher to expedite the mitigation of the influence caused by forgotten data on the model. We performed experiments on three datasets, and the findings demonstrate that our approach can efficiently mitigate the influence of target data on the model within a single epoch. This allows for one-time erasure and reconstruction of the model, and the reconstruction model achieves the same performance as the retrained model.", "url": "https://arxiv.org/abs/2308.14322"}, {"metadata": {"arXiv": "2308.14340", "Date": "Mon, 28 Aug 2023 06:32:09 ", "Title": "HRGCN: Heterogeneous Graph-level Anomaly Detection with Hierarchical Relation-augmented Graph Neural Networks", "Authors": ["Jiaxi Li", "Guansong Pang", "Ling Chen", "Mohammad-Reza Namazi-Rad"], "Categories": "cs.LG", "Comments": ["12 pages", "10 figures", "6 tables. Accepted"]}, "abstract": "This work considers the problem of heterogeneous graph-level anomaly detection. Heterogeneous graphs are commonly used to represent behaviours between different types of entities in complex industrial systems for capturing as much information about the system operations as possible. Detecting anomalous heterogeneous graphs from a large set of system behaviour graphs is crucial for many real-world applications like online web/mobile service and cloud access control. To address the problem, we propose HRGCN, an unsupervised deep heterogeneous graph neural network, to model complex heterogeneous relations between different entities in the system for effectively identifying these anomalous behaviour graphs. HRGCN trains a hierarchical relation-augmented Heterogeneous Graph Neural Network (HetGNN), which learns better graph representations by modelling the interactions among all the system entities and considering both source-to-destination entity (node) types and their relation (edge) types. Extensive evaluation on two real-world application datasets shows that HRGCN outperforms state-of-the-art competing anomaly detection approaches. We further present a real-world industrial case study to justify the effectiveness of HRGCN in detecting anomalous (e.g., congested) network devices in a mobile communication service. HRGCN is available at https://github.com/jiaxililearn/HRGCN.", "url": "https://arxiv.org/abs/2308.14340"}, {"metadata": {"arXiv": "2308.14350", "Date": "Mon, 28 Aug 2023 06:53:31 ", "Title": "Simple Modification of the Upper Confidence Bound Algorithm by Generalized Weighted Averages", "Authors": ["Nobuhito Manome", "Shuji Shinohara", "Ung-il Chung"], "Categories": "cs.LG", "Comments": ["8 pages", "8 figures"], "MSC-class": "68T37", "ACM-class": "I.2.0"}, "abstract": "The multi-armed bandit (MAB) problem is a classical problem that models sequential decision-making under uncertainty in reinforcement learning. In this study, we propose a new generalized upper confidence bound (UCB) algorithm (GWA-UCB1) by extending UCB1, which is a representative algorithm for MAB problems, using generalized weighted averages, and present an effective algorithm for various problem settings. GWA-UCB1 is a two-parameter generalization of the balance between exploration and exploitation in UCB1 and can be implemented with a simple modification of the UCB1 formula. Therefore, this algorithm can be easily applied to UCB-based reinforcement learning models. In preliminary experiments, we investigated the optimal parameters of a simple generalized UCB1 (G-UCB1), prepared for comparison and GWA-UCB1, in a stochastic MAB problem with two arms. Subsequently, we confirmed the performance of the algorithms with the investigated parameters on stochastic MAB problems when arm reward probabilities were sampled from uniform or normal distributions and on survival MAB problems assuming more realistic situations. GWA-UCB1 outperformed G-UCB1, UCB1-Tuned, and Thompson sampling in most problem settings and can be useful in many situations. The code is available at https://github.com/manome/python-mab.", "url": "https://arxiv.org/abs/2308.14350"}, {"metadata": {"arXiv": "2308.14355", "Date": "Mon, 28 Aug 2023 07:03:08 ", "Title": "Can Transformer and GNN Help Each Other?", "Authors": ["Peiyan Zhang", "Yuchen Yan", "Chaozhuo Li", "Senzhang Wang", "Xing Xie", "Sunghun Kim"], "Categories": "cs.LG cs.IR", "ACM-class": "H.3.3"}, "abstract": "Although Transformer has achieved great success in natural language process and computer vision, it has difficulty generalizing to medium and large-scale graph data for two important reasons: (i) High complexity. (ii) Failing to capture the complex and entangled structure information. In graph representation learning, Graph Neural Networks(GNNs) can fuse the graph structure and node attributes but have limited receptive fields. Therefore, we question whether can we combine Transformers and GNNs to help each other. In this paper, we propose a new model named TransGNN where the Transformer layer and GNN layer are used alternately to improve each other. Specifically, to expand the receptive field and disentangle the information aggregation from edges, we propose using Transformer to aggregate more relevant nodes' information to improve the message passing of GNNs. Besides, to capture the graph structure information, we utilize positional encoding and make use of the GNN layer to fuse the structure into node attributes, which improves the Transformer in graph data. We also propose to sample the most relevant nodes for Transformer and two efficient samples update strategies to lower the complexity. At last, we theoretically prove that TransGNN is more expressive than GNNs only with extra linear complexity. The experiments on eight datasets corroborate the effectiveness of TransGNN on node and graph classification tasks.", "url": "https://arxiv.org/abs/2308.14355"}, {"metadata": {"arXiv": "2308.14374", "Date": "Mon, 28 Aug 2023 07:42:26 ", "Title": "Online Continual Learning on Hierarchical Label Expansion", "Authors": ["Byung Hyun Lee", "Okchul Jung", "Jonghyun Choi", "Se Young Chun"], "Categories": "cs.LG", "Comments": ["Accepted to ICCV 2023"]}, "abstract": "Continual learning (CL) enables models to adapt to new tasks and environments without forgetting previously learned knowledge. While current CL setups have ignored the relationship between labels in the past task and the new task with or without small task overlaps, real-world scenarios often involve hierarchical relationships between old and new tasks, posing another challenge for traditional CL approaches. To address this challenge, we propose a novel multi-level hierarchical class incremental task configuration with an online learning constraint, called hierarchical label expansion (HLE). Our configuration allows a network to first learn coarse-grained classes, with data labels continually expanding to more fine-grained classes in various hierarchy depths. To tackle this new setup, we propose a rehearsal-based method that utilizes hierarchy-aware pseudo-labeling to incorporate hierarchical class information. Additionally, we propose a simple yet effective memory management and sampling strategy that selectively adopts samples of newly encountered classes. Our experiments demonstrate that our proposed method can effectively use hierarchy on our HLE setup to improve classification accuracy across all levels of hierarchies, regardless of depth and class imbalance ratio, outperforming prior state-of-the-art works by significant margins while also outperforming them on the conventional disjoint, blurry and i-Blurry CL setups.", "url": "https://arxiv.org/abs/2308.14374"}, {"metadata": {"arXiv": "2308.14377", "Date": "Mon, 28 Aug 2023 07:49:30 ", "Title": "Meta Attentive Graph Convolutional Recurrent Network for Traffic Forecasting", "Authors": ["Adnan Zeb", "Yongchao Ye", "Shiyao Zhang and James J. Q. Yu"], "Categories": "cs.LG"}, "abstract": "Traffic forecasting is a fundamental problem in intelligent transportation systems. Existing traffic predictors are limited by their expressive power to model the complex spatial-temporal dependencies in traffic data, mainly due to the following limitations. Firstly, most approaches are primarily designed to model the local shared patterns, which makes them insufficient to capture the specific patterns associated with each node globally. Hence, they fail to learn each node's unique properties and diversified patterns. Secondly, most existing approaches struggle to accurately model both short- and long-term dependencies simultaneously. In this paper, we propose a novel traffic predictor, named Meta Attentive Graph Convolutional Recurrent Network (MAGCRN). MAGCRN utilizes a Graph Convolutional Recurrent Network (GCRN) as a core module to model local dependencies and improves its operation with two novel modules: 1) a Node-Specific Meta Pattern Learning (NMPL) module to capture node-specific patterns globally and 2) a Node Attention Weight Generation Module (NAWG) module to capture short- and long-term dependencies by connecting the node-specific features with the ones learned initially at each time step during GCRN operation. Experiments on six real-world traffic datasets demonstrate that NMPL and NAWG together enable MAGCRN to outperform state-of-the-art baselines on both short- and long-term predictions.", "url": "https://arxiv.org/abs/2308.14377"}, {"metadata": {"arXiv": "2308.14380", "Date": "Mon, 28 Aug 2023 07:55:01 ", "Title": "Self-Supervision for Tackling Unsupervised Anomaly Detection: Pitfalls and Opportunities", "Authors": ["Leman Akoglu and Jaemin Yoo"], "Categories": "cs.LG"}, "abstract": "Self-supervised learning (SSL) is a growing torrent that has recently transformed machine learning and its many real world applications, by learning on massive amounts of unlabeled data via self-generated supervisory signals. Unsupervised anomaly detection (AD) has also capitalized on SSL, by self-generating pseudo-anomalies through various data augmentation functions or external data exposure. In this vision paper, we first underline the importance of the choice of SSL strategies on AD performance, by presenting evidences and studies from the AD literature. Equipped with the understanding that SSL incurs various hyperparameters (HPs) to carefully tune, we present recent developments on unsupervised model selection and augmentation tuning for SSL-based AD. We then highlight emerging challenges and future opportunities; on designing new pretext tasks and augmentation functions for different data modalities, creating novel model selection solutions for systematically tuning the SSL HPs, as well as on capitalizing on the potential of pretrained foundation models on AD through effective density estimation.", "url": "https://arxiv.org/abs/2308.14380"}, {"metadata": {"arXiv": "2308.14412", "Date": "Mon, 28 Aug 2023 08:50:12 ", "Title": "Task-Aware Machine Unlearning and Its Application in Load Forecasting", "Authors": ["Wangkun Xu", "Fei Teng"], "Categories": "cs.LG cs.SY eess.SY"}, "abstract": "Data privacy and security have become a non-negligible factor in load forecasting. Previous researches mainly focus on training stage enhancement. However, once the model is trained and deployed, it may need to `forget' (i.e., remove the impact of) part of training data if the data is found to be malicious or as requested by the data owner. This paper introduces machine unlearning algorithm which is specifically designed to remove the influence of part of the original dataset on an already trained forecaster. However, direct unlearning inevitably degrades the model generalization ability. To balance between unlearning completeness and performance degradation, a performance-aware algorithm is proposed by evaluating the sensitivity of local model parameter change using influence function and sample re-weighting. Moreover, we observe that the statistic criterion cannot fully reflect the operation cost of down-stream tasks. Therefore, a task-aware machine unlearning is proposed whose objective is a tri-level optimization with dispatch and redispatch problems considered. We theoretically prove the existence of the gradient of such objective, which is key to re-weighting the remaining samples. We test the unlearning algorithms on linear and neural network load forecasters with realistic load dataset. The simulation demonstrates the balance on unlearning completeness and operational cost. All codes can be found at https://github.com/xuwkk/task_aware_machine_unlearning.", "url": "https://arxiv.org/abs/2308.14412"}, {"metadata": {"arXiv": "2308.14481", "Date": "Mon, 28 Aug 2023 10:43:53 ", "Title": "Group Regression for Query Based Object Detection and Tracking", "Authors": ["Felicia Ruppel", "Florian Faion", "Claudius Gl\\\"aser and Klaus Dietmayer"], "Categories": "cs.LG cs.CV", "Comments": ["Accepted for publication at the 2023 26th IEEE International Conference on Intelligent Transportation Systems (ITSC 2023)", "Sep 24-28", "2023", "in Bilbao", "Spain"]}, "abstract": "Group regression is commonly used in 3D object detection to predict box parameters of similar classes in a joint head, aiming to benefit from similarities while separating highly dissimilar classes. For query-based perception methods, this has, so far, not been feasible. We close this gap and present a method to incorporate multi-class group regression, especially designed for the 3D domain in the context of autonomous driving, into existing attention and query-based perception approaches. We enhance a transformer based joint object detection and tracking model with this approach, and thoroughly evaluate its behavior and performance. For group regression, the classes of the nuScenes dataset are divided into six groups of similar shape and prevalence, each being regressed by a dedicated head. We show that the proposed method is applicable to many existing transformer based perception approaches and can bring potential benefits. The behavior of query group regression is thoroughly analyzed in comparison to a unified regression head, e.g. in terms of class-switching behavior and distribution of the output parameters. The proposed method offers many possibilities for further research, such as in the direction of deep multi-hypotheses tracking.", "url": "https://arxiv.org/abs/2308.14481"}, {"metadata": {"arXiv": "2308.14516", "Date": "Mon, 28 Aug 2023 12:03:03 ", "Title": "Prediction of Tourism Flow with Sparse Geolocation Data", "Authors": ["Julian Lemmel", "Zahra Babaiee", "Marvin Kleinlehner", "Ivan Majic", "Philipp Neubauer", "Johannes Scholz", "Radu Grosu", "Sophie A. Neubauer"], "Categories": "cs.LG stat.AP", "Comments": ["Accepted for publication at the proceedings of the 5th International Data Science Conference - iDSC2023. arXiv admin note: substantial text overlap with arXiv:2206.13274"]}, "abstract": "Modern tourism in the 21st century is facing numerous challenges. Among these the rapidly growing number of tourists visiting space-limited regions like historical cities, museums and bottlenecks such as bridges is one of the biggest. In this context, a proper and accurate prediction of tourism volume and tourism flow within a certain area is important and critical for visitor management tasks such as sustainable treatment of the environment and prevention of overcrowding. Static flow control methods like conventional low-level controllers or limiting access to overcrowded venues could not solve the problem yet. In this paper, we empirically evaluate the performance of state-of-the-art deep-learning methods such as RNNs, GNNs, and Transformers as well as the classic statistical ARIMA method. Granular limited data supplied by a tourism region is extended by exogenous data such as geolocation trajectories of individual tourists, weather and holidays. In the field of visitor flow prediction with sparse data, we are thereby capable of increasing the accuracy of our predictions, incorporating modern input feature handling as well as mapping geolocation data on top of discrete POI data.", "url": "https://arxiv.org/abs/2308.14516"}, {"metadata": {"arXiv": "2308.14555", "Date": "Mon, 28 Aug 2023 13:17:39 ", "Title": "Kernel Limit of Recurrent Neural Networks Trained on Ergodic Data Sequences", "Authors": ["Samuel Chun-Hei Lam", "Justin Sirignano", "and Konstantinos Spiliopoulos"], "Categories": "cs.LG math.PR stat.ML"}, "abstract": "Mathematical methods are developed to characterize the asymptotics of recurrent neural networks (RNN) as the number of hidden units, data samples in the sequence, hidden state updates, and training steps simultaneously grow to infinity. In the case of an RNN with a simplified weight matrix, we prove the convergence of the RNN to the solution of an infinite-dimensional ODE coupled with the fixed point of a random algebraic equation. The analysis requires addressing several challenges which are unique to RNNs. In typical mean-field applications (e.g., feedforward neural networks), discrete updates are of magnitude $\\mathcal{O}(\\frac{1}{N})$ and the number of updates is $\\mathcal{O}(N)$. Therefore, the system can be represented as an Euler approximation of an appropriate ODE/PDE, which it will converge to as $N \\rightarrow \\infty$. However, the RNN hidden layer updates are $\\mathcal{O}(1)$. Therefore, RNNs cannot be represented as a discretization of an ODE/PDE and standard mean-field techniques cannot be applied. Instead, we develop a fixed point analysis for the evolution of the RNN memory states, with convergence estimates in terms of the number of update steps and the number of hidden units. The RNN hidden layer is studied as a function in a Sobolev space, whose evolution is governed by the data sequence (a Markov chain), the parameter updates, and its dependence on the RNN hidden layer at the previous time step. Due to the strong correlation between updates, a Poisson equation must be used to bound the fluctuations of the RNN around its limit equation. These mathematical methods give rise to the neural tangent kernel (NTK) limits for RNNs trained on data sequences as the number of data samples and size of the neural network grow to infinity.", "url": "https://arxiv.org/abs/2308.14555"}, {"metadata": {"arXiv": "2308.14606", "Date": "Mon, 28 Aug 2023 14:20:53 ", "Title": "On the Tradeoff between Privacy Preservation and Byzantine-Robustness in Decentralized Learning", "Authors": ["Haoxiang Ye", "Heng Zhu", "and Qing Ling"], "Categories": "cs.LG cs.CR cs.DC"}, "abstract": "This paper jointly considers privacy preservation and Byzantine-robustness in decentralized learning. In a decentralized network, honest-but-curious agents faithfully follow the prescribed algorithm, but expect to infer their neighbors' private data from messages received during the learning process, while dishonest-and-Byzantine agents disobey the prescribed algorithm, and deliberately disseminate wrong messages to their neighbors so as to bias the learning process. For this novel setting, we investigate a generic privacy-preserving and Byzantine-robust decentralized stochastic gradient descent (SGD) framework, in which Gaussian noise is injected to preserve privacy and robust aggregation rules are adopted to counteract Byzantine attacks. We analyze its learning error and privacy guarantee, discovering an essential tradeoff between privacy preservation and Byzantine-robustness in decentralized learning -- the learning error caused by defending against Byzantine attacks is exacerbated by the Gaussian noise added to preserve privacy. Numerical experiments are conducted and corroborate our theoretical findings.", "url": "https://arxiv.org/abs/2308.14606"}, {"metadata": {"arXiv": "2308.14608", "Date": "Mon, 28 Aug 2023 14:23:04 ", "Title": "AI in the Gray: Exploring Moderation Policies in Dialogic Large Language Models vs. Human Answers in Controversial Topics", "Authors": ["Vahid Ghafouri", "Vibhor Agarwal", "Yong Zhang", "Nishanth Sastry", "Jose Such", "Guillermo Suarez-Tangil"], "Categories": "cs.LG cs.CL cs.CY cs.SI", "DOI": "10.1145/3583780.3614777"}, "abstract": "The introduction of ChatGPT and the subsequent improvement of Large Language Models (LLMs) have prompted more and more individuals to turn to the use of ChatBots, both for information and assistance with decision-making. However, the information the user is after is often not formulated by these ChatBots objectively enough to be provided with a definite, globally accepted answer. Controversial topics, such as \"religion\", \"gender identity\", \"freedom of speech\", and \"equality\", among others, can be a source of conflict as partisan or biased answers can reinforce preconceived notions or promote disinformation. By exposing ChatGPT to such debatable questions, we aim to understand its level of awareness and if existing models are subject to socio-political and/or economic biases. We also aim to explore how AI-generated answers compare to human ones. For exploring this, we use a dataset of a social media platform created for the purpose of debating human-generated claims on polemic subjects among users, dubbed Kialo. Our results show that while previous versions of ChatGPT have had important issues with controversial topics, more recent versions of ChatGPT (gpt-3.5-turbo) are no longer manifesting significant explicit biases in several knowledge areas. In particular, it is well-moderated regarding economic aspects. However, it still maintains degrees of implicit libertarian leaning toward right-winged ideals which suggest the need for increased moderation from the socio-political point of view. In terms of domain knowledge on controversial topics, with the exception of the \"Philosophical\" category, ChatGPT is performing well in keeping up with the collective human level of knowledge. Finally, we see that sources of Bing AI have slightly more tendency to the center when compared to human answers. All the analyses we make are generalizable to other types of biases and domains.", "url": "https://arxiv.org/abs/2308.14608"}, {"metadata": {"arXiv": "2308.14632", "Date": "Mon, 28 Aug 2023 14:57:29 ", "Title": "Comparing AutoML and Deep Learning Methods for Condition Monitoring using Realistic Validation Scenarios", "Authors": ["Payman Goodarzi", "Andreas Sch\\\"utze", "Tizian Schneider"], "Categories": "cs.LG eess.SP", "Comments": ["This work has been submitted to the IEEE for possible publication"]}, "abstract": "This study extensively compares conventional machine learning methods and deep learning for condition monitoring tasks using an AutoML toolbox. The experiments reveal consistent high accuracy in random K-fold cross-validation scenarios across all tested models. However, when employing leave-one-group-out (LOGO) cross-validation on the same datasets, no clear winner emerges, indicating the presence of domain shift in real-world scenarios. Additionally, the study assesses the scalability and interpretability of conventional methods and neural networks. Conventional methods offer explainability with their modular structure aiding feature identification. In contrast, neural networks require specialized interpretation techniques like occlusion maps to visualize important regions in the input data. Finally, the paper highlights the significance of feature selection, particularly in condition monitoring tasks with limited class variations. Low-complexity models prove sufficient for such tasks, as only a few features from the input signal are typically needed. In summary, these findings offer crucial insights into the strengths and limitations of various approaches, providing valuable benchmarks and identifying the most suitable methods for condition monitoring applications, thereby enhancing their applicability in real-world scenarios.", "url": "https://arxiv.org/abs/2308.14632"}, {"metadata": {"arXiv": "2308.14642", "Date": "Mon, 28 Aug 2023 15:16:09 ", "Title": "Rate-Optimal Policy Optimization for Linear Markov Decision Processes", "Authors": ["Uri Sherman", "Alon Cohen", "Tomer Koren", "Yishay Mansour"], "Categories": "cs.LG"}, "abstract": "We study regret minimization in online episodic linear Markov Decision Processes, and obtain rate-optimal $\\widetilde O (\\sqrt K)$ regret where $K$ denotes the number of episodes. Our work is the first to establish the optimal (w.r.t.~$K$) rate of convergence in the stochastic setting with bandit feedback using a policy optimization based approach, and the first to establish the optimal (w.r.t.~$K$) rate in the adversarial setup with full information feedback, for which no algorithm with an optimal rate guarantee is currently known.", "url": "https://arxiv.org/abs/2308.14642"}, {"metadata": {"arXiv": "2308.14647", "Date": "Mon, 28 Aug 2023 15:19:18 ", "Title": "Edge Generation Scheduling for DAG Tasks using Deep Reinforcement Learning", "Authors": ["Binqi Sun", "Mirco Theile", "Ziyuan Qin", "Daniele Bernardini", "Debayan Roy", "Andrea Bastoni", "and Marco Caccamo"], "Categories": "cs.LG cs.DC cs.DM", "Comments": ["Under review"]}, "abstract": "Directed acyclic graph (DAG) tasks are currently adopted in the real-time domain to model complex applications from the automotive, avionics, and industrial domain that implement their functionalities through chains of intercommunicating tasks. This paper studies the problem of scheduling real-time DAG tasks by presenting a novel schedulability test based on the concept of trivial schedulability. Using this schedulability test, we propose a new DAG scheduling framework (edge generation scheduling -- EGS) that attempts to minimize the DAG width by iteratively generating edges while guaranteeing the deadline constraint. We study how to efficiently solve the problem of generating edges by developing a deep reinforcement learning algorithm combined with a graph representation neural network to learn an efficient edge generation policy for EGS. We evaluate the effectiveness of the proposed algorithm by comparing it with state-of-the-art DAG scheduling heuristics and an optimal mixed-integer linear programming baseline. Experimental results show that the proposed algorithm outperforms the state-of-the-art by requiring fewer processors to schedule the same DAG tasks.", "url": "https://arxiv.org/abs/2308.14647"}, {"metadata": {"arXiv": "2308.14658", "Date": "Mon, 28 Aug 2023 15:40:50 ", "Title": "Adversarial Predictions of Data Distributions Across Federated Internet-of-Things Devices", "Authors": ["Samir Rajani", "Dario Dematties", "Nathaniel Hudson", "Kyle Chard", "Nicola Ferrier", "Rajesh Sankaran", "Peter Beckman"], "Categories": "cs.LG cs.DC", "Comments": ["6 pages", "6 figures", "accepted for publication through 2023 IEEE World Forum on Internet of Things"]}, "abstract": "Federated learning (FL) is increasingly becoming the default approach for training machine learning models across decentralized Internet-of-Things (IoT) devices. A key advantage of FL is that no raw data are communicated across the network, providing an immediate layer of privacy. Despite this, recent works have demonstrated that data reconstruction can be done with the locally trained model updates which are communicated across the network. However, many of these works have limitations with regard to how the gradients are computed in backpropagation. In this work, we demonstrate that the model weights shared in FL can expose revealing information about the local data distributions of IoT devices. This leakage could expose sensitive information to malicious actors in a distributed system. We further discuss results which show that injecting noise into model weights is ineffective at preventing data leakage without seriously harming the global model accuracy.", "url": "https://arxiv.org/abs/2308.14658"}, {"metadata": {"arXiv": "2308.14659", "Date": "Mon, 28 Aug 2023 15:41:30 ", "Title": "RESTORE: Graph Embedding Assessment Through Reconstruction", "Authors": ["Hong Yung Yip", "Chidaksh Ravuru", "Neelabha Banerjee", "Shashwat Jha", "Amit Sheth", "Aman Chadha", "Amitava Das"], "Categories": "cs.LG"}, "abstract": "Following the success of Word2Vec embeddings, graph embeddings (GEs) have gained substantial traction. GEs are commonly generated and evaluated extrinsically on downstream applications, but intrinsic evaluations of the original graph properties in terms of topological structure and semantic information have been lacking. Understanding these will help identify the deficiency of the various families of GE methods when vectorizing graphs in terms of preserving the relevant knowledge or learning incorrect knowledge. To address this, we propose RESTORE, a framework for intrinsic GEs assessment through graph reconstruction. We show that reconstructing the original graph from the underlying GEs yields insights into the relative amount of information preserved in a given vector form. We first introduce the graph reconstruction task. We generate GEs from three GE families based on factorization methods, random walks, and deep learning (with representative algorithms from each family) on the CommonSense Knowledge Graph (CSKG). We analyze their effectiveness in preserving the (a) topological structure of node-level graph reconstruction with an increasing number of hops and (b) semantic information on various word semantic and analogy tests. Our evaluations show deep learning-based GE algorithm (SDNE) is overall better at preserving (a) with a mean average precision (mAP) of 0.54 and 0.35 for 2 and 3-hop reconstruction respectively, while the factorization-based algorithm (HOPE) is better at encapsulating (b) with an average Euclidean distance of 0.14, 0.17, and 0.11 for 1, 2, and 3-hop reconstruction respectively. The modest performance of these GEs leaves room for further research avenues on better graph representation learning.", "url": "https://arxiv.org/abs/2308.14659"}, {"metadata": {"arXiv": "2308.14644", "Date": "Mon, 28 Aug 2023 15:16:35 ", "Title": "Human Comfortability Index Estimation in Industrial Human-Robot Collaboration Task", "Authors": ["Celal Savur", "Jamison Heard", "and Ferat Sahin"], "Categories": "cs.RO cs.HC cs.LG", "Comments": ["Submitted to IEEE-THMS"]}, "abstract": "Fluent human-robot collaboration requires a robot teammate to understand, learn, and adapt to the human's psycho-physiological state. Such collaborations require a computing system that monitors human physiological signals during human-robot collaboration (HRC) to quantitatively estimate a human's level of comfort, which we have termed in this research as comfortability index (CI) and uncomfortability index (unCI). Subjective metrics (surprise, anxiety, boredom, calmness, and comfortability) and physiological signals were collected during a human-robot collaboration experiment that varied robot behavior. The emotion circumplex model is adapted to calculate the CI from the participant's quantitative data as well as physiological data. To estimate CI/unCI from physiological signals, time features were extracted from electrocardiogram (ECG), galvanic skin response (GSR), and pupillometry signals. In this research, we successfully adapt the circumplex model to find the location (axis) of 'comfortability' and 'uncomfortability' on the circumplex model, and its location match with the closest emotions on the circumplex model. Finally, the study showed that the proposed approach can estimate human comfortability/uncomfortability from physiological signals.", "url": "https://arxiv.org/abs/2308.14644"}, {"metadata": {"arXiv": "2308.14348", "Date": "Mon, 28 Aug 2023 06:48:06 ", "Title": "Label-free Deep Learning Driven Secure Access Selection in Space-Air-Ground Integrated Networks", "Authors": ["Zhaowei Wang", "Zhisheng Yin", "Xiucheng Wang", "Nan Cheng", "Yuan Zhang", "Tom H. Luan"], "Categories": "eess.SY cs.CR cs.LG cs.SY"}, "abstract": "In Space-air-ground integrated networks (SAGIN), the inherent openness and extensive broadcast coverage expose these networks to significant eavesdropping threats. Considering the inherent co-channel interference due to spectrum sharing among multi-tier access networks in SAGIN, it can be leveraged to assist the physical layer security among heterogeneous transmissions. However, it is challenging to conduct a secrecy-oriented access strategy due to both heterogeneous resources and different eavesdropping models. In this paper, we explore secure access selection for a scenario involving multi-mode users capable of accessing satellites, unmanned aerial vehicles, or base stations in the presence of eavesdroppers. Particularly, we propose a Q-network approximation based deep learning approach for selecting the optimal access strategy for maximizing the sum secrecy rate. Meanwhile, the power optimization is also carried out by an unsupervised learning approach to improve the secrecy performance. Remarkably, two neural networks are trained by unsupervised learning and Q-network approximation which are both label-free methods without knowing the optimal solution as labels. Numerical results verify the efficiency of our proposed power optimization approach and access strategy, leading to enhanced secure transmission performance.", "url": "https://arxiv.org/abs/2308.14348"}, {"metadata": {"arXiv": "2308.14602", "Date": "Mon, 28 Aug 2023 14:12:52 ", "Title": "Recent Progress in Energy Management of Connected Hybrid Electric Vehicles Using Reinforcement Learning", "Authors": ["Min Hua", "Bin Shuai", "Quan Zhou", "Jinhai Wang", "Yinglong He", "Hongming Xu"], "Categories": "eess.SY cs.LG cs.SY"}, "abstract": "The growing adoption of hybrid electric vehicles (HEVs) presents a transformative opportunity for revolutionizing transportation energy systems. The shift towards electrifying transportation aims to curb environmental concerns related to fossil fuel consumption. This necessitates efficient energy management systems (EMS) to optimize energy efficiency. The evolution of EMS from HEVs to connected hybrid electric vehicles (CHEVs) represent a pivotal shift. For HEVs, EMS now confronts the intricate energy cooperation requirements of CHEVs, necessitating advanced algorithms for route optimization, charging coordination, and load distribution. Challenges persist in both domains, including optimal energy utilization for HEVs, and cooperative eco-driving control (CED) for CHEVs across diverse vehicle types. Reinforcement learning (RL) stands out as a promising tool for addressing these challenges at hand. Specifically, within the realm of CHEVs, the application of multi-agent reinforcement learning (MARL) emerges as a powerful approach for effectively tackling the intricacies of CED control. Despite extensive research, few reviews span from individual vehicles to multi-vehicle scenarios. This review bridges the gap, highlighting challenges, advancements, and potential contributions of RL-based solutions for future sustainable transportation systems.", "url": "https://arxiv.org/abs/2308.14602"}, {"metadata": {"arXiv": "2308.13542", "Date": "Mon, 21 Aug 2023 02:07:35 ", "Title": "LaGR-SEQ: Language-Guided Reinforcement Learning with Sample-Efficient Querying", "Authors": ["Thommen George Karimpanal", "Laknath Buddhika Semage", "Santu Rana", "Hung Le", "Truyen Tran", "Sunil Gupta and Svetha Venkatesh"], "Categories": "cs.AI", "Comments": ["18 pages", "11 figures"]}, "abstract": "Large language models (LLMs) have recently demonstrated their impressive ability to provide context-aware responses via text. This ability could potentially be used to predict plausible solutions in sequential decision making tasks pertaining to pattern completion. For example, by observing a partial stack of cubes, LLMs can predict the correct sequence in which the remaining cubes should be stacked by extrapolating the observed patterns (e.g., cube sizes, colors or other attributes) in the partial stack. In this work, we introduce LaGR (Language-Guided Reinforcement learning), which uses this predictive ability of LLMs to propose solutions to tasks that have been partially completed by a primary reinforcement learning (RL) agent, in order to subsequently guide the latter's training. However, as RL training is generally not sample-efficient, deploying this approach would inherently imply that the LLM be repeatedly queried for solutions; a process that can be expensive and infeasible. To address this issue, we introduce SEQ (sample efficient querying), where we simultaneously train a secondary RL agent to decide when the LLM should be queried for solutions. Specifically, we use the quality of the solutions emanating from the LLM as the reward to train this agent. We show that our proposed framework LaGR-SEQ enables more efficient primary RL training, while simultaneously minimizing the number of queries to the LLM. We demonstrate our approach on a series of tasks and highlight the advantages of our approach, along with its limitations and potential future research directions.", "url": "https://arxiv.org/abs/2308.13542"}, {"metadata": {"arXiv": "2308.13548", "Date": "Tue, 22 Aug 2023 19:19:19 ", "Title": "Towards a Holodeck-style Simulation Game", "Authors": ["Ahad Shams", "Douglas Summers-Stay", "Vsevolod Metelsky", "Arpan Tripathi", "Karan Malhotra"], "Categories": "cs.AI", "Comments": ["18 pages", "11 figures"], "ACM-class": "I.2.7"}, "abstract": "We introduce Infinitia, a simulation game system that uses generative image and language models at play time to reshape all aspects of the setting and NPCs based on a short description from the player, in a way similar to how settings are created on the fictional Holodeck. Building off the ideas of the Generative Agents paper, our system introduces gameplay elements, such as infinite generated fantasy worlds, controllability of NPC behavior, humorous dialogue, cost & time efficiency, collaboration between players and elements of non-determinism among in-game events. Infinitia is implemented in the Unity engine with a server-client architecture, facilitating the addition of exciting features by community developers in the future. Furthermore, it uses a multiplayer framework to allow humans to be present and interact in the simulation. The simulation will be available in open-alpha shortly at https://infinitia.ai/ and we are looking forward to building upon it with the community.", "url": "https://arxiv.org/abs/2308.13548"}, {"metadata": {"arXiv": "2308.13658", "Date": "Fri, 25 Aug 2023 20:17:49 ", "Title": "Generating and Explaining Corner Cases Using Learnt Probabilistic Lane Graphs", "Authors": ["Enrik Maci", "Rhys Howard", "Lars Kunze"], "Categories": "cs.AI cs.RO", "Comments": ["8 Pages", "3 Figures", "1 Table", "To be published in the Proceedings of the 26th IEEE International Conference on Intelligent Transport Systems (2023)", "Adjusted final submission version"], "ACM-class": "E.1; G.1.1; G.3; I.2.6; I.2.9; I.6.0"}, "abstract": "Validating the safety of Autonomous Vehicles (AVs) operating in open-ended, dynamic environments is challenging as vehicles will eventually encounter safety-critical situations for which there is not representative training data. By increasing the coverage of different road and traffic conditions and by including corner cases in simulation-based scenario testing, the safety of AVs can be improved. However, the creation of corner case scenarios including multiple agents is non-trivial. Our approach allows engineers to generate novel, realistic corner cases based on historic traffic data and to explain why situations were safety-critical. In this paper, we introduce Probabilistic Lane Graphs (PLGs) to describe a finite set of lane positions and directions in which vehicles might travel. The structure of PLGs is learnt directly from spatio-temporal traffic data. The graph model represents the actions of the drivers in response to a given state in the form of a probabilistic policy. We use reinforcement learning techniques to modify this policy and to generate realistic and explainable corner case scenarios which can be used for assessing the safety of AVs.", "url": "https://arxiv.org/abs/2308.13658"}, {"metadata": {"arXiv": "2308.13755", "Date": "Sat, 26 Aug 2023 03:48:52 ", "Title": "i-Align: an interpretable knowledge graph alignment model", "Authors": ["Bayu Distiawan Trisedya", "Flora D Salim", "Jeffrey Chan", "Damiano Spina", "Falk Scholer", "Mark Sanderson"], "Categories": "cs.AI", "Comments": ["Data Min Knowl Disc (2023)"], "DOI": "10.1007/s10618-023-00963-3"}, "abstract": "Knowledge graphs (KGs) are becoming essential resources for many downstream applications. However, their incompleteness may limit their potential. Thus, continuous curation is needed to mitigate this problem. One of the strategies to address this problem is KG alignment, i.e., forming a more complete KG by merging two or more KGs. This paper proposes i-Align, an interpretable KG alignment model. Unlike the existing KG alignment models, i-Align provides an explanation for each alignment prediction while maintaining high alignment performance. Experts can use the explanation to check the correctness of the alignment prediction. Thus, the high quality of a KG can be maintained during the curation process (e.g., the merging process of two KGs). To this end, a novel Transformer-based Graph Encoder (Trans-GE) is proposed as a key component of i-Align for aggregating information from entities' neighbors (structures). Trans-GE uses Edge-gated Attention that combines the adjacency matrix and the self-attention matrix to learn a gating mechanism to control the information aggregation from the neighboring entities. It also uses historical embeddings, allowing Trans-GE to be trained over mini-batches, or smaller sub-graphs, to address the scalability issue when encoding a large KG. Another component of i-Align is a Transformer encoder for aggregating entities' attributes. This way, i-Align can generate explanations in the form of a set of the most influential attributes/neighbors based on attention weights. Extensive experiments are conducted to show the power of i-Align. The experiments include several aspects, such as the model's effectiveness for aligning KGs, the quality of the generated explanations, and its practicality for aligning large KGs. The results show the effectiveness of i-Align in these aspects.", "url": "https://arxiv.org/abs/2308.13755"}, {"metadata": {"arXiv": "2308.13760", "Date": "Sat, 26 Aug 2023 04:49:46 ", "Title": "How Can Context Help? Exploring Joint Retrieval of Passage and Personalized Context", "Authors": ["Hui Wan", "Hongkang Li", "Songtao Lu", "Xiaodong Cui", "Marina Danilevsky"], "Categories": "cs.AI cs.CL cs.IR"}, "abstract": "The integration of external personalized context information into document-grounded conversational systems has significant potential business value, but has not been well-studied. Motivated by the concept of personalized context-aware document-grounded conversational systems, we introduce the task of context-aware passage retrieval. We also construct a dataset specifically curated for this purpose. We describe multiple baseline systems to address this task, and propose a novel approach, Personalized Context-Aware Search (PCAS), that effectively harnesses contextual information during passage retrieval. Experimental evaluations conducted on multiple popular dense retrieval systems demonstrate that our proposed approach not only outperforms the baselines in retrieving the most relevant passage but also excels at identifying the pertinent context among all the available contexts. We envision that our contributions will serve as a catalyst for inspiring future research endeavors in this promising direction.", "url": "https://arxiv.org/abs/2308.13760"}, {"metadata": {"arXiv": "2308.13801", "Date": "Sat, 26 Aug 2023 07:55:32 ", "Title": "Reinforcement Learning Based Multi-modal Feature Fusion Network for Novel Class Discovery", "Authors": ["Qiang Li", "Qiuyang Ma", "Weizhi Nie", "Anan Liu"], "Categories": "cs.AI cs.MM"}, "abstract": "With the development of deep learning techniques, supervised learning has achieved performances surpassing those of humans. Researchers have designed numerous corresponding models for different data modalities, achieving excellent results in supervised tasks. However, with the exponential increase of data in multiple fields, the recognition and classification of unlabeled data have gradually become a hot topic. In this paper, we employed a Reinforcement Learning framework to simulate the cognitive processes of humans for effectively addressing novel class discovery in the Open-set domain. We deployed a Member-to-Leader Multi-Agent framework to extract and fuse features from multi-modal information, aiming to acquire a more comprehensive understanding of the feature space. Furthermore, this approach facilitated the incorporation of self-supervised learning to enhance model training. We employed a clustering method with varying constraint conditions, ranging from strict to loose, allowing for the generation of dependable labels for a subset of unlabeled data during the training phase. This iterative process is similar to human exploratory learning of unknown data. These mechanisms collectively update the network parameters based on rewards received from environmental feedback. This process enables effective control over the extent of exploration learning, ensuring the accuracy of learning in unknown data categories. We demonstrate the performance of our approach in both the 3D and 2D domains by employing the OS-MN40, OS-MN40-Miss, and Cifar10 datasets. Our approach achieves competitive competitive results.", "url": "https://arxiv.org/abs/2308.13801"}, {"metadata": {"arXiv": "2308.13812", "Date": "Sat, 26 Aug 2023 08:31:48 ", "Title": "Empowering Dynamics-aware Text-to-Video Diffusion with Large Language Models", "Authors": ["Hao Fei", "Shengqiong Wu", "Wei Ji", "Hanwang Zhang", "Tat-Seng Chua"], "Categories": "cs.AI cs.CV"}, "abstract": "Text-to-video (T2V) synthesis has gained increasing attention in the community, in which the recently emerged diffusion models (DMs) have promisingly shown stronger performance than the past approaches. While existing state-of-the-art DMs are competent to achieve high-resolution video generation, they may largely suffer from key limitations (e.g., action occurrence disorders, crude video motions) with respect to the intricate temporal dynamics modeling, one of the crux of video synthesis. In this work, we investigate strengthening the awareness of video dynamics for DMs, for high-quality T2V generation. Inspired by human intuition, we design an innovative dynamic scene manager (dubbed as Dysen) module, which includes (step-1) extracting from input text the key actions with proper time-order arrangement, (step-2) transforming the action schedules into the dynamic scene graph (DSG) representations, and (step-3) enriching the scenes in the DSG with sufficient and reasonable details. Taking advantage of the existing powerful LLMs (e.g., ChatGPT) via in-context learning, Dysen realizes (nearly) human-level temporal dynamics understanding. Finally, the resulting video DSG with rich action scene details is encoded as fine-grained spatio-temporal features, integrated into the backbone T2V DM for video generating. Experiments on popular T2V datasets suggest that our framework consistently outperforms prior arts with significant margins, especially in the scenario with complex actions. Project page at https://haofei.vip/Dysen-VDM", "url": "https://arxiv.org/abs/2308.13812"}, {"metadata": {"arXiv": "2308.13871", "Date": "Sat, 26 Aug 2023 13:05:01 ", "Title": "Graph Edit Distance Learning via Different Attention", "Authors": ["Jiaxi Lv", "Liang Zhang", "Yi Huang", "Jiancheng Huang", "Shifeng Chen"], "Categories": "cs.AI"}, "abstract": "Recently, more and more research has focused on using Graph Neural Networks (GNN) to solve the Graph Similarity Computation problem (GSC), i.e., computing the Graph Edit Distance (GED) between two graphs. These methods treat GSC as an end-to-end learnable task, and the core of their architecture is the feature fusion modules to interact with the features of two graphs. Existing methods consider that graph-level embedding is difficult to capture the differences in local small structures between two graphs, and thus perform fine-grained feature fusion on node-level embedding can improve the accuracy, but leads to greater time and memory consumption in the training and inference phases. However, this paper proposes a novel graph-level fusion module Different Attention (DiffAtt), and demonstrates that graph-level fusion embeddings can substantially outperform these complex node-level fusion embeddings. We posit that the relative difference structure of the two graphs plays an important role in calculating their GED values. To this end, DiffAtt uses the difference between two graph-level embeddings as an attentional mechanism to capture the graph structural difference of the two graphs. Based on DiffAtt, a new GSC method, named Graph Edit Distance Learning via Different Attention (REDRAFT), is proposed, and experimental results demonstrate that REDRAFT achieves state-of-the-art performance in 23 out of 25 metrics in five benchmark datasets. Especially on MSE, it respectively outperforms the second best by 19.9%, 48.8%, 29.1%, 31.6%, and 2.2%. Moreover, we propose a quantitative test Remaining Subgraph Alignment Test (RESAT) to verify that among all graph-level fusion modules, the fusion embedding generated by DiffAtt can best capture the structural differences between two graphs.", "url": "https://arxiv.org/abs/2308.13871"}, {"metadata": {"arXiv": "2308.13911", "Date": "Sat, 26 Aug 2023 16:10:30 ", "Title": "A Wide Evaluation of ChatGPT on Affective Computing Tasks", "Authors": ["Mostafa M. Amin", "Rui Mao", "Erik Cambria", "Bj\\\"orn W. Schuller"], "Categories": "cs.AI cs.CL", "Comments": ["8 pages with references", "2 tables"]}, "abstract": "With the rise of foundation models, a new artificial intelligence paradigm has emerged, by simply using general purpose foundation models with prompting to solve problems instead of training a separate machine learning model for each problem. Such models have been shown to have emergent properties of solving problems that they were not initially trained on. The studies for the effectiveness of such models are still quite limited. In this work, we widely study the capabilities of the ChatGPT models, namely GPT-4 and GPT-3.5, on 13 affective computing problems, namely aspect extraction, aspect polarity classification, opinion extraction, sentiment analysis, sentiment intensity ranking, emotions intensity ranking, suicide tendency detection, toxicity detection, well-being assessment, engagement measurement, personality assessment, sarcasm detection, and subjectivity detection. We introduce a framework to evaluate the ChatGPT models on regression-based problems, such as intensity ranking problems, by modelling them as pairwise ranking classification. We compare ChatGPT against more traditional NLP methods, such as end-to-end recurrent neural networks and transformers. The results demonstrate the emergent abilities of the ChatGPT models on a wide range of affective computing problems, where GPT-3.5 and especially GPT-4 have shown strong performance on many problems, particularly the ones related to sentiment, emotions, or toxicity. The ChatGPT models fell short for problems with implicit signals, such as engagement measurement and subjectivity detection.", "url": "https://arxiv.org/abs/2308.13911"}, {"metadata": {"arXiv": "2308.14034", "Date": "Sun, 27 Aug 2023 07:53:00 ", "Title": "Confucius: Iterative Tool Learning from Introspection Feedback by Easy-to-Difficult Curriculum", "Authors": ["Shen Gao", "Zhengliang Shi", "Minghang Zhu", "Bowen Fang", "Xin Xin", "Pengjie Ren", "Zhumin Chen", "Jun Ma"], "Categories": "cs.AI cs.CL"}, "abstract": "Augmenting large language models (LLMs) with external tools has emerged as a promising approach to extending the capability of LLMs. Although some works employ open-source LLMs for the tool learning task, most of them are trained in a controlled environment in which LLMs only learn to execute the human-provided tools. However, selecting proper tools from the large toolset is also a crucial ability for the tool learning model to be applied in real-world applications. Existing methods usually directly employ self-instruction methods to train the model, which ignores differences in tool complexity. In this paper, we propose the Confucius, a novel tool learning framework to train LLM to use complicated tools in real-world scenarios, which contains two main phases: (1) We first propose a multi-stage learning method to teach the LLM to use various tools from an easy-to-difficult curriculum; (2) thenceforth, we propose the Iterative Self-instruct from Introspective Feedback (ISIF) to dynamically construct the dataset to improve the ability to use the complicated tool. Extensive experiments conducted on both controlled and real-world settings demonstrate the superiority of our tool learning framework in the real-world application scenarios compared to both tuning-free (e.g. ChatGPT, Claude) and tuning-based baselines (e.g. GPT4Tools).", "url": "https://arxiv.org/abs/2308.14034"}, {"metadata": {"arXiv": "2308.14199", "Date": "Sun, 27 Aug 2023 20:24:33 ", "Title": "Symbolic and Language Agnostic Large Language Models", "Authors": ["Walid S. Saba"], "Categories": "cs.AI cs.CL", "Comments": ["4 pages - draft. arXiv admin note: substantial text overlap with arXiv:2306.00017"]}, "abstract": "We argue that the relative success of large language models (LLMs) is not a reflection on the symbolic vs. subsymbolic debate but a reflection on employing an appropriate strategy of bottom-up reverse engineering of language at scale. However, due to the subsymbolic nature of these models whatever knowledge these systems acquire about language will always be buried in millions of microfeatures (weights) none of which is meaningful on its own. Moreover, and due to their stochastic nature, these models will often fail in capturing various inferential aspects that are prevalent in natural language. What we suggest here is employing the successful bottom-up strategy in a symbolic setting, producing symbolic, language agnostic and ontologically grounded large language models.", "url": "https://arxiv.org/abs/2308.14199"}, {"metadata": {"arXiv": "2308.14242", "Date": "Mon, 28 Aug 2023 01:05:18 ", "Title": "The Cultural Psychology of Large Language Models: Is ChatGPT a Holistic or Analytic Thinker?", "Authors": ["Chuanyang Jin", "Songyang Zhang", "Tianmin Shu", "and Zhihan Cui"], "Categories": "cs.AI cs.CL"}, "abstract": "The prevalent use of Large Language Models (LLMs) has necessitated studying their mental models, yielding noteworthy theoretical and practical implications. Current research has demonstrated that state-of-the-art LLMs, such as ChatGPT, exhibit certain theory of mind capabilities and possess relatively stable Big Five and/or MBTI personality traits. In addition, cognitive process features form an essential component of these mental models. Research in cultural psychology indicated significant differences in the cognitive processes of Eastern and Western people when processing information and making judgments. While Westerners predominantly exhibit analytical thinking that isolates things from their environment to analyze their nature independently, Easterners often showcase holistic thinking, emphasizing relationships and adopting a global viewpoint. In our research, we probed the cultural cognitive traits of ChatGPT. We employed two scales that directly measure the cognitive process: the Analysis-Holism Scale (AHS) and the Triadic Categorization Task (TCT). Additionally, we used two scales that investigate the value differences shaped by cultural thinking: the Dialectical Self Scale (DSS) and the Self-construal Scale (SCS). In cognitive process tests (AHS/TCT), ChatGPT consistently tends towards Eastern holistic thinking, but regarding value judgments (DSS/SCS), ChatGPT does not significantly lean towards the East or the West. We suggest that the result could be attributed to both the training paradigm and the training data in LLM development. We discuss the potential value of this finding for AI research and directions for future research.", "url": "https://arxiv.org/abs/2308.14242"}, {"metadata": {"arXiv": "2308.14269", "Date": "Mon, 28 Aug 2023 02:54:05 ", "Title": "Utilizing Mood-Inducing Background Music in Human-Robot Interaction", "Authors": ["Elad Liebman", "Peter Stone"], "Categories": "cs.AI"}, "abstract": "Past research has clearly established that music can affect mood and that mood affects emotional and cognitive processing, and thus decision-making. It follows that if a robot interacting with a person needs to predict the person's behavior, knowledge of the music the person is listening to when acting is a potentially relevant feature. To date, however, there has not been any concrete evidence that a robot can improve its human-interactive decision-making by taking into account what the person is listening to. This research fills this gap by reporting the results of an experiment in which human participants were required to complete a task in the presence of an autonomous agent while listening to background music. Specifically, the participants drove a simulated car through an intersection while listening to music. The intersection was not empty, as another simulated vehicle, controlled autonomously, was also crossing the intersection in a different direction. Our results clearly indicate that such background information can be effectively incorporated in an agent's world representation in order to better predict people's behavior. We subsequently analyze how knowledge of music impacted both participant behavior and the resulting learned policy.\\setcounter{footnote}{2}\\footnote{An earlier version of part of the material in this paper appeared originally in the first author's Ph.D. Dissertation~\\cite{liebman2020sequential} but it has not appeared in any pear-reviewed conference or journal.}", "url": "https://arxiv.org/abs/2308.14269"}, {"metadata": {"arXiv": "2308.14284", "Date": "Mon, 28 Aug 2023 03:49:13 ", "Title": "LLM Powered Sim-to-real Transfer for Traffic Signal Control", "Authors": ["Longchao Da", "Minchiuan Gao", "Hao Mei", "Hua Wei"], "Categories": "cs.AI", "Comments": ["9 pages", "7 figures. arXiv admin note: text overlap with arXiv:2307.12388"], "ACM-class": "H.4.0"}, "abstract": "Numerous solutions are proposed for the Traffic Signal Control (TSC) tasks aiming to provide efficient transportation and mitigate congestion waste. In recent, promising results have been attained by Reinforcement Learning (RL) methods through trial and error in simulators, bringing confidence in solving cities' congestion headaches. However, there still exist performance gaps when simulator-trained policies are deployed to the real world. This issue is mainly introduced by the system dynamic difference between the training simulator and the real-world environments. The Large Language Models (LLMs) are trained on mass knowledge and proved to be equipped with astonishing inference abilities. In this work, we leverage LLMs to understand and profile the system dynamics by a prompt-based grounded action transformation. Accepting the cloze prompt template, and then filling in the answer based on accessible context, the pre-trained LLM's inference ability is exploited and applied to understand how weather conditions, traffic states, and road types influence traffic dynamics, being aware of this, the policies' action is taken and grounded based on realistic dynamics, thus help the agent learn a more realistic policy. We conduct experiments using DQN to show the effectiveness of the proposed PromptGAT's ability in mitigating the performance gap from simulation to reality (sim-to-real).", "url": "https://arxiv.org/abs/2308.14284"}, {"metadata": {"arXiv": "2308.14301", "Date": "Mon, 28 Aug 2023 04:35:20 ", "Title": "Artificial Intelligence in Career Counseling: A Test Case with ResumAI", "Authors": ["Muhammad Rahman", "Sachi Figliolini", "Joyce Kim", "Eivy Cedeno", "Charles Kleier", "Chirag Shah", "Aman Chadha"], "Categories": "cs.AI"}, "abstract": "The rise of artificial intelligence (AI) has led to various means of integration of AI aimed to provide efficiency in tasks, one of which is career counseling. A key part of getting a job is having a solid resume that passes through the first round of programs and recruiters. It is difficult to find good resources or schedule an appointment with a career counselor to help with editing a resume for a specific role. With the rise of ChatGPT, Bard, and several other AI chat programs it is possible to provide specific, automated feedback on various concerns to suggest places for improvement within the context of career counseling. This paper begins with a quick literature review on the ethical considerations and limitations of AI in career counseling. The authors also have created their own website service, called ResumAI, to test and review the functionality of an AI career counselor. The findings of this study will contribute to the understanding of chat AI ResumAI reviewer programs and sites. The implications of the findings for the field of career counseling, AI development, and ethical practice will be discussed.", "url": "https://arxiv.org/abs/2308.14301"}, {"metadata": {"arXiv": "2308.14311", "Date": "Mon, 28 Aug 2023 05:29:49 ", "Title": "Spread Control Method on Unknown Networks Based on Hierarchical Reinforcement Learning", "Authors": ["Wenxiang Dong and H.Vicky Zhao"], "Categories": "cs.AI cs.SI"}, "abstract": "The spread of infectious diseases, rumors, and harmful speech in networks can result in substantial losses, underscoring the significance of studying how to suppress such hazardous events. However, previous studies often assume full knowledge of the network structure, which is often not the case in real-world scenarios. In this paper, we address the challenge of controlling the propagation of hazardous events by removing nodes when the network structure is unknown. To tackle this problem, we propose a hierarchical reinforcement learning method that drastically reduces the action space, making the problem feasible to solve. Simulation experiments demonstrate the superiority of our method over the baseline methods. Remarkably, even though the baseline methods possess extensive knowledge of the network structure, while our method has no prior information about it, our approach still achieves better results.", "url": "https://arxiv.org/abs/2308.14311"}, {"metadata": {"arXiv": "2308.14326", "Date": "Mon, 28 Aug 2023 06:10:26 ", "Title": "Towards solving ontological dissonance using network graphs", "Authors": ["Maximilian Staebler", "Frank Koester", "Christoph Schlueter-Langdon"], "Categories": "cs.AI cs.SI", "Comments": ["5 pages", "AMCIS 2023 proceedings"]}, "abstract": "Data Spaces are an emerging concept for the trusted implementation of data-based applications and business models, offering a high degree of flexibility and sovereignty to all stakeholders. As Data Spaces are currently emerging in different domains such as mobility, health or food, semantic interfaces need to be identified and implemented to ensure the technical interoperability of these Data Spaces. This paper consolidates data models from 13 different domains and analyzes the ontological dissonance of these domains. Using a network graph, central data models and ontology attributes are identified, while the semantic heterogeneity of these domains is described qualitatively. The research outlook describes how these results help to connect different Data Spaces across domains.", "url": "https://arxiv.org/abs/2308.14326"}, {"metadata": {"arXiv": "2308.14337", "Date": "Mon, 28 Aug 2023 06:30:33 ", "Title": "Cognitive Effects in Large Language Models", "Authors": ["Jonathan Shaki", "Sarit Kraus", "Michael Wooldridge"], "Categories": "cs.AI cs.CL", "Comments": ["Accepted and will be published in the ECAI conference"]}, "abstract": "Large Language Models (LLMs) such as ChatGPT have received enormous attention over the past year and are now used by hundreds of millions of people every day. The rapid adoption of this technology naturally raises questions about the possible biases such models might exhibit. In this work, we tested one of these models (GPT-3) on a range of cognitive effects, which are systematic patterns that are usually found in human cognitive tasks. We found that LLMs are indeed prone to several human cognitive effects. Specifically, we show that the priming, distance, SNARC, and size congruity effects were presented with GPT-3, while the anchoring effect is absent. We describe our methodology, and specifically the way we converted real-world experiments to text-based experiments. Finally, we speculate on the possible reasons why GPT-3 exhibits these effects and discuss whether they are imitated or reinvented.", "url": "https://arxiv.org/abs/2308.14337"}, {"metadata": {"arXiv": "2308.14359", "Date": "Mon, 28 Aug 2023 07:11:27 ", "Title": "Effect of Attention and Self-Supervised Speech Embeddings on Non-Semantic Speech Tasks", "Authors": ["Payal Mohapatra", "Akash Pandey", "Yueyuan Sui", "Qi Zhu"], "Categories": "cs.AI cs.CL", "Comments": ["Accepted to appear at ACM Multimedia 2023 Multimedia Grand Challenges Track"], "DOI": "10.1145/3581783.3612855"}, "abstract": "Human emotion understanding is pivotal in making conversational technology mainstream. We view speech emotion understanding as a perception task which is a more realistic setting. With varying contexts (languages, demographics, etc.) different share of people perceive the same speech segment as a non-unanimous emotion. As part of the ACM Multimedia 2023 Computational Paralinguistics ChallengE (ComParE) in the EMotion Share track, we leverage their rich dataset of multilingual speakers and multi-label regression target of 'emotion share' or perception of that emotion. We demonstrate that the training scheme of different foundation models dictates their effectiveness for tasks beyond speech recognition, especially for non-semantic speech tasks like emotion understanding. This is a very complex task due to multilingual speakers, variability in the target labels, and inherent imbalance in the regression dataset. Our results show that HuBERT-Large with a self-attention-based light-weight sequence model provides 4.6% improvement over the reported baseline.", "url": "https://arxiv.org/abs/2308.14359"}, {"metadata": {"arXiv": "2308.14363", "Date": "Mon, 28 Aug 2023 07:21:26 ", "Title": "Rethinking Mobile AI Ecosystem in the LLM Era", "Authors": ["Jinliang Yuan", "Chen Yang", "Dongqi Cai", "Shihe Wang", "Xin Yuan", "Zeling Zhang", "Xiang Li", "Dingge Zhang", "Hanzi Mei", "Xianqing Jia", "Shangguang Wang", "Mengwei Xu"], "Categories": "cs.AI"}, "abstract": "In today's landscape, smartphones have evolved into hubs for hosting a multitude of deep learning models aimed at local execution. A key realization driving this work is the notable fragmentation among these models, characterized by varied architectures, operators, and implementations. This fragmentation imposes a significant burden on the comprehensive optimization of hardware, system settings, and algorithms. Buoyed by the recent strides in large foundation models, this work introduces a pioneering paradigm for mobile AI: a collaborative management approach between the mobile OS and hardware, overseeing a foundational model capable of serving a broad spectrum of mobile AI tasks, if not all. This foundational model resides within the NPU and remains impervious to app or OS revisions, akin to firmware. Concurrently, each app contributes a concise, offline fine-tuned \"adapter\" tailored to distinct downstream tasks. From this concept emerges a concrete instantiation known as \\sys. It amalgamates a curated selection of publicly available Large Language Models (LLMs) and facilitates dynamic data flow. This concept's viability is substantiated through the creation of an exhaustive benchmark encompassing 38 mobile AI tasks spanning 50 datasets, including domains such as Computer Vision (CV), Natural Language Processing (NLP), audio, sensing, and multimodal inputs. Spanning this benchmark, \\sys unveils its impressive performance. It attains accuracy parity in 85\\% of tasks, demonstrates improved scalability in terms of storage and memory, and offers satisfactory inference speed on Commercial Off-The-Shelf (COTS) mobile devices fortified with NPU support. This stands in stark contrast to task-specific models tailored for individual applications.", "url": "https://arxiv.org/abs/2308.14363"}, {"metadata": {"arXiv": "2308.14370", "Date": "Mon, 28 Aug 2023 07:39:53 ", "Title": "Model-based learning for location-to-channel mapping", "Authors": ["Baptiste Chatelier (IETR", "MERCE-France", "INSA Rennes)", "Luc Le Magoarou (IETR", "INSA Rennes)", "Vincent Corlay (MERCE-France)", "Matthieu Crussi\\`ere (IETR", "INSA Rennes)"], "Categories": "cs.AI eess.SP"}, "abstract": "Modern communication systems rely on accurate channel estimation to achieve efficient and reliable transmission of information. As the communication channel response is highly related to the user's location, one can use a neural network to map the user's spatial coordinates to the channel coefficients. However, these latter are rapidly varying as a function of the location, on the order of the wavelength. Classical neural architectures being biased towards learning low frequency functions (spectral bias), such mapping is therefore notably difficult to learn. In order to overcome this limitation, this paper presents a frugal, model-based network that separates the low frequency from the high frequency components of the target mapping function. This yields an hypernetwork architecture where the neural network only learns low frequency sparse coefficients in a dictionary of high frequency components. Simulation results show that the proposed neural network outperforms standard approaches on realistic synthetic data.", "url": "https://arxiv.org/abs/2308.14370"}, {"metadata": {"arXiv": "2308.14390", "Date": "Mon, 28 Aug 2023 08:14:12 ", "Title": "ASCAPE: An open AI ecosystem to support the quality of life of cancer patients", "Authors": ["Konstantinos Lampropoulos", "Thanos Kosmidis", "Serge Autexier", "Milos Savic", "Manos Athanatos", "Miltiadis Kokkonidis", "Tzortzia Koutsouri", "Anamaria Vizitiu", "Antonios Valachis", "Miriam Quintero Padron"], "Categories": "cs.AI", "DOI": "10.1109/ICHI52183.2021.00054"}, "abstract": "The latest cancer statistics indicate a decrease in cancer-related mortality. However, due to the growing and ageing population, the absolute number of people living with cancer is set to keep increasing. This paper presents ASCAPE, an open AI infrastructure that takes advantage of the recent advances in Artificial Intelligence (AI) and Machine Learning (ML) to support cancer patients quality of life (QoL). With ASCAPE health stakeholders (e.g. hospitals) can locally process their private medical data and then share the produced knowledge (ML models) through the open AI infrastructure.", "url": "https://arxiv.org/abs/2308.14390"}, {"metadata": {"arXiv": "2308.14474", "Date": "Mon, 28 Aug 2023 10:24:51 ", "Title": "Causality-Based Feature Importance Quantifying Methods:PN-FI, PS-FI and PNS-FI", "Authors": ["Shuxian Du", "Yaxiu Sun and Changyi Du"], "Categories": "cs.AI", "Comments": ["7 pages"]}, "abstract": "In current ML field models are getting larger and more complex, data we use are also getting larger in quantity and higher in dimension, so in order to train better models, save training time and computational resources, a good Feature Selection (FS) method in preprocessing stage is necessary. Feature importance (FI) is of great importance since it is the basis of feature selection. This paper creatively introduces the calculation of PNS(the probability of Necessity and Sufficiency) in Causality into quantifying feature importance and creates new FI measuring methods: PN-FI, which means how much importance a feature has in image recognition tasks, PS_FI that means how much importance a feature has in image generating tasks, and PNS_FI which measures both. The main body of this paper is three RCTs, with whose results we show how PS_FI, PN_FI and PNS_FI of three features: dog nose, dog eyes and dog mouth are calculated. The FI values are intervals with tight upper and lower bounds.", "url": "https://arxiv.org/abs/2308.14474"}, {"metadata": {"arXiv": "2308.14475", "Date": "Mon, 28 Aug 2023 10:26:37 ", "Title": "Interactive Multi Interest Process Pattern Discovery", "Authors": ["Mozhgan Vazifehdoostirani", "Laura Genga", "Xixi Lu", "Rob Verhoeven", "Hanneke van Laarhoven", "Remco Dijkman"], "Categories": "cs.AI", "Comments": ["16 pages", "5 figures", "To appear in the preceedings of 21st International Conference on Business Process Management (BPM)", "11-15 September 2023", "Utrecht", "the Netherlands"]}, "abstract": "Process pattern discovery methods (PPDMs) aim at identifying patterns of interest to users. Existing PPDMs typically are unsupervised and focus on a single dimension of interest, such as discovering frequent patterns. We present an interactive multi interest driven framework for process pattern discovery aimed at identifying patterns that are optimal according to a multi-dimensional analysis goal. The proposed approach is iterative and interactive, thus taking experts knowledge into account during the discovery process. The paper focuses on a concrete analysis goal, i.e., deriving process patterns that affect the process outcome. We evaluate the approach on real world event logs in both interactive and fully automated settings. The approach extracted meaningful patterns validated by expert knowledge in the interactive setting. Patterns extracted in the automated settings consistently led to prediction performance comparable to or better than patterns derived considering single interest dimensions without requiring user defined thresholds.", "url": "https://arxiv.org/abs/2308.14475"}, {"metadata": {"arXiv": "2308.14550", "Date": "Mon, 28 Aug 2023 13:09:00 ", "Title": "ReMAV: Reward Modeling of Autonomous Vehicles for Finding Likely Failure Events", "Authors": ["Aizaz Sharif and Dusica Marijan"], "Categories": "cs.AI"}, "abstract": "Autonomous vehicles are advanced driving systems that are well known for being vulnerable to various adversarial attacks, compromising the vehicle's safety, and posing danger to other road users. Rather than actively training complex adversaries by interacting with the environment, there is a need to first intelligently find and reduce the search space to only those states where autonomous vehicles are found less confident. In this paper, we propose a blackbox testing framework ReMAV using offline trajectories first to analyze the existing behavior of autonomous vehicles and determine appropriate thresholds for finding the probability of failure events. Our reward modeling technique helps in creating a behavior representation that allows us to highlight regions of likely uncertain behavior even when the baseline autonomous vehicle is performing well. This approach allows for more efficient testing without the need for computational and inefficient active adversarial learning techniques. We perform our experiments in a high-fidelity urban driving environment using three different driving scenarios containing single and multi-agent interactions. Our experiment shows 35%, 23%, 48%, and 50% increase in occurrences of vehicle collision, road objects collision, pedestrian collision, and offroad steering events respectively by the autonomous vehicle under test, demonstrating a significant increase in failure events. We also perform a comparative analysis with prior testing frameworks and show that they underperform in terms of training-testing efficiency, finding total infractions, and simulation steps to identify the first failure compared to our approach. The results show that the proposed framework can be used to understand existing weaknesses of the autonomous vehicles under test in order to only attack those regions, starting with the simplistic perturbation models.", "url": "https://arxiv.org/abs/2308.14550"}, {"metadata": {"arXiv": "2308.14652", "Date": "Mon, 28 Aug 2023 15:34:43 ", "Title": "Learning Visual Tracking and Reaching with Deep Reinforcement Learning on a UR10e Robotic Arm", "Authors": ["Colin Bellinger", "Laurence Lamarche-Cliche"], "Categories": "cs.AI cs.RO", "MSC-class": "68T40", "ACM-class": "I.2; I.4; J.2"}, "abstract": "As technology progresses, industrial and scientific robots are increasingly being used in diverse settings. In many cases, however, programming the robot to perform such tasks is technically complex and costly. To maximize the utility of robots in industrial and scientific settings, they require the ability to quickly shift from one task to another. Reinforcement learning algorithms provide the potential to enable robots to learn optimal solutions to complete new tasks without directly reprogramming them. The current state-of-the-art in reinforcement learning, however, generally relies on fast simulations and parallelization to achieve optimal performance. These are often not possible in robotics applications. Thus, a significant amount of research is required to facilitate the efficient and safe, training and deployment of industrial and scientific reinforcement learning robots. This technical report outlines our initial research into the application of deep reinforcement learning on an industrial UR10e robot. The report describes the reinforcement learning environments created to facilitate policy learning with the UR10e, a robotic arm from Universal Robots, and presents our initial results in training deep Q-learning and proximal policy optimization agents on the developed reinforcement learning environments. Our results show that proximal policy optimization learns a better, more stable policy with less data than deep Q-learning. The corresponding code for this work is available at \\url{https://github.com/cbellinger27/bendRL_reacher_tracker}", "url": "https://arxiv.org/abs/2308.14652"}, {"metadata": {"arXiv": "2308.14657", "Date": "Mon, 28 Aug 2023 15:40:31 ", "Title": "DeepHealthNet: Adolescent Obesity Prediction System Based on a Deep Learning Framework", "Authors": ["Ji-Hoon Jeong", "In-Gyu Lee", "Sung-Kyung Kim", "Tae-Eui Kam", "Seong-Whan Lee", "Euijong Lee"], "Categories": "cs.AI cs.SE"}, "abstract": "Childhood and adolescent obesity rates are a global concern because obesity is associated with chronic diseases and long-term health risks. Artificial intelligence technology has emerged as a promising solution to accurately predict obesity rates and provide personalized feedback to adolescents. This study emphasizes the importance of early identification and prevention of obesity-related health issues. Factors such as height, weight, waist circumference, calorie intake, physical activity levels, and other relevant health information need to be considered for developing robust algorithms for obesity rate prediction and delivering personalized feedback. Hence, by collecting health datasets from 321 adolescents, we proposed an adolescent obesity prediction system that provides personalized predictions and assists individuals in making informed health decisions. Our proposed deep learning framework, DeepHealthNet, effectively trains the model using data augmentation techniques, even when daily health data are limited, resulting in improved prediction accuracy (acc: 0.8842). Additionally, the study revealed variations in the prediction of the obesity rate between boys (acc: 0.9320) and girls (acc: 0.9163), allowing the identification of disparities and the determination of the optimal time to provide feedback. The proposed system shows significant potential in effectively addressing childhood and adolescent obesity.", "url": "https://arxiv.org/abs/2308.14657"}, {"metadata": {"arXiv": "2308.14719", "Date": "Mon, 28 Aug 2023 17:20:47 ", "Title": "Hierarchical Time Series Forecasting with Bayesian Modeling", "Authors": ["Gal Elgavish"], "Categories": "cs.AI"}, "abstract": "We encounter time series data in many domains such as finance, physics, business, and weather. One of the main tasks of time series analysis, one that helps to take informed decisions under uncertainty, is forecasting. Time series are often hierarchically structured, e.g., a company sales might be broken down into different regions, and each region into different stores. In some cases the number of series in the hierarchy is too big to fit in a single model to produce forecasts in relevant time, and a decentralized approach is beneficial. One way to do this is to train independent forecasting models for each series and for some summary statistics series implied by the hierarchy (e.g. the sum of all series) and to pass those models to a reconciliation algorithm to improve those forecasts by sharing information between the series. In this work we focus on the reconciliation step, and propose a method to do so from a Bayesian perspective - Bayesian forecast reconciliation. We also define the common case of linear Gaussian reconciliation, where the forecasts are Gaussian and the hierarchy has linear structure, and show that we can compute reconciliation in closed form. We evaluate these methods on synthetic and real data sets, and compare them to other work in this field.", "url": "https://arxiv.org/abs/2308.14719"}, {"metadata": {"arXiv": "2308.14732", "Date": "Mon, 28 Aug 2023 17:34:24 ", "Title": "Bayesian artificial brain with ChatGPT", "Authors": ["Renato A. Krohling"], "Categories": "cs.AI"}, "abstract": "This paper aims to investigate the mathematical problem-solving capabilities of Chat Generative Pre-Trained Transformer (ChatGPT) in case of Bayesian reasoning. The study draws inspiration from Zhu & Gigerenzer's research in 2006, which posed the question: Can children reason the Bayesian way? In the pursuit of answering this question, a set of 10 Bayesian reasoning problems were presented. The results of their work revealed that children's ability to reason effectively using Bayesian principles is contingent upon a well-structured information representation. In this paper, we present the same set of 10 Bayesian reasoning problems to ChatGPT. Remarkably, the results demonstrate that ChatGPT provides the right solutions to all problems.", "url": "https://arxiv.org/abs/2308.14732"}, {"metadata": {"arXiv": "2308.13628", "Date": "Fri, 25 Aug 2023 18:48:40 ", "Title": "HiFiHR: Enhancing 3D Hand Reconstruction from a Single Image via High-Fidelity Texture", "Authors": ["Jiayin Zhu", "Zhuoran Zhao", "Linlin Yang", "Angela Yao"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted to DAGM German Conference on Pattern Recognition 2023"]}, "abstract": "We present HiFiHR, a high-fidelity hand reconstruction approach that utilizes render-and-compare in the learning-based framework from a single image, capable of generating visually plausible and accurate 3D hand meshes while recovering realistic textures. Our method achieves superior texture reconstruction by employing a parametric hand model with predefined texture assets, and by establishing a texture reconstruction consistency between the rendered and input images during training. Moreover, based on pretraining the network on an annotated dataset, we apply varying degrees of supervision using our pipeline, i.e., self-supervision, weak supervision, and full supervision, and discuss the various levels of contributions of the learned high-fidelity textures in enhancing hand pose and shape estimation. Experimental results on public benchmarks including FreiHAND and HO-3D demonstrate that our method outperforms the state-of-the-art hand reconstruction methods in texture reconstruction quality while maintaining comparable accuracy in pose and shape estimation. Our code is available at https://github.com/viridityzhu/HiFiHR.", "url": "https://arxiv.org/abs/2308.13628"}, {"metadata": {"arXiv": "2308.13679", "Date": "Fri, 25 Aug 2023 21:35:22 ", "Title": "An Open Hyperspectral Dataset with Sea-Land-Cloud Ground-Truth from the HYPSO-1 Satellite", "Authors": ["Jon A. Justo", "Joseph Garrett", "Dennis D. Langer", "Marie B. Henriksen", "Radu T. Ionescu", "and Tor A. Johansen"], "Categories": "cs.CV cs.AI", "Comments": ["5 pages", "4 figures", "to be published in IEEE Proceedings", "presented at WHISPERS2023 Workshop"]}, "abstract": "Hyperspectral Imaging, employed in satellites for space remote sensing, like HYPSO-1, faces constraints due to few labeled data sets, affecting the training of AI models demanding these ground-truth annotations. In this work, we introduce The HYPSO-1 Sea-Land-Cloud-Labeled Dataset, an open dataset with 200 diverse hyperspectral images from the HYPSO-1 mission, available in both raw and calibrated forms for scientific research in Earth observation. Moreover, 38 of these images from different countries include ground-truth labels at pixel-level totaling about 25 million spectral signatures labeled for sea/land/cloud categories. To demonstrate the potential of the dataset and its labeled subset, we have additionally optimized a deep learning model (1D Fully Convolutional Network), achieving superior performance to the current state of the art. The complete dataset, ground-truth labels, deep learning model, and software code are openly accessible for download at the website https://ntnu-smallsat-lab.github.io/hypso1_sea_land_clouds_dataset/ .", "url": "https://arxiv.org/abs/2308.13679"}, {"metadata": {"arXiv": "2308.13764", "Date": "Sat, 26 Aug 2023 05:09:57 ", "Title": "Unified Single-Stage Transformer Network for Efficient RGB-T Tracking", "Authors": ["Jianqiang Xia", "DianXi Shi", "Ke Song", "Linna Song", "XiaoLei Wang", "Songchang Jin", "Li Zhou", "Yu Cheng", "Lei Jin", "Zheng Zhu", "Jianan Li", "Gang Wang", "Junliang Xing", "Jian Zhao"], "Categories": "cs.CV cs.AI"}, "abstract": "Most existing RGB-T tracking networks extract modality features in a separate manner, which lacks interaction and mutual guidance between modalities. This limits the network's ability to adapt to the diverse dual-modality appearances of targets and the dynamic relationships between the modalities. Additionally, the three-stage fusion tracking paradigm followed by these networks significantly restricts the tracking speed. To overcome these problems, we propose a unified single-stage Transformer RGB-T tracking network, namely USTrack, which unifies the above three stages into a single ViT (Vision Transformer) backbone with a dual embedding layer through self-attention mechanism. With this structure, the network can extract fusion features of the template and search region under the mutual interaction of modalities. Simultaneously, relation modeling is performed between these features, efficiently obtaining the search region fusion features with better target-background discriminability for prediction. Furthermore, we introduce a novel feature selection mechanism based on modality reliability to mitigate the influence of invalid modalities for prediction, further improving the tracking performance. Extensive experiments on three popular RGB-T tracking benchmarks demonstrate that our method achieves new state-of-the-art performance while maintaining the fastest inference speed 84.2FPS. In particular, MPR/MSR on the short-term and long-term subsets of VTUAV dataset increased by 11.1$\\%$/11.7$\\%$ and 11.3$\\%$/9.7$\\%$.", "url": "https://arxiv.org/abs/2308.13764"}, {"metadata": {"arXiv": "2308.13910", "Date": "Sat, 26 Aug 2023 16:09:20 ", "Title": "Exploring Human Crowd Patterns and Categorization in Video Footage for Enhanced Security and Surveillance using Computer Vision and Machine Learning", "Authors": ["Afnan Alazbah", "Khalid Fakeeh", "Osama Rabie"], "Categories": "cs.CV cs.AI", "Comments": ["8 pages", "1 figure", "8 tables"]}, "abstract": "Computer vision and machine learning have brought revolutionary shifts in perception for researchers, scientists, and the general populace. Once thought to be unattainable, these technologies have achieved the seemingly impossible. Their exceptional applications in diverse fields like security, agriculture, and education are a testament to their impact. However, the full potential of computer vision remains untapped. This paper explores computer vision's potential in security and surveillance, presenting a novel approach to track motion in videos. By categorizing motion into Arcs, Lanes, Converging/Diverging, and Random/Block motions using Motion Information Images and Blockwise dominant motion data, the paper examines different optical flow techniques, CNN models, and machine learning models. Successfully achieving its objectives with promising accuracy, the results can train anomaly-detection models, provide behavioral insights based on motion, and enhance scene comprehension.", "url": "https://arxiv.org/abs/2308.13910"}, {"metadata": {"arXiv": "2308.13979", "Date": "Sun, 27 Aug 2023 01:11:03 ", "Title": "Enhancing Bloodstain Analysis Through AI-Based Segmentation: Leveraging Segment Anything Model for Crime Scene Investigation", "Authors": ["Zihan Dong and ZhengDong Zhang"], "Categories": "cs.CV cs.AI", "Comments": ["KDD2023 Workshop"], "MSC-class": "68-xx"}, "abstract": "Bloodstain pattern analysis plays a crucial role in crime scene investigations by providing valuable information through the study of unique blood patterns. Conventional image analysis methods, like Thresholding and Contrast, impose stringent requirements on the image background and is labor-intensive in the context of droplet image segmentation. The Segment Anything Model (SAM), a recently proposed method for extensive image recognition, is yet to be adequately assessed for its accuracy and efficiency on bloodstain image segmentation. This paper explores the application of pre-trained SAM and fine-tuned SAM on bloodstain image segmentation with diverse image backgrounds. Experiment results indicate that both pre-trained and fine-tuned SAM perform the bloodstain image segmentation task with satisfactory accuracy and efficiency, while fine-tuned SAM achieves an overall 2.2\\% accuracy improvement than pre-trained SAM and 4.70\\% acceleration in terms of speed for image recognition. Analysis of factors that influence bloodstain recognition is carried out. This research demonstrates the potential application of SAM on bloodstain image segmentation, showcasing the effectiveness of Artificial Intelligence application in criminology research. We release all code and demos at \\url{https://github.com/Zdong104/Bloodstain_Analysis_Ai_Tool}", "url": "https://arxiv.org/abs/2308.13979"}, {"metadata": {"arXiv": "2308.14009", "Date": "Sun, 27 Aug 2023 05:45:54 ", "Title": "Towards Fast and Accurate Image-Text Retrieval with Self-Supervised Fine-Grained Alignment", "Authors": ["Jiamin Zhuang", "Jing Yu", "Yang Ding", "Xiangyan Qu", "Yue Hu"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted in IEEE Transactions on Multimedia (TMM)"], "Journal-ref": "IEEE Transactions on Multimedia ( Early Access ), 29 May 2023", "DOI": "10.1109/TMM.2023.3280734"}, "abstract": "Image-text retrieval requires the system to bridge the heterogenous gap between vision and language for accurate retrieval while keeping the network lightweight-enough for efficient retrieval. Existing trade-off solutions mainly study from the view of incorporating cross-modal interactions with the independent-embedding framework or leveraging stronger pretrained encoders, which still demand time-consuming similarity measurement or heavyweight model structure in the retrieval stage. In this work, we propose an image-text alignment module SelfAlign on top of the independent-embedding framework, which improves the retrieval accuracy while maintains the retrieval efficiency without extra supervision. SelfAlign contains two collaborative sub-modules that force image-text alignment at both concept level and context level by self-supervised contrastive learning. It does not require cross-modal embedding interactions during training while maintaining independent image and text encoders during retrieval. With comparable time cost, SelfAlign consistently boosts the accuracy of state-of-the-art non-pretraining independent-embedding models respectively by 9.1%, 4.2% and 6.6% in terms of R@sum score on Flickr30K, MSCOCO 1K and MS-COCO 5K datasets. The retrieval accuracy also outperforms most existing interactive-embedding models with orders of magnitude decrease in retrieval time. The source code is available at: https://github.com/Zjamie813/SelfAlign.", "url": "https://arxiv.org/abs/2308.14009"}, {"metadata": {"arXiv": "2308.14050", "Date": "Sun, 27 Aug 2023 09:07:26 ", "Title": "PECon: Contrastive Pretraining to Enhance Feature Alignment between CT and EHR Data for Improved Pulmonary Embolism Diagnosis", "Authors": ["Santosh Sanjeev", "Salwa K. Al Khatib", "Mai A. Shaaban", "Ibrahim Almakky", "Vijay Ram Papineni and Mohammad Yaqub"], "Categories": "cs.CV cs.AI"}, "abstract": "Previous deep learning efforts have focused on improving the performance of Pulmonary Embolism(PE) diagnosis from Computed Tomography (CT) scans using Convolutional Neural Networks (CNN). However, the features from CT scans alone are not always sufficient for the diagnosis of PE. CT scans along with electronic heath records (EHR) can provide a better insight into the patients condition and can lead to more accurate PE diagnosis. In this paper, we propose Pulmonary Embolism Detection using Contrastive Learning (PECon), a supervised contrastive pretraining strategy that employs both the patients CT scans as well as the EHR data, aiming to enhance the alignment of feature representations between the two modalities and leverage information to improve the PE diagnosis. In order to achieve this, we make use of the class labels and pull the sample features of the same class together, while pushing away those of the other class. Results show that the proposed work outperforms the existing techniques and achieves state-of-the-art performance on the RadFusion dataset with an F1-score of 0.913, accuracy of 0.90 and an AUROC of 0.943. Furthermore, we also explore the explainability of our approach in comparison to other methods. Our code is publicly available at https://github.com/BioMedIA-MBZUAI/PECon.", "url": "https://arxiv.org/abs/2308.14050"}, {"metadata": {"arXiv": "2308.14084", "Date": "Sun, 27 Aug 2023 12:12:27 ", "Title": "Practical Edge Detection via Robust Collaborative Learning", "Authors": ["Yuanbin Fu and Xiaojie Guo"], "Categories": "cs.CV cs.AI"}, "abstract": "Edge detection, as a core component in a wide range of visionoriented tasks, is to identify object boundaries and prominent edges in natural images. An edge detector is desired to be both efficient and accurate for practical use. To achieve the goal, two key issues should be concerned: 1) How to liberate deep edge models from inefficient pre-trained backbones that are leveraged by most existing deep learning methods, for saving the computational cost and cutting the model size; and 2) How to mitigate the negative influence from noisy or even wrong labels in training data, which widely exist in edge detection due to the subjectivity and ambiguity of annotators, for the robustness and accuracy. In this paper, we attempt to simultaneously address the above problems via developing a collaborative learning based model, termed PEdger. The principle behind our PEdger is that, the information learned from different training moments and heterogeneous (recurrent and non recurrent in this work) architectures, can be assembled to explore robust knowledge against noisy annotations, even without the help of pre-training on extra data. Extensive ablation studies together with quantitative and qualitative experimental comparisons on the BSDS500 and NYUD datasets are conducted to verify the effectiveness of our design, and demonstrate its superiority over other competitors in terms of accuracy, speed, and model size. Codes can be found at https://github.co/ForawardStar/PEdger.", "url": "https://arxiv.org/abs/2308.14084"}, {"metadata": {"arXiv": "2308.14100", "Date": "Sun, 27 Aug 2023 13:07:44 ", "Title": "Rethinking Exemplars for Continual Semantic Segmentation in Endoscopy Scenes: Entropy-based Mini-Batch Pseudo-Replay", "Authors": ["Guankun Wang", "Long Bai", "Yanan Wu", "Tong Chen", "Hongliang Ren"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted by Computers in Biology and Medicine"]}, "abstract": "Endoscopy is a widely used technique for the early detection of diseases or robotic-assisted minimally invasive surgery (RMIS). Numerous deep learning (DL)-based research works have been developed for automated diagnosis or processing of endoscopic view. However, existing DL models may suffer from catastrophic forgetting. When new target classes are introduced over time or cross institutions, the performance of old classes may suffer severe degradation. More seriously, data privacy and storage issues may lead to the unavailability of old data when updating the model. Therefore, it is necessary to develop a continual learning (CL) methodology to solve the problem of catastrophic forgetting in endoscopic image segmentation. To tackle this, we propose a Endoscopy Continual Semantic Segmentation (EndoCSS) framework that does not involve the storage and privacy issues of exemplar data. The framework includes a mini-batch pseudo-replay (MB-PR) mechanism and a self-adaptive noisy cross-entropy (SAN-CE) loss. The MB-PR strategy circumvents privacy and storage issues by generating pseudo-replay images through a generative model. Meanwhile, the MB-PR strategy can also correct the model deviation to the replay data and current training data, which is aroused by the significant difference in the amount of current and replay images. Therefore, the model can perform effective representation learning on both new and old tasks. SAN-CE loss can help model fitting by adjusting the model's output logits, and also improve the robustness of training. Extensive continual semantic segmentation (CSS) experiments on public datasets demonstrate that our method can robustly and effectively address the catastrophic forgetting brought by class increment in endoscopy scenes. The results show that our framework holds excellent potential for real-world deployment in a streaming learning manner.", "url": "https://arxiv.org/abs/2308.14100"}, {"metadata": {"arXiv": "2308.14105", "Date": "Sun, 27 Aug 2023 13:22:55 ", "Title": "Unified and Dynamic Graph for Temporal Character Grouping in Long Videos", "Authors": ["Xiujun Shu", "Wei Wen", "Liangsheng Xu", "Mingbao Lin", "Ruizhi Qiao", "Taian Guo", "Hanjun Li", "Bei Gan", "Xiao Wang", "Xin Sun"], "Categories": "cs.CV cs.AI"}, "abstract": "Video temporal character grouping locates appearing moments of major characters within a video according to their identities. To this end, recent works have evolved from unsupervised clustering to graph-based supervised clustering. However, graph methods are built upon the premise of fixed affinity graphs, bringing many inexact connections. Besides, they extract multi-modal features with kinds of models, which are unfriendly to deployment. In this paper, we present a unified and dynamic graph (UniDG) framework for temporal character grouping. This is accomplished firstly by a unified representation network that learns representations of multiple modalities within the same space and still preserves the modality's uniqueness simultaneously. Secondly, we present a dynamic graph clustering where the neighbors of different quantities are dynamically constructed for each node via a cyclic matching strategy, leading to a more reliable affinity graph. Thirdly, a progressive association method is introduced to exploit spatial and temporal contexts among different modalities, allowing multi-modal clustering results to be well fused. As current datasets only provide pre-extracted features, we evaluate our UniDG method on a collected dataset named MTCG, which contains each character's appearing clips of face and body and speaking voice tracks. We also evaluate our key components on existing clustering and retrieval datasets to verify the generalization ability. Experimental results manifest that our method can achieve promising results and outperform several state-of-the-art approaches.", "url": "https://arxiv.org/abs/2308.14105"}, {"metadata": {"arXiv": "2308.14133", "Date": "Sun, 27 Aug 2023 15:21:25 ", "Title": "Cheap Lunch for Medical Image Segmentation by Fine-tuning SAM on Few Exemplars", "Authors": ["Weijia Feng and Lingting Zhu and Lequan Yu"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted by Brain Lesion (BrainLes) workshop of International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI BrainLes 2023). 10 pages", "3 figures"]}, "abstract": "The Segment Anything Model (SAM) has demonstrated remarkable capabilities of scaled-up segmentation models, enabling zero-shot generalization across a variety of domains. By leveraging large-scale foundational models as pre-trained models, it is a natural progression to fine-tune SAM for specific domains to further enhance performances. However, the adoption of foundational models in the medical domain presents a challenge due to the difficulty and expense of labeling sufficient data for adaptation within hospital systems. In this paper, we introduce an efficient and practical approach for fine-tuning SAM using a limited number of exemplars, making it suitable for such scenarios. Our approach combines two established techniques from the literature: an exemplar-guided synthesis module and the widely recognized Low-Rank Adaptation (LoRA) fine-tuning strategy, serving as data-level and model-level attempts respectively. Interestingly, our empirical findings suggest that SAM can be effectively aligned within the medical domain even with few labeled data. We validate our approach through experiments on brain tumor segmentation (BraTS) and multi-organ CT segmentation (Synapse). The comprehensive results underscore the feasibility and effectiveness of such an approach, paving the way for the practical application of SAM in the medical domain.", "url": "https://arxiv.org/abs/2308.14133"}, {"metadata": {"arXiv": "2308.14160", "Date": "Sun, 27 Aug 2023 17:30:56 ", "Title": "A Unified Transformer-based Network for multimodal Emotion Recognition", "Authors": ["Kamran Ali and Charles E. Hughes"], "Categories": "cs.CV cs.AI", "Comments": ["12 pages"]}, "abstract": "The development of transformer-based models has resulted in significant advances in addressing various vision and NLP-based research challenges. However, the progress made in transformer-based methods has not been effectively applied to biosensing research. This paper presents a novel Unified Biosensor-Vision Multi-modal Transformer-based (UBVMT) method to classify emotions in an arousal-valence space by combining a 2D representation of an ECG/PPG signal with the face information. To achieve this goal, we first investigate and compare the unimodal emotion recognition performance of three image-based representations of the ECG/PPG signal. We then present our UBVMT network which is trained to perform emotion recognition by combining the 2D image-based representation of the ECG/PPG signal and the facial expression features. Our unified transformer model consists of homogeneous transformer blocks that take as an input the 2D representation of the ECG/PPG signal and the corresponding face frame for emotion representation learning with minimal modality-specific design. Our UBVMT model is trained by reconstructing masked patches of video frames and 2D images of ECG/PPG signals, and contrastive modeling to align face and ECG/PPG data. Extensive experiments on the MAHNOB-HCI and DEAP datasets show that our Unified UBVMT-based model produces comparable results to the state-of-the-art techniques.", "url": "https://arxiv.org/abs/2308.14160"}, {"metadata": {"arXiv": "2308.14161", "Date": "Sun, 27 Aug 2023 17:44:25 ", "Title": "Intergrated Segmentation and Detection Models for Dentex Challenge 2023", "Authors": ["Lanshan He", "Yusheng Liu", "Lisheng Wang"], "Categories": "cs.CV cs.AI"}, "abstract": "Dental panoramic x-rays are commonly used in dental diagnosing. With the development of deep learning, auto detection of diseases from dental panoramic x-rays can help dentists to diagnose diseases more efficiently.The Dentex Challenge 2023 is a competition for automatic detection of abnormal teeth along with their enumeration ids from dental panoramic x-rays. In this paper, we propose a method integrating segmentation and detection models to detect abnormal teeth as well as obtain their enumeration ids.Our codes are available at https://github.com/xyzlancehe/DentexSegAndDet.", "url": "https://arxiv.org/abs/2308.14161"}, {"metadata": {"arXiv": "2308.14256", "Date": "Mon, 28 Aug 2023 02:20:44 ", "Title": "FaceChain: A Playground for Identity-Preserving Portrait Generation", "Authors": ["Yang Liu", "Cheng Yu", "Lei Shang", "Ziheng Wu", "Xingjun Wang", "Yuze Zhao", "Lin Zhu", "Chen Cheng", "Weitao Chen", "Chao Xu", "Haoyu Xie", "Yuan Yao", "Wenmeng Zhou", "Yingda Chen", "Xuansong Xie", "Baigui Sun"], "Categories": "cs.CV cs.AI", "Comments": ["This is an ongoing work that will be consistently refined and improved upon"]}, "abstract": "Recent advancement in personalized image generation have unveiled the intriguing capability of pre-trained text-to-image models on learning identity information from a collection of portrait images. However, existing solutions can be vulnerable in producing truthful details, and usually suffer from several defects such as (i) The generated face exhibit its own unique characteristics, \\ie facial shape and facial feature positioning may not resemble key characteristics of the input, and (ii) The synthesized face may contain warped, blurred or corrupted regions. In this paper, we present FaceChain, a personalized portrait generation framework that combines a series of customized image-generation model and a rich set of face-related perceptual understanding models (\\eg, face detection, deep face embedding extraction, and facial attribute recognition), to tackle aforementioned challenges and to generate truthful personalized portraits, with only a handful of portrait images as input. Concretely, we inject several SOTA face models into the generation procedure, achieving a more efficient label-tagging, data-processing, and model post-processing compared to previous solutions, such as DreamBooth ~\\cite{ruiz2023dreambooth} , InstantBooth ~\\cite{shi2023instantbooth} , or other LoRA-only approaches ~\\cite{hu2021lora} . Through the development of FaceChain, we have identified several potential directions to accelerate development of Face/Human-Centric AIGC research and application. We have designed FaceChain as a framework comprised of pluggable components that can be easily adjusted to accommodate different styles and personalized needs. We hope it can grow to serve the burgeoning needs from the communities. FaceChain is open-sourced under Apache-2.0 license at \\url{https://github.com/modelscope/facechain}.", "url": "https://arxiv.org/abs/2308.14256"}, {"metadata": {"arXiv": "2308.14437", "Date": "Mon, 28 Aug 2023 09:23:18 ", "Title": "Data-iterative Optimization Score Model for Stable Ultra-Sparse-View CT Reconstruction", "Authors": ["Weiwen Wu", "Yanyang Wang"], "Categories": "cs.CV cs.AI", "Comments": ["11 pages", "12 figures"]}, "abstract": "Score-based generative models (SGMs) have gained prominence in sparse-view CT reconstruction for their precise sampling of complex distributions. In SGM-based reconstruction, data consistency in the score-based diffusion model ensures close adherence of generated samples to observed data distribution, crucial for improving image quality. Shortcomings in data consistency characterization manifest in three aspects. Firstly, data from the optimization process can lead to artifacts in reconstructed images. Secondly, it often neglects that the generation model and original data constraints are independently completed, fragmenting unity. Thirdly, it predominantly focuses on constraining intermediate results in the inverse sampling process, rather than ideal real images. Thus, we propose an iterative optimization data scoring model. This paper introduces the data-iterative optimization score-based model (DOSM), integrating innovative data consistency into the Stochastic Differential Equation, a valuable constraint for ultra-sparse-view CT reconstruction. The novelty of this data consistency element lies in its sole reliance on original measurement data to confine generation outcomes, effectively balancing measurement data and generative model constraints. Additionally, we pioneer an inference strategy that traces back from current iteration results to ideal truth, enhancing reconstruction stability. We leverage conventional iteration techniques to optimize DOSM updates. Quantitative and qualitative results from 23 views of numerical and clinical cardiac datasets demonstrate DOSM's superiority over other methods. Remarkably, even with 10 views, our method achieves excellent performance.", "url": "https://arxiv.org/abs/2308.14437"}, {"metadata": {"arXiv": "2308.14448", "Date": "Mon, 28 Aug 2023 09:35:13 ", "Title": "ExpCLIP: Bridging Text and Facial Expressions via Semantic Alignment", "Authors": ["Yicheng Zhong", "Huawei Wei", "Peiji Yang", "Zhisheng Wang"], "Categories": "cs.CV cs.AI"}, "abstract": "The objective of stylized speech-driven facial animation is to create animations that encapsulate specific emotional expressions. Existing methods often depend on pre-established emotional labels or facial expression templates, which may limit the necessary flexibility for accurately conveying user intent. In this research, we introduce a technique that enables the control of arbitrary styles by leveraging natural language as emotion prompts. This technique presents benefits in terms of both flexibility and user-friendliness. To realize this objective, we initially construct a Text-Expression Alignment Dataset (TEAD), wherein each facial expression is paired with several prompt-like descriptions.We propose an innovative automatic annotation method, supported by Large Language Models (LLMs), to expedite the dataset construction, thereby eliminating the substantial expense of manual annotation. Following this, we utilize TEAD to train a CLIP-based model, termed ExpCLIP, which encodes text and facial expressions into semantically aligned style embeddings. The embeddings are subsequently integrated into the facial animation generator to yield expressive and controllable facial animations. Given the limited diversity of facial emotions in existing speech-driven facial animation training data, we further introduce an effective Expression Prompt Augmentation (EPA) mechanism to enable the animation generator to support unprecedented richness in style control. Comprehensive experiments illustrate that our method accomplishes expressive facial animation generation and offers enhanced flexibility in effectively conveying the desired style.", "url": "https://arxiv.org/abs/2308.14448"}, {"metadata": {"arXiv": "2308.14667", "Date": "Mon, 28 Aug 2023 15:54:14 ", "Title": "Neural Network-Based Histologic Remission Prediction In Ulcerative Colitis", "Authors": ["Yemin li", "Zhongcheng Liu", "Xiaoying Lou", "Mirigual Kurban", "Miao Li", "Jie Yang", "Kaiwei Che", "Jiankun Wang", "Max Q.-H Meng", "Yan Huang", "Qin Guo", "Pinjin Hu"], "Categories": "cs.CV cs.AI"}, "abstract": "BACKGROUND & AIMS: Histological remission (HR) is advocated and considered as a new therapeutic target in ulcerative colitis (UC). Diagnosis of histologic remission currently relies on biopsy; during this process, patients are at risk for bleeding, infection, and post-biopsy fibrosis. In addition, histologic response scoring is complex and time-consuming, and there is heterogeneity among pathologists. Endocytoscopy (EC) is a novel ultra-high magnification endoscopic technique that can provide excellent in vivo assessment of glands. Based on the EC technique, we propose a neural network model that can assess histological disease activity in UC using EC images to address the above issues. The experiment results demonstrate that the proposed method can assist patients in precise treatment and prognostic assessment. METHODS: We construct a neural network model for UC evaluation. A total of 5105 images of 154 intestinal segments from 87 patients undergoing EC treatment at a center in China between March 2022 and March 2023 are scored according to the Geboes score. Subsequently, 103 intestinal segments are used as the training set, 16 intestinal segments are used as the validation set for neural network training, and the remaining 35 intestinal segments are used as the test set to measure the model performance together with the validation set. RESULTS: By treating HR as a negative category and histologic activity as a positive category, the proposed neural network model can achieve an accuracy of 0.9, a specificity of 0.95, a sensitivity of 0.75, and an area under the curve (AUC) of 0.81. CONCLUSION: We develop a specific neural network model that can distinguish histologic remission/activity in EC images of UC, which helps to accelerate clinical histological diagnosis. keywords: ulcerative colitis; Endocytoscopy; Geboes score; neural network.", "url": "https://arxiv.org/abs/2308.14667"}, {"metadata": {"arXiv": "2308.14726", "Date": "Mon, 28 Aug 2023 17:30:14 ", "Title": "PanoSwin: a Pano-style Swin Transformer for Panorama Understanding", "Authors": ["Zhixin Ling", "Zhen Xing", "Xiangdong Zhou", "Manliang Cao", "Guichun Zhou"], "Categories": "cs.CV cs.AI", "Comments": ["CVPR 2023"]}, "abstract": "In panorama understanding, the widely used equirectangular projection (ERP) entails boundary discontinuity and spatial distortion. It severely deteriorates the conventional CNNs and vision Transformers on panoramas. In this paper, we propose a simple yet effective architecture named PanoSwin to learn panorama representations with ERP. To deal with the challenges brought by equirectangular projection, we explore a pano-style shift windowing scheme and novel pitch attention to address the boundary discontinuity and the spatial distortion, respectively. Besides, based on spherical distance and Cartesian coordinates, we adapt absolute positional embeddings and relative positional biases for panoramas to enhance panoramic geometry information. Realizing that planar image understanding might share some common knowledge with panorama understanding, we devise a novel two-stage learning framework to facilitate knowledge transfer from the planar images to panoramas. We conduct experiments against the state-of-the-art on various panoramic tasks, i.e., panoramic object detection, panoramic classification, and panoramic layout estimation. The experimental results demonstrate the effectiveness of PanoSwin in panorama understanding.", "url": "https://arxiv.org/abs/2308.14726"}, {"metadata": {"arXiv": "2308.14737", "Date": "Mon, 28 Aug 2023 17:38:31 ", "Title": "Flexible Techniques for Differentiable Rendering with 3D Gaussians", "Authors": ["Leonid Keselman", "Martial Hebert"], "Categories": "cs.CV cs.AI cs.GR", "ACM-class": "I.2.10; I.3.7; I.4.0"}, "abstract": "Fast, reliable shape reconstruction is an essential ingredient in many computer vision applications. Neural Radiance Fields demonstrated that photorealistic novel view synthesis is within reach, but was gated by performance requirements for fast reconstruction of real scenes and objects. Several recent approaches have built on alternative shape representations, in particular, 3D Gaussians. We develop extensions to these renderers, such as integrating differentiable optical flow, exporting watertight meshes and rendering per-ray normals. Additionally, we show how two of the recent methods are interoperable with each other. These reconstructions are quick, robust, and easily performed on GPU or CPU. For code and visual examples, see https://leonidk.github.io/fmb-plus", "url": "https://arxiv.org/abs/2308.14737"}, {"metadata": {"arXiv": "2308.13724", "Date": "Sat, 26 Aug 2023 01:31:35 ", "Title": "ISR-LLM: Iterative Self-Refined Large Language Model for Long-Horizon Sequential Task Planning", "Authors": ["Zhehua Zhou", "Jiayang Song", "Kunpeng Yao", "Zhan Shu", "Lei Ma"], "Categories": "cs.RO cs.AI"}, "abstract": "Motivated by the substantial achievements observed in Large Language Models (LLMs) in the field of natural language processing, recent research has commenced investigations into the application of LLMs for complex, long-horizon sequential task planning challenges in robotics. LLMs are advantageous in offering the potential to enhance the generalizability as task-agnostic planners and facilitate flexible interaction between human instructors and planning systems. However, task plans generated by LLMs often lack feasibility and correctness. To address this challenge, we introduce ISR-LLM, a novel framework that improves LLM-based planning through an iterative self-refinement process. The framework operates through three sequential steps: preprocessing, planning, and iterative self-refinement. During preprocessing, an LLM translator is employed to convert natural language input into a Planning Domain Definition Language (PDDL) formulation. In the planning phase, an LLM planner formulates an initial plan, which is then assessed and refined in the iterative self-refinement step by using a validator. We examine the performance of ISR-LLM across three distinct planning domains. The results show that ISR-LLM is able to achieve markedly higher success rates in task accomplishments compared to state-of-the-art LLM-based planners. Moreover, it also preserves the broad applicability and generalizability of working with natural language instructions.", "url": "https://arxiv.org/abs/2308.13724"}, {"metadata": {"arXiv": "2308.14206", "Date": "Sun, 27 Aug 2023 21:17:32 ", "Title": "Using Knowledge Representation and Task Planning for Robot-agnostic Skills on the Example of Contact-Rich Wiping Tasks", "Authors": ["Matthias Mayr", "Faseeh Ahmad", "Alexander Duerr", "Volker Krueger"], "Categories": "cs.RO cs.AI", "Comments": ["7 pages", "5 figures. Accepted at 2023 IEEE International Conference on Automation Science and Engineering (CASE)"]}, "abstract": "The transition to agile manufacturing, Industry 4.0, and high-mix-low-volume tasks require robot programming solutions that are flexible. However, most deployed robot solutions are still statically programmed and use stiff position control, which limit their usefulness. In this paper, we show how a single robot skill that utilizes knowledge representation, task planning, and automatic selection of skill implementations based on the input parameters can be executed in different contexts. We demonstrate how the skill-based control platform enables this with contact-rich wiping tasks on different robot systems. To achieve that in this case study, our approach needs to address different kinematics, gripper types, vendors, and fundamentally different control interfaces. We conducted the experiments with a mobile platform that has a Universal Robots UR5e 6 degree-of-freedom robot arm with position control and a 7 degree-of-freedom KUKA iiwa with torque control.", "url": "https://arxiv.org/abs/2308.14206"}, {"metadata": {"arXiv": "2308.14329", "Date": "Mon, 28 Aug 2023 06:17:15 ", "Title": "End-to-End Driving via Self-Supervised Imitation Learning Using Camera and LiDAR Data", "Authors": ["Jin Bok Park", "Jinkyu Lee", "Muhyun Back", "Hyunmin Han", "David T. Ma", "Sang Min Won", "Sung Soo Hwang", "Il Yong Chun"], "Categories": "cs.RO cs.AI", "Comments": ["20 pages", "8 figures"]}, "abstract": "In autonomous driving, the end-to-end (E2E) driving approach that predicts vehicle control signals directly from sensor data is rapidly gaining attention. To learn a safe E2E driving system, one needs an extensive amount of driving data and human intervention. Vehicle control data is constructed by many hours of human driving, and it is challenging to construct large vehicle control datasets. Often, publicly available driving datasets are collected with limited driving scenes, and collecting vehicle control data is only available by vehicle manufacturers. To address these challenges, this paper proposes the first self-supervised learning framework, self-supervised imitation learning (SSIL), that can learn E2E driving networks without using driving command data. To construct pseudo steering angle data, proposed SSIL predicts a pseudo target from the vehicle's poses at the current and previous time points that are estimated with light detection and ranging sensors. Our numerical experiments demonstrate that the proposed SSIL framework achieves comparable E2E driving accuracy with the supervised learning counterpart. In addition, our qualitative analyses using a conventional visual explanation tool show that trained NNs by proposed SSIL and the supervision counterpart attend similar objects in making predictions.", "url": "https://arxiv.org/abs/2308.14329"}, {"metadata": {"arXiv": "2308.14111", "Date": "Sun, 27 Aug 2023 14:06:21 ", "Title": "MARL for Decentralized Electric Vehicle Charging Coordination with V2V Energy Exchange", "Authors": ["Jiarong Fan", "Hao Wang", "Ariel Liebman"], "Categories": "eess.SY cs.AI cs.MA cs.SY", "Comments": ["IEEE IECON 2023 (The 49th Annual Conference of the IEEE Industrial Electronics Society)"]}, "abstract": "Effective energy management of electric vehicle (EV) charging stations is critical to supporting the transport sector's sustainable energy transition. This paper addresses the EV charging coordination by considering vehicle-to-vehicle (V2V) energy exchange as the flexibility to harness in EV charging stations. Moreover, this paper takes into account EV user experiences, such as charging satisfaction and fairness. We propose a Multi-Agent Reinforcement Learning (MARL) approach to coordinate EV charging with V2V energy exchange while considering uncertainties in the EV arrival time, energy price, and solar energy generation. The exploration capability of MARL is enhanced by introducing parameter noise into MARL's neural network models. Experimental results demonstrate the superior performance and scalability of our proposed method compared to traditional optimization baselines. The decentralized execution of the algorithm enables it to effectively deal with partial system faults in the charging station.", "url": "https://arxiv.org/abs/2308.14111"}, {"metadata": {"arXiv": "2308.13894", "Date": "Sat, 26 Aug 2023 14:36:30 ", "Title": "Federated Fine-tuning of Billion-Sized Language Models across Mobile Devices", "Authors": ["Mengwei Xu", "Yaozong Wu", "Dongqi Cai", "Xiang Li", "Shangguang Wang"], "Categories": "cs.AI cs.LG", "Comments": ["under review"]}, "abstract": "Large Language Models (LLMs) are transforming the landscape of mobile intelligence. Federated Learning (FL), a method to preserve user data privacy, is often employed in fine-tuning LLMs to downstream mobile tasks, an approach known as FedLLM. Though recent efforts have addressed the network issue induced by the vast model size, they have not practically mitigated vital challenges concerning integration with mobile devices, such as significant memory consumption and sluggish model convergence. In response to these challenges, this work introduces FwdLLM, an innovative FL protocol designed to enhance the FedLLM efficiency. The key idea of FwdLLM to employ backpropagation (BP)-free training methods, requiring devices only to execute ``perturbed inferences''. Consequently, FwdLLM delivers way better memory efficiency and time efficiency (expedited by mobile NPUs and an expanded array of participant devices). FwdLLM centers around three key designs: (1) it combines BP-free training with parameter-efficient training methods, an essential way to scale the approach to the LLM era; (2) it systematically and adaptively allocates computational loads across devices, striking a careful balance between convergence speed and accuracy; (3) it discriminatively samples perturbed predictions that are more valuable to model convergence. Comprehensive experiments with five LLMs and three NLP tasks illustrate FwdLLM's significant advantages over conventional methods, including up to three orders of magnitude faster convergence and a 14.6x reduction in memory footprint. Uniquely, FwdLLM paves the way for federated learning of billion-parameter LLMs such as LLaMA on COTS mobile devices -- a feat previously unattained.", "url": "https://arxiv.org/abs/2308.13894"}, {"metadata": {"arXiv": "2308.13978", "Date": "Sun, 27 Aug 2023 00:57:01 ", "Title": "Understanding the Usage of QUBO-based Hamiltonian Function in Combinatorial Optimization over Graphs: A Discussion Using Max Cut (MC) Problem", "Authors": ["Redwan Ahmed Rizvee", "Md. Mosaddek Khan"], "Categories": "cs.AI cs.LG math.OC"}, "abstract": "Quadratic Unconstrained Binary Optimization (QUBO) is a generic technique to model various NP-hard combinatorial optimization problems in the form of binary variables. The Hamiltonian function is often used to formulate QUBO problems where it is used as the objective function in the context of optimization. In this study, we investigate how reinforcement learning-based (RL) paradigms with the presence of the Hamiltonian function can address combinatorial optimization problems over graphs in QUBO formulations. We use Graph Neural Network (GNN) as the message-passing architecture to convey the information among the nodes. We have centered our discussion on QUBO formulated Max-Cut problem but the intuitions can be extended to any QUBO supported canonical NP-Hard combinatorial optimization problems. We mainly investigate three formulations, Monty-Carlo Tree Search with GNN-based RL (MCTS-GNN), DQN with GNN-based RL, and a generic GNN with attention-based RL (GRL). Our findings state that in the RL-based paradigm, the Hamiltonian function-based optimization in QUBO formulation brings model convergence and can be used as a generic reward function. We also analyze and present the performance of our RL-based setups through experimenting over graphs of different densities and compare them with a simple GNN-based setup in the light of constraint violation, learning stability and computation cost. As per one of our findings, all the architectures provide a very comparable performance in sparse graphs as per the number of constraint violation whreas MCTS-GNN gives the best performance. In the similar criteria, the performance significantly starts to drop both for GRL and simple GNN-based setups whereas MCTS-GNN and DQN shines. We also present the corresponding mathematical formulations and in-depth discussion of the observed characteristics during experimentations.", "url": "https://arxiv.org/abs/2308.13978"}, {"metadata": {"arXiv": "2308.14163", "Date": "Sun, 27 Aug 2023 17:47:30 ", "Title": "Explaining with Attribute-based and Relational Near Misses: An Interpretable Approach to Distinguishing Facial Expressions of Pain and Disgust", "Authors": ["Bettina Finzel and Simon P. Kuhn and David E. Tafler and Ute Schmid"], "Categories": "cs.AI cs.LG"}, "abstract": "Explaining concepts by contrasting examples is an efficient and convenient way of giving insights into the reasons behind a classification decision. This is of particular interest in decision-critical domains, such as medical diagnostics. One particular challenging use case is to distinguish facial expressions of pain and other states, such as disgust, due to high similarity of manifestation. In this paper, we present an approach for generating contrastive explanations to explain facial expressions of pain and disgust shown in video sequences. We implement and compare two approaches for contrastive explanation generation. The first approach explains a specific pain instance in contrast to the most similar disgust instance(s) based on the occurrence of facial expressions (attributes). The second approach takes into account which temporal relations hold between intervals of facial expressions within a sequence (relations). The input to our explanation generation approach is the output of an interpretable rule-based classifier for pain and disgust.We utilize two different similarity metrics to determine near misses and far misses as contrasting instances. Our results show that near miss explanations are shorter than far miss explanations, independent from the applied similarity metric. The outcome of our evaluation indicates that pain and disgust can be distinguished with the help of temporal relations. We currently plan experiments to evaluate how the explanations help in teaching concepts and how they could be enhanced by further modalities and interaction.", "url": "https://arxiv.org/abs/2308.14163"}, {"metadata": {"arXiv": "2308.14224", "Date": "Sun, 27 Aug 2023 22:59:08 ", "Title": "Modeling Player Personality Factors from In-Game Behavior and Affective Expression", "Authors": ["Reza Habibi", "Johannes Pfau", "Magy Seif El-Nasr"], "Categories": "cs.AI cs.HC cs.LG"}, "abstract": "Developing a thorough understanding of the target audience (and/or single individuals) is a key factor for success - which is exceptionally important and powerful for the domain of video games that can not only benefit from informed decision making during development, but ideally even tailor game content, difficulty and player experience while playing. The granular assessment of individual personality and differences across players is a particularly difficult endeavor, given the highly variant human nature, disagreement in psychological background models and because of the effortful data collection that most often builds upon long, time-consuming and deterrent questionnaires. In this work, we explore possibilities to predict a series of player personality questionnaire metrics from recorded in-game behavior and extend related work by explicitly adding affective dialog decisions to the game environment which could elevate the model's accuracy. Using random forest regression, we predicted a wide variety of personality metrics from seven established questionnaires across 62 players over 60 minute gameplay of a customized version of the role-playing game Fallout: New Vegas. While some personality variables could already be identified from reasonable underlying in-game actions and affective expressions, we did not find ways to predict others or encountered questionable correlations that could not be justified by theoretical background literature. Yet, building on the initial opportunities of this explorative study, we are striving to massively enlarge our data set to players from an ecologically valid industrial game environment and investigate the performance of more sophisticated machine learning approaches.", "url": "https://arxiv.org/abs/2308.14224"}, {"metadata": {"arXiv": "2308.14253", "Date": "Mon, 28 Aug 2023 02:10:38 ", "Title": "The Promise and Peril of Artificial Intelligence -- Violet Teaming Offers a Balanced Path Forward", "Authors": ["Alexander J. Titus and Adam H. Russell"], "Categories": "cs.AI cs.CR cs.LG", "Comments": ["14 pages", "1 figure"]}, "abstract": "Artificial intelligence (AI) promises immense benefits across sectors, yet also poses risks from dual-use potentials, biases, and unintended behaviors. This paper reviews emerging issues with opaque and uncontrollable AI systems and proposes an integrative framework called violet teaming to develop reliable and responsible AI. Violet teaming combines adversarial vulnerability probing (red teaming) with solutions for safety and security (blue teaming) while prioritizing ethics and social benefit. It emerged from AI safety research to manage risks proactively by design. The paper traces the evolution of red, blue, and purple teaming toward violet teaming, and then discusses applying violet techniques to address biosecurity risks of AI in biotechnology. Additional sections review key perspectives across law, ethics, cybersecurity, macrostrategy, and industry best practices essential for operationalizing responsible AI through holistic technical and social considerations. Violet teaming provides both philosophy and method for steering AI trajectories toward societal good. With conscience and wisdom, the extraordinary capabilities of AI can enrich humanity. But without adequate precaution, the risks could prove catastrophic. Violet teaming aims to empower moral technology for the common welfare.", "url": "https://arxiv.org/abs/2308.14253"}, {"metadata": {"arXiv": "2308.14295", "Date": "Mon, 28 Aug 2023 04:29:49 ", "Title": "Traffic Light Control with Reinforcement Learning", "Authors": ["Taoyu Pan"], "Categories": "cs.AI cs.LG"}, "abstract": "Traffic light control is important for reducing congestion in urban mobility systems. This paper proposes a real-time traffic light control method using deep Q learning. Our approach incorporates a reward function considering queue lengths, delays, travel time, and throughput. The model dynamically decides phase changes based on current traffic conditions. The training of the deep Q network involves an offline stage from pre-generated data with fixed schedules and an online stage using real-time traffic data. A deep Q network structure with a \"phase gate\" component is used to simplify the model's learning task under different phases. A \"memory palace\" mechanism is used to address sample imbalance during the training process. We validate our approach using both synthetic and real-world traffic flow data on a road intersecting in Hangzhou, China. Results demonstrate significant performance improvements of the proposed method in reducing vehicle waiting time (57.1% to 100%), queue lengths (40.9% to 100%), and total travel time (16.8% to 68.0%) compared to traditional fixed signal plans.", "url": "https://arxiv.org/abs/2308.14295"}, {"metadata": {"arXiv": "2308.14521", "Date": "Mon, 28 Aug 2023 12:13:36 ", "Title": "Context-Aware Composition of Agent Policies by Markov Decision Process Entity Embeddings and Agent Ensembles", "Authors": ["Nicole Merkle", "Ralf Mikut"], "Categories": "cs.AI cs.LG cs.PF", "Comments": ["29 pages", "11 figures", "9 tables", "3 listings", "Submitted to Semantic Web Journal", "Under revision for re-submission to Semantic Web Journal"], "ACM-class": "F.2.2; I.2.7"}, "abstract": "Computational agents support humans in many areas of life and are therefore found in heterogeneous contexts. This means that agents operate in rapidly changing environments and can be confronted with huge state and action spaces. In order to perform services and carry out activities in a goal-oriented manner, agents require prior knowledge and therefore have to develop and pursue context-dependent policies. The problem is that prescribing policies in advance is limited and inflexible, especially in dynamically changing environments. Moreover, the context of an agent determines its choice of actions. Since the environments in which agents operate can be stochastic and complex in terms of the number of states and feasible actions, activities are usually modelled in a simplified way by Markov decision processes so that agents with reinforcement learning are able to learn policies that help to capture the context and act accordingly to optimally perform activities. However, training policies for all possible contexts using reinforcement learning is time-consuming. A requirement and challenge for agents is to learn strategies quickly and respond immediately in cross-context environments and applications. In this work, we propose a novel simulation-based approach that enables a) the representation of heterogeneous contexts through knowledge graphs and entity embeddings and b) the context-aware composition of policies on demand by ensembles of agents running in parallel. The evaluation we performed on the \"Virtual Home\" dataset indicates that agents that need to seamlessly switch between different contexts, can request on-the-fly composed policies that lead to the successful completion of context-appropriate activities without having to learn these policies in lengthy training steps and episodes, in contrast to agents that apply reinforcement learning.", "url": "https://arxiv.org/abs/2308.14521"}, {"metadata": {"arXiv": "2308.13746", "Date": "Sat, 26 Aug 2023 03:11:48 ", "Title": "PE-MED: Prompt Enhancement for Interactive Medical Image Segmentation", "Authors": ["Ao Chang", "Xing Tao", "Xin Yang", "Yuhao Huang", "Xinrui Zhou", "Jiajun Zeng", "Ruobing Huang", "Dong Ni"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Accepted by MICCAI MLMI 2023"]}, "abstract": "Interactive medical image segmentation refers to the accurate segmentation of the target of interest through interaction (e.g., click) between the user and the image. It has been widely studied in recent years as it is less dependent on abundant annotated data and more flexible than fully automated segmentation. However, current studies have not fully explored user-provided prompt information (e.g., points), including the knowledge mined in one interaction, and the relationship between multiple interactions. Thus, in this paper, we introduce a novel framework equipped with prompt enhancement, called PE-MED, for interactive medical image segmentation. First, we introduce a Self-Loop strategy to generate warm initial segmentation results based on the first prompt. It can prevent the highly unfavorable scenarios, such as encountering a blank mask as the initial input after the first interaction. Second, we propose a novel Prompt Attention Learning Module (PALM) to mine useful prompt information in one interaction, enhancing the responsiveness of the network to user clicks. Last, we build a Time Series Information Propagation (TSIP) mechanism to extract the temporal relationships between multiple interactions and increase the model stability. Comparative experiments with other state-of-the-art (SOTA) medical image segmentation algorithms show that our method exhibits better segmentation accuracy and stability.", "url": "https://arxiv.org/abs/2308.13746"}, {"metadata": {"arXiv": "2308.13759", "Date": "Sat, 26 Aug 2023 04:46:10 ", "Title": "SamDSK: Combining Segment Anything Model with Domain-Specific Knowledge for Semi-Supervised Learning in Medical Image Segmentation", "Authors": ["Yizhe Zhang", "Tao Zhou", "Shuo Wang", "Ye Wu", "Pengfei Gu", "Danny Z. Chen"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["15 pages", "7 figures", "Github: https://github.com/yizhezhang2000/SamDSK"]}, "abstract": "The Segment Anything Model (SAM) exhibits a capability to segment a wide array of objects in natural images, serving as a versatile perceptual tool for various downstream image segmentation tasks. In contrast, medical image segmentation tasks often rely on domain-specific knowledge (DSK). In this paper, we propose a novel method that combines the segmentation foundation model (i.e., SAM) with domain-specific knowledge for reliable utilization of unlabeled images in building a medical image segmentation model. Our new method is iterative and consists of two main stages: (1) segmentation model training; (2) expanding the labeled set by using the trained segmentation model, an unlabeled set, SAM, and domain-specific knowledge. These two stages are repeated until no more samples are added to the labeled set. A novel optimal-matching-based method is developed for combining the SAM-generated segmentation proposals and pixel-level and image-level DSK for constructing annotations of unlabeled images in the iterative stage (2). In experiments, we demonstrate the effectiveness of our proposed method for breast cancer segmentation in ultrasound images, polyp segmentation in endoscopic images, and skin lesion segmentation in dermoscopic images. Our work initiates a new direction of semi-supervised learning for medical image segmentation: the segmentation foundation model can be harnessed as a valuable tool for label-efficient segmentation learning in medical image segmentation.", "url": "https://arxiv.org/abs/2308.13759"}, {"metadata": {"arXiv": "2308.13957", "Date": "Sat, 26 Aug 2023 20:45:52 ", "Title": "Differentiable Weight Masks for Domain Transfer", "Authors": ["Samar Khanna", "Skanda Vaidyanath", "Akash Velu"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "One of the major drawbacks of deep learning models for computer vision has been their inability to retain multiple sources of information in a modular fashion. For instance, given a network that has been trained on a source task, we would like to re-train this network on a similar, yet different, target task while maintaining its performance on the source task. Simultaneously, researchers have extensively studied modularization of network weights to localize and identify the set of weights culpable for eliciting the observed performance on a given task. One set of works studies the modularization induced in the weights of a neural network by learning and analysing weight masks. In this work, we combine these fields to study three such weight masking methods and analyse their ability to mitigate \"forgetting'' on the source task while also allowing for efficient finetuning on the target task. We find that different masking techniques have trade-offs in retaining knowledge in the source task without adversely affecting target task performance.", "url": "https://arxiv.org/abs/2308.13957"}, {"metadata": {"arXiv": "2308.13969", "Date": "Sat, 26 Aug 2023 22:48:06 ", "Title": "Fixating on Attention: Integrating Human Eye Tracking into Vision Transformers", "Authors": ["Sharath Koorathota", "Nikolas Papadopoulos", "Jia Li Ma", "Shruti Kumar", "Xiaoxiao Sun", "Arunesh Mittal", "Patrick Adelman", "Paul Sajda"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["25 pages", "9 figures", "3 tables"]}, "abstract": "Modern transformer-based models designed for computer vision have outperformed humans across a spectrum of visual tasks. However, critical tasks, such as medical image interpretation or autonomous driving, still require reliance on human judgments. This work demonstrates how human visual input, specifically fixations collected from an eye-tracking device, can be integrated into transformer models to improve accuracy across multiple driving situations and datasets. First, we establish the significance of fixation regions in left-right driving decisions, as observed in both human subjects and a Vision Transformer (ViT). By comparing the similarity between human fixation maps and ViT attention weights, we reveal the dynamics of overlap across individual heads and layers. This overlap is exploited for model pruning without compromising accuracy. Thereafter, we incorporate information from the driving scene with fixation data, employing a \"joint space-fixation\" (JSF) attention setup. Lastly, we propose a \"fixation-attention intersection\" (FAX) loss to train the ViT model to attend to the same regions that humans fixated on. We find that the ViT performance is improved in accuracy and number of training epochs when using JSF and FAX. These results hold significant implications for human-guided artificial intelligence.", "url": "https://arxiv.org/abs/2308.13969"}, {"metadata": {"arXiv": "2308.13998", "Date": "Sun, 27 Aug 2023 03:55:28 ", "Title": "Computation-efficient Deep Learning for Computer Vision: A Survey", "Authors": ["Yulin Wang", "Yizeng Han", "Chaofei Wang", "Shiji Song", "Qi Tian", "Gao Huang"], "Categories": "cs.CV cs.AI cs.LG cs.MM"}, "abstract": "Over the past decade, deep learning models have exhibited considerable advancements, reaching or even exceeding human-level performance in a range of visual perception tasks. This remarkable progress has sparked interest in applying deep networks to real-world applications, such as autonomous vehicles, mobile devices, robotics, and edge computing. However, the challenge remains that state-of-the-art models usually demand significant computational resources, leading to impractical power consumption, latency, or carbon emissions in real-world scenarios. This trade-off between effectiveness and efficiency has catalyzed the emergence of a new research focus: computationally efficient deep learning, which strives to achieve satisfactory performance while minimizing the computational cost during inference. This review offers an extensive analysis of this rapidly evolving field by examining four key areas: 1) the development of static or dynamic light-weighted backbone models for the efficient extraction of discriminative deep representations; 2) the specialized network architectures or algorithms tailored for specific computer vision tasks; 3) the techniques employed for compressing deep learning models; and 4) the strategies for deploying efficient deep networks on hardware platforms. Additionally, we provide a systematic discussion on the critical challenges faced in this domain, such as network architecture design, training schemes, practical efficiency, and more realistic model compression approaches, as well as potential future research directions.", "url": "https://arxiv.org/abs/2308.13998"}, {"metadata": {"arXiv": "2308.14108", "Date": "Sun, 27 Aug 2023 13:50:15 ", "Title": "Depth self-supervision for single image novel view synthesis", "Authors": ["Giovanni Minelli", "Matteo Poggi", "Samuele Salti"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "In this paper, we tackle the problem of generating a novel image from an arbitrary viewpoint given a single frame as input. While existing methods operating in this setup aim at predicting the target view depth map to guide the synthesis, without explicit supervision over such a task, we jointly optimize our framework for both novel view synthesis and depth estimation to unleash the synergy between the two at its best. Specifically, a shared depth decoder is trained in a self-supervised manner to predict depth maps that are consistent across the source and target views. Our results demonstrate the effectiveness of our approach in addressing the challenges of both tasks allowing for higher-quality generated images, as well as more accurate depth for the target viewpoint.", "url": "https://arxiv.org/abs/2308.14108"}, {"metadata": {"arXiv": "2308.14595", "Date": "Mon, 28 Aug 2023 14:06:36 ", "Title": "Neural Network Training Strategy to Enhance Anomaly Detection Performance: A Perspective on Reconstruction Loss Amplification", "Authors": ["YeongHyeon Park", "Sungho Kang", "Myung Jin Kim", "Hyeonho Jeong", "Hyunkyu Park", "Hyeong Seok Kim", "Juneho Yi"], "Categories": "cs.CV cs.AI cs.LG eess.IV", "Comments": ["5 pages", "4 figures", "2 tables"]}, "abstract": "Unsupervised anomaly detection (UAD) is a widely adopted approach in industry due to rare anomaly occurrences and data imbalance. A desirable characteristic of an UAD model is contained generalization ability which excels in the reconstruction of seen normal patterns but struggles with unseen anomalies. Recent studies have pursued to contain the generalization capability of their UAD models in reconstruction from different perspectives, such as design of neural network (NN) structure and training strategy. In contrast, we note that containing of generalization ability in reconstruction can also be obtained simply from steep-shaped loss landscape. Motivated by this, we propose a loss landscape sharpening method by amplifying the reconstruction loss, dubbed Loss AMPlification (LAMP). LAMP deforms the loss landscape into a steep shape so the reconstruction error on unseen anomalies becomes greater. Accordingly, the anomaly detection performance is improved without any change of the NN architecture. Our findings suggest that LAMP can be easily applied to any reconstruction error metrics in UAD settings where the reconstruction model is trained with anomaly-free samples only.", "url": "https://arxiv.org/abs/2308.14595"}, {"metadata": {"arXiv": "2308.14710", "Date": "Mon, 28 Aug 2023 17:10:12 ", "Title": "VideoCutLER: Surprisingly Simple Unsupervised Video Instance Segmentation", "Authors": ["Xudong Wang and Ishan Misra and Ziyun Zeng and Rohit Girdhar and Trevor Darrell"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Preprint. Code: https://github.com/facebookresearch/CutLER"]}, "abstract": "Existing approaches to unsupervised video instance segmentation typically rely on motion estimates and experience difficulties tracking small or divergent motions. We present VideoCutLER, a simple method for unsupervised multi-instance video segmentation without using motion-based learning signals like optical flow or training on natural videos. Our key insight is that using high-quality pseudo masks and a simple video synthesis method for model training is surprisingly sufficient to enable the resulting video model to effectively segment and track multiple instances across video frames. We show the first competitive unsupervised learning results on the challenging YouTubeVIS-2019 benchmark, achieving 50.7% APvideo^50 , surpassing the previous state-of-the-art by a large margin. VideoCutLER can also serve as a strong pretrained model for supervised video instance segmentation tasks, exceeding DINO by 15.9% on YouTubeVIS-2019 in terms of APvideo.", "url": "https://arxiv.org/abs/2308.14710"}, {"metadata": {"arXiv": "2308.13554", "Date": "Wed, 23 Aug 2023 22:19:48 ", "Title": "A Systematic Study on Quantifying Bias in GAN-Augmented Data", "Authors": ["Denis Liu"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "Generative adversarial networks (GANs) have recently become a popular data augmentation technique used by machine learning practitioners. However, they have been shown to suffer from the so-called mode collapse failure mode, which makes them vulnerable to exacerbating biases on already skewed datasets, resulting in the generated data distribution being less diverse than the training distribution. To this end, we address the problem of quantifying the extent to which mode collapse occurs. This study is a systematic effort focused on the evaluation of state-of-the-art metrics that can potentially quantify biases in GAN-augmented data. We show that, while several such methods are available, there is no single metric that quantifies bias exacerbation reliably over the span of different image domains.", "url": "https://arxiv.org/abs/2308.13554"}, {"metadata": {"arXiv": "2308.13566", "Date": "Fri, 25 Aug 2023 01:41:04 ", "Title": "MLLM-DataEngine: An Iterative Refinement Approach for MLLM", "Authors": ["Zhiyuan Zhao", "Linke Ouyang", "Bin Wang", "Siyuan Huang", "Pan Zhang", "Xiaoyi Dong", "Jiaqi Wang", "Conghui He"], "Categories": "cs.LG cs.AI cs.CL cs.CV"}, "abstract": "Despite the great advance of Multimodal Large Language Models (MLLMs) in both instruction dataset building and benchmarking, the independence of training and evaluation makes current MLLMs hard to further improve their capability under the guidance of evaluation results with a relatively low human cost. In this paper, we propose MLLM-DataEngine, a novel closed-loop system that bridges data generation, model training, and evaluation. Within each loop iteration, the MLLM-DataEngine first analyze the weakness of the model based on the evaluation results, then generate a proper incremental dataset for the next training iteration and enhance the model capability iteratively. Compared with previous data collection methods which are separate from the benchmarking, the data generated by MLLM-DataEngine shows better targeting, quality, and correctness. For targeting, we propose an Adaptive Bad-case Sampling module, which adjusts the ratio of different types of data within each incremental dataset based on the benchmarking results. For quality, we resort to GPT-4 to generate high-quality data with each given data type. For correctness, prompt design is critical for the data generation results. Rather than previous hand-crafted prompt, we propose an Interactive Prompt Optimization strategy, which optimizes the prompt with the multi-round interaction between human and GPT, and improve the correctness of generated data greatly. Through extensive experiments, we find our MLLM-DataEngine could boost the MLLM capability in a targeted and automatic manner, with only a few human participation. The MLLM-DataEngine will be released and we hope it could be a general solution for the following MLLMs building.", "url": "https://arxiv.org/abs/2308.13566"}, {"metadata": {"arXiv": "2308.13570", "Date": "Fri, 25 Aug 2023 05:52:41 ", "Title": "Stochastic Configuration Machines for Industrial Artificial Intelligence", "Authors": ["Dianhui Wang and Matthew J. Felicetti"], "Categories": "cs.LG cs.AI cs.NE", "Comments": ["23 pages", "7 figures", "12 tables"]}, "abstract": "Real-time predictive modelling with desired accuracy is highly expected in industrial artificial intelligence (IAI), where neural networks play a key role. Neural networks in IAI require powerful, high-performance computing devices to operate a large number of floating point data. Based on stochastic configuration networks (SCNs), this paper proposes a new randomized learner model, termed stochastic configuration machines (SCMs), to stress effective modelling and data size saving that are useful and valuable for industrial applications. Compared to SCNs and random vector functional-link (RVFL) nets with binarized implementation, the model storage of SCMs can be significantly compressed while retaining favourable prediction performance. Besides the architecture of the SCM learner model and its learning algorithm, as an important part of this contribution, we also provide a theoretical basis on the learning capacity of SCMs by analysing the model's complexity. Experimental studies are carried out over some benchmark datasets and three industrial applications. The results demonstrate that SCM has great potential for dealing with industrial data analytics.", "url": "https://arxiv.org/abs/2308.13570"}, {"metadata": {"arXiv": "2308.13816", "Date": "Sat, 26 Aug 2023 08:48:51 ", "Title": "Homological Convolutional Neural Networks", "Authors": ["Antonio Briola", "Yuanrong Wang", "Silvia Bartolucci", "Tomaso Aste"], "Categories": "cs.LG cs.AI cs.CC", "Comments": ["27 pages", "5 figures", "11 tables", "2 equations", "1 algorithm"]}, "abstract": "Deep learning methods have demonstrated outstanding performances on classification and regression tasks on homogeneous data types (e.g., image, audio, and text data). However, tabular data still poses a challenge with classic machine learning approaches being often computationally cheaper and equally effective than increasingly complex deep learning architectures. The challenge arises from the fact that, in tabular data, the correlation among features is weaker than the one from spatial or semantic relationships in images or natural languages, and the dependency structures need to be modeled without any prior information. In this work, we propose a novel deep learning architecture that exploits the data structural organization through topologically constrained network representations to gain spatial information from sparse tabular data. The resulting model leverages the power of convolutions and is centered on a limited number of concepts from network topology to guarantee (i) a data-centric, deterministic building pipeline; (ii) a high level of interpretability over the inference process; and (iii) an adequate room for scalability. We test our model on 18 benchmark datasets against 5 classic machine learning and 3 deep learning models demonstrating that our approach reaches state-of-the-art performances on these challenging datasets. The code to reproduce all our experiments is provided at https://github.com/FinancialComputingUCL/HomologicalCNN.", "url": "https://arxiv.org/abs/2308.13816"}, {"metadata": {"arXiv": "2308.13821", "Date": "Sat, 26 Aug 2023 09:11:44 ", "Title": "A Survey of Imbalanced Learning on Graphs: Problems, Techniques, and Future Directions", "Authors": ["Zemin Liu", "Yuan Li", "Nan Chen", "Qian Wang", "Bryan Hooi", "Bingsheng He"], "Categories": "cs.LG cs.AI", "Comments": ["The collection of awesome literature on imbalanced learning on graphs: https://github.com/Xtra-Computing/Awesome-Literature-ILoGs"]}, "abstract": "Graphs represent interconnected structures prevalent in a myriad of real-world scenarios. Effective graph analytics, such as graph learning methods, enables users to gain profound insights from graph data, underpinning various tasks including node classification and link prediction. However, these methods often suffer from data imbalance, a common issue in graph data where certain segments possess abundant data while others are scarce, thereby leading to biased learning outcomes. This necessitates the emerging field of imbalanced learning on graphs, which aims to correct these data distribution skews for more accurate and representative learning outcomes. In this survey, we embark on a comprehensive review of the literature on imbalanced learning on graphs. We begin by providing a definitive understanding of the concept and related terminologies, establishing a strong foundational understanding for readers. Following this, we propose two comprehensive taxonomies: (1) the problem taxonomy, which describes the forms of imbalance we consider, the associated tasks, and potential solutions; (2) the technique taxonomy, which details key strategies for addressing these imbalances, and aids readers in their method selection process. Finally, we suggest prospective future directions for both problems and techniques within the sphere of imbalanced learning on graphs, fostering further innovation in this critical area.", "url": "https://arxiv.org/abs/2308.13821"}, {"metadata": {"arXiv": "2308.13835", "Date": "Sat, 26 Aug 2023 09:58:09 ", "Title": "Deep Learning for Structure-Preserving Universal Stable Koopman-Inspired Embeddings for Nonlinear Canonical Hamiltonian Dynamics", "Authors": ["Pawan Goyal and S\\\"uleyman Y{\\i}ld{\\i}z and Peter Benner"], "Categories": "cs.LG cs.AI math.DS"}, "abstract": "Discovering a suitable coordinate transformation for nonlinear systems enables the construction of simpler models, facilitating prediction, control, and optimization for complex nonlinear systems. To that end, Koopman operator theory offers a framework for global linearization for nonlinear systems, thereby allowing the usage of linear tools for design studies. In this work, we focus on the identification of global linearized embeddings for canonical nonlinear Hamiltonian systems through a symplectic transformation. While this task is often challenging, we leverage the power of deep learning to discover the desired embeddings. Furthermore, to overcome the shortcomings of Koopman operators for systems with continuous spectra, we apply the lifting principle and learn global cubicized embeddings. Additionally, a key emphasis is paid to enforce the bounded stability for the dynamics of the discovered embeddings. We demonstrate the capabilities of deep learning in acquiring compact symplectic coordinate transformation and the corresponding simple dynamical models, fostering data-driven learning of nonlinear canonical Hamiltonian systems, even those with continuous spectra.", "url": "https://arxiv.org/abs/2308.13835"}, {"metadata": {"arXiv": "2308.13849", "Date": "Sat, 26 Aug 2023 11:10:54 ", "Title": "Effectively Heterogeneous Federated Learning: A Pairing and Split Learning Based Approach", "Authors": ["Jinglong Shen", "Xiucheng Wang", "Nan Cheng", "Longfei Ma", "Conghao Zhou", "Yuan Zhang"], "Categories": "cs.LG cs.AI cs.SY eess.SY"}, "abstract": "As a promising paradigm federated Learning (FL) is widely used in privacy-preserving machine learning, which allows distributed devices to collaboratively train a model while avoiding data transmission among clients. Despite its immense potential, the FL suffers from bottlenecks in training speed due to client heterogeneity, leading to escalated training latency and straggling server aggregation. To deal with this challenge, a novel split federated learning (SFL) framework that pairs clients with different computational resources is proposed, where clients are paired based on computing resources and communication rates among clients, meanwhile the neural network model is split into two parts at the logical level, and each client only computes the part assigned to it by using the SL to achieve forward inference and backward training. Moreover, to effectively deal with the client pairing problem, a heuristic greedy algorithm is proposed by reconstructing the optimization of training latency as a graph edge selection problem. Simulation results show the proposed method can significantly improve the FL training speed and achieve high performance both in independent identical distribution (IID) and Non-IID data distribution.", "url": "https://arxiv.org/abs/2308.13849"}, {"metadata": {"arXiv": "2308.13970", "Date": "Sat, 26 Aug 2023 22:54:45 ", "Title": "FAM: fast adaptive meta-learning", "Authors": ["Indrajeet Kumar Sinha", "Shekhar Verma and Krishna Pratap Singh"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["13 Pages", "1 figure"]}, "abstract": "In this work, we propose a fast adaptive federated meta-learning (FAM) framework for collaboratively learning a single global model, which can then be personalized locally on individual clients. Federated learning enables multiple clients to collaborate to train a model without sharing data. Clients with insufficient data or data diversity participate in federated learning to learn a model with superior performance. Nonetheless, learning suffers when data distributions diverge. There is a need to learn a global model that can be adapted using client's specific information to create personalised models on clients is required. MRI data suffers from this problem, wherein, one, due to data acquisition challenges, local data at a site is sufficient for training an accurate model and two, there is a restriction of data sharing due to privacy concerns and three, there is a need for personalization of a learnt shared global model on account of domain shift across client sites. The global model is sparse and captures the common features in the MRI. This skeleton network is grown on each client to train a personalised model by learning additional client-specific parameters from local data. Experimental results show that the personalization process at each client quickly converges using a limited number of epochs. The personalized client models outperformed the locally trained models, demonstrating the efficacy of the FAM mechanism. Additionally, the sparse parameter set to be communicated during federated learning drastically reduced communication overhead, which makes the scheme viable for networks with limited resources.", "url": "https://arxiv.org/abs/2308.13970"}, {"metadata": {"arXiv": "2308.13976", "Date": "Sun, 27 Aug 2023 00:31:04 ", "Title": "Label Denoising through Cross-Model Agreement", "Authors": ["Yu Wang", "Xin Xin", "Zaiqiao Meng", "Xiangnan He", "Joemon Jose", "Fuli Feng"], "Categories": "cs.LG cs.AI", "Comments": ["arXiv admin note: substantial text overlap with arXiv:2105.09605"]}, "abstract": "Learning from corrupted labels is very common in real-world machine-learning applications. Memorizing such noisy labels could affect the learning of the model, leading to sub-optimal performances. In this work, we propose a novel framework to learn robust machine-learning models from noisy labels. Through an empirical study, we find that different models make relatively similar predictions on clean examples, while the predictions on noisy examples vary much more across different models. Motivated by this observation, we propose \\em denoising with cross-model agreement \\em (DeCA) which aims to minimize the KL-divergence between the true label distributions parameterized by two machine learning models while maximizing the likelihood of data observation. We employ the proposed DeCA on both the binary label scenario and the multiple label scenario. For the binary label scenario, we select implicit feedback recommendation as the downstream task and conduct experiments with four state-of-the-art recommendation models on four datasets. For the multiple-label scenario, the downstream application is image classification on two benchmark datasets. Experimental results demonstrate that the proposed methods significantly improve the model performance compared with normal training and other denoising methods on both binary and multiple-label scenarios.", "url": "https://arxiv.org/abs/2308.13976"}, {"metadata": {"arXiv": "2308.13985", "Date": "Sun, 27 Aug 2023 02:10:22 ", "Title": "Revisiting Scalarization in Multi-Task Learning: A Theoretical Perspective", "Authors": ["Yuzheng Hu", "Ruicheng Xian", "Qilong Wu", "Qiuling Fan", "Lang Yin", "Han Zhao"], "Categories": "cs.LG cs.AI"}, "abstract": "Linear scalarization, i.e., combining all loss functions by a weighted sum, has been the default choice in the literature of multi-task learning (MTL) since its inception. In recent years, there is a surge of interest in developing Specialized Multi-Task Optimizers (SMTOs) that treat MTL as a multi-objective optimization problem. However, it remains open whether there is a fundamental advantage of SMTOs over scalarization. In fact, heated debates exist in the community comparing these two types of algorithms, mostly from an empirical perspective. To approach the above question, in this paper, we revisit scalarization from a theoretical perspective. We focus on linear MTL models and study whether scalarization is capable of fully exploring the Pareto front. Our findings reveal that, in contrast to recent works that claimed empirical advantages of scalarization, scalarization is inherently incapable of full exploration, especially for those Pareto optimal solutions that strike the balanced trade-offs between multiple tasks. More concretely, when the model is under-parametrized, we reveal a multi-surface structure of the feasible region and identify necessary and sufficient conditions for full exploration. This leads to the conclusion that scalarization is in general incapable of tracing out the Pareto front. Our theoretical results partially answer the open questions in Xin et al. (2021), and provide a more intuitive explanation on why scalarization fails beyond non-convexity. We additionally perform experiments on a real-world dataset using both scalarization and state-of-the-art SMTOs. The experimental results not only corroborate our theoretical findings, but also unveil the potential of SMTOs in finding balanced solutions, which cannot be achieved by scalarization.", "url": "https://arxiv.org/abs/2308.13985"}, {"metadata": {"arXiv": "2308.14017", "Date": "Sun, 27 Aug 2023 06:31:43 ", "Title": "Revolutionizing Disease Diagnosis: A Microservices-Based Architecture for Privacy-Preserving and Efficient IoT Data Analytics Using Federated Learning", "Authors": ["Safa Ben Atitallah", "Maha Driss", "Henda Ben Ghezala"], "Categories": "cs.LG cs.AI"}, "abstract": "Deep learning-based disease diagnosis applications are essential for accurate diagnosis at various disease stages. However, using personal data exposes traditional centralized learning systems to privacy concerns. On the other hand, by positioning processing resources closer to the device and enabling more effective data analyses, a distributed computing paradigm has the potential to revolutionize disease diagnosis. Scalable architectures for data analytics are also crucial in healthcare, where data analytics results must have low latency and high dependability and reliability. This study proposes a microservices-based approach for IoT data analytics systems to satisfy privacy and performance requirements by arranging entities into fine-grained, loosely connected, and reusable collections. Our approach relies on federated learning, which can increase disease diagnosis accuracy while protecting data privacy. Additionally, we employ transfer learning to obtain more efficient models. Using more than 5800 chest X-ray images for pneumonia detection from a publicly available dataset, we ran experiments to assess the effectiveness of our approach. Our experiments reveal that our approach performs better in identifying pneumonia than other cutting-edge technologies, demonstrating our approach's promising potential detection performance.", "url": "https://arxiv.org/abs/2308.14017"}, {"metadata": {"arXiv": "2308.14058", "Date": "Sun, 27 Aug 2023 09:45:41 ", "Title": "Pruning the Unlabeled Data to Improve Semi-Supervised Learning", "Authors": ["Guy Hacohen", "Daphna Weinshall"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "In the domain of semi-supervised learning (SSL), the conventional approach involves training a learner with a limited amount of labeled data alongside a substantial volume of unlabeled data, both drawn from the same underlying distribution. However, for deep learning models, this standard practice may not yield optimal results. In this research, we propose an alternative perspective, suggesting that distributions that are more readily separable could offer superior benefits to the learner as compared to the original distribution. To achieve this, we present PruneSSL, a practical technique for selectively removing examples from the original unlabeled dataset to enhance its separability. We present an empirical study, showing that although PruneSSL reduces the quantity of available training data for the learner, it significantly improves the performance of various competitive SSL algorithms, thereby achieving state-of-the-art results across several image classification tasks.", "url": "https://arxiv.org/abs/2308.14058"}, {"metadata": {"arXiv": "2308.14093", "Date": "Sun, 27 Aug 2023 12:35:38 ", "Title": "The inverse problem for neural networks", "Authors": ["Marcelo Forets and Christian Schilling"], "Categories": "cs.LG cs.AI cs.LO"}, "abstract": "We study the problem of computing the preimage of a set under a neural network with piecewise-affine activation functions. We recall an old result that the preimage of a polyhedral set is again a union of polyhedral sets and can be effectively computed. We show several applications of computing the preimage for analysis and interpretability of neural networks.", "url": "https://arxiv.org/abs/2308.14093"}, {"metadata": {"arXiv": "2308.14120", "Date": "Sun, 27 Aug 2023 14:28:38 ", "Title": "Empowering Clinicians and Democratizing Data Science: Large Language Models Automate Machine Learning for Clinical Studies", "Authors": ["Soroosh Tayebi Arasteh", "Tianyu Han", "Mahshad Lotfinia", "Christiane Kuhl", "Jakob Nikolas Kather", "Daniel Truhn", "Sven Nebelung"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "A knowledge gap persists between Machine Learning (ML) developers (e.g., data scientists) and practitioners (e.g., clinicians), hampering the full utilization of ML for clinical data analysis. We investigated the potential of the chatGPT Code Interpreter (CI), an extension of GPT-4, to bridge this gap and perform ML analyses efficiently. Real-world clinical datasets and study details from large trials across various medical specialties were presented to chatGPT CI without specific guidance. ChatGPT CI autonomously developed state-of-the-art ML models based on the original study's training data to predict clinical outcomes such as cancer development, cancer progression, disease complications, or biomarkers such as pathogenic gene sequences. Strikingly, these ML models matched or outperformed their published counterparts. We conclude that chatGPT CI offers a promising avenue to democratize ML in medicine, making advanced analytics accessible to non-ML experts and promoting broader applications in medical research and practice.", "url": "https://arxiv.org/abs/2308.14120"}, {"metadata": {"arXiv": "2308.14172", "Date": "Sun, 27 Aug 2023 18:28:58 ", "Title": "Hypergraph Structure Inference From Data Under Smoothness Prior", "Authors": ["Bohan Tang", "Siheng Chen", "Xiaowen Dong"], "Categories": "cs.LG cs.AI cs.SI eess.SP stat.ML"}, "abstract": "Hypergraphs are important for processing data with higher-order relationships involving more than two entities. In scenarios where explicit hypergraphs are not readily available, it is desirable to infer a meaningful hypergraph structure from the node features to capture the intrinsic relations within the data. However, existing methods either adopt simple pre-defined rules that fail to precisely capture the distribution of the potential hypergraph structure, or learn a mapping between hypergraph structures and node features but require a large amount of labelled data, i.e., pre-existing hypergraph structures, for training. Both restrict their applications in practical scenarios. To fill this gap, we propose a novel smoothness prior that enables us to design a method to infer the probability for each potential hyperedge without labelled data as supervision. The proposed prior indicates features of nodes in a hyperedge are highly correlated by the features of the hyperedge containing them. We use this prior to derive the relation between the hypergraph structure and the node features via probabilistic modelling. This allows us to develop an unsupervised inference method to estimate the probability for each potential hyperedge via solving an optimisation problem that has an analytical solution. Experiments on both synthetic and real-world data demonstrate that our method can learn meaningful hypergraph structures from data more efficiently than existing hypergraph structure inference methods.", "url": "https://arxiv.org/abs/2308.14172"}, {"metadata": {"arXiv": "2308.14181", "Date": "Sun, 27 Aug 2023 19:01:29 ", "Title": "Topological Augmentation for Class-Imbalanced Node Classification", "Authors": ["Zhining Liu", "Zhichen Zeng", "Ruizhong Qiu", "Hyunsik Yoo", "David Zhou", "Zhe Xu", "Yada Zhu", "Kommy Weldemariam", "Jingrui He", "Hanghang Tong"], "Categories": "cs.LG cs.AI", "Comments": ["19 pages", "8 figures"]}, "abstract": "Class imbalance is prevalent in real-world node classification tasks and often biases graph learning models toward majority classes. Most existing studies root from a node-centric perspective and aim to address the class imbalance in training data by node/class-wise reweighting or resampling. In this paper, we approach the source of the class-imbalance bias from an under-explored topology-centric perspective. Our investigation reveals that beyond the inherently skewed training class distribution, the graph topology also plays an important role in the formation of predictive bias: we identify two fundamental challenges, namely ambivalent and distant message-passing, that can exacerbate the bias by aggravating majority-class over-generalization and minority-class misclassification. In light of these findings, we devise a lightweight topological augmentation method ToBA to dynamically rectify the nodes influenced by ambivalent/distant message-passing during graph learning, so as to mitigate the class-imbalance bias. We highlight that ToBA is a model-agnostic, efficient, and versatile solution that can be seamlessly combined with and further boost other imbalance-handling techniques. Systematic experiments validate the superior performance of ToBA in both promoting imbalanced node classification and mitigating the prediction bias between different classes.", "url": "https://arxiv.org/abs/2308.14181"}, {"metadata": {"arXiv": "2308.14250", "Date": "Mon, 28 Aug 2023 01:57:38 ", "Title": "Rule-Based Error Detection and Correction to Operationalize Movement Trajectory Classification", "Authors": ["Bowen Xi", "Kevin Scaria", "Paulo Shakarian"], "Categories": "cs.LG cs.AI cs.LO"}, "abstract": "Classification of movement trajectories has many applications in transportation. Supervised neural models represent the current state-of-the-art. Recent security applications require this task to be rapidly employed in environments that may differ from the data used to train such models for which there is little training data. We provide a neuro-symbolic rule-based framework to conduct error correction and detection of these models to support eventual deployment in security applications. We provide a suite of experiments on several recent and state-of-the-art models and show an accuracy improvement of 1.7% over the SOTA model in the case where all classes are present in training and when 40% of classes are omitted from training, we obtain a 5.2% improvement (zero-shot) and 23.9% (few-shot) improvement over the SOTA model without resorting to retraining of the base model.", "url": "https://arxiv.org/abs/2308.14250"}, {"metadata": {"arXiv": "2308.14308", "Date": "Mon, 28 Aug 2023 05:23:16 ", "Title": "Policy Diversity for Cooperative Agents", "Authors": ["Mingxi Tan", "Andong Tian and Ludovic Denoyer"], "Categories": "cs.LG cs.AI cs.MA"}, "abstract": "Standard cooperative multi-agent reinforcement learning (MARL) methods aim to find the optimal team cooperative policy to complete a task. However there may exist multiple different ways of cooperating, which usually are very needed by domain experts. Therefore, identifying a set of significantly different policies can alleviate the task complexity for them. Unfortunately, there is a general lack of effective policy diversity approaches specifically designed for the multi-agent domain. In this work, we propose a method called Moment-Matching Policy Diversity to alleviate this problem. This method can generate different team policies to varying degrees by formalizing the difference between team policies as the difference in actions of selected agents in different policies. Theoretically, we show that our method is a simple way to implement a constrained optimization problem that regularizes the difference between two trajectory distributions by using the maximum mean discrepancy. The effectiveness of our approach is demonstrated on a challenging team-based shooter.", "url": "https://arxiv.org/abs/2308.14308"}, {"metadata": {"arXiv": "2308.14328", "Date": "Mon, 28 Aug 2023 06:15:14 ", "Title": "Reinforcement Learning for Generative AI: A Survey", "Authors": ["Yuanjiang Cao and Lina Yao and Julian McAuley and Quan Z. Sheng"], "Categories": "cs.LG cs.AI"}, "abstract": "Deep Generative AI has been a long-standing essential topic in the machine learning community, which can impact a number of application areas like text generation and computer vision. The major paradigm to train a generative model is maximum likelihood estimation, which pushes the learner to capture and approximate the target data distribution by decreasing the divergence between the model distribution and the target distribution. This formulation successfully establishes the objective of generative tasks, while it is incapable of satisfying all the requirements that a user might expect from a generative model. Reinforcement learning, serving as a competitive option to inject new training signals by creating new objectives that exploit novel signals, has demonstrated its power and flexibility to incorporate human inductive bias from multiple angles, such as adversarial learning, hand-designed rules and learned reward model to build a performant model. Thereby, reinforcement learning has become a trending research field and has stretched the limits of generative AI in both model design and application. It is reasonable to summarize and conclude advances in recent years with a comprehensive review. Although there are surveys in different application areas recently, this survey aims to shed light on a high-level review that spans a range of application areas. We provide a rigorous taxonomy in this area and make sufficient coverage on various models and applications. Notably, we also surveyed the fast-developing large language model area. We conclude this survey by showing the potential directions that might tackle the limit of current models and expand the frontiers for generative AI.", "url": "https://arxiv.org/abs/2308.14328"}, {"metadata": {"arXiv": "2308.14333", "Date": "Mon, 28 Aug 2023 06:22:43 ", "Title": "DiffSmooth: Certifiably Robust Learning via Diffusion Models and Local Smoothing", "Authors": ["Jiawei Zhang", "Zhongzhu Chen", "Huan Zhang", "Chaowei Xiao", "Bo Li"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted in 32nd USENIX Security", "2023"]}, "abstract": "Diffusion models have been leveraged to perform adversarial purification and thus provide both empirical and certified robustness for a standard model. On the other hand, different robustly trained smoothed models have been studied to improve the certified robustness. Thus, it raises a natural question: Can diffusion model be used to achieve improved certified robustness on those robustly trained smoothed models? In this work, we first theoretically show that recovered instances by diffusion models are in the bounded neighborhood of the original instance with high probability; and the \"one-shot\" denoising diffusion probabilistic models (DDPM) can approximate the mean of the generated distribution of a continuous-time diffusion model, which approximates the original instance under mild conditions. Inspired by our analysis, we propose a certifiably robust pipeline DiffSmooth, which first performs adversarial purification via diffusion models and then maps the purified instances to a common region via a simple yet effective local smoothing strategy. We conduct extensive experiments on different datasets and show that DiffSmooth achieves SOTA-certified robustness compared with eight baselines. For instance, DiffSmooth improves the SOTA-certified accuracy from $36.0\\%$ to $53.0\\%$ under $\\ell_2$ radius $1.5$ on ImageNet. The code is available at [https://github.com/javyduck/DiffSmooth].", "url": "https://arxiv.org/abs/2308.14333"}, {"metadata": {"arXiv": "2308.14338", "Date": "Mon, 28 Aug 2023 06:31:37 ", "Title": "Fair Few-shot Learning with Auxiliary Sets", "Authors": ["Song Wang", "Jing Ma", "Lu Cheng", "Jundong Li"], "Categories": "cs.LG cs.AI", "Comments": ["ECAI 2023"]}, "abstract": "Recently, there has been a growing interest in developing machine learning (ML) models that can promote fairness, i.e., eliminating biased predictions towards certain populations (e.g., individuals from a specific demographic group). Most existing works learn such models based on well-designed fairness constraints in optimization. Nevertheless, in many practical ML tasks, only very few labeled data samples can be collected, which can lead to inferior fairness performance. This is because existing fairness constraints are designed to restrict the prediction disparity among different sensitive groups, but with few samples, it becomes difficult to accurately measure the disparity, thus rendering ineffective fairness optimization. In this paper, we define the fairness-aware learning task with limited training samples as the \\emph{fair few-shot learning} problem. To deal with this problem, we devise a novel framework that accumulates fairness-aware knowledge across different meta-training tasks and then generalizes the learned knowledge to meta-test tasks. To compensate for insufficient training samples, we propose an essential strategy to select and leverage an auxiliary set for each meta-test task. These auxiliary sets contain several labeled training samples that can enhance the model performance regarding fairness in meta-test tasks, thereby allowing for the transfer of learned useful fairness-oriented knowledge to meta-test tasks. Furthermore, we conduct extensive experiments on three real-world datasets to validate the superiority of our framework against the state-of-the-art baselines.", "url": "https://arxiv.org/abs/2308.14338"}, {"metadata": {"arXiv": "2308.14352", "Date": "Mon, 28 Aug 2023 06:56:08 ", "Title": "EdgeMoE: Fast On-Device Inference of MoE-based Large Language Models", "Authors": ["Rongjie Yi", "Liwei Guo", "Shiyun Wei", "Ao Zhou", "Shangguang Wang", "Mengwei Xu"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "Large Language Models (LLMs) such as GPTs and LLaMa have ushered in a revolution in machine intelligence, owing to their exceptional capabilities in a wide range of machine learning tasks. However, the transition of LLMs from data centers to edge devices presents a set of challenges and opportunities. While this shift can enhance privacy and availability, it is hampered by the enormous parameter sizes of these models, leading to impractical runtime costs. In light of these considerations, we introduce EdgeMoE, the first on-device inference engine tailored for mixture-of-expert (MoE) LLMs, a popular variant of sparse LLMs that exhibit nearly constant computational complexity as their parameter size scales. EdgeMoE achieves both memory and computational efficiency by strategically partitioning the model across the storage hierarchy. Specifically, non-expert weights are stored in the device's memory, while expert weights are kept in external storage and are fetched into memory only when they are activated. This design is underpinned by a crucial insight that expert weights, though voluminous, are infrequently accessed due to sparse activation patterns. To further mitigate the overhead associated with expert I/O swapping, EdgeMoE incorporates two innovative techniques: (1) Expert-wise bitwidth adaptation: This method reduces the size of expert weights with an acceptable level of accuracy loss. (2) Expert management: It predicts the experts that will be activated in advance and preloads them into the compute-I/O pipeline, thus further optimizing the process. In empirical evaluations conducted on well-established MoE LLMs and various edge devices, EdgeMoE demonstrates substantial memory savings and performance improvements when compared to competitive baseline solutions.", "url": "https://arxiv.org/abs/2308.14352"}, {"metadata": {"arXiv": "2308.14364", "Date": "Mon, 28 Aug 2023 07:23:03 ", "Title": "Target-independent XLA optimization using Reinforcement Learning", "Authors": ["Milan Ganai", "Haichen Li", "Theodore Enns", "Yida Wang", "Randy Huang"], "Categories": "cs.LG cs.AI", "Comments": ["Workshop on ML for Systems @ NeurIPS 2022"]}, "abstract": "An important challenge in Machine Learning compilers like XLA is multi-pass optimization and analysis. There has been recent interest chiefly in XLA target-dependent optimization on the graph-level, subgraph-level, and kernel-level phases. We specifically focus on target-independent optimization XLA HLO pass ordering: our approach aims at finding the optimal sequence of compiler optimization passes, which is decoupled from target-dependent optimization. However, there is little domain specific study in pass ordering for XLA HLO. To this end, we propose introducing deep Reinforcement Learning (RL) based search for optimal XLA HLO pass ordering. We also propose enhancements to the deep RL algorithms to further improve optimal search performance and open the research direction for domain-specific guidance for RL. We create an XLA Gym experimentation framework as a tool to enable RL algorithms to interact with the compiler for passing optimizations and thereby train agents. Overall, in our experimentation we observe an average of $13.3\\%$ improvement in operation count reduction on a benchmark of GPT-2 training graphs and $10.4\\%$ improvement on a diverse benchmark including GPT-2, BERT, and ResNet graphs using the proposed approach over the compiler's default phase ordering.", "url": "https://arxiv.org/abs/2308.14364"}, {"metadata": {"arXiv": "2308.14376", "Date": "Mon, 28 Aug 2023 07:49:01 ", "Title": "Are Existing Out-Of-Distribution Techniques Suitable for Network Intrusion Detection?", "Authors": ["Andrea Corsini and Shanchieh Jay Yang"], "Categories": "cs.LG cs.AI cs.CR"}, "abstract": "Machine learning (ML) has become increasingly popular in network intrusion detection. However, ML-based solutions always respond regardless of whether the input data reflects known patterns, a common issue across safety-critical applications. While several proposals exist for detecting Out-Of-Distribution (OOD) in other fields, it remains unclear whether these approaches can effectively identify new forms of intrusions for network security. New attacks, not necessarily affecting overall distributions, are not guaranteed to be clearly OOD as instead, images depicting new classes are in computer vision. In this work, we investigate whether existing OOD detectors from other fields allow the identification of unknown malicious traffic. We also explore whether more discriminative and semantically richer embedding spaces within models, such as those created with contrastive learning and multi-class tasks, benefit detection. Our investigation covers a set of six OOD techniques that employ different detection strategies. These techniques are applied to models trained in various ways and subsequently exposed to unknown malicious traffic from the same and different datasets (network environments). Our findings suggest that existing detectors can identify a consistent portion of new malicious traffic, and that improved embedding spaces enhance detection. We also demonstrate that simple combinations of certain detectors can identify almost 100% of malicious traffic in our tested scenarios.", "url": "https://arxiv.org/abs/2308.14376"}, {"metadata": {"arXiv": "2308.14522", "Date": "Mon, 28 Aug 2023 12:17:51 ", "Title": "Large Graph Models: A Perspective", "Authors": ["Ziwei Zhang", "Haoyang Li", "Zeyang Zhang", "Yijian Qin", "Xin Wang", "Wenwu Zhu"], "Categories": "cs.LG cs.AI cs.SI", "Comments": ["Preliminary version. Comments are welcome"]}, "abstract": "Large models have emerged as the most recent groundbreaking achievements in artificial intelligence, and particularly machine learning. However, when it comes to graphs, large models have not achieved the same level of success as in other fields, such as natural language processing and computer vision. In order to promote applying large models for graphs forward, we present a perspective paper to discuss the challenges and opportunities associated with developing large graph models. First, we discuss the desired characteristics of large graph models. Then, we present detailed discussions from three key perspectives: representation basis, graph data, and graph models. In each category, we provide a brief overview of recent advances and highlight the remaining challenges together with our visions. Finally, we discuss valuable applications of large graph models. We believe this perspective paper is able to encourage further investigations into large graph models, ultimately pushing us one step closer towards artificial general intelligence (AGI).", "url": "https://arxiv.org/abs/2308.14522"}, {"metadata": {"arXiv": "2308.14711", "Date": "Mon, 28 Aug 2023 17:11:41 ", "Title": "Fast Feedforward Networks", "Authors": ["Peter Belcak and Roger Wattenhofer"], "Categories": "cs.LG cs.AI cs.PF", "Comments": ["12 pages", "6 figures", "4 tables"]}, "abstract": "We break the linear link between the layer size and its inference cost by introducing the fast feedforward (FFF) architecture, a logarithmic-time alternative to feedforward networks. We show that FFFs give comparable performance to feedforward networks at an exponential fraction of their inference cost, are quicker to deliver performance compared to mixture-of-expert networks, and can readily take the place of either in transformers. Pushing FFFs to the absolute limit, we train a vision transformer to perform single-neuron inferences at the cost of only 5.8% performance decrease against the full-width variant. Our implementation is available as a Python package; just use \"pip install fastfeedforward\".", "url": "https://arxiv.org/abs/2308.14711"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

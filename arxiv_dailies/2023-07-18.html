<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2307.07892", "Date": "Sat, 15 Jul 2023 22:11:34 ", "Title": "Multitemporal SAR images change detection and visualization using RABASAR and simplified GLR", "Authors": ["Weiying Zhao", "Charles-Alban Deledalle", "Lo\\\"ic Denis", "Henri Ma\\^itre", "Jean-Marie Nicolas and Florence Tupin"], "Categories": "cs.CV cs.LG eess.IV"}, "abstract": "Understanding the state of changed areas requires that precise information be given about the changes. Thus, detecting different kinds of changes is important for land surface monitoring. SAR sensors are ideal to fulfil this task, because of their all-time and all-weather capabilities, with good accuracy of the acquisition geometry and without effects of atmospheric constituents for amplitude data. In this study, we propose a simplified generalized likelihood ratio ($S_{GLR}$) method assuming that corresponding temporal pixels have the same equivalent number of looks (ENL). Thanks to the denoised data provided by a ratio-based multitemporal SAR image denoising method (RABASAR), we successfully applied this similarity test approach to compute the change areas. A new change magnitude index method and an improved spectral clustering-based change classification method are also developed. In addition, we apply the simplified generalized likelihood ratio to detect the maximum change magnitude time, and the change starting and ending times. Then, we propose to use an adaptation of the REACTIV method to visualize the detection results vividly. The effectiveness of the proposed methods is demonstrated through the processing of simulated and SAR images, and the comparison with classical techniques. In particular, numerical experiments proved that the developed method has good performances in detecting farmland area changes, building area changes, harbour area changes and flooding area changes.", "url": "https://arxiv.org/abs/2307.07892"}, {"metadata": {"arXiv": "2307.07998", "Date": "Sun, 16 Jul 2023 10:34:23 ", "Title": "LUCYD: A Feature-Driven Richardson-Lucy Deconvolution Network", "Authors": ["Tom\\'a\\v{s} Chobola", "Gesine M\\\"uller", "Veit Dausmann", "Anton Theileis", "Jan Taucher", "Jan Huisken", "Tingying Peng"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted by 26th International Conference on Medical Image Computing and Computer Assisted Intervention"]}, "abstract": "The process of acquiring microscopic images in life sciences often results in image degradation and corruption, characterised by the presence of noise and blur, which poses significant challenges in accurately analysing and interpreting the obtained data. This paper proposes LUCYD, a novel method for the restoration of volumetric microscopy images that combines the Richardson-Lucy deconvolution formula and the fusion of deep features obtained by a fully convolutional network. By integrating the image formation process into a feature-driven restoration model, the proposed approach aims to enhance the quality of the restored images whilst reducing computational costs and maintaining a high degree of interpretability. Our results demonstrate that LUCYD outperforms the state-of-the-art methods in both synthetic and real microscopy images, achieving superior performance in terms of image quality and generalisability. We show that the model can handle various microscopy modalities and different imaging conditions by evaluating it on two different microscopy datasets, including volumetric widefield and light-sheet microscopy. Our experiments indicate that LUCYD can significantly improve resolution, contrast, and overall quality of microscopy images. Therefore, it can be a valuable tool for microscopy image restoration and can facilitate further research in various microscopy applications. We made the source code for the model accessible under https://github.com/ctom2/lucyd-deconvolution.", "url": "https://arxiv.org/abs/2307.07998"}, {"metadata": {"arXiv": "2307.08117", "Date": "Sun, 16 Jul 2023 17:50:37 ", "Title": "Domain Generalisation with Bidirectional Encoder Representations from Vision Transformers", "Authors": ["Hamza Riaz and Alan F. Smeaton"], "Categories": "cs.CV cs.LG", "Comments": ["4 pages", "accepted at the Irish Machine Vision and Image Processing Conference (IMVIP)", "Galway", "August 2023"]}, "abstract": "Domain generalisation involves pooling knowledge from source domain(s) into a single model that can generalise to unseen target domain(s). Recent research in domain generalisation has faced challenges when using deep learning models as they interact with data distributions which differ from those they are trained on. Here we perform domain generalisation on out-of-distribution (OOD) vision benchmarks using vision transformers. Initially we examine four vision transformer architectures namely ViT, LeViT, DeiT, and BEIT on out-of-distribution data. As the bidirectional encoder representation from image transformers (BEIT) architecture performs best, we use it in further experiments on three benchmarks PACS, Home-Office and DomainNet. Our results show significant improvements in validation and test accuracy and our implementation significantly overcomes gaps between within-distribution and OOD data.", "url": "https://arxiv.org/abs/2307.08117"}, {"metadata": {"arXiv": "2307.08278", "Date": "Mon, 17 Jul 2023 06:58:22 ", "Title": "Adversarial Attacks on Traffic Sign Recognition: A Survey", "Authors": ["Svetlana Pavlitska", "Nico Lambing and J. Marius Z\\\"ollner"], "Categories": "cs.CV cs.CR cs.LG", "Comments": ["Accepted for publication at ICECCME2023"]}, "abstract": "Traffic sign recognition is an essential component of perception in autonomous vehicles, which is currently performed almost exclusively with deep neural networks (DNNs). However, DNNs are known to be vulnerable to adversarial attacks. Several previous works have demonstrated the feasibility of adversarial attacks on traffic sign recognition models. Traffic signs are particularly promising for adversarial attack research due to the ease of performing real-world attacks using printed signs or stickers. In this work, we survey existing works performing either digital or real-world attacks on traffic sign detection and classification models. We provide an overview of the latest advancements and highlight the existing research areas that require further investigation.", "url": "https://arxiv.org/abs/2307.08278"}, {"metadata": {"arXiv": "2307.08318", "Date": "Mon, 17 Jul 2023 08:26:36 ", "Title": "Airway Label Prediction in Video Bronchoscopy: Capturing Temporal Dependencies Utilizing Anatomical Knowledge", "Authors": ["Ron Keuth", "Mattias Heinrich", "Martin Eichenlaub and Marian Himstedt"], "Categories": "cs.CV cs.LG", "Comments": ["Submitted to International Journal of Computer Assisted Radiology and Surgery"]}, "abstract": "Purpose: Navigation guidance is a key requirement for a multitude of lung interventions using video bronchoscopy. State-of-the-art solutions focus on lung biopsies using electromagnetic tracking and intraoperative image registration w.r.t. preoperative CT scans for guidance. The requirement of patient-specific CT scans hampers the utilisation of navigation guidance for other applications such as intensive care units. Methods: This paper addresses navigation guidance solely incorporating bronchosopy video data. In contrast to state-of-the-art approaches we entirely omit the use of electromagnetic tracking and patient-specific CT scans. Guidance is enabled by means of topological bronchoscope localization w.r.t. an interpatient airway model. Particularly, we take maximally advantage of anatomical constraints of airway trees being sequentially traversed. This is realized by incorporating sequences of CNN-based airway likelihoods into a Hidden Markov Model. Results: Our approach is evaluated based on multiple experiments inside a lung phantom model. With the consideration of temporal context and use of anatomical knowledge for regularization, we are able to improve the accuracy up to to 0.98 compared to 0.81 (weighted F1: 0.98 compared to 0.81) for a classification based on individual frames. Conclusion: We combine CNN-based single image classification of airway segments with anatomical constraints and temporal HMM-based inference for the first time. Our approach renders vision-only guidance for bronchoscopy interventions in the absence of electromagnetic tracking and patient-specific CT scans possible.", "url": "https://arxiv.org/abs/2307.08318"}, {"metadata": {"arXiv": "2307.08528", "Date": "Mon, 17 Jul 2023 14:40:16 ", "Title": "Multi-Domain Learning with Modulation Adapters", "Authors": ["Ekaterina Iakovleva", "Karteek Alahari", "Jakob Verbeek"], "Categories": "cs.CV cs.LG"}, "abstract": "Deep convolutional networks are ubiquitous in computer vision, due to their excellent performance across different tasks for various domains. Models are, however, often trained in isolation for each task, failing to exploit relatedness between tasks and domains to learn more compact models that generalise better in low-data regimes. Multi-domain learning aims to handle related tasks, such as image classification across multiple domains, simultaneously. Previous work on this problem explored the use of a pre-trained and fixed domain-agnostic base network, in combination with smaller learnable domain-specific adaptation modules. In this paper, we introduce Modulation Adapters, which update the convolutional filter weights of the model in a multiplicative manner for each task. Parameterising these adaptation weights in a factored manner allows us to scale the number of per-task parameters in a flexible manner, and to strike different parameter-accuracy trade-offs. We evaluate our approach on the Visual Decathlon challenge, composed of ten image classification tasks across different domains, and on the ImageNet-to-Sketch benchmark, which consists of six image classification tasks. Our approach yields excellent results, with accuracies that are comparable to or better than those of existing state-of-the-art approaches.", "url": "https://arxiv.org/abs/2307.08528"}, {"metadata": {"arXiv": "2307.08698", "Date": "Mon, 17 Jul 2023 17:57:56 ", "Title": "Flow Matching in Latent Space", "Authors": ["Quan Dao", "Hao Phung", "Binh Nguyen", "Anh Tran"], "Categories": "cs.CV cs.LG", "Comments": ["Project Page: https://vinairesearch.github.io/LFM/"]}, "abstract": "Flow matching is a recent framework to train generative models that exhibits impressive empirical performance while being relatively easier to train compared with diffusion-based models. Despite its advantageous properties, prior methods still face the challenges of expensive computing and a large number of function evaluations of off-the-shelf solvers in the pixel space. Furthermore, although latent-based generative methods have shown great success in recent years, this particular model type remains underexplored in this area. In this work, we propose to apply flow matching in the latent spaces of pretrained autoencoders, which offers improved computational efficiency and scalability for high-resolution image synthesis. This enables flow-matching training on constrained computational resources while maintaining their quality and flexibility. Additionally, our work stands as a pioneering contribution in the integration of various conditions into flow matching for conditional generation tasks, including label-conditioned image generation, image inpainting, and semantic-to-image generation. Through extensive experiments, our approach demonstrates its effectiveness in both quantitative and qualitative results on various datasets, such as CelebA-HQ, FFHQ, LSUN Church & Bedroom, and ImageNet. We also provide a theoretical control of the Wasserstein-2 distance between the reconstructed latent flow distribution and true data distribution, showing it is upper-bounded by the latent flow matching objective. Our code will be available at https://github.com/VinAIResearch/LFM.git.", "url": "https://arxiv.org/abs/2307.08698"}, {"metadata": {"arXiv": "2307.07911", "Date": "Sun, 16 Jul 2023 00:43:54 ", "Title": "MESOB: Balancing Equilibria & Social Optimality", "Authors": ["Xin Guo", "Lihong Li", "Sareh Nabi", "Rabih Salhab", "Junzi Zhang"], "Categories": "cs.GT cs.LG cs.MA math.OC"}, "abstract": "Motivated by bid recommendation in online ad auctions, this paper considers a general class of multi-level and multi-agent games, with two major characteristics: one is a large number of anonymous agents, and the other is the intricate interplay between competition and cooperation. To model such complex systems, we propose a novel and tractable bi-objective optimization formulation with mean-field approximation, called MESOB (Mean-field Equilibria & Social Optimality Balancing), as well as an associated occupation measure optimization (OMO) method called MESOB-OMO to solve it. MESOB-OMO enables obtaining approximately Pareto efficient solutions in terms of the dual objectives of competition and cooperation in MESOB, and in particular allows for Nash equilibrium selection and social equalization in an asymptotic manner. We apply MESOB-OMO to bid recommendation in a simulated pay-per-click ad auction. Experiments demonstrate its efficacy in balancing the interests of different parties and in handling the competitive nature of bidders, as well as its advantages over baselines that only consider either the competitive or the cooperative aspects.", "url": "https://arxiv.org/abs/2307.07911"}, {"metadata": {"arXiv": "2307.07516", "Date": "Fri, 30 Jun 2023 17:05:11 ", "Title": "Voting-based Multimodal Automatic Deception Detection", "Authors": ["Lana Touma and Mohammad Al Horani and Manar Tailouni and Anas Dahabiah and Khloud Al Jallad"], "Categories": "cs.LG cs.CL cs.CV cs.HC"}, "abstract": "Automatic Deception Detection has been a hot research topic for a long time, using machine learning and deep learning to automatically detect deception, brings new light to this old field. In this paper, we proposed a voting-based method for automatic deception detection from videos using audio, visual and lexical features. Experiments were done on two datasets, the Real-life trial dataset by Michigan University and the Miami University deception detection dataset. Video samples were split into frames of images, audio, and manuscripts. Our Voting-based Multimodal proposed solution consists of three models. The first model is CNN for detecting deception from images, the second model is Support Vector Machine (SVM) on Mel spectrograms for detecting deception from audio and the third model is Word2Vec on Support Vector Machine (SVM) for detecting deception from manuscripts. Our proposed solution outperforms state of the art. Best results achieved on images, audio and text were 97%, 96%, 92% respectively on Real-Life Trial Dataset, and 97%, 82%, 73% on video, audio and text respectively on Miami University Deception Detection.", "url": "https://arxiv.org/abs/2307.07516"}, {"metadata": {"arXiv": "2307.07539", "Date": "Fri, 14 Jul 2023 13:56:11 ", "Title": "Improved Self-Normalized Concentration in Hilbert Spaces: Sublinear Regret for GP-UCB", "Authors": ["Justin Whitehouse", "Zhiwei Steven Wu", "Aaditya Ramdas"], "Categories": "cs.LG math.ST stat.ML stat.TH", "Comments": ["19 pages", "0 figures"]}, "abstract": "In the kernelized bandit problem, a learner aims to sequentially compute the optimum of a function lying in a reproducing kernel Hilbert space given only noisy evaluations at sequentially chosen points. In particular, the learner aims to minimize regret, which is a measure of the suboptimality of the choices made. Arguably the most popular algorithm is the Gaussian Process Upper Confidence Bound (GP-UCB) algorithm, which involves acting based on a simple linear estimator of the unknown function. Despite its popularity, existing analyses of GP-UCB give a suboptimal regret rate, which fails to be sublinear for many commonly used kernels such as the Mat\\'ern kernel. This has led to a longstanding open question: are existing regret analyses for GP-UCB tight, or can bounds be improved by using more sophisticated analytical techniques? In this work, we resolve this open question and show that GP-UCB enjoys nearly optimal regret. In particular, our results directly imply sublinear regret rates for the Mat\\'ern kernel, improving over the state-of-the-art analyses and partially resolving a COLT open problem posed by Vakili et al. Our improvements rely on two key technical results. First, we use modern supermartingale techniques to construct a novel, self-normalized concentration inequality that greatly simplifies existing approaches. Second, we address the importance of regularizing in proportion to the smoothness of the underlying kernel $k$. Together, these new technical tools enable a simplified, tighter analysis of the GP-UCB algorithm.", "url": "https://arxiv.org/abs/2307.07539"}, {"metadata": {"arXiv": "2307.07568", "Date": "Fri, 14 Jul 2023 18:19:31 ", "Title": "Variational Prediction", "Authors": ["Alexander A. Alemi and Ben Poole"], "Categories": "cs.LG stat.ML", "Comments": ["AABI2023"]}, "abstract": "Bayesian inference offers benefits over maximum likelihood, but it also comes with computational costs. Computing the posterior is typically intractable, as is marginalizing that posterior to form the posterior predictive distribution. In this paper, we present variational prediction, a technique for directly learning a variational approximation to the posterior predictive distribution using a variational bound. This approach can provide good predictive distributions without test time marginalization costs. We demonstrate Variational Prediction on an illustrative toy example.", "url": "https://arxiv.org/abs/2307.07568"}, {"metadata": {"arXiv": "2307.07575", "Date": "Fri, 14 Jul 2023 18:39:04 ", "Title": "A Quantitative Approach to Predicting Representational Learning and Performance in Neural Networks", "Authors": ["Ryan Pyle", "Sebastian Musslick", "Jonathan D. Cohen", "and Ankit B. Patel"], "Categories": "cs.LG cs.NE", "Comments": ["30 pages", "16 figures"]}, "abstract": "A key property of neural networks (both biological and artificial) is how they learn to represent and manipulate input information in order to solve a task. Different types of representations may be suited to different types of tasks, making identifying and understanding learned representations a critical part of understanding and designing useful networks. In this paper, we introduce a new pseudo-kernel based tool for analyzing and predicting learned representations, based only on the initial conditions of the network and the training curriculum. We validate the method on a simple test case, before demonstrating its use on a question about the effects of representational learning on sequential single versus concurrent multitask performance. We show that our method can be used to predict the effects of the scale of weight initialization and training curriculum on representational learning and downstream concurrent multitasking performance.", "url": "https://arxiv.org/abs/2307.07575"}, {"metadata": {"arXiv": "2307.07614", "Date": "Fri, 14 Jul 2023 20:21:50 ", "Title": "Towards Generalizable Detection of Urgency of Discussion Forum Posts", "Authors": ["Valdemar \\v{S}v\\'abensk\\'y", "Ryan S. Baker", "Andr\\'es Zambrano", "Yishan Zou", "Stefan Slater"], "Categories": "cs.LG cs.CL", "Comments": ["Published in EDM 2023 conference proceedings", "see https://educationaldatamining.org/EDM2023/proceedings/2023.EDM-short-papers.29/2023.EDM-short-papers.29.pdf"], "DOI": "10.5281/zenodo.8115790"}, "abstract": "Students who take an online course, such as a MOOC, use the course's discussion forum to ask questions or reach out to instructors when encountering an issue. However, reading and responding to students' questions is difficult to scale because of the time needed to consider each message. As a result, critical issues may be left unresolved, and students may lose the motivation to continue in the course. To help address this problem, we build predictive models that automatically determine the urgency of each forum post, so that these posts can be brought to instructors' attention. This paper goes beyond previous work by predicting not just a binary decision cut-off but a post's level of urgency on a 7-point scale. First, we train and cross-validate several models on an original data set of 3,503 posts from MOOCs at University of Pennsylvania. Second, to determine the generalizability of our models, we test their performance on a separate, previously published data set of 29,604 posts from MOOCs at Stanford University. While the previous work on post urgency used only one data set, we evaluated the prediction across different data sets and courses. The best-performing model was a support vector regressor trained on the Universal Sentence Encoder embeddings of the posts, achieving an RMSE of 1.1 on the training set and 1.4 on the test set. Understanding the urgency of forum posts enables instructors to focus their time more effectively and, as a result, better support student learning.", "url": "https://arxiv.org/abs/2307.07614"}, {"metadata": {"arXiv": "2307.07615", "Date": "Fri, 14 Jul 2023 20:22:21 ", "Title": "Efficiently Factorizing Boolean Matrices using Proximal Gradient Descent", "Authors": ["Sebastian Dalleiger", "Jilles Vreeken"], "Categories": "cs.LG stat.ML", "Comments": ["Accepted at NeurIPS 2022"]}, "abstract": "Addressing the interpretability problem of NMF on Boolean data, Boolean Matrix Factorization (BMF) uses Boolean algebra to decompose the input into low-rank Boolean factor matrices. These matrices are highly interpretable and very useful in practice, but they come at the high computational cost of solving an NP-hard combinatorial optimization problem. To reduce the computational burden, we propose to relax BMF continuously using a novel elastic-binary regularizer, from which we derive a proximal gradient algorithm. Through an extensive set of experiments, we demonstrate that our method works well in practice: On synthetic data, we show that it converges quickly, recovers the ground truth precisely, and estimates the simulated rank exactly. On real-world data, we improve upon the state of the art in recall, loss, and runtime, and a case study from the medical domain confirms that our results are easily interpretable and semantically meaningful.", "url": "https://arxiv.org/abs/2307.07615"}, {"metadata": {"arXiv": "2307.07620", "Date": "Fri, 14 Jul 2023 20:39:07 ", "Title": "Generalizable Embeddings with Cross-batch Metric Learning", "Authors": ["Yeti Z. Gurbuz and A. Aydin Alatan"], "Categories": "cs.LG cs.CV", "Comments": ["\\c{opyright} 2023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses", "in any current or future media", "including reprinting/republishing this material for advertising or promotional purposes", "creating new collective works", "for resale or redistribution to servers or lists", "or reuse of any copyrighted component of this work in other works"]}, "abstract": "Global average pooling (GAP) is a popular component in deep metric learning (DML) for aggregating features. Its effectiveness is often attributed to treating each feature vector as a distinct semantic entity and GAP as a combination of them. Albeit substantiated, such an explanation's algorithmic implications to learn generalizable entities to represent unseen classes, a crucial DML goal, remain unclear. To address this, we formulate GAP as a convex combination of learnable prototypes. We then show that the prototype learning can be expressed as a recursive process fitting a linear predictor to a batch of samples. Building on that perspective, we consider two batches of disjoint classes at each iteration and regularize the learning by expressing the samples of a batch with the prototypes that are fitted to the other batch. We validate our approach on 4 popular DML benchmarks.", "url": "https://arxiv.org/abs/2307.07620"}, {"metadata": {"arXiv": "2307.07631", "Date": "Fri, 14 Jul 2023 21:01:59 ", "Title": "Towards Model-Size Agnostic, Compute-Free, Memorization-based Inference of Deep Learning", "Authors": ["Davide Giacomini", "Maeesha Binte Hashem", "Jeremiah Suarez", "Swarup Bhunia", "and Amit Ranjan Trivedi"], "Categories": "cs.LG"}, "abstract": "The rapid advancement of deep neural networks has significantly improved various tasks, such as image and speech recognition. However, as the complexity of these models increases, so does the computational cost and the number of parameters, making it difficult to deploy them on resource-constrained devices. This paper proposes a novel memorization-based inference (MBI) that is compute free and only requires lookups. Specifically, our work capitalizes on the inference mechanism of the recurrent attention model (RAM), where only a small window of input domain (glimpse) is processed in a one time step, and the outputs from multiple glimpses are combined through a hidden vector to determine the overall classification output of the problem. By leveraging the low-dimensionality of glimpse, our inference procedure stores key value pairs comprising of glimpse location, patch vector, etc. in a table. The computations are obviated during inference by utilizing the table to read out key-value pairs and performing compute-free inference by memorization. By exploiting Bayesian optimization and clustering, the necessary lookups are reduced, and accuracy is improved. We also present in-memory computing circuits to quickly look up the matching key vector to an input query. Compared to competitive compute-in-memory (CIM) approaches, MBI improves energy efficiency by almost 2.7 times than multilayer perceptions (MLP)-CIM and by almost 83 times than ResNet20-CIM for MNIST character recognition.", "url": "https://arxiv.org/abs/2307.07631"}, {"metadata": {"arXiv": "2307.07649", "Date": "Fri, 14 Jul 2023 22:52:27 ", "Title": "DistTGL: Distributed Memory-Based Temporal Graph Neural Network Training", "Authors": ["Hongkuan Zhou", "Da Zheng", "Xiang Song", "George Karypis", "Viktor Prasanna"], "Categories": "cs.LG", "Comments": ["SC'23"]}, "abstract": "Memory-based Temporal Graph Neural Networks are powerful tools in dynamic graph representation learning and have demonstrated superior performance in many real-world applications. However, their node memory favors smaller batch sizes to capture more dependencies in graph events and needs to be maintained synchronously across all trainers. As a result, existing frameworks suffer from accuracy loss when scaling to multiple GPUs. Evenworse, the tremendous overhead to synchronize the node memory make it impractical to be deployed to distributed GPU clusters. In this work, we propose DistTGL -- an efficient and scalable solution to train memory-based TGNNs on distributed GPU clusters. DistTGL has three improvements over existing solutions: an enhanced TGNN model, a novel training algorithm, and an optimized system. In experiments, DistTGL achieves near-linear convergence speedup, outperforming state-of-the-art single-machine method by 14.5% in accuracy and 10.17x in training throughput.", "url": "https://arxiv.org/abs/2307.07649"}, {"metadata": {"arXiv": "2307.07652", "Date": "Fri, 14 Jul 2023 22:58:20 ", "Title": "DIGEST: Fast and Communication Efficient Decentralized Learning with Local Updates", "Authors": ["Peyman Gholami", "Hulya Seferoglu"], "Categories": "cs.LG cs.DC"}, "abstract": "Two widely considered decentralized learning algorithms are Gossip and random walk-based learning. Gossip algorithms (both synchronous and asynchronous versions) suffer from high communication cost, while random-walk based learning experiences increased convergence time. In this paper, we design a fast and communication-efficient asynchronous decentralized learning mechanism DIGEST by taking advantage of both Gossip and random-walk ideas, and focusing on stochastic gradient descent (SGD). DIGEST is an asynchronous decentralized algorithm building on local-SGD algorithms, which are originally designed for communication efficient centralized learning. We design both single-stream and multi-stream DIGEST, where the communication overhead may increase when the number of streams increases, and there is a convergence and communication overhead trade-off which can be leveraged. We analyze the convergence of single- and multi-stream DIGEST, and prove that both algorithms approach to the optimal solution asymptotically for both iid and non-iid data distributions. We evaluate the performance of single- and multi-stream DIGEST for logistic regression and a deep neural network ResNet20. The simulation results confirm that multi-stream DIGEST has nice convergence properties; i.e., its convergence time is better than or comparable to the baselines in iid setting, and outperforms the baselines in non-iid setting.", "url": "https://arxiv.org/abs/2307.07652"}, {"metadata": {"arXiv": "2307.07674", "Date": "Sat, 15 Jul 2023 01:17:14 ", "Title": "An Empirical Study of the Effectiveness of Using a Replay Buffer on Mode Discovery in GFlowNets", "Authors": ["Nikhil Vemgal", "Elaine Lau", "Doina Precup"], "Categories": "cs.LG", "Comments": ["Accepted to ICML 2023 workshop on Structured Probabilistic Inference \\& Generative Modeling"]}, "abstract": "Reinforcement Learning (RL) algorithms aim to learn an optimal policy by iteratively sampling actions to learn how to maximize the total expected return, $R(x)$. GFlowNets are a special class of algorithms designed to generate diverse candidates, $x$, from a discrete set, by learning a policy that approximates the proportional sampling of $R(x)$. GFlowNets exhibit improved mode discovery compared to conventional RL algorithms, which is very useful for applications such as drug discovery and combinatorial search. However, since GFlowNets are a relatively recent class of algorithms, many techniques which are useful in RL have not yet been associated with them. In this paper, we study the utilization of a replay buffer for GFlowNets. We explore empirically various replay buffer sampling techniques and assess the impact on the speed of mode discovery and the quality of the modes discovered. Our experimental results in the Hypergrid toy domain and a molecule synthesis environment demonstrate significant improvements in mode discovery when training with a replay buffer, compared to training only with trajectories generated on-policy.", "url": "https://arxiv.org/abs/2307.07674"}, {"metadata": {"arXiv": "2307.07675", "Date": "Sat, 15 Jul 2023 01:20:31 ", "Title": "On the Robustness of Epoch-Greedy in Multi-Agent Contextual Bandit Mechanisms", "Authors": ["Yinglun Xu", "Bhuvesh Kumar", "Jacob Abernethy"], "Categories": "cs.LG cs.IR stat.ML"}, "abstract": "Efficient learning in multi-armed bandit mechanisms such as pay-per-click (PPC) auctions typically involves three challenges: 1) inducing truthful bidding behavior (incentives), 2) using personalization in the users (context), and 3) circumventing manipulations in click patterns (corruptions). Each of these challenges has been studied orthogonally in the literature; incentives have been addressed by a line of work on truthful multi-armed bandit mechanisms, context has been extensively tackled by contextual bandit algorithms, while corruptions have been discussed via a recent line of work on bandits with adversarial corruptions. Since these challenges co-exist, it is important to understand the robustness of each of these approaches in addressing the other challenges, provide algorithms that can handle all simultaneously, and highlight inherent limitations in this combination. In this work, we show that the most prominent contextual bandit algorithm, $\\epsilon$-greedy can be extended to handle the challenges introduced by strategic arms in the contextual multi-arm bandit mechanism setting. We further show that $\\epsilon$-greedy is inherently robust to adversarial data corruption attacks and achieves performance that degrades linearly with the amount of corruption.", "url": "https://arxiv.org/abs/2307.07675"}, {"metadata": {"arXiv": "2307.07682", "Date": "Sat, 15 Jul 2023 02:11:40 ", "Title": "Learning Subjective Time-Series Data via Utopia Label Distribution Approximation", "Authors": ["Wenxin Xu", "Hexin Jiang", "Xuefeng Liang", "Ying Zhou", "Yin Zhao", "Jie Zhang"], "Categories": "cs.LG", "Comments": ["13 pages"]}, "abstract": "Subjective time-series regression (STR) tasks have gained increasing attention recently. However, most existing methods overlook the label distribution bias in STR data, which results in biased models. Emerging studies on imbalanced regression tasks, such as age estimation and depth estimation, hypothesize that the prior label distribution of the dataset is uniform. However, we observe that the label distributions of training and test sets in STR tasks are likely to be neither uniform nor identical. This distinct feature calls for new approaches that estimate more reasonable distributions to train a fair model. In this work, we propose Utopia Label Distribution Approximation (ULDA) for time-series data, which makes the training label distribution closer to real-world but unknown (utopia) label distribution. This would enhance the model's fairness. Specifically, ULDA first convolves the training label distribution by a Gaussian kernel. After convolution, the required sample quantity at each regression label may change. We further devise the Time-slice Normal Sampling (TNS) to generate new samples when the required sample quantity is greater than the initial sample quantity, and the Convolutional Weighted Loss (CWL) to lower the sample weight when the required sample quantity is less than the initial quantity. These two modules not only assist the model training on the approximated utopia label distribution, but also maintain the sample continuity in temporal context space. To the best of our knowledge, ULDA is the first method to address the label distribution bias in time-series data. Extensive experiments demonstrate that ULDA lifts the state-of-the-art performance on two STR tasks and three benchmark datasets.", "url": "https://arxiv.org/abs/2307.07682"}, {"metadata": {"arXiv": "2307.07703", "Date": "Sat, 15 Jul 2023 04:31:28 ", "Title": "Identification of Stochasticity by Matrix-decomposition: Applied on Black Hole Data", "Authors": ["Sai Pradeep Chakka", "Sunil Kumar Vengalil", "Neelam Sinha"], "Categories": "cs.LG", "Comments": ["10 pages", "7 figures"]}, "abstract": "Timeseries classification as stochastic (noise-like) or non-stochastic (structured), helps understand the underlying dynamics, in several domains. Here we propose a two-legged matrix decomposition-based algorithm utilizing two complementary techniques for classification. In Singular Value Decomposition (SVD) based analysis leg, we perform topological analysis (Betti numbers) on singular vectors containing temporal information, leading to SVD-label. Parallely, temporal-ordering agnostic Principal Component Analysis (PCA) is performed, and the proposed PCA-derived features are computed. These features, extracted from synthetic timeseries of the two labels, are observed to map the timeseries to a linearly separable feature space. Support Vector Machine (SVM) is used to produce PCA-label. The proposed methods have been applied to synthetic data, comprising 41 realisations of white-noise, pink-noise (stochastic), Logistic-map at growth-rate 4 and Lorentz-system (non-stochastic), as proof-of-concept. Proposed algorithm is applied on astronomical data: 12 temporal-classes of timeseries of black hole GRS 1915+105, obtained from RXTE satellite with average length 25000. For a given timeseries, if SVD-label and PCA-label concur, then the label is retained; else deemed \"Uncertain\". Comparison of obtained results with those in literature are presented. It's found that out of 12 temporal classes of GRS 1915+105, concurrence between SVD-label and PCA-label is obtained on 11 of them.", "url": "https://arxiv.org/abs/2307.07703"}, {"metadata": {"arXiv": "2307.07712", "Date": "Sat, 15 Jul 2023 05:13:06 ", "Title": "Visual Analytics For Machine Learning: A Data Perspective Survey", "Authors": ["Junpeng Wang", "Shixia Liu", "Wei Zhang"], "Categories": "cs.LG cs.HC", "Comments": ["20 pages"]}, "abstract": "The past decade has witnessed a plethora of works that leverage the power of visualization (VIS) to interpret machine learning (ML) models. The corresponding research topic, VIS4ML, keeps growing at a fast pace. To better organize the enormous works and shed light on the developing trend of VIS4ML, we provide a systematic review of these works through this survey. Since data quality greatly impacts the performance of ML models, our survey focuses specifically on summarizing VIS4ML works from the data perspective. First, we categorize the common data handled by ML models into five types, explain the unique features of each type, and highlight the corresponding ML models that are good at learning from them. Second, from the large number of VIS4ML works, we tease out six tasks that operate on these types of data (i.e., data-centric tasks) at different stages of the ML pipeline to understand, diagnose, and refine ML models. Lastly, by studying the distribution of 143 surveyed papers across the five data types, six data-centric tasks, and their intersections, we analyze the prospective research directions and envision future research trends.", "url": "https://arxiv.org/abs/2307.07712"}, {"metadata": {"arXiv": "2307.07756", "Date": "Sat, 15 Jul 2023 09:32:34 ", "Title": "Real-time Traffic Classification for 5G NSA Encrypted Data Flows With Physical Channel Records", "Authors": ["Xiao Fei", "Philippe Martins and Jialiang Lu"], "Categories": "cs.LG cs.CR cs.SI", "Comments": ["6 pages", "10 figures"]}, "abstract": "The classification of fifth-generation New-Radio (5G-NR) mobile network traffic is an emerging topic in the field of telecommunications. It can be utilized for quality of service (QoS) management and dynamic resource allocation. However, traditional approaches such as Deep Packet Inspection (DPI) can not be directly applied to encrypted data flows. Therefore, new real-time encrypted traffic classification algorithms need to be investigated to handle dynamic transmission. In this study, we examine the real-time encrypted 5G Non-Standalone (NSA) application-level traffic classification using physical channel records. Due to the vastness of their features, decision-tree-based gradient boosting algorithms are a viable approach for classification. We generate a noise-limited 5G NSA trace dataset with traffic from multiple applications. We develop a new pipeline to convert sequences of physical channel records into numerical vectors. A set of machine learning models are tested, and we propose our solution based on Light Gradient Boosting Machine (LGBM) due to its advantages in fast parallel training and low computational burden in practical scenarios. Our experiments demonstrate that our algorithm can achieve 95% accuracy on the classification task with a state-of-the-art response time as quick as 10ms.", "url": "https://arxiv.org/abs/2307.07756"}, {"metadata": {"arXiv": "2307.07770", "Date": "Sat, 15 Jul 2023 10:51:03 ", "Title": "randomHAR: Improving Ensemble Deep Learners for Human Activity Recognition with Sensor Selection and Reinforcement Learning", "Authors": ["Yiran Huang", "Yexu Zhou", "Till Riedel", "Likun Fang", "Michael Beigl"], "Categories": "cs.LG eess.SP"}, "abstract": "Deep learning has proven to be an effective approach in the field of Human activity recognition (HAR), outperforming other architectures that require manual feature engineering. Despite recent advancements, challenges inherent to HAR data, such as noisy data, intra-class variability and inter-class similarity, remain. To address these challenges, we propose an ensemble method, called randomHAR. The general idea behind randomHAR is training a series of deep learning models with the same architecture on randomly selected sensor data from the given dataset. Besides, an agent is trained with the reinforcement learning algorithm to identify the optimal subset of the trained models that are utilized for runtime prediction. In contrast to existing work, this approach optimizes the ensemble process rather than the architecture of the constituent models. To assess the performance of the approach, we compare it against two HAR algorithms, including the current state of the art, on six HAR benchmark datasets. The result of the experiment demonstrates that the proposed approach outperforms the state-of-the-art method, ensembleLSTM.", "url": "https://arxiv.org/abs/2307.07770"}, {"metadata": {"arXiv": "2307.07771", "Date": "Sat, 15 Jul 2023 10:54:46 ", "Title": "CatBoost Versus XGBoost and LightGBM: Developing Enhanced Predictive Models for Zero-Inflated Insurance Claim Data", "Authors": ["Banghee So"], "Categories": "cs.LG", "Comments": ["26pages", "6tables", "7figures"]}, "abstract": "In the property and casualty insurance industry, some challenges are presented in constructing claim predictive models due to a highly right-skewed distribution of positive claims with excess zeros. Traditional models, such as Poisson or negative binomial Generalized Linear Models(GLMs), frequently struggle with inflated zeros. In response to this, researchers in actuarial science have employed ``zero-inflated\" models that merge a traditional count model and a binary model to address these datasets more effectively. This paper uses boosting algorithms to process insurance claim data, including zero-inflated telematics data, in order to construct claim frequency models. We evaluated and compared three popular gradient boosting libraries - XGBoost, LightGBM, and CatBoost - with the aim of identifying the most suitable library for training insurance claim data and fitting actuarial frequency models. Through a rigorous analysis of two distinct datasets, we demonstrated that CatBoost is superior in developing auto claim frequency models based on predictive performance. We also found that Zero-inflated Poisson boosted tree models, with variations in their assumptions about the relationship between inflation probability and distribution mean, outperformed others depending on data characteristics. Furthermore, by using a specific CatBoost tool, we explored the effects and interactions of different risk features on the frequency model when using telematics data.", "url": "https://arxiv.org/abs/2307.07771"}, {"metadata": {"arXiv": "2307.07810", "Date": "Sat, 15 Jul 2023 14:19:42 ", "Title": "Graph Automorphism Group Equivariant Neural Networks", "Authors": ["Edward Pearce-Crump"], "Categories": "cs.LG math.CO math.RT stat.ML", "Comments": ["25 pages"]}, "abstract": "For any graph $G$ having $n$ vertices and its automorphism group $\\textrm{Aut}(G)$, we provide a full characterisation of all of the possible $\\textrm{Aut}(G)$-equivariant neural networks whose layers are some tensor power of $\\mathbb{R}^{n}$. In particular, we find a spanning set of matrices for the learnable, linear, $\\textrm{Aut}(G)$-equivariant layer functions between such tensor power spaces in the standard basis of $\\mathbb{R}^{n}$.", "url": "https://arxiv.org/abs/2307.07810"}, {"metadata": {"arXiv": "2307.07816", "Date": "Sat, 15 Jul 2023 14:46:43 ", "Title": "Minimal Random Code Learning with Mean-KL Parameterization", "Authors": ["Jihao Andreas Lin", "Gergely Flamich", "Jos\\'e Miguel Hern\\'andez-Lobato"], "Categories": "cs.LG stat.ML", "Comments": ["ICML Neural Compression Workshop 2023"]}, "abstract": "This paper studies the qualitative behavior and robustness of two variants of Minimal Random Code Learning (MIRACLE) used to compress variational Bayesian neural networks. MIRACLE implements a powerful, conditionally Gaussian variational approximation for the weight posterior $Q_{\\mathbf{w}}$ and uses relative entropy coding to compress a weight sample from the posterior using a Gaussian coding distribution $P_{\\mathbf{w}}$. To achieve the desired compression rate, $D_{\\mathrm{KL}}[Q_{\\mathbf{w}} \\Vert P_{\\mathbf{w}}]$ must be constrained, which requires a computationally expensive annealing procedure under the conventional mean-variance (Mean-Var) parameterization for $Q_{\\mathbf{w}}$. Instead, we parameterize $Q_{\\mathbf{w}}$ by its mean and KL divergence from $P_{\\mathbf{w}}$ to constrain the compression cost to the desired value by construction. We demonstrate that variational training with Mean-KL parameterization converges twice as fast and maintains predictive performance after compression. Furthermore, we show that Mean-KL leads to more meaningful variational distributions with heavier tails and compressed weight samples which are more robust to pruning.", "url": "https://arxiv.org/abs/2307.07816"}, {"metadata": {"arXiv": "2307.07843", "Date": "Sat, 15 Jul 2023 16:19:37 ", "Title": "Transformers are Universal Predictors", "Authors": ["Sourya Basu", "Moulik Choraria", "Lav R. Varshney"], "Categories": "cs.LG cs.CL", "Comments": ["Neural Compression Workshop (ICML 2023)"]}, "abstract": "We find limits to the Transformer architecture for language modeling and show it has a universal prediction property in an information-theoretic sense. We further analyze performance in non-asymptotic data regimes to understand the role of various components of the Transformer architecture, especially in the context of data-efficient training. We validate our theoretical analysis with experiments on both synthetic and real datasets.", "url": "https://arxiv.org/abs/2307.07843"}, {"metadata": {"arXiv": "2307.07873", "Date": "Sat, 15 Jul 2023 19:20:49 ", "Title": "Towards Understanding Adversarial Transferability From Surrogate Training", "Authors": ["Yechao Zhang", "Shengshan Hu", "Leo Yu Zhang", "Junyu Shi", "Minghui Li", "Xiaogeng Liu", "Wei Wan", "Hai Jin"], "Categories": "cs.LG cs.CR cs.CV", "Comments": ["Accepted by IEEE S&P (Oakland) 2024; 21 pages", "12 figures"]}, "abstract": "Adversarial examples (AEs) for DNNs have been shown to be transferable: AEs that successfully fool white-box surrogate models can also deceive other black-box models with different architectures. Although a bunch of empirical studies have provided guidance on generating highly transferable AEs, many of these findings lack explanations and even lead to inconsistent advice. In this paper, we take a further step towards understanding adversarial transferability, with a particular focus on surrogate aspects. Starting from the intriguing little robustness phenomenon, where models adversarially trained with mildly perturbed adversarial samples can serve as better surrogates, we attribute it to a trade-off between two predominant factors: model smoothness and gradient similarity. Our investigations focus on their joint effects, rather than their separate correlations with transferability. Through a series of theoretical and empirical analyses, we conjecture that the data distribution shift in adversarial training explains the degradation of gradient similarity. Building on these insights, we explore the impacts of data augmentation and gradient regularization on transferability and identify that the trade-off generally exists in the various training mechanisms, thus building a comprehensive blueprint for the regulation mechanism behind transferability. Finally, we provide a general route for constructing better surrogates to boost transferability which optimizes both model smoothness and gradient similarity simultaneously, e.g., the combination of input gradient regularization and sharpness-aware minimization (SAM), validated by extensive experiments. In summary, we call for attention to the united impacts of these two factors for launching effective transfer attacks, rather than optimizing one while ignoring the other, and emphasize the crucial role of manipulating surrogate models.", "url": "https://arxiv.org/abs/2307.07873"}, {"metadata": {"arXiv": "2307.07881", "Date": "Sat, 15 Jul 2023 20:45:45 ", "Title": "Graph Embedded Intuitionistic Fuzzy RVFL for Class Imbalance Learning", "Authors": ["M.A. Ganaie", "M. Sajid", "A.K. Malik", "M. Tanveer"], "Categories": "cs.LG"}, "abstract": "The domain of machine learning is confronted with a crucial research area known as class imbalance learning, which presents considerable hurdles in the precise classification of minority classes. This issue can result in biased models where the majority class takes precedence in the training process, leading to the underrepresentation of the minority class. The random vector functional link (RVFL) network is a widely-used and effective learning model for classification due to its speed and efficiency. However, it suffers from low accuracy when dealing with imbalanced datasets. To overcome this limitation, we propose a novel graph embedded intuitionistic fuzzy RVFL for class imbalance learning (GE-IFRVFL-CIL) model incorporating a weighting mechanism to handle imbalanced datasets. The proposed GE-IFRVFL-CIL model has a plethora of benefits, such as $(i)$ it leverages graph embedding to extract semantically rich information from the dataset, $(ii)$ it uses intuitionistic fuzzy sets to handle uncertainty and imprecision in the data, $(iii)$ and the most important, it tackles class imbalance learning. The amalgamation of a weighting scheme, graph embedding, and intuitionistic fuzzy sets leads to the superior performance of the proposed model on various benchmark imbalanced datasets, including UCI and KEEL. Furthermore, we implement the proposed GE-IFRVFL-CIL on the ADNI dataset and achieved promising results, demonstrating the model's effectiveness in real-world applications. The proposed method provides a promising solution for handling class imbalance in machine learning and has the potential to be applied to other classification problems.", "url": "https://arxiv.org/abs/2307.07881"}, {"metadata": {"arXiv": "2307.07882", "Date": "Sat, 15 Jul 2023 20:45:50 ", "Title": "Gradient-free training of neural ODEs for system identification and control using ensemble Kalman inversion", "Authors": ["Lucas B\\\"ottcher"], "Categories": "cs.LG cs.NA cs.SY eess.SY math.NA physics.comp-ph", "Comments": ["10 pages", "3 figures", "Workshop on New Frontiers in Learning", "Control", "and Dynamical Systems at the International Conference on Machine Learning (ICML)", "Honolulu", "Hawaii", "USA", "2023"]}, "abstract": "Ensemble Kalman inversion (EKI) is a sequential Monte Carlo method used to solve inverse problems within a Bayesian framework. Unlike backpropagation, EKI is a gradient-free optimization method that only necessitates the evaluation of artificial neural networks in forward passes. In this study, we examine the effectiveness of EKI in training neural ordinary differential equations (neural ODEs) for system identification and control tasks. To apply EKI to optimal control problems, we formulate inverse problems that incorporate a Tikhonov-type regularization term. Our numerical results demonstrate that EKI is an efficient method for training neural ODEs in system identification and optimal control problems, with runtime and quality of solutions that are competitive with commonly used gradient-based optimizers.", "url": "https://arxiv.org/abs/2307.07882"}, {"metadata": {"arXiv": "2307.07907", "Date": "Sat, 15 Jul 2023 23:53:37 ", "Title": "Seeing is not Believing: Robust Reinforcement Learning against Spurious Correlation", "Authors": ["Wenhao Ding", "Laixi Shi", "Yuejie Chi", "Ding Zhao"], "Categories": "cs.LG", "Comments": ["33 pages", "13 figures"]}, "abstract": "Robustness has been extensively studied in reinforcement learning (RL) to handle various forms of uncertainty such as random perturbations, rare events, and malicious attacks. In this work, we consider one critical type of robustness against spurious correlation, where different portions of the state do not have causality but have correlations induced by unobserved confounders. These spurious correlations are ubiquitous in real-world tasks, for instance, a self-driving car usually observes heavy traffic in the daytime and light traffic at night due to unobservable human activity. A model that learns such useless or even harmful correlation could catastrophically fail when the confounder in the test case deviates from the training one. Although motivated, enabling robustness against spurious correlation poses significant challenges since the uncertainty set, shaped by the unobserved confounder and sequential structure of RL, is difficult to characterize and identify. Existing robust algorithms that assume simple and unstructured uncertainty sets are therefore inadequate to address this challenge. To solve this issue, we propose Robust State-Confounded Markov Decision Processes (RSC-MDPs) and theoretically demonstrate its superiority in breaking spurious correlations compared with other robust RL counterparts. We also design an empirical algorithm to learn the robust optimal policy for RSC-MDPs, which outperforms all baselines in eight realistic self-driving and manipulation tasks.", "url": "https://arxiv.org/abs/2307.07907"}, {"metadata": {"arXiv": "2307.07912", "Date": "Sun, 16 Jul 2023 01:10:04 ", "Title": "Predicting mechanical properties of Carbon Nanotube (CNT) images Using Multi-Layer Synthetic Finite Element Model Simulations", "Authors": ["Kaveh Safavigerdini", "Koundinya Nouduri", "Ramakrishna Surya", "Andrew Reinhard", "Zach Quinlan", "Filiz Bunyak", "Matthew R. Maschmann", "Kannappan Palaniappan"], "Categories": "cs.LG cond-mat.mtrl-sci cs.CV eess.IV", "Comments": ["6 pages", "7 figures"]}, "abstract": "We present a pipeline for predicting mechanical properties of vertically-oriented carbon nanotube (CNT) forest images using a deep learning model for artificial intelligence (AI)-based materials discovery. Our approach incorporates an innovative data augmentation technique that involves the use of multi-layer synthetic (MLS) or quasi-2.5D images which are generated by blending 2D synthetic images. The MLS images more closely resemble 3D synthetic and real scanning electron microscopy (SEM) images of CNTs but without the computational cost of performing expensive 3D simulations or experiments. Mechanical properties such as stiffness and buckling load for the MLS images are estimated using a physics-based model. The proposed deep learning architecture, CNTNeXt, builds upon our previous CNTNet neural network, using a ResNeXt feature representation followed by random forest regression estimator. Our machine learning approach for predicting CNT physical properties by utilizing a blended set of synthetic images is expected to outperform single synthetic image-based learning when it comes to predicting mechanical properties of real scanning electron microscopy images. This has the potential to accelerate understanding and control of CNT forest self-assembly for diverse applications.", "url": "https://arxiv.org/abs/2307.07912"}, {"metadata": {"arXiv": "2307.07916", "Date": "Sun, 16 Jul 2023 01:45:00 ", "Title": "On the Robustness of Split Learning against Adversarial Attacks", "Authors": ["Mingyuan Fan", "Cen Chen", "Chengyu Wang", "Wenmeng Zhou", "Jun Huang"], "Categories": "cs.LG cs.CR cs.CV", "Comments": ["accepted by ECAI 2023"]}, "abstract": "Split learning enables collaborative deep learning model training while preserving data privacy and model security by avoiding direct sharing of raw data and model details (i.e., sever and clients only hold partial sub-networks and exchange intermediate computations). However, existing research has mainly focused on examining its reliability for privacy protection, with little investigation into model security. Specifically, by exploring full models, attackers can launch adversarial attacks, and split learning can mitigate this severe threat by only disclosing part of models to untrusted servers.This paper aims to evaluate the robustness of split learning against adversarial attacks, particularly in the most challenging setting where untrusted servers only have access to the intermediate layers of the model.Existing adversarial attacks mostly focus on the centralized setting instead of the collaborative setting, thus, to better evaluate the robustness of split learning, we develop a tailored attack called SPADV, which comprises two stages: 1) shadow model training that addresses the issue of lacking part of the model and 2) local adversarial attack that produces adversarial examples to evaluate.The first stage only requires a few unlabeled non-IID data, and, in the second stage, SPADV perturbs the intermediate output of natural samples to craft the adversarial ones. The overall cost of the proposed attack process is relatively low, yet the empirical attack effectiveness is significantly high, demonstrating the surprising vulnerability of split learning to adversarial attacks.", "url": "https://arxiv.org/abs/2307.07916"}, {"metadata": {"arXiv": "2307.07963", "Date": "Sun, 16 Jul 2023 06:47:54 ", "Title": "Enhancing Energy Efficiency and Reliability in Autonomous Systems Estimation using Neuromorphic Approach", "Authors": ["Reza Ahmadvand", "Sarah Safura Sharif", "Yaser Mike Banad"], "Categories": "cs.LG cs.NE", "Comments": ["10 pages", "14 figures"]}, "abstract": "Energy efficiency and reliability have long been crucial factors for ensuring cost-effective and safe missions in autonomous systems computers. With the rapid evolution of industries such as space robotics and advanced air mobility, the demand for these low size, weight, and power (SWaP) computers has grown significantly. This study focuses on introducing an estimation framework based on spike coding theories and spiking neural networks (SNN), leveraging the efficiency and scalability of neuromorphic computers. Therefore, we propose an SNN-based Kalman filter (KF), a fundamental and widely adopted optimal strategy for well-defined linear systems. Furthermore, based on the modified sliding innovation filter (MSIF) we present a robust strategy called SNN-MSIF. Notably, the weight matrices of the networks are designed according to the system model, eliminating the need for learning. To evaluate the effectiveness of the proposed strategies, we compare them to their algorithmic counterparts, namely the KF and the MSIF, using Monte Carlo simulations. Additionally, we assess the robustness of SNN-MSIF by comparing it to SNN-KF in the presence of modeling uncertainties and neuron loss. Our results demonstrate the applicability of the proposed methods and highlight the superior performance of SNN-MSIF in terms of accuracy and robustness. Furthermore, the spiking pattern observed from the networks serves as evidence of the energy efficiency achieved by the proposed methods, as they exhibited an impressive reduction of approximately 97 percent in emitted spikes compared to possible spikes.", "url": "https://arxiv.org/abs/2307.07963"}, {"metadata": {"arXiv": "2307.07973", "Date": "Sun, 16 Jul 2023 07:53:16 ", "Title": "Heteroscedastic Causal Structure Learning", "Authors": ["Bao Duong and Thin Nguyen"], "Categories": "cs.LG stat.ME", "Comments": ["Accepted at the 26th European Conference on Artificial Intelligence (ECAI 2023)"]}, "abstract": "Heretofore, learning the directed acyclic graphs (DAGs) that encode the cause-effect relationships embedded in observational data is a computationally challenging problem. A recent trend of studies has shown that it is possible to recover the DAGs with polynomial time complexity under the equal variances assumption. However, this prohibits the heteroscedasticity of the noise, which allows for more flexible modeling capabilities, but at the same time is substantially more challenging to handle. In this study, we tackle the heteroscedastic causal structure learning problem under Gaussian noises. By exploiting the normality of the causal mechanisms, we can recover a valid causal ordering, which can uniquely identify the causal DAG using a series of conditional independence tests. The result is HOST (Heteroscedastic causal STructure learning), a simple yet effective causal structure learning algorithm that scales polynomially in both sample size and dimensionality. In addition, via extensive empirical evaluations on a wide range of both controlled and real datasets, we show that the proposed HOST method is competitive with state-of-the-art approaches in both the causal order learning and structure learning problems.", "url": "https://arxiv.org/abs/2307.07973"}, {"metadata": {"arXiv": "2307.07980", "Date": "Sun, 16 Jul 2023 08:46:46 ", "Title": "Byzantine-Robust Distributed Online Learning: Taming Adversarial Participants in An Adversarial Environment", "Authors": ["Xingrong Dong", "Zhaoxian Wu", "Qing Ling", "Zhi Tian"], "Categories": "cs.LG cs.DC"}, "abstract": "This paper studies distributed online learning under Byzantine attacks. The performance of an online learning algorithm is often characterized by (adversarial) regret, which evaluates the quality of one-step-ahead decision-making when an environment provides adversarial losses, and a sublinear bound is preferred. But we prove that, even with a class of state-of-the-art robust aggregation rules, in an adversarial environment and in the presence of Byzantine participants, distributed online gradient descent can only achieve a linear adversarial regret bound, which is tight. This is the inevitable consequence of Byzantine attacks, even though we can control the constant of the linear adversarial regret to a reasonable level. Interestingly, when the environment is not fully adversarial so that the losses of the honest participants are i.i.d. (independent and identically distributed), we show that sublinear stochastic regret, in contrast to the aforementioned adversarial regret, is possible. We develop a Byzantine-robust distributed online momentum algorithm to attain such a sublinear stochastic regret bound. Extensive numerical experiments corroborate our theoretical analysis.", "url": "https://arxiv.org/abs/2307.07980"}, {"metadata": {"arXiv": "2307.07982", "Date": "Sun, 16 Jul 2023 08:50:50 ", "Title": "A Survey of Techniques for Optimizing Transformer Inference", "Authors": ["Krishna Teja Chitty-Venkata", "Sparsh Mittal", "Murali Emani", "Venkatram Vishwanath", "Arun K. Somani"], "Categories": "cs.LG cs.AR cs.CL cs.CV"}, "abstract": "Recent years have seen a phenomenal rise in performance and applications of transformer neural networks. The family of transformer networks, including Bidirectional Encoder Representations from Transformer (BERT), Generative Pretrained Transformer (GPT) and Vision Transformer (ViT), have shown their effectiveness across Natural Language Processing (NLP) and Computer Vision (CV) domains. Transformer-based networks such as ChatGPT have impacted the lives of common men. However, the quest for high predictive performance has led to an exponential increase in transformers' memory and compute footprint. Researchers have proposed techniques to optimize transformer inference at all levels of abstraction. This paper presents a comprehensive survey of techniques for optimizing the inference phase of transformer networks. We survey techniques such as knowledge distillation, pruning, quantization, neural architecture search and lightweight network design at the algorithmic level. We further review hardware-level optimization techniques and the design of novel hardware accelerators for transformers. We summarize the quantitative results on the number of parameters/FLOPs and accuracy of several models/techniques to showcase the tradeoff exercised by them. We also outline future directions in this rapidly evolving field of research. We believe that this survey will educate both novice and seasoned researchers and also spark a plethora of research efforts in this field.", "url": "https://arxiv.org/abs/2307.07982"}, {"metadata": {"arXiv": "2307.08013", "Date": "Sun, 16 Jul 2023 11:45:35 ", "Title": "Revisiting Implicit Models: Sparsity Trade-offs Capability in Weight-tied Model for Vision Tasks", "Authors": ["Haobo Song", "Soumajit Majumder", "Tao Lin"], "Categories": "cs.LG cs.CV"}, "abstract": "Implicit models such as Deep Equilibrium Models (DEQs) have garnered significant attention in the community for their ability to train infinite layer models with elegant solution-finding procedures and constant memory footprint. However, despite several attempts, these methods are heavily constrained by model inefficiency and optimization instability. Furthermore, fair benchmarking across relevant methods for vision tasks is missing. In this work, we revisit the line of implicit models and trace them back to the original weight-tied models. Surprisingly, we observe that weight-tied models are more effective, stable, as well as efficient on vision tasks, compared to the DEQ variants. Through the lens of these simple-yet-clean weight-tied models, we further study the fundamental limits in the model capacity of such models and propose the use of distinct sparse masks to improve the model capacity. Finally, for practitioners, we offer design guidelines regarding the depth, width, and sparsity selection for weight-tied models, and demonstrate the generalizability of our insights to other learning paradigms.", "url": "https://arxiv.org/abs/2307.08013"}, {"metadata": {"arXiv": "2307.08033", "Date": "Sun, 16 Jul 2023 13:04:40 ", "Title": "Magnetic Field-Based Reward Shaping for Goal-Conditioned Reinforcement Learning", "Authors": ["Hongyu Ding", "Yuanze Tang", "Qing Wu", "Bo Wang", "Chunlin Chen", "Zhi Wang"], "Categories": "cs.LG", "Comments": ["Accepted by IEEE-CAA Journal of Automatica Sinica", "2023", "DOI: 10.1109/JAS.2023.123477"], "DOI": "10.1109/JAS.2023.123477"}, "abstract": "Goal-conditioned reinforcement learning (RL) is an interesting extension of the traditional RL framework, where the dynamic environment and reward sparsity can cause conventional learning algorithms to fail. Reward shaping is a practical approach to improving sample efficiency by embedding human domain knowledge into the learning process. Existing reward shaping methods for goal-conditioned RL are typically built on distance metrics with a linear and isotropic distribution, which may fail to provide sufficient information about the ever-changing environment with high complexity. This paper proposes a novel magnetic field-based reward shaping (MFRS) method for goal-conditioned RL tasks with dynamic target and obstacles. Inspired by the physical properties of magnets, we consider the target and obstacles as permanent magnets and establish the reward function according to the intensity values of the magnetic field generated by these magnets. The nonlinear and anisotropic distribution of the magnetic field intensity can provide more accessible and conducive information about the optimization landscape, thus introducing a more sophisticated magnetic reward compared to the distance-based setting. Further, we transform our magnetic reward to the form of potential-based reward shaping by learning a secondary potential function concurrently to ensure the optimal policy invariance of our method. Experiments results in both simulated and real-world robotic manipulation tasks demonstrate that MFRS outperforms relevant existing methods and effectively improves the sample efficiency of RL algorithms in goal-conditioned tasks with various dynamics of the target and obstacles.", "url": "https://arxiv.org/abs/2307.08033"}, {"metadata": {"arXiv": "2307.08097", "Date": "Sun, 16 Jul 2023 16:43:38 ", "Title": "EasyTPP: Towards Open Benchmarking the Temporal Point Processes", "Authors": ["Siqiao Xue", "Xiaoming Shi", "Zhixuan Chu", "Yan Wang", "Fan Zhou", "Hongyan Hao", "Caigao Jiang", "Chen Pan", "Yi Xu", "James Y. Zhang", "Qingsong Wen", "Jun Zhou", "Hongyuan Mei"], "Categories": "cs.LG"}, "abstract": "Continuous-time event sequences play a vital role in real-world domains such as healthcare, finance, online shopping, social networks, and so on. To model such data, temporal point processes (TPPs) have emerged as the most advanced generative models, making a significant impact in both academic and application communities. Despite the emergence of many powerful models in recent years, there is still no comprehensive benchmark to evaluate them. This lack of standardization impedes researchers and practitioners from comparing methods and reproducing results, potentially slowing down progress in this field. In this paper, we present EasyTPP, which aims to establish a central benchmark for evaluating TPPs. Compared to previous work that also contributed datasets, our EasyTPP has three unique contributions to the community: (i) a comprehensive implementation of eight highly cited neural TPPs with the integration of commonly used evaluation metrics and datasets; (ii) a standardized benchmarking pipeline for a transparent and thorough comparison of different methods on different datasets; (iii) a universal framework supporting multiple ML libraries (e.g., PyTorch and TensorFlow) as well as custom implementations. Our benchmark is open-sourced: all the data and implementation can be found at this \\href{https://github.com/ant-research/EasyTemporalPointProcess}{\\textcolor{blue}{Github repository}}\\footnote{\\url{https://github.com/ant-research/EasyTemporalPointProcess}.}. We will actively maintain this benchmark and welcome contributions from other researchers and practitioners. Our benchmark will help promote reproducible research in this field, thus accelerating research progress as well as making more significant real-world impacts.", "url": "https://arxiv.org/abs/2307.08097"}, {"metadata": {"arXiv": "2307.08104", "Date": "Sun, 16 Jul 2023 17:12:45 ", "Title": "Using Decision Trees for Interpretable Supervised Clustering", "Authors": ["Natallia Kokash and Leonid Makhnist"], "Categories": "cs.LG"}, "abstract": "In this paper, we address an issue of finding explainable clusters of class-uniform data in labelled datasets. The issue falls into the domain of interpretable supervised clustering. Unlike traditional clustering, supervised clustering aims at forming clusters of labelled data with high probability densities. We are particularly interested in finding clusters of data of a given class and describing the clusters with the set of comprehensive rules. We propose an iterative method to extract high-density clusters with the help of decisiontree-based classifiers as the most intuitive learning method, and discuss the method of node selection to maximize quality of identified groups.", "url": "https://arxiv.org/abs/2307.08104"}, {"metadata": {"arXiv": "2307.08107", "Date": "Sun, 16 Jul 2023 17:16:21 ", "Title": "Discovering a reaction-diffusion model for Alzheimer's disease by combining PINNs with symbolic regression", "Authors": ["Zhen Zhang", "Zongren Zou", "Ellen Kuhl", "George Em Karniadakis"], "Categories": "cs.LG q-bio.QM"}, "abstract": "Misfolded tau proteins play a critical role in the progression and pathology of Alzheimer's disease. Recent studies suggest that the spatio-temporal pattern of misfolded tau follows a reaction-diffusion type equation. However, the precise mathematical model and parameters that characterize the progression of misfolded protein across the brain remain incompletely understood. Here, we use deep learning and artificial intelligence to discover a mathematical model for the progression of Alzheimer's disease using longitudinal tau positron emission tomography from the Alzheimer's Disease Neuroimaging Initiative database. Specifically, we integrate physics informed neural networks (PINNs) and symbolic regression to discover a reaction-diffusion type partial differential equation for tau protein misfolding and spreading. First, we demonstrate the potential of our model and parameter discovery on synthetic data. Then, we apply our method to discover the best model and parameters to explain tau imaging data from 46 individuals who are likely to develop Alzheimer's disease and 30 healthy controls. Our symbolic regression discovers different misfolding models $f(c)$ for two groups, with a faster misfolding for the Alzheimer's group, $f(c) = 0.23c^3 - 1.34c^2 + 1.11c$, than for the healthy control group, $f(c) = -c^3 +0.62c^2 + 0.39c$. Our results suggest that PINNs, supplemented by symbolic regression, can discover a reaction-diffusion type model to explain misfolded tau protein concentrations in Alzheimer's disease. We expect our study to be the starting point for a more holistic analysis to provide image-based technologies for early diagnosis, and ideally early treatment of neurodegeneration in Alzheimer's disease and possibly other misfolding-protein based neurodegenerative disorders.", "url": "https://arxiv.org/abs/2307.08107"}, {"metadata": {"arXiv": "2307.08114", "Date": "Sun, 16 Jul 2023 17:45:33 ", "Title": "Tangent Model Composition for Ensembling and Continual Fine-tuning", "Authors": ["Tian Yu Liu and Stefano Soatto"], "Categories": "cs.LG"}, "abstract": "Tangent Model Composition (TMC) is a method to combine component models independently fine-tuned around a pre-trained point. Component models are tangent vectors to the pre-trained model that can be added, scaled, or subtracted to support incremental learning, ensembling, or unlearning. Component models are composed at inference time via scalar combination, reducing the cost of ensembling to that of a single model. TMC improves accuracy by 4.2% compared to ensembling non-linearly fine-tuned models at a 2.5x to 10x reduction of inference cost, growing linearly with the number of component models. Each component model can be forgotten at zero cost, with no residual effect on the resulting inference. When used for continual fine-tuning, TMC is not constrained by sequential bias and can be executed in parallel on federated data. TMC outperforms recently published continual fine-tuning methods almost uniformly on each setting -- task-incremental, class-incremental, and data-incremental -- on a total of 13 experiments across 3 benchmark datasets, despite not using any replay buffer. TMC is designed for composing models that are local to a pre-trained embedding, but could be extended to more general settings.", "url": "https://arxiv.org/abs/2307.08114"}, {"metadata": {"arXiv": "2307.08122", "Date": "Sun, 16 Jul 2023 18:31:25 ", "Title": "Tangent Transformers for Composition, Privacy and Removal", "Authors": ["Tian Yu Liu", "Aditya Golatkar and Stefano Soatto"], "Categories": "cs.LG"}, "abstract": "We introduce Tangent Attention Fine-Tuning (TAFT), a method for fine-tuning linearized transformers obtained by computing a First-order Taylor Expansion around a pre-trained initialization. We show that the Jacobian-Vector Product resulting from linearization can be computed efficiently in a single forward pass, reducing training and inference cost to the same order of magnitude as its original non-linear counterpart, while using the same number of parameters. Furthermore, we show that, when applied to various downstream visual classification tasks, the resulting Tangent Transformer fine-tuned with TAFT can perform comparably with fine-tuning the original non-linear network. Since Tangent Transformers are linear with respect to the new set of weights, and the resulting fine-tuning loss is convex, we show that TAFT enjoys several advantages compared to non-linear fine-tuning when it comes to model composition, parallel training, machine unlearning, and differential privacy.", "url": "https://arxiv.org/abs/2307.08122"}, {"metadata": {"arXiv": "2307.08168", "Date": "Sun, 16 Jul 2023 22:36:36 ", "Title": "Feedback is All You Need: Real-World Reinforcement Learning with Approximate Physics-Based Models", "Authors": ["Tyler Westenbroek", "Jacob Levy", "David Fridovich-Keil"], "Categories": "cs.LG cs.RO"}, "abstract": "We focus on developing efficient and reliable policy optimization strategies for robot learning with real-world data. In recent years, policy gradient methods have emerged as a promising paradigm for training control policies in simulation. However, these approaches often remain too data inefficient or unreliable to train on real robotic hardware. In this paper we introduce a novel policy gradient-based policy optimization framework which systematically leverages a (possibly highly simplified) first-principles model and enables learning precise control policies with limited amounts of real-world data. Our approach $1)$ uses the derivatives of the model to produce sample-efficient estimates of the policy gradient and $2)$ uses the model to design a low-level tracking controller, which is embedded in the policy class. Theoretical analysis provides insight into how the presence of this feedback controller addresses overcomes key limitations of stand-alone policy gradient methods, while hardware experiments with a small car and quadruped demonstrate that our approach can learn precise control strategies reliably and with only minutes of real-world data.", "url": "https://arxiv.org/abs/2307.08168"}, {"metadata": {"arXiv": "2307.08169", "Date": "Sun, 16 Jul 2023 22:41:17 ", "Title": "Discovering User Types: Mapping User Traits by Task-Specific Behaviors in Reinforcement Learning", "Authors": ["L. L. Ankile", "B. S. Ham", "K. Mao", "E. Shin", "S. Swaroop", "F. Doshi-Velez", "W. Pan"], "Categories": "cs.LG cs.HC"}, "abstract": "When assisting human users in reinforcement learning (RL), we can represent users as RL agents and study key parameters, called \\emph{user traits}, to inform intervention design. We study the relationship between user behaviors (policy classes) and user traits. Given an environment, we introduce an intuitive tool for studying the breakdown of \"user types\": broad sets of traits that result in the same behavior. We show that seemingly different real-world environments admit the same set of user types and formalize this observation as an equivalence relation defined on environments. By transferring intervention design between environments within the same equivalence class, we can help rapidly personalize interventions.", "url": "https://arxiv.org/abs/2307.08169"}, {"metadata": {"arXiv": "2307.08175", "Date": "Mon, 17 Jul 2023 00:07:52 ", "Title": "Multi-Objective Optimization of Performance and Interpretability of Tabular Supervised Machine Learning Models", "Authors": ["Lennart Schneider", "Bernd Bischl", "Janek Thomas"], "Categories": "cs.LG cs.NE stat.ML", "Comments": ["Extended version of the paper accepted at GECCO 2023. 16 pages", "7 tables", "7 figures"]}, "abstract": "We present a model-agnostic framework for jointly optimizing the predictive performance and interpretability of supervised machine learning models for tabular data. Interpretability is quantified via three measures: feature sparsity, interaction sparsity of features, and sparsity of non-monotone feature effects. By treating hyperparameter optimization of a machine learning algorithm as a multi-objective optimization problem, our framework allows for generating diverse models that trade off high performance and ease of interpretability in a single optimization run. Efficient optimization is achieved via augmentation of the search space of the learning algorithm by incorporating feature selection, interaction and monotonicity constraints into the hyperparameter search space. We demonstrate that the optimization problem effectively translates to finding the Pareto optimal set of groups of selected features that are allowed to interact in a model, along with finding their optimal monotonicity constraints and optimal hyperparameters of the learning algorithm itself. We then introduce a novel evolutionary algorithm that can operate efficiently on this augmented search space. In benchmark experiments, we show that our framework is capable of finding diverse models that are highly competitive or outperform state-of-the-art XGBoost or Explainable Boosting Machine models, both with respect to performance and interpretability.", "url": "https://arxiv.org/abs/2307.08175"}, {"metadata": {"arXiv": "2307.08226", "Date": "Mon, 17 Jul 2023 04:01:48 ", "Title": "Can Euclidean Symmetry be Leveraged in Reinforcement Learning and Planning?", "Authors": ["Linfeng Zhao", "Owen Howell", "Jung Yeon Park", "Xupeng Zhu", "Robin Walters", "and Lawson L.S. Wong"], "Categories": "cs.LG cs.RO", "Comments": ["Preprint. Website: http://lfzhao.com/SymCtrl"]}, "abstract": "In robotic tasks, changes in reference frames typically do not influence the underlying physical properties of the system, which has been known as invariance of physical laws.These changes, which preserve distance, encompass isometric transformations such as translations, rotations, and reflections, collectively known as the Euclidean group. In this work, we delve into the design of improved learning algorithms for reinforcement learning and planning tasks that possess Euclidean group symmetry. We put forth a theory on that unify prior work on discrete and continuous symmetry in reinforcement learning, planning, and optimal control. Algorithm side, we further extend the 2D path planning with value-based planning to continuous MDPs and propose a pipeline for constructing equivariant sampling-based planning algorithms. Our work is substantiated with empirical evidence and illustrated through examples that explain the benefits of equivariance to Euclidean symmetry in tackling natural control problems.", "url": "https://arxiv.org/abs/2307.08226"}, {"metadata": {"arXiv": "2307.08232", "Date": "Mon, 17 Jul 2023 04:08:29 ", "Title": "Learning for Counterfactual Fairness from Observational Data", "Authors": ["Jing Ma", "Ruocheng Guo", "Aidong Zhang", "Jundong Li"], "Categories": "cs.LG cs.CY stat.ML", "DOI": "10.1145/3580305.3599408"}, "abstract": "Fairness-aware machine learning has attracted a surge of attention in many domains, such as online advertising, personalized recommendation, and social media analysis in web applications. Fairness-aware machine learning aims to eliminate biases of learning models against certain subgroups described by certain protected (sensitive) attributes such as race, gender, and age. Among many existing fairness notions, counterfactual fairness is a popular notion defined from a causal perspective. It measures the fairness of a predictor by comparing the prediction of each individual in the original world and that in the counterfactual worlds in which the value of the sensitive attribute is modified. A prerequisite for existing methods to achieve counterfactual fairness is the prior human knowledge of the causal model for the data. However, in real-world scenarios, the underlying causal model is often unknown, and acquiring such human knowledge could be very difficult. In these scenarios, it is risky to directly trust the causal models obtained from information sources with unknown reliability and even causal discovery methods, as incorrect causal models can consequently bring biases to the predictor and lead to unfair predictions. In this work, we address the problem of counterfactually fair prediction from observational data without given causal models by proposing a novel framework CLAIRE. Specifically, under certain general assumptions, CLAIRE effectively mitigates the biases from the sensitive attribute with a representation learning framework based on counterfactual data augmentation and an invariant penalty. Experiments conducted on both synthetic and real-world datasets validate the superiority of CLAIRE in both counterfactual fairness and prediction performance.", "url": "https://arxiv.org/abs/2307.08232"}, {"metadata": {"arXiv": "2307.08235", "Date": "Mon, 17 Jul 2023 04:32:45 ", "Title": "HeroLT: Benchmarking Heterogeneous Long-Tailed Learning", "Authors": ["Haohui Wang", "Weijie Guan", "Jianpeng Chen", "Zi Wang", "Dawei Zhou"], "Categories": "cs.LG"}, "abstract": "Long-tailed data distributions are prevalent in a variety of domains, including finance, e-commerce, biomedical science, and cyber security. In such scenarios, the performance of machine learning models is often dominated by the head categories, while the learning of tail categories is significantly inadequate. Given abundant studies conducted to alleviate the issue, this work aims to provide a systematic view of long-tailed learning with regard to three pivotal angles: (A1) the characterization of data long-tailedness, (A2) the data complexity of various domains, and (A3) the heterogeneity of emerging tasks. To achieve this, we develop the most comprehensive (to the best of our knowledge) long-tailed learning benchmark named HeroLT, which integrates 13 state-of-the-art algorithms and 6 evaluation metrics on 14 real-world benchmark datasets across 4 tasks from 3 domains. HeroLT with novel angles and extensive experiments (264 in total) enables researchers and practitioners to effectively and fairly evaluate newly proposed methods compared with existing baselines on varying types of datasets. Finally, we conclude by highlighting the significant applications of long-tailed learning and identifying several promising future directions. For accessibility and reproducibility, we open-source our benchmark HeroLT and corresponding results at https://github.com/SSSKJ/HeroLT.", "url": "https://arxiv.org/abs/2307.08235"}, {"metadata": {"arXiv": "2307.08237", "Date": "Mon, 17 Jul 2023 04:38:51 ", "Title": "A Look into Causal Effects under Entangled Treatment in Graphs: Investigating the Impact of Contact on MRSA Infection", "Authors": ["Jing Ma", "Chen Chen", "Anil Vullikanti", "Ritwick Mishra", "Gregory Madden", "Daniel Borrajo", "Jundong Li"], "Categories": "cs.LG stat.ML", "DOI": "10.1145/3580305.3599763"}, "abstract": "Methicillin-resistant Staphylococcus aureus (MRSA) is a type of bacteria resistant to certain antibiotics, making it difficult to prevent MRSA infections. Among decades of efforts to conquer infectious diseases caused by MRSA, many studies have been proposed to estimate the causal effects of close contact (treatment) on MRSA infection (outcome) from observational data. In this problem, the treatment assignment mechanism plays a key role as it determines the patterns of missing counterfactuals -- the fundamental challenge of causal effect estimation. Most existing observational studies for causal effect learning assume that the treatment is assigned individually for each unit. However, on many occasions, the treatments are pairwisely assigned for units that are connected in graphs, i.e., the treatments of different units are entangled. Neglecting the entangled treatments can impede the causal effect estimation. In this paper, we study the problem of causal effect estimation with treatment entangled in a graph. Despite a few explorations for entangled treatments, this problem still remains challenging due to the following challenges: (1) the entanglement brings difficulties in modeling and leveraging the unknown treatment assignment mechanism; (2) there may exist hidden confounders which lead to confounding biases in causal effect estimation; (3) the observational data is often time-varying. To tackle these challenges, we propose a novel method NEAT, which explicitly leverages the graph structure to model the treatment assignment mechanism, and mitigates confounding biases based on the treatment assignment modeling. We also extend our method into a dynamic setting to handle time-varying observational data. Experiments on both synthetic datasets and a real-world MRSA dataset validate the effectiveness of the proposed method, and provide insights for future applications.", "url": "https://arxiv.org/abs/2307.08237"}, {"metadata": {"arXiv": "2307.08283", "Date": "Mon, 17 Jul 2023 07:12:29 ", "Title": "Complexity Matters: Rethinking the Latent Space for Generative Modeling", "Authors": ["Tianyang Hu", "Fei Chen", "Haonan Wang", "Jiawei Li", "Wenjia Wang", "Jiacheng Sun", "Zhenguo Li"], "Categories": "cs.LG stat.ML", "Comments": ["TL;DR: This work characterizes the optimal latent distribution for generative models from the perspective of minimizing model complexity and proposes a two-stage training scheme that achieves practical improvements on GAN", "VQGAN and DiT"]}, "abstract": "In generative modeling, numerous successful approaches leverage a low-dimensional latent space, e.g., Stable Diffusion models the latent space induced by an encoder and generates images through a paired decoder. Although the selection of the latent space is empirically pivotal, determining the optimal choice and the process of identifying it remain unclear. In this study, we aim to shed light on this under-explored topic by rethinking the latent space from the perspective of model complexity. Our investigation starts with the classic generative adversarial networks (GANs). Inspired by the GAN training objective, we propose a novel \"distance\" between the latent and data distributions, whose minimization coincides with that of the generator complexity. The minimizer of this distance is characterized as the optimal data-dependent latent that most effectively capitalizes on the generator's capacity. Then, we consider parameterizing such a latent distribution by an encoder network and propose a two-stage training strategy called Decoupled Autoencoder (DAE), where the encoder is only updated in the first stage with an auxiliary decoder and then frozen in the second stage while the actual decoder is being trained. DAE can improve the latent distribution and as a result, improve the generative performance. Our theoretical analyses are corroborated by comprehensive experiments on various models such as VQGAN and Diffusion Transformer, where our modifications yield significant improvements in sample quality with decreased model complexity.", "url": "https://arxiv.org/abs/2307.08283"}, {"metadata": {"arXiv": "2307.08302", "Date": "Mon, 17 Jul 2023 07:55:21 ", "Title": "GBT: Two-stage transformer framework for non-stationary time series forecasting", "Authors": ["Li Shen", "Yuning Wei", "Yangzhu Wang"], "Categories": "cs.LG", "Comments": ["Accepted by Neural Networks"]}, "abstract": "This paper shows that time series forecasting Transformer (TSFT) suffers from severe over-fitting problem caused by improper initialization method of unknown decoder inputs, esp. when handling non-stationary time series. Based on this observation, we propose GBT, a novel two-stage Transformer framework with Good Beginning. It decouples the prediction process of TSFT into two stages, including Auto-Regression stage and Self-Regression stage to tackle the problem of different statistical properties between input and prediction sequences.Prediction results of Auto-Regression stage serve as a Good Beginning, i.e., a better initialization for inputs of Self-Regression stage. We also propose Error Score Modification module to further enhance the forecasting capability of the Self-Regression stage in GBT. Extensive experiments on seven benchmark datasets demonstrate that GBT outperforms SOTA TSFTs (FEDformer, Pyraformer, ETSformer, etc.) and many other forecasting models (SCINet, N-HiTS, etc.) with only canonical attention and convolution while owning less time and space complexity. It is also general enough to couple with these models to strengthen their forecasting capability. The source code is available at: https://github.com/OrigamiSL/GBT", "url": "https://arxiv.org/abs/2307.08302"}, {"metadata": {"arXiv": "2307.08324", "Date": "Mon, 17 Jul 2023 08:42:21 ", "Title": "A Secure Aggregation for Federated Learning on Long-Tailed Data", "Authors": ["Yanna Jiang", "Baihe Ma", "Xu Wang", "Guangsheng Yu", "Caijun Sun", "Wei Ni", "Ren Ping Liu"], "Categories": "cs.LG cs.CR"}, "abstract": "As a distributed learning, Federated Learning (FL) faces two challenges: the unbalanced distribution of training data among participants, and the model attack by Byzantine nodes. In this paper, we consider the long-tailed distribution with the presence of Byzantine nodes in the FL scenario. A novel two-layer aggregation method is proposed for the rejection of malicious models and the advisable selection of valuable models containing tail class data information. We introduce the concept of think tank to leverage the wisdom of all participants. Preliminary experiments validate that the think tank can make effective model selections for global aggregation.", "url": "https://arxiv.org/abs/2307.08324"}, {"metadata": {"arXiv": "2307.08336", "Date": "Mon, 17 Jul 2023 09:12:05 ", "Title": "RAYEN: Imposition of Hard Convex Constraints on Neural Networks", "Authors": ["Jesus Tordesillas", "Jonathan P. How", "Marco Hutter"], "Categories": "cs.LG cs.RO"}, "abstract": "This paper presents RAYEN, a framework to impose hard convex constraints on the output or latent variable of a neural network. RAYEN guarantees that, for any input or any weights of the network, the constraints are satisfied at all times. Compared to other approaches, RAYEN does not perform a computationally-expensive orthogonal projection step onto the feasible set, does not rely on soft constraints (which do not guarantee the satisfaction of the constraints at test time), does not use conservative approximations of the feasible set, and does not perform a potentially slow inner gradient descent correction to enforce the constraints. RAYEN supports any combination of linear, convex quadratic, second-order cone (SOC), and linear matrix inequality (LMI) constraints, achieving a very small computational overhead compared to unconstrained networks. For example, it is able to impose 1K quadratic constraints on a 1K-dimensional variable with an overhead of less than 8 ms, and an LMI constraint with 300x300 dense matrices on a 10K-dimensional variable in less than 12 ms. When used in neural networks that approximate the solution of constrained optimization problems, RAYEN achieves computation times between 20 and 7468 times faster than state-of-the-art algorithms, while guaranteeing the satisfaction of the constraints at all times and obtaining a cost very close to the optimal one.", "url": "https://arxiv.org/abs/2307.08336"}, {"metadata": {"arXiv": "2307.08352", "Date": "Mon, 17 Jul 2023 09:43:50 ", "Title": "Zero-th Order Algorithm for Softmax Attention Optimization", "Authors": ["Yichuan Deng", "Zhihang Li", "Sridhar Mahadevan", "Zhao Song"], "Categories": "cs.LG stat.ML"}, "abstract": "Large language models (LLMs) have brought about significant transformations in human society. Among the crucial computations in LLMs, the softmax unit holds great importance. Its helps the model generating a probability distribution on potential subsequent words or phrases, considering a series of input words. By utilizing this distribution, the model selects the most probable next word or phrase, based on the assigned probabilities. The softmax unit assumes a vital function in LLM training as it facilitates learning from data through the adjustment of neural network weights and biases. With the development of the size of LLMs, computing the gradient becomes expensive. However, Zero-th Order method can approximately compute the gradient with only forward passes. In this paper, we present a Zero-th Order algorithm specifically tailored for Softmax optimization. We demonstrate the convergence of our algorithm, highlighting its effectiveness in efficiently computing gradients for large-scale LLMs. By leveraging the Zeroth-Order method, our work contributes to the advancement of optimization techniques in the context of complex language models.", "url": "https://arxiv.org/abs/2307.08352"}, {"metadata": {"arXiv": "2307.08360", "Date": "Mon, 17 Jul 2023 09:55:35 ", "Title": "Universal Online Learning with Gradual Variations: A Multi-layer Online Ensemble Approach", "Authors": ["Yu-Hu Yan", "Peng Zhao", "Zhi-Hua Zhou"], "Categories": "cs.LG math.OC stat.ML"}, "abstract": "In this paper, we propose an online convex optimization method with two different levels of adaptivity. On a higher level, our method is agnostic to the specific type and curvature of the loss functions, while at a lower level, it can exploit the niceness of the environments and attain problem-dependent guarantees. To be specific, we obtain $\\mathcal{O}(\\ln V_T)$, $\\mathcal{O}(d \\ln V_T)$ and $\\hat{\\mathcal{O}}(\\sqrt{V_T})$ regret bounds for strongly convex, exp-concave and convex loss functions, respectively, where $d$ is the dimension, $V_T$ denotes problem-dependent gradient variations and $\\hat{\\mathcal{O}}(\\cdot)$-notation omits logarithmic factors on $V_T$. Our result finds broad implications and applications. It not only safeguards the worst-case guarantees, but also implies the small-loss bounds in analysis directly. Besides, it draws deep connections with adversarial/stochastic convex optimization and game theory, further validating its practical potential. Our method is based on a multi-layer online ensemble incorporating novel ingredients, including carefully-designed optimism for unifying diverse function types and cascaded corrections for algorithmic stability. Remarkably, despite its multi-layer structure, our algorithm necessitates only one gradient query per round, making it favorable when the gradient evaluation is time-consuming. This is facilitated by a novel regret decomposition equipped with customized surrogate losses.", "url": "https://arxiv.org/abs/2307.08360"}, {"metadata": {"arXiv": "2307.08364", "Date": "Mon, 17 Jul 2023 10:02:01 ", "Title": "Q(D)O-ES: Population-based Quality (Diversity) Optimisation for Post Hoc Ensemble Selection in AutoML", "Authors": ["Lennart Purucker", "Lennart Schneider", "Marie Anastacio", "Joeran Beel", "Bernd Bischl", "Holger Hoos"], "Categories": "cs.LG cs.NE", "Comments": ["10 pages main paper", "24 pages references and appendix", "4 figures", "16 subfigures", "13 tables", "to be published in: International Conference on Automated Machine Learning 2023. arXiv admin note: text overlap with arXiv:2307.00286"], "ACM-class": "I.2.6; I.5.1"}, "abstract": "Automated machine learning (AutoML) systems commonly ensemble models post hoc to improve predictive performance, typically via greedy ensemble selection (GES). However, we believe that GES may not always be optimal, as it performs a simple deterministic greedy search. In this work, we introduce two novel population-based ensemble selection methods, QO-ES and QDO-ES, and compare them to GES. While QO-ES optimises solely for predictive performance, QDO-ES also considers the diversity of ensembles within the population, maintaining a diverse set of well-performing ensembles during optimisation based on ideas of quality diversity optimisation. The methods are evaluated using 71 classification datasets from the AutoML benchmark, demonstrating that QO-ES and QDO-ES often outrank GES, albeit only statistically significant on validation data. Our results further suggest that diversity can be beneficial for post hoc ensembling but also increases the risk of overfitting.", "url": "https://arxiv.org/abs/2307.08364"}, {"metadata": {"arXiv": "2307.08382", "Date": "Mon, 17 Jul 2023 10:42:21 ", "Title": "Predicting Battery Lifetime Under Varying Usage Conditions from Early Aging Data", "Authors": ["Tingkai Li", "Zihao Zhou", "Adam Thelen", "David Howey", "Chao Hu"], "Categories": "cs.LG stat.ML"}, "abstract": "Accurate battery lifetime prediction is important for preventative maintenance, warranties, and improved cell design and manufacturing. However, manufacturing variability and usage-dependent degradation make life prediction challenging. Here, we investigate new features derived from capacity-voltage data in early life to predict the lifetime of cells cycled under widely varying charge rates, discharge rates, and depths of discharge. Features were extracted from regularly scheduled reference performance tests (i.e., low rate full cycles) during cycling. The early-life features capture a cell's state of health and the rate of change of component-level degradation modes, some of which correlate strongly with cell lifetime. Using a newly generated dataset from 225 nickel-manganese-cobalt/graphite Li-ion cells aged under a wide range of conditions, we demonstrate a lifetime prediction of in-distribution cells with 15.1% mean absolute percentage error using no more than the first 15% of data, for most cells. Further testing using a hierarchical Bayesian regression model shows improved performance on extrapolation, achieving 21.8% mean absolute percentage error for out-of-distribution cells. Our approach highlights the importance of using domain knowledge of lithium-ion battery degradation modes to inform feature engineering. Further, we provide the community with a new publicly available battery aging dataset with cells cycled beyond 80% of their rated capacity.", "url": "https://arxiv.org/abs/2307.08382"}, {"metadata": {"arXiv": "2307.08386", "Date": "Mon, 17 Jul 2023 10:50:09 ", "Title": "Tabular Machine Learning Methods for Predicting Gas Turbine Emissions", "Authors": ["Rebecca Potts", "Rick Hackney and Georgios Leontidis"], "Categories": "cs.LG", "Comments": ["23 pages", "9 figures", "1 appendix"]}, "abstract": "Predicting emissions for gas turbines is critical for monitoring harmful pollutants being released into the atmosphere. In this study, we evaluate the performance of machine learning models for predicting emissions for gas turbines. We compare an existing predictive emissions model, a first principles-based Chemical Kinetics model, against two machine learning models we developed based on SAINT and XGBoost, to demonstrate improved predictive performance of nitrogen oxides (NOx) and carbon monoxide (CO) using machine learning techniques. Our analysis utilises a Siemens Energy gas turbine test bed tabular dataset to train and validate the machine learning models. Additionally, we explore the trade-off between incorporating more features to enhance the model complexity, and the resulting presence of increased missing values in the dataset.", "url": "https://arxiv.org/abs/2307.08386"}, {"metadata": {"arXiv": "2307.08390", "Date": "Mon, 17 Jul 2023 11:04:27 ", "Title": "Correlation-aware Spatial-Temporal Graph Learning for Multivariate Time-series Anomaly Detection", "Authors": ["Yu Zheng", "Huan Yee Koh", "Ming Jin", "Lianhua Chi", "Khoa T. Phan", "Shirui Pan", "Yi-Ping Phoebe Chen", "Wei Xiang"], "Categories": "cs.LG", "Comments": ["17 pages", "double columns", "10 tables", "3 figures"]}, "abstract": "Multivariate time-series anomaly detection is critically important in many applications, including retail, transportation, power grid, and water treatment plants. Existing approaches for this problem mostly employ either statistical models which cannot capture the non-linear relations well or conventional deep learning models (e.g., CNN and LSTM) that do not explicitly learn the pairwise correlations among variables. To overcome these limitations, we propose a novel method, correlation-aware spatial-temporal graph learning (termed CST-GL), for time series anomaly detection. CST-GL explicitly captures the pairwise correlations via a multivariate time series correlation learning module based on which a spatial-temporal graph neural network (STGNN) can be developed. Then, by employing a graph convolution network that exploits one- and multi-hop neighbor information, our STGNN component can encode rich spatial information from complex pairwise dependencies between variables. With a temporal module that consists of dilated convolutional functions, the STGNN can further capture long-range dependence over time. A novel anomaly scoring component is further integrated into CST-GL to estimate the degree of an anomaly in a purely unsupervised manner. Experimental results demonstrate that CST-GL can detect anomalies effectively in general settings as well as enable early detection across different time delays.", "url": "https://arxiv.org/abs/2307.08390"}, {"metadata": {"arXiv": "2307.08423", "Date": "Mon, 17 Jul 2023 12:14:14 ", "Title": "Artificial Intelligence for Science in Quantum, Atomistic, and Continuum Systems", "Authors": ["Xuan Zhang", "Limei Wang", "Jacob Helwig", "Youzhi Luo", "Cong Fu", "Yaochen Xie", "Meng Liu", "Yuchao Lin", "Zhao Xu", "Keqiang Yan", "Keir Adams", "Maurice Weiler", "Xiner Li", "Tianfan Fu", "Yucheng Wang", "Haiyang Yu", "YuQing Xie", "Xiang Fu", "Alex Strasser", "Shenglong Xu", "Yi Liu", "Yuanqi Du", "Alexandra Saxton", "Hongyi Ling", "Hannah Lawrence", "Hannes St\\\"ark", "Shurui Gui", "Carl Edwards", "Nicholas Gao", "Adriana Ladera", "Tailin Wu", "Elyssa F. Hofgard", "Aria Mansouri Tehrani", "Rui Wang", "Ameya Daigavane", "Montgomery Bohde", "Jerry Kurtin", "Qian Huang", "Tuong Phung", "Minkai Xu", "Chaitanya K. Joshi", "Simon V. Mathis", "Kamyar Azizzadenesheli", "Ada Fang", "Al\\'an Aspuru-Guzik", "Erik Bekkers", "Michael Bronstein", "Marinka Zitnik", "Anima Anandkumar", "Stefano Ermon", "Pietro Li\\`o", "Rose Yu", "Stephan G\\\"unnemann", "Jure Leskovec", "Heng Ji", "Jimeng Sun", "Regina Barzilay", "et al. (6 additional authors not shown)"], "Categories": "cs.LG physics.comp-ph"}, "abstract": "Advances in artificial intelligence (AI) are fueling a new paradigm of discoveries in natural sciences. Today, AI has started to advance natural sciences by improving, accelerating, and enabling our understanding of natural phenomena at a wide range of spatial and temporal scales, giving rise to a new area of research known as AI for science (AI4Science). Being an emerging research paradigm, AI4Science is unique in that it is an enormous and highly interdisciplinary area. Thus, a unified and technical treatment of this field is needed yet challenging. This paper aims to provide a technically thorough account of a subarea of AI4Science; namely, AI for quantum, atomistic, and continuum systems. These areas aim at understanding the physical world from the subatomic (wavefunctions and electron density), atomic (molecules, proteins, materials, and interactions), to macro (fluids, climate, and subsurface) scales and form an important subarea of AI4Science. A unique advantage of focusing on these areas is that they largely share a common set of challenges, thereby allowing a unified and foundational treatment. A key common challenge is how to capture physics first principles, especially symmetries, in natural systems by deep learning methods. We provide an in-depth yet intuitive account of techniques to achieve equivariance to symmetry transformations. We also discuss other common technical challenges, including explainability, out-of-distribution generalization, knowledge transfer with foundation and large language models, and uncertainty quantification. To facilitate learning and education, we provide categorized lists of resources that we found to be useful. We strive to be thorough and unified and hope this initial effort may trigger more community interests and efforts to further advance AI4Science.", "url": "https://arxiv.org/abs/2307.08423"}, {"metadata": {"arXiv": "2307.08433", "Date": "Mon, 17 Jul 2023 12:25:52 ", "Title": "From random-walks to graph-sprints: a low-latency node embedding framework on continuous-time dynamic graphs", "Authors": ["Ahmad Naser Eddin", "Jacopo Bono", "David Apar\\'icio", "Hugo Ferreira", "Jo\\~ao Ascens\\~ao", "Pedro Ribeiro", "Pedro Bizarro"], "Categories": "cs.LG", "Comments": ["9 pages", "5 figures", "7 tables"]}, "abstract": "Many real-world datasets have an underlying dynamic graph structure, where entities and their interactions evolve over time. Machine learning models should consider these dynamics in order to harness their full potential in downstream tasks. Previous approaches for graph representation learning have focused on either sampling k-hop neighborhoods, akin to breadth-first search, or random walks, akin to depth-first search. However, these methods are computationally expensive and unsuitable for real-time, low-latency inference on dynamic graphs. To overcome these limitations, we propose graph-sprints a general purpose feature extraction framework for continuous-time-dynamic-graphs (CTDGs) that has low latency and is competitive with state-of-the-art, higher latency models. To achieve this, a streaming, low latency approximation to the random-walk based features is proposed. In our framework, time-aware node embeddings summarizing multi-hop information are computed using only single-hop operations on the incoming edges. We evaluate our proposed approach on three open-source datasets and two in-house datasets, and compare with three state-of-the-art algorithms (TGN-attn, TGN-ID, Jodie). We demonstrate that our graph-sprints features, combined with a machine learning classifier, achieve competitive performance (outperforming all baselines for the node classification tasks in five datasets). Simultaneously, graph-sprints significantly reduce inference latencies, achieving close to an order of magnitude speed-up in our experimental setting.", "url": "https://arxiv.org/abs/2307.08433"}, {"metadata": {"arXiv": "2307.08438", "Date": "Thu, 13 Jul 2023 18:59:28 ", "Title": "Near-Optimal Bounds for Learning Gaussian Halfspaces with Random Classification Noise", "Authors": ["Ilias Diakonikolas", "Jelena Diakonikolas", "Daniel M. Kane", "Puqian Wang", "Nikos Zarifis"], "Categories": "cs.LG cs.DS math.ST stat.ML stat.TH"}, "abstract": "We study the problem of learning general (i.e., not necessarily homogeneous) halfspaces with Random Classification Noise under the Gaussian distribution. We establish nearly-matching algorithmic and Statistical Query (SQ) lower bound results revealing a surprising information-computation gap for this basic problem. Specifically, the sample complexity of this learning problem is $\\widetilde{\\Theta}(d/\\epsilon)$, where $d$ is the dimension and $\\epsilon$ is the excess error. Our positive result is a computationally efficient learning algorithm with sample complexity $\\tilde{O}(d/\\epsilon + d/(\\max\\{p, \\epsilon\\})^2)$, where $p$ quantifies the bias of the target halfspace. On the lower bound side, we show that any efficient SQ algorithm (or low-degree test) for the problem requires sample complexity at least $\\Omega(d^{1/2}/(\\max\\{p, \\epsilon\\})^2)$. Our lower bound suggests that this quadratic dependence on $1/\\epsilon$ is inherent for efficient algorithms.", "url": "https://arxiv.org/abs/2307.08438"}, {"metadata": {"arXiv": "2307.08466", "Date": "Mon, 17 Jul 2023 13:21:02 ", "Title": "Classification of UHF Partial Discharge Signals in Gas-Insulated HVDC Systems Using Neural Networks", "Authors": ["Steffen Seitz and Thomas G\\\"otz and Christopher Lindenberg and Ronald Tetzlaff and Stephan Schlegel"], "Categories": "cs.LG cs.CV", "Comments": ["8 pages"]}, "abstract": "Undetected partial discharges (PDs) are a safety critical issue in high voltage (HV) gas insulated systems (GIS). While the diagnosis of PDs under AC voltage is well-established, the analysis of PDs under DC voltage remains an active research field. A key focus of these investigations is the classification of different PD sources to enable subsequent sophisticated analysis. In this paper, we propose and analyze a neural network-based approach for classifying PD signals caused by metallic protrusions and conductive particles on the insulator of HVDC GIS, without relying on pulse sequence analysis features. In contrast to previous approaches, our proposed model can discriminate the studied PD signals obtained at negative and positive potentials, while also generalizing to unseen operating voltage multiples. Additionally, we compare the performance of time- and frequency-domain input signals and explore the impact of different normalization schemes to mitigate the influence of free-space path loss between the sensor and defect location.", "url": "https://arxiv.org/abs/2307.08466"}, {"metadata": {"arXiv": "2307.08486", "Date": "Mon, 17 Jul 2023 13:48:27 ", "Title": "Fairness in KI-Systemen", "Authors": ["Janine Strotherm and Alissa M\\\"uller and Barbara Hammer and Benjamin Paa{\\ss}en"], "Categories": "cs.LG cs.CY", "Comments": ["in German language"]}, "abstract": "The more AI-assisted decisions affect people's lives, the more important the fairness of such decisions becomes. In this chapter, we provide an introduction to research on fairness in machine learning. We explain the main fairness definitions and strategies for achieving fairness using concrete examples and place fairness research in the European context. Our contribution is aimed at an interdisciplinary audience and therefore avoids mathematical formulation but emphasizes visualizations and examples. -- Je mehr KI-gest\\\"utzte Entscheidungen das Leben von Menschen betreffen, desto wichtiger ist die Fairness solcher Entscheidungen. In diesem Kapitel geben wir eine Einf\\\"uhrung in die Forschung zu Fairness im maschinellen Lernen. Wir erkl\\\"aren die wesentlichen Fairness-Definitionen und Strategien zur Erreichung von Fairness anhand konkreter Beispiele und ordnen die Fairness-Forschung in den europ\\\"aischen Kontext ein. Unser Beitrag richtet sich dabei an ein interdisziplin\\\"ares Publikum und verzichtet daher auf die mathematische Formulierung sondern betont Visualisierungen und Beispiele.", "url": "https://arxiv.org/abs/2307.08486"}, {"metadata": {"arXiv": "2307.08507", "Date": "Mon, 17 Jul 2023 14:09:43 ", "Title": "Efficient and Accurate Optimal Transport with Mirror Descent and Conjugate Gradients", "Authors": ["Mete Kemertas", "Allan D. Jepson", "Amir-massoud Farahmand"], "Categories": "cs.LG"}, "abstract": "We design a novel algorithm for optimal transport by drawing from the entropic optimal transport, mirror descent and conjugate gradients literatures. Our algorithm is able to compute optimal transport costs with arbitrary accuracy without running into numerical stability issues. The algorithm is implemented efficiently on GPUs and is shown empirically to converge more quickly than traditional algorithms such as Sinkhorn's Algorithm both in terms of number of iterations and wall-clock time in many cases. We pay particular attention to the entropy of marginal distributions and show that high entropy marginals make for harder optimal transport problems, for which our algorithm is a good fit. We provide a careful ablation analysis with respect to algorithm and problem parameters, and present benchmarking over the MNIST dataset. The results suggest that our algorithm can be a useful addition to the practitioner's optimal transport toolkit. Our code is open-sourced at https://github.com/adaptive-agents-lab/MDOT-PNCG .", "url": "https://arxiv.org/abs/2307.08507"}, {"metadata": {"arXiv": "2307.08519", "Date": "Mon, 17 Jul 2023 14:27:32 ", "Title": "Results on Counterfactual Invariance", "Authors": ["Jake Fawkes", "Robin J. Evans"], "Categories": "cs.LG stat.ML", "Comments": ["5 pages with 6 pages of supplementary. Accepted at the ICML 2023 workshop on Spurious Correlations", "Invariance and Stability"]}, "abstract": "In this paper we provide a theoretical analysis of counterfactual invariance. We present a variety of existing definitions, study how they relate to each other and what their graphical implications are. We then turn to the current major question surrounding counterfactual invariance, how does it relate to conditional independence? We show that whilst counterfactual invariance implies conditional independence, conditional independence does not give any implications about the degree or likelihood of satisfying counterfactual invariance. Furthermore, we show that for discrete causal models counterfactually invariant functions are often constrained to be functions of particular variables, or even constant.", "url": "https://arxiv.org/abs/2307.08519"}, {"metadata": {"arXiv": "2307.08572", "Date": "Mon, 17 Jul 2023 15:38:11 ", "Title": "Revisiting the Robustness of the Minimum Error Entropy Criterion: A Transfer Learning Case Study", "Authors": ["Luis Pedro Silvestrin", "Shujian Yu", "Mark Hoogendoorn"], "Categories": "cs.LG"}, "abstract": "Coping with distributional shifts is an important part of transfer learning methods in order to perform well in real-life tasks. However, most of the existing approaches in this area either focus on an ideal scenario in which the data does not contain noises or employ a complicated training paradigm or model design to deal with distributional shifts. In this paper, we revisit the robustness of the minimum error entropy (MEE) criterion, a widely used objective in statistical signal processing to deal with non-Gaussian noises, and investigate its feasibility and usefulness in real-life transfer learning regression tasks, where distributional shifts are common. Specifically, we put forward a new theoretical result showing the robustness of MEE against covariate shift. We also show that by simply replacing the mean squared error (MSE) loss with the MEE on basic transfer learning algorithms such as fine-tuning and linear probing, we can achieve competitive performance with respect to state-of-the-art transfer learning algorithms. We justify our arguments on both synthetic data and 5 real-world time-series data.", "url": "https://arxiv.org/abs/2307.08572"}, {"metadata": {"arXiv": "2307.08574", "Date": "Mon, 17 Jul 2023 15:40:45 ", "Title": "FedCME: Client Matching and Classifier Exchanging to Handle Data Heterogeneity in Federated Learning", "Authors": ["Jun Nie", "Danyang Xiao", "Lei Yang and Weigang Wu"], "Categories": "cs.LG"}, "abstract": "Data heterogeneity across clients is one of the key challenges in Federated Learning (FL), which may slow down the global model convergence and even weaken global model performance. Most existing approaches tackle the heterogeneity by constraining local model updates through reference to global information provided by the server. This can alleviate the performance degradation on the aggregated global model. Different from existing methods, we focus the information exchange between clients, which could also enhance the effectiveness of local training and lead to generate a high-performance global model. Concretely, we propose a novel FL framework named FedCME by client matching and classifier exchanging. In FedCME, clients with large differences in data distribution will be matched in pairs, and then the corresponding pair of clients will exchange their classifiers at the stage of local training in an intermediate moment. Since the local data determines the local model training direction, our method can correct update direction of classifiers and effectively alleviate local update divergence. Besides, we propose feature alignment to enhance the training of the feature extractor. Experimental results demonstrate that FedCME performs better than FedAvg, FedProx, MOON and FedRS on popular federated learning benchmarks including FMNIST and CIFAR10, in the case where data are heterogeneous.", "url": "https://arxiv.org/abs/2307.08574"}, {"metadata": {"arXiv": "2307.08591", "Date": "Mon, 17 Jul 2023 16:01:22 ", "Title": "Snapshot Spectral Clustering -- a costless approach to deep clustering ensembles generation", "Authors": ["Adam Pir\\'og", "Halina Kwa\\'snicka"], "Categories": "cs.LG", "Comments": ["In proceedings of the International Joint Conference on Neural Networks 2023"]}, "abstract": "Despite tremendous advancements in Artificial Intelligence, learning from large sets of data in an unsupervised manner remains a significant challenge. Classical clustering algorithms often fail to discover complex dependencies in large datasets, especially considering sparse, high-dimensional spaces. However, deep learning techniques proved to be successful when dealing with large quantities of data, efficiently reducing their dimensionality without losing track of underlying information. Several interesting advancements have already been made to combine deep learning and clustering. Still, the idea of enhancing the clustering results by combining multiple views of the data generated by deep neural networks appears to be insufficiently explored yet. This paper aims to investigate this direction and bridge the gap between deep neural networks, clustering techniques and ensemble learning methods. To achieve this goal, we propose a novel deep clustering ensemble method - Snapshot Spectral Clustering, designed to maximize the gain from combining multiple data views while minimizing the computational costs of creating the ensemble. Comparative analysis and experiments described in this paper prove the proposed concept, while the conducted hyperparameter study provides a valuable intuition to follow when selecting proper values.", "url": "https://arxiv.org/abs/2307.08591"}, {"metadata": {"arXiv": "2307.08596", "Date": "Fri, 14 Jul 2023 07:09:57 ", "Title": "Omnipotent Adversarial Training for Unknown Label-noisy and Imbalanced Datasets", "Authors": ["Guanlin Li", "Kangjie Chen", "Yuan Xu", "Han Qiu", "Tianwei Zhang"], "Categories": "cs.LG cs.CR cs.CV"}, "abstract": "Adversarial training is an important topic in robust deep learning, but the community lacks attention to its practical usage. In this paper, we aim to resolve a real-world application challenge, i.e., training a model on an imbalanced and noisy dataset to achieve high clean accuracy and robustness, with our proposed Omnipotent Adversarial Training (OAT). Our strategy consists of two innovative methodologies to address the label noise and data imbalance in the training set. We first introduce an oracle into the adversarial training process to help the model learn a correct data-label conditional distribution. This carefully-designed oracle can provide correct label annotations for adversarial training. We further propose logits adjustment adversarial training to overcome the data imbalance challenge, which can help the model learn a Bayes-optimal distribution. Our comprehensive evaluation results show that OAT outperforms other baselines by more than 20% clean accuracy improvement and 10% robust accuracy improvement under the complex combinations of data imbalance and label noise scenarios. The code can be found in https://github.com/GuanlinLee/OAT.", "url": "https://arxiv.org/abs/2307.08596"}, {"metadata": {"arXiv": "2307.08617", "Date": "Mon, 17 Jul 2023 16:32:49 ", "Title": "Understanding the impacts of crop diversification in the context of climate change: a machine learning approach", "Authors": ["Georgios Giannarakis", "Ilias Tsoumas", "Stelios Neophytides", "Christiana Papoutsa", "Charalampos Kontoes", "Diofantos Hadjimitsis"], "Categories": "cs.LG q-bio.PE", "Comments": ["Accepted for oral presentation at ISPRS Geospatial Week 2023"]}, "abstract": "The concept of sustainable intensification in agriculture necessitates the implementation of management practices that prioritize sustainability without compromising productivity. However, the effects of such practices are known to depend on environmental conditions, and are therefore expected to change as a result of a changing climate. We study the impact of crop diversification on productivity in the context of climate change. We leverage heterogeneous Earth Observation data and contribute a data-driven approach based on causal machine learning for understanding how crop diversification impacts may change in the future. We apply this method to the country of Cyprus throughout a 4-year period. We find that, on average, crop diversification significantly benefited the net primary productivity of crops, increasing it by 2.8%. The effect generally synergized well with higher maximum temperatures and lower soil moistures. In a warmer and more drought-prone climate, we conclude that crop diversification exhibits promising adaptation potential and is thus a sensible policy choice with regards to agricultural productivity for present and future.", "url": "https://arxiv.org/abs/2307.08617"}, {"metadata": {"arXiv": "2307.08637", "Date": "Mon, 17 Jul 2023 16:53:22 ", "Title": "LearnedSort as a learning-augmented SampleSort: Analysis and Parallelization", "Authors": ["Ivan Carvalho and Ramon Lawrence"], "Categories": "cs.LG cs.DB", "Comments": ["Published in SSDBM 2023"]}, "abstract": "This work analyzes and parallelizes LearnedSort, the novel algorithm that sorts using machine learning models based on the cumulative distribution function. LearnedSort is analyzed under the lens of algorithms with predictions, and it is argued that LearnedSort is a learning-augmented SampleSort. A parallel LearnedSort algorithm is developed combining LearnedSort with the state-of-the-art SampleSort implementation, IPS4o. Benchmarks on synthetic and real-world datasets demonstrate improved parallel performance for parallel LearnedSort compared to IPS4o and other sorting algorithms.", "url": "https://arxiv.org/abs/2307.08637"}, {"metadata": {"arXiv": "2307.08643", "Date": "Mon, 17 Jul 2023 16:57:01 ", "Title": "A General Framework for Learning under Corruption: Label Noise, Attribute Noise, and Beyond", "Authors": ["Laura Iacovissi and Nan Lu and Robert C. Williamson"], "Categories": "cs.LG stat.ML", "Comments": ["42 pages"]}, "abstract": "Corruption is frequently observed in collected data and has been extensively studied in machine learning under different corruption models. Despite this, there remains a limited understanding of how these models relate such that a unified view of corruptions and their consequences on learning is still lacking. In this work, we formally analyze corruption models at the distribution level through a general, exhaustive framework based on Markov kernels. We highlight the existence of intricate joint and dependent corruptions on both labels and attributes, which are rarely touched by existing research. Further, we show how these corruptions affect standard supervised learning by analyzing the resulting changes in Bayes Risk. Our findings offer qualitative insights into the consequences of \"more complex\" corruptions on the learning problem, and provide a foundation for future quantitative comparisons. Applications of the framework include corruption-corrected learning, a subcase of which we study in this paper by theoretically analyzing loss correction with respect to different corruption instances.", "url": "https://arxiv.org/abs/2307.08643"}, {"metadata": {"arXiv": "2307.08673", "Date": "Mon, 17 Jul 2023 17:34:32 ", "Title": "CohortFinder: an open-source tool for data-driven partitioning of biomedical image cohorts to yield robust machine learning models", "Authors": ["Fan Fan", "Georgia Martinez", "Thomas Desilvio", "John Shin", "Yijiang Chen", "Bangchen Wang", "Takaya Ozeki", "Maxime W. Lafarge", "Viktor H. Koelzer", "Laura Barisoni", "Anant Madabhushi", "Satish E. Viswanath", "Andrew Janowczyk"], "Categories": "cs.LG cs.CV", "Comments": ["26 pages", "9 figures", "4 tables. Abstract was accepted by European Society of Digital and Integrative Pathology (ESDIP)", "Germany", "2022"]}, "abstract": "Batch effects (BEs) refer to systematic technical differences in data collection unrelated to biological variations whose noise is shown to negatively impact machine learning (ML) model generalizability. Here we release CohortFinder, an open-source tool aimed at mitigating BEs via data-driven cohort partitioning. We demonstrate CohortFinder improves ML model performance in downstream medical image processing tasks. CohortFinder is freely available for download at cohortfinder.com.", "url": "https://arxiv.org/abs/2307.08673"}, {"metadata": {"arXiv": "2307.08691", "Date": "Mon, 17 Jul 2023 17:50:36 ", "Title": "FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning", "Authors": ["Tri Dao"], "Categories": "cs.LG"}, "abstract": "Scaling Transformers to longer sequence lengths has been a major problem in the last several years, promising to improve performance in language modeling and high-resolution image understanding, as well as to unlock new applications in code, audio, and video generation. The attention layer is the main bottleneck in scaling to longer sequences, as its runtime and memory increase quadratically in the sequence length. FlashAttention exploits the asymmetric GPU memory hierarchy to bring significant memory saving (linear instead of quadratic) and runtime speedup (2-4$\\times$ compared to optimized baselines), with no approximation. However, FlashAttention is still not nearly as fast as optimized matrix-multiply (GEMM) operations, reaching only 25-40\\% of the theoretical maximum FLOPs/s. We observe that the inefficiency is due to suboptimal work partitioning between different thread blocks and warps on the GPU, causing either low-occupancy or unnecessary shared memory reads/writes. We propose FlashAttention-2, with better work partitioning to address these issues. In particular, we (1) tweak the algorithm to reduce the number of non-matmul FLOPs (2) parallelize the attention computation, even for a single head, across different thread blocks to increase occupancy, and (3) within each thread block, distribute the work between warps to reduce communication through shared memory. These yield around 2$\\times$ speedup compared to FlashAttention, reaching 50-73\\% of the theoretical maximum FLOPs/s on A100 and getting close to the efficiency of GEMM operations. We empirically validate that when used end-to-end to train GPT-style models, FlashAttention-2 reaches training speed of up to 225 TFLOPs/s per A100 GPU (72\\% model FLOPs utilization).", "url": "https://arxiv.org/abs/2307.08691"}, {"metadata": {"arXiv": "2307.07975", "Date": "Sun, 16 Jul 2023 07:55:35 ", "Title": "Finite element inspired networks: Learning physically-plausible deformable object dynamics from partial observations", "Authors": ["Shamil Mamedov", "A. Ren\\'e Geist", "Jan Swevers", "Sebastian Trimpe"], "Categories": "cs.RO cs.LG"}, "abstract": "The accurate simulation of deformable linear object (DLO) dynamics is challenging if the task at hand requires a human-interpretable and data-efficient model that also yields fast predictions. To arrive at such model, we draw inspiration from the rigid finite element method (R-FEM) and model a DLO as a serial chain of rigid bodies whose internal state is unrolled through time by a dynamics network. As this state is not observed directly, the dynamics network is trained jointly with a physics-informed encoder mapping observed motion variables to the body chain's state. To encourage that the state acquires a physically meaningful representation, we leverage the forward kinematics (FK) of the underlying R-FEM model as a decoder. We demonstrate in a robot experiment that this architecture - being termed \"Finite element inspired network\" - forms an easy to handle, yet capable DLO dynamics model yielding physically interpretable predictions from partial observations. The project code is available at: \\url{https://tinyurl.com/fei-networks}", "url": "https://arxiv.org/abs/2307.07975"}, {"metadata": {"arXiv": "2307.08602", "Date": "Thu, 13 Jul 2023 21:51:29 ", "Title": "CART: Collision Avoidance and Robust Tracking Augmentation in Learning-based Motion Planning for Multi-Agent Systems", "Authors": ["Hiroyasu Tsukamoto and Benjamin Rivi\\`ere and Changrak Choi and Amir Rahmani and Soon-Jo Chung"], "Categories": "cs.RO cs.LG cs.MA cs.SY eess.SY math.OC", "Comments": ["IEEE Conference on Decision and Control (CDC)", "Preprint Version", "Accepted July", "2023"]}, "abstract": "This paper presents CART, an analytical method to augment a learning-based, distributed motion planning policy of a nonlinear multi-agent system with real-time collision avoidance and robust tracking guarantees, independently of learning errors. We first derive an analytical form of an optimal safety filter for Lagrangian systems, which formally ensures a collision-free operation in a multi-agent setting in a disturbance-free environment, while allowing for its distributed implementation with minimal deviation from the learned policy. We then propose an analytical form of an optimal robust filter for Lagrangian systems to be used hierarchically with the learned collision-free target trajectory, which also enables distributed implementation and guarantees exponential boundedness of the trajectory tracking error for safety, even under the presence of deterministic and stochastic disturbance. These results are shown to extend further to general control-affine nonlinear systems using contraction theory. Our key contribution is to enhance the performance of the learned motion planning policy with collision avoidance and tracking-based robustness guarantees, independently of its original performance such as approximation errors and regret bounds in machine learning. We demonstrate the effectiveness of CART in motion planning and control of several examples of nonlinear systems, including spacecraft formation flying and rotor-failed UAV swarms.", "url": "https://arxiv.org/abs/2307.08602"}, {"metadata": {"arXiv": "2307.08692", "Date": "Mon, 17 Jul 2023 17:52:57 ", "Title": "A Multiobjective Reinforcement Learning Framework for Microgrid Energy Management", "Authors": ["M. Vivienne Liu", "Patrick M. Reed", "David Gold", "Garret Quist", "and C. Lindsay Anderson"], "Categories": "eess.SY cs.LG cs.SY", "Comments": ["This work will be submitted to the IEEE Transactions on Smart Grid for possible publication. Copyright may be transferred without notice", "after which this version may no longer be accessible"]}, "abstract": "The emergence of microgrids (MGs) has provided a promising solution for decarbonizing and decentralizing the power grid, mitigating the challenges posed by climate change. However, MG operations often involve considering multiple objectives that represent the interests of different stakeholders, leading to potentially complex conflicts. To tackle this issue, we propose a novel multi-objective reinforcement learning framework that explores the high-dimensional objective space and uncovers the tradeoffs between conflicting objectives. This framework leverages exogenous information and capitalizes on the data-driven nature of reinforcement learning, enabling the training of a parametric policy without the need for long-term forecasts or knowledge of the underlying uncertainty distribution. The trained policies exhibit diverse, adaptive, and coordinative behaviors with the added benefit of providing interpretable insights on the dynamics of their information use. We employ this framework on the Cornell University MG (CU-MG), which is a combined heat and power MG, to evaluate its effectiveness. The results demonstrate performance improvements in all objectives considered compared to the status quo operations and offer more flexibility in navigating complex operational tradeoffs.", "url": "https://arxiv.org/abs/2307.08692"}, {"metadata": {"arXiv": "2307.07515", "Date": "Tue, 27 Jun 2023 19:25:09 ", "Title": "Artificial intelligence is algorithmic mimicry: why artificial \"agents\" are not (and won't be) proper agents", "Authors": ["Johannes Jaeger"], "Categories": "cs.AI"}, "abstract": "What is the prospect of developing artificial general intelligence (AGI)? I investigate this question by systematically comparing living and algorithmic systems, with a special focus on the notion of \"agency.\" There are three fundamental differences to consider: (1) Living systems are autopoietic, that is, self-manufacturing, and therefore able to set their own intrinsic goals, while algorithms exist in a computational environment with target functions that are both provided by an external agent. (2) Living systems are embodied in the sense that there is no separation between their symbolic and physical aspects, while algorithms run on computational architectures that maximally isolate software from hardware. (3) Living systems experience a large world, in which most problems are ill-defined (and not all definable), while algorithms exist in a small world, in which all problems are well-defined. These three differences imply that living and algorithmic systems have very different capabilities and limitations. In particular, it is extremely unlikely that true AGI (beyond mere mimicry) can be developed in the current algorithmic framework of AI research. Consequently, discussions about the proper development and deployment of algorithmic tools should be shaped around the dangers and opportunities of current narrow AI, not the extremely unlikely prospect of the emergence of true agency in artificial systems.", "url": "https://arxiv.org/abs/2307.07515"}, {"metadata": {"arXiv": "2307.07517", "Date": "Sat, 01 Jul 2023 09:01:49 ", "Title": "Causing is Achieving -- A solution to the problem of causation", "Authors": ["Riichiro Mizoguchi"], "Categories": "cs.AI", "Comments": ["13 pages", "3 figures"]}, "abstract": "From the standpoint of applied ontology, the problem of understanding and modeling causation has been recently challenged on the premise that causation is real. As a consequence, the following three results were obtained: (1) causation can be understood via the notion of systemic function; (2) any cause can be decomposed using only four subfunctions, namely Achieves, Prevents, Allows, and Disallows; and (3) the last three subfunctions can be defined in terms of Achieves alone. It follows that the essence of causation lies in a single function, namely Achieves. It remains to elucidate the nature of the Achieves function, which has been elaborated only partially in the previous work. In this paper, we first discuss a couple of underlying policies in the above-mentioned causal theory since these are useful in the discussion, then summarize the results obtained in the former paper, and finally reveal the nature of Achieves giving a complete solution to the problem of what causation is.", "url": "https://arxiv.org/abs/2307.07517"}, {"metadata": {"arXiv": "2307.07518", "Date": "Sat, 01 Jul 2023 15:41:12 ", "Title": "CephGPT-4: An Interactive Multimodal Cephalometric Measurement and Diagnostic System with Visual Large Language Model", "Authors": ["Lei Ma", "Jincong Han", "Zhaoxin Wang", "Dian Zhang"], "Categories": "cs.AI cs.CL cs.CV eess.IV"}, "abstract": "Large-scale multimodal language models (LMMs) have achieved remarkable success in general domains. However, the exploration of diagnostic language models based on multimodal cephalometric medical data remains limited. In this paper, we propose a novel multimodal cephalometric analysis and diagnostic dialogue model. Firstly, a multimodal orthodontic medical dataset is constructed, comprising cephalometric images and doctor-patient dialogue data, with automatic analysis of cephalometric landmarks using U-net and generation of diagnostic reports. Then, the cephalometric dataset and generated diagnostic reports are separately fine-tuned on Minigpt-4 and VisualGLM. Results demonstrate that the CephGPT-4 model exhibits excellent performance and has the potential to revolutionize orthodontic measurement and diagnostic applications. These innovations hold revolutionary application potential in the field of orthodontics.", "url": "https://arxiv.org/abs/2307.07518"}, {"metadata": {"arXiv": "2307.07523", "Date": "Mon, 10 Jul 2023 11:05:51 ", "Title": "PapagAI:Automated Feedback for Reflective Essays", "Authors": ["Veronika Solopova", "Adrian Gruszczynski", "Eiad Rostom", "Fritz Cremer", "Sascha Witte", "Chengming Zhang", "Fernando Ramos L\\'opez Lea Pl\\\"o{\\ss}l", "Florian Hofmann", "Ralf Romeike", "Michaela Gl\\\"aser-Zikuda", "Christoph Benzm\\\"uller and Tim Landgraf"], "Categories": "cs.AI cs.CL", "Comments": ["2 figures"]}, "abstract": "Written reflective practice is a regular exercise pre-service teachers perform during their higher education. Usually, their lecturers are expected to provide individual feedback, which can be a challenging task to perform on a regular basis. In this paper, we present the first open-source automated feedback tool based on didactic theory and implemented as a hybrid AI system. We describe the components and discuss the advantages and disadvantages of our system compared to the state-of-art generative large language models. The main objective of our work is to enable better learning outcomes for students and to complement the teaching activities of lecturers.", "url": "https://arxiv.org/abs/2307.07523"}, {"metadata": {"arXiv": "2307.07524", "Date": "Tue, 11 Jul 2023 02:47:33 ", "Title": "Reducing Causality to Functions with Structural Models", "Authors": ["Tianyi Miao"], "Categories": "cs.AI", "Comments": ["47 pages", "submitted to The British Journal for the Philosophy of Science"]}, "abstract": "The precise definition of causality is currently an open problem in philosophy and statistics. We believe causality should be defined as functions (in mathematics) that map causes to effects. We propose a reductive definition of causality based on Structural Functional Model (SFM). Using delta compression and contrastive forward inference, SFM can produce causal utterances like \"X causes Y\" and \"X is the cause of Y\" that match our intuitions. We compile a dataset of causal scenarios and use SFM in all of them. SFM is compatible with but not reducible to probability theory. We also compare SFM with other theories of causation and apply SFM to downstream problems like free will, causal explanation, and mental causation.", "url": "https://arxiv.org/abs/2307.07524"}, {"metadata": {"arXiv": "2307.07526", "Date": "Tue, 11 Jul 2023 11:44:09 ", "Title": "Can I say, now machines can think?", "Authors": ["Nitisha Aggarwal", "Geetika Jain Saxena", "Sanjeev Singh", "Amit Pundir"], "Categories": "cs.AI cs.CY", "Comments": ["11 pages", "3 figures"], "MSC-class": "I.2.m Miscellaneous"}, "abstract": "Generative AI techniques have opened the path for new generations of machines in diverse domains. These machines have various capabilities for example, they can produce images, generate answers or stories, and write codes based on the \"prompts\" only provided by users. These machines are considered 'thinking minds' because they have the ability to generate human-like responses. In this study, we have analyzed and explored the capabilities of artificial intelligence-enabled machines. We have revisited on Turing's concept of thinking machines and compared it with recent technological advancements. The objections and consequences of the thinking machines are also discussed in this study, along with available techniques to evaluate machines' cognitive capabilities. We have concluded that Turing Test is a critical aspect of evaluating machines' ability. However, there are other aspects of intelligence too, and AI machines exhibit most of these aspects.", "url": "https://arxiv.org/abs/2307.07526"}, {"metadata": {"arXiv": "2307.07628", "Date": "Fri, 14 Jul 2023 20:57:27 ", "Title": "Value-based Fast and Slow AI Nudging", "Authors": ["Marianna B. Ganapini", "Francesco Fabiano", "Lior Horesh", "Andrea Loreggia", "Nicholas Mattei", "Keerthiram Murugesan", "Vishal Pallagani", "Francesca Rossi", "Biplav Srivastava", "Brent Venable"], "Categories": "cs.AI cs.CY cs.HC"}, "abstract": "Nudging is a behavioral strategy aimed at influencing people's thoughts and actions. Nudging techniques can be found in many situations in our daily lives, and these nudging techniques can targeted at human fast and unconscious thinking, e.g., by using images to generate fear or the more careful and effortful slow thinking, e.g., by releasing information that makes us reflect on our choices. In this paper, we propose and discuss a value-based AI-human collaborative framework where AI systems nudge humans by proposing decision recommendations. Three different nudging modalities, based on when recommendations are presented to the human, are intended to stimulate human fast thinking, slow thinking, or meta-cognition. Values that are relevant to a specific decision scenario are used to decide when and how to use each of these nudging modalities. Examples of values are decision quality, speed, human upskilling and learning, human agency, and privacy. Several values can be present at the same time, and their priorities can vary over time. The framework treats values as parameters to be instantiated in a specific decision environment.", "url": "https://arxiv.org/abs/2307.07628"}, {"metadata": {"arXiv": "2307.07636", "Date": "Fri, 14 Jul 2023 21:27:00 ", "Title": "Dissenting Explanations: Leveraging Disagreement to Reduce Model Overreliance", "Authors": ["Omer Reingold", "Judy Hanwen Shen", "Aditi Talati"], "Categories": "cs.AI", "Comments": ["V1: AI & HCI Workshop at ICML 2023"], "MSC-class": "68", "ACM-class": "I.2"}, "abstract": "While explainability is a desirable characteristic of increasingly complex black-box models, modern explanation methods have been shown to be inconsistent and contradictory. The semantics of explanations is not always fully understood - to what extent do explanations \"explain\" a decision and to what extent do they merely advocate for a decision? Can we help humans gain insights from explanations accompanying correct predictions and not over-rely on incorrect predictions advocated for by explanations? With this perspective in mind, we introduce the notion of dissenting explanations: conflicting predictions with accompanying explanations. We first explore the advantage of dissenting explanations in the setting of model multiplicity, where multiple models with similar performance may have different predictions. In such cases, providing dissenting explanations could be done by invoking the explanations of disagreeing models. Through a pilot study, we demonstrate that dissenting explanations reduce overreliance on model predictions, without reducing overall accuracy. Motivated by the utility of dissenting explanations we present both global and local methods for their generation.", "url": "https://arxiv.org/abs/2307.07636"}, {"metadata": {"arXiv": "2307.07699", "Date": "Sat, 15 Jul 2023 03:40:55 ", "Title": "Leveraging Large Language Models to Generate Answer Set Programs", "Authors": ["Adam Ishay", "Zhun Yang", "Joohyung Lee"], "Categories": "cs.AI cs.CL cs.SC", "Comments": ["17 pages", "KR 2023"]}, "abstract": "Large language models (LLMs), such as GPT-3 and GPT-4, have demonstrated exceptional performance in various natural language processing tasks and have shown the ability to solve certain reasoning problems. However, their reasoning capabilities are limited and relatively shallow, despite the application of various prompting techniques. In contrast, formal logic is adept at handling complex reasoning, but translating natural language descriptions into formal logic is a challenging task that non-experts struggle with. This paper proposes a neuro-symbolic method that combines the strengths of large language models and answer set programming. Specifically, we employ an LLM to transform natural language descriptions of logic puzzles into answer set programs. We carefully design prompts for an LLM to convert natural language descriptions into answer set programs in a step by step manner. Surprisingly, with just a few in-context learning examples, LLMs can generate reasonably complex answer set programs. The majority of errors made are relatively simple and can be easily corrected by humans, thus enabling LLMs to effectively assist in the creation of answer set programs.", "url": "https://arxiv.org/abs/2307.07699"}, {"metadata": {"arXiv": "2307.07734", "Date": "Sat, 15 Jul 2023 07:16:38 ", "Title": "Abstracting Concept-Changing Rules for Solving Raven's Progressive Matrix Problems", "Authors": ["Fan Shi", "Bin Li", "Xiangyang Xue"], "Categories": "cs.AI"}, "abstract": "The abstract visual reasoning ability in human intelligence benefits discovering underlying rules in the novel environment. Raven's Progressive Matrix (RPM) is a classic test to realize such ability in machine intelligence by selecting from candidates. Recent studies suggest that solving RPM in an answer-generation way boosts a more in-depth understanding of rules. However, existing generative solvers cannot discover the global concept-changing rules without auxiliary supervision (e.g., rule annotations and distractors in candidate sets). To this end, we propose a deep latent variable model for Concept-changing Rule ABstraction (CRAB) by learning interpretable concepts and parsing concept-changing rules in the latent space. With the iterative learning process, CRAB can automatically abstract global rules shared on the dataset on each concept and form the learnable prior knowledge of global rules. CRAB outperforms the baselines trained without auxiliary supervision in the arbitrary-position answer generation task and achieves comparable and even higher accuracy than the compared models trained with auxiliary supervision. Finally, we conduct experiments to illustrate the interpretability of CRAB in concept learning, answer selection, and global rule abstraction.", "url": "https://arxiv.org/abs/2307.07734"}, {"metadata": {"arXiv": "2307.07764", "Date": "Sat, 15 Jul 2023 10:16:51 ", "Title": "Explainable AI with counterfactual paths", "Authors": ["Bastian Pfeifer", "Mateusz Krzyzinski", "Hubert Baniecki", "Anna Saranti", "Andreas Holzinger", "Przemyslaw Biecek"], "Categories": "cs.AI"}, "abstract": "Explainable AI (XAI) is an increasingly important area of research in machine learning, which in principle aims to make black-box models transparent and interpretable. In this paper, we propose a novel approach to XAI that uses counterfactual paths generated by conditional permutations. Our method provides counterfactual explanations by identifying alternative paths that could have led to different outcomes. The proposed method is particularly suitable for generating explanations based on counterfactual paths in knowledge graphs. By examining hypothetical changes to the input data in the knowledge graph, we can systematically validate the behaviour of the model and examine the features or combination of features that are most important to the model's predictions. Our approach provides a more intuitive and interpretable explanation for the model's behaviour than traditional feature weighting methods and can help identify and mitigate biases in the model.", "url": "https://arxiv.org/abs/2307.07764"}, {"metadata": {"arXiv": "2307.07876", "Date": "Sat, 15 Jul 2023 19:27:38 ", "Title": "Online Goal Recognition in Discrete and Continuous Domains Using a Vectorial Representation", "Authors": ["Douglas Tesch", "Leonardo Rosa Amado", "Felipe Meneguzzi"], "Categories": "cs.AI"}, "abstract": "While recent work on online goal recognition efficiently infers goals under low observability, comparatively less work focuses on online goal recognition that works in both discrete and continuous domains. Online goal recognition approaches often rely on repeated calls to the planner at each new observation, incurring high computational costs. Recognizing goals online in continuous space quickly and reliably is critical for any trajectory planning problem since the real physical world is fast-moving, e.g. robot applications. We develop an efficient method for goal recognition that relies either on a single call to the planner for each possible goal in discrete domains or a simplified motion model that reduces the computational burden in continuous ones. The resulting approach performs the online component of recognition orders of magnitude faster than the current state of the art, making it the first online method effectively usable for robotics applications that require sub-second recognition.", "url": "https://arxiv.org/abs/2307.07876"}, {"metadata": {"arXiv": "2307.07909", "Date": "Sun, 16 Jul 2023 00:34:12 ", "Title": "Is Imitation All You Need? Generalized Decision-Making with Dual-Phase Training", "Authors": ["Yao Wei and Yanchao Sun and Ruijie Zheng and Sai Vemprala and Rogerio Bonatti and Shuhang Chen and Ratnesh Madaan and Zhongjie Ba and Ashish Kapoor and Shuang Ma"], "Categories": "cs.AI"}, "abstract": "We introduce DualMind, a generalist agent designed to tackle various decision-making tasks that addresses challenges posed by current methods, such as overfitting behaviors and dependence on task-specific fine-tuning. DualMind uses a novel \"Dual-phase\" training strategy that emulates how humans learn to act in the world. The model first learns fundamental common knowledge through a self-supervised objective tailored for control tasks and then learns how to make decisions based on different contexts through imitating behaviors conditioned on given prompts. DualMind can handle tasks across domains, scenes, and embodiments using just a single set of model weights and can execute zero-shot prompting without requiring task-specific fine-tuning. We evaluate DualMind on MetaWorld and Habitat through extensive experiments and demonstrate its superior generalizability compared to previous techniques, outperforming other generalist agents by over 50$\\%$ and 70$\\%$ on Habitat and MetaWorld, respectively. On the 45 tasks in MetaWorld, DualMind achieves over 30 tasks at a 90$\\%$ success rate.", "url": "https://arxiv.org/abs/2307.07909"}, {"metadata": {"arXiv": "2307.07919", "Date": "Sun, 16 Jul 2023 01:56:41 ", "Title": "Neural Architecture Retrieval", "Authors": ["Xiaohuan Pei", "Yanxi Li", "Minjing Dong", "Chang Xu"], "Categories": "cs.AI"}, "abstract": "With the increasing number of new neural architecture designs and substantial existing neural architectures, it becomes difficult for the researchers to situate their contributions compared with existing neural architectures or establish the connections between their designs and other relevant ones. To discover similar neural architectures in an efficient and automatic manner, we define a new problem Neural Architecture Retrieval which retrieves a set of existing neural architectures which have similar designs to the query neural architecture. Existing graph pre-training strategies cannot address the computational graph in neural architectures due to the graph size and motifs. To fulfill this potential, we propose to divide the graph into motifs which are used to rebuild the macro graph to tackle these issues, and introduce multi-level contrastive learning to achieve accurate graph representation learning. Extensive evaluations on both human-designed and synthesized neural architectures demonstrate the superiority of our algorithm. Such a dataset which contains 12k real-world network architectures, as well as their embedding, is built for neural architecture retrieval.", "url": "https://arxiv.org/abs/2307.07919"}, {"metadata": {"arXiv": "2307.07951", "Date": "Sun, 16 Jul 2023 05:41:53 ", "Title": "MinT: Boosting Generalization in Mathematical Reasoning via Multi-View Fine-Tuning", "Authors": ["Zhenwen Liang", "Dian Yu", "Xiaoman Pan", "Wenlin Yao", "Qingkai Zeng", "Xiangliang Zhang", "Dong Yu"], "Categories": "cs.AI cs.CL"}, "abstract": "Reasoning in mathematical domains remains a significant challenge for relatively small language models (LMs). Many current methods focus on specializing LMs in mathematical reasoning and rely heavily on knowledge distillation from powerful but inefficient large LMs (LLMs). In this work, we explore a new direction that avoids over-reliance on LLM teachers, introducing a multi-view fine-tuning method that efficiently exploits existing mathematical problem datasets with diverse annotation styles. Our approach uniquely considers the various annotation formats as different \"views\" and leverages them in training the model. By postpending distinct instructions to input questions, models can learn to generate solutions in diverse formats in a flexible manner. Experimental results show that our strategy enables a LLaMA-7B model to outperform prior approaches that utilize knowledge distillation, as well as carefully established baselines. Additionally, the proposed method grants the models promising generalization ability across various views and datasets, and the capability to learn from inaccurate or incomplete noisy data. We hope our multi-view training paradigm could inspire future studies in other machine reasoning domains.", "url": "https://arxiv.org/abs/2307.07951"}, {"metadata": {"arXiv": "2307.08024", "Date": "Sun, 16 Jul 2023 12:29:27 ", "Title": "Bayesian inference for data-efficient, explainable, and safe robotic motion planning: A review", "Authors": ["Chengmin Zhou", "Chao Wang", "Haseeb Hassan", "Himat Shah", "Bingding Huang", "Pasi Fr\\\"anti"], "Categories": "cs.AI"}, "abstract": "Bayesian inference has many advantages in robotic motion planning over four perspectives: The uncertainty quantification of the policy, safety (risk-aware) and optimum guarantees of robot motions, data-efficiency in training of reinforcement learning, and reducing the sim2real gap when the robot is applied to real-world tasks. However, the application of Bayesian inference in robotic motion planning is lagging behind the comprehensive theory of Bayesian inference. Further, there are no comprehensive reviews to summarize the progress of Bayesian inference to give researchers a systematic understanding in robotic motion planning. This paper first provides the probabilistic theories of Bayesian inference which are the preliminary of Bayesian inference for complex cases. Second, the Bayesian estimation is given to estimate the posterior of policies or unknown functions which are used to compute the policy. Third, the classical model-based Bayesian RL and model-free Bayesian RL algorithms for robotic motion planning are summarized, while these algorithms in complex cases are also analyzed. Fourth, the analysis of Bayesian inference in inverse RL is given to infer the reward functions in a data-efficient manner. Fifth, we systematically present the hybridization of Bayesian inference and RL which is a promising direction to improve the convergence of RL for better motion planning. Sixth, given the Bayesian inference, we present the interpretable and safe robotic motion plannings which are the hot research topic recently. Finally, all algorithms reviewed in this paper are summarized analytically as the knowledge graphs, and the future of Bayesian inference for robotic motion planning is also discussed, to pave the way for data-efficient, explainable, and safe robotic motion planning strategies for practical applications.", "url": "https://arxiv.org/abs/2307.08024"}, {"metadata": {"arXiv": "2307.08087", "Date": "Sun, 16 Jul 2023 15:59:13 ", "Title": "A Recursive Bateson-Inspired Model for the Generation of Semantic Formal Concepts from Spatial Sensory Data", "Authors": ["Jaime de Miguel Rodriguez", "Fernando Sancho Caparrini"], "Categories": "cs.AI"}, "abstract": "Neural-symbolic approaches to machine learning incorporate the advantages from both connectionist and symbolic methods. Typically, these models employ a first module based on a neural architecture to extract features from complex data. Then, these features are processed as symbols by a symbolic engine that provides reasoning, concept structures, composability, better generalization and out-of-distribution learning among other possibilities. However, neural approaches to the grounding of symbols in sensory data, albeit powerful, still require heavy training and tedious labeling for the most part. This paper presents a new symbolic-only method for the generation of hierarchical concept structures from complex spatial sensory data. The approach is based on Bateson's notion of difference as the key to the genesis of an idea or a concept. Following his suggestion, the model extracts atomic features from raw data by computing elemental sequential comparisons in a stream of multivariate numerical values. Higher-level constructs are built from these features by subjecting them to further comparisons in a recursive process. At any stage in the recursion, a concept structure may be obtained from these constructs and features by means of Formal Concept Analysis. Results show that the model is able to produce fairly rich yet human-readable conceptual representations without training. Additionally, the concept structures obtained through the model (i) present high composability, which potentially enables the generation of 'unseen' concepts, (ii) allow formal reasoning, and (iii) have inherent abilities for generalization and out-of-distribution learning. Consequently, this method may offer an interesting angle to current neural-symbolic research. Future work is required to develop a training methodology so that the model can be tested against a larger dataset.", "url": "https://arxiv.org/abs/2307.08087"}, {"metadata": {"arXiv": "2307.08171", "Date": "Sun, 16 Jul 2023 23:11:26 ", "Title": "Credit Assignment: Challenges and Opportunities in Developing Human-like AI Agents", "Authors": ["Thuy Ngoc Nguyen and Chase McDonald and Cleotilde Gonzalez"], "Categories": "cs.AI cs.HC", "Comments": ["11 figures; 3 tables"]}, "abstract": "Temporal credit assignment is crucial for learning and skill development in natural and artificial intelligence. While computational methods like the TD approach in reinforcement learning have been proposed, it's unclear if they accurately represent how humans handle feedback delays. Cognitive models intend to represent the mental steps by which humans solve problems and perform a number of tasks, but limited research in cognitive science has addressed the credit assignment problem in humans and cognitive models. Our research uses a cognitive model based on a theory of decisions from experience, Instance-Based Learning Theory (IBLT), to test different credit assignment mechanisms in a goal-seeking navigation task with varying levels of decision complexity. Instance-Based Learning (IBL) models simulate the process of making sequential choices with different credit assignment mechanisms, including a new IBL-TD model that combines the IBL decision mechanism with the TD approach. We found that (1) An IBL model that gives equal credit assignment to all decisions is able to match human performance better than other models, including IBL-TD and Q-learning; (2) IBL-TD and Q-learning models underperform compared to humans initially, but eventually, they outperform humans; (3) humans are influenced by decision complexity, while models are not. Our study provides insights into the challenges of capturing human behavior and the potential opportunities to use these models in future AI systems to support human activities.", "url": "https://arxiv.org/abs/2307.08171"}, {"metadata": {"arXiv": "2307.08242", "Date": "Mon, 17 Jul 2023 04:54:58 ", "Title": "Lifted Sequential Planning with Lazy Constraint Generation Solvers", "Authors": ["Anubhav Singh", "Miquel Ramirez", "Nir Lipovetzky", "and Peter J. Stuckey"], "Categories": "cs.AI", "ACM-class": "I.2.8; I.2.4"}, "abstract": "This paper studies the possibilities made open by the use of Lazy Clause Generation (LCG) based approaches to Constraint Programming (CP) for tackling sequential classical planning. We propose a novel CP model based on seminal ideas on so-called lifted causal encodings for planning as satisfiability, that does not require grounding, as choosing groundings for functions and action schemas becomes an integral part of the problem of designing valid plans. This encoding does not require encoding frame axioms, and does not explicitly represent states as decision variables for every plan step. We also present a propagator procedure that illustrates the possibilities of LCG to widen the kind of inference methods considered to be feasible in planning as (iterated) CSP solving. We test encodings and propagators over classic IPC and recently proposed benchmarks for lifted planning, and report that for planning problem instances requiring fewer plan steps our methods compare very well with the state-of-the-art in optimal sequential planning.", "url": "https://arxiv.org/abs/2307.08242"}, {"metadata": {"arXiv": "2307.08262", "Date": "Mon, 17 Jul 2023 06:10:03 ", "Title": "Team Badminseok at IJCAI CoachAI Badminton Challenge 2023: Multi-Layer Multi-Input Transformer Network (MuLMINet) with Weighted Loss", "Authors": ["Minwoo Seong", "Jeongseok Oh", "SeungJun Kim"], "Categories": "cs.AI", "Comments": ["4 pages", "3 figures"]}, "abstract": "The increasing use of artificial intelligence (AI) technology in turn-based sports, such as badminton, has sparked significant interest in evaluating strategies through the analysis of match video data. Predicting future shots based on past ones plays a vital role in coaching and strategic planning. In this study, we present a Multi-Layer Multi-Input Transformer Network (MuLMINet) that leverages professional badminton player match data to accurately predict future shot types and area coordinates. Our approach resulted in achieving the runner-up (2nd place) in the IJCAI CoachAI Badminton Challenge 2023, Track 2. To facilitate further research, we have made our code publicly accessible online, contributing to the broader research community's knowledge and advancements in the field of AI-assisted sports analysis.", "url": "https://arxiv.org/abs/2307.08262"}, {"metadata": {"arXiv": "2307.08304", "Date": "Mon, 17 Jul 2023 07:59:47 ", "Title": "Efficient Computation of Counterfactual Bounds", "Authors": ["Marco Zaffalon and Alessandro Antonucci and Rafael Caba\\~nas and David Huber and Dario Azzimonti"], "Categories": "cs.AI"}, "abstract": "We assume to be given structural equations over discrete variables inducing a directed acyclic graph, namely, a structural causal model, together with data about its internal nodes. The question we want to answer is how we can compute bounds for partially identifiable counterfactual queries from such an input. We start by giving a map from structural casual models to credal networks. This allows us to compute exact counterfactual bounds via algorithms for credal nets on a subclass of structural causal models. Exact computation is going to be inefficient in general given that, as we show, causal inference is NP-hard even on polytrees. We target then approximate bounds via a causal EM scheme. We evaluate their accuracy by providing credible intervals on the quality of the approximation; we show through a synthetic benchmark that the EM scheme delivers accurate results in a fair number of runs. In the course of the discussion, we also point out what seems to be a neglected limitation to the trending idea that counterfactual bounds can be computed without knowledge of the structural equations. We also present a real case study on palliative care to show how our algorithms can readily be used for practical purposes.", "url": "https://arxiv.org/abs/2307.08304"}, {"metadata": {"arXiv": "2307.08368", "Date": "Mon, 17 Jul 2023 10:06:21 ", "Title": "Gender mobility in the labor market with skills-based matching models", "Authors": ["Ajaya Adhikari", "Steven Vethman", "Daan Vos", "Marc Lenz", "Ioana Cocu", "Ioannis Tolios", "Cor J. Veenman"], "Categories": "cs.AI cs.CL", "Comments": ["This paper was presented during the AAAI Spring Symposium 2023 (AI Trustworthiness Assessment (AITA) track)"]}, "abstract": "Skills-based matching promises mobility of workers between different sectors and occupations in the labor market. In this case, job seekers can look for jobs they do not yet have experience in, but for which they do have relevant skills. Currently, there are multiple occupations with a skewed gender distribution. For skills-based matching, it is unclear if and how a shift in the gender distribution, which we call gender mobility, between occupations will be effected. It is expected that the skills-based matching approach will likely be data-driven, including computational language models and supervised learning methods. This work, first, shows the presence of gender segregation in language model-based skills representation of occupations. Second, we assess the use of these representations in a potential application based on simulated data, and show that the gender segregation is propagated by various data-driven skills-based matching models.These models are based on different language representations (bag of words, word2vec, and BERT), and distance metrics (static and machine learning-based). Accordingly, we show how skills-based matching approaches can be evaluated and compared on matching performance as well as on the risk of gender segregation. Making the gender segregation bias of models more explicit can help in generating healthy trust in the use of these models in practice.", "url": "https://arxiv.org/abs/2307.08368"}, {"metadata": {"arXiv": "2307.08401", "Date": "Mon, 17 Jul 2023 11:36:15 ", "Title": "A Novel Multiagent Flexibility Aggregation Framework", "Authors": ["Stavros Orfanoudakis", "Georgios Chalkiadakis"], "Categories": "cs.AI", "Comments": ["12 pages", "9 figures"]}, "abstract": "The increasing number of Distributed Energy Resources (DERs) in the emerging Smart Grid, has created an imminent need for intelligent multiagent frameworks able to utilize these assets efficiently. In this paper, we propose a novel DER aggregation framework, encompassing a multiagent architecture and various types of mechanisms for the effective management and efficient integration of DERs in the Grid. One critical component of our architecture is the Local Flexibility Estimators (LFEs) agents, which are key for offloading the Aggregator from serious or resource-intensive responsibilities -- such as addressing privacy concerns and predicting the accuracy of DER statements regarding their offered demand response services. The proposed framework allows the formation of efficient LFE cooperatives. To this end, we developed and deployed a variety of cooperative member selection mechanisms, including (a) scoring rules, and (b) (deep) reinforcement learning. We use data from the well-known PowerTAC simulator to systematically evaluate our framework. Our experiments verify its effectiveness for incorporating heterogeneous DERs into the Grid in an efficient manner. In particular, when using the well-known probabilistic prediction accuracy-incentivizing CRPS scoring rule as a selection mechanism, our framework results in increased average payments for participants, when compared with traditional commercial aggregators.", "url": "https://arxiv.org/abs/2307.08401"}, {"metadata": {"arXiv": "2307.08424", "Date": "Mon, 17 Jul 2023 12:14:24 ", "Title": "An Indefensible Attack: Label-Only Model Inversion via Conditional Diffusion Model", "Authors": ["Rongke Liu"], "Categories": "cs.AI", "Comments": ["11 pages", "6 figures", "2 tables"]}, "abstract": "Model inversion attacks (MIAs) are aimed at recovering private data from a target model's training set, which poses a threat to the privacy of deep learning models. MIAs primarily focus on the white-box scenario where the attacker has full access to the structure and parameters of the target model. However, practical applications are black-box, it is not easy for adversaries to obtain model-related parameters, and various models only output predicted labels. Existing black-box MIAs primarily focused on designing the optimization strategy, and the generative model is only migrated from the GAN used in white-box MIA. Our research is the pioneering study of feasible attack models in label-only black-box scenarios, to the best of our knowledge. In this paper, we develop a novel method of MIA using the conditional diffusion model to recover the precise sample of the target without any extra optimization, as long as the target model outputs the label. Two primary techniques are introduced to execute the attack. Firstly, select an auxiliary dataset that is relevant to the target model task, and the labels predicted by the target model are used as conditions to guide the training process. Secondly, target labels and random standard normally distributed noise are input into the trained conditional diffusion model, generating target samples with pre-defined guidance strength. We then filter out the most robust and representative samples. Furthermore, we propose for the first time to use Learned Perceptual Image Patch Similarity (LPIPS) as one of the evaluation metrics for MIA, with systematic quantitative and qualitative evaluation in terms of attack accuracy, realism, and similarity. Experimental results show that this method can generate similar and accurate data to the target without optimization and outperforms generators of previous approaches in the label-only scenario.", "url": "https://arxiv.org/abs/2307.08424"}, {"metadata": {"arXiv": "2307.08430", "Date": "Mon, 17 Jul 2023 12:20:07 ", "Title": "Long-range Dependency based Multi-Layer Perceptron for Heterogeneous Information Networks", "Authors": ["Chao Li", "Zijie Guo", "Qiuting He", "Hao Xu and Kun He"], "Categories": "cs.AI", "Comments": ["12 pages", "3 figures"]}, "abstract": "Existing heterogeneous graph neural networks (HGNNs) have achieved great success in utilizing the rich semantic information in heterogeneous information networks (HINs). However, few works have delved into the utilization of long-range dependencies in HINs, which is extremely valuable as many real-world HINs are sparse, and each node has only a few directly connected neighbors. Although some HGNNs can utilize distant neighbors by stacking multiple layers or leveraging long meta-paths, the exponentially increased number of nodes in the receptive field or the number of meta-paths incurs high computation and memory costs. To address these issues, we investigate the importance of different meta-paths and propose Long-range Dependency based Multi-Layer Perceptron (LDMLP). Specifically, to solve the high-cost problem of leveraging long-range dependencies, LDMLP adopts a search stage to discover effective meta-paths automatically, reducing the exponentially increased number of meta-paths to a constant. To avoid the influence of specific modules on search results, LDMLP utilizes a simple architecture with only multi-layer perceptions in the search stage, improving the generalization of searched meta-paths. As a result, the searched meta-paths not only perform well in LDMLP but also enable other HGNNs like HAN and SeHGNN to perform better. Extensive experiments on eight heterogeneous datasets demonstrate that LDMLP achieves state-of-the-art performance while enjoying high efficiency and generalization, especially on sparse HINs.", "url": "https://arxiv.org/abs/2307.08430"}, {"metadata": {"arXiv": "2307.08461", "Date": "Mon, 17 Jul 2023 13:06:33 ", "Title": "Towards eXplainable AI for Mobility Data Science", "Authors": ["Anahid Jalali", "Anita Graser", "Clemens Heistracher"], "Categories": "cs.AI", "Comments": ["4 pages"], "ACM-class": "F.2.2"}, "abstract": "This paper presents our ongoing work towards XAI for Mobility Data Science applications, focusing on explainable models that can learn from dense trajectory data, such as GPS tracks of vehicles and vessels using temporal graph neural networks (GNNs) and counterfactuals. We review the existing GeoXAI studies, argue the need for comprehensible explanations with human-centered approaches, and outline a research path toward XAI for Mobility Data Science.", "url": "https://arxiv.org/abs/2307.08461"}, {"metadata": {"arXiv": "2307.08484", "Date": "Mon, 17 Jul 2023 13:45:47 ", "Title": "Navigating Fairness Measures and Trade-Offs", "Authors": ["Stefan Buijsman"], "Categories": "cs.AI"}, "abstract": "In order to monitor and prevent bias in AI systems we can use a wide range of (statistical) fairness measures. However, it is mathematically impossible to optimize for all of these measures at the same time. In addition, optimizing a fairness measure often greatly reduces the accuracy of the system (Kozodoi et al, 2022). As a result, we need a substantive theory that informs us how to make these decisions and for what reasons. I show that by using Rawls' notion of justice as fairness, we can create a basis for navigating fairness measures and the accuracy trade-off. In particular, this leads to a principled choice focusing on both the most vulnerable groups and the type of fairness measure that has the biggest impact on that group. This also helps to close part of the gap between philosophical accounts of distributive justice and the fairness literature that has been observed (Kuppler et al, 2021) and to operationalise the value of fairness.", "url": "https://arxiv.org/abs/2307.08484"}, {"metadata": {"arXiv": "2307.08598", "Date": "Mon, 17 Jul 2023 16:09:24 ", "Title": "Glamour muscles: why having a body is not what it means to be embodied", "Authors": ["Shawn L. Beaulieu and Sam Kriegman"], "Categories": "cs.AI cs.RO"}, "abstract": "Embodiment has recently enjoyed renewed consideration as a means to amplify the faculties of smart machines. Proponents of embodiment seem to imply that optimizing for movement in physical space promotes something more than the acquisition of niche capabilities for solving problems in physical space. However, there is nothing in principle which should so distinguish the problem of action selection in physical space from the problem of action selection in more abstract spaces, like that of language. Rather, what makes embodiment persuasive as a means toward higher intelligence is that it promises to capture, but does not actually realize, contingent facts about certain bodies (living intelligence) and the patterns of activity associated with them. These include an active resistance to annihilation and revisable constraints on the processes that make the world intelligible. To be theoretically or practically useful beyond the creation of niche tools, we argue that \"embodiment\" cannot be the trivial fact of a body, nor its movement through space, but the perpetual negotiation of the function, design, and integrity of that body$\\unicode{x2013}$that is, to participate in what it means to $\\textit{constitute}$ a given body. It follows that computer programs which are strictly incapable of traversing physical space might, under the right conditions, be more embodied than a walking, talking robot.", "url": "https://arxiv.org/abs/2307.08598"}, {"metadata": {"arXiv": "2307.08663", "Date": "Mon, 17 Jul 2023 17:27:06 ", "Title": "Quaternion Convolutional Neural Networks: Current Advances and Future Directions", "Authors": ["Gerardo Altamirano-Gomez and Carlos Gershenson"], "Categories": "cs.AI cs.CV", "ACM-class": "I.2.0; I.4.0; I.2.7"}, "abstract": "Since their first applications, Convolutional Neural Networks (CNNs) have solved problems that have advanced the state-of-the-art in several domains. CNNs represent information using real numbers. Despite encouraging results, theoretical analysis shows that representations such as hyper-complex numbers can achieve richer representational capacities than real numbers, and that Hamilton products can capture intrinsic interchannel relationships. Moreover, in the last few years, experimental research has shown that Quaternion-Valued CNNs (QCNNs) can achieve similar performance with fewer parameters than their real-valued counterparts. This paper condenses research in the development of QCNNs from its very beginnings. We propose a conceptual organization of current trends and analyze the main building blocks used in the design of QCNN models. Based on this conceptual organization, we propose future directions of research.", "url": "https://arxiv.org/abs/2307.08663"}, {"metadata": {"arXiv": "2307.08700", "Date": "Mon, 17 Jul 2023 17:59:09 ", "Title": "Fast model inference and training on-board of Satellites", "Authors": ["V\\'it R\\r{u}\\v{z}i\\v{c}ka", "Gonzalo Mateo-Garc\\'ia", "Chris Bridges", "Chris Brunskill", "Cormac Purcell", "Nicolas Long\\'ep\\'e", "Andrew Markham"], "Categories": "cs.AI cs.CV", "Comments": ["4 pages", "4 figures", "International Geoscience and Remote Sensing Symposium (IGARSS) 2023"]}, "abstract": "Artificial intelligence onboard satellites has the potential to reduce data transmission requirements, enable real-time decision-making and collaboration within constellations. This study deploys a lightweight foundational model called RaVAEn on D-Orbit's ION SCV004 satellite. RaVAEn is a variational auto-encoder (VAE) that generates compressed latent vectors from small image tiles, enabling several downstream tasks. In this work we demonstrate the reliable use of RaVAEn onboard a satellite, achieving an encoding time of 0.110s for tiles of a 4.8x4.8 km$^2$ area. In addition, we showcase fast few-shot training onboard a satellite using the latent representation of data. We compare the deployment of the model on the on-board CPU and on the available Myriad vision processing unit (VPU) accelerator. To our knowledge, this work shows for the first time the deployment of a multi-task model on-board a CubeSat and the on-board training of a machine learning model.", "url": "https://arxiv.org/abs/2307.08700"}, {"metadata": {"arXiv": "2307.07662", "Date": "Fri, 14 Jul 2023 23:54:49 ", "Title": "MPDIoU: A Loss for Efficient and Accurate Bounding Box Regression", "Authors": ["Ma Siliang", "Xu Yong"], "Categories": "cs.CV cs.AI", "Comments": ["13 pages", "9 figures. arXiv admin note: text overlap with arXiv:1902.09630 by other authors"]}, "abstract": "Bounding box regression (BBR) has been widely used in object detection and instance segmentation, which is an important step in object localization. However, most of the existing loss functions for bounding box regression cannot be optimized when the predicted box has the same aspect ratio as the groundtruth box, but the width and height values are exactly different. In order to tackle the issues mentioned above, we fully explore the geometric features of horizontal rectangle and propose a novel bounding box similarity comparison metric MPDIoU based on minimum point distance, which contains all of the relevant factors considered in the existing loss functions, namely overlapping or non-overlapping area, central points distance, and deviation of width and height, while simplifying the calculation process. On this basis, we propose a bounding box regression loss function based on MPDIoU, called LMPDIoU . Experimental results show that the MPDIoU loss function is applied to state-of-the-art instance segmentation (e.g., YOLACT) and object detection (e.g., YOLOv7) model trained on PASCAL VOC, MS COCO, and IIIT5k outperforms existing loss functions.", "url": "https://arxiv.org/abs/2307.07662"}, {"metadata": {"arXiv": "2307.07691", "Date": "Sat, 15 Jul 2023 03:04:35 ", "Title": "A Survey on Change Detection Techniques in Document Images", "Authors": ["Abhinandan Kumar Pun and Mohammed Javed and David S. Doermann"], "Categories": "cs.CV cs.AI", "Comments": ["Submitted to International Conference on Computer Vision and Machine Intelligence (CVMI) 2023"]}, "abstract": "The problem of change detection in images finds application in different domains like diagnosis of diseases in the medical field, detecting growth patterns of cities through remote sensing, and finding changes in legal documents and contracts. However, this paper presents a survey on core techniques and rules to detect changes in different versions of a document image. Our discussions on change detection focus on two categories -- content-based and layout-based. The content-based techniques intelligently extract and analyze the image contents (text or non-text) to show the possible differences, whereas the layout-based techniques use structural information to predict document changes. We also summarize the existing datasets and evaluation metrics used in change detection experiments. The shortcomings and challenges the existing methods face are reported, along with some pointers for future research work.", "url": "https://arxiv.org/abs/2307.07691"}, {"metadata": {"arXiv": "2307.07742", "Date": "Sat, 15 Jul 2023 08:33:08 ", "Title": "SINC: Self-Supervised In-Context Learning for Vision-Language Tasks", "Authors": ["Yi-Syuan Chen", "Yun-Zhu Song", "Cheng Yu Yeo", "Bei Liu", "Jianlong Fu", "Hong-Han Shuai"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted by ICCV 2023; Preprint"]}, "abstract": "Large Pre-trained Transformers exhibit an intriguing capacity for in-context learning. Without gradient updates, these models can rapidly construct new predictors from demonstrations presented in the inputs. Recent works promote this ability in the vision-language domain by incorporating visual information into large language models that can already make in-context predictions. However, these methods could inherit issues in the language domain, such as template sensitivity and hallucination. Also, the scale of these language models raises a significant demand for computations, making learning and operating these models resource-intensive. To this end, we raise a question: ``How can we enable in-context learning for general models without being constrained on large language models?\". To answer it, we propose a succinct and general framework, Self-supervised IN-Context learning (SINC), that introduces a meta-model to learn on self-supervised prompts consisting of tailored demonstrations. The learned models can be transferred to downstream tasks for making in-context predictions on-the-fly. Extensive experiments show that SINC outperforms gradient-based methods in various vision-language tasks under few-shot settings. Furthermore, the designs of SINC help us investigate the benefits of in-context learning across different tasks, and the analysis further reveals the essential components for the emergence of in-context learning in the vision-language domain.", "url": "https://arxiv.org/abs/2307.07742"}, {"metadata": {"arXiv": "2307.07754", "Date": "Sat, 15 Jul 2023 09:24:45 ", "Title": "Bidirectionally Deformable Motion Modulation For Video-based Human Pose Transfer", "Authors": ["Wing-Yin Yu", "Lai-Man Po", "Ray Cheung", "Yuzhi Zhao", "Yu Xue", "Kun Li"], "Categories": "cs.CV cs.AI", "Comments": ["ICCV 2023"]}, "abstract": "Video-based human pose transfer is a video-to-video generation task that animates a plain source human image based on a series of target human poses. Considering the difficulties in transferring highly structural patterns on the garments and discontinuous poses, existing methods often generate unsatisfactory results such as distorted textures and flickering artifacts. To address these issues, we propose a novel Deformable Motion Modulation (DMM) that utilizes geometric kernel offset with adaptive weight modulation to simultaneously perform feature alignment and style transfer. Different from normal style modulation used in style transfer, the proposed modulation mechanism adaptively reconstructs smoothed frames from style codes according to the object shape through an irregular receptive field of view. To enhance the spatio-temporal consistency, we leverage bidirectional propagation to extract the hidden motion information from a warped image sequence generated by noisy poses. The proposed feature propagation significantly enhances the motion prediction ability by forward and backward propagation. Both quantitative and qualitative experimental results demonstrate superiority over the state-of-the-arts in terms of image fidelity and visual continuity. The source code is publicly available at github.com/rocketappslab/bdmm.", "url": "https://arxiv.org/abs/2307.07754"}, {"metadata": {"arXiv": "2307.08016", "Date": "Sun, 16 Jul 2023 11:54:16 ", "Title": "Breaking Down the Task: A Unit-Grained Hybrid Training Framework for Vision and Language Decision Making", "Authors": ["Ruipu Luo", "Jiwen Zhang", "Zhongyu Wei"], "Categories": "cs.CV cs.AI"}, "abstract": "Vision language decision making (VLDM) is a challenging multimodal task. The agent have to understand complex human instructions and complete compositional tasks involving environment navigation and object manipulation. However, the long action sequences involved in VLDM make the task difficult to learn. From an environment perspective, we find that task episodes can be divided into fine-grained \\textit{units}, each containing a navigation phase and an interaction phase. Since the environment within a unit stays unchanged, we propose a novel hybrid-training framework that enables active exploration in the environment and reduces the exposure bias. Such framework leverages the unit-grained configurations and is model-agnostic. Specifically, we design a Unit-Transformer (UT) with an intrinsic recurrent state that maintains a unit-scale cross-modal memory. Through extensive experiments on the TEACH benchmark, we demonstrate that our proposed framework outperforms existing state-of-the-art methods in terms of all evaluation metrics. Overall, our work introduces a novel approach to tackling the VLDM task by breaking it down into smaller, manageable units and utilizing a hybrid-training framework. By doing so, we provide a more flexible and effective solution for multimodal decision making.", "url": "https://arxiv.org/abs/2307.08016"}, {"metadata": {"arXiv": "2307.08233", "Date": "Mon, 17 Jul 2023 04:25:46 ", "Title": "ROFusion: Efficient Object Detection using Hybrid Point-wise Radar-Optical Fusion", "Authors": ["Liu Liu", "Shuaifeng Zhi", "Zhenhua Du", "Li Liu", "Xinyu Zhang", "Kai Huo", "and Weidong Jiang"], "Categories": "cs.CV cs.AI"}, "abstract": "Radars, due to their robustness to adverse weather conditions and ability to measure object motions, have served in autonomous driving and intelligent agents for years. However, Radar-based perception suffers from its unintuitive sensing data, which lack of semantic and structural information of scenes. To tackle this problem, camera and Radar sensor fusion has been investigated as a trending strategy with low cost, high reliability and strong maintenance. While most recent works explore how to explore Radar point clouds and images, rich contextual information within Radar observation are discarded. In this paper, we propose a hybrid point-wise Radar-Optical fusion approach for object detection in autonomous driving scenarios. The framework benefits from dense contextual information from both the range-doppler spectrum and images which are integrated to learn a multi-modal feature representation. Furthermore, we propose a novel local coordinate formulation, tackling the object detection task in an object-centric coordinate. Extensive results show that with the information gained from optical images, we could achieve leading performance in object detection (97.69\\% recall) compared to recent state-of-the-art methods FFT-RadNet (82.86\\% recall). Ablation studies verify the key design choices and practicability of our approach given machine generated imperfect detections. The code will be available at https://github.com/LiuLiu-55/ROFusion.", "url": "https://arxiv.org/abs/2307.08233"}, {"metadata": {"arXiv": "2307.08300", "Date": "Mon, 17 Jul 2023 07:53:23 ", "Title": "ShiftNAS: Improving One-shot NAS via Probability Shift", "Authors": ["Mingyang Zhang", "Xinyi Yu", "Haodong Zhao", "Linlin Ou"], "Categories": "cs.CV cs.AI", "Comments": ["accepted by iccv 2023"]}, "abstract": "One-shot Neural architecture search (One-shot NAS) has been proposed as a time-efficient approach to obtain optimal subnet architectures and weights under different complexity cases by training only once. However, the subnet performance obtained by weight sharing is often inferior to the performance achieved by retraining. In this paper, we investigate the performance gap and attribute it to the use of uniform sampling, which is a common approach in supernet training. Uniform sampling concentrates training resources on subnets with intermediate computational resources, which are sampled with high probability. However, subnets with different complexity regions require different optimal training strategies for optimal performance. To address the problem of uniform sampling, we propose ShiftNAS, a method that can adjust the sampling probability based on the complexity of subnets. We achieve this by evaluating the performance variation of subnets with different complexity and designing an architecture generator that can accurately and efficiently provide subnets with the desired complexity. Both the sampling probability and the architecture generator can be trained end-to-end in a gradient-based manner. With ShiftNAS, we can directly obtain the optimal model architecture and parameters for a given computational complexity. We evaluate our approach on multiple visual network models, including convolutional neural networks (CNNs) and vision transformers (ViTs), and demonstrate that ShiftNAS is model-agnostic. Experimental results on ImageNet show that ShiftNAS can improve the performance of one-shot NAS without additional consumption. Source codes are available at https://github.com/bestfleer/ShiftNAS.", "url": "https://arxiv.org/abs/2307.08300"}, {"metadata": {"arXiv": "2307.08308", "Date": "Mon, 17 Jul 2023 08:05:30 ", "Title": "A Novel Multi-Task Model Imitating Dermatologists for Accurate Differential Diagnosis of Skin Diseases in Clinical Images", "Authors": ["Yan-Jie Zhou", "Wei Liu", "Yuan Gao", "Jing Xu", "Le Lu", "Yuping Duan", "Hao Cheng", "Na Jin", "Xiaoyong Man", "Shuang Zhao", "Yu Wang"], "Categories": "cs.CV cs.AI", "Comments": ["MICCAI 2023 early accept"]}, "abstract": "Skin diseases are among the most prevalent health issues, and accurate computer-aided diagnosis methods are of importance for both dermatologists and patients. However, most of the existing methods overlook the essential domain knowledge required for skin disease diagnosis. A novel multi-task model, namely DermImitFormer, is proposed to fill this gap by imitating dermatologists' diagnostic procedures and strategies. Through multi-task learning, the model simultaneously predicts body parts and lesion attributes in addition to the disease itself, enhancing diagnosis accuracy and improving diagnosis interpretability. The designed lesion selection module mimics dermatologists' zoom-in action, effectively highlighting the local lesion features from noisy backgrounds. Additionally, the presented cross-interaction module explicitly models the complicated diagnostic reasoning between body parts, lesion attributes, and diseases. To provide a more robust evaluation of the proposed method, a large-scale clinical image dataset of skin diseases with significantly more cases than existing datasets has been established. Extensive experiments on three different datasets consistently demonstrate the state-of-the-art recognition performance of the proposed approach.", "url": "https://arxiv.org/abs/2307.08308"}, {"metadata": {"arXiv": "2307.08339", "Date": "Mon, 17 Jul 2023 09:26:13 ", "Title": "Multi-Task Cross-Modality Attention-Fusion for 2D Object Detection", "Authors": ["Huawei Sun", "Hao Feng", "Georg Stettinger", "Lorenzo Servadei", "Robert Wille"], "Categories": "cs.CV cs.AI cs.MM", "Comments": ["Accepted by ITSC 2023"]}, "abstract": "Accurate and robust object detection is critical for autonomous driving. Image-based detectors face difficulties caused by low visibility in adverse weather conditions. Thus, radar-camera fusion is of particular interest but presents challenges in optimally fusing heterogeneous data sources. To approach this issue, we propose two new radar preprocessing techniques to better align radar and camera data. In addition, we introduce a Multi-Task Cross-Modality Attention-Fusion Network (MCAF-Net) for object detection, which includes two new fusion blocks. These allow for exploiting information from the feature maps more comprehensively. The proposed algorithm jointly detects objects and segments free space, which guides the model to focus on the more relevant part of the scene, namely, the occupied space. Our approach outperforms current state-of-the-art radar-camera fusion-based object detectors in the nuScenes dataset and achieves more robust results in adverse weather conditions and nighttime scenarios.", "url": "https://arxiv.org/abs/2307.08339"}, {"metadata": {"arXiv": "2307.08581", "Date": "Mon, 17 Jul 2023 15:51:47 ", "Title": "BuboGPT: Enabling Visual Grounding in Multi-Modal LLMs", "Authors": ["Yang Zhao", "Zhijie Lin", "Daquan Zhou", "Zilong Huang", "Jiashi Feng", "Bingyi Kang"], "Categories": "cs.CV cs.AI"}, "abstract": "LLMs have demonstrated remarkable abilities at interacting with humans through language, especially with the usage of instruction-following data. Recent advancements in LLMs, such as MiniGPT-4, LLaVA, and X-LLM, further enlarge their abilities by incorporating multi-modal inputs, including image, video, and speech. Despite their effectiveness at generating precise and detailed language understanding of the given modality signal, these LLMs give up the ability to ground specific parts of inputs, thus only constructing a coarse-grained mapping. However, explicit and informative correspondence between text and other modalities will not only improve the user experience but also help to expand the application scenario of multi-modal LLMs. Therefore, we propose BuboGPT, a multi-modal LLM with visual grounding that can perform cross-modal interaction between vision, audio and language, providing fine-grained understanding of visual objects and other given modalities. As a result, BuboGPT is able to point out the specific location of an object in the image, when it is generating response or description for that object. Our contributions are two-fold: 1) An off-the-shelf visual grounding module based on SAM that extracts entities in a sentence and find corresponding masks in the image. 2) A two-stage training scheme and instruction dataset to endow joint text-image-audio understanding. Our experiments show that BuboGPT achieves impressive multi-modality understanding and visual grounding abilities during the interaction with human. It performs consistently well when provided by arbitrary modality combinations (either aligned or unaligned). Our code, model and dataset are available at https://bubo-gpt.github.io .", "url": "https://arxiv.org/abs/2307.08581"}, {"metadata": {"arXiv": "2307.08699", "Date": "Mon, 17 Jul 2023 17:58:37 ", "Title": "Pair then Relation: Pair-Net for Panoptic Scene Graph Generation", "Authors": ["Jinghao Wang", "Zhengyu Wen", "Xiangtai Li", "Zujin Guo", "Jingkang Yang", "Ziwei Liu"], "Categories": "cs.CV cs.AI", "Comments": ["Project Page: https://github.com/king159/Pair-Net"]}, "abstract": "Panoptic Scene Graph (PSG) is a challenging task in Scene Graph Generation (SGG) that aims to create a more comprehensive scene graph representation using panoptic segmentation instead of boxes. However, current PSG methods have limited performance, which can hinder downstream task development. To improve PSG methods, we conducted an in-depth analysis to identify the bottleneck of the current PSG models, finding that inter-object pair-wise recall is a crucial factor which was ignored by previous PSG methods. Based on this, we present a novel framework: Pair then Relation (Pair-Net), which uses a Pair Proposal Network (PPN) to learn and filter sparse pair-wise relationships between subjects and objects. We also observed the sparse nature of object pairs and used this insight to design a lightweight Matrix Learner within the PPN. Through extensive ablation and analysis, our approach significantly improves upon leveraging the strong segmenter baseline. Notably, our approach achieves new state-of-the-art results on the PSG benchmark, with over 10% absolute gains compared to PSGFormer. The code of this paper is publicly available at https://github.com/king159/Pair-Net.", "url": "https://arxiv.org/abs/2307.08699"}, {"metadata": {"arXiv": "2307.07752", "Date": "Sat, 15 Jul 2023 09:22:37 ", "Title": "Combining model-predictive control and predictive reinforcement learning for stable quadrupedal robot locomotion", "Authors": ["Vyacheslav Kovalev", "Anna Shkromada", "Henni Ouerdane and Pavel Osinenko"], "Categories": "cs.RO cs.AI cs.SY eess.SY"}, "abstract": "Stable gait generation is a crucial problem for legged robot locomotion as this impacts other critical performance factors such as, e.g. mobility over an uneven terrain and power consumption. Gait generation stability results from the efficient control of the interaction between the legged robot's body and the environment where it moves. Here, we study how this can be achieved by a combination of model-predictive and predictive reinforcement learning controllers. Model-predictive control (MPC) is a well-established method that does not utilize any online learning (except for some adaptive variations) as it provides a convenient interface for state constraints management. Reinforcement learning (RL), in contrast, relies on adaptation based on pure experience. In its bare-bone variants, RL is not always suitable for robots due to their high complexity and expensive simulation/experimentation. In this work, we combine both control methods to address the quadrupedal robot stable gate generation problem. The hybrid approach that we develop and apply uses a cost roll-out algorithm with a tail cost in the form of a Q-function modeled by a neural network; this allows to alleviate the computational complexity, which grows exponentially with the prediction horizon in a purely MPC approach. We demonstrate that our RL gait controller achieves stable locomotion at short horizons, where a nominal MP controller fails. Further, our controller is capable of live operation, meaning that it does not require previous training. Our results suggest that the hybridization of MPC with RL, as presented here, is beneficial to achieve a good balance between online control capabilities and computational complexity.", "url": "https://arxiv.org/abs/2307.07752"}, {"metadata": {"arXiv": "2307.07857", "Date": "Sat, 15 Jul 2023 17:33:06 ", "Title": "A Multi-Heuristic Search-based Motion Planning for Automated Parking", "Authors": ["Bhargav Adabala", "Zlatan Ajanovi\\'c"], "Categories": "cs.RO cs.AI", "Comments": ["Presented at IEEE ICAT 2023 conference", "8 pages", "15 figures"], "DOI": "10.1109/ICAT57854.2023.10171306"}, "abstract": "In unstructured environments like parking lots or construction sites, due to the large search-space and kinodynamic constraints of the vehicle, it is challenging to achieve real-time planning. Several state-of-the-art planners utilize heuristic search-based algorithms. However, they heavily rely on the quality of the single heuristic function, used to guide the search. Therefore, they are not capable to achieve reasonable computational performance, resulting in unnecessary delays in the response of the vehicle. In this work, we are adopting a Multi-Heuristic Search approach, that enables the use of multiple heuristic functions and their individual advantages to capture different complexities of a given search space. Based on our knowledge, this approach was not used previously for this problem. For this purpose, multiple admissible and non-admissible heuristic functions are defined, the original Multi-Heuristic A* Search was extended for bidirectional use and dealing with hybrid continuous-discrete search space, and a mechanism for adapting scale of motion primitives is introduced. To demonstrate the advantage, the Multi-Heuristic A* algorithm is benchmarked against a very popular heuristic search-based algorithm, Hybrid A*. The Multi-Heuristic A* algorithm outperformed baseline in both terms, computation efficiency and motion plan (path) quality.", "url": "https://arxiv.org/abs/2307.07857"}, {"metadata": {"arXiv": "2307.08141", "Date": "Sun, 16 Jul 2023 19:44:27 ", "Title": "POA: Passable Obstacles Aware Path-planning Algorithm for Navigation of a Two-wheeled Robot in Highly Cluttered Environments", "Authors": ["Alexander Petrovsky", "Yomna Youssef", "Kirill Myasoedov", "Artem Timoshenko", "Vladimir Guneavoi", "Ivan Kalinov", "and Dzmitry Tsetserukou"], "Categories": "cs.RO cs.AI", "Comments": ["Accepted to the 2023 IEEE Conference on Systems", "Man", "and Cybernetics"]}, "abstract": "This paper focuses on Passable Obstacles Aware (POA) planner - a novel navigation method for two-wheeled robots in a highly cluttered environment. The navigation algorithm detects and classifies objects to distinguish two types of obstacles - passable and unpassable. Our algorithm allows two-wheeled robots to find a path through passable obstacles. Such a solution helps the robot working in areas inaccessible to standard path planners and find optimal trajectories in scenarios with a high number of objects in the robot's vicinity. The POA planner can be embedded into other planning algorithms and enables them to build a path through obstacles. Our method decreases path length and the total travel time to the final destination up to 43% and 39%, respectively, comparing to standard path planners such as GVD, A*, and RRT*", "url": "https://arxiv.org/abs/2307.08141"}, {"metadata": {"arXiv": "2307.08471", "Date": "Mon, 17 Jul 2023 13:26:44 ", "Title": "Clarifying the Half Full or Half Empty Question: Multimodal Container Classification", "Authors": ["Josua Spisak", "Matthias Kerzel", "and Stefan Wermter"], "Categories": "cs.RO cs.AI", "Comments": ["Preprint for ICANN 2023"]}, "abstract": "Multimodal integration is a key component of allowing robots to perceive the world. Multimodality comes with multiple challenges that have to be considered, such as how to integrate and fuse the data. In this paper, we compare different possibilities of fusing visual, tactile and proprioceptive data. The data is directly recorded on the NICOL robot in an experimental setup in which the robot has to classify containers and their content. Due to the different nature of the containers, the use of the modalities can wildly differ between the classes. We demonstrate the superiority of multimodal solutions in this use case and evaluate three fusion strategies that integrate the data at different time steps. We find that the accuracy of the best fusion strategy is 15% higher than the best strategy using only one singular sense.", "url": "https://arxiv.org/abs/2307.08471"}, {"metadata": {"arXiv": "2307.07513", "Date": "Tue, 20 Jun 2023 15:43:28 ", "Title": "An empirical study of using radiology reports and images to improve ICU mortality prediction", "Authors": ["Mingquan Lin", "Song Wang", "Ying Ding", "Lihui Zhao", "Fei Wang", "Yifan Peng"], "Categories": "cs.AI cs.CL cs.CV cs.LG eess.IV", "Comments": ["21 pages", "5 figures", "7 tables"]}, "abstract": "Background: The predictive Intensive Care Unit (ICU) scoring system plays an important role in ICU management because it predicts important outcomes, especially mortality. Many scoring systems have been developed and used in the ICU. These scoring systems are primarily based on the structured clinical data in the electronic health record (EHR), which may suffer the loss of important clinical information in the narratives and images. Methods: In this work, we build a deep learning based survival prediction model with multi-modality data to predict ICU mortality. Four sets of features are investigated: (1) physiological measurements of Simplified Acute Physiology Score (SAPS) II, (2) common thorax diseases pre-defined by radiologists, (3) BERT-based text representations, and (4) chest X-ray image features. We use the Medical Information Mart for Intensive Care IV (MIMIC-IV) dataset to evaluate the proposed model. Results: Our model achieves the average C-index of 0.7829 (95% confidence interval, 0.7620-0.8038), which substantially exceeds that of the baseline with SAPS-II features (0.7470 (0.7263-0.7676)). Ablation studies further demonstrate the contributions of pre-defined labels (2.00%), text features (2.44%), and image features (2.82%).", "url": "https://arxiv.org/abs/2307.07513"}, {"metadata": {"arXiv": "2307.07514", "Date": "Tue, 27 Jun 2023 09:32:49 ", "Title": "Explainability is NOT a Game", "Authors": ["Joao Marques-Silva and Xuanxiang Huang"], "Categories": "cs.AI cs.LG"}, "abstract": "Explainable artificial intelligence (XAI) aims to help human decision-makers in understanding complex machine learning (ML) models. One of the hallmarks of XAI are measures of relative feature importance, which are theoretically justified through the use of Shapley values. This paper builds on recent work and offers a simple argument for why Shapley values can provide misleading measures of relative feature importance, by assigning more importance to features that are irrelevant for a prediction, and assigning less importance to features that are relevant for a prediction. The significance of these results is that they effectively challenge the many proposed uses of measures of relative feature importance in a fast-growing range of high-stakes application domains.", "url": "https://arxiv.org/abs/2307.07514"}, {"metadata": {"arXiv": "2307.07522", "Date": "Sun, 09 Jul 2023 21:16:56 ", "Title": "The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence", "Authors": ["Hector Zenil", "Jesper Tegn\\'er", "Felipe S. Abrah\\~ao", "Alexander Lavin", "Vipin Kumar", "Jeremy G. Frey", "Adrian Weller", "Larisa Soldatova", "Alan R. Bundy", "Nicholas R. Jennings", "Koichi Takahashi", "Lawrence Hunter", "Saso Dzeroski", "Andrew Briggs", "Frederick D. Gregory", "Carla P. Gomes", "Christopher K. I. Williams", "Jon Rowe", "James Evans", "Hiroaki Kitano", "Joshua B. Tenenbaum", "Ross King"], "Categories": "cs.AI cs.LG", "Comments": ["35 pages", "first draft of the final report from the Alan Turing Institute on AI for Scientific Discovery"]}, "abstract": "Recent advances in machine learning and AI, including Generative AI and LLMs, are disrupting technological innovation, product development, and society as a whole. AI's contribution to technology can come from multiple approaches that require access to large training data sets and clear performance evaluation criteria, ranging from pattern recognition and classification to generative models. Yet, AI has contributed less to fundamental science in part because large data sets of high-quality data for scientific practice and model discovery are more difficult to access. Generative AI, in general, and Large Language Models in particular, may represent an opportunity to augment and accelerate the scientific discovery of fundamental deep science with quantitative models. Here we explore and investigate aspects of an AI-driven, automated, closed-loop approach to scientific discovery, including self-driven hypothesis generation and open-ended autonomous exploration of the hypothesis space. Integrating AI-driven automation into the practice of science would mitigate current problems, including the replication of findings, systematic production of data, and ultimately democratisation of the scientific process. Realising these possibilities requires a vision for augmented AI coupled with a diversity of AI approaches able to deal with fundamental aspects of causality analysis and model discovery while enabling unbiased search across the space of putative explanations. These advances hold the promise to unleash AI's potential for searching and discovering the fundamental structure of our world beyond what human scientists have been able to achieve. Such a vision would push the boundaries of new fundamental science rather than automatize current workflows and instead open doors for technological innovation to tackle some of the greatest challenges facing humanity today.", "url": "https://arxiv.org/abs/2307.07522"}, {"metadata": {"arXiv": "2307.07700", "Date": "Sat, 15 Jul 2023 04:03:17 ", "Title": "NeurASP: Embracing Neural Networks into Answer Set Programming", "Authors": ["Zhun Yang", "Adam Ishay", "Joohyung Lee"], "Categories": "cs.AI cs.LG cs.SC", "Comments": ["16 pages", "29th International Joint Conference on Artificial Intelligence (IJCAI 2020). arXiv admin note: substantial text overlap with arXiv:2009.10256"]}, "abstract": "We present NeurASP, a simple extension of answer set programs by embracing neural networks. By treating the neural network output as the probability distribution over atomic facts in answer set programs, NeurASP provides a simple and effective way to integrate sub-symbolic and symbolic computation. We demonstrate how NeurASP can make use of a pre-trained neural network in symbolic computation and how it can improve the neural network's perception result by applying symbolic reasoning in answer set programming. Also, NeurASP can be used to train a neural network better by training with ASP rules so that a neural network not only learns from implicit correlations from the data but also from the explicit complex semantic constraints expressed by the rules.", "url": "https://arxiv.org/abs/2307.07700"}, {"metadata": {"arXiv": "2307.07871", "Date": "Sat, 15 Jul 2023 19:05:56 ", "Title": "The SocialAI School: Insights from Developmental Psychology Towards Artificial Socio-Cultural Agents", "Authors": ["Grgur Kova\\v{c}", "R\\'emy Portelas", "Peter Ford Dominey", "Pierre-Yves Oudeyer"], "Categories": "cs.AI cs.LG", "Comments": ["Accepted at the \"Workshop on Theory-of-Mind\" at ICML 2023"], "MSC-class": "68T07", "ACM-class": "I.2.0"}, "abstract": "Developmental psychologists have long-established the importance of socio-cognitive abilities in human intelligence. These abilities enable us to enter, participate and benefit from human culture. AI research on social interactive agents mostly concerns the emergence of culture in a multi-agent setting (often without a strong grounding in developmental psychology). We argue that AI research should be informed by psychology and study socio-cognitive abilities enabling to enter a culture too. We discuss the theories of Michael Tomasello and Jerome Bruner to introduce some of their concepts to AI and outline key concepts and socio-cognitive abilities. We present The SocialAI school - a tool including a customizable parameterized uite of procedurally generated environments, which simplifies conducting experiments regarding those concepts. We show examples of such experiments with RL agents and Large Language Models. The main motivation of this work is to engage the AI community around the problem of social intelligence informed by developmental psychology, and to provide a tool to simplify first steps in this direction. Refer to the project website for code and additional information: https://sites.google.com/view/socialai-school.", "url": "https://arxiv.org/abs/2307.07871"}, {"metadata": {"arXiv": "2307.08411", "Date": "Mon, 17 Jul 2023 11:47:05 ", "Title": "Neurosymbolic AI for Reasoning on Biomedical Knowledge Graphs", "Authors": ["Lauren Nicole DeLong", "Ramon Fern\\'andez Mir", "Zonglin Ji", "Fiona Niamh Coulter Smith", "Jacques D. Fleuriot"], "Categories": "cs.AI cs.LG cs.LO", "Comments": ["Proceedings of the $\\mathit{40}^{th}$ International Conference on Machine Learning: Workshop on Knowledge and Logical Reasoning in the Era of Data-driven Learning (https://klr-icml2023.github.io/schedule.html). PMLR 202", "2023. Condensed", "workshop-ready version of previous survey", "arXiv:2302.07200 ", "which is under review. 13 pages (9 content", "4 references)", "3 figures", "1 table"]}, "abstract": "Biomedical datasets are often modeled as knowledge graphs (KGs) because they capture the multi-relational, heterogeneous, and dynamic natures of biomedical systems. KG completion (KGC), can, therefore, help researchers make predictions to inform tasks like drug repositioning. While previous approaches for KGC were either rule-based or embedding-based, hybrid approaches based on neurosymbolic artificial intelligence are becoming more popular. Many of these methods possess unique characteristics which make them even better suited toward biomedical challenges. Here, we survey such approaches with an emphasis on their utilities and prospective benefits for biomedicine.", "url": "https://arxiv.org/abs/2307.08411"}, {"metadata": {"arXiv": "2307.08674", "Date": "Mon, 17 Jul 2023 17:36:09 ", "Title": "TableGPT: Towards Unifying Tables, Nature Language and Commands into One GPT", "Authors": ["Liangyu Zha", "Junlin Zhou", "Liyao Li", "Rui Wang", "Qingyi Huang", "Saisai Yang", "Jing Yuan", "Changbao Su", "Xiang Li", "Aofeng Su", "Tao Zhang", "Chen Zhou", "Kaizhe Shou", "Miao Wang", "Wufang Zhu", "Guoshan Lu", "Chao Ye", "Yali Ye", "Wentao Ye", "Yiming Zhang", "Xinglong Deng", "Jie Xu", "Haobo Wang", "Gang Chen", "Junbo Zhao"], "Categories": "cs.AI cs.LG", "Comments": ["Technical Report"]}, "abstract": "Tables are prevalent in real-world databases, requiring significant time and effort for humans to analyze and manipulate. The advancements in large language models (LLMs) have made it possible to interact with tables using natural language input, bringing this capability closer to reality. In this paper, we present TableGPT, a unified fine-tuned framework that enables LLMs to understand and operate on tables using external functional commands. It introduces the capability to seamlessly interact with tables, enabling a wide range of functionalities such as question answering, data manipulation (e.g., insert, delete, query, and modify operations), data visualization, analysis report generation, and automated prediction. TableGPT aims to provide convenience and accessibility to users by empowering them to effortlessly leverage tabular data. At the core of TableGPT lies the novel concept of global tabular representations, which empowers LLMs to gain a comprehensive understanding of the entire table beyond meta-information. By jointly training LLMs on both table and text modalities, TableGPT achieves a deep understanding of tabular data and the ability to perform complex operations on tables through chain-of-command instructions. Importantly, TableGPT offers the advantage of being a self-contained system rather than relying on external API interfaces. Moreover, it supports efficient data process flow, query rejection (when appropriate) and private deployment, enabling faster domain data fine-tuning and ensuring data privacy, which enhances the framework's adaptability to specific use cases.", "url": "https://arxiv.org/abs/2307.08674"}, {"metadata": {"arXiv": "2307.07887", "Date": "Sat, 15 Jul 2023 21:49:22 ", "Title": "Handwritten and Printed Text Segmentation: A Signature Case Study", "Authors": ["Sina Gholamian and Ali Vahdat"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Accepted for publication in ICCV 2023.This manuscript will be updated with the camera-ready version. 17 pages including main text and appendecies"]}, "abstract": "While analyzing scanned documents, handwritten text can overlay printed text. This causes difficulties during the optical character recognition (OCR) and digitization process of documents, and subsequently, hurts downstream NLP tasks. Prior research either focuses only on the binary classification of handwritten text, or performs a three-class segmentation of the document, i.e., recognition of handwritten, printed, and background pixels. This results in the assignment of the handwritten and printed overlapping pixels to only one of the classes, and thus, they are not accounted for in the other class. Thus, in this research, we develop novel approaches for addressing the challenges of handwritten and printed text segmentation with the goal of recovering text in different classes in whole, especially improving the segmentation performance on the overlapping parts. As such, to facilitate with this task, we introduce a new dataset, SignaTR6K, collected from real legal documents, as well as a new model architecture for handwritten and printed text segmentation task. Our best configuration outperforms the prior work on two different datasets by 17.9% and 7.3% on IoU scores.", "url": "https://arxiv.org/abs/2307.07887"}, {"metadata": {"arXiv": "2307.07893", "Date": "Sat, 15 Jul 2023 22:13:36 ", "Title": "Anomaly Detection in Automated Fibre Placement: Learning with Data Limitations", "Authors": ["Assef Ghamisi", "Todd Charter", "Li Ji", "Maxime Rivard", "Gil Lund", "Homayoun Najjaran"], "Categories": "cs.CV cs.AI cs.LG eess.IV"}, "abstract": "Current defect detection systems for Automated Fibre Placement (AFP) are mostly based on end-to-end supervised learning methods requiring abundant labelled defective samples, which are not easily generated in sufficient numbers. To address this data scarcity problem, we introduce an autoencoder-based approach compatible with small datasets. Fortunately, the problem from a foundational point of view can be simplified as a binary classification between normal and abnormal samples. The proposed approach uses a depth map of the fibre layup surface, split into small windows aligned to each composite strip (tow). A subset of these windows that do not contain anomalies is passed to an autoencoder to reconstruct the input. Because the autoencoder is trained with normal samples, it produces more accurate reconstructions for these samples than for abnormal ones. Therefore, the value of reconstruction error is used as a quantitative metric for whether there are potential anomalies. These values are combined to produce an anomaly map, which can localize the manufacturing defects in the depth map. The results show that although the autoencoder is trained with a very limited number of scans, the proposed approach can produce sufficient binary classification accuracy and specify the location of the defects.", "url": "https://arxiv.org/abs/2307.07893"}, {"metadata": {"arXiv": "2307.07942", "Date": "Sun, 16 Jul 2023 04:27:03 ", "Title": "KECOR: Kernel Coding Rate Maximization for Active 3D Object Detection", "Authors": ["Yadan Luo", "Zhuoxiao Chen", "Zhen Fang", "Zheng Zhang", "Zi Huang", "Mahsa Baktashmotlagh"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["To appear in ICCV 2023"]}, "abstract": "Achieving a reliable LiDAR-based object detector in autonomous driving is paramount, but its success hinges on obtaining large amounts of precise 3D annotations. Active learning (AL) seeks to mitigate the annotation burden through algorithms that use fewer labels and can attain performance comparable to fully supervised learning. Although AL has shown promise, current approaches prioritize the selection of unlabeled point clouds with high uncertainty and/or diversity, leading to the selection of more instances for labeling and reduced computational efficiency. In this paper, we resort to a novel kernel coding rate maximization (KECOR) strategy which aims to identify the most informative point clouds to acquire labels through the lens of information theory. Greedy search is applied to seek desired point clouds that can maximize the minimal number of bits required to encode the latent features. To determine the uniqueness and informativeness of the selected samples from the model perspective, we construct a proxy network of the 3D detector head and compute the outer product of Jacobians from all proxy layers to form the empirical neural tangent kernel (NTK) matrix. To accommodate both one-stage (i.e., SECOND) and two-stage detectors (i.e., PVRCNN), we further incorporate the classification entropy maximization and well trade-off between detection performance and the total number of bounding boxes selected for annotation. Extensive experiments conducted on two 3D benchmarks and a 2D detection dataset evidence the superiority and versatility of the proposed approach. Our results show that approximately 44% box-level annotation costs and 26% computational time are reduced compared to the state-of-the-art AL method, without compromising detection performance.", "url": "https://arxiv.org/abs/2307.07942"}, {"metadata": {"arXiv": "2307.07944", "Date": "Sun, 16 Jul 2023 04:34:11 ", "Title": "Revisiting Domain-Adaptive 3D Object Detection by Reliable, Diverse and Class-balanced Pseudo-Labeling", "Authors": ["Zhuoxiao Chen", "Yadan Luo", "Zi Huang", "Zheng Wang", "Mahsa Baktashmotlagh"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["ICCV 2023"]}, "abstract": "Unsupervised domain adaptation (DA) with the aid of pseudo labeling techniques has emerged as a crucial approach for domain-adaptive 3D object detection. While effective, existing DA methods suffer from a substantial drop in performance when applied to a multi-class training setting, due to the co-existence of low-quality pseudo labels and class imbalance issues. In this paper, we address this challenge by proposing a novel ReDB framework tailored for learning to detect all classes at once. Our approach produces Reliable, Diverse, and class-Balanced pseudo 3D boxes to iteratively guide the self-training on a distributionally different target domain. To alleviate disruptions caused by the environmental discrepancy (e.g., beam numbers), the proposed cross-domain examination (CDE) assesses the correctness of pseudo labels by copy-pasting target instances into a source environment and measuring the prediction consistency. To reduce computational overhead and mitigate the object shift (e.g., scales and point densities), we design an overlapped boxes counting (OBC) metric that allows to uniformly downsample pseudo-labeled objects across different geometric characteristics. To confront the issue of inter-class imbalance, we progressively augment the target point clouds with a class-balanced set of pseudo-labeled target instances and source objects, which boosts recognition accuracies on both frequently appearing and rare classes. Experimental results on three benchmark datasets using both voxel-based (i.e., SECOND) and point-based 3D detectors (i.e., PointRCNN) demonstrate that our proposed ReDB approach outperforms existing 3D domain adaptation methods by a large margin, improving 23.15% mAP on the nuScenes $\\rightarrow$ KITTI task.", "url": "https://arxiv.org/abs/2307.07944"}, {"metadata": {"arXiv": "2307.08132", "Date": "Sun, 16 Jul 2023 19:06:29 ", "Title": "Heterogeneous graphs model spatial relationships between biological entities for breast cancer diagnosis", "Authors": ["Akhila Krishna K", "Ravi Kant Gupta", "Nikhil Cherian Kurian", "Pranav Jeevan", "Amit Sethi"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "The heterogeneity of breast cancer presents considerable challenges for its early detection, prognosis, and treatment selection. Convolutional neural networks often neglect the spatial relationships within histopathological images, which can limit their accuracy. Graph neural networks (GNNs) offer a promising solution by coding the spatial relationships within images. Prior studies have investigated the modeling of histopathological images as cell and tissue graphs, but they have not fully tapped into the potential of extracting interrelationships between these biological entities. In this paper, we present a novel approach using a heterogeneous GNN that captures the spatial and hierarchical relations between cell and tissue graphs to enhance the extraction of useful information from histopathological images. We also compare the performance of a cross-attention-based network and a transformer architecture for modeling the intricate relationships within tissue and cell graphs. Our model demonstrates superior efficiency in terms of parameter count and achieves higher accuracy compared to the transformer-based state-of-the-art approach on three publicly available breast cancer datasets -- BRIGHT, BreakHis, and BACH.", "url": "https://arxiv.org/abs/2307.08132"}, {"metadata": {"arXiv": "2307.08347", "Date": "Mon, 17 Jul 2023 09:38:41 ", "Title": "M-FLAG: Medical Vision-Language Pre-training with Frozen Language Models and Latent Space Geometry Optimization", "Authors": ["Che Liu", "Sibo Cheng", "Chen Chen", "Mengyun Qiao", "Weitong Zhang", "Anand Shah", "Wenjia Bai", "Rossella Arcucci"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Medical vision-language models enable co-learning and integrating features from medical imaging and clinical text. However, these models are not easy to train and the latent representation space can be complex. Here we propose a novel way for pre-training and regularising medical vision-language models. The proposed method, named Medical vision-language pre-training with Frozen language models and Latent spAce Geometry optimization (M-FLAG), leverages a frozen language model for training stability and efficiency and introduces a novel orthogonality loss to harmonize the latent space geometry. We demonstrate the potential of the pre-trained model on three downstream tasks: medical image classification, segmentation, and object detection. Extensive experiments across five public datasets demonstrate that M-FLAG significantly outperforms existing medical vision-language pre-training approaches and reduces the number of parameters by 78\\%. Notably, M-FLAG achieves outstanding performance on the segmentation task while using only 1\\% of the RSNA dataset, even outperforming ImageNet pre-trained models that have been fine-tuned using 100\\% of the data.", "url": "https://arxiv.org/abs/2307.08347"}, {"metadata": {"arXiv": "2307.08506", "Date": "Mon, 17 Jul 2023 14:08:38 ", "Title": "Does Visual Pretraining Help End-to-End Reasoning?", "Authors": ["Chen Sun", "Calvin Luo", "Xingyi Zhou", "Anurag Arnab", "Cordelia Schmid"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "We aim to investigate whether end-to-end learning of visual reasoning can be achieved with general-purpose neural networks, with the help of visual pretraining. A positive result would refute the common belief that explicit visual abstraction (e.g. object detection) is essential for compositional generalization on visual reasoning, and confirm the feasibility of a neural network \"generalist\" to solve visual recognition and reasoning tasks. We propose a simple and general self-supervised framework which \"compresses\" each video frame into a small set of tokens with a transformer network, and reconstructs the remaining frames based on the compressed temporal context. To minimize the reconstruction loss, the network must learn a compact representation for each image, as well as capture temporal dynamics and object permanence from temporal context. We perform evaluation on two visual reasoning benchmarks, CATER and ACRE. We observe that pretraining is essential to achieve compositional generalization for end-to-end visual reasoning. Our proposed framework outperforms traditional supervised pretraining, including image classification and explicit object detection, by large margins.", "url": "https://arxiv.org/abs/2307.08506"}, {"metadata": {"arXiv": "2307.08526", "Date": "Mon, 17 Jul 2023 14:38:11 ", "Title": "Image Captions are Natural Prompts for Text-to-Image Models", "Authors": ["Shiye Lei", "Hao Chen", "Sen Zhang", "Bo Zhao and Dacheng Tao"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["20 pages", "1 figure", "10 tables"]}, "abstract": "With the rapid development of Artificial Intelligence Generated Content (AIGC), it has become common practice in many learning tasks to train or fine-tune large models on synthetic data due to the data-scarcity and privacy leakage problems. Albeit promising with unlimited data generation, owing to massive and diverse information conveyed in real images, it is challenging for text-to-image generative models to synthesize informative training data with hand-crafted prompts, which usually leads to inferior generalization performance when training downstream models. In this paper, we theoretically analyze the relationship between the training effect of synthetic data and the synthetic data distribution induced by prompts. Then we correspondingly propose a simple yet effective method that prompts text-to-image generative models to synthesize more informative and diverse training data. Specifically, we caption each real image with the advanced captioning model to obtain informative and faithful prompts that extract class-relevant information and clarify the polysemy of class names. The image captions and class names are concatenated to prompt generative models for training image synthesis. Extensive experiments on ImageNette, ImageNet-100, and ImageNet-1K verify that our method significantly improves the performance of models trained on synthetic training data, i.e., 10% classification accuracy improvements on average.", "url": "https://arxiv.org/abs/2307.08526"}, {"metadata": {"arXiv": "2307.07527", "Date": "Wed, 12 Jul 2023 10:20:19 ", "Title": "Machine Learning for Autonomous Vehicle's Trajectory Prediction: A comprehensive survey, Challenges, and Future Research Directions", "Authors": ["Vibha Bharilya", "Neetesh Kumar"], "Categories": "cs.LG cs.AI", "Comments": ["Under review"]}, "abstract": "Autonomous Vehicles (AVs) have emerged as a promising solution by replacing human drivers with advanced computer-aided decision-making systems. However, for AVs to effectively navigate the road, they must possess the capability to predict the future behavior of nearby traffic participants, similar to the predictive driving abilities of human drivers. Building upon existing literature is crucial to advance the field and develop a comprehensive understanding of trajectory prediction methods in the context of automated driving. To address this need, we have undertaken a comprehensive review that focuses on trajectory prediction methods for AVs, with a particular emphasis on machine learning techniques including deep learning and reinforcement learning-based approaches. We have extensively examined over two hundred studies related to trajectory prediction in the context of AVs. The paper begins with an introduction to the general problem of predicting vehicle trajectories and provides an overview of the key concepts and terminology used throughout. After providing a brief overview of conventional methods, this review conducts a comprehensive evaluation of several deep learning-based techniques. Each method is summarized briefly, accompanied by a detailed analysis of its strengths and weaknesses. The discussion further extends to reinforcement learning-based methods. This article also examines the various datasets and evaluation metrics that are commonly used in trajectory prediction tasks. Encouraging an unbiased and objective discussion, we compare two major learning processes, considering specific functional features. By identifying challenges in the existing literature and outlining potential research directions, this review significantly contributes to the advancement of knowledge in the domain of AV trajectory prediction.", "url": "https://arxiv.org/abs/2307.07527"}, {"metadata": {"arXiv": "2307.07529", "Date": "Thu, 13 Jul 2023 13:41:24 ", "Title": "Learning Multiple Coordinated Agents under Directed Acyclic Graph Constraints", "Authors": ["Jaeyeon Jang", "Diego Klabjan", "Han Liu", "Nital S. Patel", "Xiuqi Li", "Balakrishnan Ananthanarayanan", "Husam Dauod", "Tzung-Han Juang"], "Categories": "cs.LG cs.AI cs.MA"}, "abstract": "This paper proposes a novel multi-agent reinforcement learning (MARL) method to learn multiple coordinated agents under directed acyclic graph (DAG) constraints. Unlike existing MARL approaches, our method explicitly exploits the DAG structure between agents to achieve more effective learning performance. Theoretically, we propose a novel surrogate value function based on a MARL model with synthetic rewards (MARLM-SR) and prove that it serves as a lower bound of the optimal value function. Computationally, we propose a practical training algorithm that exploits new notion of leader agent and reward generator and distributor agent to guide the decomposed follower agents to better explore the parameter space in environments with DAG constraints. Empirically, we exploit four DAG environments including a real-world scheduling for one of Intel's high volume packaging and test factory to benchmark our methods and show it outperforms the other non-DAG approaches.", "url": "https://arxiv.org/abs/2307.07529"}, {"metadata": {"arXiv": "2307.07650", "Date": "Fri, 14 Jul 2023 22:55:52 ", "Title": "SALC: Skeleton-Assisted Learning-Based Clustering for Time-Varying Indoor Localization", "Authors": ["An-Hung Hsiao", "Li-Hsiang Shen", "Chen-Yi Chang", "Chun-Jie Chiu", "Kai-Ten Feng"], "Categories": "cs.LG cs.AI eess.SP"}, "abstract": "Wireless indoor localization has attracted significant amount of attention in recent years. Using received signal strength (RSS) obtained from WiFi access points (APs) for establishing fingerprinting database is a widely utilized method in indoor localization. However, the time-variant problem for indoor positioning systems is not well-investigated in existing literature. Compared to conventional static fingerprinting, the dynamicallyreconstructed database can adapt to a highly-changing environment, which achieves sustainability of localization accuracy. To deal with the time-varying issue, we propose a skeleton-assisted learning-based clustering localization (SALC) system, including RSS-oriented map-assisted clustering (ROMAC), cluster-based online database establishment (CODE), and cluster-scaled location estimation (CsLE). The SALC scheme jointly considers similarities from the skeleton-based shortest path (SSP) and the time-varying RSS measurements across the reference points (RPs). ROMAC clusters RPs into different feature sets and therefore selects suitable monitor points (MPs) for enhancing location estimation. Moreover, the CODE algorithm aims for establishing adaptive fingerprint database to alleviate the timevarying problem. Finally, CsLE is adopted to acquire the target position by leveraging the benefits of clustering information and estimated signal variations in order to rescale the weights fromweighted k-nearest neighbors (WkNN) method. Both simulation and experimental results demonstrate that the proposed SALC system can effectively reconstruct the fingerprint database with an enhanced location estimation accuracy, which outperforms the other existing schemes in the open literature.", "url": "https://arxiv.org/abs/2307.07650"}, {"metadata": {"arXiv": "2307.07666", "Date": "Sat, 15 Jul 2023 00:26:51 ", "Title": "Efficient Action Robust Reinforcement Learning with Probabilistic Policy Execution Uncertainty", "Authors": ["Guanin Liu", "Zhihan Zhou", "Han Liu", "Lifeng Lai"], "Categories": "cs.LG cs.AI math.OC"}, "abstract": "Robust reinforcement learning (RL) aims to find a policy that optimizes the worst-case performance in the face of uncertainties. In this paper, we focus on action robust RL with the probabilistic policy execution uncertainty, in which, instead of always carrying out the action specified by the policy, the agent will take the action specified by the policy with probability $1-\\rho$ and an alternative adversarial action with probability $\\rho$. We establish the existence of an optimal policy on the action robust MDPs with probabilistic policy execution uncertainty and provide the action robust Bellman optimality equation for its solution. Furthermore, we develop Action Robust Reinforcement Learning with Certificates (ARRLC) algorithm that achieves minimax optimal regret and sample complexity. Furthermore, we conduct numerical experiments to validate our approach's robustness, demonstrating that ARRLC outperforms non-robust RL algorithms and converges faster than the robust TD algorithm in the presence of action perturbations.", "url": "https://arxiv.org/abs/2307.07666"}, {"metadata": {"arXiv": "2307.07670", "Date": "Sat, 15 Jul 2023 00:38:55 ", "Title": "Efficient Adversarial Attacks on Online Multi-agent Reinforcement Learning", "Authors": ["Guanlin Liu", "Lifeng Lai"], "Categories": "cs.LG cs.AI cs.CR math.OC"}, "abstract": "Due to the broad range of applications of multi-agent reinforcement learning (MARL), understanding the effects of adversarial attacks against MARL model is essential for the safe applications of this model. Motivated by this, we investigate the impact of adversarial attacks on MARL. In the considered setup, there is an exogenous attacker who is able to modify the rewards before the agents receive them or manipulate the actions before the environment receives them. The attacker aims to guide each agent into a target policy or maximize the cumulative rewards under some specific reward function chosen by the attacker, while minimizing the amount of manipulation on feedback and action. We first show the limitations of the action poisoning only attacks and the reward poisoning only attacks. We then introduce a mixed attack strategy with both the action poisoning and the reward poisoning. We show that the mixed attack strategy can efficiently attack MARL agents even if the attacker has no prior information about the underlying environment and the agents' algorithms.", "url": "https://arxiv.org/abs/2307.07670"}, {"metadata": {"arXiv": "2307.07753", "Date": "Sat, 15 Jul 2023 09:24:33 ", "Title": "Learning Expressive Priors for Generalization and Uncertainty Estimation in Neural Networks", "Authors": ["Dominik Schnaus", "Jongseok Lee", "Daniel Cremers", "Rudolph Triebel"], "Categories": "cs.LG cs.AI stat.ML", "Comments": ["Accepted to ICML 2023"]}, "abstract": "In this work, we propose a novel prior learning method for advancing generalization and uncertainty estimation in deep neural networks. The key idea is to exploit scalable and structured posteriors of neural networks as informative priors with generalization guarantees. Our learned priors provide expressive probabilistic representations at large scale, like Bayesian counterparts of pre-trained models on ImageNet, and further produce non-vacuous generalization bounds. We also extend this idea to a continual learning framework, where the favorable properties of our priors are desirable. Major enablers are our technical contributions: (1) the sums-of-Kronecker-product computations, and (2) the derivations and optimizations of tractable objectives that lead to improved generalization bounds. Empirically, we exhaustively show the effectiveness of this method for uncertainty estimation and generalization.", "url": "https://arxiv.org/abs/2307.07753"}, {"metadata": {"arXiv": "2307.07832", "Date": "Sat, 15 Jul 2023 15:46:38 ", "Title": "MixupExplainer: Generalizing Explanations for Graph Neural Networks with Data Augmentation", "Authors": ["Jiaxing Zhang", "Dongsheng Luo", "and Hua Wei"], "Categories": "cs.LG cs.AI", "DOI": "10.1145/3580305.3599435"}, "abstract": "Graph Neural Networks (GNNs) have received increasing attention due to their ability to learn from graph-structured data. However, their predictions are often not interpretable. Post-hoc instance-level explanation methods have been proposed to understand GNN predictions. These methods seek to discover substructures that explain the prediction behavior of a trained GNN. In this paper, we shed light on the existence of the distribution shifting issue in existing methods, which affects explanation quality, particularly in applications on real-life datasets with tight decision boundaries. To address this issue, we introduce a generalized Graph Information Bottleneck (GIB) form that includes a label-independent graph variable, which is equivalent to the vanilla GIB. Driven by the generalized GIB, we propose a graph mixup method, MixupExplainer, with a theoretical guarantee to resolve the distribution shifting issue. We conduct extensive experiments on both synthetic and real-world datasets to validate the effectiveness of our proposed mixup approach over existing approaches. We also provide a detailed analysis of how our proposed approach alleviates the distribution shifting issue.", "url": "https://arxiv.org/abs/2307.07832"}, {"metadata": {"arXiv": "2307.07840", "Date": "Sat, 15 Jul 2023 16:16:22 ", "Title": "RegExplainer: Generating Explanations for Graph Neural Networks in Regression Task", "Authors": ["Jiaxing Zhang", "Zhuomin Chen", "Hao Mei", "Dongsheng Luo", "and Hua Wei"], "Categories": "cs.LG cs.AI"}, "abstract": "Graph regression is a fundamental task and has received increasing attention in a wide range of graph learning tasks. However, the inference process is often not interpretable. Most existing explanation techniques are limited to understanding GNN behaviors in classification tasks. In this work, we seek an explanation to interpret the graph regression models (XAIG-R). We show that existing methods overlook the distribution shifting and continuously ordered decision boundary, which hinders them away from being applied in the regression tasks. To address these challenges, we propose a novel objective based on the information bottleneck theory and introduce a new mix-up framework, which could support various GNNs in a model-agnostic manner. We further present a contrastive learning strategy to tackle the continuously ordered labels in regression task. To empirically verify the effectiveness of the proposed method, we introduce three benchmark datasets and a real-life dataset for evaluation. Extensive experiments show the effectiveness of the proposed method in interpreting GNN models in regression tasks.", "url": "https://arxiv.org/abs/2307.07840"}, {"metadata": {"arXiv": "2307.07863", "Date": "Sat, 15 Jul 2023 18:13:29 ", "Title": "Benchmarking the Effectiveness of Classification Algorithms and SVM Kernels for Dry Beans", "Authors": ["Anant Mehta", "Prajit Sengupta", "Divisha Garg", "Harpreet Singh", "Yosi Shacham Diamand"], "Categories": "cs.LG cs.AI", "Comments": ["6 pages", "5 figures"]}, "abstract": "Plant breeders and agricultural researchers can increase crop productivity by identifying desirable features, disease resistance, and nutritional content by analysing the Dry Bean dataset. This study analyses and compares different Support Vector Machine (SVM) classification algorithms, namely linear, polynomial, and radial basis function (RBF), along with other popular classification algorithms. The analysis is performed on the Dry Bean Dataset, with PCA (Principal Component Analysis) conducted as a preprocessing step for dimensionality reduction. The primary evaluation metric used is accuracy, and the RBF SVM kernel algorithm achieves the highest Accuracy of 93.34%, Precision of 92.61%, Recall of 92.35% and F1 Score as 91.40%. Along with adept visualization and empirical analysis, this study offers valuable guidance by emphasizing the importance of considering different SVM algorithms for complex and non-linear structured datasets.", "url": "https://arxiv.org/abs/2307.07863"}, {"metadata": {"arXiv": "2307.07872", "Date": "Sat, 15 Jul 2023 19:09:35 ", "Title": "Does Double Descent Occur in Self-Supervised Learning?", "Authors": ["Alisia Lupidi", "Yonatan Gideoni", "Dulhan Jayalath"], "Categories": "cs.LG cs.AI", "Comments": ["7 pages", "2 tables", "3 figures. Accepted for the workshop on High-Dimensional Learning Dynamics at ICML 2023"]}, "abstract": "Most investigations into double descent have focused on supervised models while the few works studying self-supervised settings find a surprising lack of the phenomenon. These results imply that double descent may not exist in self-supervised models. We show this empirically using a standard and linear autoencoder, two previously unstudied settings. The test loss is found to have either a classical U-shape or to monotonically decrease instead of exhibiting a double-descent curve. We hope that further work on this will help elucidate the theoretical underpinnings of this phenomenon.", "url": "https://arxiv.org/abs/2307.07872"}, {"metadata": {"arXiv": "2307.07956", "Date": "Sun, 16 Jul 2023 06:14:12 ", "Title": "Automated Polynomial Filter Learning for Graph Neural Networks", "Authors": ["Wendi Yu", "Zhichao Hou", "Xiaorui Liu"], "Categories": "cs.LG cs.AI", "Comments": ["10 pages", "3 figures"]}, "abstract": "Polynomial graph filters have been widely used as guiding principles in the design of Graph Neural Networks (GNNs). Recently, the adaptive learning of the polynomial graph filters has demonstrated promising performance for modeling graph signals on both homophilic and heterophilic graphs, owning to their flexibility and expressiveness. In this work, we conduct a novel preliminary study to explore the potential and limitations of polynomial graph filter learning approaches, revealing a severe overfitting issue. To improve the effectiveness of polynomial graph filters, we propose Auto-Polynomial, a novel and general automated polynomial graph filter learning framework that efficiently learns better filters capable of adapting to various complex graph signals. Comprehensive experiments and ablation studies demonstrate significant and consistent performance improvements on both homophilic and heterophilic graphs across multiple learning settings considering various labeling ratios, which unleashes the potential of polynomial filter learning.", "url": "https://arxiv.org/abs/2307.07956"}, {"metadata": {"arXiv": "2307.07997", "Date": "Sun, 16 Jul 2023 10:28:49 ", "Title": "MargCTGAN: A \"Marginally'' Better CTGAN for the Low Sample Regime", "Authors": ["Tejumade Afonja", "Dingfan Chen", "Mario Fritz"], "Categories": "cs.LG cs.AI", "Comments": ["ICML 2023 Workshop on Deployable Generative AI"]}, "abstract": "The potential of realistic and useful synthetic data is significant. However, current evaluation methods for synthetic tabular data generation predominantly focus on downstream task usefulness, often neglecting the importance of statistical properties. This oversight becomes particularly prominent in low sample scenarios, accompanied by a swift deterioration of these statistical measures. In this paper, we address this issue by conducting an evaluation of three state-of-the-art synthetic tabular data generators based on their marginal distribution, column-pair correlation, joint distribution and downstream task utility performance across high to low sample regimes. The popular CTGAN model shows strong utility, but underperforms in low sample settings in terms of utility. To overcome this limitation, we propose MargCTGAN that adds feature matching of de-correlated marginals, which results in a consistent improvement in downstream utility as well as statistical properties of the synthetic data.", "url": "https://arxiv.org/abs/2307.07997"}, {"metadata": {"arXiv": "2307.08044", "Date": "Sun, 16 Jul 2023 13:58:28 ", "Title": "Towards Flexible Time-to-event Modeling: Optimizing Neural Networks via Rank Regression", "Authors": ["Hyunjun Lee", "Junhyun Lee", "Taehwa Choi", "Jaewoo Kang", "Sangbum Choi"], "Categories": "cs.LG cs.AI stat.ML", "Comments": ["Accepted at ECAI 2023"]}, "abstract": "Time-to-event analysis, also known as survival analysis, aims to predict the time of occurrence of an event, given a set of features. One of the major challenges in this area is dealing with censored data, which can make learning algorithms more complex. Traditional methods such as Cox's proportional hazards model and the accelerated failure time (AFT) model have been popular in this field, but they often require assumptions such as proportional hazards and linearity. In particular, the AFT models often require pre-specified parametric distributional assumptions. To improve predictive performance and alleviate strict assumptions, there have been many deep learning approaches for hazard-based models in recent years. However, representation learning for AFT has not been widely explored in the neural network literature, despite its simplicity and interpretability in comparison to hazard-focused methods. In this work, we introduce the Deep AFT Rank-regression model for Time-to-event prediction (DART). This model uses an objective function based on Gehan's rank statistic, which is efficient and reliable for representation learning. On top of eliminating the requirement to establish a baseline event time distribution, DART retains the advantages of directly predicting event time in standard AFT models. The proposed method is a semiparametric approach to AFT modeling that does not impose any distributional assumptions on the survival time distribution. This also eliminates the need for additional hyperparameters or complex model architectures, unlike existing neural network-based AFT models. Through quantitative analysis on various benchmark datasets, we have shown that DART has significant potential for modeling high-throughput censored time-to-event data.", "url": "https://arxiv.org/abs/2307.08044"}, {"metadata": {"arXiv": "2307.08082", "Date": "Sun, 16 Jul 2023 15:44:58 ", "Title": "POMDP inference and robust solution via deep reinforcement learning: An application to railway optimal maintenance", "Authors": ["Giacomo Arcieri", "Cyprien Hoelzl", "Oliver Schwery", "Daniel Straub", "Konstantinos G. Papakonstantinou", "Eleni Chatzi"], "Categories": "cs.LG cs.AI"}, "abstract": "Partially Observable Markov Decision Processes (POMDPs) can model complex sequential decision-making problems under stochastic and uncertain environments. A main reason hindering their broad adoption in real-world applications is the lack of availability of a suitable POMDP model or a simulator thereof. Available solution algorithms, such as Reinforcement Learning (RL), require the knowledge of the transition dynamics and the observation generating process, which are often unknown and non-trivial to infer. In this work, we propose a combined framework for inference and robust solution of POMDPs via deep RL. First, all transition and observation model parameters are jointly inferred via Markov Chain Monte Carlo sampling of a hidden Markov model, which is conditioned on actions, in order to recover full posterior distributions from the available data. The POMDP with uncertain parameters is then solved via deep RL techniques with the parameter distributions incorporated into the solution via domain randomization, in order to develop solutions that are robust to model uncertainty. As a further contribution, we compare the use of transformers and long short-term memory networks, which constitute model-free RL solutions, with a model-based/model-free hybrid approach. We apply these methods to the real-world problem of optimal maintenance planning for railway assets.", "url": "https://arxiv.org/abs/2307.08082"}, {"metadata": {"arXiv": "2307.08086", "Date": "Sun, 16 Jul 2023 15:58:19 ", "Title": "Dataset Distillation Meets Provable Subset Selection", "Authors": ["Murad Tukan", "Alaa Maalouf", "Margarita Osadchy"], "Categories": "cs.LG cs.AI"}, "abstract": "Deep learning has grown tremendously over recent years, yielding state-of-the-art results in various fields. However, training such models requires huge amounts of data, increasing the computational time and cost. To address this, dataset distillation was proposed to compress a large training dataset into a smaller synthetic one that retains its performance -- this is usually done by (1) uniformly initializing a synthetic set and (2) iteratively updating/learning this set according to a predefined loss by uniformly sampling instances from the full data. In this paper, we improve both phases of dataset distillation: (1) we present a provable, sampling-based approach for initializing the distilled set by identifying important and removing redundant points in the data, and (2) we further merge the idea of data subset selection with dataset distillation, by training the distilled set on ``important'' sampled points during the training procedure instead of randomly sampling the next batch. To do so, we define the notion of importance based on the relative contribution of instances with respect to two different loss functions, i.e., one for the initialization phase (a kernel fitting function for kernel ridge regression and $K$-means based loss function for any other distillation method), and the relative cross-entropy loss (or any other predefined loss) function for the training phase. Finally, we provide experimental results showing how our method can latch on to existing dataset distillation techniques and improve their performance.", "url": "https://arxiv.org/abs/2307.08086"}, {"metadata": {"arXiv": "2307.08187", "Date": "Mon, 17 Jul 2023 01:27:10 ", "Title": "An Empirical Investigation of Pre-trained Model Selection for Out-of-Distribution Generalization and Calibration", "Authors": ["Hiroki Naganuma", "Ryuichiro Hataya"], "Categories": "cs.LG cs.AI"}, "abstract": "In the realm of out-of-distribution generalization tasks, finetuning has risen as a key strategy. While the most focus has been on optimizing learning algorithms, our research highlights the influence of pre-trained model selection in finetuning on out-of-distribution performance and inference uncertainty. Balancing model size constraints of a single GPU, we examined the impact of varying pre-trained datasets and model parameters on performance metrics like accuracy and expected calibration error. Our findings underscore the significant influence of pre-trained model selection, showing marked performance improvements over algorithm choice. Larger models outperformed others, though the balance between memorization and true generalization merits further investigation. Ultimately, our research emphasizes the importance of pre-trained model selection for enhancing out-of-distribution generalization.", "url": "https://arxiv.org/abs/2307.08187"}, {"metadata": {"arXiv": "2307.08192", "Date": "Mon, 17 Jul 2023 01:46:15 ", "Title": "HOPE: High-order Polynomial Expansion of Black-box Neural Networks", "Authors": ["Tingxiong Xiao", "Weihang Zhang", "Yuxiao Cheng", "Jinli Suo"], "Categories": "cs.LG cs.AI"}, "abstract": "Despite their remarkable performance, deep neural networks remain mostly ``black boxes'', suggesting inexplicability and hindering their wide applications in fields requiring making rational decisions. Here we introduce HOPE (High-order Polynomial Expansion), a method for expanding a network into a high-order Taylor polynomial on a reference input. Specifically, we derive the high-order derivative rule for composite functions and extend the rule to neural networks to obtain their high-order derivatives quickly and accurately. From these derivatives, we can then derive the Taylor polynomial of the neural network, which provides an explicit expression of the network's local interpretations. Numerical analysis confirms the high accuracy, low computational complexity, and good convergence of the proposed method. Moreover, we demonstrate HOPE's wide applications built on deep learning, including function discovery, fast inference, and feature selection. The code is available at https://github.com/HarryPotterXTX/HOPE.git.", "url": "https://arxiv.org/abs/2307.08192"}, {"metadata": {"arXiv": "2307.08286", "Date": "Mon, 17 Jul 2023 07:16:28 ", "Title": "Going Beyond Linear Mode Connectivity: The Layerwise Linear Feature Connectivity", "Authors": ["Zhanpeng Zhou", "Yongyi Yang", "Xiaojiang Yang", "Junchi Yan", "Wei Hu"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["25 pages", "23 figures"]}, "abstract": "Recent work has revealed many intriguing empirical phenomena in neural network training, despite the poorly understood and highly complex loss landscapes and training dynamics. One of these phenomena, Linear Mode Connectivity (LMC), has gained considerable attention due to the intriguing observation that different solutions can be connected by a linear path in the parameter space while maintaining near-constant training and test losses. In this work, we introduce a stronger notion of linear connectivity, Layerwise Linear Feature Connectivity (LLFC), which says that the feature maps of every layer in different trained networks are also linearly connected. We provide comprehensive empirical evidence for LLFC across a wide range of settings, demonstrating that whenever two trained networks satisfy LMC (via either spawning or permutation methods), they also satisfy LLFC in nearly all the layers. Furthermore, we delve deeper into the underlying factors contributing to LLFC, which reveal new insights into the spawning and permutation approaches. The study of LLFC transcends and advances our understanding of LMC by adopting a feature-learning perspective.", "url": "https://arxiv.org/abs/2307.08286"}, {"metadata": {"arXiv": "2307.08327", "Date": "Mon, 17 Jul 2023 08:50:36 ", "Title": "Analyzing the Impact of Adversarial Examples on Explainable Machine Learning", "Authors": ["Prathyusha Devabhakthini", "Sasmita Parida", "Raj Mani Shukla", "Suvendu Chandan Nayak"], "Categories": "cs.LG cs.AI"}, "abstract": "Adversarial attacks are a type of attack on machine learning models where an attacker deliberately modifies the inputs to cause the model to make incorrect predictions. Adversarial attacks can have serious consequences, particularly in applications such as autonomous vehicles, medical diagnosis, and security systems. Work on the vulnerability of deep learning models to adversarial attacks has shown that it is very easy to make samples that make a model predict things that it doesn't want to. In this work, we analyze the impact of model interpretability due to adversarial attacks on text classification problems. We develop an ML-based classification model for text data. Then, we introduce the adversarial perturbations on the text data to understand the classification performance after the attack. Subsequently, we analyze and interpret the model's explainability before and after the attack", "url": "https://arxiv.org/abs/2307.08327"}, {"metadata": {"arXiv": "2307.08496", "Date": "Mon, 17 Jul 2023 13:59:07 ", "Title": "Can We Trust Race Prediction?", "Authors": ["Cangyuan Li"], "Categories": "cs.LG cs.AI cs.CY stat.ML"}, "abstract": "In the absence of sensitive race and ethnicity data, researchers, regulators, and firms alike turn to proxies. In this paper, I train a Bidirectional Long Short-Term Memory (BiLSTM) model on a novel dataset of voter registration data from all 50 US states and create an ensemble that achieves up to 36.8% higher out of sample (OOS) F1 scores than the best performing machine learning models in the literature. Additionally, I construct the most comprehensive database of first and surname distributions in the US in order to improve the coverage and accuracy of Bayesian Improved Surname Geocoding (BISG) and Bayesian Improved Firstname Surname Geocoding (BIFSG). Finally, I provide the first high-quality benchmark dataset in order to fairly compare existing models and aid future model developers.", "url": "https://arxiv.org/abs/2307.08496"}, {"metadata": {"arXiv": "2307.08532", "Date": "Mon, 17 Jul 2023 14:46:59 ", "Title": "LuckyMera: a Modular AI Framework for Building Hybrid NetHack Agents", "Authors": ["Luigi Quarantiello", "Simone Marzeddu", "Antonio Guzzi", "Vincenzo Lomonaco"], "Categories": "cs.LG cs.AI"}, "abstract": "In the last few decades we have witnessed a significant development in Artificial Intelligence (AI) thanks to the availability of a variety of testbeds, mostly based on simulated environments and video games. Among those, roguelike games offer a very good trade-off in terms of complexity of the environment and computational costs, which makes them perfectly suited to test AI agents generalization capabilities. In this work, we present LuckyMera, a flexible, modular, extensible and configurable AI framework built around NetHack, a popular terminal-based, single-player roguelike video game. This library is aimed at simplifying and speeding up the development of AI agents capable of successfully playing the game and offering a high-level interface for designing game strategies. LuckyMera comes with a set of off-the-shelf symbolic and neural modules (called \"skills\"): these modules can be either hard-coded behaviors, or neural Reinforcement Learning approaches, with the possibility of creating compositional hybrid solutions. Additionally, LuckyMera comes with a set of utility features to save its experiences in the form of trajectories for further analysis and to use them as datasets to train neural modules, with a direct interface to the NetHack Learning Environment and MiniHack. Through an empirical evaluation we validate our skills implementation and propose a strong baseline agent that can reach state-of-the-art performances in the complete NetHack game. LuckyMera is open-source and available at https://github.com/Pervasive-AI-Lab/LuckyMera.", "url": "https://arxiv.org/abs/2307.08532"}, {"metadata": {"arXiv": "2307.08623", "Date": "Fri, 14 Jul 2023 05:41:22 ", "Title": "HYTREL: Hypergraph-enhanced Tabular Data Representation Learning", "Authors": ["Pei Chen", "Soumajyoti Sarkar", "Leonard Lausen", "Balasubramaniam Srinivasan", "Sheng Zha", "Ruihong Huang and George Karypis"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "Language models pretrained on large collections of tabular data have demonstrated their effectiveness in several downstream tasks. However, many of these models do not take into account the row/column permutation invariances, hierarchical structure, etc. that exist in tabular data. To alleviate these limitations, we propose HYTREL, a tabular language model, that captures the permutation invariances and three more structural properties of tabular data by using hypergraphs - where the table cells make up the nodes and the cells occurring jointly together in each row, column, and the entire table are used to form three different types of hyperedges. We show that HYTREL is maximally invariant under certain conditions for tabular data, i.e., two tables obtain the same representations via HYTREL iff the two tables are identical up to permutations. Our empirical results demonstrate that HYTREL consistently outperforms other competitive baselines on four downstream tasks with minimal pretraining, illustrating the advantages of incorporating the inductive biases associated with tabular data into the representations. Finally, our qualitative analyses showcase that HYTREL can assimilate the table structures to generate robust representations for the cells, rows, columns, and the entire table.", "url": "https://arxiv.org/abs/2307.08623"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2309.10972", "Date": "Wed, 20 Sep 2023 00:07:30 ", "Title": "SEMPART: Self-supervised Multi-resolution Partitioning of Image Semantics", "Authors": ["Sriram Ravindran", "Debraj Basu"], "Categories": "cs.CV cs.LG"}, "abstract": "Accurately determining salient regions of an image is challenging when labeled data is scarce. DINO-based self-supervised approaches have recently leveraged meaningful image semantics captured by patch-wise features for locating foreground objects. Recent methods have also incorporated intuitive priors and demonstrated value in unsupervised methods for object partitioning. In this paper, we propose SEMPART, which jointly infers coarse and fine bi-partitions over an image's DINO-based semantic graph. Furthermore, SEMPART preserves fine boundary details using graph-driven regularization and successfully distills the coarse mask semantics into the fine mask. Our salient object detection and single object localization findings suggest that SEMPART produces high-quality masks rapidly without additional post-processing and benefits from co-optimizing the coarse and fine branches.", "url": "https://arxiv.org/abs/2309.10972"}, {"metadata": {"arXiv": "2309.11267", "Date": "Wed, 20 Sep 2023 12:50:52 ", "Title": "From Classification to Segmentation with Explainable AI: A Study on Crack Detection and Growth Monitoring", "Authors": ["Florent Forest", "Hugo Porta", "Devis Tuia", "Olga Fink"], "Categories": "cs.CV cs.LG eess.IV", "Comments": ["43 pages. Under review"]}, "abstract": "Monitoring surface cracks in infrastructure is crucial for structural health monitoring. Automatic visual inspection offers an effective solution, especially in hard-to-reach areas. Machine learning approaches have proven their effectiveness but typically require large annotated datasets for supervised training. Once a crack is detected, monitoring its severity often demands precise segmentation of the damage. However, pixel-level annotation of images for segmentation is labor-intensive. To mitigate this cost, one can leverage explainable artificial intelligence (XAI) to derive segmentations from the explanations of a classifier, requiring only weak image-level supervision. This paper proposes applying this methodology to segment and monitor surface cracks. We evaluate the performance of various XAI methods and examine how this approach facilitates severity quantification and growth monitoring. Results reveal that while the resulting segmentation masks may exhibit lower quality than those produced by supervised methods, they remain meaningful and enable severity monitoring, thus reducing substantial labeling costs.", "url": "https://arxiv.org/abs/2309.11267"}, {"metadata": {"arXiv": "2309.11354", "Date": "Wed, 20 Sep 2023 14:35:23 ", "Title": "Self-supervised learning unveils change in urban housing from street-level images", "Authors": ["Steven Stalder", "Michele Volpi", "Nicolas B\\\"uttner", "Stephen Law", "Kenneth Harttgen", "Esra Suel"], "Categories": "cs.CV cs.LG", "Comments": ["16 pages", "5 figures"]}, "abstract": "Cities around the world face a critical shortage of affordable and decent housing. Despite its critical importance for policy, our ability to effectively monitor and track progress in urban housing is limited. Deep learning-based computer vision methods applied to street-level images have been successful in the measurement of socioeconomic and environmental inequalities but did not fully utilize temporal images to track urban change as time-varying labels are often unavailable. We used self-supervised methods to measure change in London using 15 million street images taken between 2008 and 2021. Our novel adaptation of Barlow Twins, Street2Vec, embeds urban structure while being invariant to seasonal and daily changes without manual annotations. It outperformed generic embeddings, successfully identified point-level change in London's housing supply from street-level images, and distinguished between major and minor change. This capability can provide timely information for urban planning and policy decisions toward more liveable, equitable, and sustainable cities.", "url": "https://arxiv.org/abs/2309.11354"}, {"metadata": {"arXiv": "2309.11443", "Date": "Wed, 20 Sep 2023 16:17:26 ", "Title": "Signature Activation: A Sparse Signal View for Holistic Saliency", "Authors": ["Jose Roberto Tello Ayala", "Akl C. Fahed", "Weiwei Pan", "Eugene V. Pomerantsev", "Patrick T. Ellinor", "Anthony Philippakis", "Finale Doshi-Velez"], "Categories": "cs.CV cs.LG"}, "abstract": "The adoption of machine learning in healthcare calls for model transparency and explainability. In this work, we introduce Signature Activation, a saliency method that generates holistic and class-agnostic explanations for Convolutional Neural Network (CNN) outputs. Our method exploits the fact that certain kinds of medical images, such as angiograms, have clear foreground and background objects. We give theoretical explanation to justify our methods. We show the potential use of our method in clinical settings through evaluating its efficacy for aiding the detection of lesions in coronary angiograms.", "url": "https://arxiv.org/abs/2309.11443"}, {"metadata": {"arXiv": "2309.11499", "Date": "Wed, 20 Sep 2023 17:58:05 ", "Title": "DreamLLM: Synergistic Multimodal Comprehension and Creation", "Authors": ["Runpei Dong", "Chunrui Han", "Yuang Peng", "Zekun Qi", "Zheng Ge", "Jinrong Yang", "Liang Zhao", "Jianjian Sun", "Hongyu Zhou", "Haoran Wei", "Xiangwen Kong", "Xiangyu Zhang", "Kaisheng Ma", "Li Yi"], "Categories": "cs.CV cs.CL cs.LG", "Comments": ["see project page at https://dreamllm.github.io/"]}, "abstract": "This paper presents DreamLLM, a learning framework that first achieves versatile Multimodal Large Language Models (MLLMs) empowered with frequently overlooked synergy between multimodal comprehension and creation. DreamLLM operates on two fundamental principles. The first focuses on the generative modeling of both language and image posteriors by direct sampling in the raw multimodal space. This approach circumvents the limitations and information loss inherent to external feature extractors like CLIP, and a more thorough multimodal understanding is obtained. Second, DreamLLM fosters the generation of raw, interleaved documents, modeling both text and image contents, along with unstructured layouts. This allows DreamLLM to learn all conditional, marginal, and joint multimodal distributions effectively. As a result, DreamLLM is the first MLLM capable of generating free-form interleaved content. Comprehensive experiments highlight DreamLLM's superior performance as a zero-shot multimodal generalist, reaping from the enhanced learning synergy.", "url": "https://arxiv.org/abs/2309.11499"}, {"metadata": {"arXiv": "2309.10831", "Date": "Mon, 18 Sep 2023 18:05:35 ", "Title": "Actively Learning Reinforcement Learning: A Stochastic Optimal Control Approach", "Authors": ["Mohammad S. Ramadan", "Mahmoud A. Hayajnh", "Michael T. Tolley", "Kyriakos G. Vamvoudakis"], "Categories": "cs.LG cs.SY eess.SY"}, "abstract": "In this paper we provide framework to cope with two problems: (i) the fragility of reinforcement learning due to modeling uncertainties because of the mismatch between controlled laboratory/simulation and real-world conditions and (ii) the prohibitive computational cost of stochastic optimal control. We approach both problems by using reinforcement learning to solve the stochastic dynamic programming equation. The resulting reinforcement learning controller is safe with respect to several types of constraints constraints and it can actively learn about the modeling uncertainties. Unlike exploration and exploitation, probing and safety are employed automatically by the controller itself, resulting real-time learning. A simulation example demonstrates the efficacy of the proposed approach.", "url": "https://arxiv.org/abs/2309.10831"}, {"metadata": {"arXiv": "2309.10834", "Date": "Tue, 19 Sep 2023 14:05:12 ", "Title": "Sparser Random Networks Exist: Enforcing Communication-Efficient Federated Learning via Regularization", "Authors": ["Mohamad Mestoukirdi", "Omid Esrafilian", "David Gesbert", "Qianrui Li", "Nicolas Gresset"], "Categories": "cs.LG cs.CV cs.DC cs.DS", "Comments": ["Draft to be submitted"]}, "abstract": "This work presents a new method for enhancing communication efficiency in stochastic Federated Learning that trains over-parameterized random networks. In this setting, a binary mask is optimized instead of the model weights, which are kept fixed. The mask characterizes a sparse sub-network that is able to generalize as good as a smaller target network. Importantly, sparse binary masks are exchanged rather than the floating point weights in traditional federated learning, reducing communication cost to at most 1 bit per parameter. We show that previous state of the art stochastic methods fail to find the sparse networks that can reduce the communication and storage overhead using consistent loss objectives. To address this, we propose adding a regularization term to local objectives that encourages sparser solutions by eliminating redundant features across sub-networks. Extensive experiments demonstrate significant improvements in communication and memory efficiency of up to five magnitudes compared to the literature, with minimal performance degradation in validation accuracy in some instances.", "url": "https://arxiv.org/abs/2309.10834"}, {"metadata": {"arXiv": "2309.10878", "Date": "Tue, 19 Sep 2023 18:58:38 ", "Title": "DeepliteRT: Computer Vision at the Edge", "Authors": ["Saad Ashfaq", "Alexander Hoffman", "Saptarshi Mitra", "Sudhakar Sah", "MohammadHossein AskariHemmat", "Ehsan Saboori"], "Categories": "cs.LG cs.CV", "Comments": ["Accepted at British Machine Vision Conference (BMVC) 2023"]}, "abstract": "The proliferation of edge devices has unlocked unprecedented opportunities for deep learning model deployment in computer vision applications. However, these complex models require considerable power, memory and compute resources that are typically not available on edge platforms. Ultra low-bit quantization presents an attractive solution to this problem by scaling down the model weights and activations from 32-bit to less than 8-bit. We implement highly optimized ultra low-bit convolution operators for ARM-based targets that outperform existing methods by up to 4.34x. Our operator is implemented within Deeplite Runtime (DeepliteRT), an end-to-end solution for the compilation, tuning, and inference of ultra low-bit models on ARM devices. Compiler passes in DeepliteRT automatically convert a fake-quantized model in full precision to a compact ultra low-bit representation, easing the process of quantized model deployment on commodity hardware. We analyze the performance of DeepliteRT on classification and detection models against optimized 32-bit floating-point, 8-bit integer, and 2-bit baselines, achieving significant speedups of up to 2.20x, 2.33x and 2.17x, respectively.", "url": "https://arxiv.org/abs/2309.10878"}, {"metadata": {"arXiv": "2309.10916", "Date": "Tue, 19 Sep 2023 20:28:24 ", "Title": "What Learned Representations and Influence Functions Can Tell Us About Adversarial Examples", "Authors": ["Shakila Mahjabin Tonni and Mark Dras"], "Categories": "cs.LG cs.CL", "Comments": ["20 pages", "Accepted long-paper IJCNLP_AACL 2023"]}, "abstract": "Adversarial examples, deliberately crafted using small perturbations to fool deep neural networks, were first studied in image processing and more recently in NLP. While approaches to detecting adversarial examples in NLP have largely relied on search over input perturbations, image processing has seen a range of techniques that aim to characterise adversarial subspaces over the learned representations. In this paper, we adapt two such approaches to NLP, one based on nearest neighbors and influence functions and one on Mahalanobis distances. The former in particular produces a state-of-the-art detector when compared against several strong baselines; moreover, the novel use of influence functions provides insight into how the nature of adversarial example subspaces in NLP relate to those in image processing, and also how they differ depending on the kind of NLP task.", "url": "https://arxiv.org/abs/2309.10916"}, {"metadata": {"arXiv": "2309.10948", "Date": "Tue, 19 Sep 2023 22:14:52 ", "Title": "A Novel Deep Neural Network for Trajectory Prediction in Automated Vehicles Using Velocity Vector Field", "Authors": ["MReza Alipour Sormoli", "Amir Samadi", "Sajjad Mozaffari", "Konstantinos Koufos", "Mehrdad Dianati and Roger Woodman"], "Categories": "cs.LG cs.CV", "Comments": ["This paper has been accepted and nominated as the best student paper at the 26th IEEE International Conference on Intelligent Transportation Systems (ITSC 2023)"]}, "abstract": "Anticipating the motion of other road users is crucial for automated driving systems (ADS), as it enables safe and informed downstream decision-making and motion planning. Unfortunately, contemporary learning-based approaches for motion prediction exhibit significant performance degradation as the prediction horizon increases or the observation window decreases. This paper proposes a novel technique for trajectory prediction that combines a data-driven learning-based method with a velocity vector field (VVF) generated from a nature-inspired concept, i.e., fluid flow dynamics. In this work, the vector field is incorporated as an additional input to a convolutional-recurrent deep neural network to help predict the most likely future trajectories given a sequence of bird's eye view scene representations. The performance of the proposed model is compared with state-of-the-art methods on the HighD dataset demonstrating that the VVF inclusion improves the prediction accuracy for both short and long-term (5~sec) time horizons. It is also shown that the accuracy remains consistent with decreasing observation windows which alleviates the requirement of a long history of past observations for accurate trajectory prediction. Source codes are available at: https://github.com/Amir-Samadi/VVF-TP.", "url": "https://arxiv.org/abs/2309.10948"}, {"metadata": {"arXiv": "2309.10975", "Date": "Wed, 20 Sep 2023 00:35:16 ", "Title": "SPFQ: A Stochastic Algorithm and Its Error Analysis for Neural Network Quantization", "Authors": ["Jinjie Zhang", "Rayan Saab"], "Categories": "cs.LG stat.ML"}, "abstract": "Quantization is a widely used compression method that effectively reduces redundancies in over-parameterized neural networks. However, existing quantization techniques for deep neural networks often lack a comprehensive error analysis due to the presence of non-convex loss functions and nonlinear activations. In this paper, we propose a fast stochastic algorithm for quantizing the weights of fully trained neural networks. Our approach leverages a greedy path-following mechanism in combination with a stochastic quantizer. Its computational complexity scales only linearly with the number of weights in the network, thereby enabling the efficient quantization of large networks. Importantly, we establish, for the first time, full-network error bounds, under an infinite alphabet condition and minimal assumptions on the weights and input data. As an application of this result, we prove that when quantizing a multi-layer network having Gaussian weights, the relative square quantization error exhibits a linear decay as the degree of over-parametrization increases. Furthermore, we demonstrate that it is possible to achieve error bounds equivalent to those obtained in the infinite alphabet case, using on the order of a mere $\\log\\log N$ bits per weight, where $N$ represents the largest number of neurons in a layer.", "url": "https://arxiv.org/abs/2309.10975"}, {"metadata": {"arXiv": "2309.10976", "Date": "Wed, 20 Sep 2023 00:35:27 ", "Title": "Accurate and Scalable Estimation of Epistemic Uncertainty for Graph Neural Networks", "Authors": ["Puja Trivedi", "Mark Heimann", "Rushil Anirudh", "Danai Koutra", "Jayaraman J. Thiagarajan"], "Categories": "cs.LG", "Comments": ["22 pages", "11 figures"]}, "abstract": "Safe deployment of graph neural networks (GNNs) under distribution shift requires models to provide accurate confidence indicators (CI). However, while it is well-known in computer vision that CI quality diminishes under distribution shift, this behavior remains understudied for GNNs. Hence, we begin with a case study on CI calibration under controlled structural and feature distribution shifts and demonstrate that increased expressivity or model size do not always lead to improved CI performance. Consequently, we instead advocate for the use of epistemic uncertainty quantification (UQ) methods to modulate CIs. To this end, we propose G-$\\Delta$UQ, a new single model UQ method that extends the recently proposed stochastic centering framework to support structured data and partial stochasticity. Evaluated across covariate, concept, and graph size shifts, G-$\\Delta$UQ not only outperforms several popular UQ methods in obtaining calibrated CIs, but also outperforms alternatives when CIs are used for generalization gap prediction or OOD detection. Overall, our work not only introduces a new, flexible GNN UQ method, but also provides novel insights into GNN CIs on safety-critical tasks.", "url": "https://arxiv.org/abs/2309.10976"}, {"metadata": {"arXiv": "2309.10977", "Date": "Wed, 20 Sep 2023 00:37:35 ", "Title": "PAGER: A Framework for Failure Analysis of Deep Regression Models", "Authors": ["Jayaraman J. Thiagarajan", "Vivek Narayanaswamy", "Puja Trivedi", "Rushil Anirudh"], "Categories": "cs.LG stat.ML"}, "abstract": "Safe deployment of AI models requires proactive detection of potential prediction failures to prevent costly errors. While failure detection in classification problems has received significant attention, characterizing failure modes in regression tasks is more complicated and less explored. Existing approaches rely on epistemic uncertainties or feature inconsistency with the training distribution to characterize model risk. However, we show that uncertainties are necessary but insufficient to accurately characterize failure, owing to the various sources of error. In this paper, we propose PAGER (Principled Analysis of Generalization Errors in Regressors), a framework to systematically detect and characterize failures in deep regression models. Built upon the recently proposed idea of anchoring in deep models, PAGER unifies both epistemic uncertainties and novel, complementary non-conformity scores to organize samples into different risk regimes, thereby providing a comprehensive analysis of model errors. Additionally, we introduce novel metrics for evaluating failure detectors in regression tasks. We demonstrate the effectiveness of PAGER on synthetic and real-world benchmarks. Our results highlight the capability of PAGER to identify regions of accurate generalization and detect failure cases in out-of-distribution and out-of-support scenarios.", "url": "https://arxiv.org/abs/2309.10977"}, {"metadata": {"arXiv": "2309.10979", "Date": "Wed, 20 Sep 2023 00:40:13 ", "Title": "Towards Data-centric Graph Machine Learning: Review and Outlook", "Authors": ["Xin Zheng", "Yixin Liu", "Zhifeng Bao", "Meng Fang", "Xia Hu", "Alan Wee-Chung Liew", "Shirui Pan"], "Categories": "cs.LG", "Comments": ["42 pages", "9 figures"]}, "abstract": "Data-centric AI, with its primary focus on the collection, management, and utilization of data to drive AI models and applications, has attracted increasing attention in recent years. In this article, we conduct an in-depth and comprehensive review, offering a forward-looking outlook on the current efforts in data-centric AI pertaining to graph data-the fundamental data structure for representing and capturing intricate dependencies among massive and diverse real-life entities. We introduce a systematic framework, Data-centric Graph Machine Learning (DC-GML), that encompasses all stages of the graph data lifecycle, including graph data collection, exploration, improvement, exploitation, and maintenance. A thorough taxonomy of each stage is presented to answer three critical graph-centric questions: (1) how to enhance graph data availability and quality; (2) how to learn from graph data with limited-availability and low-quality; (3) how to build graph MLOps systems from the graph data-centric view. Lastly, we pinpoint the future prospects of the DC-GML domain, providing insights to navigate its advancements and applications.", "url": "https://arxiv.org/abs/2309.10979"}, {"metadata": {"arXiv": "2309.11005", "Date": "Wed, 20 Sep 2023 02:16:19 ", "Title": "It's Simplex! Disaggregating Measures to Improve Certified Robustness", "Authors": ["Andrew C. Cullen and Paul Montague and Shijie Liu and Sarah M. Erfani and Benjamin I.P. Rubinstein"], "Categories": "cs.LG cs.CR", "Comments": ["IEEE S&P 2024", "IEEE Security & Privacy 2024", "14 pages"]}, "abstract": "Certified robustness circumvents the fragility of defences against adversarial attacks, by endowing model predictions with guarantees of class invariance for attacks up to a calculated size. While there is value in these certifications, the techniques through which we assess their performance do not present a proper accounting of their strengths and weaknesses, as their analysis has eschewed consideration of performance over individual samples in favour of aggregated measures. By considering the potential output space of certified models, this work presents two distinct approaches to improve the analysis of certification mechanisms, that allow for both dataset-independent and dataset-dependent measures of certification performance. Embracing such a perspective uncovers new certification approaches, which have the potential to more than double the achievable radius of certification, relative to current state-of-the-art. Empirical evaluation verifies that our new approach can certify $9\\%$ more samples at noise scale $\\sigma = 1$, with greater relative improvements observed as the difficulty of the predictive task increases.", "url": "https://arxiv.org/abs/2309.11005"}, {"metadata": {"arXiv": "2309.11018", "Date": "Wed, 20 Sep 2023 02:40:59 ", "Title": "Conformalized Multimodal Uncertainty Regression and Reasoning", "Authors": ["Domenico Parente", "Nastaran Darabi", "Alex C. Stutts", "Theja Tulabandhula", "and Amit Ranjan Trivedi"], "Categories": "cs.LG cs.CV cs.RO"}, "abstract": "This paper introduces a lightweight uncertainty estimator capable of predicting multimodal (disjoint) uncertainty bounds by integrating conformal prediction with a deep-learning regressor. We specifically discuss its application for visual odometry (VO), where environmental features such as flying domain symmetries and sensor measurements under ambiguities and occlusion can result in multimodal uncertainties. Our simulation results show that uncertainty estimates in our framework adapt sample-wise against challenging operating conditions such as pronounced noise, limited training data, and limited parametric size of the prediction model. We also develop a reasoning framework that leverages these robust uncertainty estimates and incorporates optical flow-based reasoning to improve prediction prediction accuracy. Thus, by appropriately accounting for predictive uncertainties of data-driven learning and closing their estimation loop via rule-based reasoning, our methodology consistently surpasses conventional deep learning approaches on all these challenging scenarios--pronounced noise, limited training data, and limited model size-reducing the prediction error by 2-3x.", "url": "https://arxiv.org/abs/2309.11018"}, {"metadata": {"arXiv": "2309.11022", "Date": "Wed, 20 Sep 2023 02:55:03 ", "Title": "Information Leakage from Data Updates in Machine Learning Models", "Authors": ["Tian Hui", "Farhad Farokhi", "Olga Ohrimenko"], "Categories": "cs.LG cs.CR", "Journal-ref": "Proceedings of the 16th ACM Workshop on Artificial Intelligence and Security (AISec '23), November 30, 2023, Copenhagen, Denmark"}, "abstract": "In this paper we consider the setting where machine learning models are retrained on updated datasets in order to incorporate the most up-to-date information or reflect distribution shifts. We investigate whether one can infer information about these updates in the training data (e.g., changes to attribute values of records). Here, the adversary has access to snapshots of the machine learning model before and after the change in the dataset occurs. Contrary to the existing literature, we assume that an attribute of a single or multiple training data points are changed rather than entire data records are removed or added. We propose attacks based on the difference in the prediction confidence of the original model and the updated model. We evaluate our attack methods on two public datasets along with multi-layer perceptron and logistic regression models. We validate that two snapshots of the model can result in higher information leakage in comparison to having access to only the updated model. Moreover, we observe that data records with rare values are more vulnerable to attacks, which points to the disparate vulnerability of privacy attacks in the update setting. When multiple records with the same original attribute value are updated to the same new value (i.e., repeated changes), the attacker is more likely to correctly guess the updated values since repeated changes leave a larger footprint on the trained model. These observations point to vulnerability of machine learning models to attribute inference attacks in the update setting.", "url": "https://arxiv.org/abs/2309.11022"}, {"metadata": {"arXiv": "2309.11036", "Date": "Wed, 20 Sep 2023 03:31:11 ", "Title": "A Region-Shrinking-Based Acceleration for Classification-Based Derivative-Free Optimization", "Authors": ["Tianyi Han", "Jingya Li", "Zhipeng Guo and Yuan Jin"], "Categories": "cs.LG cs.NA math.NA math.OC"}, "abstract": "Derivative-free optimization algorithms play an important role in scientific and engineering design optimization problems, especially when derivative information is not accessible. In this paper, we study the framework of classification-based derivative-free optimization algorithms. By introducing a concept called hypothesis-target shattering rate, we revisit the computational complexity upper bound of this type of algorithms. Inspired by the revisited upper bound, we propose an algorithm named \"RACE-CARS\", which adds a random region-shrinking step compared with \"SRACOS\" (Hu et al., 2017).. We further establish a theorem showing the acceleration of region-shrinking. Experiments on the synthetic functions as well as black-box tuning for language-model-as-a-service demonstrate empirically the efficiency of \"RACE-CARS\". An ablation experiment on the introduced hyperparameters is also conducted, revealing the mechanism of \"RACE-CARS\" and putting forward an empirical hyperparameter-tuning guidance.", "url": "https://arxiv.org/abs/2309.11036"}, {"metadata": {"arXiv": "2309.11048", "Date": "Wed, 20 Sep 2023 03:52:04 ", "Title": "Containing Analog Data Deluge at Edge through Frequency-Domain Compression in Collaborative Compute-in-Memory Networks", "Authors": ["Nastaran Darabi", "and Amit R. Trivedi"], "Categories": "cs.LG", "Comments": ["arXiv admin note: text overlap with arXiv:2307.03863", "arXiv:2309.01771"]}, "abstract": "Edge computing is a promising solution for handling high-dimensional, multispectral analog data from sensors and IoT devices for applications such as autonomous drones. However, edge devices' limited storage and computing resources make it challenging to perform complex predictive modeling at the edge. Compute-in-memory (CiM) has emerged as a principal paradigm to minimize energy for deep learning-based inference at the edge. Nevertheless, integrating storage and processing complicates memory cells and/or memory peripherals, essentially trading off area efficiency for energy efficiency. This paper proposes a novel solution to improve area efficiency in deep learning inference tasks. The proposed method employs two key strategies. Firstly, a Frequency domain learning approach uses binarized Walsh-Hadamard Transforms, reducing the necessary parameters for DNN (by 87% in MobileNetV2) and enabling compute-in-SRAM, which better utilizes parallelism during inference. Secondly, a memory-immersed collaborative digitization method is described among CiM arrays to reduce the area overheads of conventional ADCs. This facilitates more CiM arrays in limited footprint designs, leading to better parallelism and reduced external memory accesses. Different networking configurations are explored, where Flash, SA, and their hybrid digitization steps can be implemented using the memory-immersed scheme. The results are demonstrated using a 65 nm CMOS test chip, exhibiting significant area and energy savings compared to a 40 nm-node 5-bit SAR ADC and 5-bit Flash ADC. By processing analog data more efficiently, it is possible to selectively retain valuable data from sensors and alleviate the challenges posed by the analog data deluge.", "url": "https://arxiv.org/abs/2309.11048"}, {"metadata": {"arXiv": "2309.11071", "Date": "Wed, 20 Sep 2023 05:34:52 ", "Title": "InkStream: Real-time GNN Inference on Streaming Graphs via Incremental Update", "Authors": ["Dan Wu", "Zhaoying Li", "Tulika Mitra"], "Categories": "cs.LG cs.DC"}, "abstract": "Classic Graph Neural Network (GNN) inference approaches, designed for static graphs, are ill-suited for streaming graphs that evolve with time. The dynamism intrinsic to streaming graphs necessitates constant updates, posing unique challenges to acceleration on GPU. We address these challenges based on two key insights: (1) Inside the $k$-hop neighborhood, a significant fraction of the nodes is not impacted by the modified edges when the model uses min or max as aggregation function; (2) When the model weights remain static while the graph structure changes, node embeddings can incrementally evolve over time by computing only the impacted part of the neighborhood. With these insights, we propose a novel method, InkStream, designed for real-time inference with minimal memory access and computation, while ensuring an identical output to conventional methods. InkStream operates on the principle of propagating and fetching data only when necessary. It uses an event-based system to control inter-layer effect propagation and intra-layer incremental updates of node embedding. InkStream is highly extensible and easily configurable by allowing users to create and process customized events. We showcase that less than 10 lines of additional user code are needed to support popular GNN models such as GCN, GraphSAGE, and GIN. Our experiments with three GNN models on four large graphs demonstrate that InkStream accelerates by 2.5-427$\\times$ on a CPU cluster and 2.4-343$\\times$ on two different GPU clusters while producing identical outputs as GNN model inference on the latest graph snapshot.", "url": "https://arxiv.org/abs/2309.11071"}, {"metadata": {"arXiv": "2309.11076", "Date": "Wed, 20 Sep 2023 05:44:49 ", "Title": "GPSINDy: Data-Driven Discovery of Equations of Motion", "Authors": ["Junette Hsin", "Shubhankar Agarwal", "Adam Thorpe", "David Fridovich-Keil"], "Categories": "cs.LG cs.SY eess.SY", "Comments": ["Submitted to ICRA 2024"]}, "abstract": "In this paper, we consider the problem of discovering dynamical system models from noisy data. The presence of noise is known to be a significant problem for symbolic regression algorithms. We combine Gaussian process regression, a nonparametric learning method, with SINDy, a parametric learning approach, to identify nonlinear dynamical systems from data. The key advantages of our proposed approach are its simplicity coupled with the fact that it demonstrates improved robustness properties with noisy data over SINDy. We demonstrate our proposed approach on a Lotka-Volterra model and a unicycle dynamic model in simulation and on an NVIDIA JetRacer system using hardware data. We demonstrate improved performance over SINDy for discovering the system dynamics and predicting future trajectories.", "url": "https://arxiv.org/abs/2309.11076"}, {"metadata": {"arXiv": "2309.11096", "Date": "Wed, 20 Sep 2023 07:04:46 ", "Title": "Delays in Reinforcement Learning", "Authors": ["Pierre Liotet"], "Categories": "cs.LG"}, "abstract": "Delays are inherent to most dynamical systems. Besides shifting the process in time, they can significantly affect their performance. For this reason, it is usually valuable to study the delay and account for it. Because they are dynamical systems, it is of no surprise that sequential decision-making problems such as Markov decision processes (MDP) can also be affected by delays. These processes are the foundational framework of reinforcement learning (RL), a paradigm whose goal is to create artificial agents capable of learning to maximise their utility by interacting with their environment. RL has achieved strong, sometimes astonishing, empirical results, but delays are seldom explicitly accounted for. The understanding of the impact of delay on the MDP is limited. In this dissertation, we propose to study the delay in the agent's observation of the state of the environment or in the execution of the agent's actions. We will repeatedly change our point of view on the problem to reveal some of its structure and peculiarities. A wide spectrum of delays will be considered, and potential solutions will be presented. This dissertation also aims to draw links between celebrated frameworks of the RL literature and the one of delays.", "url": "https://arxiv.org/abs/2309.11096"}, {"metadata": {"arXiv": "2309.11103", "Date": "Wed, 20 Sep 2023 07:17:28 ", "Title": "Bold but Cautious: Unlocking the Potential of Personalized Federated Learning through Cautiously Aggressive Collaboration", "Authors": ["Xinghao Wu", "Xuefeng Liu", "Jianwei Niu", "Guogang Zhu", "Shaojie Tang"], "Categories": "cs.LG", "Comments": ["Accepted by ICCV2023"]}, "abstract": "Personalized federated learning (PFL) reduces the impact of non-independent and identically distributed (non-IID) data among clients by allowing each client to train a personalized model when collaborating with others. A key question in PFL is to decide which parameters of a client should be localized or shared with others. In current mainstream approaches, all layers that are sensitive to non-IID data (such as classifier layers) are generally personalized. The reasoning behind this approach is understandable, as localizing parameters that are easily influenced by non-IID data can prevent the potential negative effect of collaboration. However, we believe that this approach is too conservative for collaboration. For example, for a certain client, even if its parameters are easily influenced by non-IID data, it can still benefit by sharing these parameters with clients having similar data distribution. This observation emphasizes the importance of considering not only the sensitivity to non-IID data but also the similarity of data distribution when determining which parameters should be localized in PFL. This paper introduces a novel guideline for client collaboration in PFL. Unlike existing approaches that prohibit all collaboration of sensitive parameters, our guideline allows clients to share more parameters with others, leading to improved model performance. Additionally, we propose a new PFL method named FedCAC, which employs a quantitative metric to evaluate each parameter's sensitivity to non-IID data and carefully selects collaborators based on this evaluation. Experimental results demonstrate that FedCAC enables clients to share more parameters with others, resulting in superior performance compared to state-of-the-art methods, particularly in scenarios where clients have diverse distributions.", "url": "https://arxiv.org/abs/2309.11103"}, {"metadata": {"arXiv": "2309.11193", "Date": "Wed, 20 Sep 2023 10:27:41 ", "Title": "RHALE: Robust and Heterogeneity-aware Accumulated Local Effects", "Authors": ["Vasilis Gkolemis", "Theodore Dalamagas", "Eirini Ntoutsi", "Christos Diou"], "Categories": "cs.LG", "Comments": ["Accepted at ECAI 2023 (European Conference on Artificial Intelligence)"]}, "abstract": "Accumulated Local Effects (ALE) is a widely-used explainability method for isolating the average effect of a feature on the output, because it handles cases with correlated features well. However, it has two limitations. First, it does not quantify the deviation of instance-level (local) effects from the average (global) effect, known as heterogeneity. Second, for estimating the average effect, it partitions the feature domain into user-defined, fixed-sized bins, where different bin sizes may lead to inconsistent ALE estimations. To address these limitations, we propose Robust and Heterogeneity-aware ALE (RHALE). RHALE quantifies the heterogeneity by considering the standard deviation of the local effects and automatically determines an optimal variable-size bin-splitting. In this paper, we prove that to achieve an unbiased approximation of the standard deviation of local effects within each bin, bin splitting must follow a set of sufficient conditions. Based on these conditions, we propose an algorithm that automatically determines the optimal partitioning, balancing the estimation bias and variance. Through evaluations on synthetic and real datasets, we demonstrate the superiority of RHALE compared to other methods, including the advantages of automatic bin splitting, especially in cases with correlated features.", "url": "https://arxiv.org/abs/2309.11193"}, {"metadata": {"arXiv": "2309.11197", "Date": "Wed, 20 Sep 2023 10:31:17 ", "Title": "The Languini Kitchen: Enabling Language Modelling Research at Different Scales of Compute", "Authors": ["Aleksandar Stani\\'c", "Dylan Ashley", "Oleg Serikov", "Louis Kirsch", "Francesco Faccio", "J\\\"urgen Schmidhuber", "Thomas Hofmann", "Imanol Schlag"], "Categories": "cs.LG cs.CL"}, "abstract": "The Languini Kitchen serves as both a research collective and codebase designed to empower researchers with limited computational resources to contribute meaningfully to the field of language modelling. We introduce an experimental protocol that enables model comparisons based on equivalent compute, measured in accelerator hours. The number of tokens on which a model is trained is defined by the model's throughput and the chosen compute class. Notably, this approach avoids constraints on critical hyperparameters which affect total parameters or floating-point operations. For evaluation, we pre-process an existing large, diverse, and high-quality dataset of books that surpasses existing academic benchmarks in quality, diversity, and document length. On it, we compare methods based on their empirical scaling trends which are estimated through experiments at various levels of compute. This work also provides two baseline models: a feed-forward model derived from the GPT-2 architecture and a recurrent model in the form of a novel LSTM with ten-fold throughput. While the GPT baseline achieves better perplexity throughout all our levels of compute, our LSTM baseline exhibits a predictable and more favourable scaling law. This is due to the improved throughput and the need for fewer training tokens to achieve the same decrease in test perplexity. Extrapolating the scaling laws leads of both models results in an intersection at roughly 50,000 accelerator hours. We hope this work can serve as the foundation for meaningful and reproducible language modelling research.", "url": "https://arxiv.org/abs/2309.11197"}, {"metadata": {"arXiv": "2309.11226", "Date": "Wed, 20 Sep 2023 11:35:03 ", "Title": "Towards a Prediction of Machine Learning Training Time to Support Continuous Learning Systems Development", "Authors": ["Francesca Marzi", "Giordano d'Aloisio", "Antinisca Di Marco", "and Giovanni Stilo"], "Categories": "cs.LG cs.PF"}, "abstract": "The problem of predicting the training time of machine learning (ML) models has become extremely relevant in the scientific community. Being able to predict a priori the training time of an ML model would enable the automatic selection of the best model both in terms of energy efficiency and in terms of performance in the context of, for instance, MLOps architectures. In this paper, we present the work we are conducting towards this direction. In particular, we present an extensive empirical study of the Full Parameter Time Complexity (FPTC) approach by Zheng et al., which is, to the best of our knowledge, the only approach formalizing the training time of ML models as a function of both dataset's and model's parameters. We study the formulations proposed for the Logistic Regression and Random Forest classifiers, and we highlight the main strengths and weaknesses of the approach. Finally, we observe how, from the conducted study, the prediction of training time is strictly related to the context (i.e., the involved dataset) and how the FPTC approach is not generalizable.", "url": "https://arxiv.org/abs/2309.11226"}, {"metadata": {"arXiv": "2309.11246", "Date": "Wed, 20 Sep 2023 12:15:58 ", "Title": "Grassroots Operator Search for Model Edge Adaptation", "Authors": ["Hadjer Benmeziane", "Kaoutar El Maghraoui", "Hamza Ouarnoughi", "Smail Niar"], "Categories": "cs.LG cs.NE"}, "abstract": "Hardware-aware Neural Architecture Search (HW-NAS) is increasingly being used to design efficient deep learning architectures. An efficient and flexible search space is crucial to the success of HW-NAS. Current approaches focus on designing a macro-architecture and searching for the architecture's hyperparameters based on a set of possible values. This approach is biased by the expertise of deep learning (DL) engineers and standard modeling approaches. In this paper, we present a Grassroots Operator Search (GOS) methodology. Our HW-NAS adapts a given model for edge devices by searching for efficient operator replacement. We express each operator as a set of mathematical instructions that capture its behavior. The mathematical instructions are then used as the basis for searching and selecting efficient replacement operators that maintain the accuracy of the original model while reducing computational complexity. Our approach is grassroots since it relies on the mathematical foundations to construct new and efficient operators for DL architectures. We demonstrate on various DL models, that our method consistently outperforms the original models on two edge devices, namely Redmi Note 7S and Raspberry Pi3, with a minimum of 2.2x speedup while maintaining high accuracy. Additionally, we showcase a use case of our GOS approach in pulse rate estimation on wristband devices, where we achieve state-of-the-art performance, while maintaining reduced computational complexity, demonstrating the effectiveness of our approach in practical applications.", "url": "https://arxiv.org/abs/2309.11246"}, {"metadata": {"arXiv": "2309.11294", "Date": "Wed, 20 Sep 2023 13:21:12 ", "Title": "Beyond Accuracy: Measuring Representation Capacity of Embeddings to Preserve Structural and Contextual Information", "Authors": ["Sarwan Ali"], "Categories": "cs.LG", "Comments": ["Accepted at ISBRA 2023"]}, "abstract": "Effective representation of data is crucial in various machine learning tasks, as it captures the underlying structure and context of the data. Embeddings have emerged as a powerful technique for data representation, but evaluating their quality and capacity to preserve structural and contextual information remains a challenge. In this paper, we address this need by proposing a method to measure the \\textit{representation capacity} of embeddings. The motivation behind this work stems from the importance of understanding the strengths and limitations of embeddings, enabling researchers and practitioners to make informed decisions in selecting appropriate embedding models for their specific applications. By combining extrinsic evaluation methods, such as classification and clustering, with t-SNE-based neighborhood analysis, such as neighborhood agreement and trustworthiness, we provide a comprehensive assessment of the representation capacity. Additionally, the use of optimization techniques (bayesian optimization) for weight optimization (for classification, clustering, neighborhood agreement, and trustworthiness) ensures an objective and data-driven approach in selecting the optimal combination of metrics. The proposed method not only contributes to advancing the field of embedding evaluation but also empowers researchers and practitioners with a quantitative measure to assess the effectiveness of embeddings in capturing structural and contextual information. For the evaluation, we use $3$ real-world biological sequence (proteins and nucleotide) datasets and performed representation capacity analysis of $4$ embedding methods from the literature, namely Spike2Vec, Spaced $k$-mers, PWM2Vec, and AutoEncoder.", "url": "https://arxiv.org/abs/2309.11294"}, {"metadata": {"arXiv": "2309.11305", "Date": "Wed, 20 Sep 2023 13:30:49 ", "Title": "Create and Find Flatness: Building Flat Training Spaces in Advance for Continual Learning", "Authors": ["Wenhang Shi", "Yiren Chen", "Zhe Zhao", "Wei Lu", "Kimmo Yan", "Xiaoyong Du"], "Categories": "cs.LG", "Comments": ["10pages", "ECAI2023 conference"]}, "abstract": "Catastrophic forgetting remains a critical challenge in the field of continual learning, where neural networks struggle to retain prior knowledge while assimilating new information. Most existing studies emphasize mitigating this issue only when encountering new tasks, overlooking the significance of the pre-task phase. Therefore, we shift the attention to the current task learning stage, presenting a novel framework, C&F (Create and Find Flatness), which builds a flat training space for each task in advance. Specifically, during the learning of the current task, our framework adaptively creates a flat region around the minimum in the loss landscape. Subsequently, it finds the parameters' importance to the current task based on their flatness degrees. When adapting the model to a new task, constraints are applied according to the flatness and a flat space is simultaneously prepared for the impending task. We theoretically demonstrate the consistency between the created and found flatness. In this manner, our framework not only accommodates ample parameter space for learning new tasks but also preserves the preceding knowledge of earlier tasks. Experimental results exhibit C&F's state-of-the-art performance as a standalone continual learning approach and its efficacy as a framework incorporating other methods. Our work is available at https://github.com/Eric8932/Create-and-Find-Flatness.", "url": "https://arxiv.org/abs/2309.11305"}, {"metadata": {"arXiv": "2309.11319", "Date": "Wed, 20 Sep 2023 13:44:18 ", "Title": "WFTNet: Exploiting Global and Local Periodicity in Long-term Time Series Forecasting", "Authors": ["Peiyuan Liu", "Beiliang Wu", "Naiqi Li", "Tao Dai", "Fengmao Lei", "Jigang Bao", "Yong Jiang", "Shu-Tao Xia"], "Categories": "cs.LG"}, "abstract": "Recent CNN and Transformer-based models tried to utilize frequency and periodicity information for long-term time series forecasting. However, most existing work is based on Fourier transform, which cannot capture fine-grained and local frequency structure. In this paper, we propose a Wavelet-Fourier Transform Network (WFTNet) for long-term time series forecasting. WFTNet utilizes both Fourier and wavelet transforms to extract comprehensive temporal-frequency information from the signal, where Fourier transform captures the global periodic patterns and wavelet transform captures the local ones. Furthermore, we introduce a Periodicity-Weighted Coefficient (PWC) to adaptively balance the importance of global and local frequency patterns. Extensive experiments on various time series datasets show that WFTNet consistently outperforms other state-of-the-art baseline.", "url": "https://arxiv.org/abs/2309.11319"}, {"metadata": {"arXiv": "2309.11341", "Date": "Wed, 20 Sep 2023 14:18:04 ", "Title": "Improving Article Classification with Edge-Heterogeneous Graph Neural Networks", "Authors": ["Khang Ly", "Yury Kashnitsky", "Savvas Chamezopoulos", "Valeria Krzhizhanovskaya"], "Categories": "cs.LG cs.CL"}, "abstract": "Classifying research output into context-specific label taxonomies is a challenging and relevant downstream task, given the volume of existing and newly published articles. We propose a method to enhance the performance of article classification by enriching simple Graph Neural Networks (GNN) pipelines with edge-heterogeneous graph representations. SciBERT is used for node feature generation to capture higher-order semantics within the articles' textual metadata. Fully supervised transductive node classification experiments are conducted on the Open Graph Benchmark (OGB) ogbn-arxiv dataset and the PubMed diabetes dataset, augmented with additional metadata from Microsoft Academic Graph (MAG) and PubMed Central, respectively. The results demonstrate that edge-heterogeneous graphs consistently improve the performance of all GNN models compared to the edge-homogeneous graphs. The transformed data enable simple and shallow GNN pipelines to achieve results on par with more complex architectures. On ogbn-arxiv, we achieve a top-15 result in the OGB competition with a 2-layer GCN (accuracy 74.61%), being the highest-scoring solution with sub-1 million parameters. On PubMed, we closely trail SOTA GNN architectures using a 2-layer GraphSAGE by including additional co-authorship edges in the graph (accuracy 89.88%). The implementation is available at: $\\href{https://github.com/lyvykhang/edgehetero-nodeproppred}{\\text{https://github.com/lyvykhang/edgehetero-nodeproppred}}$.", "url": "https://arxiv.org/abs/2309.11341"}, {"metadata": {"arXiv": "2309.11343", "Date": "Wed, 20 Sep 2023 14:20:56 ", "Title": "Using Property Elicitation to Understand the Impacts of Fairness Constraints", "Authors": ["Jessie Finocchiaro"], "Categories": "cs.LG stat.ML", "Comments": ["Please reach out if you have comments or thoughts; this is a living project"]}, "abstract": "Predictive algorithms are often trained by optimizing some loss function, to which regularization functions are added to impose a penalty for violating constraints. As expected, the addition of such regularization functions can change the minimizer of the objective. It is not well-understood which regularizers change the minimizer of the loss, and, when the minimizer does change, how it changes. We use property elicitation to take first steps towards understanding the joint relationship between the loss and regularization functions and the optimal decision for a given problem instance. In particular, we give a necessary and sufficient condition on loss and regularizer pairs for when a property changes with the addition of the regularizer, and examine some regularizers satisfying this condition standard in the fair machine learning literature. We empirically demonstrate how algorithmic decision-making changes as a function of both data distribution changes and hardness of the constraints.", "url": "https://arxiv.org/abs/2309.11343"}, {"metadata": {"arXiv": "2309.11373", "Date": "Wed, 20 Sep 2023 14:54:48 ", "Title": "Learning Patient Static Information from Time-series EHR and an Approach for Safeguarding Privacy and Fairness", "Authors": ["Wei Liao", "Joel Voldman"], "Categories": "cs.LG cs.CY"}, "abstract": "Recent work in machine learning for healthcare has raised concerns about patient privacy and algorithmic fairness. For example, previous work has shown that patient self-reported race can be predicted from medical data that does not explicitly contain racial information. However, the extent of data identification is unknown, and we lack ways to develop models whose outcomes are minimally affected by such information. Here we systematically investigated the ability of time-series electronic health record data to predict patient static information. We found that not only the raw time-series data, but also learned representations from machine learning models, can be trained to predict a variety of static information with area under the receiver operating characteristic curve as high as 0.851 for biological sex, 0.869 for binarized age and 0.810 for self-reported race. Such high predictive performance can be extended to a wide range of comorbidity factors and exists even when the model was trained for different tasks, using different cohorts, using different model architectures and databases. Given the privacy and fairness concerns these findings pose, we develop a variational autoencoder-based approach that learns a structured latent space to disentangle patient-sensitive attributes from time-series data. Our work thoroughly investigates the ability of machine learning models to encode patient static information from time-series electronic health records and introduces a general approach to protect patient-sensitive attribute information for downstream tasks.", "url": "https://arxiv.org/abs/2309.11373"}, {"metadata": {"arXiv": "2309.11420", "Date": "Wed, 20 Sep 2023 15:51:10 ", "Title": "Deep Networks as Denoising Algorithms: Sample-Efficient Learning of Diffusion Models in High-Dimensional Graphical Models", "Authors": ["Song Mei", "Yuchen Wu"], "Categories": "cs.LG math.ST stat.ML stat.TH", "Comments": ["41 pages"]}, "abstract": "We investigate the approximation efficiency of score functions by deep neural networks in diffusion-based generative modeling. While existing approximation theories utilize the smoothness of score functions, they suffer from the curse of dimensionality for intrinsically high-dimensional data. This limitation is pronounced in graphical models such as Markov random fields, common for image distributions, where the approximation efficiency of score functions remains unestablished. To address this, we observe score functions can often be well-approximated in graphical models through variational inference denoising algorithms. Furthermore, these algorithms are amenable to efficient neural network representation. We demonstrate this in examples of graphical models, including Ising models, conditional Ising models, restricted Boltzmann machines, and sparse encoding models. Combined with off-the-shelf discretization error bounds for diffusion-based sampling, we provide an efficient sample complexity bound for diffusion-based generative modeling when the score function is learned by deep neural networks.", "url": "https://arxiv.org/abs/2309.11420"}, {"metadata": {"arXiv": "2309.11446", "Date": "Wed, 20 Sep 2023 16:23:30 ", "Title": "Weight Averaging Improves Knowledge Distillation under Domain Shift", "Authors": ["Valeriy Berezovskiy", "Nikita Morozov"], "Categories": "cs.LG cs.CV", "Comments": ["ICCV 2023 Workshop on Out-of-Distribution Generalization in Computer Vision (OOD-CV)"]}, "abstract": "Knowledge distillation (KD) is a powerful model compression technique broadly used in practical deep learning applications. It is focused on training a small student network to mimic a larger teacher network. While it is widely known that KD can offer an improvement to student generalization in i.i.d setting, its performance under domain shift, i.e. the performance of student networks on data from domains unseen during training, has received little attention in the literature. In this paper we make a step towards bridging the research fields of knowledge distillation and domain generalization. We show that weight averaging techniques proposed in domain generalization literature, such as SWAD and SMA, also improve the performance of knowledge distillation under domain shift. In addition, we propose a simplistic weight averaging strategy that does not require evaluation on validation data during training and show that it performs on par with SWAD and SMA when applied to KD. We name our final distillation approach Weight-Averaged Knowledge Distillation (WAKD).", "url": "https://arxiv.org/abs/2309.11446"}, {"metadata": {"arXiv": "2309.11461", "Date": "Wed, 20 Sep 2023 16:57:11 ", "Title": "Digital twins of nonlinear dynamical systems: A perspective", "Authors": ["Ying-Cheng Lai"], "Categories": "cs.LG math.DS nlin.CD physics.data-an", "Comments": ["12 pages", "3 figures"]}, "abstract": "Digital twins have attracted a great deal of recent attention from a wide range of fields. A basic requirement for digital twins of nonlinear dynamical systems is the ability to generate the system evolution and predict potentially catastrophic emergent behaviors so as to providing early warnings. The digital twin can then be used for system \"health\" monitoring in real time and for predictive problem solving. In particular, if the digital twin forecasts a possible system collapse in the future due to parameter drifting as caused by environmental changes or perturbations, an optimal control strategy can be devised and executed as early intervention to prevent the collapse. Two approaches exist for constructing digital twins of nonlinear dynamical systems: sparse optimization and machine learning. The basics of these two approaches are described and their advantages and caveats are discussed.", "url": "https://arxiv.org/abs/2309.11461"}, {"metadata": {"arXiv": "2309.11453", "Date": "Wed, 20 Sep 2023 16:35:29 ", "Title": "Multi-Step Model Predictive Safety Filters: Reducing Chattering by Increasing the Prediction Horizon", "Authors": ["Federico Pizarro Bejarano", "Lukas Brunke", "and Angela P. Schoellig"], "Categories": "cs.RO cs.LG cs.SY eess.SY", "Comments": ["8 pages", "9 figures. Accepted to IEEE CDC 2023. Code is publicly available at https://github.com/Federico-PizarroBejarano/safe-control-gym/tree/smooth_mpsc_paper"]}, "abstract": "Learning-based controllers have demonstrated superior performance compared to classical controllers in various tasks. However, providing safety guarantees is not trivial. Safety, the satisfaction of state and input constraints, can be guaranteed by augmenting the learned control policy with a safety filter. Model predictive safety filters (MPSFs) are a common safety filtering approach based on model predictive control (MPC). MPSFs seek to guarantee safety while minimizing the difference between the proposed and applied inputs in the immediate next time step. This limited foresight can lead to jerky motions and undesired oscillations close to constraint boundaries, known as chattering. In this paper, we reduce chattering by considering input corrections over a longer horizon. Under the assumption of bounded model uncertainties, we prove recursive feasibility using techniques from robust MPC. We verified the proposed approach in both extensive simulation and quadrotor experiments. In experiments with a Crazyflie 2.0 drone, we show that, in addition to preserving the desired safety guarantees, the proposed MPSF reduces chattering by more than a factor of 4 compared to previous MPSF formulations.", "url": "https://arxiv.org/abs/2309.11453"}, {"metadata": {"arXiv": "2309.11470", "Date": "Wed, 20 Sep 2023 17:10:10 ", "Title": "Model-free tracking control of complex dynamical trajectories with machine learning", "Authors": ["Zheng-Meng Zhai", "Mohammadamin Moradi", "Ling-Wei Kong", "Bryan Glaz", "Mulugeta Haile", "and Ying-Cheng Lai"], "Categories": "cs.RO cs.LG math.DS nlin.CD", "Comments": ["16 pages", "8 figures"], "Journal-ref": "Nat Commun 14, 5698 (2023)", "DOI": "10.1038/s41467-023-41379-3"}, "abstract": "Nonlinear tracking control enabling a dynamical system to track a desired trajectory is fundamental to robotics, serving a wide range of civil and defense applications. In control engineering, designing tracking control requires complete knowledge of the system model and equations. We develop a model-free, machine-learning framework to control a two-arm robotic manipulator using only partially observed states, where the controller is realized by reservoir computing. Stochastic input is exploited for training, which consists of the observed partial state vector as the first and its immediate future as the second component so that the neural machine regards the latter as the future state of the former. In the testing (deployment) phase, the immediate-future component is replaced by the desired observational vector from the reference trajectory. We demonstrate the effectiveness of the control framework using a variety of periodic and chaotic signals, and establish its robustness against measurement noise, disturbances, and uncertainties.", "url": "https://arxiv.org/abs/2309.11470"}, {"metadata": {"arXiv": "2309.10852", "Date": "Tue, 19 Sep 2023 18:01:25 ", "Title": "Using AI Uncertainty Quantification to Improve Human Decision-Making", "Authors": ["Laura R. Marusich", "Jonathan Z. Bakdash", "Yan Zhou", "Murat Kantarcioglu"], "Categories": "cs.AI cs.HC", "Comments": ["10 pages and 7 figures"]}, "abstract": "AI Uncertainty Quantification (UQ) has the potential to improve human decision-making beyond AI predictions alone by providing additional useful probabilistic information to users. The majority of past research on AI and human decision-making has concentrated on model explainability and interpretability. We implemented instance-based UQ for three real datasets. To achieve this, we trained different AI models for classification for each dataset, and used random samples generated around the neighborhood of the given instance to create confidence intervals for UQ. The computed UQ was calibrated using a strictly proper scoring rule as a form of quality assurance for UQ. We then conducted two preregistered online behavioral experiments that compared objective human decision-making performance under different AI information conditions, including UQ. In Experiment 1, we compared decision-making for no AI (control), AI prediction alone, and AI prediction with a visualization of UQ. We found UQ significantly improved decision-making beyond the other two conditions. In Experiment 2, we focused on comparing different representations of UQ information: Point vs. distribution of uncertainty and visualization type (needle vs. dotplot). We did not find meaningful differences in decision-making performance among these different representations of UQ. Overall, our results indicate that human decision-making can be improved by providing UQ information along with AI predictions, and that this benefit generalizes across a variety of representations of UQ.", "url": "https://arxiv.org/abs/2309.10852"}, {"metadata": {"arXiv": "2309.10871", "Date": "Tue, 19 Sep 2023 18:32:49 ", "Title": "Believable Minecraft Settlements by Means of Decentralised Iterative Planning", "Authors": ["Arthur van der Staaij", "Jelmer Prins", "Vincent L. Prins", "Julian Poelsma", "Thera Smit", "Matthias M\\\"uller-Brockhausen", "Mike Preuss"], "Categories": "cs.AI", "Comments": ["8 pages", "8 figures", "to be published in \"2023 IEEE Conference on Games (CoG)\""]}, "abstract": "Procedural city generation that focuses on believability and adaptability to random terrain is a difficult challenge in the field of Procedural Content Generation (PCG). Dozens of researchers compete for a realistic approach in challenges such as the Generative Settlement Design in Minecraft (GDMC), in which our method has won the 2022 competition. This was achieved through a decentralised, iterative planning process that is transferable to similar generation processes that aims to produce \"organic\" content procedurally.", "url": "https://arxiv.org/abs/2309.10871"}, {"metadata": {"arXiv": "2309.10892", "Date": "Tue, 19 Sep 2023 19:31:15 ", "Title": "Artificial Intelligence-Enabled Intelligent Assistant for Personalized and Adaptive Learning in Higher Education", "Authors": ["Ramteja Sajja", "Yusuf Sermet", "Muhammed Cikmaz", "David Cwiertny", "Ibrahim Demir"], "Categories": "cs.AI cs.HC cs.IR", "Comments": ["29 pages", "10 figures", "9659 words"]}, "abstract": "This paper presents a novel framework, Artificial Intelligence-Enabled Intelligent Assistant (AIIA), for personalized and adaptive learning in higher education. The AIIA system leverages advanced AI and Natural Language Processing (NLP) techniques to create an interactive and engaging learning platform. This platform is engineered to reduce cognitive load on learners by providing easy access to information, facilitating knowledge assessment, and delivering personalized learning support tailored to individual needs and learning styles. The AIIA's capabilities include understanding and responding to student inquiries, generating quizzes and flashcards, and offering personalized learning pathways. The research findings have the potential to significantly impact the design, implementation, and evaluation of AI-enabled Virtual Teaching Assistants (VTAs) in higher education, informing the development of innovative educational tools that can enhance student learning outcomes, engagement, and satisfaction. The paper presents the methodology, system architecture, intelligent services, and integration with Learning Management Systems (LMSs) while discussing the challenges, limitations, and future directions for the development of AI-enabled intelligent assistants in education.", "url": "https://arxiv.org/abs/2309.10892"}, {"metadata": {"arXiv": "2309.10982", "Date": "Wed, 20 Sep 2023 00:47:52 ", "Title": "Is GPT4 a Good Trader?", "Authors": ["Bingzhe Wu"], "Categories": "cs.AI"}, "abstract": "Recently, large language models (LLMs), particularly GPT-4, have demonstrated significant capabilities in various planning and reasoning tasks \\cite{cheng2023gpt4,bubeck2023sparks}. Motivated by these advancements, there has been a surge of interest among researchers to harness the capabilities of GPT-4 for the automated design of quantitative factors that do not overlap with existing factor libraries, with an aspiration to achieve alpha returns \\cite{webpagequant}. In contrast to these work, this study aims to examine the fidelity of GPT-4's comprehension of classic trading theories and its proficiency in applying its code interpreter abilities to real-world trading data analysis. Such an exploration is instrumental in discerning whether the underlying logic GPT-4 employs for trading is intrinsically reliable. Furthermore, given the acknowledged interpretative latitude inherent in most trading theories, we seek to distill more precise methodologies of deploying these theories from GPT-4's analytical process, potentially offering invaluable insights to human traders. To achieve this objective, we selected daily candlestick (K-line) data from specific periods for certain assets, such as the Shanghai Stock Index. Through meticulous prompt engineering, we guided GPT-4 to analyze the technical structures embedded within this data, based on specific theories like the Elliott Wave Theory. We then subjected its analytical output to manual evaluation, assessing its interpretative depth and accuracy vis-\\`a-vis these trading theories from multiple dimensions. The results and findings from this study could pave the way for a synergistic amalgamation of human expertise and AI-driven insights in the realm of trading.", "url": "https://arxiv.org/abs/2309.10982"}, {"metadata": {"arXiv": "2309.11064", "Date": "Wed, 20 Sep 2023 05:04:16 ", "Title": "Exploring the Relationship between LLM Hallucinations and Prompt Linguistic Nuances: Readability, Formality, and Concreteness", "Authors": ["Vipula Rawte", "Prachi Priya", "S.M Towhidul Islam Tonmoy", "S M Mehedi Zaman", "Amit Sheth", "Amitava Das"], "Categories": "cs.AI"}, "abstract": "As Large Language Models (LLMs) have advanced, they have brought forth new challenges, with one of the prominent issues being LLM hallucination. While various mitigation techniques are emerging to address hallucination, it is equally crucial to delve into its underlying causes. Consequently, in this preliminary exploratory investigation, we examine how linguistic factors in prompts, specifically readability, formality, and concreteness, influence the occurrence of hallucinations. Our experimental results suggest that prompts characterized by greater formality and concreteness tend to result in reduced hallucination. However, the outcomes pertaining to readability are somewhat inconclusive, showing a mixed pattern.", "url": "https://arxiv.org/abs/2309.11064"}, {"metadata": {"arXiv": "2309.11155", "Date": "Wed, 20 Sep 2023 09:03:56 ", "Title": "ProtoExplorer: Interpretable Forensic Analysis of Deepfake Videos using Prototype Exploration and Refinement", "Authors": ["Merel de Leeuw den Bouter", "Javier Lloret Pardo", "Zeno Geradts", "Marcel Worring"], "Categories": "cs.AI", "Comments": ["15 pages", "6 figures"]}, "abstract": "In high-stakes settings, Machine Learning models that can provide predictions that are interpretable for humans are crucial. This is even more true with the advent of complex deep learning based models with a huge number of tunable parameters. Recently, prototype-based methods have emerged as a promising approach to make deep learning interpretable. We particularly focus on the analysis of deepfake videos in a forensics context. Although prototype-based methods have been introduced for the detection of deepfake videos, their use in real-world scenarios still presents major challenges, in that prototypes tend to be overly similar and interpretability varies between prototypes. This paper proposes a Visual Analytics process model for prototype learning, and, based on this, presents ProtoExplorer, a Visual Analytics system for the exploration and refinement of prototype-based deepfake detection models. ProtoExplorer offers tools for visualizing and temporally filtering prototype-based predictions when working with video data. It disentangles the complexity of working with spatio-temporal prototypes, facilitating their visualization. It further enables the refinement of models by interactively deleting and replacing prototypes with the aim to achieve more interpretable and less biased predictions while preserving detection accuracy. The system was designed with forensic experts and evaluated in a number of rounds based on both open-ended think aloud evaluation and interviews. These sessions have confirmed the strength of our prototype based exploration of deepfake videos while they provided the feedback needed to continuously improve the system.", "url": "https://arxiv.org/abs/2309.11155"}, {"metadata": {"arXiv": "2309.11202", "Date": "Wed, 20 Sep 2023 10:38:08 ", "Title": "Using Artificial Intelligence for the Automation of Knitting Patterns", "Authors": ["Uduak Uboh"], "Categories": "cs.AI"}, "abstract": "Knitting patterns are a crucial component in the creation and design of knitted materials. Traditionally, these patterns were taught informally, but thanks to advancements in technology, anyone interested in knitting can use the patterns as a guide to start knitting. Perhaps because knitting is mostly a hobby, with the exception of industrial manufacturing utilising specialised knitting machines, the use of Al in knitting is less widespread than its application in other fields. However, it is important to determine whether knitted pattern classification using an automated system is viable. In order to recognise and classify knitting patterns. Using data augmentation and a transfer learning technique, this study proposes a deep learning model. The Inception ResNet-V2 is the main feature extraction and classification algorithm used in the model. Metrics like accuracy, logarithmic loss, F1-score, precision, and recall score were used to evaluate the model. The model evaluation's findings demonstrate high model accuracy, precision, recall, and F1 score. In addition, the AUC score for majority of the classes was in the range (0.7-0.9). A comparative analysis was done using other pretrained models and a ResNet-50 model with transfer learning and the proposed model evaluation results surpassed all others. The major limitation for this project is time, as with more time, there might have been better accuracy over a larger number of epochs.", "url": "https://arxiv.org/abs/2309.11202"}, {"metadata": {"arXiv": "2309.11224", "Date": "Wed, 20 Sep 2023 11:28:39 ", "Title": "Leveraging Diversity in Online Interactions", "Authors": ["Nardine Osman and Bruno Rosell i Gui and Carles Sierra"], "Categories": "cs.AI", "MSC-class": "68T01", "ACM-class": "H.0", "Journal-ref": "Workshops at the Second International Conference on Hybrid Human-Artificial Intelligence (HHAI-WS 2023), June 26-27, 2023, Munich, Germany"}, "abstract": "This paper addresses the issue of connecting people online to help them find support with their day-to-day problems. We make use of declarative norms for mediating online interactions, and we specifically focus on the issue of leveraging diversity when connecting people. We run pilots at different university sites, and the results show relative success in the diversity of the selected profiles, backed by high user satisfaction.", "url": "https://arxiv.org/abs/2309.11224"}, {"metadata": {"arXiv": "2309.11231", "Date": "Wed, 20 Sep 2023 11:44:45 ", "Title": "ChatGPT-4 as a Tool for Reviewing Academic Books in Spanish", "Authors": ["Jonnathan Berrezueta-Guzman", "Laura Malache-Silva and Stephan Krusche"], "Categories": "cs.AI", "Comments": ["Preprint. Paper accepted in the 18\\textsuperscript{th} Latin American Conference on Learning Technologies (LACLO 2023)", "14 pages"]}, "abstract": "This study evaluates the potential of ChatGPT-4, an artificial intelligence language model developed by OpenAI, as an editing tool for Spanish literary and academic books. The need for efficient and accessible reviewing and editing processes in the publishing industry has driven the search for automated solutions. ChatGPT-4, being one of the most advanced language models, offers notable capabilities in text comprehension and generation. In this study, the features and capabilities of ChatGPT-4 are analyzed in terms of grammatical correction, stylistic coherence, and linguistic enrichment of texts in Spanish. Tests were conducted with 100 literary and academic texts, where the edits made by ChatGPT-4 were compared to those made by expert human reviewers and editors. The results show that while ChatGPT-4 is capable of making grammatical and orthographic corrections with high accuracy and in a very short time, it still faces challenges in areas such as context sensitivity, bibliometric analysis, deep contextual understanding, and interaction with visual content like graphs and tables. However, it is observed that collaboration between ChatGPT-4 and human reviewers and editors can be a promising strategy for improving efficiency without compromising quality. Furthermore, the authors consider that ChatGPT-4 represents a valuable tool in the editing process, but its use should be complementary to the work of human editors to ensure high-caliber editing in Spanish literary and academic books.", "url": "https://arxiv.org/abs/2309.11231"}, {"metadata": {"arXiv": "2309.11236", "Date": "Wed, 20 Sep 2023 11:57:19 ", "Title": "Colour Passing Revisited: Lifted Model Construction with Commutative Factors", "Authors": ["Malte Luttermann", "Tanya Braun", "Ralf M\\\"oller", "Marcel Gehrke"], "Categories": "cs.AI"}, "abstract": "Lifted probabilistic inference exploits symmetries in a probabilistic model to allow for tractable probabilistic inference with respect to domain sizes. To apply lifted inference, a lifted representation has to be obtained, and to do so, the so-called colour passing algorithm is the state of the art. The colour passing algorithm, however, is bound to a specific inference algorithm and we found that it ignores commutativity of factors while constructing a lifted representation. We contribute a modified version of the colour passing algorithm that uses logical variables to construct a lifted representation independent of a specific inference algorithm while at the same time exploiting commutativity of factors during an offline-step. Our proposed algorithm efficiently detects more symmetries than the state of the art and thereby drastically increases compression, yielding significantly faster online query times for probabilistic inference when the resulting model is applied.", "url": "https://arxiv.org/abs/2309.11236"}, {"metadata": {"arXiv": "2309.11274", "Date": "Wed, 20 Sep 2023 12:58:35 ", "Title": "Machine Learning Data Suitability and Performance Testing Using Fault Injection Testing Framework", "Authors": ["Manal Rahal and Bestoun S. Ahmed and Jorgen Samuelsson"], "Categories": "cs.AI", "Comments": ["18 pages"]}, "abstract": "Creating resilient machine learning (ML) systems has become necessary to ensure production-ready ML systems that acquire user confidence seamlessly. The quality of the input data and the model highly influence the successful end-to-end testing in data-sensitive systems. However, the testing approaches of input data are not as systematic and are few compared to model testing. To address this gap, this paper presents the Fault Injection for Undesirable Learning in input Data (FIUL-Data) testing framework that tests the resilience of ML models to multiple intentionally-triggered data faults. Data mutators explore vulnerabilities of ML systems against the effects of different fault injections. The proposed framework is designed based on three main ideas: The mutators are not random; one data mutator is applied at an instance of time, and the selected ML models are optimized beforehand. This paper evaluates the FIUL-Data framework using data from analytical chemistry, comprising retention time measurements of anti-sense oligonucleotide. Empirical evaluation is carried out in a two-step process in which the responses of selected ML models to data mutation are analyzed individually and then compared with each other. The results show that the FIUL-Data framework allows the evaluation of the resilience of ML models. In most experiments cases, ML models show higher resilience at larger training datasets, where gradient boost performed better than support vector regression in smaller training sets. Overall, the mean squared error metric is useful in evaluating the resilience of models due to its higher sensitivity to data mutation.", "url": "https://arxiv.org/abs/2309.11274"}, {"metadata": {"arXiv": "2309.11284", "Date": "Wed, 20 Sep 2023 13:08:34 ", "Title": "Rethinking Sensors Modeling: Hierarchical Information Enhanced Traffic Forecasting", "Authors": ["Qian Ma", "Zijian Zhang", "Xiangyu Zhao", "Haoliang Li", "Hongwei Zhao", "Yiqi Wang", "Zitao Liu", "and Wanyu Wang"], "Categories": "cs.AI", "Comments": ["9 pages", "accepted by CIKM'23"], "DOI": "10.1145/3583780.3614910"}, "abstract": "With the acceleration of urbanization, traffic forecasting has become an essential role in smart city construction. In the context of spatio-temporal prediction, the key lies in how to model the dependencies of sensors. However, existing works basically only consider the micro relationships between sensors, where the sensors are treated equally, and their macroscopic dependencies are neglected. In this paper, we argue to rethink the sensor's dependency modeling from two hierarchies: regional and global perspectives. Particularly, we merge original sensors with high intra-region correlation as a region node to preserve the inter-region dependency. Then, we generate representative and common spatio-temporal patterns as global nodes to reflect a global dependency between sensors and provide auxiliary information for spatio-temporal dependency learning. In pursuit of the generality and reality of node representations, we incorporate a Meta GCN to calibrate the regional and global nodes in the physical data space. Furthermore, we devise the cross-hierarchy graph convolution to propagate information from different hierarchies. In a nutshell, we propose a Hierarchical Information Enhanced Spatio-Temporal prediction method, HIEST, to create and utilize the regional dependency and common spatio-temporal patterns. Extensive experiments have verified the leading performance of our HIEST against state-of-the-art baselines. We publicize the code to ease reproducibility.", "url": "https://arxiv.org/abs/2309.11284"}, {"metadata": {"arXiv": "2309.11356", "Date": "Wed, 20 Sep 2023 14:36:57 ", "Title": "A Comprehensive Survey on Rare Event Prediction", "Authors": ["Chathurangi Shyalika", "Ruwan Wickramarachchi", "Amit Sheth"], "Categories": "cs.AI", "Comments": ["44 pages"]}, "abstract": "Rare event prediction involves identifying and forecasting events with a low probability using machine learning and data analysis. Due to the imbalanced data distributions, where the frequency of common events vastly outweighs that of rare events, it requires using specialized methods within each step of the machine learning pipeline, i.e., from data processing to algorithms to evaluation protocols. Predicting the occurrences of rare events is important for real-world applications, such as Industry 4.0, and is an active research area in statistical and machine learning. This paper comprehensively reviews the current approaches for rare event prediction along four dimensions: rare event data, data processing, algorithmic approaches, and evaluation approaches. Specifically, we consider 73 datasets from different modalities (i.e., numerical, image, text, and audio), four major categories of data processing, five major algorithmic groupings, and two broader evaluation approaches. This paper aims to identify gaps in the current literature and highlight the challenges of predicting rare events. It also suggests potential research directions, which can help guide practitioners and researchers.", "url": "https://arxiv.org/abs/2309.11356"}, {"metadata": {"arXiv": "2309.11361", "Date": "Wed, 20 Sep 2023 14:43:43 ", "Title": "Knowledge Graph Question Answering for Materials Science (KGQA4MAT): Developing Natural Language Interface for Metal-Organic Frameworks Knowledge Graph (MOF-KG)", "Authors": ["Yuan An", "Jane Greenberg", "Alex Kalinowski", "Xintong Zhao", "Xiaohua Hu", "Fernando J. Uribe-Romo", "Kyle Langlois", "Jacob Furst", "Diego A. G\\'omez-Gualdr\\'on"], "Categories": "cs.AI", "Comments": ["In 17th International Conference on Metadata and Semantics Research", "October 2023"]}, "abstract": "We present a comprehensive benchmark dataset for Knowledge Graph Question Answering in Materials Science (KGQA4MAT), with a focus on metal-organic frameworks (MOFs). A knowledge graph for metal-organic frameworks (MOF-KG) has been constructed by integrating structured databases and knowledge extracted from the literature. To enhance MOF-KG accessibility for domain experts, we aim to develop a natural language interface for querying the knowledge graph. We have developed a benchmark comprised of 161 complex questions involving comparison, aggregation, and complicated graph structures. Each question is rephrased in three additional variations, resulting in 644 questions and 161 KG queries. To evaluate the benchmark, we have developed a systematic approach for utilizing ChatGPT to translate natural language questions into formal KG queries. We also apply the approach to the well-known QALD-9 dataset, demonstrating ChatGPT's potential in addressing KGQA issues for different platforms and query languages. The benchmark and the proposed approach aim to stimulate further research and development of user-friendly and efficient interfaces for querying domain-specific materials science knowledge graphs, thereby accelerating the discovery of novel materials.", "url": "https://arxiv.org/abs/2309.11361"}, {"metadata": {"arXiv": "2309.11452", "Date": "Wed, 20 Sep 2023 16:27:52 ", "Title": "Using deep learning to construct stochastic local search SAT solvers with performance bounds", "Authors": ["Maximilian Kramer", "Paul Boes"], "Categories": "cs.AI math.OC", "Comments": ["15 pages", "9 figures"]}, "abstract": "The Boolean Satisfiability problem (SAT) is the most prototypical NP-complete problem and of great practical relevance. One important class of solvers for this problem are stochastic local search (SLS) algorithms that iteratively and randomly update a candidate assignment. Recent breakthrough results in theoretical computer science have established sufficient conditions under which SLS solvers are guaranteed to efficiently solve a SAT instance, provided they have access to suitable \"oracles\" that provide samples from an instance-specific distribution, exploiting an instance's local structure. Motivated by these results and the well established ability of neural networks to learn common structure in large datasets, in this work, we train oracles using Graph Neural Networks and evaluate them on two SLS solvers on random SAT instances of varying difficulty. We find that access to GNN-based oracles significantly boosts the performance of both solvers, allowing them, on average, to solve 17% more difficult instances (as measured by the ratio between clauses and variables), and to do so in 35% fewer steps, with improvements in the median number of steps of up to a factor of 8. As such, this work bridges formal results from theoretical computer science and practically motivated research on deep learning for constraint satisfaction problems and establishes the promise of purpose-trained SAT solvers with performance guarantees.", "url": "https://arxiv.org/abs/2309.11452"}, {"metadata": {"arXiv": "2309.11469", "Date": "Wed, 20 Sep 2023 17:09:09 ", "Title": "Multi-Label Takagi-Sugeno-Kang Fuzzy System", "Authors": ["Qiongdan Lou", "Zhaohong Deng", "Zhiyong Xiao", "Kup-Sze Choi", "Shitong Wang"], "Categories": "cs.AI", "Comments": ["This work has been accepted by IEEE Transactions on Fuzzy Systems"]}, "abstract": "Multi-label classification can effectively identify the relevant labels of an instance from a given set of labels. However,the modeling of the relationship between the features and the labels is critical to the classification performance. To this end, we propose a new multi-label classification method, called Multi-Label Takagi-Sugeno-Kang Fuzzy System (ML-TSK FS), to improve the classification performance. The structure of ML-TSK FS is designed using fuzzy rules to model the relationship between features and labels. The fuzzy system is trained by integrating fuzzy inference based multi-label correlation learning with multi-label regression loss. The proposed ML-TSK FS is evaluated experimentally on 12 benchmark multi-label datasets. 1 The results show that the performance of ML-TSK FS is competitive with existing methods in terms of various evaluation metrics, indicating that it is able to model the feature-label relationship effectively using fuzzy inference rules and enhances the classification performance.", "url": "https://arxiv.org/abs/2309.11469"}, {"metadata": {"arXiv": "2309.11473", "Date": "Wed, 20 Sep 2023 17:13:15 ", "Title": "Multi-view Fuzzy Representation Learning with Rules based Model", "Authors": ["Wei Zhang", "Zhaohong Deng", "Te Zhang", "Kup-Sze Choi", "Shitong Wang"], "Categories": "cs.AI", "Comments": ["This work has been accepted by IEEE Transactions on Knowledge and Data Engineering"]}, "abstract": "Unsupervised multi-view representation learning has been extensively studied for mining multi-view data. However, some critical challenges remain. On the one hand, the existing methods cannot explore multi-view data comprehensively since they usually learn a common representation between views, given that multi-view data contains both the common information between views and the specific information within each view. On the other hand, to mine the nonlinear relationship between data, kernel or neural network methods are commonly used for multi-view representation learning. However, these methods are lacking in interpretability. To this end, this paper proposes a new multi-view fuzzy representation learning method based on the interpretable Takagi-Sugeno-Kang (TSK) fuzzy system (MVRL_FS). The method realizes multi-view representation learning from two aspects. First, multi-view data are transformed into a high-dimensional fuzzy feature space, while the common information between views and specific information of each view are explored simultaneously. Second, a new regularization method based on L_(2,1)-norm regression is proposed to mine the consistency information between views, while the geometric structure of the data is preserved through the Laplacian graph. Finally, extensive experiments on many benchmark multi-view datasets are conducted to validate the superiority of the proposed method.", "url": "https://arxiv.org/abs/2309.11473"}, {"metadata": {"arXiv": "2309.11478", "Date": "Wed, 20 Sep 2023 17:23:05 ", "Title": "Fictional Worlds, Real Connections: Developing Community Storytelling Social Chatbots through LLMs", "Authors": ["Yuqian Sun", "Hanyi Wang", "Pok Man Chan", "Morteza Tabibi", "Yan Zhang", "Huan Lu", "Yuheng Chen", "Chang Hee Lee", "Ali Asadipour"], "Categories": "cs.AI"}, "abstract": "We address the integration of storytelling and Large Language Models (LLMs) to develop engaging and believable Social Chatbots (SCs) in community settings. Motivated by the potential of fictional characters to enhance social interactions, we introduce Storytelling Social Chatbots (SSCs) and the concept of story engineering to transform fictional game characters into \"live\" social entities within player communities. Our story engineering process includes three steps: (1) Character and story creation, defining the SC's personality and worldview, (2) Presenting Live Stories to the Community, allowing the SC to recount challenges and seek suggestions, and (3) Communication with community members, enabling interaction between the SC and users. We employed the LLM GPT-3 to drive our SSC prototypes, \"David\" and \"Catherine,\" and evaluated their performance in an online gaming community, \"DE (Alias),\" on Discord. Our mixed-method analysis, based on questionnaires (N=15) and interviews (N=8) with community members, reveals that storytelling significantly enhances the engagement and believability of SCs in community settings.", "url": "https://arxiv.org/abs/2309.11478"}, {"metadata": {"arXiv": "2309.11069", "Date": "Wed, 20 Sep 2023 05:25:12 ", "Title": "Dynamic Tiling: A Model-Agnostic, Adaptive, Scalable, and Inference-Data-Centric Approach for Efficient and Accurate Small Object Detection", "Authors": ["Son The Nguyen", "Theja Tulabandhula", "Duy Nguyen"], "Categories": "cs.CV cs.AI"}, "abstract": "We introduce Dynamic Tiling, a model-agnostic, adaptive, and scalable approach for small object detection, anchored in our inference-data-centric philosophy. Dynamic Tiling starts with non-overlapping tiles for initial detections and utilizes dynamic overlapping rates along with a tile minimizer. This dual approach effectively resolves fragmented objects, improves detection accuracy, and minimizes computational overhead by reducing the number of forward passes through the object detection model. Adaptable to a variety of operational environments, our method negates the need for laborious recalibration. Additionally, our large-small filtering mechanism boosts the detection quality across a range of object sizes. Overall, Dynamic Tiling outperforms existing model-agnostic uniform cropping methods, setting new benchmarks for efficiency and accuracy.", "url": "https://arxiv.org/abs/2309.11069"}, {"metadata": {"arXiv": "2309.11306", "Date": "Wed, 20 Sep 2023 13:33:00 ", "Title": "FaceDiffuser: Speech-Driven 3D Facial Animation Synthesis Using Diffusion", "Authors": ["Stefan Stan and Kazi Injamamul Haque and Zerrin Yumak"], "Categories": "cs.CV cs.AI cs.GR", "Comments": ["Pre-print of the paper accepted at ACM SIGGRAPH MIG 2023"]}, "abstract": "Speech-driven 3D facial animation synthesis has been a challenging task both in industry and research. Recent methods mostly focus on deterministic deep learning methods meaning that given a speech input, the output is always the same. However, in reality, the non-verbal facial cues that reside throughout the face are non-deterministic in nature. In addition, majority of the approaches focus on 3D vertex based datasets and methods that are compatible with existing facial animation pipelines with rigged characters is scarce. To eliminate these issues, we present FaceDiffuser, a non-deterministic deep learning model to generate speech-driven facial animations that is trained with both 3D vertex and blendshape based datasets. Our method is based on the diffusion technique and uses the pre-trained large speech representation model HuBERT to encode the audio input. To the best of our knowledge, we are the first to employ the diffusion method for the task of speech-driven 3D facial animation synthesis. We have run extensive objective and subjective analyses and show that our approach achieves better or comparable results in comparison to the state-of-the-art methods. We also introduce a new in-house dataset that is based on a blendshape based rigged character. We recommend watching the accompanying supplementary video. The code and the dataset will be publicly available.", "url": "https://arxiv.org/abs/2309.11306"}, {"metadata": {"arXiv": "2309.11331", "Date": "Wed, 20 Sep 2023 14:03:47 ", "Title": "Gold-YOLO: Efficient Object Detector via Gather-and-Distribute Mechanism", "Authors": ["Chengcheng Wang", "Wei He", "Ying Nie", "Jianyuan Guo", "Chuanjian Liu", "Kai Han", "Yunhe Wang"], "Categories": "cs.CV cs.AI"}, "abstract": "In the past years, YOLO-series models have emerged as the leading approaches in the area of real-time object detection. Many studies pushed up the baseline to a higher level by modifying the architecture, augmenting data and designing new losses. However, we find previous models still suffer from information fusion problem, although Feature Pyramid Network (FPN) and Path Aggregation Network (PANet) have alleviated this. Therefore, this study provides an advanced Gatherand-Distribute mechanism (GD) mechanism, which is realized with convolution and self-attention operations. This new designed model named as Gold-YOLO, which boosts the multi-scale feature fusion capabilities and achieves an ideal balance between latency and accuracy across all model scales. Additionally, we implement MAE-style pretraining in the YOLO-series for the first time, allowing YOLOseries models could be to benefit from unsupervised pretraining. Gold-YOLO-N attains an outstanding 39.9% AP on the COCO val2017 datasets and 1030 FPS on a T4 GPU, which outperforms the previous SOTA model YOLOv6-3.0-N with similar FPS by +2.4%. The PyTorch code is available at https://github.com/huaweinoah/Efficient-Computing/Detection/Gold-YOLO, and the MindSpore code is available at https://gitee.com/mindspore/models/tree/master/research/cv/Gold_YOLO.", "url": "https://arxiv.org/abs/2309.11331"}, {"metadata": {"arXiv": "2309.11433", "Date": "Wed, 20 Sep 2023 16:10:53 ", "Title": "A Systematic Review of Few-Shot Learning in Medical Imaging", "Authors": ["Eva Pachetti", "Sara Colantonio"], "Categories": "cs.CV cs.AI", "Comments": ["48 pages", "29 figures", "10 tables", "submitted to Elsevier on 19 Sep 2023"], "ACM-class": "I.2.6; I.4; I.5; J.3"}, "abstract": "The lack of annotated medical images limits the performance of deep learning models, which usually need large-scale labelled datasets. Few-shot learning techniques can reduce data scarcity issues and enhance medical image analysis, especially with meta-learning. This systematic review gives a comprehensive overview of few-shot learning in medical imaging. We searched the literature systematically and selected 80 relevant articles published from 2018 to 2023. We clustered the articles based on medical outcomes, such as tumour segmentation, disease classification, and image registration; anatomical structure investigated (i.e. heart, lung, etc.); and the meta-learning method used. For each cluster, we examined the papers' distributions and the results provided by the state-of-the-art. In addition, we identified a generic pipeline shared among all the studies. The review shows that few-shot learning can overcome data scarcity in most outcomes and that meta-learning is a popular choice to perform few-shot learning because it can adapt to new tasks with few labelled samples. In addition, following meta-learning, supervised learning and semi-supervised learning stand out as the predominant techniques employed to tackle few-shot learning challenges in medical imaging and also best performing. Lastly, we observed that the primary application areas predominantly encompass cardiac, pulmonary, and abdominal domains. This systematic review aims to inspire further research to improve medical image analysis and patient care.", "url": "https://arxiv.org/abs/2309.11433"}, {"metadata": {"arXiv": "2309.11312", "Date": "Wed, 20 Sep 2023 13:38:43 ", "Title": "A Competition-based Pricing Strategy in Cloud Markets using Regret Minimization Techniques", "Authors": ["S.Ghasemi", "M.R.Meybodi", "M.Dehghan", "A.M.Rahmani"], "Categories": "cs.GT cs.AI"}, "abstract": "Cloud computing as a fairly new commercial paradigm, widely investigated by different researchers, already has a great range of challenges. Pricing is a major problem in Cloud computing marketplace; as providers are competing to attract more customers without knowing the pricing policies of each other. To overcome this lack of knowledge, we model their competition by an incomplete-information game. Considering the issue, this work proposes a pricing policy related to the regret minimization algorithm and applies it to the considered incomplete-information game. Based on the competition based marketplace of the Cloud, providers update the distribution of their strategies using the experienced regret. The idea of iteratively applying the algorithm for updating probabilities of strategies causes the regret get minimized faster. The experimental results show much more increase in profits of the providers in comparison with other pricing policies. Besides, the efficiency of a variety of regret minimization techniques in a simulated marketplace of Cloud are discussed which have not been observed in the studied literature. Moreover, return on investment of providers in considered organizations is studied and promising results appeared.", "url": "https://arxiv.org/abs/2309.11312"}, {"metadata": {"arXiv": "2309.11316", "Date": "Wed, 20 Sep 2023 13:41:45 ", "Title": "Dynamic Pricing of Applications in Cloud Marketplaces using Game Theory", "Authors": ["Safiye Ghasemi", "Mohammad Reza Meybodi", "Mehdi Dehghan Takht-Fooladi", "and Amir Masoud Rahmani"], "Categories": "cs.GT cs.AI"}, "abstract": "The competitive nature of Cloud marketplaces as new concerns in delivery of services makes the pricing policies a crucial task for firms. so that, pricing strategies has recently attracted many researchers. Since game theory can handle such competing well this concern is addressed by designing a normal form game between providers in current research. A committee is considered in which providers register for improving their competition based pricing policies. The functionality of game theory is applied to design dynamic pricing policies. The usage of the committee makes the game a complete information one, in which each player is aware of every others payoff functions. The players enhance their pricing policies to maximize their profits. The contribution of this paper is the quantitative modeling of Cloud marketplaces in form of a game to provide novel dynamic pricing strategies; the model is validated by proving the existence and the uniqueness of Nash equilibrium of the game.", "url": "https://arxiv.org/abs/2309.11316"}, {"metadata": {"arXiv": "2309.10908", "Date": "Tue, 19 Sep 2023 20:03:17 ", "Title": "Multicopy Reinforcement Learning Agents", "Authors": ["Alicia P. Wolfe", "Oliver Diamond", "Remi Feuerman", "Magdalena Kisielinska", "Brigitte Goeler-Slough", "Victoria Manfredi"], "Categories": "cs.MA cs.AI"}, "abstract": "This paper examines a novel type of multi-agent problem, in which an agent makes multiple identical copies of itself in order to achieve a single agent task better or more efficiently. This strategy improves performance if the environment is noisy and the task is sometimes unachievable by a single agent copy. We propose a learning algorithm for this multicopy problem which takes advantage of the structure of the value function to efficiently learn how to balance the advantages and costs of adding additional copies.", "url": "https://arxiv.org/abs/2309.10908"}, {"metadata": {"arXiv": "2309.11275", "Date": "Wed, 20 Sep 2023 12:58:51 ", "Title": "Open-endedness induced through a predator-prey scenario using modular robots", "Authors": ["Dimitri Kachler and Karine Miras"], "Categories": "cs.RO cs.AI"}, "abstract": "This work investigates how a predator-prey scenario can induce the emergence of Open-Ended Evolution (OEE). We utilize modular robots of fixed morphologies whose controllers are subject to evolution. In both species, robots can send and receive signals and perceive the relative positions of other robots in the environment. Specifically, we introduce a feature we call a tagging system: it modifies how individuals can perceive each other and is expected to increase behavioral complexity. Our results show the emergence of adaptive strategies, demonstrating the viability of inducing OEE through predator-prey dynamics using modular robots. Such emergence, nevertheless, seemed to depend on conditioning reproduction to an explicit behavioral criterion.", "url": "https://arxiv.org/abs/2309.11275"}, {"metadata": {"arXiv": "2309.11368", "Date": "Wed, 20 Sep 2023 14:51:09 ", "Title": "Dynamic Hand Gesture-Featured Human Motor Adaptation in Tool Delivery using Voice Recognition", "Authors": ["Haolin Fei", "Stefano Tedeschi", "Yanpei Huang", "Andrew Kennedy and Ziwei Wang"], "Categories": "cs.RO cs.AI", "Comments": ["This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice", "after which this version may no longer be accessible"]}, "abstract": "Human-robot collaboration has benefited users with higher efficiency towards interactive tasks. Nevertheless, most collaborative schemes rely on complicated human-machine interfaces, which might lack the requisite intuitiveness compared with natural limb control. We also expect to understand human intent with low training data requirements. In response to these challenges, this paper introduces an innovative human-robot collaborative framework that seamlessly integrates hand gesture and dynamic movement recognition, voice recognition, and a switchable control adaptation strategy. These modules provide a user-friendly approach that enables the robot to deliver the tools as per user need, especially when the user is working with both hands. Therefore, users can focus on their task execution without additional training in the use of human-machine interfaces, while the robot interprets their intuitive gestures. The proposed multimodal interaction framework is executed in the UR5e robot platform equipped with a RealSense D435i camera, and the effectiveness is assessed through a soldering circuit board task. The experiment results have demonstrated superior performance in hand gesture recognition, where the static hand gesture recognition module achieves an accuracy of 94.3\\%, while the dynamic motion recognition module reaches 97.6\\% accuracy. Compared with human solo manipulation, the proposed approach facilitates higher efficiency tool delivery, without significantly distracting from human intents.", "url": "https://arxiv.org/abs/2309.11368"}, {"metadata": {"arXiv": "2309.11382", "Date": "Wed, 20 Sep 2023 15:04:49 ", "Title": "Discuss Before Moving: Visual Language Navigation via Multi-expert Discussions", "Authors": ["Yuxing Long", "Xiaoqi Li", "Wenzhe Cai", "Hao Dong"], "Categories": "cs.RO cs.AI cs.CL cs.CV", "Comments": ["Submitted to ICRA 2024"]}, "abstract": "Visual language navigation (VLN) is an embodied task demanding a wide range of skills encompassing understanding, perception, and planning. For such a multifaceted challenge, previous VLN methods totally rely on one model's own thinking to make predictions within one round. However, existing models, even the most advanced large language model GPT4, still struggle with dealing with multiple tasks by single-round self-thinking. In this work, drawing inspiration from the expert consultation meeting, we introduce a novel zero-shot VLN framework. Within this framework, large models possessing distinct abilities are served as domain experts. Our proposed navigation agent, namely DiscussNav, can actively discuss with these experts to collect essential information before moving at every step. These discussions cover critical navigation subtasks like instruction understanding, environment perception, and completion estimation. Through comprehensive experiments, we demonstrate that discussions with domain experts can effectively facilitate navigation by perceiving instruction-relevant information, correcting inadvertent errors, and sifting through in-consistent movement decisions. The performances on the representative VLN task R2R show that our method surpasses the leading zero-shot VLN model by a large margin on all metrics. Additionally, real-robot experiments display the obvious advantages of our method over single-round self-thinking.", "url": "https://arxiv.org/abs/2309.11382"}, {"metadata": {"arXiv": "2309.11456", "Date": "Wed, 20 Sep 2023 16:43:05 ", "Title": "Generative Agent-Based Modeling: Unveiling Social System Dynamics through Coupling Mechanistic Models with Generative Artificial Intelligence", "Authors": ["Navid Ghaffarzadegan", "Aritra Majumdar", "Ross Williams", "Niyousha Hosseinichimeh"], "Categories": "cs.AI cs.LG cs.MA nlin.AO physics.soc-ph"}, "abstract": "We discuss the emerging new opportunity for building feedback-rich computational models of social systems using generative artificial intelligence. Referred to as Generative Agent-Based Models (GABMs), such individual-level models utilize large language models such as ChatGPT to represent human decision-making in social settings. We provide a GABM case in which human behavior can be incorporated in simulation models by coupling a mechanistic model of human interactions with a pre-trained large language model. This is achieved by introducing a simple GABM of social norm diffusion in an organization. For educational purposes, the model is intentionally kept simple. We examine a wide range of scenarios and the sensitivity of the results to several changes in the prompt. We hope the article and the model serve as a guide for building useful diffusion models that include realistic human reasoning and decision-making.", "url": "https://arxiv.org/abs/2309.11456"}, {"metadata": {"arXiv": "2309.11077", "Date": "Wed, 20 Sep 2023 06:00:02 ", "Title": "Weak Supervision for Label Efficient Visual Bug Detection", "Authors": ["Farrukh Rahman"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Accepted to BMVC 2023: Workshop on Computer Vision for Games and Games for Computer Vision (CVG). 9 pages"], "ACM-class": "I.2.10"}, "abstract": "As video games evolve into expansive, detailed worlds, visual quality becomes essential, yet increasingly challenging. Traditional testing methods, limited by resources, face difficulties in addressing the plethora of potential bugs. Machine learning offers scalable solutions; however, heavy reliance on large labeled datasets remains a constraint. Addressing this challenge, we propose a novel method, utilizing unlabeled gameplay and domain-specific augmentations to generate datasets & self-supervised objectives used during pre-training or multi-task settings for downstream visual bug detection. Our methodology uses weak-supervision to scale datasets for the crafted objectives and facilitates both autonomous and interactive weak-supervision, incorporating unsupervised clustering and/or an interactive approach based on text and geometric prompts. We demonstrate on first-person player clipping/collision bugs (FPPC) within the expansive Giantmap game world, that our approach is very effective, improving over a strong supervised baseline in a practical, very low-prevalence, low data regime (0.336 $\\rightarrow$ 0.550 F1 score). With just 5 labeled \"good\" exemplars (i.e., 0 bugs), our self-supervised objective alone captures enough signal to outperform the low-labeled supervised settings. Building on large-pretrained vision models, our approach is adaptable across various visual bugs. Our results suggest applicability in curating datasets for broader image and video tasks within video games beyond visual bugs.", "url": "https://arxiv.org/abs/2309.11077"}, {"metadata": {"arXiv": "2309.11357", "Date": "Wed, 20 Sep 2023 14:39:03 ", "Title": "3D Face Reconstruction: the Road to Forensics", "Authors": ["Simone Maurizio La Cava", "Giulia Orr\\`u", "Martin Drahansky", "Gian Luca Marcialis", "Fabio Roli"], "Categories": "cs.CV cs.AI cs.LG eess.IV", "Comments": ["The manuscript has been accepted for publication in ACM Computing Surveys. arXiv admin note: text overlap with arXiv:2303.11164"]}, "abstract": "3D face reconstruction algorithms from images and videos are applied to many fields, from plastic surgery to the entertainment sector, thanks to their advantageous features. However, when looking at forensic applications, 3D face reconstruction must observe strict requirements that still make its possible role in bringing evidence to a lawsuit unclear. An extensive investigation of the constraints, potential, and limits of its application in forensics is still missing. Shedding some light on this matter is the goal of the present survey, which starts by clarifying the relation between forensic applications and biometrics, with a focus on face recognition. Therefore, it provides an analysis of the achievements of 3D face reconstruction algorithms from surveillance videos and mugshot images and discusses the current obstacles that separate 3D face reconstruction from an active role in forensic applications. Finally, it examines the underlying data sets, with their advantages and limitations, while proposing alternatives that could substitute or complement them.", "url": "https://arxiv.org/abs/2309.11357"}, {"metadata": {"arXiv": "2309.10910", "Date": "Tue, 19 Sep 2023 20:09:15 ", "Title": "Amplifying Pathological Detection in EEG Signaling Pathways through Cross-Dataset Transfer Learning", "Authors": ["Mohammad-Javad Darvishi-Bayazi", "Mohammad Sajjad Ghaemi", "Timothee Lesort", "Md Rifat Arefin", "Jocelyn Faubert", "Irina Rish"], "Categories": "cs.LG cs.AI"}, "abstract": "Pathology diagnosis based on EEG signals and decoding brain activity holds immense importance in understanding neurological disorders. With the advancement of artificial intelligence methods and machine learning techniques, the potential for accurate data-driven diagnoses and effective treatments has grown significantly. However, applying machine learning algorithms to real-world datasets presents diverse challenges at multiple levels. The scarcity of labelled data, especially in low regime scenarios with limited availability of real patient cohorts due to high costs of recruitment, underscores the vital deployment of scaling and transfer learning techniques. In this study, we explore a real-world pathology classification task to highlight the effectiveness of data and model scaling and cross-dataset knowledge transfer. As such, we observe varying performance improvements through data scaling, indicating the need for careful evaluation and labelling. Additionally, we identify the challenges of possible negative transfer and emphasize the significance of some key components to overcome distribution shifts and potential spurious correlations and achieve positive transfer. We see improvement in the performance of the target model on the target (NMT) datasets by using the knowledge from the source dataset (TUAB) when a low amount of labelled data was available. Our findings indicate a small and generic model (e.g. ShallowNet) performs well on a single dataset, however, a larger model (e.g. TCN) performs better on transfer and learning from a larger and diverse dataset.", "url": "https://arxiv.org/abs/2309.10910"}, {"metadata": {"arXiv": "2309.10980", "Date": "Wed, 20 Sep 2023 00:42:08 ", "Title": "AI-Driven Patient Monitoring with Multi-Agent Deep Reinforcement Learning", "Authors": ["Thanveer Shaik", "Xiaohui Tao", "Haoran Xie", "Lin Li", "Jianming Yong", "and Hong-Ning Dai"], "Categories": "cs.LG cs.AI", "Comments": ["arXiv admin note: text overlap with arXiv:2309.10576"]}, "abstract": "Effective patient monitoring is vital for timely interventions and improved healthcare outcomes. Traditional monitoring systems often struggle to handle complex, dynamic environments with fluctuating vital signs, leading to delays in identifying critical conditions. To address this challenge, we propose a novel AI-driven patient monitoring framework using multi-agent deep reinforcement learning (DRL). Our approach deploys multiple learning agents, each dedicated to monitoring a specific physiological feature, such as heart rate, respiration, and temperature. These agents interact with a generic healthcare monitoring environment, learn the patients' behavior patterns, and make informed decisions to alert the corresponding Medical Emergency Teams (METs) based on the level of emergency estimated. In this study, we evaluate the performance of the proposed multi-agent DRL framework using real-world physiological and motion data from two datasets: PPG-DaLiA and WESAD. We compare the results with several baseline models, including Q-Learning, PPO, Actor-Critic, Double DQN, and DDPG, as well as monitoring frameworks like WISEML and CA-MAQL. Our experiments demonstrate that the proposed DRL approach outperforms all other baseline models, achieving more accurate monitoring of patient's vital signs. Furthermore, we conduct hyperparameter optimization to fine-tune the learning process of each agent. By optimizing hyperparameters, we enhance the learning rate and discount factor, thereby improving the agents' overall performance in monitoring patient health status. Our AI-driven patient monitoring system offers several advantages over traditional methods, including the ability to handle complex and uncertain environments, adapt to varying patient conditions, and make real-time decisions without external supervision.", "url": "https://arxiv.org/abs/2309.10980"}, {"metadata": {"arXiv": "2309.11013", "Date": "Wed, 20 Sep 2023 02:27:40 ", "Title": "ModelGiF: Gradient Fields for Model Functional Distance", "Authors": ["Jie Song", "Zhengqi Xu", "Sai Wu", "Gang Chen", "Mingli Song"], "Categories": "cs.LG cs.AI", "Comments": ["ICCV 2023"]}, "abstract": "The last decade has witnessed the success of deep learning and the surge of publicly released trained models, which necessitates the quantification of the model functional distance for various purposes. However, quantifying the model functional distance is always challenging due to the opacity in inner workings and the heterogeneity in architectures or tasks. Inspired by the concept of \"field\" in physics, in this work we introduce Model Gradient Field (abbr. ModelGiF) to extract homogeneous representations from the heterogeneous pre-trained models. Our main assumption underlying ModelGiF is that each pre-trained deep model uniquely determines a ModelGiF over the input space. The distance between models can thus be measured by the similarity between their ModelGiFs. We validate the effectiveness of the proposed ModelGiF with a suite of testbeds, including task relatedness estimation, intellectual property protection, and model unlearning verification. Experimental results demonstrate the versatility of the proposed ModelGiF on these tasks, with significantly superiority performance to state-of-the-art competitors. Codes are available at https://github.com/zju-vipa/modelgif.", "url": "https://arxiv.org/abs/2309.11013"}, {"metadata": {"arXiv": "2309.11039", "Date": "Wed, 20 Sep 2023 03:39:30 ", "Title": "Federated Learning in Intelligent Transportation Systems: Recent Applications and Open Problems", "Authors": ["Shiying Zhang", "Jun Li", "Long Shi", "Ming Ding", "Dinh C. Nguyen", "Wuzheng Tan", "Jian Weng", "Zhu Han"], "Categories": "cs.LG cs.AI cs.DC"}, "abstract": "Intelligent transportation systems (ITSs) have been fueled by the rapid development of communication technologies, sensor technologies, and the Internet of Things (IoT). Nonetheless, due to the dynamic characteristics of the vehicle networks, it is rather challenging to make timely and accurate decisions of vehicle behaviors. Moreover, in the presence of mobile wireless communications, the privacy and security of vehicle information are at constant risk. In this context, a new paradigm is urgently needed for various applications in dynamic vehicle environments. As a distributed machine learning technology, federated learning (FL) has received extensive attention due to its outstanding privacy protection properties and easy scalability. We conduct a comprehensive survey of the latest developments in FL for ITS. Specifically, we initially research the prevalent challenges in ITS and elucidate the motivations for applying FL from various perspectives. Subsequently, we review existing deployments of FL in ITS across various scenarios, and discuss specific potential issues in object recognition, traffic management, and service providing scenarios. Furthermore, we conduct a further analysis of the new challenges introduced by FL deployment and the inherent limitations that FL alone cannot fully address, including uneven data distribution, limited storage and computing power, and potential privacy and security concerns. We then examine the existing collaborative technologies that can help mitigate these challenges. Lastly, we discuss the open challenges that remain to be addressed in applying FL in ITS and propose several future research directions.", "url": "https://arxiv.org/abs/2309.11039"}, {"metadata": {"arXiv": "2309.11044", "Date": "Wed, 20 Sep 2023 03:47:53 ", "Title": "Clustered FedStack: Intermediate Global Models with Bayesian Information Criterion", "Authors": ["Thanveer Shaik", "Xiaohui Tao", "Lin Li", "Niall Higgins", "Raj Gururajan", "Xujuan Zhou", "Jianming Yong"], "Categories": "cs.LG cs.AI", "Comments": ["This work has been submitted to the ELSEVIER for possible publication. Copyright may be transferred without notice", "after which this version may no longer be accessible"]}, "abstract": "Federated Learning (FL) is currently one of the most popular technologies in the field of Artificial Intelligence (AI) due to its collaborative learning and ability to preserve client privacy. However, it faces challenges such as non-identically and non-independently distributed (non-IID) and data with imbalanced labels among local clients. To address these limitations, the research community has explored various approaches such as using local model parameters, federated generative adversarial learning, and federated representation learning. In our study, we propose a novel Clustered FedStack framework based on the previously published Stacked Federated Learning (FedStack) framework. The local clients send their model predictions and output layer weights to a server, which then builds a robust global model. This global model clusters the local clients based on their output layer weights using a clustering mechanism. We adopt three clustering mechanisms, namely K-Means, Agglomerative, and Gaussian Mixture Models, into the framework and evaluate their performance. We use Bayesian Information Criterion (BIC) with the maximum likelihood function to determine the number of clusters. The Clustered FedStack models outperform baseline models with clustering mechanisms. To estimate the convergence of our proposed framework, we use Cyclical learning rates.", "url": "https://arxiv.org/abs/2309.11044"}, {"metadata": {"arXiv": "2309.11101", "Date": "Wed, 20 Sep 2023 07:15:48 ", "Title": "A New Interpretable Neural Network-Based Rule Model for Healthcare Decision Making", "Authors": ["Adrien Benamira", "Tristan Guerand", "Thomas Peyrin"], "Categories": "cs.LG cs.AI", "Comments": ["This work was presented at IAIM23 in Singapore https://iaim2023.sg/. arXiv admin note: substantial text overlap with arXiv:2309.09638"]}, "abstract": "In healthcare applications, understanding how machine/deep learning models make decisions is crucial. In this study, we introduce a neural network framework, $\\textit{Truth Table rules}$ (TT-rules), that combines the global and exact interpretability properties of rule-based models with the high performance of deep neural networks. TT-rules is built upon $\\textit{Truth Table nets}$ (TTnet), a family of deep neural networks initially developed for formal verification. By extracting the necessary and sufficient rules $\\mathcal{R}$ from the trained TTnet model (global interpretability) to yield the same output as the TTnet (exact interpretability), TT-rules effectively transforms the neural network into a rule-based model. This rule-based model supports binary classification, multi-label classification, and regression tasks for small to large tabular datasets. After outlining the framework, we evaluate TT-rules' performance on healthcare applications and compare it to state-of-the-art rule-based methods. Our results demonstrate that TT-rules achieves equal or higher performance compared to other interpretable methods. Notably, TT-rules presents the first accurate rule-based model capable of fitting large tabular datasets, including two real-life DNA datasets with over 20K features.", "url": "https://arxiv.org/abs/2309.11101"}, {"metadata": {"arXiv": "2309.11196", "Date": "Wed, 20 Sep 2023 10:31:09 ", "Title": "When to Trust AI: Advances and Challenges for Certification of Neural Networks", "Authors": ["Marta Kwiatkowska", "Xiyue Zhang"], "Categories": "cs.LG cs.AI cs.CR cs.SC"}, "abstract": "Artificial intelligence (AI) has been advancing at a fast pace and it is now poised for deployment in a wide range of applications, such as autonomous systems, medical diagnosis and natural language processing. Early adoption of AI technology for real-world applications has not been without problems, particularly for neural networks, which may be unstable and susceptible to adversarial examples. In the longer term, appropriate safety assurance techniques need to be developed to reduce potential harm due to avoidable system failures and ensure trustworthiness. Focusing on certification and explainability, this paper provides an overview of techniques that have been developed to ensure safety of AI decisions and discusses future challenges.", "url": "https://arxiv.org/abs/2309.11196"}, {"metadata": {"arXiv": "2309.11247", "Date": "Wed, 20 Sep 2023 12:16:00 ", "Title": "Hierarchical Multi-Agent Reinforcement Learning for Air Combat Maneuvering", "Authors": ["Ardian Selmonaj", "Oleg Szehr", "Giacomo Del Rio", "Alessandro Antonucci", "Adrian Schneider", "Michael R\\\"uegsegger"], "Categories": "cs.LG cs.AI cs.MA", "Comments": ["22nd International Conference on Machine Learning and Applications (ICMLA 23)"]}, "abstract": "The application of artificial intelligence to simulate air-to-air combat scenarios is attracting increasing attention. To date the high-dimensional state and action spaces, the high complexity of situation information (such as imperfect and filtered information, stochasticity, incomplete knowledge about mission targets) and the nonlinear flight dynamics pose significant challenges for accurate air combat decision-making. These challenges are exacerbated when multiple heterogeneous agents are involved. We propose a hierarchical multi-agent reinforcement learning framework for air-to-air combat with multiple heterogeneous agents. In our framework, the decision-making process is divided into two stages of abstraction, where heterogeneous low-level policies control the action of individual units, and a high-level commander policy issues macro commands given the overall mission targets. Low-level policies are trained for accurate unit combat control. Their training is organized in a learning curriculum with increasingly complex training scenarios and league-based self-play. The commander policy is trained on mission targets given pre-trained low-level policies. The empirical validation advocates the advantages of our design choices.", "url": "https://arxiv.org/abs/2309.11247"}, {"metadata": {"arXiv": "2309.11378", "Date": "Wed, 20 Sep 2023 14:58:47 ", "Title": "Preconditioned Federated Learning", "Authors": ["Zeyi Tao", "Jindi Wu", "Qun Li"], "Categories": "cs.LG cs.AI", "Comments": ["preprint"]}, "abstract": "Federated Learning (FL) is a distributed machine learning approach that enables model training in communication efficient and privacy-preserving manner. The standard optimization method in FL is Federated Averaging (FedAvg), which performs multiple local SGD steps between communication rounds. FedAvg has been considered to lack algorithm adaptivity compared to modern first-order adaptive optimizations. In this paper, we propose new communication-efficient FL algortithms based on two adaptive frameworks: local adaptivity (PreFed) and server-side adaptivity (PreFedOp). Proposed methods adopt adaptivity by using a novel covariance matrix preconditioner. Theoretically, we provide convergence guarantees for our algorithms. The empirical experiments show our methods achieve state-of-the-art performances on both i.i.d. and non-i.i.d. settings.", "url": "https://arxiv.org/abs/2309.11378"}, {"metadata": {"arXiv": "2309.11427", "Date": "Wed, 20 Sep 2023 16:01:45 ", "Title": "Generative Pre-Training of Time-Series Data for Unsupervised Fault Detection in Semiconductor Manufacturing", "Authors": ["Sewoong Lee", "JinKyou Choi and Min Su Kim"], "Categories": "cs.LG cs.AI"}, "abstract": "This paper introduces TRACE-GPT, which stands for Time-seRies Anomaly-detection with Convolutional Embedding and Generative Pre-trained Transformers. TRACE-GPT is designed to pre-train univariate time-series sensor data and detect faults on unlabeled datasets in semiconductor manufacturing. In semiconductor industry, classifying abnormal time-series sensor data from normal data is important because it is directly related to wafer defect. However, small, unlabeled, and even mixed training data without enough anomalies make classification tasks difficult. In this research, we capture features of time-series data with temporal convolutional embedding and Generative Pre-trained Transformer (GPT) to classify abnormal sequences from normal sequences using cross entropy loss. We prove that our model shows better performance than previous unsupervised models with both an open dataset, the University of California Riverside (UCR) time-series classification archive, and the process log of our Chemical Vapor Deposition (CVD) equipment. Our model has the highest F1 score at Equal Error Rate (EER) across all datasets and is only 0.026 below the supervised state-of-the-art baseline on the open dataset.", "url": "https://arxiv.org/abs/2309.11427"}, {"metadata": {"arXiv": "2309.11489", "Date": "Wed, 20 Sep 2023 17:39:13 ", "Title": "Text2Reward: Automated Dense Reward Function Generation for Reinforcement Learning", "Authors": ["Tianbao Xie and Siheng Zhao and Chen Henry Wu and Yitao Liu and Qian Luo and Victor Zhong and Yanchao Yang and Tao Yu"], "Categories": "cs.LG cs.AI cs.CL cs.RO", "Comments": ["23 pages", "10 figures"]}, "abstract": "Designing reward functions is a longstanding challenge in reinforcement learning (RL); it requires specialized knowledge or domain data, leading to high costs for development. To address this, we introduce Text2Reward, a data-free framework that automates the generation of dense reward functions based on large language models (LLMs). Given a goal described in natural language, Text2Reward generates dense reward functions as an executable program grounded in a compact representation of the environment. Unlike inverse RL and recent work that uses LLMs to write sparse reward codes, Text2Reward produces interpretable, free-form dense reward codes that cover a wide range of tasks, utilize existing packages, and allow iterative refinement with human feedback. We evaluate Text2Reward on two robotic manipulation benchmarks (ManiSkill2, MetaWorld) and two locomotion environments of MuJoCo. On 13 of the 17 manipulation tasks, policies trained with generated reward codes achieve similar or better task success rates and convergence speed than expert-written reward codes. For locomotion tasks, our method learns six novel locomotion behaviors with a success rate exceeding 94%. Furthermore, we show that the policies trained in the simulator with our method can be deployed in the real world. Finally, Text2Reward further improves the policies by refining their reward functions with human feedback. Video results are available at https://text-to-reward.github.io", "url": "https://arxiv.org/abs/2309.11489"}, {"metadata": {"arXiv": "2309.11414", "Date": "Wed, 20 Sep 2023 15:40:32 ", "Title": "EDMP: Ensemble-of-costs-guided Diffusion for Motion Planning", "Authors": ["Kallol Saha", "Vishal Mandadi", "Jayaram Reddy", "Ajit Srikanth", "Aditya Agarwal", "Bipasha Sen", "Arun Singh and Madhava Krishna"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["8 pages", "8 figures", "submitted to ICRA 2024 (International Conference on Robotics and Automation)"]}, "abstract": "Classical motion planning for robotic manipulation includes a set of general algorithms that aim to minimize a scene-specific cost of executing a given plan. This approach offers remarkable adaptability, as they can be directly used off-the-shelf for any new scene without needing specific training datasets. However, without a prior understanding of what diverse valid trajectories are and without specially designed cost functions for a given scene, the overall solutions tend to have low success rates. While deep-learning-based algorithms tremendously improve success rates, they are much harder to adopt without specialized training datasets. We propose EDMP, an Ensemble-of-costs-guided Diffusion for Motion Planning that aims to combine the strengths of classical and deep-learning-based motion planning. Our diffusion-based network is trained on a set of diverse kinematically valid trajectories. Like classical planning, for any new scene at the time of inference, we compute scene-specific costs such as \"collision cost\" and guide the diffusion to generate valid trajectories that satisfy the scene-specific constraints. Further, instead of a single cost function that may be insufficient in capturing diversity across scenes, we use an ensemble of costs to guide the diffusion process, significantly improving the success rate compared to classical planners. EDMP performs comparably with SOTA deep-learning-based methods while retaining the generalization capabilities primarily associated with classical planners.", "url": "https://arxiv.org/abs/2309.11414"}, {"metadata": {"arXiv": "2309.11089", "Date": "Wed, 20 Sep 2023 06:39:19 ", "Title": "Practical Probabilistic Model-based Deep Reinforcement Learning by Integrating Dropout Uncertainty and Trajectory Sampling", "Authors": ["Wenjun Huang", "Yunduan Cui", "Huiyun Li", "Xinyu Wu"], "Categories": "eess.SY cs.AI cs.LG cs.SY"}, "abstract": "This paper addresses the prediction stability, prediction accuracy and control capability of the current probabilistic model-based reinforcement learning (MBRL) built on neural networks. A novel approach dropout-based probabilistic ensembles with trajectory sampling (DPETS) is proposed where the system uncertainty is stably predicted by combining the Monte-Carlo dropout and trajectory sampling in one framework. Its loss function is designed to correct the fitting error of neural networks for more accurate prediction of probabilistic models. The state propagation in its policy is extended to filter the aleatoric uncertainty for superior control capability. Evaluated by several Mujoco benchmark control tasks under additional disturbances and one practical robot arm manipulation task, DPETS outperforms related MBRL approaches in both average return and convergence velocity while achieving superior performance than well-known model-free baselines with significant sample efficiency. The open source code of DPETS is available at https://github.com/mrjun123/DPETS.", "url": "https://arxiv.org/abs/2309.11089"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

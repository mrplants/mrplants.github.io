<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2310.03843", "Date": "Thu, 05 Oct 2023 19:00:49 ", "Title": "Less is More: On the Feature Redundancy of Pretrained Models When Transferring to Few-shot Tasks", "Authors": ["Xu Luo", "Difan Zou", "Lianli Gao", "Zenglin Xu", "Jingkuan Song"], "Categories": "cs.CV cs.LG"}, "abstract": "Transferring a pretrained model to a downstream task can be as easy as conducting linear probing with target data, that is, training a linear classifier upon frozen features extracted from the pretrained model. As there may exist significant gaps between pretraining and downstream datasets, one may ask whether all dimensions of the pretrained features are useful for a given downstream task. We show that, for linear probing, the pretrained features can be extremely redundant when the downstream data is scarce, or few-shot. For some cases such as 5-way 1-shot tasks, using only 1\\% of the most important feature dimensions is able to recover the performance achieved by using the full representation. Interestingly, most dimensions are redundant only under few-shot settings and gradually become useful when the number of shots increases, suggesting that feature redundancy may be the key to characterizing the \"few-shot\" nature of few-shot transfer problems. We give a theoretical understanding of this phenomenon and show how dimensions with high variance and small distance between class centroids can serve as confounding factors that severely disturb classification results under few-shot settings. As an attempt at solving this problem, we find that the redundant features are difficult to identify accurately with a small number of training samples, but we can instead adjust feature magnitude with a soft mask based on estimated feature importance. We show that this method can generally improve few-shot transfer performance across various pretrained models and downstream datasets.", "url": "https://arxiv.org/abs/2310.03843"}, {"metadata": {"arXiv": "2310.03848", "Date": "Thu, 05 Oct 2023 19:08:08 ", "Title": "OpenIncrement: A Unified Framework for Open Set Recognition and Deep Class-Incremental Learning", "Authors": ["Jiawen Xu", "Claas Grohnfeldt", "Odej Kao"], "Categories": "cs.CV cs.LG", "Journal-ref": "1st Workshop on Visual Continual Learning in conjunction with ICCV 2023"}, "abstract": "In most works on deep incremental learning research, it is assumed that novel samples are pre-identified for neural network retraining. However, practical deep classifiers often misidentify these samples, leading to erroneous predictions. Such misclassifications can degrade model performance. Techniques like open set recognition offer a means to detect these novel samples, representing a significant area in the machine learning domain. In this paper, we introduce a deep class-incremental learning framework integrated with open set recognition. Our approach refines class-incrementally learned features to adapt them for distance-based open set recognition. Experimental results validate that our method outperforms state-of-the-art incremental learning techniques and exhibits superior performance in open set recognition compared to baseline methods.", "url": "https://arxiv.org/abs/2310.03848"}, {"metadata": {"arXiv": "2310.03986", "Date": "Fri, 06 Oct 2023 03:04:21 ", "Title": "Robust Multimodal Learning with Missing Modalities via Parameter-Efficient Adaptation", "Authors": ["Md Kaykobad Reza", "Ashley Prater-Bennette", "M. Salman Asif"], "Categories": "cs.CV cs.LG", "Comments": ["18 pages", "3 figures", "11 tables"]}, "abstract": "Multimodal learning seeks to utilize data from multiple sources to improve the overall performance of downstream tasks. It is desirable for redundancies in the data to make multimodal systems robust to missing or corrupted observations in some correlated modalities. However, we observe that the performance of several existing multimodal networks significantly deteriorates if one or multiple modalities are absent at test time. To enable robustness to missing modalities, we propose simple and parameter-efficient adaptation procedures for pretrained multimodal networks. In particular, we exploit low-rank adaptation and modulation of intermediate features to compensate for the missing modalities. We demonstrate that such adaptation can partially bridge performance drop due to missing modalities and outperform independent, dedicated networks trained for the available modality combinations in some cases. The proposed adaptation requires extremely small number of parameters (e.g., fewer than 0.7% of the total parameters in most experiments). We conduct a series of experiments to highlight the robustness of our proposed method using diverse datasets for RGB-thermal and RGB-Depth semantic segmentation, multimodal material segmentation, and multimodal sentiment analysis tasks. Our proposed method demonstrates versatility across various tasks and datasets, and outperforms existing methods for robust multimodal learning with missing modalities.", "url": "https://arxiv.org/abs/2310.03986"}, {"metadata": {"arXiv": "2310.04179", "Date": "Fri, 06 Oct 2023 11:49:21 ", "Title": "Entropic Score metric: Decoupling Topology and Size in Training-free NAS", "Authors": ["Niccol\\`o Cavagnero", "Luca Robbiano", "Francesca Pistilli", "Barbara Caputo", "Giuseppe Averta"], "Categories": "cs.CV cs.LG", "Comments": ["10 pages", "3 figures"]}, "abstract": "Neural Networks design is a complex and often daunting task, particularly for resource-constrained scenarios typical of mobile-sized models. Neural Architecture Search is a promising approach to automate this process, but existing competitive methods require large training time and computational resources to generate accurate models. To overcome these limits, this paper contributes with: i) a novel training-free metric, named Entropic Score, to estimate model expressivity through the aggregated element-wise entropy of its activations; ii) a cyclic search algorithm to separately yet synergistically search model size and topology. Entropic Score shows remarkable ability in searching for the topology of the network, and a proper combination with LogSynflow, to search for model size, yields superior capability to completely design high-performance Hybrid Transformers for edge applications in less than 1 GPU hour, resulting in the fastest and most accurate NAS method for ImageNet classification.", "url": "https://arxiv.org/abs/2310.04179"}, {"metadata": {"arXiv": "2310.04311", "Date": "Fri, 06 Oct 2023 15:17:45 ", "Title": "Distributed Deep Joint Source-Channel Coding with Decoder-Only Side Information", "Authors": ["Selim F. Yilmaz", "Ezgi Ozyilkan", "Deniz Gunduz", "Elza Erkip"], "Categories": "cs.CV cs.IT cs.LG math.IT", "Comments": ["7 pages", "4 figures"]}, "abstract": "We consider low-latency image transmission over a noisy wireless channel when correlated side information is present only at the receiver side (the Wyner-Ziv scenario). In particular, we are interested in developing practical schemes using a data-driven joint source-channel coding (JSCC) approach, which has been previously shown to outperform conventional separation-based approaches in the practical finite blocklength regimes, and to provide graceful degradation with channel quality. We propose a novel neural network architecture that incorporates the decoder-only side information at multiple stages at the receiver side. Our results demonstrate that the proposed method succeeds in integrating the side information, yielding improved performance at all channel noise levels in terms of the various distortion criteria considered here, especially at low channel signal-to-noise ratios (SNRs) and small bandwidth ratios (BRs). We also provide the source code of the proposed method to enable further research and reproducibility of the results.", "url": "https://arxiv.org/abs/2310.04311"}, {"metadata": {"arXiv": "2310.04378", "Date": "Fri, 06 Oct 2023 17:11:58 ", "Title": "Latent Consistency Models: Synthesizing High-Resolution Images with Few-Step Inference", "Authors": ["Simian Luo", "Yiqin Tan", "Longbo Huang", "Jian Li", "Hang Zhao"], "Categories": "cs.CV cs.LG"}, "abstract": "Latent Diffusion models (LDMs) have achieved remarkable results in synthesizing high-resolution images. However, the iterative sampling process is computationally intensive and leads to slow generation. Inspired by Consistency Models (song et al.), we propose Latent Consistency Models (LCMs), enabling swift inference with minimal steps on any pre-trained LDMs, including Stable Diffusion (rombach et al). Viewing the guided reverse diffusion process as solving an augmented probability flow ODE (PF-ODE), LCMs are designed to directly predict the solution of such ODE in latent space, mitigating the need for numerous iterations and allowing rapid, high-fidelity sampling. Efficiently distilled from pre-trained classifier-free guided diffusion models, a high-quality 768 x 768 2~4-step LCM takes only 32 A100 GPU hours for training. Furthermore, we introduce Latent Consistency Fine-tuning (LCF), a novel method that is tailored for fine-tuning LCMs on customized image datasets. Evaluation on the LAION-5B-Aesthetics dataset demonstrates that LCMs achieve state-of-the-art text-to-image generation performance with few-step inference. Project Page: https://latent-consistency-models.github.io/", "url": "https://arxiv.org/abs/2310.04378"}, {"metadata": {"arXiv": "2310.03767", "Date": "Wed, 04 Oct 2023 12:32:14 ", "Title": "Deep Reinforcement Learning Algorithms for Hybrid V2X Communication: A Benchmarking Study", "Authors": ["Fouzi Boukhalfa", "Reda Alami", "Mastane Achab", "Eric Moulines", "Mehdi Bennis"], "Categories": "cs.LG cs.NI eess.SP"}, "abstract": "In today's era, autonomous vehicles demand a safety level on par with aircraft. Taking a cue from the aerospace industry, which relies on redundancy to achieve high reliability, the automotive sector can also leverage this concept by building redundancy in V2X (Vehicle-to-Everything) technologies. Given the current lack of reliable V2X technologies, this idea is particularly promising. By deploying multiple RATs (Radio Access Technologies) in parallel, the ongoing debate over the standard technology for future vehicles can be put to rest. However, coordinating multiple communication technologies is a complex task due to dynamic, time-varying channels and varying traffic conditions. This paper addresses the vertical handover problem in V2X using Deep Reinforcement Learning (DRL) algorithms. The goal is to assist vehicles in selecting the most appropriate V2X technology (DSRC/V-VLC) in a serpentine environment. The results show that the benchmarked algorithms outperform the current state-of-the-art approaches in terms of redundancy and usage rate of V-VLC headlights. This result is a significant reduction in communication costs while maintaining a high level of reliability. These results provide strong evidence for integrating advanced DRL decision mechanisms into the architecture as a promising approach to solving the vertical handover problem in V2X.", "url": "https://arxiv.org/abs/2310.03767"}, {"metadata": {"arXiv": "2310.03773", "Date": "Thu, 05 Oct 2023 04:46:52 ", "Title": "Functional data learning using convolutional neural networks", "Authors": ["Jose Galarza and Tamer Oraby"], "Categories": "cs.LG cs.CV", "Comments": ["38 pages", "23 figures"]}, "abstract": "In this paper, we show how convolutional neural networks (CNN) can be used in regression and classification learning problems of noisy and non-noisy functional data. The main idea is to transform the functional data into a 28 by 28 image. We use a specific but typical architecture of a convolutional neural network to perform all the regression exercises of parameter estimation and functional form classification. First, we use some functional case studies of functional data with and without random noise to showcase the strength of the new method. In particular, we use it to estimate exponential growth and decay rates, the bandwidths of sine and cosine functions, and the magnitudes and widths of curve peaks. We also use it to classify the monotonicity and curvatures of functional data, algebraic versus exponential growth, and the number of peaks of functional data. Second, we apply the same convolutional neural networks to Lyapunov exponent estimation in noisy and non-noisy chaotic data, in estimating rates of disease transmission from epidemic curves, and in detecting the similarity of drug dissolution profiles. Finally, we apply the method to real-life data to detect Parkinson's disease patients in a classification problem. The method, although simple, shows high accuracy and is promising for future use in engineering and medical applications.", "url": "https://arxiv.org/abs/2310.03773"}, {"metadata": {"arXiv": "2310.03812", "Date": "Thu, 05 Oct 2023 18:01:04 ", "Title": "Fishnets: Information-Optimal, Scalable Aggregation for Sets and Graphs", "Authors": ["T. Lucas Makinen", "Justin Alsing", "Benjamin D. Wandelt"], "Categories": "cs.LG stat.ML", "Comments": ["13 pages", "9 figures", "2 tables. Submitted to ICLR 2024"]}, "abstract": "Set-based learning is an essential component of modern deep learning and network science. Graph Neural Networks (GNNs) and their edge-free counterparts Deepsets have proven remarkably useful on ragged and topologically challenging datasets. The key to learning informative embeddings for set members is a specified aggregation function, usually a sum, max, or mean. We propose Fishnets, an aggregation strategy for learning information-optimal embeddings for sets of data for both Bayesian inference and graph aggregation. We demonstrate that i) Fishnets neural summaries can be scaled optimally to an arbitrary number of data objects, ii) Fishnets aggregations are robust to changes in data distribution, unlike standard deepsets, iii) Fishnets saturate Bayesian information content and extend to regimes where MCMC techniques fail and iv) Fishnets can be used as a drop-in aggregation scheme within GNNs. We show that by adopting a Fishnets aggregation scheme for message passing, GNNs can achieve state-of-the-art performance versus architecture size on ogbn-protein data over existing benchmarks with a fraction of learnable parameters and faster training time.", "url": "https://arxiv.org/abs/2310.03812"}, {"metadata": {"arXiv": "2310.03833", "Date": "Thu, 05 Oct 2023 18:33:32 ", "Title": "Learning A Disentangling Representation For PU Learning", "Authors": ["Omar Zamzam", "Haleh Akrami", "Mahdi Soltanolkotabi", "Richard Leahy"], "Categories": "cs.LG"}, "abstract": "In this paper, we address the problem of learning a binary (positive vs. negative) classifier given Positive and Unlabeled data commonly referred to as PU learning. Although rudimentary techniques like clustering, out-of-distribution detection, or positive density estimation can be used to solve the problem in low-dimensional settings, their efficacy progressively deteriorates with higher dimensions due to the increasing complexities in the data distribution. In this paper we propose to learn a neural network-based data representation using a loss function that can be used to project the unlabeled data into two (positive and negative) clusters that can be easily identified using simple clustering techniques, effectively emulating the phenomenon observed in low-dimensional settings. We adopt a vector quantization technique for the learned representations to amplify the separation between the learned unlabeled data clusters. We conduct experiments on simulated PU data that demonstrate the improved performance of our proposed method compared to the current state-of-the-art approaches. We also provide some theoretical justification for our two cluster-based approach and our algorithmic choices.", "url": "https://arxiv.org/abs/2310.03833"}, {"metadata": {"arXiv": "2310.03838", "Date": "Thu, 05 Oct 2023 18:46:27 ", "Title": "Chameleon: Increasing Label-Only Membership Leakage with Adaptive Poisoning", "Authors": ["Harsh Chaudhari", "Giorgio Severi", "Alina Oprea", "Jonathan Ullman"], "Categories": "cs.LG"}, "abstract": "The integration of machine learning (ML) in numerous critical applications introduces a range of privacy concerns for individuals who provide their datasets for model training. One such privacy risk is Membership Inference (MI), in which an attacker seeks to determine whether a particular data sample was included in the training dataset of a model. Current state-of-the-art MI attacks capitalize on access to the model's predicted confidence scores to successfully perform membership inference, and employ data poisoning to further enhance their effectiveness. In this work, we focus on the less explored and more realistic label-only setting, where the model provides only the predicted label on a queried sample. We show that existing label-only MI attacks are ineffective at inferring membership in the low False Positive Rate (FPR) regime. To address this challenge, we propose a new attack Chameleon that leverages a novel adaptive data poisoning strategy and an efficient query selection method to achieve significantly more accurate membership inference than existing label-only attacks, especially at low FPRs.", "url": "https://arxiv.org/abs/2310.03838"}, {"metadata": {"arXiv": "2310.03865", "Date": "Thu, 05 Oct 2023 19:50:15 ", "Title": "Model Complexity of Program Phases", "Authors": ["Arjun Karuvally", "J. Eliot B. Moss"], "Categories": "cs.LG cs.IT math.IT"}, "abstract": "In resource limited computing systems, sequence prediction models must operate under tight constraints. Various models are available that cater to prediction under these conditions that in some way focus on reducing the cost of implementation. These resource constrained sequence prediction models, in practice, exhibit a fundamental tradeoff between the cost of implementation and the quality of its predictions. This fundamental tradeoff seems to be largely unexplored for models for different tasks. Here we formulate the necessary theory and an associated empirical procedure to explore this tradeoff space for a particular family of machine learning models such as deep neural networks. We anticipate that the knowledge of the behavior of this tradeoff may be beneficial in understanding the theoretical and practical limits of creation and deployment of models for resource constrained tasks.", "url": "https://arxiv.org/abs/2310.03865"}, {"metadata": {"arXiv": "2310.03879", "Date": "Thu, 05 Oct 2023 20:27:22 ", "Title": "Non Commutative Convolutional Signal Models in Neural Networks: Stability to Small Deformations", "Authors": ["Alejandro Parada-Mayorga", "Landon Butler", "and Alejandro Ribeiro"], "Categories": "cs.LG"}, "abstract": "In this paper we discuss the results recently published in~[1] about algebraic signal models (ASMs) based on non commutative algebras and their use in convolutional neural networks. Relying on the general tools from algebraic signal processing (ASP), we study the filtering and stability properties of non commutative convolutional filters. We show how non commutative filters can be stable to small perturbations on the space of operators. We also show that although the spectral components of the Fourier representation in a non commutative signal model are associated to spaces of dimension larger than one, there is a trade-off between stability and selectivity similar to that observed for commutative models. Our results have direct implications for group neural networks, multigraph neural networks and quaternion neural networks, among other non commutative architectures. We conclude by corroborating these results through numerical experiments.", "url": "https://arxiv.org/abs/2310.03879"}, {"metadata": {"arXiv": "2310.03898", "Date": "Thu, 05 Oct 2023 21:07:45 ", "Title": "Class-Incremental Learning Using Generative Experience Replay Based on Time-aware Regularization", "Authors": ["Zizhao Hu", "Mohammad Rostami"], "Categories": "cs.LG"}, "abstract": "Learning new tasks accumulatively without forgetting remains a critical challenge in continual learning. Generative experience replay addresses this challenge by synthesizing pseudo-data points for past learned tasks and later replaying them for concurrent training along with the new tasks' data. Generative replay is the best strategy for continual learning under a strict class-incremental setting when certain constraints need to be met: (i) constant model size, (ii) no pre-training dataset, and (iii) no memory buffer for storing past tasks' data. Inspired by the biological nervous system mechanisms, we introduce a time-aware regularization method to dynamically fine-tune the three training objective terms used for generative replay: supervised learning, latent regularization, and data reconstruction. Experimental results on major benchmarks indicate that our method pushes the limit of brain-inspired continual learners under such strict settings, improves memory retention, and increases the average performance over continually arriving tasks.", "url": "https://arxiv.org/abs/2310.03898"}, {"metadata": {"arXiv": "2310.03899", "Date": "Thu, 05 Oct 2023 21:10:22 ", "Title": "CrysFormer: Protein Structure Prediction via 3d Patterson Maps and Partial Structure Attention", "Authors": ["Chen Dun", "Qiutai Pan", "Shikai Jin", "Ria Stevens", "Mitchell D. Miller", "George N. Phillips", "Jr.", "Anastasios Kyrillidis"], "Categories": "cs.LG"}, "abstract": "Determining the structure of a protein has been a decades-long open question. A protein's three-dimensional structure often poses nontrivial computation costs, when classical simulation algorithms are utilized. Advances in the transformer neural network architecture -- such as AlphaFold2 -- achieve significant improvements for this problem, by learning from a large dataset of sequence information and corresponding protein structures. Yet, such methods only focus on sequence information; other available prior knowledge, such as protein crystallography and partial structure of amino acids, could be potentially utilized. To the best of our knowledge, we propose the first transformer-based model that directly utilizes protein crystallography and partial structure information to predict the electron density maps of proteins. Via two new datasets of peptide fragments (2-residue and 15-residue) , we demonstrate our method, dubbed \\texttt{CrysFormer}, can achieve accurate predictions, based on a much smaller dataset size and with reduced computation costs.", "url": "https://arxiv.org/abs/2310.03899"}, {"metadata": {"arXiv": "2310.03906", "Date": "Thu, 05 Oct 2023 21:24:54 ", "Title": "PyDCM: Custom Data Center Models with Reinforcement Learning for Sustainability", "Authors": ["Avisek Naug", "Antonio Guillen", "Ricardo Luna Guti\\'errez", "Vineet Gundecha", "Dejan Markovikj", "Lekhapriya Dheeraj Kashyap", "Lorenz Krause", "Sahand Ghorbanpour", "Sajad Mousavi", "Ashwin Ramesh Babu", "Soumyendu Sarkar"], "Categories": "cs.LG", "Comments": ["The 10th ACM International Conference on Systems for Energy-Efficient Buildings", "Cities", "and Transportation (BuildSys '23)", "November 15--16", "2023", "Istanbul", "Turkey"], "DOI": "10.1145/3600100.3623732"}, "abstract": "The increasing global emphasis on sustainability and reducing carbon emissions is pushing governments and corporations to rethink their approach to data center design and operation. Given their high energy consumption and exponentially large computational workloads, data centers are prime candidates for optimizing power consumption, especially in areas such as cooling and IT energy usage. A significant challenge in this pursuit is the lack of a configurable and scalable thermal data center model that offers an end-to-end pipeline. Data centers consist of multiple IT components whose geometric configuration and heat dissipation make thermal modeling difficult. This paper presents PyDCM, a customizable Data Center Model implemented in Python, that allows users to create unique configurations of IT equipment with custom server specifications and geometric arrangements of IT cabinets. The use of vectorized thermal calculations makes PyDCM orders of magnitude faster (30 times) than current Energy Plus modeling implementations and scales sublinearly with the number of CPUs. Also, PyDCM enables the use of Deep Reinforcement Learning via the Gymnasium wrapper to optimize data center cooling and offers a user-friendly platform for testing various data center design prototypes.", "url": "https://arxiv.org/abs/2310.03906"}, {"metadata": {"arXiv": "2310.03915", "Date": "Thu, 05 Oct 2023 21:44:18 ", "Title": "Leveraging Low-Rank and Sparse Recurrent Connectivity for Robust Closed-Loop Control", "Authors": ["Neehal Tumma", "Mathias Lechner", "Noel Loo", "Ramin Hasani", "Daniela Rus"], "Categories": "cs.LG"}, "abstract": "Developing autonomous agents that can interact with changing environments is an open challenge in machine learning. Robustness is particularly important in these settings as agents are often fit offline on expert demonstrations but deployed online where they must generalize to the closed feedback loop within the environment. In this work, we explore the application of recurrent neural networks to tasks of this nature and understand how a parameterization of their recurrent connectivity influences robustness in closed-loop settings. Specifically, we represent the recurrent connectivity as a function of rank and sparsity and show both theoretically and empirically that modulating these two variables has desirable effects on network dynamics. The proposed low-rank, sparse connectivity induces an interpretable prior on the network that proves to be most amenable for a class of models known as closed-form continuous-time neural networks (CfCs). We find that CfCs with fewer parameters can outperform their full-rank, fully-connected counterparts in the online setting under distribution shift. This yields memory-efficient and robust agents while opening a new perspective on how we can modulate network dynamics through connectivity.", "url": "https://arxiv.org/abs/2310.03915"}, {"metadata": {"arXiv": "2310.03927", "Date": "Thu, 05 Oct 2023 22:11:52 ", "Title": "Improving classifier decision boundaries using nearest neighbors", "Authors": ["Johannes Schneider"], "Categories": "cs.LG"}, "abstract": "Neural networks are not learning optimal decision boundaries. We show that decision boundaries are situated in areas of low training data density. They are impacted by few training samples which can easily lead to overfitting. We provide a simple algorithm performing a weighted average of the prediction of a sample and its nearest neighbors' (computed in latent space) leading to a minor favorable outcomes for a variety of important measures for neural networks. In our evaluation, we employ various self-trained and pre-trained convolutional neural networks to show that our approach improves (i) resistance to label noise, (ii) robustness against adversarial attacks, (iii) classification accuracy, and to some degree even (iv) interpretability. While improvements are not necessarily large in all four areas, our approach is conceptually simple, i.e., improvements come without any modification to network architecture, training procedure or dataset. Furthermore, they are in stark contrast to prior works that often require trade-offs among the four objectives or provide valuable, but non-actionable insights.", "url": "https://arxiv.org/abs/2310.03927"}, {"metadata": {"arXiv": "2310.03941", "Date": "Thu, 05 Oct 2023 23:09:31 ", "Title": "LaTeX: Language Pattern-aware Triggering Event Detection for Adverse Experience during Pandemics", "Authors": ["Kaiqun Fu", "Yangxiao Bai", "Weiwei Zhang", "Deepthi Kolady"], "Categories": "cs.LG cs.SI", "Comments": ["arXiv admin note: text overlap with arXiv:1911.08684"]}, "abstract": "The COVID-19 pandemic has accentuated socioeconomic disparities across various racial and ethnic groups in the United States. While previous studies have utilized traditional survey methods like the Household Pulse Survey (HPS) to elucidate these disparities, this paper explores the role of social media platforms in both highlighting and addressing these challenges. Drawing from real-time data sourced from Twitter, we analyzed language patterns related to four major types of adverse experiences: loss of employment income (LI), food scarcity (FS), housing insecurity (HI), and unmet needs for mental health services (UM). We first formulate a sparsity optimization problem that extracts low-level language features from social media data sources. Second, we propose novel constraints on feature similarity exploiting prior knowledge about the similarity of the language patterns among the adverse experiences. The proposed problem is challenging to solve due to the non-convexity objective and non-smoothness penalties. We develop an algorithm based on the alternating direction method of multipliers (ADMM) framework to solve the proposed formulation. Extensive experiments and comparisons to other models on real-world social media and the detection of adverse experiences justify the efficacy of our model.", "url": "https://arxiv.org/abs/2310.03941"}, {"metadata": {"arXiv": "2310.03946", "Date": "Thu, 05 Oct 2023 23:46:45 ", "Title": "Improved prediction of ligand-protein binding affinities by meta-modeling", "Authors": ["Ho-Joon Lee", "Prashant S. Emani", "and Mark B. Gerstein"], "Categories": "cs.LG q-bio.QM", "Comments": ["61 pages", "3 main tables", "6 main figures", "6 supplementary figures", "and supporting information. For 8 supplementary tables and code", "see https://github.com/Lee1701/Lee2023a"]}, "abstract": "The accurate screening of candidate drug ligands against target proteins through computational approaches is of prime interest to drug development efforts, as filtering potential candidates would save time and expenses for finding drugs. Such virtual screening depends in part on methods to predict the binding affinity between ligands and proteins. Given many computational models for binding affinity prediction with varying results across targets, we herein develop a meta-modeling framework by integrating published empirical structure-based docking and sequence-based deep learning models. In building this framework, we evaluate many combinations of individual models, training databases, and linear and nonlinear meta-modeling approaches. We show that many of our meta-models significantly improve affinity predictions over individual base models. Our best meta-models achieve comparable performance to state-of-the-art exclusively structure-based deep learning tools. Overall, we demonstrate that diverse modeling approaches can be ensembled together to gain substantial improvement in binding affinity prediction while allowing control over input features such as physicochemical properties or molecular descriptors.", "url": "https://arxiv.org/abs/2310.03946"}, {"metadata": {"arXiv": "2310.03957", "Date": "Fri, 06 Oct 2023 00:52:48 ", "Title": "Understanding prompt engineering may not require rethinking generalization", "Authors": ["Victor Akinwande", "Yiding Jiang", "Dylan Sam", "J. Zico Kolter"], "Categories": "cs.LG cs.CV"}, "abstract": "Zero-shot learning in prompted vision-language models, the practice of crafting prompts to build classifiers without an explicit training process, has achieved impressive performance in many settings. This success presents a seemingly surprising observation: these methods suffer relatively little from overfitting, i.e., when a prompt is manually engineered to achieve low error on a given training set (thus rendering the method no longer actually zero-shot), the approach still performs well on held-out test data. In this paper, we show that we can explain such performance well via recourse to classical PAC-Bayes bounds. Specifically, we show that the discrete nature of prompts, combined with a PAC-Bayes prior given by a language model, results in generalization bounds that are remarkably tight by the standards of the literature: for instance, the generalization bound of an ImageNet classifier is often within a few percentage points of the true test error. We demonstrate empirically that this holds for existing handcrafted prompts and prompts generated through simple greedy search. Furthermore, the resulting bound is well-suited for model selection: the models with the best bound typically also have the best test performance. This work thus provides a possible justification for the widespread practice of prompt engineering, even if it seems that such methods could potentially overfit the training data.", "url": "https://arxiv.org/abs/2310.03957"}, {"metadata": {"arXiv": "2310.03968", "Date": "Fri, 06 Oct 2023 01:53:42 ", "Title": "Ultimate limit on learning non-Markovian behavior: Fisher information rate and excess information", "Authors": ["Paul M. Riechers"], "Categories": "cs.LG math.ST physics.data-an stat.TH"}, "abstract": "We address the fundamental limits of learning unknown parameters of any stochastic process from time-series data, and discover exact closed-form expressions for how optimal inference scales with observation length. Given a parametrized class of candidate models, the Fisher information of observed sequence probabilities lower-bounds the variance in model estimation from finite data. As sequence-length increases, the minimal variance scales as the square inverse of the length -- with constant coefficient given by the information rate. We discover a simple closed-form expression for this information rate, even in the case of infinite Markov order. We furthermore obtain the exact analytic lower bound on model variance from the observation-induced metadynamic among belief states. We discover ephemeral, exponential, and more general modes of convergence to the asymptotic information rate. Surprisingly, this myopic information rate converges to the asymptotic Fisher information rate with exactly the same relaxation timescales that appear in the myopic entropy rate as it converges to the Shannon entropy rate for the process. We illustrate these results with a sequence of examples that highlight qualitatively distinct features of stochastic processes that shape optimal learning.", "url": "https://arxiv.org/abs/2310.03968"}, {"metadata": {"arXiv": "2310.03999", "Date": "Fri, 06 Oct 2023 03:57:56 ", "Title": "Runtime Monitoring DNN-Based Perception", "Authors": ["Chih-Hong Cheng", "Michael Luttenberger", "Rongjie Yan"], "Categories": "cs.LG cs.SE"}, "abstract": "Deep neural networks (DNNs) are instrumental in realizing complex perception systems. As many of these applications are safety-critical by design, engineering rigor is required to ensure that the functional insufficiency of the DNN-based perception is not the source of harm. In addition to conventional static verification and testing techniques employed during the design phase, there is a need for runtime verification techniques that can detect critical events, diagnose issues, and even enforce requirements. This tutorial aims to provide readers with a glimpse of techniques proposed in the literature. We start with classical methods proposed in the machine learning community, then highlight a few techniques proposed by the formal methods community. While we surely can observe similarities in the design of monitors, how the decision boundaries are created vary between the two communities. We conclude by highlighting the need to rigorously design monitors, where data availability outside the operational domain plays an important role.", "url": "https://arxiv.org/abs/2310.03999"}, {"metadata": {"arXiv": "2310.04015", "Date": "Fri, 06 Oct 2023 04:52:46 ", "Title": "Learning via Look-Alike Clustering: A Precise Analysis of Model Generalization", "Authors": ["Adel Javanmard and Vahab Mirrokni"], "Categories": "cs.LG math.ST stat.ML stat.TH", "Comments": ["accepted at the Conference on Neural Information Processing Systems (NeurIPS 2023)"]}, "abstract": "While personalized recommendations systems have become increasingly popular, ensuring user data protection remains a paramount concern in the development of these learning systems. A common approach to enhancing privacy involves training models using anonymous data rather than individual data. In this paper, we explore a natural technique called \\emph{look-alike clustering}, which involves replacing sensitive features of individuals with the cluster's average values. We provide a precise analysis of how training models using anonymous cluster centers affects their generalization capabilities. We focus on an asymptotic regime where the size of the training set grows in proportion to the features dimension. Our analysis is based on the Convex Gaussian Minimax Theorem (CGMT) and allows us to theoretically understand the role of different model components on the generalization error. In addition, we demonstrate that in certain high-dimensional regimes, training over anonymous cluster centers acts as a regularization and improves generalization error of the trained models. Finally, we corroborate our asymptotic theory with finite-sample numerical experiments where we observe a perfect match when the sample size is only of order of a few hundreds.", "url": "https://arxiv.org/abs/2310.04015"}, {"metadata": {"arXiv": "2310.04017", "Date": "Fri, 06 Oct 2023 05:00:25 ", "Title": "PGraphDTA: Improving Drug Target Interaction Prediction using Protein Language Models and Contact Maps", "Authors": ["Rakesh Bal", "Yijia Xiao", "Wei Wang"], "Categories": "cs.LG q-bio.QM", "Comments": ["11 pages", "5 figures", "4 tables"]}, "abstract": "Developing and discovering new drugs is a complex and resource-intensive endeavor that often involves substantial costs, time investment, and safety concerns. A key aspect of drug discovery involves identifying novel drug-target (DT) interactions. Existing computational methods for predicting DT interactions have primarily focused on binary classification tasks, aiming to determine whether a DT pair interacts or not. However, protein-ligand interactions exhibit a continuum of binding strengths, known as binding affinity, presenting a persistent challenge for accurate prediction. In this study, we investigate various techniques employed in Drug Target Interaction (DTI) prediction and propose novel enhancements to enhance their performance. Our approaches include the integration of Protein Language Models (PLMs) and the incorporation of Contact Map information as an inductive bias within current models. Through extensive experimentation, we demonstrate that our proposed approaches outperform the baseline models considered in this study, presenting a compelling case for further development in this direction. We anticipate that the insights gained from this work will significantly narrow the search space for potential drugs targeting specific proteins, thereby accelerating drug discovery. Code and data for PGraphDTA are available at https://anonymous.4open.science/r/PGraphDTA.", "url": "https://arxiv.org/abs/2310.04017"}, {"metadata": {"arXiv": "2310.04028", "Date": "Fri, 06 Oct 2023 05:43:50 ", "Title": "Genetic prediction of quantitative traits: a machine learner's guide focused on height", "Authors": ["Lucie Bourguignon and Caroline Weis and Catherine R. Jutzeler and Michael Adamer"], "Categories": "cs.LG q-bio.GN"}, "abstract": "Machine learning and deep learning have been celebrating many successes in the application to biological problems, especially in the domain of protein folding. Another equally complex and important question has received relatively little attention by the machine learning community, namely the one of prediction of complex traits from genetics. Tackling this problem requires in-depth knowledge of the related genetics literature and awareness of various subtleties associated with genetic data. In this guide, we provide an overview for the machine learning community on current state of the art models and associated subtleties which need to be taken into consideration when developing new models for phenotype prediction. We use height as an example of a continuous-valued phenotype and provide an introduction to benchmark datasets, confounders, feature selection, and common metrics.", "url": "https://arxiv.org/abs/2310.04028"}, {"metadata": {"arXiv": "2310.04038", "Date": "Fri, 06 Oct 2023 06:19:16 ", "Title": "Joint Projection Learning and Tensor Decomposition Based Incomplete Multi-view Clustering", "Authors": ["Wei Lv", "Chao Zhang", "Huaxiong Li", "Xiuyi Jia", "Chunlin Chen"], "Categories": "cs.LG", "Comments": ["IEEE Transactions on Neural Networks and Learning Systems", "2023"], "DOI": "10.1109/TNNLS.2023.3306006"}, "abstract": "Incomplete multi-view clustering (IMVC) has received increasing attention since it is often that some views of samples are incomplete in reality. Most existing methods learn similarity subgraphs from original incomplete multi-view data and seek complete graphs by exploring the incomplete subgraphs of each view for spectral clustering. However, the graphs constructed on the original high-dimensional data may be suboptimal due to feature redundancy and noise. Besides, previous methods generally ignored the graph noise caused by the inter-class and intra-class structure variation during the transformation of incomplete graphs and complete graphs. To address these problems, we propose a novel Joint Projection Learning and Tensor Decomposition Based method (JPLTD) for IMVC. Specifically, to alleviate the influence of redundant features and noise in high-dimensional data, JPLTD introduces an orthogonal projection matrix to project the high-dimensional features into a lower-dimensional space for compact feature learning.Meanwhile, based on the lower-dimensional space, the similarity graphs corresponding to instances of different views are learned, and JPLTD stacks these graphs into a third-order low-rank tensor to explore the high-order correlations across different views. We further consider the graph noise of projected data caused by missing samples and use a tensor-decomposition based graph filter for robust clustering.JPLTD decomposes the original tensor into an intrinsic tensor and a sparse tensor. The intrinsic tensor models the true data similarities. An effective optimization algorithm is adopted to solve the JPLTD model. Comprehensive experiments on several benchmark datasets demonstrate that JPLTD outperforms the state-of-the-art methods. The code of JPLTD is available at https://github.com/weilvNJU/JPLTD.", "url": "https://arxiv.org/abs/2310.04038"}, {"metadata": {"arXiv": "2310.04047", "Date": "Fri, 06 Oct 2023 06:51:16 ", "Title": "AUTOPARLLM: GNN-Guided Automatic Code Parallelization using Large Language Models", "Authors": ["Quazi Ishtiaque Mahmud", "Ali TehraniJamsaz", "Hung D Phan", "Nesreen K. Ahmed and Ali Jannesari"], "Categories": "cs.LG", "Comments": ["10 pages"]}, "abstract": "Parallelizing sequentially written programs is a challenging task. Even experienced developers need to spend considerable time finding parallelism opportunities and then actually writing parallel versions of sequentially written programs. To address this issue, we present AUTOPARLLM, a framework for automatically discovering parallelism and generating the parallel version of the sequentially written program. Our framework consists of two major components: i) a heterogeneous Graph Neural Network (GNN) based parallelism discovery and parallel pattern detection module, and ii) an LLM-based code generator to generate the parallel counterpart of the sequential programs. We use the GNN to learn the flow-aware characteristics of the programs to identify parallel regions in sequential programs and then construct an enhanced prompt using the GNN's results for the LLM-based generator to finally produce the parallel counterparts of the sequential programs. We evaluate AUTOPARLLM on 11 applications of 2 well-known benchmark suites: NAS Parallel Benchmark and Rodinia Benchmark. Our results show that AUTOPARLLM is indeed effective in improving the state-of-the-art LLM-based models for the task of parallel code generation in terms of multiple code generation metrics. AUTOPARLLM also improves the average runtime of the parallel code generated by the state-of-the-art LLMs by as high as 3.4% and 2.9% for the NAS Parallel Benchmark and Rodinia Benchmark respectively. Additionally, to overcome the issue that well-known metrics for translation evaluation have not been optimized to evaluate the quality of the generated parallel code, we propose OMPScore for evaluating the quality of the generated code. We show that OMPScore exhibits a better correlation with human judgment than existing metrics, measured by up to 75% improvement of Spearman correlation.", "url": "https://arxiv.org/abs/2310.04047"}, {"metadata": {"arXiv": "2310.04059", "Date": "Fri, 06 Oct 2023 07:26:40 ", "Title": "DEFT: A new distance-based feature set for keystroke dynamics", "Authors": ["Nuwan Kaluarachchi", "Sevvandi Kandanaarachchi", "Kristen Moore and Arathi Arakala"], "Categories": "cs.LG", "Comments": ["12 pages", "5 figures", "3 tables", "conference paper"]}, "abstract": "Keystroke dynamics is a behavioural biometric utilised for user identification and authentication. We propose a new set of features based on the distance between keys on the keyboard, a concept that has not been considered before in keystroke dynamics. We combine flight times, a popular metric, with the distance between keys on the keyboard and call them as Distance Enhanced Flight Time features (DEFT). This novel approach provides comprehensive insights into a person's typing behaviour, surpassing typing velocity alone. We build a DEFT model by combining DEFT features with other previously used keystroke dynamic features. The DEFT model is designed to be device-agnostic, allowing us to evaluate its effectiveness across three commonly used devices: desktop, mobile, and tablet. The DEFT model outperforms the existing state-of-the-art methods when we evaluate its effectiveness across two datasets. We obtain accuracy rates exceeding 99% and equal error rates below 10% on all three devices.", "url": "https://arxiv.org/abs/2310.04059"}, {"metadata": {"arXiv": "2310.04078", "Date": "Fri, 06 Oct 2023 08:06:15 ", "Title": "Beyond Myopia: Learning from Positive and Unlabeled Data through Holistic Predictive Trends", "Authors": ["Xinrui Wang and Wenhai Wan and Chuanxin Geng and Shaoyuan LI and Songcan Chen"], "Categories": "cs.LG", "Comments": ["25 pages"], "Journal-ref": "NeurIPS 2023"}, "abstract": "Learning binary classifiers from positive and unlabeled data (PUL) is vital in many real-world applications, especially when verifying negative examples is difficult. Despite the impressive empirical performance of recent PUL methods, challenges like accumulated errors and increased estimation bias persist due to the absence of negative labels. In this paper, we unveil an intriguing yet long-overlooked observation in PUL: \\textit{resampling the positive data in each training iteration to ensure a balanced distribution between positive and unlabeled examples results in strong early-stage performance. Furthermore, predictive trends for positive and negative classes display distinctly different patterns.} Specifically, the scores (output probability) of unlabeled negative examples consistently decrease, while those of unlabeled positive examples show largely chaotic trends. Instead of focusing on classification within individual time frames, we innovatively adopt a holistic approach, interpreting the scores of each example as a temporal point process (TPP). This reformulates the core problem of PUL as recognizing trends in these scores. We then propose a novel TPP-inspired measure for trend detection and prove its asymptotic unbiasedness in predicting changes. Notably, our method accomplishes PUL without requiring additional parameter tuning or prior assumptions, offering an alternative perspective for tackling this problem. Extensive experiments verify the superiority of our method, particularly in a highly imbalanced real-world setting, where it achieves improvements of up to $11.3\\%$ in key metrics. The code is available at \\href{https://github.com/wxr99/HolisticPU}{https://github.com/wxr99/HolisticPU}.", "url": "https://arxiv.org/abs/2310.04078"}, {"metadata": {"arXiv": "2310.04140", "Date": "Fri, 06 Oct 2023 10:24:33 ", "Title": "Routing Arena: A Benchmark Suite for Neural Routing Solvers", "Authors": ["Daniela Thyssens", "Tim Dernedde", "Jonas K. Falkner", "Lars Schmidt-Thieme"], "Categories": "cs.LG"}, "abstract": "Neural Combinatorial Optimization has been researched actively in the last eight years. Even though many of the proposed Machine Learning based approaches are compared on the same datasets, the evaluation protocol exhibits essential flaws and the selection of baselines often neglects State-of-the-Art Operations Research approaches. To improve on both of these shortcomings, we propose the Routing Arena, a benchmark suite for Routing Problems that provides a seamless integration of consistent evaluation and the provision of baselines and benchmarks prevalent in the Machine Learning- and Operations Research field. The proposed evaluation protocol considers the two most important evaluation cases for different applications: First, the solution quality for an a priori fixed time budget and secondly the anytime performance of the respective methods. By setting the solution trajectory in perspective to a Best Known Solution and a Base Solver's solutions trajectory, we furthermore propose the Weighted Relative Average Performance (WRAP), a novel evaluation metric that quantifies the often claimed runtime efficiency of Neural Routing Solvers. A comprehensive first experimental evaluation demonstrates that the most recent Operations Research solvers generate state-of-the-art results in terms of solution quality and runtime efficiency when it comes to the vehicle routing problem. Nevertheless, some findings highlight the advantages of neural approaches and motivate a shift in how neural solvers should be conceptualized.", "url": "https://arxiv.org/abs/2310.04140"}, {"metadata": {"arXiv": "2310.04145", "Date": "Fri, 06 Oct 2023 10:36:28 ", "Title": "From Zero to Hero: Detecting Leaked Data through Synthetic Data Injection and Model Querying", "Authors": ["Biao Wu", "Qiang Huang", "Anthony K. H. Tung"], "Categories": "cs.LG cs.DB", "Comments": ["13 pages", "11 figures", "and 4 tables"]}, "abstract": "Safeguarding the Intellectual Property (IP) of data has become critically important as machine learning applications continue to proliferate, and their success heavily relies on the quality of training data. While various mechanisms exist to secure data during storage, transmission, and consumption, fewer studies have been developed to detect whether they are already leaked for model training without authorization. This issue is particularly challenging due to the absence of information and control over the training process conducted by potential attackers. In this paper, we concentrate on the domain of tabular data and introduce a novel methodology, Local Distribution Shifting Synthesis (\\textsc{LDSS}), to detect leaked data that are used to train classification models. The core concept behind \\textsc{LDSS} involves injecting a small volume of synthetic data--characterized by local shifts in class distribution--into the owner's dataset. This enables the effective identification of models trained on leaked data through model querying alone, as the synthetic data injection results in a pronounced disparity in the predictions of models trained on leaked and modified datasets. \\textsc{LDSS} is \\emph{model-oblivious} and hence compatible with a diverse range of classification models, such as Naive Bayes, Decision Tree, and Random Forest. We have conducted extensive experiments on seven types of classification models across five real-world datasets. The comprehensive results affirm the reliability, robustness, fidelity, security, and efficiency of \\textsc{LDSS}.", "url": "https://arxiv.org/abs/2310.04145"}, {"metadata": {"arXiv": "2310.04159", "Date": "Fri, 06 Oct 2023 11:17:28 ", "Title": "Amortized Network Intervention to Steer the Excitatory Point Processes", "Authors": ["Zitao Song", "Wendi Ren", "Shuang Li"], "Categories": "cs.LG"}, "abstract": "We tackle the challenge of large-scale network intervention for guiding excitatory point processes, such as infectious disease spread or traffic congestion control. Our model-based reinforcement learning utilizes neural ODEs to capture how the networked excitatory point processes will evolve subject to the time-varying changes in network topology. Our approach incorporates Gradient-Descent based Model Predictive Control (GD-MPC), offering policy flexibility to accommodate prior knowledge and constraints. To address the intricacies of planning and overcome the high dimensionality inherent to such decision-making problems, we design an Amortize Network Interventions (ANI) framework, allowing for the pooling of optimal policies from history and other contexts, while ensuring a permutation equivalent property. This property enables efficient knowledge transfer and sharing across diverse contexts. Our approach has broad applications, from curbing infectious disease spread to reducing carbon emissions through traffic light optimization, and thus has the potential to address critical societal and environmental challenges.", "url": "https://arxiv.org/abs/2310.04159"}, {"metadata": {"arXiv": "2310.04190", "Date": "Fri, 06 Oct 2023 12:09:09 ", "Title": "Non-Redundant Graph Neural Networks with Improved Expressiveness", "Authors": ["Franka Bause", "Samir Moustafa", "Johannes Langguth", "Wilfried N. Gansterer", "Nils M. Kriege"], "Categories": "cs.LG"}, "abstract": "Message passing graph neural networks iteratively compute node embeddings by aggregating messages from all neighbors. This procedure can be viewed as a neural variant of the Weisfeiler-Leman method, which limits their expressive power. Moreover, oversmoothing and oversquashing restrict the number of layers these networks can effectively utilize. The repeated exchange and encoding of identical information in message passing amplifies oversquashing. We propose a novel aggregation scheme based on neighborhood trees, which allows for controlling the redundancy by pruning branches of the unfolding trees underlying standard message passing. We prove that reducing redundancy improves expressivity and experimentally show that it alleviates oversquashing. We investigate the interaction between redundancy in message passing and redundancy in computation and propose a compact representation of neighborhood trees, from which we compute node and graph embeddings via a neural tree canonization technique. Our method is provably more expressive than the Weisfeiler-Leman method, less susceptible to oversquashing than message passing neural networks, and provides high classification accuracy on widely-used benchmark datasets.", "url": "https://arxiv.org/abs/2310.04190"}, {"metadata": {"arXiv": "2310.04216", "Date": "Fri, 06 Oct 2023 13:02:29 ", "Title": "Cost-Effective Retraining of Machine Learning Models", "Authors": ["Ananth Mahadevan and Michael Mathioudakis"], "Categories": "cs.LG"}, "abstract": "It is important to retrain a machine learning (ML) model in order to maintain its performance as the data changes over time. However, this can be costly as it usually requires processing the entire dataset again. This creates a trade-off between retraining too frequently, which leads to unnecessary computing costs, and not retraining often enough, which results in stale and inaccurate ML models. To address this challenge, we propose ML systems that make automated and cost-effective decisions about when to retrain an ML model. We aim to optimize the trade-off by considering the costs associated with each decision. Our research focuses on determining whether to retrain or keep an existing ML model based on various factors, including the data, the model, and the predictive queries answered by the model. Our main contribution is a Cost-Aware Retraining Algorithm called Cara, which optimizes the trade-off over streams of data and queries. To evaluate the performance of Cara, we analyzed synthetic datasets and demonstrated that Cara can adapt to different data drifts and retraining costs while performing similarly to an optimal retrospective algorithm. We also conducted experiments with real-world datasets and showed that Cara achieves better accuracy than drift detection baselines while making fewer retraining decisions, ultimately resulting in lower total costs.", "url": "https://arxiv.org/abs/2310.04216"}, {"metadata": {"arXiv": "2310.04238", "Date": "Fri, 06 Oct 2023 13:21:16 ", "Title": "Bringing Quantum Algorithms to Automated Machine Learning: A Systematic Review of AutoML Frameworks Regarding Extensibility for QML Algorithms", "Authors": ["Dennis Klau", "Marc Z\\\"oller", "Christian Tutschku"], "Categories": "cs.LG cs.SE", "Comments": ["Whitepaper"]}, "abstract": "This work describes the selection approach and analysis of existing AutoML frameworks regarding their capability of a) incorporating Quantum Machine Learning (QML) algorithms into this automated solving approach of the AutoML framing and b) solving a set of industrial use-cases with different ML problem types by benchmarking their most important characteristics. For that, available open-source tools are condensed into a market overview and suitable frameworks are systematically selected on a multi-phase, multi-criteria approach. This is done by considering software selection approaches, as well as in terms of the technical perspective of AutoML. The requirements for the framework selection are divided into hard and soft criteria regarding their software and ML attributes. Additionally, a classification of AutoML frameworks is made into high- and low-level types, inspired by the findings of. Finally, we select Ray and AutoGluon as the suitable low- and high-level frameworks respectively, as they fulfil all requirements sufficiently and received the best evaluation feedback during the use-case study. Based on those findings, we build an extended Automated Quantum Machine Learning (AutoQML) framework with QC-specific pipeline steps and decision characteristics for hardware and software constraints.", "url": "https://arxiv.org/abs/2310.04238"}, {"metadata": {"arXiv": "2310.04264", "Date": "Fri, 06 Oct 2023 14:11:21 ", "Title": "C(NN)FD -- deep learning predictions of tip clearance variations on multi-stage axial compressors aerodynamic performance", "Authors": ["Giuseppe Bruni", "Sepehr Maleki", "Senthil K. Krishnababu"], "Categories": "cs.LG cs.CE physics.flu-dyn", "Comments": ["arXiv admin note: text overlap with arXiv:2306.05889"]}, "abstract": "Application of deep learning methods to physical simulations such as CFD (Computational Fluid Dynamics), have been so far of limited industrial relevance. This paper demonstrates the development and application of a deep learning framework for real-time predictions of the impact of tip clearance variations on the aerodynamic performance of multi-stage axial compressors in gas turbines. The proposed C(NN)FD architecture is proven to be scalable to industrial applications, and achieves in real-time accuracy comparable to the CFD benchmark. The deployed model, is readily integrated within the manufacturing and build process of gas turbines, thus providing the opportunity to analytically assess the impact on performance and potentially reduce requirements for expensive physical tests.", "url": "https://arxiv.org/abs/2310.04264"}, {"metadata": {"arXiv": "2310.04283", "Date": "Fri, 06 Oct 2023 14:33:21 ", "Title": "On the Error-Propagation of Inexact Deflation for Principal Component Analysis", "Authors": ["Fangshuo Liao", "Junhyung Lyle Kim", "Cruz Barnum", "Anastasios Kyrillidis"], "Categories": "cs.LG math.OC stat.ML"}, "abstract": "Principal Component Analysis (PCA) is a popular tool in data analysis, especially when the data is high-dimensional. PCA aims to find subspaces, spanned by the so-called \\textit{principal components}, that best explain the variance in the dataset. The deflation method is a popular meta-algorithm -- used to discover such subspaces -- that sequentially finds individual principal components, starting from the most important one and working its way towards the less important ones. However, due to its sequential nature, the numerical error introduced by not estimating principal components exactly -- e.g., due to numerical approximations through this process -- propagates, as deflation proceeds. To the best of our knowledge, this is the first work that mathematically characterizes the error propagation of the inexact deflation method, and this is the key contribution of this paper. We provide two main results: $i)$ when the sub-routine for finding the leading eigenvector is generic, and $ii)$ when power iteration is used as the sub-routine. In the latter case, the additional directional information from power iteration allows us to obtain a tighter error bound than the analysis of the sub-routine agnostic case. As an outcome, we provide explicit characterization on how the error progresses and affects subsequent principal component estimations for this fundamental problem.", "url": "https://arxiv.org/abs/2310.04283"}, {"metadata": {"arXiv": "2310.04292", "Date": "Fri, 06 Oct 2023 14:51:17 ", "Title": "Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets", "Authors": ["Dominique Beaini", "Shenyang Huang", "Joao Alex Cunha", "Gabriela Moisescu-Pareja", "Oleksandr Dymov", "Samuel Maddrell-Mander", "Callum McLean", "Frederik Wenkel", "Luis M\\\"uller", "Jama Hussein Mohamud", "Ali Parviz", "Michael Craig", "Micha{\\l} Koziarski", "Jiarui Lu", "Zhaocheng Zhu", "Cristian Gabellini", "Kerstin Klaser", "Josef Dean", "Cas Wognum", "Maciej Sypetkowski", "Guillaume Rabusseau", "Reihaneh Rabbany", "Jian Tang", "Christopher Morris", "Mirco Ravanelli", "Guy Wolf", "Prudencio Tossou", "Hadrien Mary", "Therence Bois", "Andrew Fitzgibbon", "B{\\l}a\\.zej Banaszewski", "Chad Martin", "Dominic Masters"], "Categories": "cs.LG"}, "abstract": "Recently, pre-trained foundation models have enabled significant advancements in multiple fields. In molecular machine learning, however, where datasets are often hand-curated, and hence typically small, the lack of datasets with labeled features, and codebases to manage those datasets, has hindered the development of foundation models. In this work, we present seven novel datasets categorized by size into three distinct categories: ToyMix, LargeMix and UltraLarge. These datasets push the boundaries in both the scale and the diversity of supervised labels for molecular learning. They cover nearly 100 million molecules and over 3000 sparsely defined tasks, totaling more than 13 billion individual labels of both quantum and biological nature. In comparison, our datasets contain 300 times more data points than the widely used OGB-LSC PCQM4Mv2 dataset, and 13 times more than the quantum-only QM1B dataset. In addition, to support the development of foundational models based on our proposed datasets, we present the Graphium graph machine learning library which simplifies the process of building and training molecular machine learning models for multi-task and multi-level molecular datasets. Finally, we present a range of baseline results as a starting point of multi-task and multi-level training on these datasets. Empirically, we observe that performance on low-resource biological datasets show improvement by also training on large amounts of quantum data. This indicates that there may be potential in multi-task and multi-level training of a foundation model and fine-tuning it to resource-constrained downstream tasks.", "url": "https://arxiv.org/abs/2310.04292"}, {"metadata": {"arXiv": "2310.04314", "Date": "Fri, 06 Oct 2023 15:22:40 ", "Title": "Latent Graph Inference with Limited Supervision", "Authors": ["Jianglin Lu", "Yi Xu", "Huan Wang", "Yue Bai", "Yun Fu"], "Categories": "cs.LG"}, "abstract": "Latent graph inference (LGI) aims to jointly learn the underlying graph structure and node representations from data features. However, existing LGI methods commonly suffer from the issue of supervision starvation, where massive edge weights are learned without semantic supervision and do not contribute to the training loss. Consequently, these supervision-starved weights, which may determine the predictions of testing samples, cannot be semantically optimal, resulting in poor generalization. In this paper, we observe that this issue is actually caused by the graph sparsification operation, which severely destroys the important connections established between pivotal nodes and labeled ones. To address this, we propose to restore the corrupted affinities and replenish the missed supervision for better LGI. The key challenge then lies in identifying the critical nodes and recovering the corrupted affinities. We begin by defining the pivotal nodes as $k$-hop starved nodes, which can be identified based on a given adjacency matrix. Considering the high computational burden, we further present a more efficient alternative inspired by CUR matrix decomposition. Subsequently, we eliminate the starved nodes by reconstructing the destroyed connections. Extensive experiments on representative benchmarks demonstrate that reducing the starved nodes consistently improves the performance of state-of-the-art LGI methods, especially under extremely limited supervision (6.12% improvement on Pubmed with a labeling rate of only 0.3%).", "url": "https://arxiv.org/abs/2310.04314"}, {"metadata": {"arXiv": "2310.04327", "Date": "Fri, 06 Oct 2023 15:44:47 ", "Title": "Program Synthesis with Best-First Bottom-Up Search", "Authors": ["Saqib Ameen and Levi H. S. Lelis"], "Categories": "cs.LG", "Comments": ["Published at the Journal of Artificial Intelligence Research (JAIR)"], "DOI": "10.1613/jair.1.14394"}, "abstract": "Cost-guided bottom-up search (BUS) algorithms use a cost function to guide the search to solve program synthesis tasks. In this paper, we show that current state-of-the-art cost-guided BUS algorithms suffer from a common problem: they can lose useful information given by the model and fail to perform the search in a best-first order according to a cost function. We introduce a novel best-first bottom-up search algorithm, which we call Bee Search, that does not suffer information loss and is able to perform cost-guided bottom-up synthesis in a best-first manner. Importantly, Bee Search performs best-first search with respect to the generation of programs, i.e., it does not even create in memory programs that are more expensive than the solution program. It attains best-first ordering with respect to generation by performing a search in an abstract space of program costs. We also introduce a new cost function that better uses the information provided by an existing cost model. Empirical results on string manipulation and bit-vector tasks show that Bee Search can outperform existing cost-guided BUS approaches when employing more complex domain-specific languages (DSLs); Bee Search and previous approaches perform equally well with simpler DSLs. Furthermore, our new cost function with Bee Search outperforms previous cost functions on string manipulation tasks.", "url": "https://arxiv.org/abs/2310.04327"}, {"metadata": {"arXiv": "2310.04328", "Date": "Fri, 06 Oct 2023 15:45:10 ", "Title": "Robust Losses for Decision-Focused Learning", "Authors": ["Noah Schutte", "Krzysztof Postek", "Neil Yorke-Smith"], "Categories": "cs.LG math.OC", "Comments": ["13 pages", "3 figures"]}, "abstract": "Optimization models used to make discrete decisions often contain uncertain parameters that are context-dependent and are estimated through prediction. To account for the quality of the decision made based on the prediction, decision-focused learning (end-to-end predict-then-optimize) aims at training the predictive model to minimize regret, i.e., the loss incurred by making a suboptimal decision. Despite the challenge of this loss function being possibly non-convex and in general non-differentiable, effective gradient-based learning approaches have been proposed to minimize the expected loss, using the empirical loss as a surrogate. However, empirical regret can be an ineffective surrogate because the uncertainty in the optimization model makes the empirical regret unequal to the expected regret in expectation. To illustrate the impact of this inequality, we evaluate the effect of aleatoric and epistemic uncertainty on the accuracy of empirical regret as a surrogate. Next, we propose three robust loss functions that more closely approximate expected regret. Experimental results show that training two state-of-the-art decision-focused learning approaches using robust regret losses improves test-sample empirical regret in general while keeping computational time equivalent relative to the number of training epochs.", "url": "https://arxiv.org/abs/2310.04328"}, {"metadata": {"arXiv": "2310.04334", "Date": "Fri, 06 Oct 2023 15:54:12 ", "Title": "Saliency-Guided Hidden Associative Replay for Continual Learning", "Authors": ["Guangji Bai", "Qilong Zhao", "Xiaoyang Jiang", "Yifei Zhang", "Liang Zhao"], "Categories": "cs.LG", "Comments": ["Preprint. Do not distribute"]}, "abstract": "Continual Learning is a burgeoning domain in next-generation AI, focusing on training neural networks over a sequence of tasks akin to human learning. While CL provides an edge over traditional supervised learning, its central challenge remains to counteract catastrophic forgetting and ensure the retention of prior tasks during subsequent learning. Amongst various strategies to tackle this, replay based methods have emerged as preeminent, echoing biological memory mechanisms. However, these methods are memory intensive, often preserving entire data samples, an approach inconsistent with humans selective memory retention of salient experiences. While some recent works have explored the storage of only significant portions of data in episodic memory, the inherent nature of partial data necessitates innovative retrieval mechanisms. Current solutions, like inpainting, approximate full data reconstruction from partial cues, a method that diverges from genuine human memory processes. Addressing these nuances, this paper presents the Saliency Guided Hidden Associative Replay for Continual Learning. This novel framework synergizes associative memory with replay-based strategies. SHARC primarily archives salient data segments via sparse memory encoding. Importantly, by harnessing associative memory paradigms, it introduces a content focused memory retrieval mechanism, promising swift and near-perfect recall, bringing CL a step closer to authentic human memory processes. Extensive experimental results demonstrate the effectiveness of our proposed method for various continual learning tasks.", "url": "https://arxiv.org/abs/2310.04334"}, {"metadata": {"arXiv": "2310.04343", "Date": "Fri, 06 Oct 2023 16:08:41 ", "Title": "Functional Geometry Guided Protein Sequence and Backbone Structure Co-Design", "Authors": ["Zhenqiao Song", "Yunlong Zhao", "Wenxian Shi", "Yang Yang", "Lei Li"], "Categories": "cs.LG"}, "abstract": "Proteins are macromolecules responsible for essential functions in almost all living organisms. Designing reasonable proteins with desired functions is crucial. A protein's sequence and structure are strongly correlated and they together determine its function. In this paper, we propose NAEPro, a model to jointly design Protein sequence and structure based on automatically detected functional sites. NAEPro is powered by an interleaving network of attention and equivariant layers, which can capture global correlation in a whole sequence and local influence from nearest amino acids in three dimensional (3D) space. Such an architecture facilitates effective yet economic message passing at two levels. We evaluate our model and several strong baselines on two protein datasets, $\\beta$-lactamase and myoglobin. Experimental results show that our model consistently achieves the highest amino acid recovery rate, TM-score, and the lowest RMSD among all competitors. These findings prove the capability of our model to design protein sequences and structures that closely resemble their natural counterparts. Furthermore, in-depth analysis further confirms our model's ability to generate highly effective proteins capable of binding to their target metallocofactors. We provide code, data and models in Github.", "url": "https://arxiv.org/abs/2310.04343"}, {"metadata": {"arXiv": "2310.04361", "Date": "Fri, 06 Oct 2023 16:34:51 ", "Title": "Exploiting Transformer Activation Sparsity with Dynamic Inference", "Authors": ["Miko{\\l}aj Pi\\'orczy\\'nski", "Filip Szatkowski", "Klaudia Ba{\\l}azy", "Bartosz W\\'ojcik"], "Categories": "cs.LG"}, "abstract": "Transformer models, despite their impressive performance, often face practical limitations due to their high computational requirements. At the same time, previous studies have revealed significant activation sparsity in these models, indicating the presence of redundant computations. In this paper, we propose Dynamic Sparsified Transformer Inference (DSTI), a method that radically reduces the inference cost of Transformer models by enforcing activation sparsity and subsequently transforming a dense model into its sparse Mixture of Experts (MoE) version. We demonstrate that it is possible to train small gating networks that successfully predict the relative contribution of each expert during inference. Furthermore, we introduce a mechanism that dynamically determines the number of executed experts individually for each token. DSTI can be applied to any Transformer-based architecture and has negligible impact on the accuracy. For the BERT-base classification model, we reduce inference cost by almost 60%.", "url": "https://arxiv.org/abs/2310.04361"}, {"metadata": {"arXiv": "2310.04363", "Date": "Fri, 06 Oct 2023 16:36:08 ", "Title": "Amortizing intractable inference in large language models", "Authors": ["Edward J. Hu", "Moksh Jain", "Eric Elmoznino", "Younesse Kaddar", "Guillaume Lajoie", "Yoshua Bengio", "Nikolay Malkin"], "Categories": "cs.LG cs.CL", "Comments": ["23 pages; code: https://github.com/GFNOrg/gfn-lm-tuning"]}, "abstract": "Autoregressive large language models (LLMs) compress knowledge from their training data through next-token conditional distributions. This limits tractable querying of this knowledge to start-to-end autoregressive sampling. However, many tasks of interest -- including sequence continuation, infilling, and other forms of constrained generation -- involve sampling from intractable posterior distributions. We address this limitation by using amortized Bayesian inference to sample from these intractable posteriors. Such amortization is algorithmically achieved by fine-tuning LLMs via diversity-seeking reinforcement learning algorithms: generative flow networks (GFlowNets). We empirically demonstrate that this distribution-matching paradigm of LLM fine-tuning can serve as an effective alternative to maximum-likelihood training and reward-maximizing policy optimization. As an important application, we interpret chain-of-thought reasoning as a latent variable modeling problem and demonstrate that our approach enables data-efficient adaptation of LLMs to tasks that require multi-step rationalization and tool use.", "url": "https://arxiv.org/abs/2310.04363"}, {"metadata": {"arXiv": "2310.04400", "Date": "Fri, 06 Oct 2023 17:50:38 ", "Title": "On the Embedding Collapse when Scaling up Recommendation Models", "Authors": ["Xingzhuo Guo", "Junwei Pan", "Ximei Wang", "Baixu Chen", "Jie Jiang", "Mingsheng Long"], "Categories": "cs.LG cs.IR"}, "abstract": "Recent advances in deep foundation models have led to a promising trend of developing large recommendation models to leverage vast amounts of available data. However, we experiment to scale up existing recommendation models and observe that the enlarged models do not improve satisfactorily. In this context, we investigate the embedding layers of enlarged models and identify a phenomenon of embedding collapse, which ultimately hinders scalability, wherein the embedding matrix tends to reside in a low-dimensional subspace. Through empirical and theoretical analysis, we demonstrate that the feature interaction module specific to recommendation models has a two-sided effect. On the one hand, the interaction restricts embedding learning when interacting with collapsed embeddings, exacerbating the collapse issue. On the other hand, feature interaction is crucial in mitigating the fitting of spurious features, thereby improving scalability. Based on this analysis, we propose a simple yet effective multi-embedding design incorporating embedding-set-specific interaction modules to capture diverse patterns and reduce collapse. Extensive experiments demonstrate that this proposed design provides consistent scalability for various recommendation models.", "url": "https://arxiv.org/abs/2310.04400"}, {"metadata": {"arXiv": "2310.04411", "Date": "Fri, 06 Oct 2023 17:57:44 ", "Title": "Understanding, Predicting and Better Resolving Q-Value Divergence in Offline-RL", "Authors": ["Yang Yue", "Rui Lu", "Bingyi Kang", "Shiji Song", "Gao Huang"], "Categories": "cs.LG", "Comments": ["31 pages", "20 figures"], "Journal-ref": "NeurIPS 2023"}, "abstract": "The divergence of the Q-value estimation has been a prominent issue in offline RL, where the agent has no access to real dynamics. Traditional beliefs attribute this instability to querying out-of-distribution actions when bootstrapping value targets. Though this issue can be alleviated with policy constraints or conservative Q estimation, a theoretical understanding of the underlying mechanism causing the divergence has been absent. In this work, we aim to thoroughly comprehend this mechanism and attain an improved solution. We first identify a fundamental pattern, self-excitation, as the primary cause of Q-value estimation divergence in offline RL. Then, we propose a novel Self-Excite Eigenvalue Measure (SEEM) metric based on Neural Tangent Kernel (NTK) to measure the evolving property of Q-network at training, which provides an intriguing explanation of the emergence of divergence. For the first time, our theory can reliably decide whether the training will diverge at an early stage, and even predict the order of the growth for the estimated Q-value, the model's norm, and the crashing step when an SGD optimizer is used. The experiments demonstrate perfect alignment with this theoretic analysis. Building on our insights, we propose to resolve divergence from a novel perspective, namely improving the model's architecture for better extrapolating behavior. Through extensive empirical studies, we identify LayerNorm as a good solution to effectively avoid divergence without introducing detrimental bias, leading to superior performance. Experimental results prove that it can still work in some most challenging settings, i.e. using only 1 transitions of the dataset, where all previous methods fail. Moreover, it can be easily plugged into modern offline RL methods and achieve SOTA results on many challenging tasks. We also give unique insights into its effectiveness.", "url": "https://arxiv.org/abs/2310.04411"}, {"metadata": {"arXiv": "2310.04415", "Date": "Fri, 06 Oct 2023 17:58:21 ", "Title": "Why Do We Need Weight Decay in Modern Deep Learning?", "Authors": ["Maksym Andriushchenko and Francesco D'Angelo and Aditya Varre and Nicolas Flammarion"], "Categories": "cs.LG"}, "abstract": "Weight decay is a broadly used technique for training state-of-the-art deep networks, including large language models. Despite its widespread usage, its role remains poorly understood. In this work, we highlight that the role of weight decay in modern deep learning is different from its regularization effect studied in classical learning theory. For overparameterized deep networks, we show how weight decay modifies the optimization dynamics enhancing the ever-present implicit regularization of SGD via the loss stabilization mechanism. In contrast, for underparameterized large language models trained with nearly online SGD, we describe how weight decay balances the bias-variance tradeoff in stochastic optimization leading to lower training loss. Moreover, we show that weight decay also prevents sudden loss divergences for bfloat16 mixed-precision training which is a crucial tool for LLM training. Overall, we present a unifying perspective from ResNets on vision tasks to LLMs: weight decay is never useful as an explicit regularizer but instead changes the training dynamics in a desirable way. Our code is available at https://github.com/tml-epfl/why-weight-decay.", "url": "https://arxiv.org/abs/2310.04415"}, {"metadata": {"arXiv": "2310.04418", "Date": "Fri, 06 Oct 2023 17:59:11 ", "Title": "Functional Interpolation for Relative Positions Improves Long Context Transformers", "Authors": ["Shanda Li", "Chong You", "Guru Guruganesh", "Joshua Ainslie", "Santiago Ontanon", "Manzil Zaheer", "Sumit Sanghai", "Yiming Yang", "Sanjiv Kumar", "Srinadh Bhojanapalli"], "Categories": "cs.LG"}, "abstract": "Preventing the performance decay of Transformers on inputs longer than those used for training has been an important challenge in extending the context length of these models. Though the Transformer architecture has fundamentally no limits on the input sequence lengths it can process, the choice of position encoding used during training can limit the performance of these models on longer inputs. We propose a novel functional relative position encoding with progressive interpolation, FIRE, to improve Transformer generalization to longer contexts. We theoretically prove that this can represent some of the popular relative position encodings, such as T5's RPE, Alibi, and Kerple. We next empirically show that FIRE models have better generalization to longer contexts on both zero-shot language modeling and long text benchmarks.", "url": "https://arxiv.org/abs/2310.04418"}, {"metadata": {"arXiv": "2310.04420", "Date": "Fri, 06 Oct 2023 17:59:53 ", "Title": "BrainSCUBA: Fine-Grained Natural Language Captions of Visual Cortex Selectivity", "Authors": ["Andrew F. Luo", "Margaret M. Henderson", "Michael J. Tarr", "Leila Wehbe"], "Categories": "cs.LG q-bio.NC"}, "abstract": "Understanding the functional organization of higher visual cortex is a central focus in neuroscience. Past studies have primarily mapped the visual and semantic selectivity of neural populations using hand-selected stimuli, which may potentially bias results towards pre-existing hypotheses of visual cortex functionality. Moving beyond conventional approaches, we introduce a data-driven method that generates natural language descriptions for images predicted to maximally activate individual voxels of interest. Our method -- Semantic Captioning Using Brain Alignments (\"BrainSCUBA\") -- builds upon the rich embedding space learned by a contrastive vision-language model and utilizes a pre-trained large language model to generate interpretable captions. We validate our method through fine-grained voxel-level captioning across higher-order visual regions. We further perform text-conditioned image synthesis with the captions, and show that our images are semantically coherent and yield high predicted activations. Finally, to demonstrate how our method enables scientific discovery, we perform exploratory investigations on the distribution of \"person\" representations in the brain, and discover fine-grained semantic selectivity in body-selective areas. Unlike earlier studies that decode text, our method derives voxel-wise captions of semantic selectivity. Our results show that BrainSCUBA is a promising means for understanding functional preferences in the brain, and provides motivation for further hypothesis-driven investigation of visual cortex.", "url": "https://arxiv.org/abs/2310.04420"}, {"metadata": {"arXiv": "2310.04349", "Date": "Fri, 06 Oct 2023 16:16:00 ", "Title": "Learning to Grasp: from Somewhere to Anywhere", "Authors": ["Fran\\c{c}ois H\\'el\\'enon", "Johann Huber", "Fa\\\"iz Ben Amar and St\\'ephane Doncieux"], "Categories": "cs.RO cs.LG"}, "abstract": "Robotic grasping is still a partially solved, multidisciplinary problem where data-driven techniques play an increasing role. The sparse nature of rewards make the automatic generation of grasping datasets challenging, especially for unconventional morphologies or highly actuated end-effectors. Most approaches for obtaining large-scale datasets rely on numerous human-provided demonstrations or heavily engineered solutions that do not scale well. Recent advances in Quality-Diversity (QD) methods have investigated how to learn object grasping at a specific pose with different robot morphologies. The present work introduces a pipeline for adapting QD-generated trajectories to new object poses. Using an RGB-D data stream, the vision pipeline first detects the targeted object, predicts its 6-DOF pose, and finally tracks it. An automatically generated reach-and-grasp trajectory can then be adapted by projecting it relatively to the object frame. Hundreds of trajectories have been deployed into the real world on several objects and with different robotic setups: a Franka Research 3 with a parallel gripper and a UR5 with a dexterous SIH Schunk hand. The transfer ratio obtained when applying transformation to the object pose matches the one obtained when the object pose matches the simulation, demonstrating the efficiency of the proposed approach.", "url": "https://arxiv.org/abs/2310.04349"}, {"metadata": {"arXiv": "2310.03780", "Date": "Thu, 05 Oct 2023 17:02:59 ", "Title": "Automating Human Tutor-Style Programming Feedback: Leveraging GPT-4 Tutor Model for Hint Generation and GPT-3.5 Student Model for Hint Validation", "Authors": ["Tung Phung", "Victor-Alexandru P\\u{a}durean", "Anjali Singh", "Christopher Brooks", "Jos\\'e Cambronero", "Sumit Gulwani", "Adish Singla", "Gustavo Soares"], "Categories": "cs.AI"}, "abstract": "Generative AI and large language models hold great promise in enhancing programming education by automatically generating individualized feedback for students. We investigate the role of generative AI models in providing human tutor-style programming hints to help students resolve errors in their buggy programs. Recent works have benchmarked state-of-the-art models for various feedback generation scenarios; however, their overall quality is still inferior to human tutors and not yet ready for real-world deployment. In this paper, we seek to push the limits of generative AI models toward providing high-quality programming hints and develop a novel technique, GPT4Hints-GPT3.5Val. As a first step, our technique leverages GPT-4 as a ``tutor'' model to generate hints -- it boosts the generative quality by using symbolic information of failing test cases and fixes in prompts. As a next step, our technique leverages GPT-3.5, a weaker model, as a ``student'' model to further validate the hint quality -- it performs an automatic quality validation by simulating the potential utility of providing this feedback. We show the efficacy of our technique via extensive evaluation using three real-world datasets of Python programs covering a variety of concepts ranging from basic algorithms to regular expressions and data analysis using pandas library.", "url": "https://arxiv.org/abs/2310.03780"}, {"metadata": {"arXiv": "2310.03965", "Date": "Fri, 06 Oct 2023 01:40:09 ", "Title": "Thought Propagation: An Analogical Approach to Complex Reasoning with Large Language Models", "Authors": ["Junchi Yu", "Ran He", "Rex Ying"], "Categories": "cs.AI cs.CL"}, "abstract": "Large Language Models (LLMs) have achieved remarkable success in reasoning tasks with the development of prompting methods. However, existing prompting approaches cannot reuse insights of solving similar problems and suffer from accumulated errors in multi-step reasoning, since they prompt LLMs to reason \\textit{from scratch}. To address these issues, we propose \\textbf{\\textit{Thought Propagation} (TP)}, which explores the analogous problems and leverages their solutions to enhance the complex reasoning ability of LLMs. These analogous problems are related to the input one, with reusable solutions and problem-solving strategies. Thus, it is promising to propagate insights of solving previous analogous problems to inspire new problem-solving. To achieve this, TP first prompts LLMs to propose and solve a set of analogous problems that are related to the input one. Then, TP reuses the results of analogous problems to directly yield a new solution or derive a knowledge-intensive plan for execution to amend the initial solution obtained from scratch. TP is compatible with existing prompting approaches, allowing plug-and-play generalization and enhancement in a wide range of tasks without much labor in task-specific prompt engineering. Experiments across three challenging tasks demonstrate TP enjoys a substantial improvement over the baselines by an average of 12\\% absolute increase in finding the optimal solutions in Shortest-path Reasoning, 13\\% improvement of human preference in Creative Writing, and 15\\% enhancement in the task completion rate of LLM-Agent Planning.", "url": "https://arxiv.org/abs/2310.03965"}, {"metadata": {"arXiv": "2310.04276", "Date": "Fri, 06 Oct 2023 14:21:59 ", "Title": "From task structures to world models: What do LLMs know?", "Authors": ["Ilker Yildirim", "L.A. Paul"], "Categories": "cs.AI q-bio.NC"}, "abstract": "In what sense does a large language model have knowledge? The answer to this question extends beyond the capabilities of a particular AI system, and challenges our assumptions about the nature of knowledge and intelligence. We answer by granting LLMs \"instrumental knowledge\"; knowledge defined by a certain set of abilities. We then ask how such knowledge is related to the more ordinary, \"worldly\" knowledge exhibited by human agents, and explore this in terms of the degree to which instrumental knowledge can be said to incorporate the structured world models of cognitive science. We discuss ways LLMs could recover degrees of worldly knowledge, and suggest such recovery will be governed by an implicit, resource-rational tradeoff between world models and task demands.", "url": "https://arxiv.org/abs/2310.04276"}, {"metadata": {"arXiv": "2310.03940", "Date": "Thu, 05 Oct 2023 23:09:19 ", "Title": "Hard View Selection for Contrastive Learning", "Authors": ["Fabio Ferreira", "Ivo Rapant", "Frank Hutter"], "Categories": "cs.CV cs.AI"}, "abstract": "Many Contrastive Learning (CL) methods train their models to be invariant to different \"views\" of an image input for which a good data augmentation pipeline is crucial. While considerable efforts were directed towards improving pre-text tasks, architectures, or robustness (e.g., Siamese networks or teacher-softmax centering), the majority of these methods remain strongly reliant on the random sampling of operations within the image augmentation pipeline, such as the random resized crop or color distortion operation. In this paper, we argue that the role of the view generation and its effect on performance has so far received insufficient attention. To address this, we propose an easy, learning-free, yet powerful Hard View Selection (HVS) strategy designed to extend the random view generation to expose the pretrained model to harder samples during CL training. It encompasses the following iterative steps: 1) randomly sample multiple views and create pairs of two views, 2) run forward passes for each view pair on the currently trained model, 3) adversarially select the pair yielding the worst loss, and 4) run the backward pass with the selected pair. In our empirical analysis we show that under the hood, HVS increases task difficulty by controlling the Intersection over Union of views during pretraining. With only 300-epoch pretraining, HVS is able to closely rival the 800-epoch DINO baseline which remains very favorable even when factoring in the slowdown induced by the additional forwards of HVS. Additionally, HVS consistently achieves accuracy improvements on ImageNet between 0.55% and 1.9% on linear evaluation and similar improvements on transfer tasks across multiple CL methods, such as DINO, SimSiam, and SimCLR.", "url": "https://arxiv.org/abs/2310.03940"}, {"metadata": {"arXiv": "2310.03967", "Date": "Fri, 06 Oct 2023 01:53:27 ", "Title": "Sub-token ViT Embedding via Stochastic Resonance Transformers", "Authors": ["Dong Lao", "Yangchao Wu", "Tian Yu Liu", "Alex Wong", "Stefano Soatto"], "Categories": "cs.CV cs.AI"}, "abstract": "We discover the presence of quantization artifacts in Vision Transformers (ViTs), which arise due to the image tokenization step inherent in these architectures. These artifacts result in coarsely quantized features, which negatively impact performance, especially on downstream dense prediction tasks. We present a zero-shot method to improve how pre-trained ViTs handle spatial quantization. In particular, we propose to ensemble the features obtained from perturbing input images via sub-token spatial translations, inspired by Stochastic Resonance, a method traditionally applied to climate dynamics and signal processing. We term our method ``Stochastic Resonance Transformer\" (SRT), which we show can effectively super-resolve features of pre-trained ViTs, capturing more of the local fine-grained structures that might otherwise be neglected as a result of tokenization. SRT can be applied at any layer, on any task, and does not require any fine-tuning. The advantage of the former is evident when applied to monocular depth prediction, where we show that ensembling model outputs are detrimental while applying SRT on intermediate ViT features outperforms the baseline models by an average of 4.7% and 14.9% on the RMSE and RMSE-log metrics across three different architectures. When applied to semi-supervised video object segmentation, SRT also improves over the baseline models uniformly across all metrics, and by an average of 2.4% in F&J score. We further show that these quantization artifacts can be attenuated to some extent via self-distillation. On the unsupervised salient region segmentation, SRT improves upon the base model by an average of 2.1% on the maxF metric. Finally, despite operating purely on pixel-level features, SRT generalizes to non-dense prediction tasks such as image retrieval and object discovery, yielding consistent improvements of up to 2.6% and 1.0% respectively.", "url": "https://arxiv.org/abs/2310.03967"}, {"metadata": {"arXiv": "2310.04010", "Date": "Fri, 06 Oct 2023 04:40:48 ", "Title": "Excision and Recovery: Enhancing Surface Anomaly Detection with Attention-based Single Deterministic Masking", "Authors": ["YeongHyeon Park", "Sungho Kang", "Myung Jin Kim", "Yeonho Lee", "Juneho Yi"], "Categories": "cs.CV cs.AI eess.IV", "Comments": ["5 pages", "3 figures", "4 tables"]}, "abstract": "Anomaly detection (AD) in surface inspection is an essential yet challenging task in manufacturing due to the quantity imbalance problem of scarce abnormal data. To overcome the above, a reconstruction encoder-decoder (ED) such as autoencoder or U-Net which is trained with only anomaly-free samples is widely adopted, in the hope that unseen abnormals should yield a larger reconstruction error than normal. Over the past years, researches on self-supervised reconstruction-by-inpainting have been reported. They mask out suspected defective regions for inpainting in order to make them invisible to the reconstruction ED to deliberately cause inaccurate reconstruction for abnormals. However, their limitation is multiple random masking to cover the whole input image due to defective regions not being known in advance. We propose a novel reconstruction-by-inpainting method dubbed Excision and Recovery (EAR) that features single deterministic masking. For this, we exploit a pre-trained spatial attention model to predict potential suspected defective regions that should be masked out. We also employ a variant of U-Net as our ED to further limit the reconstruction ability of the U-Net model for abnormals, in which skip connections of different layers can be selectively disabled. In the training phase, all the skip connections are switched on to fully take the benefits from the U-Net architecture. In contrast, for inferencing, we only keep deeper skip connections with shallower connections off. We validate the effectiveness of EAR using an MNIST pre-trained attention for a commonly used surface AD dataset, KolektorSDD2. The experimental results show that EAR achieves both better AD performance and higher throughput than state-of-the-art methods. We expect that the proposed EAR model can be widely adopted as training and inference strategies for AD purposes.", "url": "https://arxiv.org/abs/2310.04010"}, {"metadata": {"arXiv": "2310.04081", "Date": "Fri, 06 Oct 2023 08:22:24 ", "Title": "A Deeply Supervised Semantic Segmentation Method Based on GAN", "Authors": ["Wei Zhao and Qiyu Wei and Zeng Zeng"], "Categories": "cs.CV cs.AI cs.CE", "Comments": ["6 pages", "2 figures", "ITSC conference"]}, "abstract": "In recent years, the field of intelligent transportation has witnessed rapid advancements, driven by the increasing demand for automation and efficiency in transportation systems. Traffic safety, one of the tasks integral to intelligent transport systems, requires accurately identifying and locating various road elements, such as road cracks, lanes, and traffic signs. Semantic segmentation plays a pivotal role in achieving this task, as it enables the partition of images into meaningful regions with accurate boundaries. In this study, we propose an improved semantic segmentation model that combines the strengths of adversarial learning with state-of-the-art semantic segmentation techniques. The proposed model integrates a generative adversarial network (GAN) framework into the traditional semantic segmentation model, enhancing the model's performance in capturing complex and subtle features in transportation images. The effectiveness of our approach is demonstrated by a significant boost in performance on the road crack dataset compared to the existing methods, \\textit{i.e.,} SEGAN. This improvement can be attributed to the synergistic effect of adversarial learning and semantic segmentation, which leads to a more refined and accurate representation of road structures and conditions. The enhanced model not only contributes to better detection of road cracks but also to a wide range of applications in intelligent transportation, such as traffic sign recognition, vehicle detection, and lane segmentation.", "url": "https://arxiv.org/abs/2310.04081"}, {"metadata": {"arXiv": "2310.04148", "Date": "Fri, 06 Oct 2023 10:40:46 ", "Title": "Self-Supervised Neuron Segmentation with Multi-Agent Reinforcement Learning", "Authors": ["Yinda Chen", "Wei Huang", "Shenglong Zhou", "Qi Chen", "Zhiwei Xiong"], "Categories": "cs.CV cs.AI", "Comments": ["IJCAI 23 main track paper"], "DOI": "10.24963/ijcai.2023/68"}, "abstract": "The performance of existing supervised neuron segmentation methods is highly dependent on the number of accurate annotations, especially when applied to large scale electron microscopy (EM) data. By extracting semantic information from unlabeled data, self-supervised methods can improve the performance of downstream tasks, among which the mask image model (MIM) has been widely used due to its simplicity and effectiveness in recovering original information from masked images. However, due to the high degree of structural locality in EM images, as well as the existence of considerable noise, many voxels contain little discriminative information, making MIM pretraining inefficient on the neuron segmentation task. To overcome this challenge, we propose a decision-based MIM that utilizes reinforcement learning (RL) to automatically search for optimal image masking ratio and masking strategy. Due to the vast exploration space, using single-agent RL for voxel prediction is impractical. Therefore, we treat each input patch as an agent with a shared behavior policy, allowing for multi-agent collaboration. Furthermore, this multi-agent model can capture dependencies between voxels, which is beneficial for the downstream segmentation task. Experiments conducted on representative EM datasets demonstrate that our approach has a significant advantage over alternative self-supervised methods on the task of neuron segmentation. Code is available at \\url{https://github.com/ydchen0806/dbMiM}.", "url": "https://arxiv.org/abs/2310.04148"}, {"metadata": {"arXiv": "2310.04306", "Date": "Fri, 06 Oct 2023 15:05:41 ", "Title": "Towards A Robust Group-level Emotion Recognition via Uncertainty-Aware Learning", "Authors": ["Qing Zhu", "Qirong Mao", "Jialin Zhang", "Xiaohua Huang", "Wenming Zheng"], "Categories": "cs.CV cs.AI", "Comments": ["11 pages,3 figures"]}, "abstract": "Group-level emotion recognition (GER) is an inseparable part of human behavior analysis, aiming to recognize an overall emotion in a multi-person scene. However, the existing methods are devoted to combing diverse emotion cues while ignoring the inherent uncertainties under unconstrained environments, such as congestion and occlusion occurring within a group. Additionally, since only group-level labels are available, inconsistent emotion predictions among individuals in one group can confuse the network. In this paper, we propose an uncertainty-aware learning (UAL) method to extract more robust representations for GER. By explicitly modeling the uncertainty of each individual, we utilize stochastic embedding drawn from a Gaussian distribution instead of deterministic point embedding. This representation captures the probabilities of different emotions and generates diverse predictions through this stochasticity during the inference stage. Furthermore, uncertainty-sensitive scores are adaptively assigned as the fusion weights of individuals' face within each group. Moreover, we develop an image enhancement module to enhance the model's robustness against severe noise. The overall three-branch model, encompassing face, object, and scene component, is guided by a proportional-weighted fusion strategy and integrates the proposed uncertainty-aware method to produce the final group-level output. Experimental results demonstrate the effectiveness and generalization ability of our method across three widely used databases.", "url": "https://arxiv.org/abs/2310.04306"}, {"metadata": {"arXiv": "2310.04102", "Date": "Fri, 06 Oct 2023 09:06:44 ", "Title": "Nash Welfare and Facility Location", "Authors": ["Alexander Lam", "Haris Aziz", "Toby Walsh"], "Categories": "cs.GT cs.AI cs.MA"}, "abstract": "We consider the problem of locating a facility to serve a set of agents located along a line. The Nash welfare objective function, defined as the product of the agents' utilities, is known to provide a compromise between fairness and efficiency in resource allocation problems. We apply this welfare notion to the facility location problem, converting individual costs to utilities and analyzing the facility placement that maximizes the Nash welfare. We give a polynomial-time approximation algorithm to compute this facility location, and prove results suggesting that it achieves a good balance of fairness and efficiency. Finally, we take a mechanism design perspective and propose a strategy-proof mechanism with a bounded approximation ratio for Nash welfare.", "url": "https://arxiv.org/abs/2310.04102"}, {"metadata": {"arXiv": "2310.04232", "Date": "Fri, 06 Oct 2023 13:17:46 ", "Title": "The WayHome: Long-term Motion Prediction on Dynamically Scaled", "Authors": ["Kay Scheerer", "Thomas Michalke", "Juergen Mathes"], "Categories": "cs.RO cs.AI"}, "abstract": "One of the key challenges for autonomous vehicles is the ability to accurately predict the motion of other objects in the surrounding environment, such as pedestrians or other vehicles. In this contribution, a novel motion forecasting approach for autonomous vehicles is developed, inspired by the work of Gilles et al. [1]. We predict multiple heatmaps with a neuralnetwork-based model for every traffic participant in the vicinity of the autonomous vehicle; with one heatmap per timestep. The heatmaps are used as input to a novel sampling algorithm that extracts coordinates corresponding to the most likely future positions. We experiment with different encoders and decoders, as well as a comparison of two loss functions. Additionally, a new grid-scaling technique is introduced, showing further improved performance. Overall, our approach improves stateof-the-art miss rate performance for the function-relevant prediction interval of 3 seconds while being competitive in longer prediction intervals (up to eight seconds). The evaluation is done on the public 2022 Waymo motion challenge.", "url": "https://arxiv.org/abs/2310.04232"}, {"metadata": {"arXiv": "2310.04266", "Date": "Fri, 06 Oct 2023 14:11:35 ", "Title": "DRIFT: Deep Reinforcement Learning for Intelligent Floating Platforms Trajectories", "Authors": ["Matteo El-Hariry", "Antoine Richard", "Vivek Muralidharan", "Baris Can Yalcin", "Matthieu Geist", "Miguel Olivares-Mendez"], "Categories": "cs.RO cs.AI"}, "abstract": "This investigation introduces a novel deep reinforcement learning-based suite to control floating platforms in both simulated and real-world environments. Floating platforms serve as versatile test-beds to emulate microgravity environments on Earth. Our approach addresses the system and environmental uncertainties in controlling such platforms by training policies capable of precise maneuvers amid dynamic and unpredictable conditions. Leveraging state-of-the-art deep reinforcement learning techniques, our suite achieves robustness, adaptability, and good transferability from simulation to reality. Our Deep Reinforcement Learning (DRL) framework provides advantages such as fast training times, large-scale testing capabilities, rich visualization options, and ROS bindings for integration with real-world robotic systems. Beyond policy development, our suite provides a comprehensive platform for researchers, offering open-access at https://github.com/elharirymatteo/RANS/tree/ICRA24.", "url": "https://arxiv.org/abs/2310.04266"}, {"metadata": {"arXiv": "2310.04288", "Date": "Fri, 06 Oct 2023 14:45:57 ", "Title": "Searching for Optimal Runtime Assurance via Reachability and Reinforcement Learning", "Authors": ["Kristina Miller", "Christopher K. Zeitler", "William Shen", "Kerianne Hobbs", "Sayan Mitra", "John Schierman", "Mahesh Viswanathan"], "Categories": "eess.SY cs.AI cs.FL cs.SY"}, "abstract": "A runtime assurance system (RTA) for a given plant enables the exercise of an untrusted or experimental controller while assuring safety with a backup (or safety) controller. The relevant computational design problem is to create a logic that assures safety by switching to the safety controller as needed, while maximizing some performance criteria, such as the utilization of the untrusted controller. Existing RTA design strategies are well-known to be overly conservative and, in principle, can lead to safety violations. In this paper, we formulate the optimal RTA design problem and present a new approach for solving it. Our approach relies on reward shaping and reinforcement learning. It can guarantee safety and leverage machine learning technologies for scalability. We have implemented this algorithm and present experimental results comparing our approach with state-of-the-art reachability and simulation-based RTA approaches in a number of scenarios using aircraft models in 3D space with complex safety requirements. Our approach can guarantee safety while increasing utilization of the experimental controller over existing approaches.", "url": "https://arxiv.org/abs/2310.04288"}, {"metadata": {"arXiv": "2310.03779", "Date": "Thu, 05 Oct 2023 16:14:46 ", "Title": "HandMeThat: Human-Robot Communication in Physical and Social Environments", "Authors": ["Yanming Wan", "Jiayuan Mao", "Joshua B. Tenenbaum"], "Categories": "cs.AI cs.CL cs.LG cs.RO", "Comments": ["NeurIPS 2022 (Dataset and Benchmark Track). First two authors contributed equally. Project page: http://handmethat.csail.mit.edu/"]}, "abstract": "We introduce HandMeThat, a benchmark for a holistic evaluation of instruction understanding and following in physical and social environments. While previous datasets primarily focused on language grounding and planning, HandMeThat considers the resolution of human instructions with ambiguities based on the physical (object states and relations) and social (human actions and goals) information. HandMeThat contains 10,000 episodes of human-robot interactions. In each episode, the robot first observes a trajectory of human actions towards her internal goal. Next, the robot receives a human instruction and should take actions to accomplish the subgoal set through the instruction. In this paper, we present a textual interface for our benchmark, where the robot interacts with a virtual environment through textual commands. We evaluate several baseline models on HandMeThat, and show that both offline and online reinforcement learning algorithms perform poorly on HandMeThat, suggesting significant room for future work on physical and social human-robot communications and interactions.", "url": "https://arxiv.org/abs/2310.03779"}, {"metadata": {"arXiv": "2310.04406", "Date": "Fri, 06 Oct 2023 17:55:11 ", "Title": "Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models", "Authors": ["Andy Zhou", "Kai Yan", "Michal Shlapentokh-Rothman", "Haohan Wang", "Yu-Xiong Wang"], "Categories": "cs.AI cs.CL cs.CV cs.LG", "Comments": ["Website and code can be found at https://andyz245.github.io/LanguageAgentTreeSearch"]}, "abstract": "While large language models (LLMs) have demonstrated impressive performance on a range of decision-making tasks, they rely on simple acting processes and fall short of broad deployment as autonomous agents. We introduce LATS (Language Agent Tree Search), a general framework that synergizes the capabilities of LLMs in planning, acting, and reasoning. Drawing inspiration from Monte Carlo tree search in model-based reinforcement learning, LATS employs LLMs as agents, value functions, and optimizers, repurposing their latent strengths for enhanced decision-making. What is crucial in this method is the use of an environment for external feedback, which offers a more deliberate and adaptive problem-solving mechanism that moves beyond the limitations of existing techniques. Our experimental evaluation across diverse domains, such as programming, HotPotQA, and WebShop, illustrates the applicability of LATS for both reasoning and acting. In particular, LATS achieves 94.4\\% for programming on HumanEval with GPT-4 and an average score of 75.9 for web browsing on WebShop with GPT-3.5, demonstrating the effectiveness and generality of our method.", "url": "https://arxiv.org/abs/2310.04406"}, {"metadata": {"arXiv": "2310.03981", "Date": "Fri, 06 Oct 2023 02:35:31 ", "Title": "CUPre: Cross-domain Unsupervised Pre-training for Few-Shot Cell Segmentation", "Authors": ["Weibin Liao and Xuhong Li and Qingzhong Wang and Yanwu Xu and Zhaozheng Yin and Haoyi Xiong"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "While pre-training on object detection tasks, such as Common Objects in Contexts (COCO) [1], could significantly boost the performance of cell segmentation, it still consumes on massive fine-annotated cell images [2] with bounding boxes, masks, and cell types for every cell in every image, to fine-tune the pre-trained model. To lower the cost of annotation, this work considers the problem of pre-training DNN models for few-shot cell segmentation, where massive unlabeled cell images are available but only a small proportion is annotated. Hereby, we propose Cross-domain Unsupervised Pre-training, namely CUPre, transferring the capability of object detection and instance segmentation for common visual objects (learned from COCO) to the visual domain of cells using unlabeled images. Given a standard COCO pre-trained network with backbone, neck, and head modules, CUPre adopts an alternate multi-task pre-training (AMT2) procedure with two sub-tasks -- in every iteration of pre-training, AMT2 first trains the backbone with cell images from multiple cell datasets via unsupervised momentum contrastive learning (MoCo) [3], and then trains the whole model with vanilla COCO datasets via instance segmentation. After pre-training, CUPre fine-tunes the whole model on the cell segmentation task using a few annotated images. We carry out extensive experiments to evaluate CUPre using LIVECell [2] and BBBC038 [4] datasets in few-shot instance segmentation settings. The experiment shows that CUPre can outperform existing pre-training methods, achieving the highest average precision (AP) for few-shot cell segmentation and detection.", "url": "https://arxiv.org/abs/2310.03981"}, {"metadata": {"arXiv": "2310.04285", "Date": "Fri, 06 Oct 2023 14:37:22 ", "Title": "Assessing Robustness via Score-Based Adversarial Image Generation", "Authors": ["Marcel Kollovieh", "Lukas Gosch", "Yan Scholten", "Marten Lienen", "Stephan G\\\"unnemann"], "Categories": "cs.CV cs.AI cs.LG stat.ML"}, "abstract": "Most adversarial attacks and defenses focus on perturbations within small $\\ell_p$-norm constraints. However, $\\ell_p$ threat models cannot capture all relevant semantic-preserving perturbations, and hence, the scope of robustness evaluations is limited. In this work, we introduce Score-Based Adversarial Generation (ScoreAG), a novel framework that leverages the advancements in score-based generative models to generate adversarial examples beyond $\\ell_p$-norm constraints, so-called unrestricted adversarial examples, overcoming their limitations. Unlike traditional methods, ScoreAG maintains the core semantics of images while generating realistic adversarial examples, either by transforming existing images or synthesizing new ones entirely from scratch. We further exploit the generative capability of ScoreAG to purify images, empirically enhancing the robustness of classifiers. Our extensive empirical evaluation demonstrates that ScoreAG matches the performance of state-of-the-art attacks and defenses across multiple benchmarks. This work highlights the importance of investigating adversarial examples bounded by semantics rather than $\\ell_p$-norm constraints. ScoreAG represents an important step towards more encompassing robustness assessments.", "url": "https://arxiv.org/abs/2310.04285"}, {"metadata": {"arXiv": "2310.03770", "Date": "Wed, 04 Oct 2023 23:50:14 ", "Title": "Progressive reduced order modeling: empowering data-driven modeling with selective knowledge transfer", "Authors": ["Teeratorn Kadeethum", "Daniel O'Malley", "Youngsoo Choi", "Hari S. Viswanathan", "Hongkyu Yoon"], "Categories": "cs.LG cs.AI cs.CE"}, "abstract": "Data-driven modeling can suffer from a constant demand for data, leading to reduced accuracy and impractical for engineering applications due to the high cost and scarcity of information. To address this challenge, we propose a progressive reduced order modeling framework that minimizes data cravings and enhances data-driven modeling's practicality. Our approach selectively transfers knowledge from previously trained models through gates, similar to how humans selectively use valuable knowledge while ignoring unuseful information. By filtering relevant information from previous models, we can create a surrogate model with minimal turnaround time and a smaller training set that can still achieve high accuracy. We have tested our framework in several cases, including transport in porous media, gravity-driven flow, and finite deformation in hyperelastic materials. Our results illustrate that retaining information from previous models and utilizing a valuable portion of that knowledge can significantly improve the accuracy of the current model. We have demonstrated the importance of progressive knowledge transfer and its impact on model accuracy with reduced training samples. For instance, our framework with four parent models outperforms the no-parent counterpart trained on data nine times larger. Our research unlocks data-driven modeling's potential for practical engineering applications by mitigating the data scarcity issue. Our proposed framework is a significant step toward more efficient and cost-effective data-driven modeling, fostering advancements across various fields.", "url": "https://arxiv.org/abs/2310.03770"}, {"metadata": {"arXiv": "2310.03778", "Date": "Thu, 05 Oct 2023 13:57:05 ", "Title": "Lightweight Boosting Models for User Response Prediction Using Adversarial Validation", "Authors": ["Hyeonwoo Kim and Wonsung Lee"], "Categories": "cs.LG cs.AI", "Comments": ["7 pages", "4 figures", "ACM RecSys 2023 Challenge Workshop accepted paper"]}, "abstract": "The ACM RecSys Challenge 2023, organized by ShareChat, aims to predict the probability of the app being installed. This paper describes the lightweight solution to this challenge. We formulate the task as a user response prediction task. For rapid prototyping for the task, we propose a lightweight solution including the following steps: 1) using adversarial validation, we effectively eliminate uninformative features from a dataset; 2) to address noisy continuous features and categorical features with a large number of unique values, we employ feature engineering techniques.; 3) we leverage Gradient Boosted Decision Trees (GBDT) for their exceptional performance and scalability. The experiments show that a single LightGBM model, without additional ensembling, performs quite well. Our team achieved ninth place in the challenge with the final leaderboard score of 6.059065. Code for our approach can be found here: https://github.com/choco9966/recsys-challenge-2023.", "url": "https://arxiv.org/abs/2310.03778"}, {"metadata": {"arXiv": "2310.03823", "Date": "Thu, 05 Oct 2023 18:17:26 ", "Title": "ECAvg: An Edge-Cloud Collaborative Learning Approach using Averaged Weights", "Authors": ["Atah Nuh Mih", "Hung Cao", "Asfia Kawnine", "Monica Wachowicz"], "Categories": "cs.LG cs.AI", "Comments": ["Key words: edge-cloud collaboration", "averaging weights", "Edge AI", "edge computing", "cloud computing", "transfer learning"]}, "abstract": "The use of edge devices together with cloud provides a collaborative relationship between both classes of devices where one complements the shortcomings of the other. Resource-constraint edge devices can benefit from the abundant computing power provided by servers by offloading computationally intensive tasks to the server. Meanwhile, edge devices can leverage their close proximity to the data source to perform less computationally intensive tasks on the data. In this paper, we propose a collaborative edge-cloud paradigm called ECAvg in which edge devices pre-train local models on their respective datasets and transfer the models to the server for fine-tuning. The server averages the pre-trained weights into a global model, which is fine-tuned on the combined data from the various edge devices. The local (edge) models are then updated with the weights of the global (server) model. We implement a CIFAR-10 classification task using MobileNetV2, a CIFAR-100 classification task using ResNet50, and an MNIST classification using a neural network with a single hidden layer. We observed performance improvement in the CIFAR-10 and CIFAR-100 classification tasks using our approach, where performance improved on the server model with averaged weights and the edge models had a better performance after model update. On the MNIST classification, averaging weights resulted in a drop in performance on both the server and edge models due to negative transfer learning. From the experiment results, we conclude that our approach is successful when implemented on deep neural networks such as MobileNetV2 and ResNet50 instead of simple neural networks.", "url": "https://arxiv.org/abs/2310.03823"}, {"metadata": {"arXiv": "2310.03840", "Date": "Thu, 05 Oct 2023 18:51:33 ", "Title": "Contextualized Structural Self-supervised Learning for Ontology Matching", "Authors": ["Zhu Wang"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "Ontology matching (OM) entails the identification of semantic relationships between concepts within two or more knowledge graphs (KGs) and serves as a critical step in integrating KGs from various sources. Recent advancements in deep OM models have harnessed the power of transformer-based language models and the advantages of knowledge graph embedding. Nevertheless, these OM models still face persistent challenges, such as a lack of reference alignments, runtime latency, and unexplored different graph structures within an end-to-end framework. In this study, we introduce a novel self-supervised learning OM framework with input ontologies, called LaKERMap. This framework capitalizes on the contextual and structural information of concepts by integrating implicit knowledge into transformers. Specifically, we aim to capture multiple structural contexts, encompassing both local and global interactions, by employing distinct training objectives. To assess our methods, we utilize the Bio-ML datasets and tasks. The findings from our innovative approach reveal that LaKERMap surpasses state-of-the-art systems in terms of alignment quality and inference time. Our models and codes are available here: https://github.com/ellenzhuwang/lakermap.", "url": "https://arxiv.org/abs/2310.03840"}, {"metadata": {"arXiv": "2310.03882", "Date": "Thu, 05 Oct 2023 20:31:37 ", "Title": "Small batch deep reinforcement learning", "Authors": ["Johan Obando-Ceron", "Marc G. Bellemare", "Pablo Samuel Castro"], "Categories": "cs.LG cs.AI", "Comments": ["Published at NeurIPS 2023"]}, "abstract": "In value-based deep reinforcement learning with replay memories, the batch size parameter specifies how many transitions to sample for each gradient update. Although critical to the learning process, this value is typically not adjusted when proposing new algorithms. In this work we present a broad empirical study that suggests {\\em reducing} the batch size can result in a number of significant performance gains; this is surprising, as the general tendency when training neural networks is towards larger batch sizes for improved performance. We complement our experimental findings with a set of empirical analyses towards better understanding this phenomenon.", "url": "https://arxiv.org/abs/2310.03882"}, {"metadata": {"arXiv": "2310.03890", "Date": "Thu, 05 Oct 2023 20:49:48 ", "Title": "Accelerated Neural Network Training with Rooted Logistic Objectives", "Authors": ["Zhu Wang", "Praveen Raj Veluswami", "Harsh Mishra", "Sathya N. Ravi"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "Many neural networks deployed in the real world scenarios are trained using cross entropy based loss functions. From the optimization perspective, it is known that the behavior of first order methods such as gradient descent crucially depend on the separability of datasets. In fact, even in the most simplest case of binary classification, the rate of convergence depends on two factors: (1) condition number of data matrix, and (2) separability of the dataset. With no further pre-processing techniques such as over-parametrization, data augmentation etc., separability is an intrinsic quantity of the data distribution under consideration. We focus on the landscape design of the logistic function and derive a novel sequence of {\\em strictly} convex functions that are at least as strict as logistic loss. The minimizers of these functions coincide with those of the minimum norm solution wherever possible. The strict convexity of the derived function can be extended to finetune state-of-the-art models and applications. In empirical experimental analysis, we apply our proposed rooted logistic objective to multiple deep models, e.g., fully-connected neural networks and transformers, on various of classification benchmarks. Our results illustrate that training with rooted loss function is converged faster and gains performance improvements. Furthermore, we illustrate applications of our novel rooted loss function in generative modeling based downstream applications, such as finetuning StyleGAN model with the rooted loss. The code implementing our losses and models can be found here for open source software development purposes: https://anonymous.4open.science/r/rooted_loss.", "url": "https://arxiv.org/abs/2310.03890"}, {"metadata": {"arXiv": "2310.03912", "Date": "Thu, 05 Oct 2023 21:37:20 ", "Title": "RTDK-BO: High Dimensional Bayesian Optimization with Reinforced Transformer Deep kernels", "Authors": ["Alexander Shmakov", "Avisek Naug", "Vineet Gundecha", "Sahand Ghorbanpour", "Ricardo Luna Gutierrez", "Ashwin Ramesh Babu", "Antonio Guillen and Soumyendu Sarkar"], "Categories": "cs.LG cs.AI", "Comments": ["2023 IEEE 19th International Conference on Automation Science and Engineering (CASE)"], "DOI": "10.1109/CASE56687.2023.10260520"}, "abstract": "Bayesian Optimization (BO), guided by Gaussian process (GP) surrogates, has proven to be an invaluable technique for efficient, high-dimensional, black-box optimization, a critical problem inherent to many applications such as industrial design and scientific computing. Recent contributions have introduced reinforcement learning (RL) to improve the optimization performance on both single function optimization and \\textit{few-shot} multi-objective optimization. However, even few-shot techniques fail to exploit similarities shared between closely related objectives. In this paper, we combine recent developments in Deep Kernel Learning (DKL) and attention-based Transformer models to improve the modeling powers of GP surrogates with meta-learning. We propose a novel method for improving meta-learning BO surrogates by incorporating attention mechanisms into DKL, empowering the surrogates to adapt to contextual information gathered during the BO process. We combine this Transformer Deep Kernel with a learned acquisition function trained with continuous Soft Actor-Critic Reinforcement Learning to aid in exploration. This Reinforced Transformer Deep Kernel (RTDK-BO) approach yields state-of-the-art results in continuous high-dimensional optimization problems.", "url": "https://arxiv.org/abs/2310.03912"}, {"metadata": {"arXiv": "2310.03916", "Date": "Thu, 05 Oct 2023 21:44:50 ", "Title": "Toward a Foundation Model for Time Series Data", "Authors": ["Chin-Chia Michael Yeh", "Xin Dai", "Huiyuan Chen", "Yan Zheng", "Yujie Fan", "Audrey Der", "Vivian Lai", "Zhongfang Zhuang", "Junpeng Wang", "Liang Wang", "Wei Zhang"], "Categories": "cs.LG cs.AI"}, "abstract": "A foundation model is a machine learning model trained on a large and diverse set of data, typically using self-supervised learning-based pre-training techniques, that can be adapted to various downstream tasks. However, current research on time series pre-training has mostly focused on models pre-trained solely on data from a single domain, resulting in a lack of knowledge about other types of time series. However, current research on time series pre-training has predominantly focused on models trained exclusively on data from a single domain. As a result, these models possess domain-specific knowledge that may not be easily transferable to time series from other domains. In this paper, we aim to develop an effective time series foundation model by leveraging unlabeled samples from multiple domains. To achieve this, we repurposed the publicly available UCR Archive and evaluated four existing self-supervised learning-based pre-training methods, along with a novel method, on the datasets. We tested these methods using four popular neural network architectures for time series to understand how the pre-training methods interact with different network designs. Our experimental results show that pre-training improves downstream classification tasks by enhancing the convergence of the fine-tuning process. Furthermore, we found that the proposed pre-training method, when combined with the Transformer model, outperforms the alternatives.", "url": "https://arxiv.org/abs/2310.03916"}, {"metadata": {"arXiv": "2310.03925", "Date": "Thu, 05 Oct 2023 22:00:17 ", "Title": "Multitask Learning for Time Series Data\\\\with 2D Convolution", "Authors": ["Chin-Chia Michael Yeh", "Xin Dai", "Yan Zheng", "Junpeng Wang", "Huiyuan Chen", "Yujie Fan", "Audrey Der", "Zhongfang Zhuang", "Liang Wang", "Wei Zhang"], "Categories": "cs.LG cs.AI"}, "abstract": "Multitask learning (MTL) aims to develop a unified model that can handle a set of closely related tasks simultaneously. By optimizing the model across multiple tasks, MTL generally surpasses its non-MTL counterparts in terms of generalizability. Although MTL has been extensively researched in various domains such as computer vision, natural language processing, and recommendation systems, its application to time series data has received limited attention. In this paper, we investigate the application of MTL to the time series classification (TSC) problem. However, when we integrate the state-of-the-art 1D convolution-based TSC model with MTL, the performance of the TSC model actually deteriorates. By comparing the 1D convolution-based models with the Dynamic Time Warping (DTW) distance function, it appears that the underwhelming results stem from the limited expressive power of the 1D convolutional layers. To overcome this challenge, we propose a novel design for a 2D convolution-based model that enhances the model's expressiveness. Leveraging this advantage, our proposed method outperforms competing approaches on both the UCR Archive and an industrial transaction TSC dataset.", "url": "https://arxiv.org/abs/2310.03925"}, {"metadata": {"arXiv": "2310.03964", "Date": "Fri, 06 Oct 2023 01:33:47 ", "Title": "A Learnable Counter-condition Analysis Framework for Functional Connectivity-based Neurological Disorder Diagnosis", "Authors": ["Eunsong Kang", "Da-woon Heo", "Jiwon Lee", "Heung-Il Suk"], "Categories": "cs.LG cs.AI q-bio.NC"}, "abstract": "To understand the biological characteristics of neurological disorders with functional connectivity (FC), recent studies have widely utilized deep learning-based models to identify the disease and conducted post-hoc analyses via explainable models to discover disease-related biomarkers. Most existing frameworks consist of three stages, namely, feature selection, feature extraction for classification, and analysis, where each stage is implemented separately. However, if the results at each stage lack reliability, it can cause misdiagnosis and incorrect analysis in afterward stages. In this study, we propose a novel unified framework that systemically integrates diagnoses (i.e., feature selection and feature extraction) and explanations. Notably, we devised an adaptive attention network as a feature selection approach to identify individual-specific disease-related connections. We also propose a functional network relational encoder that summarizes the global topological properties of FC by learning the inter-network relations without pre-defined edges between functional networks. Last but not least, our framework provides a novel explanatory power for neuroscientific interpretation, also termed counter-condition analysis. We simulated the FC that reverses the diagnostic information (i.e., counter-condition FC): converting a normal brain to be abnormal and vice versa. We validated the effectiveness of our framework by using two large resting-state functional magnetic resonance imaging (fMRI) datasets, Autism Brain Imaging Data Exchange (ABIDE) and REST-meta-MDD, and demonstrated that our framework outperforms other competing methods for disease identification. Furthermore, we analyzed the disease-related neurological patterns based on counter-condition analysis.", "url": "https://arxiv.org/abs/2310.03964"}, {"metadata": {"arXiv": "2310.03977", "Date": "Fri, 06 Oct 2023 02:22:49 ", "Title": "Perfect Alignment May be Poisonous to Graph Contrastive Learning", "Authors": ["Jingyu Liu", "Huayi Tang", "Yong Liu"], "Categories": "cs.LG cs.AI"}, "abstract": "Graph Contrastive Learning (GCL) aims to learn node representations by aligning positive pairs and separating negative ones. However, limited research has been conducted on the inner law behind specific augmentations used in graph-based learning. What kind of augmentation will help downstream performance, how does contrastive learning actually influence downstream tasks, and why the magnitude of augmentation matters? This paper seeks to address these questions by establishing a connection between augmentation and downstream performance, as well as by investigating the generalization of contrastive learning. Our findings reveal that GCL contributes to downstream tasks mainly by separating different classes rather than gathering nodes of the same class. So perfect alignment and augmentation overlap which draw all intra-class samples the same can not explain the success of contrastive learning. Then in order to comprehend how augmentation aids the contrastive learning process, we conduct further investigations into its generalization, finding that perfect alignment that draw positive pair the same could help contrastive loss but is poisonous to generalization, on the contrary, imperfect alignment enhances the model's generalization ability. We analyse the result by information theory and graph spectrum theory respectively, and propose two simple but effective methods to verify the theories. The two methods could be easily applied to various GCL algorithms and extensive experiments are conducted to prove its effectiveness.", "url": "https://arxiv.org/abs/2310.03977"}, {"metadata": {"arXiv": "2310.04041", "Date": "Fri, 06 Oct 2023 06:29:06 ", "Title": "Observation-Guided Diffusion Probabilistic Models", "Authors": ["Junoh Kang", "Jinyoung Choi", "Sungik Choi", "Bohyung Han"], "Categories": "cs.LG cs.AI"}, "abstract": "We propose a novel diffusion model called observation-guided diffusion probabilistic model (OGDM), which effectively addresses the trade-off between quality control and fast sampling. Our approach reestablishes the training objective by integrating the guidance of the observation process with the Markov chain in a principled way. This is achieved by introducing an additional loss term derived from the observation based on the conditional discriminator on noise level, which employs Bernoulli distribution indicating whether its input lies on the (noisy) real manifold or not. This strategy allows us to optimize the more accurate negative log-likelihood induced in the inference stage especially when the number of function evaluations is limited. The proposed training method is also advantageous even when incorporated only into the fine-tuning process, and it is compatible with various fast inference strategies since our method yields better denoising networks using the exactly same inference procedure without incurring extra computational cost. We demonstrate the effectiveness of the proposed training algorithm using diverse inference methods on strong diffusion model baselines.", "url": "https://arxiv.org/abs/2310.04041"}, {"metadata": {"arXiv": "2310.04128", "Date": "Fri, 06 Oct 2023 09:56:26 ", "Title": "Reinforcement Learning with Fast and Forgetful Memory", "Authors": ["Steven Morad", "Ryan Kortvelesy", "Stephan Liwicki", "Amanda Prorok"], "Categories": "cs.LG cs.AI"}, "abstract": "Nearly all real world tasks are inherently partially observable, necessitating the use of memory in Reinforcement Learning (RL). Most model-free approaches summarize the trajectory into a latent Markov state using memory models borrowed from Supervised Learning (SL), even though RL tends to exhibit different training and efficiency characteristics. Addressing this discrepancy, we introduce Fast and Forgetful Memory, an algorithm-agnostic memory model designed specifically for RL. Our approach constrains the model search space via strong structural priors inspired by computational psychology. It is a drop-in replacement for recurrent neural networks (RNNs) in recurrent RL algorithms, achieving greater reward than RNNs across various recurrent benchmarks and algorithms without changing any hyperparameters. Moreover, Fast and Forgetful Memory exhibits training speeds two orders of magnitude faster than RNNs, attributed to its logarithmic time and linear space complexity. Our implementation is available at https://github.com/proroklab/ffm.", "url": "https://arxiv.org/abs/2310.04128"}, {"metadata": {"arXiv": "2310.04171", "Date": "Fri, 06 Oct 2023 11:41:38 ", "Title": "Dynamic Relation-Attentive Graph Neural Networks for Fraud Detection", "Authors": ["Heehyeon Kim", "Jinhyeok Choi", "Joyce Jiyoung Whang"], "Categories": "cs.LG cs.AI cs.CR", "Comments": ["5 pages", "3 figures", "3 tables. 23rd IEEE International Conference on Data Mining Workshops (ICDMW)"], "ACM-class": "I.2"}, "abstract": "Fraud detection aims to discover fraudsters deceiving other users by, for example, leaving fake reviews or making abnormal transactions. Graph-based fraud detection methods consider this task as a classification problem with two classes: frauds or normal. We address this problem using Graph Neural Networks (GNNs) by proposing a dynamic relation-attentive aggregation mechanism. Based on the observation that many real-world graphs include different types of relations, we propose to learn a node representation per relation and aggregate the node representations using a learnable attention function that assigns a different attention coefficient to each relation. Furthermore, we combine the node representations from different layers to consider both the local and global structures of a target node, which is beneficial to improving the performance of fraud detection on graphs with heterophily. By employing dynamic graph attention in all the aggregation processes, our method adaptively computes the attention coefficients for each node. Experimental results show that our method, DRAG, outperforms state-of-the-art fraud detection methods on real-world benchmark datasets.", "url": "https://arxiv.org/abs/2310.04171"}, {"metadata": {"arXiv": "2310.04178", "Date": "Fri, 06 Oct 2023 11:48:26 ", "Title": "Introducing the Attribution Stability Indicator: a Measure for Time Series XAI Attributions", "Authors": ["Udo Schlegel", "Daniel A. Keim"], "Categories": "cs.LG cs.AI", "Comments": ["16 pages", "6 figures", "ECML-PKDD Workshop XAI-TS: Explainable AI for Time Series: Advances and Applications"]}, "abstract": "Given the increasing amount and general complexity of time series data in domains such as finance, weather forecasting, and healthcare, there is a growing need for state-of-the-art performance models that can provide interpretable insights into underlying patterns and relationships. Attribution techniques enable the extraction of explanations from time series models to gain insights but are hard to evaluate for their robustness and trustworthiness. We propose the Attribution Stability Indicator (ASI), a measure to incorporate robustness and trustworthiness as properties of attribution techniques for time series into account. We extend a perturbation analysis with correlations of the original time series to the perturbed instance and the attributions to include wanted properties in the measure. We demonstrate the wanted properties based on an analysis of the attributions in a dimension-reduced space and the ASI scores distribution over three whole time series classification datasets.", "url": "https://arxiv.org/abs/2310.04178"}, {"metadata": {"arXiv": "2310.04241", "Date": "Fri, 06 Oct 2023 13:22:26 ", "Title": "Comparing Auxiliary Tasks for Learning Representations for Reinforcement Learning", "Authors": ["Moritz Lange", "Noah Krystiniak", "Raphael C. Engelhardt", "Wolfgang Konen", "Laurenz Wiskott"], "Categories": "cs.LG cs.AI"}, "abstract": "Learning state representations has gained steady popularity in reinforcement learning (RL) due to its potential to improve both sample efficiency and returns on many environments. A straightforward and efficient method is to generate representations with a distinct neural network trained on an auxiliary task, i.e. a task that differs from the actual RL task. While a whole range of such auxiliary tasks has been proposed in the literature, a comparison on typical continuous control benchmark environments is computationally expensive and has, to the best of our knowledge, not been performed before. This paper presents such a comparison of common auxiliary tasks, based on hundreds of agents trained with state-of-the-art off-policy RL algorithms. We compare possible improvements in both sample efficiency and returns for environments ranging from simple pendulum to a complex simulated robotics task. Our findings show that representation learning with auxiliary tasks is beneficial for environments of higher dimension and complexity, and that learning environment dynamics is preferable to predicting rewards. We believe these insights will enable other researchers to make more informed decisions on how to utilize representation learning for their specific problem.", "url": "https://arxiv.org/abs/2310.04241"}, {"metadata": {"arXiv": "2310.04295", "Date": "Fri, 06 Oct 2023 14:58:28 ", "Title": "Identifying Representations for Intervention Extrapolation", "Authors": ["Sorawit Saengkyongam", "Elan Rosenfeld", "Pradeep Ravikumar", "Niklas Pfister", "Jonas Peters"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "The premise of identifiable and causal representation learning is to improve the current representation learning paradigm in terms of generalizability or robustness. Despite recent progress in questions of identifiability, more theoretical results demonstrating concrete advantages of these methods for downstream tasks are needed. In this paper, we consider the task of intervention extrapolation: predicting how interventions affect an outcome, even when those interventions are not observed at training time, and show that identifiable representations can provide an effective solution to this task even if the interventions affect the outcome non-linearly. Our setup includes an outcome Y, observed features X, which are generated as a non-linear transformation of latent features Z, and exogenous action variables A, which influence Z. The objective of intervention extrapolation is to predict how interventions on A that lie outside the training support of A affect Y. Here, extrapolation becomes possible if the effect of A on Z is linear and the residual when regressing Z on A has full support. As Z is latent, we combine the task of intervention extrapolation with identifiable representation learning, which we call Rep4Ex: we aim to map the observed features X into a subspace that allows for non-linear extrapolation in A. We show using Wiener's Tauberian theorem that the hidden representation is identifiable up to an affine transformation in Z-space, which is sufficient for intervention extrapolation. The identifiability is characterized by a novel constraint describing the linearity assumption of A on Z. Based on this insight, we propose a method that enforces the linear invariance constraint and can be combined with any type of autoencoder. We validate our theoretical findings through synthetic experiments and show that our approach succeeds in predicting the effects of unseen interventions.", "url": "https://arxiv.org/abs/2310.04295"}, {"metadata": {"arXiv": "2310.04323", "Date": "Fri, 06 Oct 2023 15:34:21 ", "Title": "Adjustable Robust Reinforcement Learning for Online 3D Bin Packing", "Authors": ["Yuxin Pan", "Yize Chen", "Fangzhen Lin"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted to NeurIPS2023"]}, "abstract": "Designing effective policies for the online 3D bin packing problem (3D-BPP) has been a long-standing challenge, primarily due to the unpredictable nature of incoming box sequences and stringent physical constraints. While current deep reinforcement learning (DRL) methods for online 3D-BPP have shown promising results in optimizing average performance over an underlying box sequence distribution, they often fail in real-world settings where some worst-case scenarios can materialize. Standard robust DRL algorithms tend to overly prioritize optimizing the worst-case performance at the expense of performance under normal problem instance distribution. To address these issues, we first introduce a permutation-based attacker to investigate the practical robustness of both DRL-based and heuristic methods proposed for solving online 3D-BPP. Then, we propose an adjustable robust reinforcement learning (AR2L) framework that allows efficient adjustment of robustness weights to achieve the desired balance of the policy's performance in average and worst-case environments. Specifically, we formulate the objective function as a weighted sum of expected and worst-case returns, and derive the lower performance bound by relating to the return under a mixture dynamics. To realize this lower bound, we adopt an iterative procedure that searches for the associated mixture dynamics and improves the corresponding policy. We integrate this procedure into two popular robust adversarial algorithms to develop the exact and approximate AR2L algorithms. Experiments demonstrate that AR2L is versatile in the sense that it improves policy robustness while maintaining an acceptable level of performance for the nominal case.", "url": "https://arxiv.org/abs/2310.04323"}, {"metadata": {"arXiv": "2310.04353", "Date": "Fri, 06 Oct 2023 16:21:22 ", "Title": "A Language-Agent Approach to Formal Theorem-Proving", "Authors": ["Amitayush Thakur", "Yeming Wen", "Swarat Chaudhuri"], "Categories": "cs.LG cs.AI cs.LO cs.PL"}, "abstract": "Language agents, which use a large language model (LLM) capable of in-context learning to interact with an external environment, have recently emerged as a promising approach to control tasks. We present the first language-agent approach to formal theorem-proving. Our method, COPRA, uses a high-capacity, black-box LLM (GPT-4) as part of a policy for a stateful backtracking search. During the search, the policy can select proof tactics and retrieve lemmas and definitions from an external database. Each selected tactic is executed in the underlying proof framework, and the execution feedback is used to build the prompt for the next policy invocation. The search also tracks selected information from its history and uses it to reduce hallucinations and unnecessary LLM queries. We evaluate COPRA on the miniF2F benchmark for Lean and a set of Coq tasks from the Compcert project. On these benchmarks, COPRA is significantly better than one-shot invocations of GPT-4, as well as state-of-the-art models fine-tuned on proof data, at finding correct proofs quickly.", "url": "https://arxiv.org/abs/2310.04353"}, {"metadata": {"arXiv": "2310.04373", "Date": "Fri, 06 Oct 2023 16:59:17 ", "Title": "Confronting Reward Model Overoptimization with Constrained RLHF", "Authors": ["Ted Moskovitz", "Aaditya K. Singh", "DJ Strouse", "Tuomas Sandholm", "Ruslan Salakhutdinov", "Anca D. Dragan", "Stephen McAleer"], "Categories": "cs.LG cs.AI"}, "abstract": "Large language models are typically aligned with human preferences by optimizing $\\textit{reward models}$ (RMs) fitted to human feedback. However, human preferences are multi-faceted, and it is increasingly common to derive reward from a composition of simpler reward models which each capture a different aspect of language quality. This itself presents a challenge, as it is difficult to appropriately weight these component RMs when combining them. Compounding this difficulty, because any RM is only a proxy for human evaluation, this process is vulnerable to $\\textit{overoptimization}$, wherein past a certain point, accumulating higher reward is associated with worse human ratings. In this paper, we perform, to our knowledge, the first study on overoptimization in composite RMs, showing that correlation between component RMs has a significant effect on the locations of these points. We then introduce an approach to solve this issue using constrained reinforcement learning as a means of preventing the agent from exceeding each RM's threshold of usefulness. Our method addresses the problem of weighting component RMs by learning dynamic weights, naturally given by the Lagrange multipliers. As a result, each RM stays within the range at which it is an effective proxy, improving evaluation performance. Finally, we introduce an adaptive method using gradient-free optimization to identify and optimize towards these points during a single run.", "url": "https://arxiv.org/abs/2310.04373"}, {"metadata": {"arXiv": "2310.04395", "Date": "Fri, 06 Oct 2023 17:41:41 ", "Title": "Leveraging Self-Consistency for Data-Efficient Amortized Bayesian Inference", "Authors": ["Marvin Schmitt", "Daniel Habermann", "Paul-Christian B\\\"urkner", "Ullrich K\\\"othe", "Stefan T. Radev"], "Categories": "cs.LG cs.AI"}, "abstract": "We propose a method to improve the efficiency and accuracy of amortized Bayesian inference (ABI) by leveraging universal symmetries in the probabilistic joint model $p(\\theta, y)$ of parameters $\\theta$ and data $y$. In a nutshell, we invert Bayes' theorem and estimate the marginal likelihood based on approximate representations of the joint model. Upon perfect approximation, the marginal likelihood is constant across all parameter values by definition. However, approximation error leads to undesirable variance in the marginal likelihood estimates across different parameter values. We formulate violations of this symmetry as a loss function to accelerate the learning dynamics of conditional neural density estimators. We apply our method to a bimodal toy problem with an explicit likelihood (likelihood-based) and a realistic model with an implicit likelihood (simulation-based).", "url": "https://arxiv.org/abs/2310.04395"}, {"metadata": {"arXiv": "2310.04413", "Date": "Fri, 06 Oct 2023 17:58:14 ", "Title": "Beyond Uniform Sampling: Offline Reinforcement Learning with Imbalanced Datasets", "Authors": ["Zhang-Wei Hong", "Aviral Kumar", "Sathwik Karnik", "Abhishek Bhandwaldar", "Akash Srivastava", "Joni Pajarinen", "Romain Laroche", "Abhishek Gupta", "Pulkit Agrawal"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted NeurIPS 2023"]}, "abstract": "Offline policy learning is aimed at learning decision-making policies using existing datasets of trajectories without collecting additional data. The primary motivation for using reinforcement learning (RL) instead of supervised learning techniques such as behavior cloning is to find a policy that achieves a higher average return than the trajectories constituting the dataset. However, we empirically find that when a dataset is dominated by suboptimal trajectories, state-of-the-art offline RL algorithms do not substantially improve over the average return of trajectories in the dataset. We argue this is due to an assumption made by current offline RL algorithms of staying close to the trajectories in the dataset. If the dataset primarily consists of sub-optimal trajectories, this assumption forces the policy to mimic the suboptimal actions. We overcome this issue by proposing a sampling strategy that enables the policy to only be constrained to ``good data\" rather than all actions in the dataset (i.e., uniform sampling). We present a realization of the sampling strategy and an algorithm that can be used as a plug-and-play module in standard offline RL algorithms. Our evaluation demonstrates significant performance gains in 72 imbalanced datasets, D4RL dataset, and across three different offline RL algorithms. Code is available at https://github.com/Improbable-AI/dw-offline-rl.", "url": "https://arxiv.org/abs/2310.04413"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

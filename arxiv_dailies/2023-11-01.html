<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2310.19898", "Date": "Mon, 30 Oct 2023 18:07:57 ", "Title": "MIST: Medical Image Segmentation Transformer with Convolutional Attention Mixing (CAM) Decoder", "Authors": ["Md Motiur Rahman", "Shiva Shokouhmand", "Smriti Bhatt", "and Miad Faezipour"], "Categories": "cs.CV cs.LG", "Comments": ["10 pages", "2 figures", "3 tables", "accepted for publication in WACV 2024"]}, "abstract": "One of the common and promising deep learning approaches used for medical image segmentation is transformers, as they can capture long-range dependencies among the pixels by utilizing self-attention. Despite being successful in medical image segmentation, transformers face limitations in capturing local contexts of pixels in multimodal dimensions. We propose a Medical Image Segmentation Transformer (MIST) incorporating a novel Convolutional Attention Mixing (CAM) decoder to address this issue. MIST has two parts: a pre-trained multi-axis vision transformer (MaxViT) is used as an encoder, and the encoded feature representation is passed through the CAM decoder for segmenting the images. In the CAM decoder, an attention-mixer combining multi-head self-attention, spatial attention, and squeeze and excitation attention modules is introduced to capture long-range dependencies in all spatial dimensions. Moreover, to enhance spatial information gain, deep and shallow convolutions are used for feature extraction and receptive field expansion, respectively. The integration of low-level and high-level features from different network stages is enabled by skip connections, allowing MIST to suppress unnecessary information. The experiments show that our MIST transformer with CAM decoder outperforms the state-of-the-art models specifically designed for medical image segmentation on the ACDC and Synapse datasets. Our results also demonstrate that adding the CAM decoder with a hierarchical transformer improves segmentation performance significantly. Our model with data and code is publicly available on GitHub.", "url": "https://arxiv.org/abs/2310.19898"}, {"metadata": {"arXiv": "2310.19909", "Date": "Mon, 30 Oct 2023 18:23:58 ", "Title": "Battle of the Backbones: A Large-Scale Comparison of Pretrained Models across Computer Vision Tasks", "Authors": ["Micah Goldblum", "Hossein Souri", "Renkun Ni", "Manli Shu", "Viraj Prabhu", "Gowthami Somepalli", "Prithvijit Chattopadhyay", "Mark Ibrahim", "Adrien Bardes", "Judy Hoffman", "Rama Chellappa", "Andrew Gordon Wilson", "Tom Goldstein"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted to NeurIPS 2023"]}, "abstract": "Neural network based computer vision systems are typically built on a backbone, a pretrained or randomly initialized feature extractor. Several years ago, the default option was an ImageNet-trained convolutional neural network. However, the recent past has seen the emergence of countless backbones pretrained using various algorithms and datasets. While this abundance of choice has led to performance increases for a range of systems, it is difficult for practitioners to make informed decisions about which backbone to choose. Battle of the Backbones (BoB) makes this choice easier by benchmarking a diverse suite of pretrained models, including vision-language models, those trained via self-supervised learning, and the Stable Diffusion backbone, across a diverse set of computer vision tasks ranging from classification to object detection to OOD generalization and more. Furthermore, BoB sheds light on promising directions for the research community to advance computer vision by illuminating strengths and weakness of existing approaches through a comprehensive analysis conducted on more than 1500 training runs. While vision transformers (ViTs) and self-supervised learning (SSL) are increasingly popular, we find that convolutional neural networks pretrained in a supervised fashion on large training sets still perform best on most tasks among the models we consider. Moreover, in apples-to-apples comparisons on the same architectures and similarly sized pretraining datasets, we find that SSL backbones are highly competitive, indicating that future works should perform SSL pretraining with advanced architectures and larger pretraining datasets. We release the raw results of our experiments along with code that allows researchers to put their own backbones through the gauntlet here: https://github.com/hsouri/Battle-of-the-Backbones", "url": "https://arxiv.org/abs/2310.19909"}, {"metadata": {"arXiv": "2310.20064", "Date": "Mon, 30 Oct 2023 22:29:07 ", "Title": "A Scalable Training Strategy for Blind Multi-Distribution Noise Removal", "Authors": ["Kevin Zhang", "Sakshum Kulshrestha", "Christopher Metzler"], "Categories": "cs.CV cs.LG eess.IV"}, "abstract": "Despite recent advances, developing general-purpose universal denoising and artifact-removal networks remains largely an open problem: Given fixed network weights, one inherently trades-off specialization at one task (e.g.,~removing Poisson noise) for performance at another (e.g.,~removing speckle noise). In addition, training such a network is challenging due to the curse of dimensionality: As one increases the dimensions of the specification-space (i.e.,~the number of parameters needed to describe the noise distribution) the number of unique specifications one needs to train for grows exponentially. Uniformly sampling this space will result in a network that does well at very challenging problem specifications but poorly at easy problem specifications, where even large errors will have a small effect on the overall mean squared error. In this work we propose training denoising networks using an adaptive-sampling/active-learning strategy. Our work improves upon a recently proposed universal denoiser training strategy by extending these results to higher dimensions and by incorporating a polynomial approximation of the true specification-loss landscape. This approximation allows us to reduce training times by almost two orders of magnitude. We test our method on simulated joint Poisson-Gaussian-Speckle noise and demonstrate that with our proposed training strategy, a single blind, generalist denoiser network can achieve peak signal-to-noise ratios within a uniform bound of specialized denoiser networks across a large range of operating conditions. We also capture a small dataset of images with varying amounts of joint Poisson-Gaussian-Speckle noise and demonstrate that a universal denoiser trained using our adaptive-sampling strategy outperforms uniformly trained baselines.", "url": "https://arxiv.org/abs/2310.20064"}, {"metadata": {"arXiv": "2310.20065", "Date": "Mon, 30 Oct 2023 22:29:50 ", "Title": "LinFlo-Net: A two-stage deep learning method to generate simulation ready meshes of the heart", "Authors": ["Arjun Narayanan", "Fanwei Kong", "Shawn Shadden"], "Categories": "cs.CV cs.LG", "Comments": ["Submitted to to the Journal of Biomechanical Engineering"]}, "abstract": "We present a deep learning model to automatically generate computer models of the human heart from patient imaging data with an emphasis on its capability to generate thin-walled cardiac structures. Our method works by deforming a template mesh to fit the cardiac structures to the given image. Compared with prior deep learning methods that adopted this approach, our framework is designed to minimize mesh self-penetration, which typically arises when deforming surface meshes separated by small distances. We achieve this by using a two-stage diffeomorphic deformation process along with a novel loss function derived from the kinematics of motion that penalizes surface contact and interpenetration. Our model demonstrates comparable accuracy with state-of-the-art methods while additionally producing meshes free of self-intersections. The resultant meshes are readily usable in physics based simulation, minimizing the need for post-processing and cleanup.", "url": "https://arxiv.org/abs/2310.20065"}, {"metadata": {"arXiv": "2310.20190", "Date": "Tue, 31 Oct 2023 05:18:53 ", "Title": "Visible to Thermal image Translation for improving visual task in low light conditions", "Authors": ["Md Azim Khan"], "Categories": "cs.CV cs.LG eess.IV"}, "abstract": "Several visual tasks, such as pedestrian detection and image-to-image translation, are challenging to accomplish in low light using RGB images. Heat variation of objects in thermal images can be used to overcome this. In this work, an end-to-end framework, which consists of a generative network and a detector network, is proposed to translate RGB image into Thermal ones and compare generated thermal images with real data. We have collected images from two different locations using the Parrot Anafi Thermal drone. After that, we created a two-stream network, preprocessed, augmented, the image data, and trained the generator and discriminator models from scratch. The findings demonstrate that it is feasible to translate RGB training data to thermal data using GAN. As a result, thermal data can now be produced more quickly and affordably, which is useful for security and surveillance applications.", "url": "https://arxiv.org/abs/2310.20190"}, {"metadata": {"arXiv": "2310.20249", "Date": "Tue, 31 Oct 2023 08:13:00 ", "Title": "Pose-to-Motion: Cross-Domain Motion Retargeting with Pose Prior", "Authors": ["Qingqing Zhao and Peizhuo Li and Wang Yifan and Olga Sorkine-Hornung and Gordon Wetzstein"], "Categories": "cs.CV cs.GR cs.LG", "Comments": ["Project page: https://cyanzhao42.github.io/pose2motion"]}, "abstract": "Creating believable motions for various characters has long been a goal in computer graphics. Current learning-based motion synthesis methods depend on extensive motion datasets, which are often challenging, if not impossible, to obtain. On the other hand, pose data is more accessible, since static posed characters are easier to create and can even be extracted from images using recent advancements in computer vision. In this paper, we utilize this alternative data source and introduce a neural motion synthesis approach through retargeting. Our method generates plausible motions for characters that have only pose data by transferring motion from an existing motion capture dataset of another character, which can have drastically different skeletons. Our experiments show that our method effectively combines the motion features of the source character with the pose features of the target character, and performs robustly with small or noisy pose data sets, ranging from a few artist-created poses to noisy poses estimated directly from images. Additionally, a conducted user study indicated that a majority of participants found our retargeted motion to be more enjoyable to watch, more lifelike in appearance, and exhibiting fewer artifacts. Project page: https://cyanzhao42.github.io/pose2motion", "url": "https://arxiv.org/abs/2310.20249"}, {"metadata": {"arXiv": "2310.20319", "Date": "Tue, 31 Oct 2023 09:55:04 ", "Title": "GACE: Geometry Aware Confidence Enhancement for Black-Box 3D Object Detectors on LiDAR-Data", "Authors": ["David Schinagl", "Georg Krispel", "Christian Fruhwirth-Reisinger", "Horst Possegger", "Horst Bischof"], "Categories": "cs.CV cs.LG", "Comments": ["ICCV 2023", "code is available at https://github.com/dschinagl/gace"]}, "abstract": "Widely-used LiDAR-based 3D object detectors often neglect fundamental geometric information readily available from the object proposals in their confidence estimation. This is mostly due to architectural design choices, which were often adopted from the 2D image domain, where geometric context is rarely available. In 3D, however, considering the object properties and its surroundings in a holistic way is important to distinguish between true and false positive detections, e.g. occluded pedestrians in a group. To address this, we present GACE, an intuitive and highly efficient method to improve the confidence estimation of a given black-box 3D object detector. We aggregate geometric cues of detections and their spatial relationships, which enables us to properly assess their plausibility and consequently, improve the confidence estimation. This leads to consistent performance gains over a variety of state-of-the-art detectors. Across all evaluated detectors, GACE proves to be especially beneficial for the vulnerable road user classes, i.e. pedestrians and cyclists.", "url": "https://arxiv.org/abs/2310.20319"}, {"metadata": {"arXiv": "2310.20348", "Date": "Tue, 31 Oct 2023 10:45:03 ", "Title": "Class Incremental Learning with Pre-trained Vision-Language Models", "Authors": ["Xialei Liu", "Xusheng Cao", "Haori Lu", "Jia-wen Xiao", "Andrew D. Bagdanov", "Ming-Ming Cheng"], "Categories": "cs.CV cs.LG"}, "abstract": "With the advent of large-scale pre-trained models, interest in adapting and exploiting them for continual learning scenarios has grown. In this paper, we propose an approach to exploiting pre-trained vision-language models (e.g. CLIP) that enables further adaptation instead of only using zero-shot learning of new tasks. We augment a pre-trained CLIP model with additional layers after the Image Encoder or before the Text Encoder. We investigate three different strategies: a Linear Adapter, a Self-attention Adapter, each operating on the image embedding, and Prompt Tuning which instead modifies prompts input to the CLIP text encoder. We also propose a method for parameter retention in the adapter layers that uses a measure of parameter importance to better maintain stability and plasticity during incremental learning. Our experiments demonstrate that the simplest solution -- a single Linear Adapter layer with parameter retention -- produces the best results. Experiments on several conventional benchmarks consistently show a significant margin of improvement over the current state-of-the-art.", "url": "https://arxiv.org/abs/2310.20348"}, {"metadata": {"arXiv": "2310.20490", "Date": "Tue, 31 Oct 2023 14:30:31 ", "Title": "Long-Tailed Learning as Multi-Objective Optimization", "Authors": ["Weiqi Li", "Fan Lyu", "Fanhua Shang", "Liang Wan", "Wei Feng"], "Categories": "cs.CV cs.LG", "Comments": ["In submission"]}, "abstract": "Real-world data is extremely imbalanced and presents a long-tailed distribution, resulting in models that are biased towards classes with sufficient samples and perform poorly on rare classes. Recent methods propose to rebalance classes but they undertake the seesaw dilemma (what is increasing performance on tail classes may decrease that of head classes, and vice versa). In this paper, we argue that the seesaw dilemma is derived from gradient imbalance of different classes, in which gradients of inappropriate classes are set to important for updating, thus are prone to overcompensation or undercompensation on tail classes. To achieve ideal compensation, we formulate the long-tailed recognition as an multi-objective optimization problem, which fairly respects the contributions of head and tail classes simultaneously. For efficiency, we propose a Gradient-Balancing Grouping (GBG) strategy to gather the classes with similar gradient directions, thus approximately make every update under a Pareto descent direction. Our GBG method drives classes with similar gradient directions to form more representative gradient and provide ideal compensation to the tail classes. Moreover, We conduct extensive experiments on commonly used benchmarks in long-tailed learning and demonstrate the superiority of our method over existing SOTA methods.", "url": "https://arxiv.org/abs/2310.20490"}, {"metadata": {"arXiv": "2310.20618", "Date": "Tue, 31 Oct 2023 16:51:40 ", "Title": "Diffusion Reconstruction of Ultrasound Images with Informative Uncertainty", "Authors": ["Yuxin Zhang", "Cl\\'ement Huneau", "J\\'er\\^ome Idier", "and Diana Mateus"], "Categories": "cs.CV cs.LG", "Comments": ["This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice", "after which this version may no longer be accessible. (10 pages)"]}, "abstract": "Despite its wide use in medicine, ultrasound imaging faces several challenges related to its poor signal-to-noise ratio and several sources of noise and artefacts. Enhancing ultrasound image quality involves balancing concurrent factors like contrast, resolution, and speckle preservation. In recent years, there has been progress both in model-based and learning-based approaches to improve ultrasound image reconstruction. Bringing the best from both worlds, we propose a hybrid approach leveraging advances in diffusion models. To this end, we adapt Denoising Diffusion Restoration Models (DDRM) to incorporate ultrasound physics through a linear direct model and an unsupervised fine-tuning of the prior diffusion model. We conduct comprehensive experiments on simulated, in-vitro, and in-vivo data, demonstrating the efficacy of our approach in achieving high-quality image reconstructions from a single plane wave input and in comparison to state-of-the-art methods. Finally, given the stochastic nature of the method, we analyse in depth the statistical properties of single and multiple-sample reconstructions, experimentally show the informativeness of their variance, and provide an empirical model relating this behaviour to speckle noise. The code and data are available at: (upon acceptance).", "url": "https://arxiv.org/abs/2310.20618"}, {"metadata": {"arXiv": "2310.20636", "Date": "Tue, 31 Oct 2023 17:05:02 ", "Title": "Using Higher-Order Moments to Assess the Quality of GAN-generated Image Features", "Authors": ["Lorenzo Luzi", "Helen Jenne", "Ryan Murray", "Carlos Ortiz Marrero"], "Categories": "cs.CV cs.LG", "Report-no": "PNNL-SA-175469"}, "abstract": "The rapid advancement of Generative Adversarial Networks (GANs) necessitates the need to robustly evaluate these models. Among the established evaluation criteria, the Fr\\'{e}chet Inception Distance (FID) has been widely adopted due to its conceptual simplicity, fast computation time, and strong correlation with human perception. However, FID has inherent limitations, mainly stemming from its assumption that feature embeddings follow a Gaussian distribution, and therefore can be defined by their first two moments. As this does not hold in practice, in this paper we explore the importance of third-moments in image feature data and use this information to define a new measure, which we call the Skew Inception Distance (SID). We prove that SID is a pseudometric on probability distributions, show how it extends FID, and present a practical method for its computation. Our numerical experiments support that SID either tracks with FID or, in some cases, aligns more closely with human perception when evaluating image features of ImageNet data.", "url": "https://arxiv.org/abs/2310.20636"}, {"metadata": {"arXiv": "2310.20649", "Date": "Tue, 31 Oct 2023 17:20:30 ", "Title": "Dynamic Batch Norm Statistics Update for Natural Robustness", "Authors": ["Shahbaz Rezaei", "Mohammad Sadegh Norouzzadeh"], "Categories": "cs.CV cs.LG"}, "abstract": "DNNs trained on natural clean samples have been shown to perform poorly on corrupted samples, such as noisy or blurry images. Various data augmentation methods have been recently proposed to improve DNN's robustness against common corruptions. Despite their success, they require computationally expensive training and cannot be applied to off-the-shelf trained models. Recently, it has been shown that updating BatchNorm (BN) statistics of an off-the-shelf model on a single corruption improves its accuracy on that corruption significantly. However, adopting the idea at inference time when the type of corruption is unknown and changing decreases the effectiveness of this method. In this paper, we harness the Fourier domain to detect the corruption type, a challenging task in the image domain. We propose a unified framework consisting of a corruption-detection model and BN statistics update that improves the corruption accuracy of any off-the-shelf trained model. We benchmark our framework on different models and datasets. Our results demonstrate about 8% and 4% accuracy improvement on CIFAR10-C and ImageNet-C, respectively. Furthermore, our framework can further improve the accuracy of state-of-the-art robust models, such as AugMix and DeepAug.", "url": "https://arxiv.org/abs/2310.20649"}, {"metadata": {"arXiv": "2310.19802", "Date": "Wed, 04 Oct 2023 01:32:55 ", "Title": "Stochastic Thermodynamics of Learning Generative Parametric Probabilistic Models", "Authors": ["Shervin Sadat Parsi"], "Categories": "cs.LG"}, "abstract": "We have formulated generative machine learning problems as the time evolution of Parametric Probabilistic Models (PPMs), inherently rendering a thermodynamic process. Then, we have studied the thermodynamic exchange between the model's parameters, denoted as $\\Theta$, and the model's generated samples, denoted as $X$. We demonstrate that the training dataset and the action of the Stochastic Gradient Descent (SGD) optimizer serve as a work source that governs the time evolution of these two subsystems. Our findings reveal that the model learns through the dissipation of heat during the generation of samples $X$, leading to an increase in the entropy of the model's parameters, $\\Theta$. Thus, the parameter subsystem acts as a heat reservoir, effectively storing the learned information. Furthermore, the role of the model's parameters as a heat reservoir provides valuable thermodynamic insights into the generalization power of over-parameterized models. This approach offers an unambiguous framework for computing information-theoretic quantities within deterministic neural networks by establishing connections with thermodynamic variables. To illustrate the utility of this framework, we introduce two information-theoretic metrics: Memorized-information (M-info) and Learned-information (L-info), which trace the dynamic flow of information during the learning process of PPMs.", "url": "https://arxiv.org/abs/2310.19802"}, {"metadata": {"arXiv": "2310.19807", "Date": "Mon, 09 Oct 2023 16:48:56 ", "Title": "Improved Communication Efficiency in Federated Natural Policy Gradient via ADMM-based Gradient Updates", "Authors": ["Guangchen Lan", "Han Wang", "James Anderson", "Christopher Brinton", "Vaneet Aggarwal"], "Categories": "cs.LG math.OC", "Comments": ["Accepted at the 37th Conference on Neural Information Processing Systems (NeurIPS 2023)"], "ACM-class": "I.2.6"}, "abstract": "Federated reinforcement learning (FedRL) enables agents to collaboratively train a global policy without sharing their individual data. However, high communication overhead remains a critical bottleneck, particularly for natural policy gradient (NPG) methods, which are second-order. To address this issue, we propose the FedNPG-ADMM framework, which leverages the alternating direction method of multipliers (ADMM) to approximate global NPG directions efficiently. We theoretically demonstrate that using ADMM-based gradient updates reduces communication complexity from ${O}({d^{2}})$ to ${O}({d})$ at each iteration, where $d$ is the number of model parameters. Furthermore, we show that achieving an $\\epsilon$-error stationary convergence requires ${O}(\\frac{1}{(1-\\gamma)^{2}{\\epsilon}})$ iterations for discount factor $\\gamma$, demonstrating that FedNPG-ADMM maintains the same convergence rate as the standard FedNPG. Through evaluation of the proposed algorithms in MuJoCo environments, we demonstrate that FedNPG-ADMM maintains the reward performance of standard FedNPG, and that its convergence rate improves when the number of federated agents increases.", "url": "https://arxiv.org/abs/2310.19807"}, {"metadata": {"arXiv": "2310.19809", "Date": "Mon, 16 Oct 2023 13:01:35 ", "Title": "MgNO: Efficient Parameterization of Linear Operators via Multigrid", "Authors": ["Juncai He", "Xinliang Liu and Jinchao Xu"], "Categories": "cs.LG cs.NA math.NA"}, "abstract": "In this work, we propose a concise neural operator architecture for operator learning. Drawing an analogy with a conventional fully connected neural network, we define the neural operator as follows: the output of the $i$-th neuron in a nonlinear operator layer is defined by $\\mathcal O_i(u) = \\sigma\\left( \\sum_j \\mathcal W_{ij} u + \\mathcal B_{ij}\\right)$. Here, $\\mathcal W_{ij}$ denotes the bounded linear operator connecting $j$-th input neuron to $i$-th output neuron, and the bias $\\mathcal B_{ij}$ takes the form of a function rather than a scalar. Given its new universal approximation property, the efficient parameterization of the bounded linear operators between two neurons (Banach spaces) plays a critical role. As a result, we introduce MgNO, utilizing multigrid structures to parameterize these linear operators between neurons. This approach offers both mathematical rigor and practical expressivity. Additionally, MgNO obviates the need for conventional lifting and projecting operators typically required in previous neural operators. Moreover, it seamlessly accommodates diverse boundary conditions. Our empirical observations reveal that MgNO exhibits superior ease of training compared to other CNN-based models, while also displaying a reduced susceptibility to overfitting when contrasted with spectral-type neural operators. We demonstrate the efficiency and accuracy of our method with consistently state-of-the-art performance on different types of partial differential equations (PDEs).", "url": "https://arxiv.org/abs/2310.19809"}, {"metadata": {"arXiv": "2310.19810", "Date": "Mon, 16 Oct 2023 13:02:43 ", "Title": "Advantages of Machine Learning in Bus Transport Analysis", "Authors": ["Amirsadegh Roshanzamir"], "Categories": "cs.LG"}, "abstract": "Supervised Machine Learning is an innovative method that aims to mimic human learning by using past experiences. In this study, we utilize supervised machine learning algorithms to analyze the factors that contribute to the punctuality of Tehran BRT bus system. We gather publicly available datasets of 2020 to 2022 from Municipality of Tehran to train and test our models. By employing various algorithms and leveraging Python's Sci Kit Learn and Stats Models libraries, we construct accurate models capable of predicting whether a bus route will meet the prescribed standards for on-time performance on any given day. Furthermore, we delve deeper into the decision-making process of each algorithm to determine the most influential factor it considers. This investigation allows us to uncover the key feature that significantly impacts the effectiveness of bus routes, providing valuable insights for improving their performance.", "url": "https://arxiv.org/abs/2310.19810"}, {"metadata": {"arXiv": "2310.19811", "Date": "Wed, 18 Oct 2023 08:52:16 ", "Title": "A Historical Context for Data Streams", "Authors": ["Indre Zliobaite and Jesse Read"], "Categories": "cs.LG cs.DB cs.SY eess.SY", "Comments": ["9 pages"]}, "abstract": "Machine learning from data streams is an active and growing research area. Research on learning from streaming data typically makes strict assumptions linked to computational resource constraints, including requirements for stream mining algorithms to inspect each instance not more than once and be ready to give a prediction at any time. Here we review the historical context of data streams research placing the common assumptions used in machine learning over data streams in their historical context.", "url": "https://arxiv.org/abs/2310.19811"}, {"metadata": {"arXiv": "2310.19814", "Date": "Wed, 18 Oct 2023 15:52:55 ", "Title": "Learning Gradient Fields for Scalable and Generalizable Irregular Packing", "Authors": ["Tianyang Xue", "Mingdong Wu", "Lin Lu", "Haoxuan Wang", "Hao Dong", "Baoquan Chen"], "Categories": "cs.LG cs.GR"}, "abstract": "The packing problem, also known as cutting or nesting, has diverse applications in logistics, manufacturing, layout design, and atlas generation. It involves arranging irregularly shaped pieces to minimize waste while avoiding overlap. Recent advances in machine learning, particularly reinforcement learning, have shown promise in addressing the packing problem. In this work, we delve deeper into a novel machine learning-based approach that formulates the packing problem as conditional generative modeling. To tackle the challenges of irregular packing, including object validity constraints and collision avoidance, our method employs the score-based diffusion model to learn a series of gradient fields. These gradient fields encode the correlations between constraint satisfaction and the spatial relationships of polygons, learned from teacher examples. During the testing phase, packing solutions are generated using a coarse-to-fine refinement mechanism guided by the learned gradient fields. To enhance packing feasibility and optimality, we introduce two key architectural designs: multi-scale feature extraction and coarse-to-fine relation extraction. We conduct experiments on two typical industrial packing domains, considering translations only. Empirically, our approach demonstrates spatial utilization rates comparable to, or even surpassing, those achieved by the teacher algorithm responsible for training data generation. Additionally, it exhibits some level of generalization to shape variations. We are hopeful that this method could pave the way for new possibilities in solving the packing problem.", "url": "https://arxiv.org/abs/2310.19814"}, {"metadata": {"arXiv": "2310.19820", "Date": "Tue, 24 Oct 2023 04:27:51 ", "Title": "NetDistiller: Empowering Tiny Deep Learning via In-Situ Distillation", "Authors": ["Shunyao Zhang", "Yonggan Fu", "Shang Wu", "Jyotikrishna Dass", "Haoran You", "Yingyan (Celine) Lin"], "Categories": "cs.LG cs.CV"}, "abstract": "Boosting the task accuracy of tiny neural networks (TNNs) has become a fundamental challenge for enabling the deployments of TNNs on edge devices which are constrained by strict limitations in terms of memory, computation, bandwidth, and power supply. To this end, we propose a framework called NetDistiller to boost the achievable accuracy of TNNs by treating them as sub-networks of a weight-sharing teacher constructed by expanding the number of channels of the TNN. Specifically, the target TNN model is jointly trained with the weight-sharing teacher model via (1) gradient surgery to tackle the gradient conflicts between them and (2) uncertainty-aware distillation to mitigate the overfitting of the teacher model. Extensive experiments across diverse tasks validate NetDistiller's effectiveness in boosting TNNs' achievable accuracy over state-of-the-art methods. Our code is available at https://github.com/GATECH-EIC/NetDistiller.", "url": "https://arxiv.org/abs/2310.19820"}, {"metadata": {"arXiv": "2310.19821", "Date": "Tue, 24 Oct 2023 19:29:13 ", "Title": "A Risk-Averse Framework for Non-Stationary Stochastic Multi-Armed Bandits", "Authors": ["Reda Alami", "Mohammed Mahfoud", "Mastane Achab"], "Categories": "cs.LG stat.ML"}, "abstract": "In a typical stochastic multi-armed bandit problem, the objective is often to maximize the expected sum of rewards over some time horizon $T$. While the choice of a strategy that accomplishes that is optimal with no additional information, it is no longer the case when provided additional environment-specific knowledge. In particular, in areas of high volatility like healthcare or finance, a naive reward maximization approach often does not accurately capture the complexity of the learning problem and results in unreliable solutions. To tackle problems of this nature, we propose a framework of adaptive risk-aware strategies that operate in non-stationary environments. Our framework incorporates various risk measures prevalent in the literature to map multiple families of multi-armed bandit algorithms into a risk-sensitive setting. In addition, we equip the resulting algorithms with the Restarted Bayesian Online Change-Point Detection (R-BOCPD) algorithm and impose a (tunable) forced exploration strategy to detect local (per-arm) switches. We provide finite-time theoretical guarantees and an asymptotic regret bound of order $\\tilde O(\\sqrt{K_T T})$ up to time horizon $T$ with $K_T$ the total number of change-points. In practice, our framework compares favorably to the state-of-the-art in both synthetic and real-world environments and manages to perform efficiently with respect to both risk-sensitivity and non-stationarity.", "url": "https://arxiv.org/abs/2310.19821"}, {"metadata": {"arXiv": "2310.19822", "Date": "Wed, 25 Oct 2023 02:16:02 ", "Title": "FuXi-Extreme: Improving extreme rainfall and wind forecasts with diffusion model", "Authors": ["Xiaohui Zhong and Lei Chen and Jun Liu and Chensen Lin and Yuan Qi and Hao Li"], "Categories": "cs.LG physics.ao-ph stat.AP"}, "abstract": "Significant advancements in the development of machine learning (ML) models for weather forecasting have produced remarkable results. State-of-the-art ML-based weather forecast models, such as FuXi, have demonstrated superior statistical forecast performance in comparison to the high-resolution forecasts (HRES) of the European Centre for Medium-Range Weather Forecasts (ECMWF). However, ML models face a common challenge: as forecast lead times increase, they tend to generate increasingly smooth predictions, leading to an underestimation of the intensity of extreme weather events. To address this challenge, we developed the FuXi-Extreme model, which employs a denoising diffusion probabilistic model (DDPM) to restore finer-scale details in the surface forecast data generated by the FuXi model in 5-day forecasts. An evaluation of extreme total precipitation ($\\textrm{TP}$), 10-meter wind speed ($\\textrm{WS10}$), and 2-meter temperature ($\\textrm{T2M}$) illustrates the superior performance of FuXi-Extreme over both FuXi and HRES. Moreover, when evaluating tropical cyclone (TC) forecasts based on International Best Track Archive for Climate Stewardship (IBTrACS) dataset, both FuXi and FuXi-Extreme shows superior performance in TC track forecasts compared to HRES, but they show inferior performance in TC intensity forecasts in comparison to HRES.", "url": "https://arxiv.org/abs/2310.19822"}, {"metadata": {"arXiv": "2310.19841", "Date": "Mon, 30 Oct 2023 07:53:42 ", "Title": "An interpretable clustering approach to safety climate analysis: examining driver group distinction in safety climate perceptions", "Authors": ["Kailai Sun", "Tianxiang Lan", "Yang Miang Goh", "Sufiana Safiena", "Yueng-Hsiang Huang", "Bailey Lytle", "Yimin He"], "Categories": "cs.LG", "Comments": ["Submitted to Journal:Accident Analysis and Prevention"]}, "abstract": "The transportation industry, particularly the trucking sector, is prone to workplace accidents and fatalities. Accidents involving large trucks accounted for a considerable percentage of overall traffic fatalities. Recognizing the crucial role of safety climate in accident prevention, researchers have sought to understand its factors and measure its impact within organizations. While existing data-driven safety climate studies have made remarkable progress, clustering employees based on their safety climate perception is innovative and has not been extensively utilized in research. Identifying clusters of drivers based on their safety climate perception allows the organization to profile its workforce and devise more impactful interventions. The lack of utilizing the clustering approach could be due to difficulties interpreting or explaining the factors influencing employees' cluster membership. Moreover, existing safety-related studies did not compare multiple clustering algorithms, resulting in potential bias. To address these issues, this study introduces an interpretable clustering approach for safety climate analysis. This study compares 5 algorithms for clustering truck drivers based on their safety climate perceptions. It proposes a novel method for quantitatively evaluating partial dependence plots (QPDP). To better interpret the clustering results, this study introduces different interpretable machine learning measures (SHAP, PFI, and QPDP). Drawing on data collected from more than 7,000 American truck drivers, this study significantly contributes to the scientific literature. It highlights the critical role of supervisory care promotion in distinguishing various driver groups. The Python code is available at https://github.com/NUS-DBE/truck-driver-safety-climate.", "url": "https://arxiv.org/abs/2310.19841"}, {"metadata": {"arXiv": "2310.19848", "Date": "Mon, 30 Oct 2023 15:04:40 ", "Title": "Efficient Exploration in Continuous-time Model-based Reinforcement Learning", "Authors": ["Lenart Treven", "Jonas H\\\"ubotter", "Bhavya Sukhija", "Florian D\\\"orfler", "Andreas Krause"], "Categories": "cs.LG cs.RO math.OC"}, "abstract": "Reinforcement learning algorithms typically consider discrete-time dynamics, even though the underlying systems are often continuous in time. In this paper, we introduce a model-based reinforcement learning algorithm that represents continuous-time dynamics using nonlinear ordinary differential equations (ODEs). We capture epistemic uncertainty using well-calibrated probabilistic models, and use the optimistic principle for exploration. Our regret bounds surface the importance of the measurement selection strategy(MSS), since in continuous time we not only must decide how to explore, but also when to observe the underlying system. Our analysis demonstrates that the regret is sublinear when modeling ODEs with Gaussian Processes (GP) for common choices of MSS, such as equidistant sampling. Additionally, we propose an adaptive, data-dependent, practical MSS that, when combined with GP dynamics, also achieves sublinear regret with significantly fewer samples. We showcase the benefits of continuous-time modeling over its discrete-time counterpart, as well as our proposed adaptive MSS over standard baselines, on several applications.", "url": "https://arxiv.org/abs/2310.19848"}, {"metadata": {"arXiv": "2310.19861", "Date": "Mon, 30 Oct 2023 17:59:26 ", "Title": "Posterior Sampling for Competitive RL: Function Approximation and Partial Observation", "Authors": ["Shuang Qiu", "Ziyu Dai", "Han Zhong", "Zhaoran Wang", "Zhuoran Yang", "Tong Zhang"], "Categories": "cs.LG cs.GT stat.ML", "Comments": ["NeurIPS 2023"]}, "abstract": "This paper investigates posterior sampling algorithms for competitive reinforcement learning (RL) in the context of general function approximations. Focusing on zero-sum Markov games (MGs) under two critical settings, namely self-play and adversarial learning, we first propose the self-play and adversarial generalized eluder coefficient (GEC) as complexity measures for function approximation, capturing the exploration-exploitation trade-off in MGs. Based on self-play GEC, we propose a model-based self-play posterior sampling method to control both players to learn Nash equilibrium, which can successfully handle the partial observability of states. Furthermore, we identify a set of partially observable MG models fitting MG learning with the adversarial policies of the opponent. Incorporating the adversarial GEC, we propose a model-based posterior sampling method for learning adversarial MG with potential partial observability. We further provide low regret bounds for proposed algorithms that can scale sublinearly with the proposed GEC and the number of episodes $T$. To the best of our knowledge, we for the first time develop generic model-based posterior sampling algorithms for competitive RL that can be applied to a majority of tractable zero-sum MG classes in both fully observable and partially observable MGs with self-play and adversarial learning.", "url": "https://arxiv.org/abs/2310.19861"}, {"metadata": {"arXiv": "2310.19886", "Date": "Mon, 30 Oct 2023 18:00:26 ", "Title": "BTRec: BERT-Based Trajectory Recommendation for Personalized Tours", "Authors": ["Ngai Lam Ho", "Roy Ka-Wei Lee", "Kwan Hui Lim"], "Categories": "cs.LG cs.IR cs.SI", "Comments": ["RecSys 2023", "Workshop on Recommenders in Tourism"]}, "abstract": "An essential task for tourists having a pleasant holiday is to have a well-planned itinerary with relevant recommendations, especially when visiting unfamiliar cities. Many tour recommendation tools only take into account a limited number of factors, such as popular Points of Interest (POIs) and routing constraints. Consequently, the solutions they provide may not always align with the individual users of the system. We propose an iterative algorithm in this paper, namely: BTREC (BERT-based Trajectory Recommendation), that extends from the POIBERT embedding algorithm to recommend personalized itineraries on POIs using the BERT framework. Our BTREC algorithm incorporates users' demographic information alongside past POI visits into a modified BERT language model to recommend a personalized POI itinerary prediction given a pair of source and destination POIs. Our recommendation system can create a travel itinerary that maximizes POIs visited, while also taking into account user preferences for categories of POIs and time availability. Our recommendation algorithm is largely inspired by the problem of sentence completion in natural language processing (NLP). Using a dataset of eight cities of different sizes, our experimental results demonstrate that our proposed algorithm is stable and outperforms many other sequence prediction algorithms, measured by recall, precision, and F1-scores.", "url": "https://arxiv.org/abs/2310.19886"}, {"metadata": {"arXiv": "2310.19915", "Date": "Mon, 30 Oct 2023 18:28:50 ", "Title": "GPCR-BERT: Interpreting Sequential Design of G Protein Coupled Receptors Using Protein Language Models", "Authors": ["Seongwon Kim", "Parisa Mollaei", "Akshay Antony", "Rishikesh Magar", "Amir Barati Farimani"], "Categories": "cs.LG q-bio.BM", "Comments": ["25 pages", "5 figures"]}, "abstract": "With the rise of Transformers and Large Language Models (LLMs) in Chemistry and Biology, new avenues for the design and understanding of therapeutics have opened up to the scientific community. Protein sequences can be modeled as language and can take advantage of recent advances in LLMs, specifically with the abundance of our access to the protein sequence datasets. In this paper, we developed the GPCR-BERT model for understanding the sequential design of G Protein-Coupled Receptors (GPCRs). GPCRs are the target of over one-third of FDA-approved pharmaceuticals. However, there is a lack of comprehensive understanding regarding the relationship between amino acid sequence, ligand selectivity, and conformational motifs (such as NPxxY, CWxP, E/DRY). By utilizing the pre-trained protein model (Prot-Bert) and fine-tuning with prediction tasks of variations in the motifs, we were able to shed light on several relationships between residues in the binding pocket and some of the conserved motifs. To achieve this, we took advantage of attention weights, and hidden states of the model that are interpreted to extract the extent of contributions of amino acids in dictating the type of masked ones. The fine-tuned models demonstrated high accuracy in predicting hidden residues within the motifs. In addition, the analysis of embedding was performed over 3D structures to elucidate the higher-order interactions within the conformations of the receptors.", "url": "https://arxiv.org/abs/2310.19915"}, {"metadata": {"arXiv": "2310.19932", "Date": "Mon, 30 Oct 2023 18:49:06 ", "Title": "Sim2Real for Environmental Neural Processes", "Authors": ["Jonas Scholz", "Tom R. Andersson", "Anna Vaughan", "James Requeima", "Richard E. Turner"], "Categories": "cs.LG physics.ao-ph", "Comments": ["4 pages", "3 figures", "To be published in Tackling Climate Change with Machine Learning workshop at NeurIPS"]}, "abstract": "Machine learning (ML)-based weather models have recently undergone rapid improvements. These models are typically trained on gridded reanalysis data from numerical data assimilation systems. However, reanalysis data comes with limitations, such as assumptions about physical laws and low spatiotemporal resolution. The gap between reanalysis and reality has sparked growing interest in training ML models directly on observations such as weather stations. Modelling scattered and sparse environmental observations requires scalable and flexible ML architectures, one of which is the convolutional conditional neural process (ConvCNP). ConvCNPs can learn to condition on both gridded and off-the-grid context data to make uncertainty-aware predictions at target locations. However, the sparsity of real observations presents a challenge for data-hungry deep learning models like the ConvCNP. One potential solution is 'Sim2Real': pre-training on reanalysis and fine-tuning on observational data. We analyse Sim2Real with a ConvCNP trained to interpolate surface air temperature over Germany, using varying numbers of weather stations for fine-tuning. On held-out weather stations, Sim2Real training substantially outperforms the same model architecture trained only with reanalysis data or only with station data, showing that reanalysis data can serve as a stepping stone for learning from real observations. Sim2Real could thus enable more accurate models for weather prediction and climate monitoring.", "url": "https://arxiv.org/abs/2310.19932"}, {"metadata": {"arXiv": "2310.19943", "Date": "Mon, 30 Oct 2023 18:58:03 ", "Title": "The Acquisition of Physical Knowledge in Generative Neural Networks", "Authors": ["Luca M. Schulze Buschoff", "Eric Schulz", "Marcel Binz"], "Categories": "cs.LG q-bio.NC", "Comments": ["Published as a conference paper at ICML 2023"]}, "abstract": "As children grow older, they develop an intuitive understanding of the physical processes around them. Their physical understanding develops in stages, moving along developmental trajectories which have been mapped out extensively in previous empirical research. Here, we investigate how the learning trajectories of deep generative neural networks compare to children's developmental trajectories using physical understanding as a testbed. We outline an approach that allows us to examine two distinct hypotheses of human development - stochastic optimization and complexity increase. We find that while our models are able to accurately predict a number of physical processes, their learning trajectories under both hypotheses do not follow the developmental trajectories of children.", "url": "https://arxiv.org/abs/2310.19943"}, {"metadata": {"arXiv": "2310.19958", "Date": "Mon, 30 Oct 2023 19:18:09 ", "Title": "PriPrune: Quantifying and Preserving Privacy in Pruned Federated Learning", "Authors": ["Tianyue Chu", "Mengwei Yang", "Nikolaos Laoutaris", "Athina Markopoulou"], "Categories": "cs.LG cs.CR cs.IT math.IT"}, "abstract": "Federated learning (FL) is a paradigm that allows several client devices and a server to collaboratively train a global model, by exchanging only model updates, without the devices sharing their local training data. These devices are often constrained in terms of communication and computation resources, and can further benefit from model pruning -- a paradigm that is widely used to reduce the size and complexity of models. Intuitively, by making local models coarser, pruning is expected to also provide some protection against privacy attacks in the context of FL. However this protection has not been previously characterized, formally or experimentally, and it is unclear if it is sufficient against state-of-the-art attacks. In this paper, we perform the first investigation of privacy guarantees for model pruning in FL. We derive information-theoretic upper bounds on the amount of information leaked by pruned FL models. We complement and validate these theoretical findings, with comprehensive experiments that involve state-of-the-art privacy attacks, on several state-of-the-art FL pruning schemes, using benchmark datasets. This evaluation provides valuable insights into the choices and parameters that can affect the privacy protection provided by pruning. Based on these insights, we introduce PriPrune -- a privacy-aware algorithm for local model pruning, which uses a personalized per-client defense mask and adapts the defense pruning rate so as to jointly optimize privacy and model performance. PriPrune is universal in that can be applied after any pruned FL scheme on the client, without modification, and protects against any inversion attack by the server. Our empirical evaluation demonstrates that PriPrune significantly improves the privacy-accuracy tradeoff compared to state-of-the-art pruned FL schemes that do not take privacy into account.", "url": "https://arxiv.org/abs/2310.19958"}, {"metadata": {"arXiv": "2310.19960", "Date": "Mon, 30 Oct 2023 19:20:48 ", "Title": "Topological Learning for Motion Data via Mixed Coordinates", "Authors": ["Hengrui Luo", "Jisu Kim", "Alice Patania", "Mikael Vejdemo-Johansson"], "Categories": "cs.LG math.AT stat.CO", "Comments": ["7 pages", "4 figures"], "Journal-ref": "2021 IEEE International Conference on Big Data (Big Data)", "DOI": "10.1109/BigData52589.2021.9671525"}, "abstract": "Topology can extract the structural information in a dataset efficiently. In this paper, we attempt to incorporate topological information into a multiple output Gaussian process model for transfer learning purposes. To achieve this goal, we extend the framework of circular coordinates into a novel framework of mixed valued coordinates to take linear trends in the time series into consideration. One of the major challenges to learn from multiple time series effectively via a multiple output Gaussian process model is constructing a functional kernel. We propose to use topologically induced clustering to construct a cluster based kernel in a multiple output Gaussian process model. This kernel not only incorporates the topological structural information, but also allows us to put forward a unified framework using topological information in time and motion series.", "url": "https://arxiv.org/abs/2310.19960"}, {"metadata": {"arXiv": "2310.19967", "Date": "Mon, 30 Oct 2023 19:30:00 ", "Title": "Early detection of inflammatory arthritis to improve referrals using multimodal machine learning from blood testing, semi-structured and unstructured patient records", "Authors": ["Bing Wang", "Weizi Li", "Anthony Bradlow", "Antoni T.Y. Chan", "Eghosa Bazuaye"], "Categories": "cs.LG", "Comments": ["Accepted in The 57th Hawaii International Conference on System Sciences", "3-6 Jan 2024", "Hawaii"]}, "abstract": "Early detection of inflammatory arthritis (IA) is critical to efficient and accurate hospital referral triage for timely treatment and preventing the deterioration of the IA disease course, especially under limited healthcare resources. The manual assessment process is the most common approach in practice for the early detection of IA, but it is extremely labor-intensive and inefficient. A large amount of clinical information needs to be assessed for every referral from General Practice (GP) to the hospitals. Machine learning shows great potential in automating repetitive assessment tasks and providing decision support for the early detection of IA. However, most machine learning-based methods for IA detection rely on blood testing results. But in practice, blood testing data is not always available at the point of referrals, so we need methods to leverage multimodal data such as semi-structured and unstructured data for early detection of IA. In this research, we present fusion and ensemble learning-based methods using multimodal data to assist decision-making in the early detection of IA. To the best of our knowledge, our study is the first attempt to utilize multimodal data to support the early detection of IA from GP referrals.", "url": "https://arxiv.org/abs/2310.19967"}, {"metadata": {"arXiv": "2310.19978", "Date": "Mon, 30 Oct 2023 19:52:43 ", "Title": "Scaling Up Differentially Private LASSO Regularized Logistic Regression via Faster Frank-Wolfe Iterations", "Authors": ["Edward Raff", "Amol Khanna", "Fred Lu"], "Categories": "cs.LG stat.CO stat.ML", "Comments": ["To appear in the 37th Conference on Neural Information Processing Systems (NeurIPS 2023)"]}, "abstract": "To the best of our knowledge, there are no methods today for training differentially private regression models on sparse input data. To remedy this, we adapt the Frank-Wolfe algorithm for $L_1$ penalized linear regression to be aware of sparse inputs and to use them effectively. In doing so, we reduce the training time of the algorithm from $\\mathcal{O}( T D S + T N S)$ to $\\mathcal{O}(N S + T \\sqrt{D} \\log{D} + T S^2)$, where $T$ is the number of iterations and a sparsity rate $S$ of a dataset with $N$ rows and $D$ features. Our results demonstrate that this procedure can reduce runtime by a factor of up to $2,200\\times$, depending on the value of the privacy parameter $\\epsilon$ and the sparsity of the dataset.", "url": "https://arxiv.org/abs/2310.19978"}, {"metadata": {"arXiv": "2310.19986", "Date": "Mon, 30 Oct 2023 20:04:50 ", "Title": "Addressing Weak Decision Boundaries in Image Classification by Leveraging Web Search and Generative Models", "Authors": ["Preetam Prabhu Srikar Dammu", "Yunhe Feng", "Chirag Shah"], "Categories": "cs.LG cs.CV", "Comments": ["Note: This is a copy of the copyrighted version published in IJCAI 2023 (DOI: https://doi.org/10.24963/ijcai.2023/659)"], "DOI": "10.24963/ijcai.2023/659"}, "abstract": "Machine learning (ML) technologies are known to be riddled with ethical and operational problems, however, we are witnessing an increasing thrust by businesses to deploy them in sensitive applications. One major issue among many is that ML models do not perform equally well for underrepresented groups. This puts vulnerable populations in an even disadvantaged and unfavorable position. We propose an approach that leverages the power of web search and generative models to alleviate some of the shortcomings of discriminative models. We demonstrate our method on an image classification problem using ImageNet's People Subtree subset, and show that it is effective in enhancing robustness and mitigating bias in certain classes that represent vulnerable populations (e.g., female doctor of color). Our new method is able to (1) identify weak decision boundaries for such classes; (2) construct search queries for Google as well as text for generating images through DALL-E 2 and Stable Diffusion; and (3) show how these newly captured training samples could alleviate population bias issue. While still improving the model's overall performance considerably, we achieve a significant reduction (77.30\\%) in the model's gender accuracy disparity. In addition to these improvements, we observed a notable enhancement in the classifier's decision boundary, as it is characterized by fewer weakspots and an increased separation between classes. Although we showcase our method on vulnerable populations in this study, the proposed technique is extendable to a wide range of problems and domains.", "url": "https://arxiv.org/abs/2310.19986"}, {"metadata": {"arXiv": "2310.19991", "Date": "Mon, 30 Oct 2023 20:19:41 ", "Title": "PolyThrottle: Energy-efficient Neural Network Inference on Edge Devices", "Authors": ["Minghao Yan", "Hongyi Wang", "Shivaram Venkataraman"], "Categories": "cs.LG cs.AR"}, "abstract": "As neural networks (NN) are deployed across diverse sectors, their energy demand correspondingly grows. While several prior works have focused on reducing energy consumption during training, the continuous operation of ML-powered systems leads to significant energy use during inference. This paper investigates how the configuration of on-device hardware-elements such as GPU, memory, and CPU frequency, often neglected in prior studies, affects energy consumption for NN inference with regular fine-tuning. We propose PolyThrottle, a solution that optimizes configurations across individual hardware components using Constrained Bayesian Optimization in an energy-conserving manner. Our empirical evaluation uncovers novel facets of the energy-performance equilibrium showing that we can save up to 36 percent of energy for popular models. We also validate that PolyThrottle can quickly converge towards near-optimal settings while satisfying application constraints.", "url": "https://arxiv.org/abs/2310.19991"}, {"metadata": {"arXiv": "2310.20030", "Date": "Mon, 30 Oct 2023 21:27:53 ", "Title": "Scaling Riemannian Diffusion Models", "Authors": ["Aaron Lou", "Minkai Xu", "Stefano Ermon"], "Categories": "cs.LG math.DG stat.ML", "Comments": ["NeurIPS 2023"]}, "abstract": "Riemannian diffusion models draw inspiration from standard Euclidean space diffusion models to learn distributions on general manifolds. Unfortunately, the additional geometric complexity renders the diffusion transition term inexpressible in closed form, so prior methods resort to imprecise approximations of the score matching training objective that degrade performance and preclude applications in high dimensions. In this work, we reexamine these approximations and propose several practical improvements. Our key observation is that most relevant manifolds are symmetric spaces, which are much more amenable to computation. By leveraging and combining various ans\\\"{a}tze, we can quickly compute relevant quantities to high precision. On low dimensional datasets, our correction produces a noticeable improvement, allowing diffusion to compete with other methods. Additionally, we show that our method enables us to scale to high dimensional tasks on nontrivial manifolds. In particular, we model QCD densities on $SU(n)$ lattices and contrastively learned embeddings on high dimensional hyperspheres.", "url": "https://arxiv.org/abs/2310.20030"}, {"metadata": {"arXiv": "2310.20051", "Date": "Mon, 30 Oct 2023 22:16:18 ", "Title": "The Expressibility of Polynomial based Attention Scheme", "Authors": ["Zhao Song", "Guangyi Xu", "Junze Yin"], "Categories": "cs.LG", "Comments": ["arXiv admin note: substantial text overlap with arXiv:2310.11685"]}, "abstract": "Large language models (LLMs) have significantly improved various aspects of our daily lives. These models have impacted numerous domains, from healthcare to education, enhancing productivity, decision-making processes, and accessibility. As a result, they have influenced and, to some extent, reshaped people's lifestyles. However, the quadratic complexity of attention in transformer architectures poses a challenge when scaling up these models for processing long textual contexts. This issue makes it impractical to train very large models on lengthy texts or use them efficiently during inference. While a recent study by [KMZ23] introduced a technique that replaces the softmax with a polynomial function and polynomial sketching to speed up attention mechanisms, the theoretical understandings of this new approach are not yet well understood. In this paper, we offer a theoretical analysis of the expressive capabilities of polynomial attention. Our study reveals a disparity in the ability of high-degree and low-degree polynomial attention. Specifically, we construct two carefully designed datasets, namely $\\mathcal{D}_0$ and $\\mathcal{D}_1$, where $\\mathcal{D}_1$ includes a feature with a significantly larger value compared to $\\mathcal{D}_0$. We demonstrate that with a sufficiently high degree $\\beta$, a single-layer polynomial attention network can distinguish between $\\mathcal{D}_0$ and $\\mathcal{D}_1$. However, with a low degree $\\beta$, the network cannot effectively separate the two datasets. This analysis underscores the greater effectiveness of high-degree polynomials in amplifying large values and distinguishing between datasets. Our analysis offers insight into the representational capacity of polynomial attention and provides a rationale for incorporating higher-degree polynomials in attention mechanisms to capture intricate linguistic correlations.", "url": "https://arxiv.org/abs/2310.20051"}, {"metadata": {"arXiv": "2310.20075", "Date": "Mon, 30 Oct 2023 23:15:27 ", "Title": "Meek Separators and Their Applications in Targeted Causal Discovery", "Authors": ["Kirankumar Shiragur and Jiaqi Zhang and Caroline Uhler"], "Categories": "cs.LG cs.DM stat.ME stat.ML"}, "abstract": "Learning causal structures from interventional data is a fundamental problem with broad applications across various fields. While many previous works have focused on recovering the entire causal graph, in practice, there are scenarios where learning only part of the causal graph suffices. This is called $targeted$ causal discovery. In our work, we focus on two such well-motivated problems: subset search and causal matching. We aim to minimize the number of interventions in both cases. Towards this, we introduce the $Meek~separator$, which is a subset of vertices that, when intervened, decomposes the remaining unoriented edges into smaller connected components. We then present an efficient algorithm to find Meek separators that are of small sizes. Such a procedure is helpful in designing various divide-and-conquer-based approaches. In particular, we propose two randomized algorithms that achieve logarithmic approximation for subset search and causal matching, respectively. Our results provide the first known average-case provable guarantees for both problems. We believe that this opens up possibilities to design near-optimal methods for many other targeted causal structure learning problems arising from various applications.", "url": "https://arxiv.org/abs/2310.20075"}, {"metadata": {"arXiv": "2310.20082", "Date": "Mon, 30 Oct 2023 23:41:05 ", "Title": "Efficient Subgraph GNNs by Learning Effective Selection Policies", "Authors": ["Beatrice Bevilacqua", "Moshe Eliasof", "Eli Meirom", "Bruno Ribeiro", "Haggai Maron"], "Categories": "cs.LG", "Comments": ["21 pages", "3 figures"]}, "abstract": "Subgraph GNNs are provably expressive neural architectures that learn graph representations from sets of subgraphs. Unfortunately, their applicability is hampered by the computational complexity associated with performing message passing on many subgraphs. In this paper, we consider the problem of learning to select a small subset of the large set of possible subgraphs in a data-driven fashion. We first motivate the problem by proving that there are families of WL-indistinguishable graphs for which there exist efficient subgraph selection policies: small subsets of subgraphs that can already identify all the graphs within the family. We then propose a new approach, called Policy-Learn, that learns how to select subgraphs in an iterative manner. We prove that, unlike popular random policies and prior work addressing the same problem, our architecture is able to learn the efficient policies mentioned above. Our experimental results demonstrate that Policy-Learn outperforms existing baselines across a wide range of datasets.", "url": "https://arxiv.org/abs/2310.20082"}, {"metadata": {"arXiv": "2310.20092", "Date": "Tue, 31 Oct 2023 00:12:14 ", "Title": "Beyond U: Making Diffusion Models Faster & Lighter", "Authors": ["Sergio Calvo-Ordonez", "Jiahao Huang", "Lipei Zhang", "Guang Yang", "Carola-Bibiane Schonlieb", "Angelica I Aviles-Rivero"], "Categories": "cs.LG cs.CV", "Comments": ["5 pages", "4 figures", "Neural Information Processing Systems (NeurIPS) 2023 Workshop on Diffusion Models"]}, "abstract": "Diffusion models are a family of generative models that yield record-breaking performance in tasks such as image synthesis, video generation, and molecule design. Despite their capabilities, their efficiency, especially in the reverse denoising process, remains a challenge due to slow convergence rates and high computational costs. In this work, we introduce an approach that leverages continuous dynamical systems to design a novel denoising network for diffusion models that is more parameter-efficient, exhibits faster convergence, and demonstrates increased noise robustness. Experimenting with denoising probabilistic diffusion models, our framework operates with approximately a quarter of the parameters and 30% of the Floating Point Operations (FLOPs) compared to standard U-Nets in Denoising Diffusion Probabilistic Models (DDPMs). Furthermore, our model is up to 70% faster in inference than the baseline models when measured in equal conditions while converging to better quality solutions.", "url": "https://arxiv.org/abs/2310.20092"}, {"metadata": {"arXiv": "2310.20098", "Date": "Tue, 31 Oct 2023 00:22:55 ", "Title": "Robust Learning for Smoothed Online Convex Optimization with Feedback Delay", "Authors": ["Pengfei Li", "Jianyi Yang", "Adam Wierman", "Shaolei Ren"], "Categories": "cs.LG cs.DS math.OC", "Comments": ["Accepted by NeurIPS 2023"]}, "abstract": "We study a challenging form of Smoothed Online Convex Optimization, a.k.a. SOCO, including multi-step nonlinear switching costs and feedback delay. We propose a novel machine learning (ML) augmented online algorithm, Robustness-Constrained Learning (RCL), which combines untrusted ML predictions with a trusted expert online algorithm via constrained projection to robustify the ML prediction. Specifically,we prove that RCL is able to guarantee$(1+\\lambda)$-competitiveness against any given expert for any$\\lambda>0$, while also explicitly training the ML model in a robustification-aware manner to improve the average-case performance. Importantly,RCL is the first ML-augmented algorithm with a provable robustness guarantee in the case of multi-step switching cost and feedback delay.We demonstrate the improvement of RCL in both robustness and average performance using battery management for electrifying transportationas a case study.", "url": "https://arxiv.org/abs/2310.20098"}, {"metadata": {"arXiv": "2310.20145", "Date": "Tue, 31 Oct 2023 03:29:31 ", "Title": "Efficient Robust Bayesian Optimization for Arbitrary Uncertain inputs", "Authors": ["Lin Yang", "Junlong Lyu", "Wenlong Lyu", "and Zhitang Chen"], "Categories": "cs.LG stat.ML"}, "abstract": "Bayesian Optimization (BO) is a sample-efficient optimization algorithm widely employed across various applications. In some challenging BO tasks, input uncertainty arises due to the inevitable randomness in the optimization process, such as machining errors, execution noise, or contextual variability. This uncertainty deviates the input from the intended value before evaluation, resulting in significant performance fluctuations in the final result. In this paper, we introduce a novel robust Bayesian Optimization algorithm, AIRBO, which can effectively identify a robust optimum that performs consistently well under arbitrary input uncertainty. Our method directly models the uncertain inputs of arbitrary distributions by empowering the Gaussian Process with the Maximum Mean Discrepancy (MMD) and further accelerates the posterior inference via Nystrom approximation. Rigorous theoretical regret bound is established under MMD estimation error and extensive experiments on synthetic functions and real problems demonstrate that our approach can handle various input uncertainties and achieve state-of-the-art performance.", "url": "https://arxiv.org/abs/2310.20145"}, {"metadata": {"arXiv": "2310.20168", "Date": "Tue, 31 Oct 2023 04:25:00 ", "Title": "Understanding and Visualizing Droplet Distributions in Simulations of Shallow Clouds", "Authors": ["Justus C. Will", "Andrea M. Jenney", "Kara D. Lamb", "Michael S. Pritchard", "Colleen Kaul", "Po-Lun Ma", "Kyle Pressel", "Jacob Shpund", "Marcus van Lier-Walqui", "Stephan Mandt"], "Categories": "cs.LG physics.ao-ph physics.flu-dyn", "Comments": ["4 pages", "3 figures", "accepted at NeurIPS 2023 (Machine Learning and the Physical Sciences Workshop)"]}, "abstract": "Thorough analysis of local droplet-level interactions is crucial to better understand the microphysical processes in clouds and their effect on the global climate. High-accuracy simulations of relevant droplet size distributions from Large Eddy Simulations (LES) of bin microphysics challenge current analysis techniques due to their high dimensionality involving three spatial dimensions, time, and a continuous range of droplet sizes. Utilizing the compact latent representations from Variational Autoencoders (VAEs), we produce novel and intuitive visualizations for the organization of droplet sizes and their evolution over time beyond what is possible with clustering techniques. This greatly improves interpretation and allows us to examine aerosol-cloud interactions by contrasting simulations with different aerosol concentrations. We find that the evolution of the droplet spectrum is similar across aerosol levels but occurs at different paces. This similarity suggests that precipitation initiation processes are alike despite variations in onset times.", "url": "https://arxiv.org/abs/2310.20168"}, {"metadata": {"arXiv": "2310.20193", "Date": "Tue, 31 Oct 2023 05:36:53 ", "Title": "FedRec+: Enhancing Privacy and Addressing Heterogeneity in Federated Recommendation Systems", "Authors": ["Lin Wang", "Zhichao Wang", "Xi Leng", "Xiaoying Tang"], "Categories": "cs.LG cs.CR cs.IR", "Comments": ["Accepted by 59th Annual Allerton Conference on Communication", "Control", "and Computing"]}, "abstract": "Preserving privacy and reducing communication costs for edge users pose significant challenges in recommendation systems. Although federated learning has proven effective in protecting privacy by avoiding data exchange between clients and servers, it has been shown that the server can infer user ratings based on updated non-zero gradients obtained from two consecutive rounds of user-uploaded gradients. Moreover, federated recommendation systems (FRS) face the challenge of heterogeneity, leading to decreased recommendation performance. In this paper, we propose FedRec+, an ensemble framework for FRS that enhances privacy while addressing the heterogeneity challenge. FedRec+ employs optimal subset selection based on feature similarity to generate near-optimal virtual ratings for pseudo items, utilizing only the user's local information. This approach reduces noise without incurring additional communication costs. Furthermore, we utilize the Wasserstein distance to estimate the heterogeneity and contribution of each client, and derive optimal aggregation weights by solving a defined optimization problem. Experimental results demonstrate the state-of-the-art performance of FedRec+ across various reference datasets.", "url": "https://arxiv.org/abs/2310.20193"}, {"metadata": {"arXiv": "2310.20203", "Date": "Tue, 31 Oct 2023 06:00:17 ", "Title": "Importance Estimation with Random Gradient for Neural Network Pruning", "Authors": ["Suman Sapkota", "Binod Bhattarai"], "Categories": "cs.LG", "Comments": ["7 pages", "2 figures", "ICLR 2023 Workshop on Sparsity in Neural Networks. arXiv admin note: text overlap with arXiv:2306.13203"]}, "abstract": "Global Neuron Importance Estimation is used to prune neural networks for efficiency reasons. To determine the global importance of each neuron or convolutional kernel, most of the existing methods either use activation or gradient information or both, which demands abundant labelled examples. In this work, we use heuristics to derive importance estimation similar to Taylor First Order (TaylorFO) approximation based methods. We name our methods TaylorFO-abs and TaylorFO-sq. We propose two additional methods to improve these importance estimation methods. Firstly, we propagate random gradients from the last layer of a network, thus avoiding the need for labelled examples. Secondly, we normalize the gradient magnitude of the last layer output before propagating, which allows all examples to contribute similarly to the importance score. Our methods with additional techniques perform better than previous methods when tested on ResNet and VGG architectures on CIFAR-100 and STL-10 datasets. Furthermore, our method also complements the existing methods and improves their performances when combined with them.", "url": "https://arxiv.org/abs/2310.20203"}, {"metadata": {"arXiv": "2310.20204", "Date": "Tue, 31 Oct 2023 06:04:18 ", "Title": "General-Purpose Retrieval-Enhanced Medical Prediction Model Using Near-Infinite History", "Authors": ["Junu Kim and Chaeeun Shim and Bosco Seong Kyu Yang and Chami Im and Sung Yoon Lim and Han-Gil Jeong and Edward Choi"], "Categories": "cs.LG cs.CL", "Comments": ["The source codes corresponding to this paper are available at: https://github.com/starmpcc/REMed"]}, "abstract": "Developing clinical prediction models (e.g., mortality prediction) based on electronic health records (EHRs) typically relies on expert opinion for feature selection and adjusting observation window size. This burdens experts and creates a bottleneck in the development process. We propose Retrieval-Enhanced Medical prediction model (REMed) to address such challenges. REMed can essentially evaluate an unlimited number of clinical events, select the relevant ones, and make predictions. This approach effectively eliminates the need for manual feature selection and enables an unrestricted observation window. We verified these properties through experiments on 27 clinical tasks and two independent cohorts from publicly available EHR datasets, where REMed outperformed other contemporary architectures that aim to handle as many events as possible. Notably, we found that the preferences of REMed align closely with those of medical experts. We expect our approach to significantly expedite the development of EHR prediction models by minimizing clinicians' need for manual involvement.", "url": "https://arxiv.org/abs/2310.20204"}, {"metadata": {"arXiv": "2310.20209", "Date": "Tue, 31 Oct 2023 06:17:23 ", "Title": "Network Contention-Aware Cluster Scheduling with Reinforcement Learning", "Authors": ["Junyeol Ryu", "Jeongyoon Eo"], "Categories": "cs.LG cs.DC"}, "abstract": "With continuous advances in deep learning, distributed training is becoming common in GPU clusters. Specifically, for emerging workloads with diverse amounts, ratios, and patterns of communication, we observe that network contention can significantly degrade training throughput. However, widely used scheduling policies often face limitations as they are agnostic to network contention between jobs. In this paper, we present a new approach to mitigate network contention in GPU clusters using reinforcement learning. We formulate GPU cluster scheduling as a reinforcement learning problem and opt to learn a network contention-aware scheduling policy that efficiently captures contention sensitivities and dynamically adapts scheduling decisions through continuous evaluation and improvement. We show that compared to widely used scheduling policies, our approach reduces average job completion time by up to 18.2\\% and effectively cuts the tail job completion time by up to 20.7\\% while allowing a preferable trade-off between average job completion time and resource utilization.", "url": "https://arxiv.org/abs/2310.20209"}, {"metadata": {"arXiv": "2310.20211", "Date": "Tue, 31 Oct 2023 06:19:40 ", "Title": "Calibration by Distribution Matching: Trainable Kernel Calibration Metrics", "Authors": ["Charles Marx", "Sofian Zalouk", "Stefano Ermon"], "Categories": "cs.LG stat.ML"}, "abstract": "Calibration ensures that probabilistic forecasts meaningfully capture uncertainty by requiring that predicted probabilities align with empirical frequencies. However, many existing calibration methods are specialized for post-hoc recalibration, which can worsen the sharpness of forecasts. Drawing on the insight that calibration can be viewed as a distribution matching task, we introduce kernel-based calibration metrics that unify and generalize popular forms of calibration for both classification and regression. These metrics admit differentiable sample estimates, making it easy to incorporate a calibration objective into empirical risk minimization. Furthermore, we provide intuitive mechanisms to tailor calibration metrics to a decision task, and enforce accurate loss estimation and no regret decisions. Our empirical evaluation demonstrates that employing these metrics as regularizers enhances calibration, sharpness, and decision-making across a range of regression and classification tasks, outperforming methods relying solely on post-hoc recalibration.", "url": "https://arxiv.org/abs/2310.20211"}, {"metadata": {"arXiv": "2310.20223", "Date": "Tue, 31 Oct 2023 06:52:56 ", "Title": "STDA-Meta: A Meta-Learning Framework for Few-Shot Traffic Prediction", "Authors": ["Maoxiang Sun", "Weilong Ding", "Tianpu Zhang", "Zijian Liu", "Mengda Xing"], "Categories": "cs.LG"}, "abstract": "As the development of cities, traffic congestion becomes an increasingly pressing issue, and traffic prediction is a classic method to relieve that issue. Traffic prediction is one specific application of spatio-temporal prediction learning, like taxi scheduling, weather prediction, and ship trajectory prediction. Against these problems, classical spatio-temporal prediction learning methods including deep learning, require large amounts of training data. In reality, some newly developed cities with insufficient sensors would not hold that assumption, and the data scarcity makes predictive performance worse. In such situation, the learning method on insufficient data is known as few-shot learning (FSL), and the FSL of traffic prediction remains challenges. On the one hand, graph structures' irregularity and dynamic nature of graphs cannot hold the performance of spatio-temporal learning method. On the other hand, conventional domain adaptation methods cannot work well on insufficient training data, when transferring knowledge from different domains to the intended target domain.To address these challenges, we propose a novel spatio-temporal domain adaptation (STDA) method that learns transferable spatio-temporal meta-knowledge from data-sufficient cities in an adversarial manner. This learned meta-knowledge can improve the prediction performance of data-scarce cities. Specifically, we train the STDA model using a Model-Agnostic Meta-Learning (MAML) based episode learning process, which is a model-agnostic meta-learning framework that enables the model to solve new learning tasks using only a small number of training samples. We conduct numerous experiments on four traffic prediction datasets, and our results show that the prediction performance of our model has improved by 7\\% compared to baseline models on the two metrics of MAE and RMSE.", "url": "https://arxiv.org/abs/2310.20223"}, {"metadata": {"arXiv": "2310.20258", "Date": "Tue, 31 Oct 2023 08:24:41 ", "Title": "Advancing Bayesian Optimization via Learning Correlated Latent Space", "Authors": ["Seunghun Lee", "Jaewon Chu", "Sihyeon Kim", "Juyeon Ko", "Hyunwoo J. Kim"], "Categories": "cs.LG"}, "abstract": "Bayesian optimization is a powerful method for optimizing black-box functions with limited function evaluations. Recent works have shown that optimization in a latent space through deep generative models such as variational autoencoders leads to effective and efficient Bayesian optimization for structured or discrete data. However, as the optimization does not take place in the input space, it leads to an inherent gap that results in potentially suboptimal solutions. To alleviate the discrepancy, we propose Correlated latent space Bayesian Optimization (CoBO), which focuses on learning correlated latent spaces characterized by a strong correlation between the distances in the latent space and the distances within the objective function. Specifically, our method introduces Lipschitz regularization, loss weighting, and trust region recoordination to minimize the inherent gap around the promising areas. We demonstrate the effectiveness of our approach on several optimization tasks in discrete data, such as molecule design and arithmetic expression fitting, and achieve high performance within a small budget.", "url": "https://arxiv.org/abs/2310.20258"}, {"metadata": {"arXiv": "2310.20285", "Date": "Tue, 31 Oct 2023 08:58:16 ", "Title": "Accelerating Generalized Linear Models by Trading off Computation for Uncertainty", "Authors": ["Lukas Tatzel", "Jonathan Wenger", "Frank Schneider", "Philipp Hennig"], "Categories": "cs.LG stat.ML", "Comments": ["Main text: 10 pages", "6 figures; Supplements: 13 pages", "2 figures"]}, "abstract": "Bayesian Generalized Linear Models (GLMs) define a flexible probabilistic framework to model categorical, ordinal and continuous data, and are widely used in practice. However, exact inference in GLMs is prohibitively expensive for large datasets, thus requiring approximations in practice. The resulting approximation error adversely impacts the reliability of the model and is not accounted for in the uncertainty of the prediction. In this work, we introduce a family of iterative methods that explicitly model this error. They are uniquely suited to parallel modern computing hardware, efficiently recycle computations, and compress information to reduce both the time and memory requirements for GLMs. As we demonstrate on a realistically large classification problem, our method significantly accelerates training by explicitly trading off reduced computation for increased uncertainty.", "url": "https://arxiv.org/abs/2310.20285"}, {"metadata": {"arXiv": "2310.20299", "Date": "Tue, 31 Oct 2023 09:11:12 ", "Title": "Verification of Neural Networks Local Differential Classification Privacy", "Authors": ["Roie Reshef", "Anan Kabaha", "Olga Seleznova", "and Dana Drachsler-Cohen"], "Categories": "cs.LG cs.CR cs.LO"}, "abstract": "Neural networks are susceptible to privacy attacks. To date, no verifier can reason about the privacy of individuals participating in the training set. We propose a new privacy property, called local differential classification privacy (LDCP), extending local robustness to a differential privacy setting suitable for black-box classifiers. Given a neighborhood of inputs, a classifier is LDCP if it classifies all inputs the same regardless of whether it is trained with the full dataset or whether any single entry is omitted. A naive algorithm is highly impractical because it involves training a very large number of networks and verifying local robustness of the given neighborhood separately for every network. We propose Sphynx, an algorithm that computes an abstraction of all networks, with a high probability, from a small set of networks, and verifies LDCP directly on the abstract network. The challenge is twofold: network parameters do not adhere to a known distribution probability, making it difficult to predict an abstraction, and predicting too large abstraction harms the verification. Our key idea is to transform the parameters into a distribution given by KDE, allowing to keep the over-approximation error small. To verify LDCP, we extend a MILP verifier to analyze an abstract network. Experimental results show that by training only 7% of the networks, Sphynx predicts an abstract network obtaining 93% verification accuracy and reducing the analysis time by $1.7\\cdot10^4$x.", "url": "https://arxiv.org/abs/2310.20299"}, {"metadata": {"arXiv": "2310.20363", "Date": "Tue, 31 Oct 2023 11:14:26 ", "Title": "CAFE: Conflict-Aware Feature-wise Explanations", "Authors": ["Adam Dejl", "Hamed Ayoobi", "Matthew Williams", "Francesca Toni"], "Categories": "cs.LG"}, "abstract": "Feature attribution methods are widely used to explain neural models by determining the influence of individual input features on the models' outputs. We propose a novel feature attribution method, CAFE (Conflict-Aware Feature-wise Explanations), that addresses three limitations of the existing methods: their disregard for the impact of conflicting features, their lack of consideration for the influence of bias terms, and an overly high sensitivity to local variations in the underpinning activation functions. Unlike other methods, CAFE provides safeguards against overestimating the effects of neuron inputs and separately traces positive and negative influences of input features and biases, resulting in enhanced robustness and increased ability to surface feature conflicts. We show experimentally that CAFE is better able to identify conflicting features on synthetic tabular data and exhibits the best overall fidelity on several real-world tabular datasets, while being highly computationally efficient.", "url": "https://arxiv.org/abs/2310.20363"}, {"metadata": {"arXiv": "2310.20366", "Date": "Tue, 31 Oct 2023 11:23:10 ", "Title": "Distil the informative essence of loop detector data set: Is network-level traffic forecasting hungry for more data?", "Authors": ["Guopeng Li", "Victor L. Knoop", "J.W.C.(Hans) van Lint"], "Categories": "cs.LG cs.SY eess.SY", "Comments": ["13 pages", "5 figures"]}, "abstract": "Network-level traffic condition forecasting has been intensively studied for decades. Although prediction accuracy has been continuously improved with emerging deep learning models and ever-expanding traffic data, traffic forecasting still faces many challenges in practice. These challenges include the robustness of data-driven models, the inherent unpredictability of traffic dynamics, and whether further improvement of traffic forecasting requires more sensor data. In this paper, we focus on this latter question and particularly on data from loop detectors. To answer this, we propose an uncertainty-aware traffic forecasting framework to explore how many samples of loop data are truly effective for training forecasting models. Firstly, the model design combines traffic flow theory with graph neural networks, ensuring the robustness of prediction and uncertainty quantification. Secondly, evidential learning is employed to quantify different sources of uncertainty in a single pass. The estimated uncertainty is used to \"distil\" the essence of the dataset that sufficiently covers the information content. Results from a case study of a highway network around Amsterdam show that, from 2018 to 2021, more than 80\\% of the data during daytime can be removed. The remaining 20\\% samples have equal prediction power for training models. This result suggests that indeed large traffic datasets can be subdivided into significantly smaller but equally informative datasets. From these findings, we conclude that the proposed methodology proves valuable in evaluating large traffic datasets' true information content. Further extensions, such as extracting smaller, spatially non-redundant datasets, are possible with this method.", "url": "https://arxiv.org/abs/2310.20366"}, {"metadata": {"arXiv": "2310.20369", "Date": "Tue, 31 Oct 2023 11:27:01 ", "Title": "Stability and Generalization of the Decentralized Stochastic Gradient Descent Ascent Algorithm", "Authors": ["Miaoxi Zhu", "Li Shen", "Bo Du", "Dacheng Tao"], "Categories": "cs.LG math.OC", "Comments": ["NeurIPS 2023"]}, "abstract": "The growing size of available data has attracted increasing interest in solving minimax problems in a decentralized manner for various machine learning tasks. Previous theoretical research has primarily focused on the convergence rate and communication complexity of decentralized minimax algorithms, with little attention given to their generalization. In this paper, we investigate the primal-dual generalization bound of the decentralized stochastic gradient descent ascent (D-SGDA) algorithm using the approach of algorithmic stability under both convex-concave and nonconvex-nonconcave settings. Our theory refines the algorithmic stability in a decentralized manner and demonstrates that the decentralized structure does not destroy the stability and generalization of D-SGDA, implying that it can generalize as well as the vanilla SGDA in certain situations. Our results analyze the impact of different topologies on the generalization bound of the D-SGDA algorithm beyond trivial factors such as sample sizes, learning rates, and iterations. We also evaluate the optimization error and balance it with the generalization gap to obtain the optimal population risk of D-SGDA in the convex-concave setting. Additionally, we perform several numerical experiments which validate our theoretical findings.", "url": "https://arxiv.org/abs/2310.20369"}, {"metadata": {"arXiv": "2310.20380", "Date": "Tue, 31 Oct 2023 11:38:26 ", "Title": "Dropout Strategy in Reinforcement Learning: Limiting the Surrogate Objective Variance in Policy Optimization Methods", "Authors": ["Zhengpeng Xie", "Changdong Yu", "Weizheng Qiao"], "Categories": "cs.LG"}, "abstract": "Policy-based reinforcement learning algorithms are widely used in various fields. Among them, mainstream policy optimization algorithms such as PPO and TRPO introduce importance sampling into reinforcement learning, which allows the reuse of historical data. However, this also results in high variance of the surrogate objective and indirectly affects the stability and convergence of the algorithm. In this paper, we first derived an upper bound of the variance of the surrogate objective, which can grow quadratically with the increase of the surrogate objective. Next, we proposed a dropout technique to avoid the excessive increase of the surrogate objective variance caused by importance sampling. Then, we introduced a general reinforcement learning framework applicable to mainstream policy optimization methods, and applied the dropout technique to the PPO algorithm to obtain the D-PPO variant. Finally, we conduct comparative experiments between D-PPO and PPO algorithms in the Atari 2600 environment, results show that D-PPO achieved significant performance improvements compared to PPO, and effectively limited the excessive increase of the surrogate objective variance during training.", "url": "https://arxiv.org/abs/2310.20380"}, {"metadata": {"arXiv": "2310.20425", "Date": "Tue, 31 Oct 2023 12:50:25 ", "Title": "Discussing the Spectrum of Physics-Enhanced Machine Learning via a Survey on Structural Mechanics Applications", "Authors": ["Marcus Haywood-Alexander", "Wei Liu", "Kiran Bacsa", "Zhilu Lai", "Eleni Chatzi"], "Categories": "cs.LG"}, "abstract": "The intersection of physics and machine learning has given rise to a paradigm that we refer to here as physics-enhanced machine learning (PEML), aiming to improve the capabilities and reduce the individual shortcomings of data- or physics-only methods. In this paper, the spectrum of physics-enhanced machine learning methods, expressed across the defining axes of physics and data, is discussed by engaging in a comprehensive exploration of its characteristics, usage, and motivations. In doing so, this paper offers a survey of recent applications and developments of PEML techniques, revealing the potency of PEML in addressing complex challenges. We further demonstrate application of select such schemes on the simple working example of a single-degree-of-freedom Duffing oscillator, which allows to highlight the individual characteristics and motivations of different `genres' of PEML approaches. To promote collaboration and transparency, and to provide practical examples for the reader, the code of these working examples is provided alongside this paper. As a foundational contribution, this paper underscores the significance of PEML in pushing the boundaries of scientific and engineering research, underpinned by the synergy of physical insights and machine learning capabilities.", "url": "https://arxiv.org/abs/2310.20425"}, {"metadata": {"arXiv": "2310.20457", "Date": "Tue, 31 Oct 2023 13:51:13 ", "Title": "FlexTrain: A Dynamic Training Framework for Heterogeneous Devices Environments", "Authors": ["Mert Unsal", "Ali Maatouk", "Antonio De Domenico", "Nicola Piovesan", "Fadhel Ayed"], "Categories": "cs.LG", "Comments": ["Workshop on Advancing Neural Network Training (WANT) at NeurIPS 2023"]}, "abstract": "As deep learning models become increasingly large, they pose significant challenges in heterogeneous devices environments. The size of deep learning models makes it difficult to deploy them on low-power or resource-constrained devices, leading to long inference times and high energy consumption. To address these challenges, we propose FlexTrain, a framework that accommodates the diverse storage and computational resources available on different devices during the training phase. FlexTrain enables efficient deployment of deep learning models, while respecting device constraints, minimizing communication costs, and ensuring seamless integration with diverse devices. We demonstrate the effectiveness of FlexTrain on the CIFAR-100 dataset, where a single global model trained with FlexTrain can be easily deployed on heterogeneous devices, saving training time and energy consumption. We also extend FlexTrain to the federated learning setting, showing that our approach outperforms standard federated learning benchmarks on both CIFAR-10 and CIFAR-100 datasets.", "url": "https://arxiv.org/abs/2310.20457"}, {"metadata": {"arXiv": "2310.20492", "Date": "Tue, 31 Oct 2023 14:32:08 ", "Title": "Log-based Anomaly Detection of Enterprise Software: An Empirical Study", "Authors": ["Nadun Wijesinghe (Calgary", "Canada)", "Hadi Hemmati (Toronto", "Canada)"], "Categories": "cs.LG cs.SE", "Comments": ["12 pages", "14 figures. Submitted to QRS 2023 - 23rd IEEE International Conference on Software Quality", "Reliability and Security"], "ACM-class": "I.5.2; I.5.1; I.5.4; I.2.7; I.2.6; D.2.5"}, "abstract": "Most enterprise applications use logging as a mechanism to diagnose anomalies, which could help with reducing system downtime. Anomaly detection using software execution logs has been explored in several prior studies, using both classical and deep neural network-based machine learning models. In recent years, the research has largely focused in using variations of sequence-based deep neural networks (e.g., Long-Short Term Memory and Transformer-based models) for log-based anomaly detection on open-source data. However, they have not been applied in industrial datasets, as often. In addition, the studied open-source datasets are typically very large in size with logging statements that do not change much over time, which may not be the case with a dataset from an industrial service that is relatively new. In this paper, we evaluate several state-of-the-art anomaly detection models on an industrial dataset from our research partner, which is much smaller and loosely structured than most large scale open-source benchmark datasets. Results show that while all models are capable of detecting anomalies, certain models are better suited for less-structured datasets. We also see that model effectiveness changes when a common data leak associated with a random train-test split in some prior work is removed. A qualitative study of the defects' characteristics identified by the developers on the industrial dataset further shows strengths and weaknesses of the models in detecting different types of anomalies. Finally, we explore the effect of limited training data by gradually increasing the training set size, to evaluate if the model effectiveness does depend on the training set size.", "url": "https://arxiv.org/abs/2310.20492"}, {"metadata": {"arXiv": "2310.20493", "Date": "Tue, 31 Oct 2023 14:32:54 ", "Title": "Requirement falsification for cyber-physical systems using generative models", "Authors": ["Jarkko Peltom\\\"aki and Ivan Porres"], "Categories": "cs.LG cs.SE", "Comments": ["38 pages", "5 figures", "10 tables"]}, "abstract": "We present the OGAN algorithm for automatic requirement falsification of cyber-physical systems. System inputs and output are represented as piecewise constant signals over time while requirements are expressed in signal temporal logic. OGAN can find inputs that are counterexamples for the safety of a system revealing design, software, or hardware defects before the system is taken into operation. The OGAN algorithm works by training a generative machine learning model to produce such counterexamples. It executes tests atomically and does not require any previous model of the system under test. We evaluate OGAN using the ARCH-COMP benchmark problems, and the experimental results show that generative models are a viable method for requirement falsification. OGAN can be applied to new systems with little effort, has few requirements for the system under test, and exhibits state-of-the-art CPS falsification efficiency and effectiveness.", "url": "https://arxiv.org/abs/2310.20493"}, {"metadata": {"arXiv": "2310.20496", "Date": "Tue, 31 Oct 2023 14:34:00 ", "Title": "BasisFormer: Attention-based Time Series Forecasting with Learnable and Interpretable Basis", "Authors": ["Zelin Ni and Hang Yu and Shizhan Liu and Jianguo Li and Weiyao Lin"], "Categories": "cs.LG", "Comments": ["NeurIPS 2023(poster)"]}, "abstract": "Bases have become an integral part of modern deep learning-based models for time series forecasting due to their ability to act as feature extractors or future references. To be effective, a basis must be tailored to the specific set of time series data and exhibit distinct correlation with each time series within the set. However, current state-of-the-art methods are limited in their ability to satisfy both of these requirements simultaneously. To address this challenge, we propose BasisFormer, an end-to-end time series forecasting architecture that leverages learnable and interpretable bases. This architecture comprises three components: First, we acquire bases through adaptive self-supervised learning, which treats the historical and future sections of the time series as two distinct views and employs contrastive learning. Next, we design a Coef module that calculates the similarity coefficients between the time series and bases in the historical view via bidirectional cross-attention. Finally, we present a Forecast module that selects and consolidates the bases in the future view based on the similarity coefficients, resulting in accurate future predictions. Through extensive experiments on six datasets, we demonstrate that BasisFormer outperforms previous state-of-the-art methods by 11.04\\% and 15.78\\% respectively for univariate and multivariate forecasting tasks. Code is available at: \\url{https://github.com/nzl5116190/Basisformer}", "url": "https://arxiv.org/abs/2310.20496"}, {"metadata": {"arXiv": "2310.20498", "Date": "Tue, 31 Oct 2023 14:37:37 ", "Title": "Generative Learning of Continuous Data by Tensor Networks", "Authors": ["Alex Meiburg", "Jing Chen", "Jacob Miller", "Rapha\\\"elle Tihon", "Guillaume Rabusseau and Alejandro Perdomo-Ortiz"], "Categories": "cs.LG cond-mat.stat-mech quant-ph stat.ML", "Comments": ["21 pages", "15 figures"]}, "abstract": "Beyond their origin in modeling many-body quantum systems, tensor networks have emerged as a promising class of models for solving machine learning problems, notably in unsupervised generative learning. While possessing many desirable features arising from their quantum-inspired nature, tensor network generative models have previously been largely restricted to binary or categorical data, limiting their utility in real-world modeling problems. We overcome this by introducing a new family of tensor network generative models for continuous data, which are capable of learning from distributions containing continuous random variables. We develop our method in the setting of matrix product states, first deriving a universal expressivity theorem proving the ability of this model family to approximate any reasonably smooth probability density function with arbitrary precision. We then benchmark the performance of this model on several synthetic and real-world datasets, finding that the model learns and generalizes well on distributions of continuous and discrete variables. We develop methods for modeling different data domains, and introduce a trainable compression layer which is found to increase model performance given limited memory or computational resources. Overall, our methods give important theoretical and empirical evidence of the efficacy of quantum-inspired methods for the rapidly growing field of generative learning.", "url": "https://arxiv.org/abs/2310.20498"}, {"metadata": {"arXiv": "2310.20524", "Date": "Tue, 31 Oct 2023 15:04:53 ", "Title": "Group-Feature (Sensor) Selection With Controlled Redundancy Using Neural Networks", "Authors": ["Aytijhya Saha and Nikhil R. Pal"], "Categories": "cs.LG"}, "abstract": "In this paper, we present a novel embedded feature selection method based on a Multi-layer Perceptron (MLP) network and generalize it for group-feature or sensor selection problems, which can control the level of redundancy among the selected features or groups. Additionally, we have generalized the group lasso penalty for feature selection to encompass a mechanism for selecting valuable group features while simultaneously maintaining a control over redundancy. We establish the monotonicity and convergence of the proposed algorithm, with a smoothed version of the penalty terms, under suitable assumptions. Experimental results on several benchmark datasets demonstrate the promising performance of the proposed methodology for both feature selection and group feature selection over some state-of-the-art methods.", "url": "https://arxiv.org/abs/2310.20524"}, {"metadata": {"arXiv": "2310.20545", "Date": "Tue, 31 Oct 2023 15:26:33 ", "Title": "Multi-task learning of convex combinations of forecasting models", "Authors": ["Giovanni Felici", "Antonio M. Sudoso"], "Categories": "cs.LG math.OC stat.ML"}, "abstract": "Forecast combination involves using multiple forecasts to create a single, more accurate prediction. Recently, feature-based forecasting has been employed to either select the most appropriate forecasting models or to learn the weights of their convex combination. In this paper, we present a multi-task learning methodology that simultaneously addresses both problems. This approach is implemented through a deep neural network with two branches: the regression branch, which learns the weights of various forecasting methods by minimizing the error of combined forecasts, and the classification branch, which selects forecasting methods with an emphasis on their diversity. To generate training labels for the classification task, we introduce an optimization-driven approach that identifies the most appropriate methods for a given time series. The proposed approach elicits the essential role of diversity in feature-based forecasting and highlights the interplay between model combination and model selection when learning forecasting ensembles. Experimental results on a large set of series from the M4 competition dataset show that our proposal enhances point forecast accuracy compared to state-of-the-art methods.", "url": "https://arxiv.org/abs/2310.20545"}, {"metadata": {"arXiv": "2310.20552", "Date": "Tue, 31 Oct 2023 15:34:59 ", "Title": "Privacy-preserving design of graph neural networks with applications to vertical federated learning", "Authors": ["Ruofan Wu", "Mingyang Zhang", "Lingjuan Lyu", "Xiaolong Xu", "Xiuquan Hao", "Xinyi Fu", "Tengfei Liu", "Tianyi Zhang", "Weiqiang Wang"], "Categories": "cs.LG cs.CR"}, "abstract": "The paradigm of vertical federated learning (VFL), where institutions collaboratively train machine learning models via combining each other's local feature or label information, has achieved great success in applications to financial risk management (FRM). The surging developments of graph representation learning (GRL) have opened up new opportunities for FRM applications under FL via efficiently utilizing the graph-structured data generated from underlying transaction networks. Meanwhile, transaction information is often considered highly sensitive. To prevent data leakage during training, it is critical to develop FL protocols with formal privacy guarantees. In this paper, we present an end-to-end GRL framework in the VFL setting called VESPER, which is built upon a general privatization scheme termed perturbed message passing (PMP) that allows the privatization of many popular graph neural architectures.Based on PMP, we discuss the strengths and weaknesses of specific design choices of concrete graph neural architectures and provide solutions and improvements for both dense and sparse graphs. Extensive empirical evaluations over both public datasets and an industry dataset demonstrate that VESPER is capable of training high-performance GNN models over both sparse and dense graphs under reasonable privacy budgets.", "url": "https://arxiv.org/abs/2310.20552"}, {"metadata": {"arXiv": "2310.20574", "Date": "Tue, 31 Oct 2023 16:08:38 ", "Title": "Information-Theoretic Trust Regions for Stochastic Gradient-Based Optimization", "Authors": ["Philipp Dahlinger", "Philipp Becker", "Maximilian H\\\"uttenrauch", "Gerhard Neumann"], "Categories": "cs.LG"}, "abstract": "Stochastic gradient-based optimization is crucial to optimize neural networks. While popular approaches heuristically adapt the step size and direction by rescaling gradients, a more principled approach to improve optimizers requires second-order information. Such methods precondition the gradient using the objective's Hessian. Yet, computing the Hessian is usually expensive and effectively using second-order information in the stochastic gradient setting is non-trivial. We propose using Information-Theoretic Trust Region Optimization (arTuRO) for improved updates with uncertain second-order information. By modeling the network parameters as a Gaussian distribution and using a Kullback-Leibler divergence-based trust region, our approach takes bounded steps accounting for the objective's curvature and uncertainty in the parameters. Before each update, it solves the trust region problem for an optimal step size, resulting in a more stable and faster optimization process. We approximate the diagonal elements of the Hessian from stochastic gradients using a simple recursive least squares approach, constructing a model of the expected Hessian over time using only first-order information. We show that arTuRO combines the fast convergence of adaptive moment-based optimization with the generalization capabilities of SGD.", "url": "https://arxiv.org/abs/2310.20574"}, {"metadata": {"arXiv": "2310.20581", "Date": "Tue, 31 Oct 2023 16:15:13 ", "Title": "Stochastic Gradient Descent for Gaussian Processes Done Right", "Authors": ["Jihao Andreas Lin", "Shreyas Padhy", "Javier Antor\\'an", "Austin Tripp", "Alexander Terenin", "Csaba Szepesv\\'ari", "Jos\\'e Miguel Hern\\'andez-Lobato", "David Janz"], "Categories": "cs.LG stat.ML"}, "abstract": "We study the optimisation problem associated with Gaussian process regression using squared loss. The most common approach to this problem is to apply an exact solver, such as conjugate gradient descent, either directly, or to a reduced-order version of the problem. Recently, driven by successes in deep learning, stochastic gradient descent has gained traction as an alternative. In this paper, we show that when done right$\\unicode{x2014}$by which we mean using specific insights from the optimisation and kernel communities$\\unicode{x2014}$this approach is highly effective. We thus introduce a particular stochastic dual gradient descent algorithm, that may be implemented with a few lines of code using any deep learning framework. We explain our design decisions by illustrating their advantage against alternatives with ablation studies and show that the new method is highly competitive. Our evaluations on standard regression benchmarks and a Bayesian optimisation task set our approach apart from preconditioned conjugate gradients, variational Gaussian process approximations, and a previous version of stochastic gradient descent for Gaussian processes. On a molecular binding affinity prediction task, our method places Gaussian process regression on par in terms of performance with state-of-the-art graph neural networks.", "url": "https://arxiv.org/abs/2310.20581"}, {"metadata": {"arXiv": "2310.20587", "Date": "Tue, 31 Oct 2023 16:24:17 ", "Title": "Unleashing the Power of Pre-trained Language Models for Offline Reinforcement Learning", "Authors": ["Ruizhe Shi", "Yuyao Liu", "Yanjie Ze", "Simon S. Du", "Huazhe Xu"], "Categories": "cs.LG", "Comments": ["19 pages", "9 tables"]}, "abstract": "Offline reinforcement learning (RL) aims to find a near-optimal policy using pre-collected datasets. In real-world scenarios, data collection could be costly and risky; therefore, offline RL becomes particularly challenging when the in-domain data is limited. Given recent advances in Large Language Models (LLMs) and their few-shot learning prowess, this paper introduces $\\textbf{La}$nguage Models for $\\textbf{Mo}$tion Control ($\\textbf{LaMo}$), a general framework based on Decision Transformers to effectively use pre-trained Language Models (LMs) for offline RL. Our framework highlights four crucial components: (1) Initializing Decision Transformers with sequentially pre-trained LMs, (2) employing the LoRA fine-tuning method, in contrast to full-weight fine-tuning, to combine the pre-trained knowledge from LMs and in-domain knowledge effectively, (3) using the non-linear MLP transformation instead of linear projections, to generate embeddings, and (4) integrating an auxiliary language prediction loss during fine-tuning to stabilize the LMs and retain their original abilities on languages. Empirical results indicate $\\textbf{LaMo}$ achieves state-of-the-art performance in sparse-reward tasks and closes the gap between value-based offline RL methods and decision transformers in dense-reward tasks. In particular, our method demonstrates superior performance in scenarios with limited data samples. Our project website is https://lamo2023.github.io", "url": "https://arxiv.org/abs/2310.20587"}, {"metadata": {"arXiv": "2310.20641", "Date": "Tue, 31 Oct 2023 17:11:29 ", "Title": "Performance Improvement in Multi-class Classification via Automated Hierarchy Generation and Exploitation through Extended LCPN Schemes", "Authors": ["Celal Alagoz"], "Categories": "cs.LG"}, "abstract": "Hierarchical classification (HC) plays a pivotal role in multi-class classification tasks, where objects are organized into a hierarchical structure. This study explores the performance of HC through a comprehensive analysis that encompasses both hierarchy generation and hierarchy exploitation. This analysis is particularly relevant in scenarios where a predefined hierarchy structure is not readily accessible. Notably, two novel hierarchy exploitation schemes, LCPN+ and LCPN+F, which extend the capabilities of LCPN and combine the strengths of global and local classification, have been introduced and evaluated alongside existing methods. The findings reveal the consistent superiority of LCPN+F, which outperforms other schemes across various datasets and scenarios. Moreover, this research emphasizes not only effectiveness but also efficiency, as LCPN+ and LCPN+F maintain runtime performance comparable to Flat Classification (FC). Additionally, this study underscores the importance of selecting the right hierarchy exploitation scheme to maximize classification performance. This work extends our understanding of HC and establishes a benchmark for future research, fostering advancements in multi-class classification methodologies.", "url": "https://arxiv.org/abs/2310.20641"}, {"metadata": {"arXiv": "2310.20673", "Date": "Tue, 31 Oct 2023 17:37:35 ", "Title": "Balancing Act: Constraining Disparate Impact in Sparse Models", "Authors": ["Meraj Hashemizadeh", "Juan Ramirez", "Rohan Sukumaran", "Golnoosh Farnadi", "Simon Lacoste-Julien", "Jose Gallego-Posada"], "Categories": "cs.LG cs.CY", "Comments": ["Code available at https://github.com/merajhashemi/Balancing_Act"]}, "abstract": "Model pruning is a popular approach to enable the deployment of large deep learning models on edge devices with restricted computational or storage capacities. Although sparse models achieve performance comparable to that of their dense counterparts at the level of the entire dataset, they exhibit high accuracy drops for some data sub-groups. Existing methods to mitigate this disparate impact induced by pruning (i) rely on surrogate metrics that address the problem indirectly and have limited interpretability; or (ii) scale poorly with the number of protected sub-groups in terms of computational cost. We propose a constrained optimization approach that $\\textit{directly addresses the disparate impact of pruning}$: our formulation bounds the accuracy change between the dense and sparse models, for each sub-group. This choice of constraints provides an interpretable success criterion to determine if a pruned model achieves acceptable disparity levels. Experimental results demonstrate that our technique scales reliably to problems involving large models and hundreds of protected sub-groups.", "url": "https://arxiv.org/abs/2310.20673"}, {"metadata": {"arXiv": "2310.20679", "Date": "Tue, 31 Oct 2023 17:45:39 ", "Title": "Latent Field Discovery In Interacting Dynamical Systems With Neural Fields", "Authors": ["Miltiadis Kofinas", "Erik J. Bekkers", "Naveen Shankar Nagaraja", "Efstratios Gavves"], "Categories": "cs.LG stat.ML", "Comments": ["NeurIPS 2023. https://github.com/mkofinas/aether"]}, "abstract": "Systems of interacting objects often evolve under the influence of field effects that govern their dynamics, yet previous works have abstracted away from such effects, and assume that systems evolve in a vacuum. In this work, we focus on discovering these fields, and infer them from the observed dynamics alone, without directly observing them. We theorize the presence of latent force fields, and propose neural fields to learn them. Since the observed dynamics constitute the net effect of local object interactions and global field effects, recently popularized equivariant networks are inapplicable, as they fail to capture global information. To address this, we propose to disentangle local object interactions -- which are $\\mathrm{SE}(n)$ equivariant and depend on relative states -- from external global field effects -- which depend on absolute states. We model interactions with equivariant graph networks, and combine them with neural fields in a novel graph network that integrates field forces. Our experiments show that we can accurately discover the underlying fields in charged particles settings, traffic scenes, and gravitational n-body problems, and effectively use them to learn the system and forecast future trajectories.", "url": "https://arxiv.org/abs/2310.20679"}, {"metadata": {"arXiv": "2310.20682", "Date": "Tue, 31 Oct 2023 17:48:22 ", "Title": "Compression with Exact Error Distribution for Federated Learning", "Authors": ["Mahmoud Hegazy", "R\\'emi Leluc", "Cheuk Ting Li", "Aymeric Dieuleveut"], "Categories": "cs.LG cs.IT math.IT"}, "abstract": "Compression schemes have been extensively used in Federated Learning (FL) to reduce the communication cost of distributed learning. While most approaches rely on a bounded variance assumption of the noise produced by the compressor, this paper investigates the use of compression and aggregation schemes that produce a specific error distribution, e.g., Gaussian or Laplace, on the aggregated data. We present and analyze different aggregation schemes based on layered quantizers achieving exact error distribution. We provide different methods to leverage the proposed compression schemes to obtain compression-for-free in differential privacy applications. Our general compression methods can recover and improve standard FL schemes with Gaussian perturbations such as Langevin dynamics and randomized smoothing.", "url": "https://arxiv.org/abs/2310.20682"}, {"metadata": {"arXiv": "2310.20705", "Date": "Tue, 31 Oct 2023 17:59:14 ", "Title": "Farthest Greedy Path Sampling for Two-shot Recommender Search", "Authors": ["Yufan Cao", "Tunhou Zhang", "Wei Wen", "Feng Yan", "Hai Li", "Yiran Chen"], "Categories": "cs.LG cs.IR", "Comments": ["9 pages", "5 figures"]}, "abstract": "Weight-sharing Neural Architecture Search (WS-NAS) provides an efficient mechanism for developing end-to-end deep recommender models. However, in complex search spaces, distinguishing between superior and inferior architectures (or paths) is challenging. This challenge is compounded by the limited coverage of the supernet and the co-adaptation of subnet weights, which restricts the exploration and exploitation capabilities inherent to weight-sharing mechanisms. To address these challenges, we introduce Farthest Greedy Path Sampling (FGPS), a new path sampling strategy that balances path quality and diversity. FGPS enhances path diversity to facilitate more comprehensive supernet exploration, while emphasizing path quality to ensure the effective identification and utilization of promising architectures. By incorporating FGPS into a Two-shot NAS (TS-NAS) framework, we derive high-performance architectures. Evaluations on three Click-Through Rate (CTR) prediction benchmarks demonstrate that our approach consistently achieves superior results, outperforming both manually designed and most NAS-based models.", "url": "https://arxiv.org/abs/2310.20705"}, {"metadata": {"arXiv": "2310.20708", "Date": "Tue, 31 Oct 2023 17:59:56 ", "Title": "Unexpected Improvements to Expected Improvement for Bayesian Optimization", "Authors": ["Sebastian Ament", "Samuel Daulton", "David Eriksson", "Maximilian Balandat", "Eytan Bakshy"], "Categories": "cs.LG cs.NA math.NA stat.ML", "Comments": ["NeurIPS 2023 Spotlight"]}, "abstract": "Expected Improvement (EI) is arguably the most popular acquisition function in Bayesian optimization and has found countless successful applications, but its performance is often exceeded by that of more recent methods. Notably, EI and its variants, including for the parallel and multi-objective settings, are challenging to optimize because their acquisition values vanish numerically in many regions. This difficulty generally increases as the number of observations, dimensionality of the search space, or the number of constraints grow, resulting in performance that is inconsistent across the literature and most often sub-optimal. Herein, we propose LogEI, a new family of acquisition functions whose members either have identical or approximately equal optima as their canonical counterparts, but are substantially easier to optimize numerically. We demonstrate that numerical pathologies manifest themselves in \"classic\" analytic EI, Expected Hypervolume Improvement (EHVI), as well as their constrained, noisy, and parallel variants, and propose corresponding reformulations that remedy these pathologies. Our empirical results show that members of the LogEI family of acquisition functions substantially improve on the optimization performance of their canonical counterparts and surprisingly, are on par with or exceed the performance of recent state-of-the-art acquisition functions, highlighting the understated role of numerical optimization in the literature.", "url": "https://arxiv.org/abs/2310.20708"}, {"metadata": {"arXiv": "2310.19938", "Date": "Mon, 30 Oct 2023 18:54:08 ", "Title": "Lyapunov-Based Dropout Deep Neural Network (Lb-DDNN) Controller", "Authors": ["Saiedeh Akbari", "Emily J. Griffis", "Omkar Sudhir Patil", "Warren E. Dixon"], "Categories": "eess.SY cs.LG cs.SY"}, "abstract": "Deep neural network (DNN)-based adaptive controllers can be used to compensate for unstructured uncertainties in nonlinear dynamic systems. However, DNNs are also very susceptible to overfitting and co-adaptation. Dropout regularization is an approach where nodes are randomly dropped during training to alleviate issues such as overfitting and co-adaptation. In this paper, a dropout DNN-based adaptive controller is developed. The developed dropout technique allows the deactivation of weights that are stochastically selected for each individual layer within the DNN. Simultaneously, a Lyapunov-based real-time weight adaptation law is introduced to update the weights of all layers of the DNN for online unsupervised learning. A non-smooth Lyapunov-based stability analysis is performed to ensure asymptotic convergence of the tracking error. Simulation results of the developed dropout DNN-based adaptive controller indicate a 38.32% improvement in the tracking error, a 53.67% improvement in the function approximation error, and 50.44% lower control effort when compared to a baseline adaptive DNN-based controller without dropout regularization.", "url": "https://arxiv.org/abs/2310.19938"}, {"metadata": {"arXiv": "2310.20567", "Date": "Tue, 31 Oct 2023 15:56:17 ", "Title": "One-shot backpropagation for multi-step prediction in physics-based system identification", "Authors": ["Cesare Donati", "Martina Mammarella", "Fabrizio Dabbene", "Carlo Novara", "Constantino Lagoa"], "Categories": "eess.SY cs.LG cs.SY"}, "abstract": "The aim of this paper is to present a novel general framework for the identification of possibly interconnected systems, while preserving their physical properties and providing accuracy in multi-step prediction. An analytical and recursive algorithm for the gradient computation of the multi-step loss function based on backpropagation is introduced, providing physical and structural insight directly into the learning algorithm. As a case study, the proposed approach is tested for estimating the inertia matrix of a space debris starting from state observations.", "url": "https://arxiv.org/abs/2310.20567"}, {"metadata": {"arXiv": "2310.19834", "Date": "Sun, 29 Oct 2023 13:07:33 ", "Title": "AMIR: Automated MisInformation Rebuttal -- A COVID-19 Vaccination Datasets based Recommendation System", "Authors": ["Shakshi Sharma", "Anwitaman Datta", "and Rajesh Sharma"], "Categories": "cs.AI"}, "abstract": "Misinformation has emerged as a major societal threat in recent years in general; specifically in the context of the COVID-19 pandemic, it has wrecked havoc, for instance, by fuelling vaccine hesitancy. Cost-effective, scalable solutions for combating misinformation are the need of the hour. This work explored how existing information obtained from social media and augmented with more curated fact checked data repositories can be harnessed to facilitate automated rebuttal of misinformation at scale. While the ideas herein can be generalized and reapplied in the broader context of misinformation mitigation using a multitude of information sources and catering to the spectrum of social media platforms, this work serves as a proof of concept, and as such, it is confined in its scope to only rebuttal of tweets, and in the specific context of misinformation regarding COVID-19. It leverages two publicly available datasets, viz. FaCov (fact-checked articles) and misleading (social media Twitter) data on COVID-19 Vaccination.", "url": "https://arxiv.org/abs/2310.19834"}, {"metadata": {"arXiv": "2310.19852", "Date": "Mon, 30 Oct 2023 15:52:15 ", "Title": "AI Alignment: A Comprehensive Survey", "Authors": ["Jiaming Ji", "Tianyi Qiu", "Boyuan Chen", "Borong Zhang", "Hantao Lou", "Kaile Wang", "Yawen Duan", "Zhonghao He", "Jiayi Zhou", "Zhaowei Zhang", "Fanzhi Zeng", "Kwan Yee Ng", "Juntao Dai", "Xuehai Pan", "Aidan O'Gara", "Yingshan Lei", "Hua Xu", "Brian Tse", "Jie Fu", "Stephen McAleer", "Yaodong Yang", "Yizhou Wang", "Song-Chun Zhu", "Yike Guo", "Wen Gao"], "Categories": "cs.AI", "Comments": ["Continually updated; 55 pages (excluding references)", "802 citations. Abstract on arXiv webpage is abridged"]}, "abstract": "AI alignment aims to build AI systems that are in accordance with human intentions and values. With the emergence of AI systems possessing superhuman capabilities, the potential large-scale risks associated with misaligned systems become apparent. Hundreds of AI experts and public figures have expressed their concerns about AI risks, arguing that mitigating the risk of extinction from AI should be a global priority, alongside other societal-scale risks such as pandemics and nuclear war. Motivated by the lack of an up-to-date systematic survey on AI alignment, in this paper, we delve into the core concepts, methodology, and practice of alignment research. To begin with, we identify four principles as the key objectives of AI alignment: Robustness, Interpretability, Controllability, and Ethicality (RICE). We outline the landscape of current alignment research and decompose them into two key components: forward alignment and backward alignment. The former aims to make AI systems aligned via alignment training, while the latter aims to gain evidence about the systems' alignment and govern them appropriately to avoid exacerbating misalignment risks. On forward alignment, we discuss how to conduct learning from various types of feedback (a.k.a., outer alignment) and how to overcome the distribution shift to avoid goal misgeneralization (a.k.a., inner alignment). On backward alignment, we discuss verification techniques that can tell the degree of value alignment for various AI systems deployed, which can further improve the assurance of forward alignment outcomes. Based on this, we also release a constantly updated website featuring tutorials, collections of papers, blogs, and other learning resources at https://www.alignmentsurvey.com.", "url": "https://arxiv.org/abs/2310.19852"}, {"metadata": {"arXiv": "2310.19902", "Date": "Mon, 30 Oct 2023 18:11:02 ", "Title": "Herd: Using multiple, smaller LLMs to match the performances of proprietary, large LLMs via an intelligent composer", "Authors": ["Surya Narayanan Hari", "Matt Thomson"], "Categories": "cs.AI"}, "abstract": "Currently, over a thousand LLMs exist that are multi-purpose and are capable of performing real world tasks, including Q&A, text summarization, content generation, etc. However, accessibility, scale and reliability of free models prevents them from being widely deployed in everyday use cases. To address the first two issues of access and scale, organisations such as HuggingFace have created model repositories where users have uploaded model weights and quantized versions of models trained using different paradigms, as well as model cards describing their training process. While some models report performance on commonly used benchmarks, not all do, and interpreting the real world impact of trading off performance on a benchmark for model deployment cost, is unclear. Here, we show that a herd of open source models can match or exceed the performance of proprietary models via an intelligent router. We show that a Herd of open source models is able to match the accuracy of ChatGPT, despite being composed of models that are effectively 2.5x smaller. We show that in cases where GPT is not able to answer the query, Herd is able to identify a model that can, at least 40% of the time.", "url": "https://arxiv.org/abs/2310.19902"}, {"metadata": {"arXiv": "2310.20008", "Date": "Mon, 30 Oct 2023 20:53:26 ", "Title": "Evolutionary Tabletop Game Design: A Case Study in the Risk Game", "Authors": ["Lana Bertoldo Rossato", "Leonardo Boaventura Bombardelli", "and Anderson Rocha Tavares"], "Categories": "cs.AI", "Comments": ["11 pages", "8 figures", "accepted for publication at the XXII Braziliam Simposium on Games and Digital Entertainment (SBGames 2023)"]}, "abstract": "Creating and evaluating games manually is an arduous and laborious task. Procedural content generation can aid by creating game artifacts, but usually not an entire game. Evolutionary game design, which combines evolutionary algorithms with automated playtesting, has been used to create novel board games with simple equipment; however, the original approach does not include complex tabletop games with dice, cards, and maps. This work proposes an extension of the approach for tabletop games, evaluating the process by generating variants of Risk, a military strategy game where players must conquer map territories to win. We achieved this using a genetic algorithm to evolve the chosen parameters, as well as a rules-based agent to test the games and a variety of quality criteria to evaluate the new variations generated. Our results show the creation of new variations of the original game with smaller maps, resulting in shorter matches. Also, the variants produce more balanced matches, maintaining the usual drama. We also identified limitations in the process, where, in many cases, where the objective function was correctly pursued, but the generated games were nearly trivial. This work paves the way towards promising research regarding the use of evolutionary game design beyond classic board games.", "url": "https://arxiv.org/abs/2310.20008"}, {"metadata": {"arXiv": "2310.20052", "Date": "Mon, 30 Oct 2023 22:16:26 ", "Title": "Look At Me, No Replay! SurpriseNet: Anomaly Detection Inspired Class Incremental Learning", "Authors": ["Anton Lee and Yaqian Zhang and Heitor Murilo Gomes and Albert Bifet and Bernhard Pfahringer"], "Categories": "cs.AI", "Journal-ref": "Proceedings of the 32nd ACM international conference on information and knowledge management, CIKM 2023, birmingham, united kingdom, october 21-25, 2023", "DOI": "10.1145/3583780.3615236"}, "abstract": "Continual learning aims to create artificial neural networks capable of accumulating knowledge and skills through incremental training on a sequence of tasks. The main challenge of continual learning is catastrophic interference, wherein new knowledge overrides or interferes with past knowledge, leading to forgetting. An associated issue is the problem of learning \"cross-task knowledge,\" where models fail to acquire and retain knowledge that helps differentiate classes across task boundaries. A common solution to both problems is \"replay,\" where a limited buffer of past instances is utilized to learn cross-task knowledge and mitigate catastrophic interference. However, a notable drawback of these methods is their tendency to overfit the limited replay buffer. In contrast, our proposed solution, SurpriseNet, addresses catastrophic interference by employing a parameter isolation method and learning cross-task knowledge using an auto-encoder inspired by anomaly detection. SurpriseNet is applicable to both structured and unstructured data, as it does not rely on image-specific inductive biases. We have conducted empirical experiments demonstrating the strengths of SurpriseNet on various traditional vision continual-learning benchmarks, as well as on structured data datasets. Source code made available at https://doi.org/10.5281/zenodo.8247906 and https://github.com/tachyonicClock/SurpriseNet-CIKM-23", "url": "https://arxiv.org/abs/2310.20052"}, {"metadata": {"arXiv": "2310.20054", "Date": "Mon, 30 Oct 2023 22:16:53 ", "Title": "Constrained Hierarchical Monte Carlo Belief-State Planning", "Authors": ["Arec Jamgochian", "Hugo Buurmeijer", "Kyle H. Wray", "Anthony Corso", "Mykel J. Kochenderfer"], "Categories": "cs.AI cs.RO", "Comments": ["Under review for the 2024 IEEE International Conference on Robotics and Automation (ICRA)"]}, "abstract": "Optimal plans in Constrained Partially Observable Markov Decision Processes (CPOMDPs) maximize reward objectives while satisfying hard cost constraints, generalizing safe planning under state and transition uncertainty. Unfortunately, online CPOMDP planning is extremely difficult in large or continuous problem domains. In many large robotic domains, hierarchical decomposition can simplify planning by using tools for low-level control given high-level action primitives (options). We introduce Constrained Options Belief Tree Search (COBeTS) to leverage this hierarchy and scale online search-based CPOMDP planning to large robotic problems. We show that if primitive option controllers are defined to satisfy assigned constraint budgets, then COBeTS will satisfy constraints anytime. Otherwise, COBeTS will guide the search towards a safe sequence of option primitives, and hierarchical monitoring can be used to achieve runtime safety. We demonstrate COBeTS in several safety-critical, constrained partially observable robotic domains, showing that it can plan successfully in continuous CPOMDPs while non-hierarchical baselines cannot.", "url": "https://arxiv.org/abs/2310.20054"}, {"metadata": {"arXiv": "2310.20059", "Date": "Mon, 30 Oct 2023 22:23:15 ", "Title": "Concept Alignment as a Prerequisite for Value Alignment", "Authors": ["Sunayana Rane", "Mark Ho", "Ilia Sucholutsky", "Thomas L. Griffiths"], "Categories": "cs.AI"}, "abstract": "Value alignment is essential for building AI systems that can safely and reliably interact with people. However, what a person values -- and is even capable of valuing -- depends on the concepts that they are currently using to understand and evaluate what happens in the world. The dependence of values on concepts means that concept alignment is a prerequisite for value alignment -- agents need to align their representation of a situation with that of humans in order to successfully align their values. Here, we formally analyze the concept alignment problem in the inverse reinforcement learning setting, show how neglecting concept alignment can lead to systematic value mis-alignment, and describe an approach that helps minimize such failure modes by jointly reasoning about a person's concepts and values. Additionally, we report experimental results with human participants showing that humans reason about the concepts used by an agent when acting intentionally, in line with our joint reasoning model.", "url": "https://arxiv.org/abs/2310.20059"}, {"metadata": {"arXiv": "2310.20104", "Date": "Tue, 31 Oct 2023 00:51:14 ", "Title": "Plagiarism and AI Assistance Misuse in Web Programming: Unfair Benefits and Characteristics", "Authors": ["Oscar Karnalim", "Hapnes Toba", "Meliana Christianti Johan", "Erico Darmawan Handoyo", "Yehezkiel David Setiawan", "Josephine Alvina Luwia"], "Categories": "cs.AI cs.CY", "Comments": ["Accepted at IEEE TALE 2023"]}, "abstract": "In programming education, plagiarism and misuse of artificial intelligence (AI) assistance are emerging issues. However, not many relevant studies are focused on web programming. We plan to develop automated tools to help instructors identify both misconducts. To fully understand the issues, we conducted a controlled experiment to observe the unfair benefits and the characteristics. We compared student performance in completing web programming tasks independently, with a submission to plagiarize, and with the help of AI assistance (ChatGPT). Our study shows that students who are involved in such misconducts get comparable test marks with less completion time. Plagiarized submissions are similar to the independent ones except in trivial aspects such as color and identifier names. AI-assisted submissions are more complex, making them less readable. Students believe AI assistance could be useful given proper acknowledgment of the use, although they are not convinced with readability and correctness of the solutions.", "url": "https://arxiv.org/abs/2310.20104"}, {"metadata": {"arXiv": "2310.20148", "Date": "Tue, 31 Oct 2023 03:31:09 ", "Title": "Decision-Making for Autonomous Vehicles with Interaction-Aware Behavioral Prediction and Social-Attention Neural Network", "Authors": ["Xiao Li", "Kaiwen Liu", "H. Eric Tseng", "Anouck Girard", "Ilya Kolmanovsky"], "Categories": "cs.AI cs.RO cs.SY eess.SY"}, "abstract": "Autonomous vehicles need to accomplish their tasks while interacting with human drivers in traffic. It is thus crucial to equip autonomous vehicles with artificial reasoning to better comprehend the intentions of the surrounding traffic, thereby facilitating the accomplishments of the tasks. In this work, we propose a behavioral model that encodes drivers' interacting intentions into latent social-psychological parameters. Leveraging a Bayesian filter, we develop a receding-horizon optimization-based controller for autonomous vehicle decision-making which accounts for the uncertainties in the interacting drivers' intentions. For online deployment, we design a neural network architecture based on the attention mechanism which imitates the behavioral model with online estimated parameter priors. We also propose a decision tree search algorithm to solve the decision-making problem online. The proposed behavioral model is then evaluated in terms of its capabilities for real-world trajectory prediction. We further conduct extensive evaluations of the proposed decision-making module, in forced highway merging scenarios, using both simulated environments and real-world traffic datasets. The results demonstrate that our algorithms can complete the forced merging tasks in various traffic conditions while ensuring driving safety.", "url": "https://arxiv.org/abs/2310.20148"}, {"metadata": {"arXiv": "2310.20162", "Date": "Tue, 31 Oct 2023 04:10:31 ", "Title": "Is Robustness Transferable across Languages in Multilingual Neural Machine Translation?", "Authors": ["Leiyu Pan", "Supryadi and Deyi Xiong"], "Categories": "cs.AI"}, "abstract": "Robustness, the ability of models to maintain performance in the face of perturbations, is critical for developing reliable NLP systems. Recent studies have shown promising results in improving the robustness of models through adversarial training and data augmentation. However, in machine translation, most of these studies have focused on bilingual machine translation with a single translation direction. In this paper, we investigate the transferability of robustness across different languages in multilingual neural machine translation. We propose a robustness transfer analysis protocol and conduct a series of experiments. In particular, we use character-, word-, and multi-level noises to attack the specific translation direction of the multilingual neural machine translation model and evaluate the robustness of other translation directions. Our findings demonstrate that the robustness gained in one translation direction can indeed transfer to other translation directions. Additionally, we empirically find scenarios where robustness to character-level noise and word-level noise is more likely to transfer.", "url": "https://arxiv.org/abs/2310.20162"}, {"metadata": {"arXiv": "2310.20174", "Date": "Tue, 31 Oct 2023 04:53:10 ", "Title": "GraphTransformers for Geospatial Forecasting", "Authors": ["Pallavi Banerjee", "Satyaki Chakraborty"], "Categories": "cs.AI"}, "abstract": "In this paper we introduce a novel framework for trajectory prediction of geospatial sequences using GraphTransformers. When viewed across several sequences, we observed that a graph structure automatically emerges between different geospatial points that is often not taken into account for such sequence modeling tasks. We show that by leveraging this graph structure explicitly, geospatial trajectory prediction can be significantly improved. Our GraphTransformer approach improves upon state-of-the-art Transformer based baseline significantly on HURDAT, a dataset where we are interested in predicting the trajectory of a hurricane on a 6 hourly basis.", "url": "https://arxiv.org/abs/2310.20174"}, {"metadata": {"arXiv": "2310.20199", "Date": "Tue, 31 Oct 2023 05:47:33 ", "Title": "In Search of Lost Online Test-time Adaptation: A Survey", "Authors": ["Zixin Wang", "Yadan Luo", "Liang Zheng", "Zhuoxiao Chen", "Sen Wang", "Zi Huang"], "Categories": "cs.AI"}, "abstract": "In this paper, we present a comprehensive survey on online test-time adaptation (OTTA), a paradigm focused on adapting machine learning models to novel data distributions upon batch arrival. Despite the proliferation of OTTA methods recently, the field is mired in issues like ambiguous settings, antiquated backbones, and inconsistent hyperparameter tuning, obfuscating the real challenges and making reproducibility elusive. For clarity and a rigorous comparison, we classify OTTA techniques into three primary categories and subject them to benchmarks using the potent Vision Transformer (ViT) backbone to discover genuinely effective strategies. Our benchmarks span not only conventional corrupted datasets such as CIFAR-10/100-C and ImageNet-C but also real-world shifts embodied in CIFAR-10.1 and CIFAR-10-Warehouse, encapsulating variations across search engines and synthesized data by diffusion models. To gauge efficiency in online scenarios, we introduce novel evaluation metrics, inclusive of FLOPs, shedding light on the trade-offs between adaptation accuracy and computational overhead. Our findings diverge from existing literature, indicating: (1) transformers exhibit heightened resilience to diverse domain shifts, (2) the efficacy of many OTTA methods hinges on ample batch sizes, and (3) stability in optimization and resistance to perturbations are critical during adaptation, especially when the batch size is 1. Motivated by these insights, we pointed out promising directions for future research. The source code will be made available.", "url": "https://arxiv.org/abs/2310.20199"}, {"metadata": {"arXiv": "2310.20216", "Date": "Tue, 31 Oct 2023 06:27:52 ", "Title": "Does GPT-4 Pass the Turing Test?", "Authors": ["Cameron Jones and Benjamin Bergen"], "Categories": "cs.AI cs.CL", "Comments": ["25 pages", "21 figures"]}, "abstract": "We evaluated GPT-4 in a public online Turing Test. The best-performing GPT-4 prompt passed in 41% of games, outperforming baselines set by ELIZA (27%) and GPT-3.5 (14%), but falling short of chance and the baseline set by human participants (63%). Participants' decisions were based mainly on linguistic style (35%) and socio-emotional traits (27%), supporting the idea that intelligence is not sufficient to pass the Turing Test. Participants' demographics, including education and familiarity with LLMs, did not predict detection rate, suggesting that even those who understand systems deeply and interact with them frequently may be susceptible to deception. Despite known limitations as a test of intelligence, we argue that the Turing Test continues to be relevant as an assessment of naturalistic communication and deception. AI models with the ability to masquerade as humans could have widespread societal consequences, and we analyse the effectiveness of different strategies and criteria for judging humanlikeness.", "url": "https://arxiv.org/abs/2310.20216"}, {"metadata": {"arXiv": "2310.20250", "Date": "Tue, 31 Oct 2023 08:13:21 ", "Title": "Diversified Node Sampling based Hierarchical Transformer Pooling for Graph Representation Learning", "Authors": ["Gaichao Li", "Jinsong Chen", "John E. Hopcroft", "Kun He"], "Categories": "cs.AI"}, "abstract": "Graph pooling methods have been widely used on downsampling graphs, achieving impressive results on multiple graph-level tasks like graph classification and graph generation. An important line called node dropping pooling aims at exploiting learnable scoring functions to drop nodes with comparatively lower significance scores. However, existing node dropping methods suffer from two limitations: (1) for each pooled node, these models struggle to capture long-range dependencies since they mainly take GNNs as the backbones; (2) pooling only the highest-scoring nodes tends to preserve similar nodes, thus discarding the affluent information of low-scoring nodes. To address these issues, we propose a Graph Transformer Pooling method termed GTPool, which introduces Transformer to node dropping pooling to efficiently capture long-range pairwise interactions and meanwhile sample nodes diversely. Specifically, we design a scoring module based on the self-attention mechanism that takes both global context and local context into consideration, measuring the importance of nodes more comprehensively. GTPool further utilizes a diversified sampling method named Roulette Wheel Sampling (RWS) that is able to flexibly preserve nodes across different scoring intervals instead of only higher scoring nodes. In this way, GTPool could effectively obtain long-range information and select more representative nodes. Extensive experiments on 11 benchmark datasets demonstrate the superiority of GTPool over existing popular graph pooling methods.", "url": "https://arxiv.org/abs/2310.20250"}, {"metadata": {"arXiv": "2310.20254", "Date": "Tue, 31 Oct 2023 08:16:22 ", "Title": "Artificial Intelligence for reverse engineering: application to detergents using Raman spectroscopy", "Authors": ["Pedro Marote (UCBL", "ISA)", "Marie Martin (UCBL", "ISA)", "Anne Bonhomme", "Pierre Lant\\'eri (ISA", "UCBL)", "Yohann Cl\\'ement"], "Categories": "cs.AI"}, "abstract": "The reverse engineering of a complex mixture, regardless of its nature, has become significant today. Being able to quickly assess the potential toxicity of new commercial products in relation to the environment presents a genuine analytical challenge. The development of digital tools (databases, chemometrics, machine learning, etc.) and analytical techniques (Raman spectroscopy, NIR spectroscopy, mass spectrometry, etc.) will allow for the identification of potential toxic molecules. In this article, we use the example of detergent products, whose composition can prove dangerous to humans or the environment, necessitating precise identification and quantification for quality control and regulation purposes. The combination of various digital tools (spectral database, mixture database, experimental design, Chemometrics / Machine Learning algorithm{\\ldots}) together with different sample preparation methods (raw sample, or several concentrated / diluted samples) Raman spectroscopy, has enabled the identification of the mixture's constituents and an estimation of its composition. Implementing such strategies across different analytical tools can result in time savings for pollutant identification and contamination assessment in various matrices. This strategy is also applicable in the industrial sector for product or raw material control, as well as for quality control purposes.", "url": "https://arxiv.org/abs/2310.20254"}, {"metadata": {"arXiv": "2310.20266", "Date": "Tue, 31 Oct 2023 08:36:41 ", "Title": "Beyond Average Return in Markov Decision Processes", "Authors": ["Alexandre Marthe (ENS de Lyon", "UMPA-ENSL)", "Aur\\'elien Garivier (UMPA-ENSL", "MC2)", "Claire Vernade"], "Categories": "cs.AI math.OC math.PR", "Comments": ["Neurips 2023", "Dec 2023", "New Orleans", "United States"]}, "abstract": "What are the functionals of the reward that can be computed and optimized exactly in Markov Decision Processes? In the finite-horizon, undiscounted setting, Dynamic Programming (DP) can only handle these operations efficiently for certain classes of statistics. We summarize the characterization of these classes for policy evaluation, and give a new answer for the planning problem. Interestingly, we prove that only generalized means can be optimized exactly, even in the more general framework of Distributional Reinforcement Learning (DistRL).DistRL permits, however, to evaluate other functionals approximately. We provide error bounds on the resulting estimators, and discuss the potential of this approach as well as its limitations.These results contribute to advancing the theory of Markov Decision Processes by examining overall characteristics of the return, and particularly risk-conscious strategies.", "url": "https://arxiv.org/abs/2310.20266"}, {"metadata": {"arXiv": "2310.20301", "Date": "Tue, 31 Oct 2023 09:15:35 ", "Title": "Revolutionizing Global Food Security: Empowering Resilience through Integrated AI Foundation Models and Data-Driven Solutions", "Authors": ["Mohamed R. Shoaib", "Heba M. Emara", "Jun Zhao"], "Categories": "cs.AI cs.CV"}, "abstract": "Food security, a global concern, necessitates precise and diverse data-driven solutions to address its multifaceted challenges. This paper explores the integration of AI foundation models across various food security applications, leveraging distinct data types, to overcome the limitations of current deep and machine learning methods. Specifically, we investigate their utilization in crop type mapping, cropland mapping, field delineation and crop yield prediction. By capitalizing on multispectral imagery, meteorological data, soil properties, historical records, and high-resolution satellite imagery, AI foundation models offer a versatile approach. The study demonstrates that AI foundation models enhance food security initiatives by providing accurate predictions, improving resource allocation, and supporting informed decision-making. These models serve as a transformative force in addressing global food security limitations, marking a significant leap toward a sustainable and secure food future.", "url": "https://arxiv.org/abs/2310.20301"}, {"metadata": {"arXiv": "2310.20327", "Date": "Tue, 31 Oct 2023 10:10:48 ", "Title": "Improving Entropy-Based Test-Time Adaptation from a Clustering View", "Authors": ["Guoliang Lin", "Hanjiang Lai", "Yan Pan", "Jian Yin"], "Categories": "cs.AI"}, "abstract": "Domain shift is a common problem in the realistic world, where training data and test data follow different data distributions. To deal with this problem, fully test-time adaptation (TTA) leverages the unlabeled data encountered during test time to adapt the model. In particular, Entropy-Based TTA (EBTTA) methods, which minimize the prediction's entropy on test samples, have shown great success. In this paper, we introduce a new perspective on the EBTTA, which interprets these methods from a view of clustering. It is an iterative algorithm: 1) in the assignment step, the forward process of the EBTTA models is the assignment of labels for these test samples, and 2) in the updating step, the backward process is the update of the model via the assigned samples. Based on the interpretation, we can gain a deeper understanding of EBTTA, where we show that the entropy loss would further increase the largest probability. Accordingly, we offer an alternative explanation that why existing EBTTA methods are sensitive to initial assignments, outliers, and batch size. This observation can guide us to put forward the improvement of EBTTA. We propose robust label assignment, weight adjustment, and gradient accumulation to alleviate the above problems. Experimental results demonstrate that our method can achieve consistent improvements on various datasets. Code is provided in the supplementary material.", "url": "https://arxiv.org/abs/2310.20327"}, {"metadata": {"arXiv": "2310.20357", "Date": "Tue, 31 Oct 2023 10:57:35 ", "Title": "Enhancing the Spatial Awareness Capability of Multi-Modal Large Language Model", "Authors": ["Yongqiang Zhao", "Zhenyu Li", "Zhi Jin", "Feng Zhang", "Haiyan Zhao", "Chengfeng Dou", "Zhengwei Tao", "Xinhai Xu", "Donghong Liu"], "Categories": "cs.AI cs.MM"}, "abstract": "The Multi-Modal Large Language Model (MLLM) refers to an extension of the Large Language Model (LLM) equipped with the capability to receive and infer multi-modal data. Spatial awareness stands as one of the crucial abilities of MLLM, encompassing diverse skills related to understanding spatial relationships among objects and between objects and the scene area. Industries such as autonomous driving, smart healthcare, robotics, virtual, and augmented reality heavily demand MLLM's spatial awareness capabilities. However, there exists a noticeable gap between the current spatial awareness capabilities of MLLM and the requirements set by human needs. To address this issue, this paper proposes using more precise spatial position information between objects to guide MLLM in providing more accurate responses to user-related inquiries. Specifically, for a particular multi-modal task, we utilize algorithms for acquiring geometric spatial information and scene graphs to obtain relevant geometric spatial information and scene details of objects involved in the query. Subsequently, based on this information, we direct MLLM to address spatial awareness-related queries posed by the user. Extensive experiments were conducted in benchmarks such as MME, MM-Vet, and other multi-modal large language models. The experimental results thoroughly confirm the efficacy of the proposed method in enhancing the spatial awareness tasks and associated tasks of MLLM.", "url": "https://arxiv.org/abs/2310.20357"}, {"metadata": {"arXiv": "2310.20401", "Date": "Tue, 31 Oct 2023 12:23:24 ", "Title": "Utilitarian Algorithm Configuration", "Authors": ["Devon R. Graham", "Kevin Leyton-Brown and Tim Roughgarden"], "Categories": "cs.AI"}, "abstract": "We present the first nontrivial procedure for configuring heuristic algorithms to maximize the utility provided to their end users while also offering theoretical guarantees about performance. Existing procedures seek configurations that minimize expected runtime. However, very recent theoretical work argues that expected runtime minimization fails to capture algorithm designers' preferences. Here we show that the utilitarian objective also confers significant algorithmic benefits. Intuitively, this is because mean runtime is dominated by extremely long runs even when they are incredibly rare; indeed, even when an algorithm never gives rise to such long runs, configuration procedures that provably minimize mean runtime must perform a huge number of experiments to demonstrate this fact. In contrast, utility is bounded and monotonically decreasing in runtime, allowing for meaningful empirical bounds on a configuration's performance. This paper builds on this idea to describe effective and theoretically sound configuration procedures. We prove upper bounds on the runtime of these procedures that are similar to theoretical lower bounds, while also demonstrating their performance empirically.", "url": "https://arxiv.org/abs/2310.20401"}, {"metadata": {"arXiv": "2310.20443", "Date": "Tue, 31 Oct 2023 13:24:28 ", "Title": "Ontologies for Models and Algorithms in Applied Mathematics and Related Disciplines", "Authors": ["Bj\\\"orn Schembera", "Frank W\\\"ubbeling", "Hendrik Kleikamp", "Christine Biedinger", "Jochen Fiedler", "Marco Reidelbach", "Aurela Shehu", "Burkhard Schmidt", "Thomas Koprucki", "Dorothea Iglezakis", "Dominik G\\\"oddeke"], "Categories": "cs.AI cs.DB cs.DL cs.IR", "Comments": ["Preprint of a Conference Paper to appear in the Proceeding of the 17th International Conference on Metadata and Semantics Research"], "ACM-class": "H.3; H.4; I.2.4"}, "abstract": "In applied mathematics and related disciplines, the modeling-simulation-optimization workflow is a prominent scheme, with mathematical models and numerical algorithms playing a crucial role. For these types of mathematical research data, the Mathematical Research Data Initiative has developed, merged and implemented ontologies and knowledge graphs. This contributes to making mathematical research data FAIR by introducing semantic technology and documenting the mathematical foundations accordingly. Using the concrete example of microfracture analysis of porous media, it is shown how the knowledge of the underlying mathematical model and the corresponding numerical algorithms for its solution can be represented by the ontologies.", "url": "https://arxiv.org/abs/2310.20443"}, {"metadata": {"arXiv": "2310.20444", "Date": "Tue, 31 Oct 2023 13:27:04 ", "Title": "Analyzing the Impact of Companies on AI Research Based on Publications", "Authors": ["Michael F\\\"arber", "Lazaros Tampakis"], "Categories": "cs.AI cs.DL cs.IR", "Comments": ["Published in Scientometrics"]}, "abstract": "Artificial Intelligence (AI) is one of the most momentous technologies of our time. Thus, it is of major importance to know which stakeholders influence AI research. Besides researchers at universities and colleges, researchers in companies have hardly been considered in this context. In this article, we consider how the influence of companies on AI research can be made measurable on the basis of scientific publishing activities. We compare academic- and company-authored AI publications published in the last decade and use scientometric data from multiple scholarly databases to look for differences across these groups and to disclose the top contributing organizations. While the vast majority of publications is still produced by academia, we find that the citation count an individual publication receives is significantly higher when it is (co-)authored by a company. Furthermore, using a variety of altmetric indicators, we notice that publications with company participation receive considerably more attention online. Finally, we place our analysis results in a broader context and present targeted recommendations to safeguard a harmonious balance between academia and industry in the realm of AI research.", "url": "https://arxiv.org/abs/2310.20444"}, {"metadata": {"arXiv": "2310.20463", "Date": "Tue, 31 Oct 2023 13:56:25 ", "Title": "Interpretable Neural PDE Solvers using Symbolic Frameworks", "Authors": ["Yolanne Yi Ran Lee"], "Categories": "cs.AI", "Comments": ["Accepted to the NeurIPS 2023 AI for Science Workshop. arXiv admin note: text overlap with arXiv:2310.19763"]}, "abstract": "Partial differential equations (PDEs) are ubiquitous in the world around us, modelling phenomena from heat and sound to quantum systems. Recent advances in deep learning have resulted in the development of powerful neural solvers; however, while these methods have demonstrated state-of-the-art performance in both accuracy and computational efficiency, a significant challenge remains in their interpretability. Most existing methodologies prioritize predictive accuracy over clarity in the underlying mechanisms driving the model's decisions. Interpretability is crucial for trustworthiness and broader applicability, especially in scientific and engineering domains where neural PDE solvers might see the most impact. In this context, a notable gap in current research is the integration of symbolic frameworks (such as symbolic regression) into these solvers. Symbolic frameworks have the potential to distill complex neural operations into human-readable mathematical expressions, bridging the divide between black-box predictions and solutions.", "url": "https://arxiv.org/abs/2310.20463"}, {"metadata": {"arXiv": "2310.20474", "Date": "Tue, 31 Oct 2023 14:08:07 ", "Title": "Critical Role of Artificially Intelligent Conversational Chatbot", "Authors": ["Seraj A. M. Mostafa", "Md Z. Islam", "Mohammad Z. Islam", "Fairose Jeehan", "Saujanna Jafreen", "Raihan U. Islam"], "Categories": "cs.AI", "Comments": ["Extended version of Conversation 2023 position paper"]}, "abstract": "Artificially intelligent chatbot, such as ChatGPT, represents a recent and powerful advancement in the AI domain. Users prefer them for obtaining quick and precise answers, avoiding the usual hassle of clicking through multiple links in traditional searches. ChatGPT's conversational approach makes it comfortable and accessible for finding answers quickly and in an organized manner. However, it is important to note that these chatbots have limitations, especially in terms of providing accurate answers as well as ethical concerns. In this study, we explore various scenarios involving ChatGPT's ethical implications within academic contexts, its limitations, and the potential misuse by specific user groups. To address these challenges, we propose architectural solutions aimed at preventing inappropriate use and promoting responsible AI interactions.", "url": "https://arxiv.org/abs/2310.20474"}, {"metadata": {"arXiv": "2310.20478", "Date": "Tue, 31 Oct 2023 14:11:37 ", "Title": "Unveiling Black-boxes: Explainable Deep Learning Models for Patent Classification", "Authors": ["Md Shajalal", "Sebastian Denef", "Md. Rezaul Karim", "Alexander Boden", "Gunnar Stevens"], "Categories": "cs.AI", "Comments": ["This is the pre-print of the submitted manuscript on the World Conference on eXplainable Artificial Intelligence (xAI2023)", "Lisbon", "Portugal. The published manuscript can be found here https://doi.org/10.1007/978-3-031-44067-0_24"], "DOI": "10.1007/978-3-031-44067-0_24"}, "abstract": "Recent technological advancements have led to a large number of patents in a diverse range of domains, making it challenging for human experts to analyze and manage. State-of-the-art methods for multi-label patent classification rely on deep neural networks (DNNs), which are complex and often considered black-boxes due to their opaque decision-making processes. In this paper, we propose a novel deep explainable patent classification framework by introducing layer-wise relevance propagation (LRP) to provide human-understandable explanations for predictions. We train several DNN models, including Bi-LSTM, CNN, and CNN-BiLSTM, and propagate the predictions backward from the output layer up to the input layer of the model to identify the relevance of words for individual predictions. Considering the relevance score, we then generate explanations by visualizing relevant words for the predicted patent class. Experimental results on two datasets comprising two-million patent texts demonstrate high performance in terms of various evaluation measures. The explanations generated for each prediction highlight important relevant words that align with the predicted class, making the prediction more understandable. Explainable systems have the potential to facilitate the adoption of complex AI-enabled methods for patent classification in real-world applications.", "url": "https://arxiv.org/abs/2310.20478"}, {"metadata": {"arXiv": "2310.20494", "Date": "Tue, 31 Oct 2023 14:33:30 ", "Title": "A Transformer-Based Model With Self-Distillation for Multimodal Emotion Recognition in Conversations", "Authors": ["Hui Ma", "Jian Wang", "Hongfei Lin", "Bo Zhang", "Yijia Zhang", "Bo Xu"], "Categories": "cs.AI cs.MM", "Comments": ["13 pages", "10 figures. Accepted by IEEE Transactions on Multimedia (TMM)"], "Journal-ref": "IEEE Transactions on Multimedia (Early Access), 27 April 2023", "DOI": "10.1109/TMM.2023.3271019"}, "abstract": "Emotion recognition in conversations (ERC), the task of recognizing the emotion of each utterance in a conversation, is crucial for building empathetic machines. Existing studies focus mainly on capturing context- and speaker-sensitive dependencies on the textual modality but ignore the significance of multimodal information. Different from emotion recognition in textual conversations, capturing intra- and inter-modal interactions between utterances, learning weights between different modalities, and enhancing modal representations play important roles in multimodal ERC. In this paper, we propose a transformer-based model with self-distillation (SDT) for the task. The transformer-based model captures intra- and inter-modal interactions by utilizing intra- and inter-modal transformers, and learns weights between modalities dynamically by designing a hierarchical gated fusion strategy. Furthermore, to learn more expressive modal representations, we treat soft labels of the proposed model as extra training supervision. Specifically, we introduce self-distillation to transfer knowledge of hard and soft labels from the proposed model to each modality. Experiments on IEMOCAP and MELD datasets demonstrate that SDT outperforms previous state-of-the-art baselines.", "url": "https://arxiv.org/abs/2310.20494"}, {"metadata": {"arXiv": "2310.20563", "Date": "Tue, 31 Oct 2023 15:53:14 ", "Title": "Taking control: Policies to address extinction risks from AI", "Authors": ["Andrea Miotti and Akash Wasil"], "Categories": "cs.AI"}, "abstract": "This paper provides policy recommendations to reduce extinction risks from advanced artificial intelligence (AI). First, we briefly provide background information about extinction risks from AI. Second, we argue that voluntary commitments from AI companies would be an inappropriate and insufficient response. Third, we describe three policy proposals that would meaningfully address the threats from advanced AI: (1) establishing a Multinational AGI Consortium to enable democratic oversight of advanced AI (MAGIC), (2) implementing a global cap on the amount of computing power used to train an AI system (global compute cap), and (3) requiring affirmative safety evaluations to ensure that risks are kept below acceptable levels (gating critical experiments). MAGIC would be a secure, safety-focused, internationally-governed institution responsible for reducing risks from advanced AI and performing research to safely harness the benefits of AI. MAGIC would also maintain emergency response infrastructure (kill switch) to swiftly halt AI development or withdraw model deployment in the event of an AI-related emergency. The global compute cap would end the corporate race toward dangerous AI systems while enabling the vast majority of AI innovation to continue unimpeded. Gating critical experiments would ensure that companies developing powerful AI systems are required to present affirmative evidence that these models keep extinction risks below an acceptable threshold. After describing these recommendations, we propose intermediate steps that the international community could take to implement these proposals and lay the groundwork for international coordination around advanced AI.", "url": "https://arxiv.org/abs/2310.20563"}, {"metadata": {"arXiv": "2310.19859", "Date": "Mon, 30 Oct 2023 17:58:19 ", "Title": "Res-Tuning: A Flexible and Efficient Tuning Paradigm via Unbinding Tuner from Backbone", "Authors": ["Zeyinzi Jiang", "Chaojie Mao", "Ziyuan Huang", "Ao Ma", "Yiliang Lv", "Yujun Shen", "Deli Zhao", "Jingren Zhou"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted to NeurIPS 2023"]}, "abstract": "Parameter-efficient tuning has become a trend in transferring large-scale foundation models to downstream applications. Existing methods typically embed some light-weight tuners into the backbone, where both the design and the learning of the tuners are highly dependent on the base model. This work offers a new tuning paradigm, dubbed Res-Tuning, which intentionally unbinds tuners from the backbone. With both theoretical and empirical evidence, we show that popular tuning approaches have their equivalent counterparts under our unbinding formulation, and hence can be integrated into our framework effortlessly. Thanks to the structural disentanglement, we manage to free the design of tuners from the network architecture, facilitating flexible combination of various tuning strategies. We further propose a memory-efficient variant of Res-Tuning, where the bypass i.e., formed by a sequence of tuners) is effectively detached from the main branch, such that the gradients are back-propagated only to the tuners but not to the backbone. Such a detachment also allows one-time backbone forward for multi-task inference. Extensive experiments on both discriminative and generative tasks demonstrate the superiority of our method over existing alternatives from the perspectives of efficacy and efficiency. Project page: $\\href{https://res-tuning.github.io/}{\\textit{https://res-tuning.github.io/}}$.", "url": "https://arxiv.org/abs/2310.19859"}, {"metadata": {"arXiv": "2310.20159", "Date": "Tue, 31 Oct 2023 03:54:11 ", "Title": "Language Guided Visual Question Answering: Elevate Your Multimodal Language Model Using Knowledge-Enriched Prompts", "Authors": ["Deepanway Ghosal", "Navonil Majumder", "Roy Ka-Wei Lee", "Rada Mihalcea", "Soujanya Poria"], "Categories": "cs.CV cs.AI"}, "abstract": "Visual question answering (VQA) is the task of answering questions about an image. The task assumes an understanding of both the image and the question to provide a natural language answer. VQA has gained popularity in recent years due to its potential applications in a wide range of fields, including robotics, education, and healthcare. In this paper, we focus on knowledge-augmented VQA, where answering the question requires commonsense knowledge, world knowledge, and reasoning about ideas and concepts not present in the image. We propose a multimodal framework that uses language guidance (LG) in the form of rationales, image captions, scene graphs, etc to answer questions more accurately. We benchmark our method on the multi-choice question-answering task of the A-OKVQA, Science-QA, VSR, and IconQA datasets using CLIP and BLIP models. We show that the use of language guidance is a simple but powerful and effective strategy for visual question answering. Our language guidance improves the performance of CLIP by 7.6% and BLIP-2 by 4.8% in the challenging A-OKVQA dataset. We also observe consistent improvement in performance on the Science-QA, VSR, and IconQA datasets when using the proposed language guidances. The implementation of LG-VQA is publicly available at https:// github.com/declare-lab/LG-VQA.", "url": "https://arxiv.org/abs/2310.20159"}, {"metadata": {"arXiv": "2310.20225", "Date": "Tue, 31 Oct 2023 06:56:51 ", "Title": "VisPercep: A Vision-Language Approach to Enhance Visual Perception for People with Blindness and Low Vision", "Authors": ["Yu Hao", "Fan Yang", "Hao Huang", "Shuaihang Yuan", "Sundeep Rangan", "John-Ross Rizzo", "Yao Wang", "Yi Fang"], "Categories": "cs.CV cs.AI"}, "abstract": "People with blindness and low vision (pBLV) encounter substantial challenges when it comes to comprehensive scene recognition and precise object identification in unfamiliar environments. Additionally, due to the vision loss, pBLV have difficulty in accessing and identifying potential tripping hazards on their own. In this paper, we present a pioneering approach that leverages a large vision-language model to enhance visual perception for pBLV, offering detailed and comprehensive descriptions of the surrounding environments and providing warnings about the potential risks. Our method begins by leveraging a large image tagging model (i.e., Recognize Anything (RAM)) to identify all common objects present in the captured images. The recognition results and user query are then integrated into a prompt, tailored specifically for pBLV using prompt engineering. By combining the prompt and input image, a large vision-language model (i.e., InstructBLIP) generates detailed and comprehensive descriptions of the environment and identifies potential risks in the environment by analyzing the environmental objects and scenes, relevant to the prompt. We evaluate our approach through experiments conducted on both indoor and outdoor datasets. Our results demonstrate that our method is able to recognize objects accurately and provide insightful descriptions and analysis of the environment for pBLV.", "url": "https://arxiv.org/abs/2310.20225"}, {"metadata": {"arXiv": "2310.20240", "Date": "Tue, 31 Oct 2023 07:47:19 ", "Title": "Breathing Life into Faces: Speech-driven 3D Facial Animation with Natural Head Pose and Detailed Shape", "Authors": ["Wei Zhao", "Yijun Wang", "Tianyu He", "Lianying Yin", "Jianxin Lin", "Xin Jin"], "Categories": "cs.CV cs.AI"}, "abstract": "The creation of lifelike speech-driven 3D facial animation requires a natural and precise synchronization between audio input and facial expressions. However, existing works still fail to render shapes with flexible head poses and natural facial details (e.g., wrinkles). This limitation is mainly due to two aspects: 1) Collecting training set with detailed 3D facial shapes is highly expensive. This scarcity of detailed shape annotations hinders the training of models with expressive facial animation. 2) Compared to mouth movement, the head pose is much less correlated to speech content. Consequently, concurrent modeling of both mouth movement and head pose yields the lack of facial movement controllability. To address these challenges, we introduce VividTalker, a new framework designed to facilitate speech-driven 3D facial animation characterized by flexible head pose and natural facial details. Specifically, we explicitly disentangle facial animation into head pose and mouth movement and encode them separately into discrete latent spaces. Then, these attributes are generated through an autoregressive process leveraging a window-based Transformer architecture. To augment the richness of 3D facial animation, we construct a new 3D dataset with detailed shapes and learn to synthesize facial details in line with speech content. Extensive quantitative and qualitative experiments demonstrate that VividTalker outperforms state-of-the-art methods, resulting in vivid and realistic speech-driven 3D facial animation.", "url": "https://arxiv.org/abs/2310.20240"}, {"metadata": {"arXiv": "2310.20268", "Date": "Tue, 31 Oct 2023 08:38:14 ", "Title": "Constructing Sample-to-Class Graph for Few-Shot Class-Incremental Learning", "Authors": ["Fuyuan Hu", "Jian Zhang", "Fan Lyu", "Linyan Li", "Fenglei Xu"], "Categories": "cs.CV cs.AI"}, "abstract": "Few-shot class-incremental learning (FSCIL) aims to build machine learning model that can continually learn new concepts from a few data samples, without forgetting knowledge of old classes. The challenges of FSCIL lies in the limited data of new classes, which not only lead to significant overfitting issues but also exacerbates the notorious catastrophic forgetting problems. As proved in early studies, building sample relationships is beneficial for learning from few-shot samples. In this paper, we promote the idea to the incremental scenario, and propose a Sample-to-Class (S2C) graph learning method for FSCIL. Specifically, we propose a Sample-level Graph Network (SGN) that focuses on analyzing sample relationships within a single session. This network helps aggregate similar samples, ultimately leading to the extraction of more refined class-level features. Then, we present a Class-level Graph Network (CGN) that establishes connections across class-level features of both new and old classes. This network plays a crucial role in linking the knowledge between different sessions and helps improve overall learning in the FSCIL scenario. Moreover, we design a multi-stage strategy for training S2C model, which mitigates the training challenges posed by limited data in the incremental process. The multi-stage training strategy is designed to build S2C graph from base to few-shot stages, and improve the capacity via an extra pseudo-incremental stage. Experiments on three popular benchmark datasets show that our method clearly outperforms the baselines and sets new state-of-the-art results in FSCIL.", "url": "https://arxiv.org/abs/2310.20268"}, {"metadata": {"arXiv": "2310.20323", "Date": "Tue, 31 Oct 2023 09:58:11 ", "Title": "SemanticBoost: Elevating Motion Generation with Augmented Textual Cues", "Authors": ["Xin He", "Shaoli Huang", "Xiaohang Zhan", "Chao Wen", "Ying Shan"], "Categories": "cs.CV cs.AI cs.GR cs.HC"}, "abstract": "Current techniques face difficulties in generating motions from intricate semantic descriptions, primarily due to insufficient semantic annotations in datasets and weak contextual understanding. To address these issues, we present SemanticBoost, a novel framework that tackles both challenges simultaneously. Our framework comprises a Semantic Enhancement module and a Context-Attuned Motion Denoiser (CAMD). The Semantic Enhancement module extracts supplementary semantics from motion data, enriching the dataset's textual description and ensuring precise alignment between text and motion data without depending on large language models. On the other hand, the CAMD approach provides an all-encompassing solution for generating high-quality, semantically consistent motion sequences by effectively capturing context information and aligning the generated motion with the given textual descriptions. Distinct from existing methods, our approach can synthesize accurate orientational movements, combined motions based on specific body part descriptions, and motions generated from complex, extended sentences. Our experimental results demonstrate that SemanticBoost, as a diffusion-based method, outperforms auto-regressive-based techniques, achieving cutting-edge performance on the Humanml3D dataset while maintaining realistic and smooth motion generation quality.", "url": "https://arxiv.org/abs/2310.20323"}, {"metadata": {"arXiv": "2310.20381", "Date": "Tue, 31 Oct 2023 11:39:09 ", "Title": "A Comprehensive Study of GPT-4V's Multimodal Capabilities in Medical Imaging", "Authors": ["Yingshu Li", "Yunyi Liu", "Zhanyu Wang", "Xinyu Liang", "Lingqiao Liu", "Lei Wang", "Leyang Cui", "Zhaopeng Tu", "Longyue Wang", "Luping Zhou"], "Categories": "cs.CV cs.AI"}, "abstract": "This paper presents a comprehensive evaluation of GPT-4V's capabilities across diverse medical imaging tasks, including Radiology Report Generation, Medical Visual Question Answering (VQA), and Visual Grounding. While prior efforts have explored GPT-4V's performance in medical imaging, to the best of our knowledge, our study represents the first quantitative evaluation on publicly available benchmarks. Our findings highlight GPT-4V's potential in generating descriptive reports for chest X-ray images, particularly when guided by well-structured prompts. However, its performance on the MIMIC-CXR dataset benchmark reveals areas for improvement in certain evaluation metrics, such as CIDEr. In the domain of Medical VQA, GPT-4V demonstrates proficiency in distinguishing between question types but falls short of prevailing benchmarks in terms of accuracy. Furthermore, our analysis finds the limitations of conventional evaluation metrics like the BLEU score, advocating for the development of more semantically robust assessment methods. In the field of Visual Grounding, GPT-4V exhibits preliminary promise in recognizing bounding boxes, but its precision is lacking, especially in identifying specific medical organs and signs. Our evaluation underscores the significant potential of GPT-4V in the medical imaging domain, while also emphasizing the need for targeted refinements to fully unlock its capabilities.", "url": "https://arxiv.org/abs/2310.20381"}, {"metadata": {"arXiv": "2310.20607", "Date": "Tue, 31 Oct 2023 16:43:03 ", "Title": "What a Whole Slide Image Can Tell? Subtype-guided Masked Transformer for Pathological Image Captioning", "Authors": ["Wenkang Qin", "Rui Xu", "Peixiang Huang", "Xiaomin Wu", "Heyu Zhang and Lin Luo"], "Categories": "cs.CV cs.AI"}, "abstract": "Pathological captioning of Whole Slide Images (WSIs), though is essential in computer-aided pathological diagnosis, has rarely been studied due to the limitations in datasets and model training efficacy. In this paper, we propose a new paradigm Subtype-guided Masked Transformer (SGMT) for pathological captioning based on Transformers, which treats a WSI as a sequence of sparse patches and generates an overall caption sentence from the sequence. An accompanying subtype prediction is introduced into SGMT to guide the training process and enhance the captioning accuracy. We also present an Asymmetric Masked Mechansim approach to tackle the large size constraint of pathological image captioning, where the numbers of sequencing patches in SGMT are sampled differently in the training and inferring phases, respectively. Experiments on the PatchGastricADC22 dataset demonstrate that our approach effectively adapts to the task with a transformer-based model and achieves superior performance than traditional RNN-based methods. Our codes are to be made available for further research and development.", "url": "https://arxiv.org/abs/2310.20607"}, {"metadata": {"arXiv": "2310.20638", "Date": "Tue, 31 Oct 2023 17:06:36 ", "Title": "Histopathological Image Analysis with Style-Augmented Feature Domain Mixing for Improved Generalization", "Authors": ["Vaibhav Khamankar", "Sutanu Bera", "Saumik Bhattacharya", "Debashis Sen", "and Prabir Kumar Biswas"], "Categories": "cs.CV cs.AI q-bio.TO", "Comments": ["Paper is published in MedAGI 2023 (MICCAI 2023 1st International Workshop on Foundation Models for General Medical AI) Code link: https://github.com/Vaibhav-Khamankar/FuseStyle Paper link: https://nbviewer.org/github/MedAGI/medagi.github.io/blob/main/src/assets/papers/P17.pdf"]}, "abstract": "Histopathological images are essential for medical diagnosis and treatment planning, but interpreting them accurately using machine learning can be challenging due to variations in tissue preparation, staining and imaging protocols. Domain generalization aims to address such limitations by enabling the learning models to generalize to new datasets or populations. Style transfer-based data augmentation is an emerging technique that can be used to improve the generalizability of machine learning models for histopathological images. However, existing style transfer-based methods can be computationally expensive, and they rely on artistic styles, which can negatively impact model accuracy. In this study, we propose a feature domain style mixing technique that uses adaptive instance normalization to generate style-augmented versions of images. We compare our proposed method with existing style transfer-based data augmentation methods and found that it performs similarly or better, despite requiring less computation and time. Our results demonstrate the potential of feature domain statistics mixing in the generalization of learning models for histopathological image analysis.", "url": "https://arxiv.org/abs/2310.20638"}, {"metadata": {"arXiv": "2310.20695", "Date": "Tue, 31 Oct 2023 17:56:11 ", "Title": "HAP: Structure-Aware Masked Image Modeling for Human-Centric Perception", "Authors": ["Junkun Yuan", "Xinyu Zhang", "Hao Zhou", "Jian Wang", "Zhongwei Qiu", "Zhiyin Shao", "Shaofeng Zhang", "Sifan Long", "Kun Kuang", "Kun Yao", "Junyu Han", "Errui Ding", "Lanfen Lin", "Fei Wu", "Jingdong Wang"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted by NeurIPS 2023"]}, "abstract": "Model pre-training is essential in human-centric perception. In this paper, we first introduce masked image modeling (MIM) as a pre-training approach for this task. Upon revisiting the MIM training strategy, we reveal that human structure priors offer significant potential. Motivated by this insight, we further incorporate an intuitive human structure prior - human parts - into pre-training. Specifically, we employ this prior to guide the mask sampling process. Image patches, corresponding to human part regions, have high priority to be masked out. This encourages the model to concentrate more on body structure information during pre-training, yielding substantial benefits across a range of human-centric perception tasks. To further capture human characteristics, we propose a structure-invariant alignment loss that enforces different masked views, guided by the human part prior, to be closely aligned for the same image. We term the entire method as HAP. HAP simply uses a plain ViT as the encoder yet establishes new state-of-the-art performance on 11 human-centric benchmarks, and on-par result on one dataset. For example, HAP achieves 78.1% mAP on MSMT17 for person re-identification, 86.54% mA on PA-100K for pedestrian attribute recognition, 78.2% AP on MS COCO for 2D pose estimation, and 56.0 PA-MPJPE on 3DPW for 3D pose and shape estimation.", "url": "https://arxiv.org/abs/2310.20695"}, {"metadata": {"arXiv": "2310.20704", "Date": "Tue, 31 Oct 2023 17:59:07 ", "Title": "Limited Data, Unlimited Potential: A Study on ViTs Augmented by Masked Autoencoders", "Authors": ["Srijan Das", "Tanmay Jain", "Dominick Reilly", "Pranav Balaji", "Soumyajit Karmakar", "Shyam Marjit", "Xiang Li", "Abhijit Das", "and Michael Ryoo"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted to WACV 2024"]}, "abstract": "Vision Transformers (ViTs) have become ubiquitous in computer vision. Despite their success, ViTs lack inductive biases, which can make it difficult to train them with limited data. To address this challenge, prior studies suggest training ViTs with self-supervised learning (SSL) and fine-tuning sequentially. However, we observe that jointly optimizing ViTs for the primary task and a Self-Supervised Auxiliary Task (SSAT) is surprisingly beneficial when the amount of training data is limited. We explore the appropriate SSL tasks that can be optimized alongside the primary task, the training schemes for these tasks, and the data scale at which they can be most effective. Our findings reveal that SSAT is a powerful technique that enables ViTs to leverage the unique characteristics of both the self-supervised and primary tasks, achieving better performance than typical ViTs pre-training with SSL and fine-tuning sequentially. Our experiments, conducted on 10 datasets, demonstrate that SSAT significantly improves ViT performance while reducing carbon footprint. We also confirm the effectiveness of SSAT in the video domain for deepfake detection, showcasing its generalizability. Our code is available at https://github.com/dominickrei/Limited-data-vits.", "url": "https://arxiv.org/abs/2310.20704"}, {"metadata": {"arXiv": "2310.20096", "Date": "Tue, 31 Oct 2023 00:21:09 ", "Title": "Data Market Design through Deep Learning", "Authors": ["Sai Srivatsa Ravindranath", "Yanchen Jiang", "David C. Parkes"], "Categories": "cs.GT cs.AI"}, "abstract": "The $\\textit{data market design}$ problem is a problem in economic theory to find a set of signaling schemes (statistical experiments) to maximize expected revenue to the information seller, where each experiment reveals some of the information known to a seller and has a corresponding price [Bergemann et al., 2018]. Each buyer has their own decision to make in a world environment, and their subjective expected value for the information associated with a particular experiment comes from the improvement in this decision and depends on their prior and value for different outcomes. In a setting with multiple buyers, a buyer's expected value for an experiment may also depend on the information sold to others [Bonatti et al., 2022]. We introduce the application of deep learning for the design of revenue-optimal data markets, looking to expand the frontiers of what can be understood and achieved. Relative to earlier work on deep learning for auction design [D\\\"utting et al., 2023], we must learn signaling schemes rather than allocation rules and handle $\\textit{obedience constraints}$ $-$ these arising from modeling the downstream actions of buyers $-$ in addition to incentive constraints on bids. Our experiments demonstrate that this new deep learning framework can almost precisely replicate all known solutions from theory, expand to more complex settings, and be used to establish the optimality of new designs for data markets and make conjectures in regard to the structure of optimal designs.", "url": "https://arxiv.org/abs/2310.20096"}, {"metadata": {"arXiv": "2310.20414", "Date": "Tue, 31 Oct 2023 12:40:46 ", "Title": "Meta Learning for Multi-View Visuomotor Systems", "Authors": ["Benji Alwis", "Nick Pears and Pengcheng Liu"], "Categories": "cs.RO cs.AI"}, "abstract": "This paper introduces a new approach for quickly adapting a multi-view visuomotor system for robots to varying camera configurations from the baseline setup. It utilises meta-learning to fine-tune the perceptual network while keeping the policy network fixed. Experimental results demonstrate a significant reduction in the number of new training episodes needed to attain baseline performance.", "url": "https://arxiv.org/abs/2310.20414"}, {"metadata": {"arXiv": "2310.19917", "Date": "Mon, 30 Oct 2023 18:29:15 ", "Title": "Unmasking Bias and Inequities: A Systematic Review of Bias Detection and Mitigation in Healthcare Artificial Intelligence Using Electronic Health Records", "Authors": ["Feng Chen", "Liqin Wang", "Julie Hong", "Jiaqi Jiang", "Li Zhou"], "Categories": "cs.AI cs.CY cs.LG q-bio.QM", "Comments": ["29 pages", "2 figures", "2 tables", "2 supplementary files", "66 references"]}, "abstract": "Objectives: Artificial intelligence (AI) applications utilizing electronic health records (EHRs) have gained popularity, but they also introduce various types of bias. This study aims to systematically review the literature that address bias in AI research utilizing EHR data. Methods: A systematic review was conducted following the Preferred Reporting Items for Systematic Reviews and Meta-analyses (PRISMA) guideline. We retrieved articles published between January 1, 2010, and October 31, 2022, from PubMed, Web of Science, and the Institute of Electrical and Electronics Engineers. We defined six major types of bias and summarized the existing approaches in bias handling. Results: Out of the 252 retrieved articles, 20 met the inclusion criteria for the final review. Five out of six bias were covered in this review: eight studies analyzed selection bias; six on implicit bias; five on confounding bias; four on measurement bias; two on algorithmic bias. For bias handling approaches, ten studies identified bias during model development, while seventeen presented methods to mitigate the bias. Discussion: Bias may infiltrate the AI application development process at various stages. Although this review discusses methods for addressing bias at different development stages, there is room for implementing additional effective approaches. Conclusion: Despite growing attention to bias in healthcare AI, research using EHR data on this topic is still limited. Detecting and mitigating AI bias with EHR data continues to pose challenges. Further research is needed to raise a standardized method that is generalizable and interpretable to detect, mitigate and evaluate bias in medical AI.", "url": "https://arxiv.org/abs/2310.19917"}, {"metadata": {"arXiv": "2310.19990", "Date": "Mon, 30 Oct 2023 20:16:42 ", "Title": "Unveiling the Limits of Learned Local Search Heuristics: Are You the Mightiest of the Meek?", "Authors": ["Ankur Nath", "Alan Kuhnle"], "Categories": "cs.AI cs.LG"}, "abstract": "In recent years, combining neural networks with local search heuristics has become popular in the field of combinatorial optimization. Despite its considerable computational demands, this approach has exhibited promising outcomes with minimal manual engineering. However, we have identified three critical limitations in the empirical evaluation of these integration attempts. Firstly, instances with moderate complexity and weak baselines pose a challenge in accurately evaluating the effectiveness of learning-based approaches. Secondly, the absence of an ablation study makes it difficult to quantify and attribute improvements accurately to the deep learning architecture. Lastly, the generalization of learned heuristics across diverse distributions remains underexplored. In this study, we conduct a comprehensive investigation into these identified limitations. Surprisingly, we demonstrate that a simple learned heuristic based on Tabu Search surpasses state-of-the-art (SOTA) learned heuristics in terms of performance and generalizability. Our findings challenge prevailing assumptions and open up exciting avenues for future research and innovation in combinatorial optimization.", "url": "https://arxiv.org/abs/2310.19990"}, {"metadata": {"arXiv": "2310.20071", "Date": "Mon, 30 Oct 2023 22:55:29 ", "Title": "FOCAL: Contrastive Learning for Multimodal Time-Series Sensing Signals in Factorized Orthogonal Latent Space", "Authors": ["Shengzhong Liu", "Tomoyoshi Kimura", "Dongxin Liu", "Ruijie Wang", "Jinyang Li", "Suhas Diggavi", "Mani Srivastava", "Tarek Abdelzaher"], "Categories": "cs.AI cs.LG cs.MM", "Comments": ["Code available at: [github](https://github.com/tomoyoshki/focal)"]}, "abstract": "This paper proposes a novel contrastive learning framework, called FOCAL, for extracting comprehensive features from multimodal time-series sensing signals through self-supervised training. Existing multimodal contrastive frameworks mostly rely on the shared information between sensory modalities, but do not explicitly consider the exclusive modality information that could be critical to understanding the underlying sensing physics. Besides, contrastive frameworks for time series have not handled the temporal information locality appropriately. FOCAL solves these challenges by making the following contributions: First, given multimodal time series, it encodes each modality into a factorized latent space consisting of shared features and private features that are orthogonal to each other. The shared space emphasizes feature patterns consistent across sensory modalities through a modal-matching objective. In contrast, the private space extracts modality-exclusive information through a transformation-invariant objective. Second, we propose a temporal structural constraint for modality features, such that the average distance between temporally neighboring samples is no larger than that of temporally distant samples. Extensive evaluations are performed on four multimodal sensing datasets with two backbone encoders and two classifiers to demonstrate the superiority of FOCAL. It consistently outperforms the state-of-the-art baselines in downstream tasks with a clear margin, under different ratios of available labels. The code and self-collected dataset are available at https://github.com/tomoyoshki/focal.", "url": "https://arxiv.org/abs/2310.20071"}, {"metadata": {"arXiv": "2310.20307", "Date": "Tue, 31 Oct 2023 09:27:12 ", "Title": "Causal Interpretation of Self-Attention in Pre-Trained Transformers", "Authors": ["Raanan Y. Rohekar", "Yaniv Gurwicz", "Shami Nisimov"], "Categories": "cs.AI cs.LG", "Comments": ["37th Conference on Neural Information Processing Systems (NeurIPS 2023). arXiv admin note: text overlap with arXiv:2210.10621"]}, "abstract": "We propose a causal interpretation of self-attention in the Transformer neural network architecture. We interpret self-attention as a mechanism that estimates a structural equation model for a given input sequence of symbols (tokens). The structural equation model can be interpreted, in turn, as a causal structure over the input symbols under the specific context of the input sequence. Importantly, this interpretation remains valid in the presence of latent confounders. Following this interpretation, we estimate conditional independence relations between input symbols by calculating partial correlations between their corresponding representations in the deepest attention layer. This enables learning the causal structure over an input sequence using existing constraint-based algorithms. In this sense, existing pre-trained Transformers can be utilized for zero-shot causal-discovery. We demonstrate this method by providing causal explanations for the outcomes of Transformers in two tasks: sentiment classification (NLP) and recommendation.", "url": "https://arxiv.org/abs/2310.20307"}, {"metadata": {"arXiv": "2310.19889", "Date": "Mon, 30 Oct 2023 18:00:33 ", "Title": "Exploring Geometry of Blind Spots in Vision Models", "Authors": ["Sriram Balasubramanian", "Gaurang Sriramanan", "Vinu Sankar Sadasivan", "Soheil Feizi"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["25 pages", "20 figures", "Accepted at NeurIPS 2023 (spotlight)"], "ACM-class": "I.2.6; I.2.10"}, "abstract": "Despite the remarkable success of deep neural networks in a myriad of settings, several works have demonstrated their overwhelming sensitivity to near-imperceptible perturbations, known as adversarial attacks. On the other hand, prior works have also observed that deep networks can be under-sensitive, wherein large-magnitude perturbations in input space do not induce appreciable changes to network activations. In this work, we study in detail the phenomenon of under-sensitivity in vision models such as CNNs and Transformers, and present techniques to study the geometry and extent of \"equi-confidence\" level sets of such networks. We propose a Level Set Traversal algorithm that iteratively explores regions of high confidence with respect to the input space using orthogonal components of the local gradients. Given a source image, we use this algorithm to identify inputs that lie in the same equi-confidence level set as the source image despite being perceptually similar to arbitrary images from other classes. We further observe that the source image is linearly connected by a high-confidence path to these inputs, uncovering a star-like structure for level sets of deep networks. Furthermore, we attempt to identify and estimate the extent of these connected higher-dimensional regions over which the model maintains a high degree of confidence. The code for this project is publicly available at https://github.com/SriramB-98/blindspots-neurips-sub", "url": "https://arxiv.org/abs/2310.19889"}, {"metadata": {"arXiv": "2310.19936", "Date": "Mon, 30 Oct 2023 18:51:25 ", "Title": "Towards Few-Annotation Learning for Object Detection: Are Transformer-based Models More Efficient ?", "Authors": ["Quentin Bouniot", "Ang\\'elique Loesch", "Romaric Audigier", "Amaury Habrard"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Published at WACV 2023"], "DOI": "10.1109/WACV56688.2023.00016"}, "abstract": "For specialized and dense downstream tasks such as object detection, labeling data requires expertise and can be very expensive, making few-shot and semi-supervised models much more attractive alternatives. While in the few-shot setup we observe that transformer-based object detectors perform better than convolution-based two-stage models for a similar amount of parameters, they are not as effective when used with recent approaches in the semi-supervised setting. In this paper, we propose a semi-supervised method tailored for the current state-of-the-art object detector Deformable DETR in the few-annotation learning setup using a student-teacher architecture, which avoids relying on a sensitive post-processing of the pseudo-labels generated by the teacher model. We evaluate our method on the semi-supervised object detection benchmarks COCO and Pascal VOC, and it outperforms previous methods, especially when annotations are scarce. We believe that our contributions open new possibilities to adapt similar object detection methods in this setup as well.", "url": "https://arxiv.org/abs/2310.19936"}, {"metadata": {"arXiv": "2310.20355", "Date": "Tue, 31 Oct 2023 10:56:10 ", "Title": "Muscle volume quantification: guiding transformers with anatomical priors", "Authors": ["Louise Piecuch", "Vanessa Gonzales Duque", "Aur\\'elie Sarcher", "Enzo Hollville", "Antoine Nordez", "Giuseppe Rabita", "Ga\\\"el Guilhem", "and Diana Mateus"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Muscle volume is a useful quantitative biomarker in sports, but also for the follow-up of degenerative musculo-skelletal diseases. In addition to volume, other shape biomarkers can be extracted by segmenting the muscles of interest from medical images. Manual segmentation is still today the gold standard for such measurements despite being very time-consuming. We propose a method for automatic segmentation of 18 muscles of the lower limb on 3D Magnetic Resonance Images to assist such morphometric analysis. By their nature, the tissue of different muscles is undistinguishable when observed in MR Images. Thus, muscle segmentation algorithms cannot rely on appearance but only on contour cues. However, such contours are hard to detect and their thickness varies across subjects. To cope with the above challenges, we propose a segmentation approach based on a hybrid architecture, combining convolutional and visual transformer blocks. We investigate for the first time the behaviour of such hybrid architectures in the context of muscle segmentation for shape analysis. Considering the consistent anatomical muscle configuration, we rely on transformer blocks to capture the longrange relations between the muscles. To further exploit the anatomical priors, a second contribution of this work consists in adding a regularisation loss based on an adjacency matrix of plausible muscle neighbourhoods estimated from the training data. Our experimental results on a unique database of elite athletes show it is possible to train complex hybrid models from a relatively small database of large volumes, while the anatomical prior regularisation favours better predictions.", "url": "https://arxiv.org/abs/2310.20355"}, {"metadata": {"arXiv": "2310.20550", "Date": "Tue, 31 Oct 2023 15:31:39 ", "Title": "CapsFusion: Rethinking Image-Text Data at Scale", "Authors": ["Qiying Yu", "Quan Sun", "Xiaosong Zhang", "Yufeng Cui", "Fan Zhang", "Xinlong Wang", "Jingjing Liu"], "Categories": "cs.CV cs.AI cs.CL cs.LG"}, "abstract": "Large multimodal models demonstrate remarkable generalist ability to perform diverse multimodal tasks in a zero-shot manner. Large-scale web-based image-text pairs contribute fundamentally to this success, but suffer from excessive noise. Recent studies use alternative captions synthesized by captioning models and have achieved notable benchmark performance. However, our experiments reveal significant Scalability Deficiency and World Knowledge Loss issues in models trained with synthetic captions, which have been largely obscured by their initial benchmark success. Upon closer examination, we identify the root cause as the overly-simplified language structure and lack of knowledge details in existing synthetic captions. To provide higher-quality and more scalable multimodal pretraining data, we propose CapsFusion, an advanced framework that leverages large language models to consolidate and refine information from both web-based image-text pairs and synthetic captions. Extensive experiments show that CapsFusion captions exhibit remarkable all-round superiority over existing captions in terms of model performance (e.g., 18.8 and 18.3 improvements in CIDEr score on COCO and NoCaps), sample efficiency (requiring 11-16 times less computation than baselines), world knowledge depth, and scalability. These effectiveness, efficiency and scalability advantages position CapsFusion as a promising candidate for future scaling of LMM training.", "url": "https://arxiv.org/abs/2310.20550"}, {"metadata": {"arXiv": "2310.19801", "Date": "Mon, 02 Oct 2023 17:24:10 ", "Title": "SyMPox: An Automated Monkeypox Detection System Based on Symptoms Using XGBoost", "Authors": ["Alireza Farzipour", "Roya Elmi", "Hamid Nasiri"], "Categories": "cs.LG cs.AI cs.CY"}, "abstract": "Monkeypox is a zoonotic disease. About 87000 cases of monkeypox were confirmed by the World Health Organization until 10th June 2023. The most prevalent methods for identifying this disease are image-based recognition techniques. Still, they are not too fast and could only be available to a few individuals. This study presents an independent application named SyMPox, developed to diagnose Monkeypox cases based on symptoms. SyMPox utilizes the robust XGBoost algorithm to analyze symptom patterns and provide accurate assessments. Developed using the Gradio framework, SyMPox offers a user-friendly platform for individuals to assess their symptoms and obtain reliable Monkeypox diagnoses.", "url": "https://arxiv.org/abs/2310.19801"}, {"metadata": {"arXiv": "2310.19804", "Date": "Thu, 05 Oct 2023 20:44:57 ", "Title": "A Kernel Perspective on Behavioural Metrics for Markov Decision Processes", "Authors": ["Pablo Samuel Castro", "Tyler Kastner", "Prakash Panangaden", "Mark Rowland"], "Categories": "cs.LG cs.AI", "Comments": ["Published in TMLR"]}, "abstract": "Behavioural metrics have been shown to be an effective mechanism for constructing representations in reinforcement learning. We present a novel perspective on behavioural metrics for Markov decision processes via the use of positive definite kernels. We leverage this new perspective to define a new metric that is provably equivalent to the recently introduced MICo distance (Castro et al., 2021). The kernel perspective further enables us to provide new theoretical results, which has so far eluded prior work. These include bounding value function differences by means of our metric, and the demonstration that our metric can be provably embedded into a finite-dimensional Euclidean space with low distortion error. These are two crucial properties when using behavioural metrics for reinforcement learning representations. We complement our theory with strong empirical results that demonstrate the effectiveness of these methods in practice.", "url": "https://arxiv.org/abs/2310.19804"}, {"metadata": {"arXiv": "2310.19805", "Date": "Sat, 07 Oct 2023 00:02:05 ", "Title": "SERA:Sample Efficient Reward Augmentation in offline-to-online Reinforcement Learning", "Authors": ["Ziqi Zhang", "Xiao Xiong", "Zifeng Zhuang", "Jinxin Liu", "Donglin Wang"], "Categories": "cs.LG cs.AI", "Comments": ["23 pages", "11 Figures", "and 6 Tables"]}, "abstract": "A prospective application of offline reinforcement learning (RL) involves initializing a pre-trained policy using existing static datasets for subsequent online fine-tuning. However, direct fine-tuning of the offline pre-trained policy often results in sub-optimal performance. A primary reason is that offline conservative methods diminish the agent's capability of exploration, thereby impacting online fine-tuning performance. To enhance exploration during online fine-tuning and thus enhance the overall online fine-tuning performance, we introduce a generalized reward augmentation framework called Sample Efficient Reward Augmentation (SERA). SERA aims to improve the performance of online fine-tuning by designing intrinsic rewards that encourage the agent to explore. Specifically, it implicitly implements State Marginal Matching (SMM) and penalizes out-of-distribution (OOD) state actions, thus encouraging agents to cover the target state density, and achieving better online fine-tuning results. Additionally, SERA can be effortlessly plugged into various RL algorithms to improve online fine-tuning and ensure sustained asymptotic improvement, showing the versatility as well as the effectiveness of SERA. Moreover, extensive experimental results will demonstrate that when conducting offline-to-online problems, SERA consistently and effectively enhances the performance of various offline algorithms.", "url": "https://arxiv.org/abs/2310.19805"}, {"metadata": {"arXiv": "2310.19815", "Date": "Thu, 19 Oct 2023 13:48:21 ", "Title": "Training binary neural networks without floating point precision", "Authors": ["Federico Fontana"], "Categories": "cs.LG cs.AI cs.NE", "Comments": ["74 pages", "Master's thesis"]}, "abstract": "The main goal of this work is to improve the efficiency of training binary neural networks, which are low latency and low energy networks. The main contribution of this work is the proposal of two solutions comprised of topology changes and strategy training that allow the network to achieve near the state-of-the-art performance and efficient training. The time required for training and the memory required in the process are two factors that contribute to efficient training.", "url": "https://arxiv.org/abs/2310.19815"}, {"metadata": {"arXiv": "2310.19819", "Date": "Mon, 23 Oct 2023 15:45:27 ", "Title": "Machine Learning and Knowledge: Why Robustness Matters", "Authors": ["Jonathan Vandenburgh"], "Categories": "cs.LG cs.AI", "Comments": ["Comments are welcome"]}, "abstract": "Trusting machine learning algorithms requires having confidence in their outputs. Confidence is typically interpreted in terms of model reliability, where a model is reliable if it produces a high proportion of correct outputs. However, model reliability does not address concerns about the robustness of machine learning models, such as models relying on the wrong features or variations in performance based on context. I argue that the epistemic dimension of trust can instead be understood through the concept of knowledge, where the trustworthiness of an algorithm depends on whether its users are in the position to know that its outputs are correct. Knowledge requires beliefs to be formed for the right reasons and to be robust to error, so machine learning algorithms can only provide knowledge if they work well across counterfactual scenarios and if they make decisions based on the right features. This, I argue, can explain why we should care about model properties like interpretability, causal shortcut independence, and distribution shift robustness even if such properties are not required for model reliability.", "url": "https://arxiv.org/abs/2310.19819"}, {"metadata": {"arXiv": "2310.19843", "Date": "Mon, 30 Oct 2023 08:46:55 ", "Title": "Modeling the Telemarketing Process using Genetic Algorithms and Extreme Boosting: Feature Selection and Cost-Sensitive Analytical Approach", "Authors": ["Nazeeh Ghatasheh", "Ismail Altaharwa", "Khaled Aldebei"], "Categories": "cs.LG cs.AI cs.NE", "Journal-ref": "IEEE Access, vol. 11, pp. 67806-67824, 2023", "DOI": "10.1109/ACCESS.2023.3292840"}, "abstract": "Currently, almost all direct marketing activities take place virtually rather than in person, weakening interpersonal skills at an alarming pace. Furthermore, businesses have been striving to sense and foster the tendency of their clients to accept a marketing offer. The digital transformation and the increased virtual presence forced firms to seek novel marketing research approaches. This research aims at leveraging the power of telemarketing data in modeling the willingness of clients to make a term deposit and finding the most significant characteristics of the clients. Real-world data from a Portuguese bank and national socio-economic metrics are used to model the telemarketing decision-making process. This research makes two key contributions. First, propose a novel genetic algorithm-based classifier to select the best discriminating features and tune classifier parameters simultaneously. Second, build an explainable prediction model. The best-generated classification models were intensively validated using 50 times repeated 10-fold stratified cross-validation and the selected features have been analyzed. The models significantly outperform the related works in terms of class of interest accuracy, they attained an average of 89.07\\% and 0.059 in terms of geometric mean and type I error respectively. The model is expected to maximize the potential profit margin at the least possible cost and provide more insights to support marketing decision-making.", "url": "https://arxiv.org/abs/2310.19843"}, {"metadata": {"arXiv": "2310.19845", "Date": "Mon, 30 Oct 2023 09:00:05 ", "Title": "Modified Genetic Algorithm for Feature Selection and Hyper Parameter Optimization: Case of XGBoost in Spam Prediction", "Authors": ["Nazeeh Ghatasheh", "Ismail Altaharwa", "Khaled Aldebei"], "Categories": "cs.LG cs.AI cs.CR cs.NE", "Journal-ref": "IEEE Access, 2022, vol. 10, pp. 84365-84383", "DOI": "10.1109/ACCESS.2022.3196905"}, "abstract": "Recently, spam on online social networks has attracted attention in the research and business world. Twitter has become the preferred medium to spread spam content. Many research efforts attempted to encounter social networks spam. Twitter brought extra challenges represented by the feature space size, and imbalanced data distributions. Usually, the related research works focus on part of these main challenges or produce black-box models. In this paper, we propose a modified genetic algorithm for simultaneous dimensionality reduction and hyper parameter optimization over imbalanced datasets. The algorithm initialized an eXtreme Gradient Boosting classifier and reduced the features space of tweets dataset; to generate a spam prediction model. The model is validated using a 50 times repeated 10-fold stratified cross-validation, and analyzed using nonparametric statistical tests. The resulted prediction model attains on average 82.32\\% and 92.67\\% in terms of geometric mean and accuracy respectively, utilizing less than 10\\% of the total feature space. The empirical results show that the modified genetic algorithm outperforms $Chi^2$ and $PCA$ feature selection methods. In addition, eXtreme Gradient Boosting outperforms many machine learning algorithms, including BERT-based deep learning model, in spam prediction. Furthermore, the proposed approach is applied to SMS spam modeling and compared to related works.", "url": "https://arxiv.org/abs/2310.19845"}, {"metadata": {"arXiv": "2310.19906", "Date": "Mon, 30 Oct 2023 18:16:19 ", "Title": "Interpretable Prototype-based Graph Information Bottleneck", "Authors": ["Sangwoo Seo", "Sungwon Kim", "Chanyoung Park"], "Categories": "cs.LG cs.AI", "Comments": ["NeurIPS 2023"]}, "abstract": "The success of Graph Neural Networks (GNNs) has led to a need for understanding their decision-making process and providing explanations for their predictions, which has given rise to explainable AI (XAI) that offers transparent explanations for black-box models. Recently, the use of prototypes has successfully improved the explainability of models by learning prototypes to imply training graphs that affect the prediction. However, these approaches tend to provide prototypes with excessive information from the entire graph, leading to the exclusion of key substructures or the inclusion of irrelevant substructures, which can limit both the interpretability and the performance of the model in downstream tasks. In this work, we propose a novel framework of explainable GNNs, called interpretable Prototype-based Graph Information Bottleneck (PGIB) that incorporates prototype learning within the information bottleneck framework to provide prototypes with the key subgraph from the input graph that is important for the model prediction. This is the first work that incorporates prototype learning into the process of identifying the key subgraphs that have a critical impact on the prediction performance. Extensive experiments, including qualitative analysis, demonstrate that PGIB outperforms state-of-the-art methods in terms of both prediction performance and explainability.", "url": "https://arxiv.org/abs/2310.19906"}, {"metadata": {"arXiv": "2310.19927", "Date": "Mon, 30 Oct 2023 18:43:21 ", "Title": "Model-Based Reparameterization Policy Gradient Methods: Theory and Practical Algorithms", "Authors": ["Shenao Zhang", "Boyi Liu", "Zhaoran Wang", "Tuo Zhao"], "Categories": "cs.LG cs.AI", "Comments": ["Published at NeurIPS 2023"]}, "abstract": "ReParameterization (RP) Policy Gradient Methods (PGMs) have been widely adopted for continuous control tasks in robotics and computer graphics. However, recent studies have revealed that, when applied to long-term reinforcement learning problems, model-based RP PGMs may experience chaotic and non-smooth optimization landscapes with exploding gradient variance, which leads to slow convergence. This is in contrast to the conventional belief that reparameterization methods have low gradient estimation variance in problems such as training deep generative models. To comprehend this phenomenon, we conduct a theoretical examination of model-based RP PGMs and search for solutions to the optimization difficulties. Specifically, we analyze the convergence of the model-based RP PGMs and pinpoint the smoothness of function approximators as a major factor that affects the quality of gradient estimation. Based on our analysis, we propose a spectral normalization method to mitigate the exploding variance issue caused by long model unrolls. Our experimental results demonstrate that proper normalization significantly reduces the gradient variance of model-based RP PGMs. As a result, the performance of the proposed method is comparable or superior to other gradient estimators, such as the Likelihood Ratio (LR) gradient estimator. Our code is available at https://github.com/agentification/RP_PGM.", "url": "https://arxiv.org/abs/2310.19927"}, {"metadata": {"arXiv": "2310.19957", "Date": "Mon, 30 Oct 2023 19:12:51 ", "Title": "Deep Learning for Spatiotemporal Big Data: A Vision on Opportunities and Challenges", "Authors": ["Zhe Jiang"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "With advancements in GPS, remote sensing, and computational simulation, an enormous volume of spatiotemporal data is being collected at an increasing speed from various application domains, spanning Earth sciences, agriculture, smart cities, and public safety. Such emerging geospatial and spatiotemporal big data, coupled with recent advances in deep learning technologies, foster new opportunities to solve problems that have not been possible before. For instance, remote sensing researchers can potentially train a foundation model using Earth imagery big data for numerous land cover and land use modeling tasks. Coastal modelers can train AI surrogates to speed up numerical simulations. However, the distinctive characteristics of spatiotemporal big data pose new challenges for deep learning technologies. This vision paper introduces various types of spatiotemporal big data, discusses new research opportunities in the realm of deep learning applied to spatiotemporal big data, lists the unique challenges, and identifies several future research needs.", "url": "https://arxiv.org/abs/2310.19957"}, {"metadata": {"arXiv": "2310.19961", "Date": "Mon, 30 Oct 2023 19:25:43 ", "Title": "ExPT: Synthetic Pretraining for Few-Shot Experimental Design", "Authors": ["Tung Nguyen", "Sudhanshu Agrawal", "Aditya Grover"], "Categories": "cs.LG cs.AI", "Comments": ["2023 Conference on Neural Information Processing Systems (NeurIPS)"]}, "abstract": "Experimental design is a fundamental problem in many science and engineering fields. In this problem, sample efficiency is crucial due to the time, money, and safety costs of real-world design evaluations. Existing approaches either rely on active data collection or access to large, labeled datasets of past experiments, making them impractical in many real-world scenarios. In this work, we address the more challenging yet realistic setting of few-shot experimental design, where only a few labeled data points of input designs and their corresponding values are available. We approach this problem as a conditional generation task, where a model conditions on a few labeled examples and the desired output to generate an optimal input design. To this end, we introduce Experiment Pretrained Transformers (ExPT), a foundation model for few-shot experimental design that employs a novel combination of synthetic pretraining with in-context learning. In ExPT, we only assume knowledge of a finite collection of unlabelled data points from the input domain and pretrain a transformer neural network to optimize diverse synthetic functions defined over this domain. Unsupervised pretraining allows ExPT to adapt to any design task at test time in an in-context fashion by conditioning on a few labeled data points from the target task and generating the candidate optima. We evaluate ExPT on few-shot experimental design in challenging domains and demonstrate its superior generality and performance compared to existing methods. The source code is available at https://github.com/tung-nd/ExPT.git.", "url": "https://arxiv.org/abs/2310.19961"}, {"metadata": {"arXiv": "2310.20012", "Date": "Mon, 30 Oct 2023 20:58:28 ", "Title": "Multiscale Feature Attribution for Outliers", "Authors": ["Jeff Shen", "Peter Melchior"], "Categories": "cs.LG astro-ph.IM cs.AI", "Comments": ["6 pages", "2 figures", "accepted to NeurIPS 2023 Workshop on Machine Learning and the Physical Sciences. Code available at https://github.com/al-jshen/imo"]}, "abstract": "Machine learning techniques can automatically identify outliers in massive datasets, much faster and more reproducible than human inspection ever could. But finding such outliers immediately leads to the question: which features render this input anomalous? We propose a new feature attribution method, Inverse Multiscale Occlusion, that is specifically designed for outliers, for which we have little knowledge of the type of features we want to identify and expect that the model performance is questionable because anomalous test data likely exceed the limits of the training data. We demonstrate our method on outliers detected in galaxy spectra from the Dark Energy Survey Instrument and find its results to be much more interpretable than alternative attribution approaches.", "url": "https://arxiv.org/abs/2310.20012"}, {"metadata": {"arXiv": "2310.20025", "Date": "Mon, 30 Oct 2023 21:19:52 ", "Title": "GOPlan: Goal-conditioned Offline Reinforcement Learning by Planning with Learned Models", "Authors": ["Mianchu Wang", "Rui Yang", "Xi Chen", "Meng Fang"], "Categories": "cs.LG cs.AI", "Comments": ["Spotlight Presentation at Goal-conditioned Reinforcement Learning Workshop at NeurIPS", "2023"]}, "abstract": "Offline goal-conditioned RL (GCRL) offers a feasible paradigm to learn general-purpose policies from diverse and multi-task offline datasets. Despite notable recent progress, the predominant offline GCRL methods have been restricted to model-free approaches, constraining their capacity to tackle limited data budgets and unseen goal generalization. In this work, we propose a novel two-stage model-based framework, Goal-conditioned Offline Planning (GOPlan), including (1) pretraining a prior policy capable of capturing multi-modal action distribution within the multi-goal dataset; (2) employing the reanalysis method with planning to generate imagined trajectories for funetuning policies. Specifically, the prior policy is based on an advantage-weighted Conditioned Generative Adversarial Networks that exhibits distinct mode separation to overcome the pitfalls of out-of-distribution (OOD) actions. For further policy optimization, the reanalysis method generates high-quality imaginary data by planning with learned models for both intra-trajectory and inter-trajectory goals. Through experimental evaluations, we demonstrate that GOPlan achieves state-of-the-art performance on various offline multi-goal manipulation tasks. Moreover, our results highlight the superior ability of GOPlan to handle small data budgets and generalize to OOD goals.", "url": "https://arxiv.org/abs/2310.20025"}, {"metadata": {"arXiv": "2310.20049", "Date": "Mon, 30 Oct 2023 22:12:35 ", "Title": "SURF: A Generalization Benchmark for GNNs Predicting Fluid Dynamics", "Authors": ["Stefan K\\\"unzli", "Florain Gr\\\"otschla", "Jo\\\"el Mathys and Roger Wattenhofer"], "Categories": "cs.LG cs.AI physics.flu-dyn"}, "abstract": "Simulating fluid dynamics is crucial for the design and development process, ranging from simple valves to complex turbomachinery. Accurately solving the underlying physical equations is computationally expensive. Therefore, learning-based solvers that model interactions on meshes have gained interest due to their promising speed-ups. However, it is unknown to what extent these models truly understand the underlying physical principles and can generalize rather than interpolate. Generalization is a key requirement for a general-purpose fluid simulator, which should adapt to different topologies, resolutions, or thermodynamic ranges. We propose SURF, a benchmark designed to test the \\textit{generalization} of learned graph-based fluid simulators. SURF comprises individual datasets and provides specific performance and generalization metrics for evaluating and comparing different models. We empirically demonstrate the applicability of SURF by thoroughly investigating the two state-of-the-art graph-based models, yielding new insights into their generalization.", "url": "https://arxiv.org/abs/2310.20049"}, {"metadata": {"arXiv": "2310.20141", "Date": "Tue, 31 Oct 2023 03:16:32 ", "Title": "Contrastive Difference Predictive Coding", "Authors": ["Chongyi Zheng", "Ruslan Salakhutdinov", "Benjamin Eysenbach"], "Categories": "cs.LG cs.AI", "Comments": ["Website (https://chongyi-zheng.github.io/td_infonce) and code (https://github.com/chongyi-zheng/td_infonce)"]}, "abstract": "Predicting and reasoning about the future lie at the heart of many time-series questions. For example, goal-conditioned reinforcement learning can be viewed as learning representations to predict which states are likely to be visited in the future. While prior methods have used contrastive predictive coding to model time series data, learning representations that encode long-term dependencies usually requires large amounts of data. In this paper, we introduce a temporal difference version of contrastive predictive coding that stitches together pieces of different time series data to decrease the amount of data required to learn predictions of future events. We apply this representation learning method to derive an off-policy algorithm for goal-conditioned RL. Experiments demonstrate that, compared with prior RL methods, ours achieves $2 \\times$ median improvement in success rates and can better cope with stochastic environments. In tabular settings, we show that our method is about $20 \\times$ more sample efficient than the successor representation and $1500 \\times$ more sample efficient than the standard (Monte Carlo) version of contrastive predictive coding.", "url": "https://arxiv.org/abs/2310.20141"}, {"metadata": {"arXiv": "2310.20178", "Date": "Tue, 31 Oct 2023 05:01:02 ", "Title": "Learning to Discover Skills through Guidance", "Authors": ["Hyunseung Kim", "Byungkun Lee", "Hojoon Lee", "Dongyoon Hwang", "Sejik Park", "Kyushik Min", "Jaegul Choo"], "Categories": "cs.LG cs.AI", "Comments": ["29 pages", "18 figures"]}, "abstract": "In the field of unsupervised skill discovery (USD), a major challenge is limited exploration, primarily due to substantial penalties when skills deviate from their initial trajectories. To enhance exploration, recent methodologies employ auxiliary rewards to maximize the epistemic uncertainty or entropy of states. However, we have identified that the effectiveness of these rewards declines as the environmental complexity rises. Therefore, we present a novel USD algorithm, skill discovery with guidance (DISCO-DANCE), which (1) selects the guide skill that possesses the highest potential to reach unexplored states, (2) guides other skills to follow guide skill, then (3) the guided skills are dispersed to maximize their discriminability in unexplored states. Empirical evaluation demonstrates that DISCO-DANCE outperforms other USD baselines in challenging environments, including two navigation benchmarks and a continuous control benchmark. Qualitative visualizations and code of DISCO-DANCE are available at https://mynsng.github.io/discodance.", "url": "https://arxiv.org/abs/2310.20178"}, {"metadata": {"arXiv": "2310.20187", "Date": "Tue, 31 Oct 2023 05:13:10 ", "Title": "Self-supervised Pre-training for Precipitation Post-processor", "Authors": ["Sojung An", "Junha Lee", "Jiyeon Jang", "Inchae Na", "Wooyeon Park", "Sujeong You"], "Categories": "cs.LG cs.AI"}, "abstract": "Securing sufficient forecast lead time for local precipitation is essential for preventing hazardous weather events. Nonetheless, global warming-induced climate change is adding to the challenge of accurately predicting severe precipitation events, such as heavy rainfall. In this work, we propose a deep learning-based precipitation post-processor approach to numerical weather prediction (NWP) models. The precipitation post-processor consists of (i) self-supervised pre-training, where parameters of encoder are pre-trained on the reconstruction of masked variables of the atmospheric physics domain, and (ii) transfer learning on precipitation segmentation tasks (target domain) from the pre-trained encoder. We also introduce a heuristic labeling approach for effectively training class-imbalanced datasets. Our experiment results in precipitation correction for regional NWP show that the proposed method outperforms other approaches.", "url": "https://arxiv.org/abs/2310.20187"}, {"metadata": {"arXiv": "2310.20218", "Date": "Tue, 31 Oct 2023 06:37:51 ", "Title": "A Systematic Review for Transformer-based Long-term Series Forecasting", "Authors": ["Liyilei Su", "Xumin Zuo", "Rui Li", "Xin Wang", "Heng Zhao and Bingding Huang"], "Categories": "cs.LG cs.AI"}, "abstract": "The emergence of deep learning has yielded noteworthy advancements in time series forecasting (TSF). Transformer architectures, in particular, have witnessed broad utilization and adoption in TSF tasks. Transformers have proven to be the most successful solution to extract the semantic correlations among the elements within a long sequence. Various variants have enabled transformer architecture to effectively handle long-term time series forecasting (LTSF) tasks. In this article, we first present a comprehensive overview of transformer architectures and their subsequent enhancements developed to address various LTSF tasks. Then, we summarize the publicly available LTSF datasets and relevant evaluation metrics. Furthermore, we provide valuable insights into the best practices and techniques for effectively training transformers in the context of time-series analysis. Lastly, we propose potential research directions in this rapidly evolving field.", "url": "https://arxiv.org/abs/2310.20218"}, {"metadata": {"arXiv": "2310.20280", "Date": "Tue, 31 Oct 2023 08:50:52 ", "Title": "AutoMixer for Improved Multivariate Time-Series Forecasting on BizITOps Data", "Authors": ["Santosh Palaskar", "Vijay Ekambaram", "Arindam Jati", "Neelamadhav Gantayat", "Avirup Saha", "Seema Nagar", "Nam H. Nguyen", "Pankaj Dayama", "Renuka Sindhgatta", "Prateeti Mohapatra", "Harshit Kumar", "Jayant Kalagnanam", "Nandyala Hemachandra", "Narayan Rangaraj"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted in the Thirty-Sixth Annual Conference on Innovative Applications of Artificial Intelligence (IAAI-24)"]}, "abstract": "The efficiency of business processes relies on business key performance indicators (Biz-KPIs), that can be negatively impacted by IT failures. BizITOps data fuses both Biz-KPIs and IT event channels together as multivariate time series data. Forecasting Biz-KPIs in advance can enhance efficiency and revenue through proactive corrective measures. However, BizITOps data generally exhibit both useful and noisy inter-channel interactions between Biz-KPIs and IT events that need to be effectively decoupled. This leads to suboptimal forecasting performance when existing multivariate forecasting models are employed. To address this, we introduce AutoMixer, a time-series Foundation Model (FM) approach, grounded on the novel technique of channel-compressed pretrain and finetune workflows. AutoMixer leverages an AutoEncoder for channel-compressed pretraining and integrates it with the advanced TSMixer model for multivariate time series forecasting. This fusion greatly enhances the potency of TSMixer for accurate forecasts and also generalizes well across several downstream tasks. Through detailed experiments and dashboard analytics, we show AutoMixer's capability to consistently improve the Biz-KPI's forecasting accuracy (by 11-15%) which directly translates to actionable business insights.", "url": "https://arxiv.org/abs/2310.20280"}, {"metadata": {"arXiv": "2310.20287", "Date": "Tue, 31 Oct 2023 08:59:39 ", "Title": "Sample-Efficient and Safe Deep Reinforcement Learning via Reset Deep Ensemble Agents", "Authors": ["Woojun Kim", "Yongjae Shin", "Jongeui Park", "Youngchul Sung"], "Categories": "cs.LG cs.AI", "Comments": ["NeurIPS 2023 camera-ready"]}, "abstract": "Deep reinforcement learning (RL) has achieved remarkable success in solving complex tasks through its integration with deep neural networks (DNNs) as function approximators. However, the reliance on DNNs has introduced a new challenge called primacy bias, whereby these function approximators tend to prioritize early experiences, leading to overfitting. To mitigate this primacy bias, a reset method has been proposed, which performs periodic resets of a portion or the entirety of a deep RL agent while preserving the replay buffer. However, the use of the reset method can result in performance collapses after executing the reset, which can be detrimental from the perspective of safe RL and regret minimization. In this paper, we propose a new reset-based method that leverages deep ensemble learning to address the limitations of the vanilla reset method and enhance sample efficiency. The proposed method is evaluated through various experiments including those in the domain of safe RL. Numerical results show its effectiveness in high sample efficiency and safety considerations.", "url": "https://arxiv.org/abs/2310.20287"}, {"metadata": {"arXiv": "2310.20360", "Date": "Tue, 31 Oct 2023 11:01:23 ", "Title": "Mathematical Introduction to Deep Learning: Methods, Implementations, and Theory", "Authors": ["Arnulf Jentzen", "Benno Kuckuck", "Philippe von Wurstemberger"], "Categories": "cs.LG cs.AI cs.NA math.NA math.PR stat.ML", "Comments": ["601 pages", "36 figures", "45 source codes"], "MSC-class": "68T07"}, "abstract": "This book aims to provide an introduction to the topic of deep learning algorithms. We review essential components of deep learning algorithms in full mathematical detail including different artificial neural network (ANN) architectures (such as fully-connected feedforward ANNs, convolutional ANNs, recurrent ANNs, residual ANNs, and ANNs with batch normalization) and different optimization algorithms (such as the basic stochastic gradient descent (SGD) method, accelerated methods, and adaptive methods). We also cover several theoretical aspects of deep learning algorithms such as approximation capacities of ANNs (including a calculus for ANNs), optimization theory (including Kurdyka-{\\L}ojasiewicz inequalities), and generalization errors. In the last part of the book some deep learning approximation methods for PDEs are reviewed including physics-informed neural networks (PINNs) and deep Galerkin methods. We hope that this book will be useful for students and scientists who do not yet have any background in deep learning at all and would like to gain a solid foundation as well as for practitioners who would like to obtain a firmer mathematical understanding of the objects and methods considered in deep learning.", "url": "https://arxiv.org/abs/2310.20360"}, {"metadata": {"arXiv": "2310.20367", "Date": "Tue, 31 Oct 2023 11:23:26 ", "Title": "A Machine Learning-Based Framework for Clustering Residential Electricity Load Profiles to Enhance Demand Response Programs", "Authors": ["Vasilis Michalakopoulos", "Elissaios Sarmas", "Ioannis Papias", "Panagiotis Skaloumpakas", "Vangelis Marinakis", "Haris Doukas"], "Categories": "cs.LG cs.AI", "Comments": ["29 pages", "19 figures"]}, "abstract": "Load shapes derived from smart meter data are frequently employed to analyze daily energy consumption patterns, particularly in the context of applications like Demand Response (DR). Nevertheless, one of the most important challenges to this endeavor lies in identifying the most suitable consumer clusters with similar consumption behaviors. In this paper, we present a novel machine learning based framework in order to achieve optimal load profiling through a real case study, utilizing data from almost 5000 households in London. Four widely used clustering algorithms are applied specifically K-means, K-medoids, Hierarchical Agglomerative Clustering and Density-based Spatial Clustering. An empirical analysis as well as multiple evaluation metrics are leveraged to assess those algorithms. Following that, we redefine the problem as a probabilistic classification one, with the classifier emulating the behavior of a clustering algorithm,leveraging Explainable AI (xAI) to enhance the interpretability of our solution. According to the clustering algorithm analysis the optimal number of clusters for this case is seven. Despite that, our methodology shows that two of the clusters, almost 10\\% of the dataset, exhibit significant internal dissimilarity and thus it splits them even further to create nine clusters in total. The scalability and versatility of our solution makes it an ideal choice for power utility companies aiming to segment their users for creating more targeted Demand Response programs.", "url": "https://arxiv.org/abs/2310.20367"}, {"metadata": {"arXiv": "2310.20431", "Date": "Tue, 31 Oct 2023 13:07:41 ", "Title": "Raising the ClaSS of Streaming Time Series Segmentation", "Authors": ["Arik Ermshaus", "Patrick Sch\\\"afer", "Ulf Leser"], "Categories": "cs.LG cs.AI cs.DB"}, "abstract": "Ubiquitous sensors today emit high frequency streams of numerical measurements that reflect properties of human, animal, industrial, commercial, and natural processes. Shifts in such processes, e.g. caused by external events or internal state changes, manifest as changes in the recorded signals. The task of streaming time series segmentation (STSS) is to partition the stream into consecutive variable-sized segments that correspond to states of the observed processes or entities. The partition operation itself must in performance be able to cope with the input frequency of the signals. We introduce ClaSS, a novel, efficient, and highly accurate algorithm for STSS. ClaSS assesses the homogeneity of potential partitions using self-supervised time series classification and applies statistical tests to detect significant change points (CPs). In our experimental evaluation using two large benchmarks and six real-world data archives, we found ClaSS to be significantly more precise than eight state-of-the-art competitors. Its space and time complexity is independent of segment sizes and linear only in the sliding window size. We also provide ClaSS as a window operator with an average throughput of 538 data points per second for the Apache Flink streaming engine.", "url": "https://arxiv.org/abs/2310.20431"}, {"metadata": {"arXiv": "2310.20447", "Date": "Tue, 31 Oct 2023 13:30:30 ", "Title": "Efficient Bayesian Learning Curve Extrapolation using Prior-Data Fitted Networks", "Authors": ["Steven Adriaensen", "Herilalaina Rakotoarison", "Samuel M\\\"uller", "Frank Hutter"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "Learning curve extrapolation aims to predict model performance in later epochs of training, based on the performance in earlier epochs. In this work, we argue that, while the inherent uncertainty in the extrapolation of learning curves warrants a Bayesian approach, existing methods are (i) overly restrictive, and/or (ii) computationally expensive. We describe the first application of prior-data fitted neural networks (PFNs) in this context. A PFN is a transformer, pre-trained on data generated from a prior, to perform approximate Bayesian inference in a single forward pass. We propose LC-PFN, a PFN trained to extrapolate 10 million artificial right-censored learning curves generated from a parametric prior proposed in prior art using MCMC. We demonstrate that LC-PFN can approximate the posterior predictive distribution more accurately than MCMC, while being over 10 000 times faster. We also show that the same LC-PFN achieves competitive performance extrapolating a total of 20 000 real learning curves from four learning curve benchmarks (LCBench, NAS-Bench-201, Taskset, and PD1) that stem from training a wide range of model architectures (MLPs, CNNs, RNNs, and Transformers) on 53 different datasets with varying input modalities (tabular, image, text, and protein data). Finally, we investigate its potential in the context of model selection and find that a simple LC-PFN based predictive early stopping criterion obtains 2 - 6x speed-ups on 45 of these datasets, at virtually no overhead.", "url": "https://arxiv.org/abs/2310.20447"}, {"metadata": {"arXiv": "2310.20452", "Date": "Tue, 31 Oct 2023 13:44:53 ", "Title": "AsGrad: A Sharp Unified Analysis of Asynchronous-SGD Algorithms", "Authors": ["Rustem Islamov and Mher Safaryan and Dan Alistarh"], "Categories": "cs.LG cs.AI math.OC stat.ML"}, "abstract": "We analyze asynchronous-type algorithms for distributed SGD in the heterogeneous setting, where each worker has its own computation and communication speeds, as well as data distribution. In these algorithms, workers compute possibly stale and stochastic gradients associated with their local data at some iteration back in history and then return those gradients to the server without synchronizing with other workers. We present a unified convergence theory for non-convex smooth functions in the heterogeneous regime. The proposed analysis provides convergence for pure asynchronous SGD and its various modifications. Moreover, our theory explains what affects the convergence rate and what can be done to improve the performance of asynchronous algorithms. In particular, we introduce a novel asynchronous method based on worker shuffling. As a by-product of our analysis, we also demonstrate convergence guarantees for gradient-type algorithms such as SGD with random reshuffling and shuffle-once mini-batch SGD. The derived rates match the best-known results for those algorithms, highlighting the tightness of our approach. Finally, our numerical evaluations support theoretical findings and show the good practical performance of our method.", "url": "https://arxiv.org/abs/2310.20452"}, {"metadata": {"arXiv": "2310.20476", "Date": "Tue, 31 Oct 2023 14:09:32 ", "Title": "Global Transformer Architecture for Indoor Room Temperature Forecasting", "Authors": ["Alfredo V Clemente and Alessandro Nocente and Massimiliano Ruocco"], "Categories": "cs.LG cs.AI"}, "abstract": "A thorough regulation of building energy systems translates in relevant energy savings and in a better comfort for the occupants. Algorithms to predict the thermal state of a building on a certain time horizon with a good confidence are essential for the implementation of effective control systems. This work presents a global Transformer architecture for indoor temperature forecasting in multi-room buildings, aiming at optimizing energy consumption and reducing greenhouse gas emissions associated with HVAC systems. Recent advancements in deep learning have enabled the development of more sophisticated forecasting models compared to traditional feedback control systems. The proposed global Transformer architecture can be trained on the entire dataset encompassing all rooms, eliminating the need for multiple room-specific models, significantly improving predictive performance, and simplifying deployment and maintenance. Notably, this study is the first to apply a Transformer architecture for indoor temperature forecasting in multi-room buildings. The proposed approach provides a novel solution to enhance the accuracy and efficiency of temperature forecasting, serving as a valuable tool to optimize energy consumption and decrease greenhouse gas emissions in the building sector.", "url": "https://arxiv.org/abs/2310.20476"}, {"metadata": {"arXiv": "2310.20608", "Date": "Tue, 31 Oct 2023 16:43:56 ", "Title": "Autonomous Robotic Reinforcement Learning with Asynchronous Human Feedback", "Authors": ["Max Balsells", "Marcel Torne", "Zihan Wang", "Samedh Desai", "Pulkit Agrawal", "Abhishek Gupta"], "Categories": "cs.LG cs.AI cs.RO", "Comments": ["Project website https://guided-exploration-autonomous-rl.github.io/GEAR/"]}, "abstract": "Ideally, we would place a robot in a real-world environment and leave it there improving on its own by gathering more experience autonomously. However, algorithms for autonomous robotic learning have been challenging to realize in the real world. While this has often been attributed to the challenge of sample complexity, even sample-efficient techniques are hampered by two major challenges - the difficulty of providing well \"shaped\" rewards, and the difficulty of continual reset-free training. In this work, we describe a system for real-world reinforcement learning that enables agents to show continual improvement by training directly in the real world without requiring painstaking effort to hand-design reward functions or reset mechanisms. Our system leverages occasional non-expert human-in-the-loop feedback from remote users to learn informative distance functions to guide exploration while leveraging a simple self-supervised learning algorithm for goal-directed policy learning. We show that in the absence of resets, it is particularly important to account for the current \"reachability\" of the exploration policy when deciding which regions of the space to explore. Based on this insight, we instantiate a practical learning system - GEAR, which enables robots to simply be placed in real-world environments and left to train autonomously without interruption. The system streams robot experience to a web interface only requiring occasional asynchronous feedback from remote, crowdsourced, non-expert humans in the form of binary comparative feedback. We evaluate this system on a suite of robotic tasks in simulation and demonstrate its effectiveness at learning behaviors both in simulation and the real world. Project website https://guided-exploration-autonomous-rl.github.io/GEAR/.", "url": "https://arxiv.org/abs/2310.20608"}, {"metadata": {"arXiv": "2310.20624", "Date": "Tue, 31 Oct 2023 16:55:06 ", "Title": "LoRA Fine-tuning Efficiently Undoes Safety Training in Llama 2-Chat 70B", "Authors": ["Simon Lermen", "Charlie Rogers-Smith", "Jeffrey Ladish"], "Categories": "cs.LG cs.AI"}, "abstract": "AI developers often apply safety alignment procedures to prevent the misuse of their AI systems. For example, before Meta released Llama 2-Chat, a collection of instruction fine-tuned large language models, they invested heavily in safety training, incorporating extensive red-teaming and reinforcement learning from human feedback. However, it remains unclear how well safety training guards against model misuse when attackers have access to model weights. We explore the robustness of safety training in language models by subversively fine-tuning the public weights of Llama 2-Chat. We employ low-rank adaptation (LoRA) as an efficient fine-tuning method. With a budget of less than $200 per model and using only one GPU, we successfully undo the safety training of Llama 2-Chat models of sizes 7B, 13B, and 70B. Specifically, our fine-tuning technique significantly reduces the rate at which the model refuses to follow harmful instructions. We achieve a refusal rate below 1% for our 70B Llama 2-Chat model on two refusal benchmarks. Our fine-tuning method retains general performance, which we validate by comparing our fine-tuned models against Llama 2-Chat across two benchmarks. Additionally, we present a selection of harmful outputs produced by our models. While there is considerable uncertainty about the scope of risks from current models, it is likely that future models will have significantly more dangerous capabilities, including the ability to hack into critical infrastructure, create dangerous bio-weapons, or autonomously replicate and adapt to new environments. We show that subversive fine-tuning is practical and effective, and hence argue that evaluating risks from fine-tuning should be a core part of risk assessments for releasing model weights.", "url": "https://arxiv.org/abs/2310.20624"}, {"metadata": {"arXiv": "2310.20654", "Date": "Tue, 31 Oct 2023 17:24:40 ", "Title": "\"Pick-and-Pass\" as a Hat-Trick Class for First-Principle Memory, Generalizability, and Interpretability Benchmarks", "Authors": ["Jason Wang and Ryan Rezai"], "Categories": "cs.LG cs.AI", "Comments": ["2 pages", "2 figures"]}, "abstract": "Closed drafting or \"pick and pass\" is a popular game mechanic where each round players select a card or other playable element from their hand and pass the rest to the next player. Games employing closed drafting make for great studies on memory and turn order due to their explicitly calculable memory of other players' hands. In this paper, we establish first-principle benchmarks for studying model-free reinforcement learning algorithms and their comparative ability to learn memory in a popular family of closed drafting games called \"Sushi Go Party!\", producing state-of-the-art results on this environment along the way. Furthermore, as Sushi Go Party! can be expressed as a set of closely-related games based on the set of cards in play, we quantify the generalizability of reinforcement learning algorithms trained on various sets of cards, establishing key trends between generalized performance and the set distance between the train and evaluation game configurations. Finally, we fit decision rules to interpret the strategy of the learned models and compare them to the ranking preferences of human players, finding intuitive common rules and intriguing new moves.", "url": "https://arxiv.org/abs/2310.20654"}, {"metadata": {"arXiv": "2310.20663", "Date": "Tue, 31 Oct 2023 17:29:46 ", "Title": "Offline RL with Observation Histories: Analyzing and Improving Sample Complexity", "Authors": ["Joey Hong and Anca Dragan and Sergey Levine"], "Categories": "cs.LG cs.AI", "Comments": ["21 pages", "4 figures"]}, "abstract": "Offline reinforcement learning (RL) can in principle synthesize more optimal behavior from a dataset consisting only of suboptimal trials. One way that this can happen is by \"stitching\" together the best parts of otherwise suboptimal trajectories that overlap on similar states, to create new behaviors where each individual state is in-distribution, but the overall returns are higher. However, in many interesting and complex applications, such as autonomous navigation and dialogue systems, the state is partially observed. Even worse, the state representation is unknown or not easy to define. In such cases, policies and value functions are often conditioned on observation histories instead of states. In these cases, it is not clear if the same kind of \"stitching\" is feasible at the level of observation histories, since two different trajectories would always have different histories, and thus \"similar states\" that might lead to effective stitching cannot be leveraged. Theoretically, we show that standard offline RL algorithms conditioned on observation histories suffer from poor sample complexity, in accordance with the above intuition. We then identify sufficient conditions under which offline RL can still be efficient -- intuitively, it needs to learn a compact representation of history comprising only features relevant for action selection. We introduce a bisimulation loss that captures the extent to which this happens, and propose that offline RL can explicitly optimize this loss to aid worst-case sample complexity. Empirically, we show that across a variety of tasks either our proposed loss improves performance, or the value of this loss is already minimized as a consequence of standard offline RL, indicating that it correlates well with good performance.", "url": "https://arxiv.org/abs/2310.20663"}, {"metadata": {"arXiv": "2310.20703", "Date": "Tue, 31 Oct 2023 17:59:05 ", "Title": "Vanishing Gradients in Reinforcement Finetuning of Language Models", "Authors": ["Noam Razin", "Hattie Zhou", "Omid Saremi", "Vimal Thilak", "Arwen Bradley", "Preetum Nakkiran", "Joshua Susskind", "Etai Littwin"], "Categories": "cs.LG cs.AI cs.CL stat.ML"}, "abstract": "Pretrained language models are commonly aligned with human preferences and downstream tasks via reinforcement finetuning (RFT), which entails maximizing a (possibly learned) reward function using policy gradient algorithms. This work highlights a fundamental optimization obstacle in RFT: we prove that the expected gradient for an input vanishes when its reward standard deviation under the model is small, even if the expected reward is far from optimal. Through experiments on an RFT benchmark and controlled environments, as well as a theoretical analysis, we then demonstrate that vanishing gradients due to small reward standard deviation are prevalent and detrimental, leading to extremely slow reward maximization. Lastly, we explore ways to overcome vanishing gradients in RFT. We find the common practice of an initial supervised finetuning (SFT) phase to be the most promising candidate, which sheds light on its importance in an RFT pipeline. Moreover, we show that a relatively small number of SFT optimization steps on as few as 1% of the input samples can suffice, indicating that the initial SFT phase need not be expensive in terms of compute and data labeling efforts. Overall, our results emphasize that being mindful for inputs whose expected gradient vanishes, as measured by the reward standard deviation, is crucial for successful execution of RFT.", "url": "https://arxiv.org/abs/2310.20703"}, {"metadata": {"arXiv": "2310.19944", "Date": "Mon, 30 Oct 2023 18:59:32 ", "Title": "Conditional Unscented Autoencoders for Trajectory Prediction", "Authors": ["Faris Janjo\\v{s}", "Marcel Hallgarten", "Anthony Knittel", "Maxim Dolgov", "Andreas Zell", "J. Marius Z\\\"ollner"], "Categories": "cs.RO cs.AI cs.CV cs.LG"}, "abstract": "The \\ac{CVAE} is one of the most widely-used models in trajectory prediction for \\ac{AD}. It captures the interplay between a driving context and its ground-truth future into a probabilistic latent space and uses it to produce predictions. In this paper, we challenge key components of the CVAE. We leverage recent advances in the space of the VAE, the foundation of the CVAE, which show that a simple change in the sampling procedure can greatly benefit performance. We find that unscented sampling, which draws samples from any learned distribution in a deterministic manner, can naturally be better suited to trajectory prediction than potentially dangerous random sampling. We go further and offer additional improvements, including a more structured mixture latent space, as well as a novel, potentially more expressive way to do inference with CVAEs. We show wide applicability of our models by evaluating them on the INTERACTION prediction dataset, outperforming the state of the art, as well as at the task of image modeling on the CelebA dataset, outperforming the baseline vanilla CVAE. Code is available at https://github.com/boschresearch/cuae-prediction.", "url": "https://arxiv.org/abs/2310.19944"}, {"metadata": {"arXiv": "2310.20024", "Date": "Mon, 30 Oct 2023 21:16:46 ", "Title": "Topology Recoverability Prediction for Ad-Hoc Robot Networks: A Data-Driven Fault-Tolerant Approach", "Authors": ["Matin Macktoobian and Zhan Shu and Qing Zhao"], "Categories": "cs.RO cs.AI cs.LG cs.MA", "Journal-ref": "IEEE Transactions on Signal and Information Processing over Networks, 2023", "DOI": "10.1109/TSIPN.2023.3328275"}, "abstract": "Faults occurring in ad-hoc robot networks may fatally perturb their topologies leading to disconnection of subsets of those networks. Optimal topology synthesis is generally resource-intensive and time-consuming to be done in real time for large ad-hoc robot networks. One should only perform topology re-computations if the probability of topology recoverability after the occurrence of any fault surpasses that of its irrecoverability. We formulate this problem as a binary classification problem. Then, we develop a two-pathway data-driven model based on Bayesian Gaussian mixture models that predicts the solution to a typical problem by two different pre-fault and post-fault prediction pathways. The results, obtained by the integration of the predictions of those pathways, clearly indicate the success of our model in solving the topology (ir)recoverability prediction problem compared to the best of current strategies found in the literature.", "url": "https://arxiv.org/abs/2310.20024"}, {"metadata": {"arXiv": "2310.20350", "Date": "Tue, 31 Oct 2023 10:46:19 ", "Title": "Combining Shape Completion and Grasp Prediction for Fast and Versatile Grasping with a Multi-Fingered Hand", "Authors": ["Matthias Humt", "Dominik Winkelbauer", "Ulrich Hillenbrand and Berthold B\\\"auml"], "Categories": "cs.RO cs.AI cs.CV cs.LG", "Comments": ["8 pages", "10 figures", "3 tables", "1 algorithm", "2023 IEEE-RAS International Conference on Humanoid Robots (Humanoids)", "Project page: https://dlr-alr.github.io/2023-humanoids-completion"]}, "abstract": "Grasping objects with limited or no prior knowledge about them is a highly relevant skill in assistive robotics. Still, in this general setting, it has remained an open problem, especially when it comes to only partial observability and versatile grasping with multi-fingered hands. We present a novel, fast, and high fidelity deep learning pipeline consisting of a shape completion module that is based on a single depth image, and followed by a grasp predictor that is based on the predicted object shape. The shape completion network is based on VQDIF and predicts spatial occupancy values at arbitrary query points. As grasp predictor, we use our two-stage architecture that first generates hand poses using an autoregressive model and then regresses finger joint configurations per pose. Critical factors turn out to be sufficient data realism and augmentation, as well as special attention to difficult cases during training. Experiments on a physical robot platform demonstrate successful grasping of a wide range of household objects based on a depth image from a single viewpoint. The whole pipeline is fast, taking only about 1 s for completing the object's shape (0.7 s) and generating 1000 grasps (0.3 s).", "url": "https://arxiv.org/abs/2310.20350"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

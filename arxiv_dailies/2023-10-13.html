<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2310.07855", "Date": "Wed, 11 Oct 2023 19:57:51 ", "Title": "CrIBo: Self-Supervised Learning via Cross-Image Object-Level Bootstrapping", "Authors": ["Tim Lebailly", "Thomas Stegm\\\"uller", "Behzad Bozorgtabar", "Jean-Philippe Thiran", "Tinne Tuytelaars"], "Categories": "cs.CV cs.LG"}, "abstract": "Leveraging nearest neighbor retrieval for self-supervised representation learning has proven beneficial with object-centric images. However, this approach faces limitations when applied to scene-centric datasets, where multiple objects within an image are only implicitly captured in the global representation. Such global bootstrapping can lead to undesirable entanglement of object representations. Furthermore, even object-centric datasets stand to benefit from a finer-grained bootstrapping approach. In response to these challenges, we introduce a novel Cross-Image Object-Level Bootstrapping method tailored to enhance dense visual representation learning. By employing object-level nearest neighbor bootstrapping throughout the training, CrIBo emerges as a notably strong and adequate candidate for in-context learning, leveraging nearest neighbor retrieval at test time. CrIBo shows state-of-the-art performance on the latter task while being highly competitive in more standard downstream segmentation tasks. Our code and pretrained models will be publicly available upon acceptance.", "url": "https://arxiv.org/abs/2310.07855"}, {"metadata": {"arXiv": "2310.07969", "Date": "Thu, 12 Oct 2023 01:25:21 ", "Title": "CleftGAN: Adapting A Style-Based Generative Adversarial Network To Create Images Depicting Cleft Lip Deformity", "Authors": ["Abdullah Hayajneh and Erchin Serpedin and Mohammad Shaqfeh and Graeme Glass and Mitchell A. Stotland"], "Categories": "cs.CV cs.LG"}, "abstract": "A major obstacle when attempting to train a machine learning system to evaluate facial clefts is the scarcity of large datasets of high-quality, ethics board-approved patient images. In response, we have built a deep learning-based cleft lip generator designed to produce an almost unlimited number of artificial images exhibiting high-fidelity facsimiles of cleft lip with wide variation. We undertook a transfer learning protocol testing different versions of StyleGAN-ADA (a generative adversarial network image generator incorporating adaptive data augmentation (ADA)) as the base model. Training images depicting a variety of cleft deformities were pre-processed to adjust for rotation, scaling, color adjustment and background blurring. The ADA modification of the primary algorithm permitted construction of our new generative model while requiring input of a relatively small number of training images. Adversarial training was carried out using 514 unique frontal photographs of cleft-affected faces to adapt a pre-trained model based on 70,000 normal faces. The Frechet Inception Distance (FID) was used to measure the similarity of the newly generated facial images to the cleft training dataset, while Perceptual Path Length (PPL) and the novel Divergence Index of Severity Histograms (DISH) measures were also used to assess the performance of the image generator that we dub CleftGAN. We found that StyleGAN3 with translation invariance (StyleGAN3-t) performed optimally as a base model. Generated images achieved a low FID reflecting a close similarity to our training input dataset of genuine cleft images. Low PPL and DISH measures reflected a smooth and semantically valid interpolation of images through the transfer learning process and a similar distribution of severity in the training and generated images, respectively.", "url": "https://arxiv.org/abs/2310.07969"}, {"metadata": {"arXiv": "2310.08182", "Date": "Thu, 12 Oct 2023 10:17:40 ", "Title": "XIMAGENET-12: An Explainable AI Benchmark Dataset for Model Robustness Evaluation", "Authors": ["Qiang Li", "Dan Zhang", "Shengzhao Lei", "Xun Zhao", "Shuyan Li", "Porawit Kamnoedboon", "WeiWei Li"], "Categories": "cs.CV cs.LG", "Comments": ["UnderSubmission"]}, "abstract": "The lack of standardized robustness metrics and the widespread reliance on numerous unrelated benchmark datasets for testing have created a gap between academically validated robust models and their often problematic practical adoption. To address this, we introduce XIMAGENET-12, an explainable benchmark dataset with over 200K images and 15,600 manual semantic annotations. Covering 12 categories from ImageNet to represent objects commonly encountered in practical life and simulating six diverse scenarios, including overexposure, blurring, color changing, etc., we further propose a novel robustness criterion that extends beyond model generation ability assessment. This benchmark dataset, along with related code, is available at https://sites.google.com/view/ximagenet-12/home. Researchers and practitioners can leverage this resource to evaluate the robustness of their visual models under challenging conditions and ultimately benefit from the demands of practical computer vision systems.", "url": "https://arxiv.org/abs/2310.08182"}, {"metadata": {"arXiv": "2310.08204", "Date": "Thu, 12 Oct 2023 10:50:21 ", "Title": "Lifelong Audio-video Masked Autoencoder with Forget-robust Localized Alignments", "Authors": ["Jaewoo Lee", "Jaehong Yoon", "Wonjae Kim", "Yunji Kim", "and Sung Ju Hwang"], "Categories": "cs.CV cs.LG", "Comments": ["Preprint", "project page: https://g-jwlee.github.io/FLAVA/"]}, "abstract": "We present a lifelong audio-video masked autoencoder that continually learns the multimodal representations from a video stream containing audio-video pairs, while its distribution continually shifts over time. Specifically, we propose two novel ideas to tackle the problem: (1) Localized Alignment: We introduce a small trainable multimodal encoder that predicts the audio and video tokens that are well-aligned with each other. This allows the model to learn only the highly correlated audiovisual patches with accurate multimodal relationships. (2) Forget-robust multimodal patch selection: We compare the relative importance of each audio-video patch between the current and past data pair to mitigate unintended drift of the previously learned audio-video representations. Our proposed method, FLAVA (Forget-robust Localized Audio-Video Alignment), therefore, captures the complex relationships between the audio and video modalities during training on a sequence of pre-training tasks while alleviating the forgetting of learned audiovisual correlations. Our experiments validate that FLAVA outperforms the state-of-the-art continual learning methods on several benchmark datasets under continual audio-video representation learning scenarios.", "url": "https://arxiv.org/abs/2310.08204"}, {"metadata": {"arXiv": "2310.08312", "Date": "Thu, 12 Oct 2023 13:20:17 ", "Title": "GePSAn: Generative Procedure Step Anticipation in Cooking Videos", "Authors": ["Mohamed Ashraf Abdelsalam", "Samrudhdhi B. Rangrej", "Isma Hadji", "Nikita Dvornik", "Konstantinos G. Derpanis", "Afsaneh Fazly"], "Categories": "cs.CV cs.LG", "Comments": ["published at ICCV 2023"]}, "abstract": "We study the problem of future step anticipation in procedural videos. Given a video of an ongoing procedural activity, we predict a plausible next procedure step described in rich natural language. While most previous work focus on the problem of data scarcity in procedural video datasets, another core challenge of future anticipation is how to account for multiple plausible future realizations in natural settings. This problem has been largely overlooked in previous work. To address this challenge, we frame future step prediction as modelling the distribution of all possible candidates for the next step. Specifically, we design a generative model that takes a series of video clips as input, and generates multiple plausible and diverse candidates (in natural language) for the next step. Following previous work, we side-step the video annotation scarcity by pretraining our model on a large text-based corpus of procedural activities, and then transfer the model to the video domain. Our experiments, both in textual and video domains, show that our model captures diversity in the next step prediction and generates multiple plausible future predictions. Moreover, our model establishes new state-of-the-art results on YouCookII, where it outperforms existing baselines on the next step anticipation. Finally, we also show that our model can successfully transfer from text to the video domain zero-shot, ie, without fine-tuning or adaptation, and produces good-quality future step predictions from video.", "url": "https://arxiv.org/abs/2310.08312"}, {"metadata": {"arXiv": "2310.08381", "Date": "Thu, 12 Oct 2023 14:55:31 ", "Title": "AutoVP: An Automated Visual Prompting Framework and Benchmark", "Authors": ["Hsi-Ai Tsao", "Lei Hsiung", "Pin-Yu Chen", "Sijia Liu", "Tsung-Yi Ho"], "Categories": "cs.CV cs.LG", "Comments": ["Preprint. The code is available at https://github.com/IBM/AutoVP"]}, "abstract": "Visual prompting (VP) is an emerging parameter-efficient fine-tuning approach to adapting pre-trained vision models to solve various downstream image-classification tasks. However, there has hitherto been little systematic study of the design space of VP and no clear benchmark for evaluating its performance. To bridge this gap, we propose AutoVP, an end-to-end expandable framework for automating VP design choices, along with 12 downstream image-classification tasks that can serve as a holistic VP-performance benchmark. Our design space covers 1) the joint optimization of the prompts; 2) the selection of pre-trained models, including image classifiers and text-image encoders; and 3) model output mapping strategies, including nonparametric and trainable label mapping. Our extensive experimental results show that AutoVP outperforms the best-known current VP methods by a substantial margin, having up to 6.7% improvement in accuracy; and attains a maximum performance increase of 27.5% compared to linear-probing (LP) baseline. AutoVP thus makes a two-fold contribution: serving both as an efficient tool for hyperparameter tuning on VP design choices, and as a comprehensive benchmark that can reasonably be expected to accelerate VP's development. The source code is available at https://github.com/IBM/AutoVP.", "url": "https://arxiv.org/abs/2310.08381"}, {"metadata": {"arXiv": "2310.08387", "Date": "Thu, 12 Oct 2023 14:59:22 ", "Title": "MeanAP-Guided Reinforced Active Learning for Object Detection", "Authors": ["Zhixuan Liang", "Xingyu Zeng", "Rui Zhao", "Ping Luo"], "Categories": "cs.CV cs.LG"}, "abstract": "Active learning presents a promising avenue for training high-performance models with minimal labeled data, achieved by judiciously selecting the most informative instances to label and incorporating them into the task learner. Despite notable advancements in active learning for image recognition, metrics devised or learned to gauge the information gain of data, crucial for query strategy design, do not consistently align with task model performance metrics, such as Mean Average Precision (MeanAP) in object detection tasks. This paper introduces MeanAP-Guided Reinforced Active Learning for Object Detection (MAGRAL), a novel approach that directly utilizes the MeanAP metric of the task model to devise a sampling strategy employing a reinforcement learning-based sampling agent. Built upon LSTM architecture, the agent efficiently explores and selects subsequent training instances, and optimizes the process through policy gradient with MeanAP serving as reward. Recognizing the time-intensive nature of MeanAP computation at each step, we propose fast look-up tables to expedite agent training. We assess MAGRAL's efficacy across popular benchmarks, PASCAL VOC and MS COCO, utilizing different backbone architectures. Empirical findings substantiate MAGRAL's superiority over recent state-of-the-art methods, showcasing substantial performance gains. MAGRAL establishes a robust baseline for reinforced active object detection, signifying its potential in advancing the field.", "url": "https://arxiv.org/abs/2310.08387"}, {"metadata": {"arXiv": "2310.08577", "Date": "Thu, 12 Oct 2023 17:59:30 ", "Title": "Visual Data-Type Understanding does not emerge from Scaling Vision-Language Models", "Authors": ["Vishaal Udandarao", "Max F. Burg", "Samuel Albanie", "Matthias Bethge"], "Categories": "cs.CV cs.CL cs.LG"}, "abstract": "Recent advances in the development of vision-language models (VLMs) are yielding remarkable success in recognizing visual semantic content, including impressive instances of compositional image understanding. Here, we introduce the novel task of \\textit{Visual Data-Type Identification}, a basic perceptual skill with implications for data curation (e.g., noisy data-removal from large datasets, domain-specific retrieval) and autonomous vision (e.g., distinguishing changing weather conditions from camera lens staining). We develop two datasets consisting of animal images altered across a diverse set of 27 visual \\textit{data-types}, spanning four broad categories. An extensive zero-shot evaluation of 39 VLMs, ranging from 100M to 80B parameters, shows a nuanced performance landscape. While VLMs are reasonably good at identifying certain stylistic \\textit{data-types}, such as cartoons and sketches, they struggle with simpler \\textit{data-types} arising from basic manipulations like image rotations or additive noise. Our findings reveal that (i) model scaling alone yields marginal gains for contrastively-trained models like CLIP, and (ii) there is a pronounced drop in performance for the largest auto-regressively trained VLMs like OpenFlamingo. This finding points to a blind spot in current frontier VLMs: they excel in recognizing semantic content but fail to acquire an understanding of visual \\textit{data-types} through scaling. By analyzing the pre-training distributions of these models and incorporating \\textit{data-type} information into the captions during fine-tuning, we achieve a significant enhancement in performance. By exploring this previously uncharted task, we aim to set the stage for further advancing VLMs to equip them with visual data-type understanding. Code and datasets are released \\href{https://github.com/bethgelab/DataTypeIdentification}{here}.", "url": "https://arxiv.org/abs/2310.08577"}, {"metadata": {"arXiv": "2310.08339", "Date": "Thu, 12 Oct 2023 13:57:32 ", "Title": "A Generic Software Framework for Distributed Topological Analysis Pipelines", "Authors": ["Eve Le Guillou", "Michael Will", "Pierre Guillou", "Jonas Lukasczyk", "Pierre Fortin", "Christoph Garth", "Julien Tierny"], "Categories": "cs.DC cs.CG cs.CV cs.LG cs.MS", "Comments": ["18 pages", "12 figures"]}, "abstract": "This system paper presents a software framework for the support of topological analysis pipelines in a distributed-memory model. While several recent papers introduced topology-based approaches for distributed-memory environments, these were reporting experiments obtained with tailored, mono-algorithm implementations. In contrast, we describe in this paper a general-purpose, generic framework for topological analysis pipelines, i.e. a sequence of topological algorithms interacting together, possibly on distinct numbers of processes. Specifically, we instantiated our framework with the MPI model, within the Topology ToolKit (TTK). While developing this framework, we faced several algorithmic and software engineering challenges, which we document in this paper. We provide a taxonomy for the distributed-memory topological algorithms supported by TTK, depending on their communication needs and provide examples of hybrid MPI+thread parallelizations. Detailed performance analyses show that parallel efficiencies range from $20\\%$ to $80\\%$ (depending on the algorithms), and that the MPI-specific preconditioning introduced by our framework induces a negligible computation time overhead. We illustrate the new distributed-memory capabilities of TTK with an example of advanced analysis pipeline, combining multiple algorithms, run on the largest publicly available dataset we have found (120 billion vertices) on a standard cluster with 64 nodes (for a total of 1,536 cores). Finally, we provide a roadmap for the completion of TTK's MPI extension, along with generic recommendations for each algorithm communication category.", "url": "https://arxiv.org/abs/2310.08339"}, {"metadata": {"arXiv": "2310.07874", "Date": "Wed, 11 Oct 2023 20:34:17 ", "Title": "Refined Mechanism Design for Approximately Structured Priors via Active Regression", "Authors": ["Christos Boutsikas", "Petros Drineas", "Marios Mertzanidis", "Alexandros Psomas", "Paritosh Verma"], "Categories": "cs.GT cs.DS cs.IR cs.LG", "Comments": ["37th Conference on Neural Information Processing Systems (NeurIPS 2023)"]}, "abstract": "We consider the problem of a revenue-maximizing seller with a large number of items $m$ for sale to $n$ strategic bidders, whose valuations are drawn independently from high-dimensional, unknown prior distributions. It is well-known that optimal and even approximately-optimal mechanisms for this setting are notoriously difficult to characterize or compute, and, even when they can be found, are often rife with various counter-intuitive properties. In this paper, following a model introduced recently by Cai and Daskalakis~\\cite{cai2022recommender}, we consider the case that bidders' prior distributions can be well-approximated by a topic model. We design an active learning component, responsible for interacting with the bidders and outputting low-dimensional approximations of their types, and a mechanism design component, responsible for robustifying mechanisms for the low-dimensional model to work for the approximate types of the former component. On the active learning front, we cast our problem in the framework of Randomized Linear Algebra (RLA) for regression problems, allowing us to import several breakthrough results from that line of research, and adapt them to our setting. On the mechanism design front, we remove many restrictive assumptions of prior work on the type of access needed to the underlying distributions and the associated mechanisms. To the best of our knowledge, our work is the first to formulate connections between mechanism design, and RLA for active learning of regression problems, opening the door for further applications of randomized linear algebra primitives to mechanism design.", "url": "https://arxiv.org/abs/2310.07874"}, {"metadata": {"arXiv": "2310.07720", "Date": "Fri, 11 Aug 2023 08:59:27 ", "Title": "Parametric Leaky Tanh: A New Hybrid Activation Function for Deep Learning", "Authors": ["Stamatis Mastromichalakis"], "Categories": "cs.LG cs.NE", "Comments": ["11 pages,2 figures,1 table,1 Python code snippets"], "MSC-class": "68T07, 68T45, 68T10, 68T50, 68U35"}, "abstract": "Activation functions (AFs) are crucial components of deep neural networks (DNNs), having a significant impact on their performance. An activation function in a DNN is typically a smooth, nonlinear function that transforms an input signal into an output signal for the subsequent layer. In this paper, we propose the Parametric Leaky Tanh (PLTanh), a novel hybrid activation function designed to combine the strengths of both the Tanh and Leaky ReLU (LReLU) activation functions. PLTanh is differentiable at all points and addresses the 'dying ReLU' problem by ensuring a non-zero gradient for negative inputs, consistent with the behavior of LReLU. By integrating the unique advantages of these two diverse activation functions, PLTanh facilitates the learning of more intricate nonlinear relationships within the network. This paper presents an empirical evaluation of PLTanh against established activation functions, namely ReLU, LReLU, and ALReLU utilizing five diverse datasets.", "url": "https://arxiv.org/abs/2310.07720"}, {"metadata": {"arXiv": "2310.07725", "Date": "Tue, 19 Sep 2023 21:31:25 ", "Title": "Extreme Image Transformations Facilitate Robust Latent Object Representations", "Authors": ["Girik Malik and Dakarai Crowder and Ennio Mingolla"], "Categories": "cs.LG cs.CV eess.IV"}, "abstract": "Adversarial attacks can affect the object recognition capabilities of machines in wild. These can often result from spurious correlations between input and class labels, and are prone to memorization in large networks. While networks are expected to do automated feature selection, it is not effective at the scale of the object. Humans, however, are able to select the minimum set of features required to form a robust representation of an object. In this work, we show that finetuning any pretrained off-the-shelf network with Extreme Image Transformations (EIT) not only helps in learning a robust latent representation, it also improves the performance of these networks against common adversarial attacks of various intensities. Our EIT trained networks show strong activations in the object regions even when tested with more intense noise, showing promising generalizations across different kinds of adversarial attacks.", "url": "https://arxiv.org/abs/2310.07725"}, {"metadata": {"arXiv": "2310.07745", "Date": "Wed, 11 Oct 2023 16:24:14 ", "Title": "Deep Reinforcement Learning for Autonomous Cyber Operations: A Survey", "Authors": ["Gregory Palmer", "Chris Parry", "Daniel J.B. Harrold", "Chris Willis"], "Categories": "cs.LG", "Comments": ["60 pages", "14 figures", "3 tables"]}, "abstract": "The rapid increase in the number of cyber-attacks in recent years raises the need for principled methods for defending networks against malicious actors. Deep reinforcement learning (DRL) has emerged as a promising approach for mitigating these attacks. However, while DRL has shown much potential for cyber-defence, numerous challenges must be overcome before DRL can be applied to autonomous cyber-operations (ACO) at scale. Principled methods are required for environments that confront learners with very high-dimensional state spaces, large multi-discrete action spaces, and adversarial learning. Recent works have reported success in solving these problems individually. There have also been impressive engineering efforts towards solving all three for real-time strategy games. However, applying DRL to the full ACO problem remains an open challenge. Here, we survey the relevant DRL literature and conceptualize an idealised ACO-DRL agent. We provide: i.) A summary of the domain properties that define the ACO problem; ii.) A comprehensive evaluation of the extent to which domains used for benchmarking DRL approaches are comparable to ACO; iii.) An overview of state-of-the-art approaches for scaling DRL to domains that confront learners with the curse of dimensionality, and; iv.) A survey and critique of current methods for limiting the exploitability of agents within adversarial settings from the perspective of ACO. We conclude with open research questions that we hope will motivate future directions for researchers and practitioners working on ACO.", "url": "https://arxiv.org/abs/2310.07745"}, {"metadata": {"arXiv": "2310.07756", "Date": "Wed, 11 Oct 2023 18:00:01 ", "Title": "Self-supervised Representation Learning From Random Data Projectors", "Authors": ["Yi Sui", "Tongzi Wu", "Jesse.C.Cresswell", "Ga Wu", "George Stein", "Xiaoshi Huang", "Xiaochen Zhang", "Maksims Volkovs"], "Categories": "cs.LG"}, "abstract": "Self-supervised representation learning~(SSRL) has advanced considerably by exploiting the transformation invariance assumption under artificially designed data augmentations. While augmentation-based SSRL algorithms push the boundaries of performance in computer vision and natural language processing, they are often not directly applicable to other data modalities, and can conflict with application-specific data augmentation constraints. This paper presents an SSRL approach that can be applied to any data modality and network architecture because it does not rely on augmentations or masking. Specifically, we show that high-quality data representations can be learned by reconstructing random data projections. We evaluate the proposed approach on a wide range of representation learning tasks that span diverse modalities and real-world applications. We show that it outperforms multiple state-of-the-art SSRL baselines. Due to its wide applicability and strong empirical results, we argue that learning from randomness is a fruitful research direction worthy of attention and further study.", "url": "https://arxiv.org/abs/2310.07756"}, {"metadata": {"arXiv": "2310.07765", "Date": "Wed, 11 Oct 2023 18:00:02 ", "Title": "Feature Learning and Generalization in Deep Networks with Orthogonal Weights", "Authors": ["Hannah Day", "Yonatan Kahn", "Daniel A. Roberts"], "Categories": "cs.LG hep-ph hep-th stat.ML", "Comments": ["v1: 30+11 pages", "19 figures"], "Report-no": "MIT-CTP/5625"}, "abstract": "Fully-connected deep neural networks with weights initialized from independent Gaussian distributions can be tuned to criticality, which prevents the exponential growth or decay of signals propagating through the network. However, such networks still exhibit fluctuations that grow linearly with the depth of the network, which may impair the training of networks with width comparable to depth. We show analytically that rectangular networks with tanh activations and weights initialized from the ensemble of orthogonal matrices have corresponding preactivation fluctuations which are independent of depth, to leading order in inverse width. Moreover, we demonstrate numerically that, at initialization, all correlators involving the neural tangent kernel (NTK) and its descendants at leading order in inverse width -- which govern the evolution of observables during training -- saturate at a depth of $\\sim 20$, rather than growing without bound as in the case of Gaussian initializations. We speculate that this structure preserves finite-width feature learning while reducing overall noise, thus improving both generalization and training speed. We provide some experimental justification by relating empirical measurements of the NTK to the superior performance of deep nonlinear orthogonal networks trained under full-batch gradient descent on the MNIST and CIFAR-10 classification tasks.", "url": "https://arxiv.org/abs/2310.07765"}, {"metadata": {"arXiv": "2310.07780", "Date": "Wed, 11 Oct 2023 18:06:05 ", "Title": "Promoting Robustness of Randomized Smoothing: Two Cost-Effective Approaches", "Authors": ["Linbo Liu", "Trong Nghia Hoang", "Lam M. Nguyen", "Tsui-Wei Weng"], "Categories": "cs.LG"}, "abstract": "Randomized smoothing has recently attracted attentions in the field of adversarial robustness to provide provable robustness guarantees on smoothed neural network classifiers. However, existing works show that vanilla randomized smoothing usually does not provide good robustness performance and often requires (re)training techniques on the base classifier in order to boost the robustness of the resulting smoothed classifier. In this work, we propose two cost-effective approaches to boost the robustness of randomized smoothing while preserving its clean performance. The first approach introduces a new robust training method AdvMacerwhich combines adversarial training and robustness certification maximization for randomized smoothing. We show that AdvMacer can improve the robustness performance of randomized smoothing classifiers compared to SOTA baselines, while being 3x faster to train than MACER baseline. The second approach introduces a post-processing method EsbRS which greatly improves the robustness certificate based on building model ensembles. We explore different aspects of model ensembles that has not been studied by prior works and propose a novel design methodology to further improve robustness of the ensemble based on our theoretical analysis.", "url": "https://arxiv.org/abs/2310.07780"}, {"metadata": {"arXiv": "2310.07786", "Date": "Wed, 11 Oct 2023 18:15:55 ", "Title": "Non-Stationary Contextual Bandit Learning via Neural Predictive Ensemble Sampling", "Authors": ["Zheqing Zhu", "Yueyang Liu", "Xu Kuang", "Benjamin Van Roy"], "Categories": "cs.LG cs.IR"}, "abstract": "Real-world applications of contextual bandits often exhibit non-stationarity due to seasonality, serendipity, and evolving social trends. While a number of non-stationary contextual bandit learning algorithms have been proposed in the literature, they excessively explore due to a lack of prioritization for information of enduring value, or are designed in ways that do not scale in modern applications with high-dimensional user-specific features and large action set, or both. In this paper, we introduce a novel non-stationary contextual bandit algorithm that addresses these concerns. It combines a scalable, deep-neural-network-based architecture with a carefully designed exploration mechanism that strategically prioritizes collecting information with the most lasting value in a non-stationary environment. Through empirical evaluations on two real-world recommendation datasets, which exhibit pronounced non-stationarity, we demonstrate that our approach significantly outperforms the state-of-the-art baselines.", "url": "https://arxiv.org/abs/2310.07786"}, {"metadata": {"arXiv": "2310.07787", "Date": "Wed, 11 Oct 2023 18:20:17 ", "Title": "Using Spark Machine Learning Models to Perform Predictive Analysis on Flight Ticket Pricing Data", "Authors": ["Philip Wong", "Phue Thant", "Pratiksha Yadav", "Ruta Antaliya", "Jongwook Woo"], "Categories": "cs.LG cs.DC", "Comments": ["4 pages", "13 figures", "1 table"]}, "abstract": "This paper discusses predictive performance and processes undertaken on flight pricing data utilizing r2(r-square) and RMSE that leverages a large dataset, originally from Expedia.com, consisting of approximately 20 million records or 4.68 gigabytes. The project aims to determine the best models usable in the real world to predict airline ticket fares for non-stop flights across the US. Therefore, good generalization capability and optimized processing times are important measures for the model. We will discover key business insights utilizing feature importance and discuss the process and tools used for our analysis. Four regression machine learning algorithms were utilized: Random Forest, Gradient Boost Tree, Decision Tree, and Factorization Machines utilizing Cross Validator and Training Validator functions for assessing performance and generalization capability.", "url": "https://arxiv.org/abs/2310.07787"}, {"metadata": {"arXiv": "2310.07807", "Date": "Wed, 11 Oct 2023 18:39:08 ", "Title": "FedSym: Unleashing the Power of Entropy for Benchmarking the Algorithms for Federated Learning", "Authors": ["Ensiye Kiyamousavi", "Boris Kraychev", "Ivan Koychev"], "Categories": "cs.LG"}, "abstract": "Federated learning (FL) is a decentralized machine learning approach where independent learners process data privately. Its goal is to create a robust and accurate model by aggregating and retraining local models over multiple rounds. However, FL faces challenges regarding data heterogeneity and model aggregation effectiveness. In order to simulate real-world data, researchers use methods for data partitioning that transform a dataset designated for centralized learning into a group of sub-datasets suitable for distributed machine learning with different data heterogeneity. In this paper, we study the currently popular data partitioning techniques and visualize their main disadvantages: the lack of precision in the data diversity, which leads to unreliable heterogeneity indexes, and the inability to incrementally challenge the FL algorithms. To resolve this problem, we propose a method that leverages entropy and symmetry to construct 'the most challenging' and controllable data distributions with gradual difficulty. We introduce a metric to measure data heterogeneity among the learning agents and a transformation technique that divides any dataset into splits with precise data diversity. Through a comparative study, we demonstrate the superiority of our method over existing FL data partitioning approaches, showcasing its potential to challenge model aggregation algorithms. Experimental results indicate that our approach gradually challenges the FL strategies, and the models trained on FedSym distributions are more distinct.", "url": "https://arxiv.org/abs/2310.07807"}, {"metadata": {"arXiv": "2310.07811", "Date": "Wed, 11 Oct 2023 18:50:25 ", "Title": "Online RL in Linearly $q^\\pi$-Realizable MDPs Is as Easy as in Linear MDPs If You Learn What to Ignore", "Authors": ["Gell\\'ert Weisz and Andr\\'as Gy\\\"orgy and Csaba Szepesv\\'ari"], "Categories": "cs.LG stat.ML"}, "abstract": "We consider online reinforcement learning (RL) in episodic Markov decision processes (MDPs) under the linear $q^\\pi$-realizability assumption, where it is assumed that the action-values of all policies can be expressed as linear functions of state-action features. This class is known to be more general than linear MDPs, where the transition kernel and the reward function are assumed to be linear functions of the feature vectors. As our first contribution, we show that the difference between the two classes is the presence of states in linearly $q^\\pi$-realizable MDPs where for any policy, all the actions have approximately equal values, and skipping over these states by following an arbitrarily fixed policy in those states transforms the problem to a linear MDP. Based on this observation, we derive a novel (computationally inefficient) learning algorithm for linearly $q^\\pi$-realizable MDPs that simultaneously learns what states should be skipped over and runs another learning algorithm on the linear MDP hidden in the problem. The method returns an $\\epsilon$-optimal policy after $\\text{polylog}(H, d)/\\epsilon^2$ interactions with the MDP, where $H$ is the time horizon and $d$ is the dimension of the feature vectors, giving the first polynomial-sample-complexity online RL algorithm for this setting. The results are proved for the misspecified case, where the sample complexity is shown to degrade gracefully with the misspecification error.", "url": "https://arxiv.org/abs/2310.07811"}, {"metadata": {"arXiv": "2310.07820", "Date": "Wed, 11 Oct 2023 19:01:28 ", "Title": "Large Language Models Are Zero-Shot Time Series Forecasters", "Authors": ["Nate Gruver", "Marc Finzi", "Shikai Qiu", "Andrew Gordon Wilson"], "Categories": "cs.LG", "Comments": ["NeurIPS 2023. Code available at: https://github.com/ngruver/llmtime"]}, "abstract": "By encoding time series as a string of numerical digits, we can frame time series forecasting as next-token prediction in text. Developing this approach, we find that large language models (LLMs) such as GPT-3 and LLaMA-2 can surprisingly zero-shot extrapolate time series at a level comparable to or exceeding the performance of purpose-built time series models trained on the downstream tasks. To facilitate this performance, we propose procedures for effectively tokenizing time series data and converting discrete distributions over tokens into highly flexible densities over continuous values. We argue the success of LLMs for time series stems from their ability to naturally represent multimodal distributions, in conjunction with biases for simplicity, and repetition, which align with the salient features in many time series, such as repeated seasonal trends. We also show how LLMs can naturally handle missing data without imputation through non-numerical text, accommodate textual side information, and answer questions to help explain predictions. While we find that increasing model size generally improves performance on time series, we show GPT-4 can perform worse than GPT-3 because of how it tokenizes numbers, and poor uncertainty calibration, which is likely the result of alignment interventions such as RLHF.", "url": "https://arxiv.org/abs/2310.07820"}, {"metadata": {"arXiv": "2310.07837", "Date": "Wed, 11 Oct 2023 19:26:52 ", "Title": "Measuring Feature Sparsity in Language Models", "Authors": ["Mingyang Deng", "Lucas Tao", "Joe Benton"], "Categories": "cs.LG"}, "abstract": "Recent works have proposed that activations in language models can be modelled as sparse linear combinations of vectors corresponding to features of input text. Under this assumption, these works aimed to reconstruct feature directions using sparse coding. We develop metrics to assess the success of these sparse coding techniques and test the validity of the linearity and sparsity assumptions. We show our metrics can predict the level of sparsity on synthetic sparse linear activations, and can distinguish between sparse linear data and several other distributions. We use our metrics to measure levels of sparsity in several language models. We find evidence that language model activations can be accurately modelled by sparse linear combinations of features, significantly more so than control datasets. We also show that model activations appear to be sparsest in the first and final layers.", "url": "https://arxiv.org/abs/2310.07837"}, {"metadata": {"arXiv": "2310.07895", "Date": "Wed, 11 Oct 2023 21:07:04 ", "Title": "Precise localization within the GI tract by combining classification of CNNs and time-series analysis of HMMs", "Authors": ["Julia Werner", "Christoph Gerum", "Moritz Reiber", "J\\\"org Nick", "and Oliver Bringmann"], "Categories": "cs.LG", "Comments": ["Accepted at MLMI 2023"]}, "abstract": "This paper presents a method to efficiently classify the gastroenterologic section of images derived from Video Capsule Endoscopy (VCE) studies by exploring the combination of a Convolutional Neural Network (CNN) for classification with the time-series analysis properties of a Hidden Markov Model (HMM). It is demonstrated that successive time-series analysis identifies and corrects errors in the CNN output. Our approach achieves an accuracy of $98.04\\%$ on the Rhode Island (RI) Gastroenterology dataset. This allows for precise localization within the gastrointestinal (GI) tract while requiring only approximately 1M parameters and thus, provides a method suitable for low power devices", "url": "https://arxiv.org/abs/2310.07895"}, {"metadata": {"arXiv": "2310.07923", "Date": "Wed, 11 Oct 2023 22:35:18 ", "Title": "The Expresssive Power of Transformers with Chain of Thought", "Authors": ["William Merrill and Ashish Sabharwal"], "Categories": "cs.LG cs.CC cs.CL cs.LO", "Comments": ["9-page preprint"]}, "abstract": "Recent theoretical work has identified surprisingly simple reasoning problems, such as checking if two nodes in a graph are connected or simulating finite-state machines, that are provably unsolvable by standard transformers that answer immediately after reading their input. However, in practice, transformers' reasoning can be improved by allowing them to use a \"chain of thought\" or \"scratchpad\", i.e., generate and condition on a sequence of intermediate tokens before answering. Motivated by this, we ask: Does such intermediate generation fundamentally extend the computational power of a decoder-only transformer? We show that the answer is yes, but the amount of increase depends crucially on the amount of intermediate generation. For instance, we find that transformer decoders with a logarithmic number of decoding steps (w.r.t. the input length) push the limits of standard transformers only slightly, while a linear number of decoding steps adds a clear new ability (under standard complexity conjectures): recognizing all regular languages. Our results also imply that linear steps keep transformer decoders within context-sensitive languages, and polynomial steps make them recognize exactly the class of polynomial-time solvable problems -- the first exact characterization of a type of transformers in terms of standard complexity classes. Together, our results provide a nuanced framework for understanding how the length of a transformer's chain of thought or scratchpad impacts its reasoning power.", "url": "https://arxiv.org/abs/2310.07923"}, {"metadata": {"arXiv": "2310.07940", "Date": "Wed, 11 Oct 2023 23:22:30 ", "Title": "Cost-Driven Hardware-Software Co-Optimization of Machine Learning Pipelines", "Authors": ["Ravit Sharma", "Wojciech Romaszkan", "Feiqian Zhu", "Puneet Gupta"], "Categories": "cs.LG"}, "abstract": "Researchers have long touted a vision of the future enabled by a proliferation of internet-of-things devices, including smart sensors, homes, and cities. Increasingly, embedding intelligence in such devices involves the use of deep neural networks. However, their storage and processing requirements make them prohibitive for cheap, off-the-shelf platforms. Overcoming those requirements is necessary for enabling widely-applicable smart devices. While many ways of making models smaller and more efficient have been developed, there is a lack of understanding of which ones are best suited for particular scenarios. More importantly for edge platforms, those choices cannot be analyzed in isolation from cost and user experience. In this work, we holistically explore how quantization, model scaling, and multi-modality interact with system components such as memory, sensors, and processors. We perform this hardware/software co-design from the cost, latency, and user-experience perspective, and develop a set of guidelines for optimal system design and model deployment for the most cost-constrained platforms. We demonstrate our approach using an end-to-end, on-device, biometric user authentication system using a $20 ESP-EYE board.", "url": "https://arxiv.org/abs/2310.07940"}, {"metadata": {"arXiv": "2310.07970", "Date": "Thu, 12 Oct 2023 01:26:05 ", "Title": "Hyperparameter Adaptive Search for Surrogate Optimization: A Self-Adjusting Approach", "Authors": ["Nazanin Nezami and Hadis Anahideh"], "Categories": "cs.LG math.OC math.PR stat.ML", "Comments": ["2023 Winter Simulation Conference (WSC)"]}, "abstract": "Surrogate Optimization (SO) algorithms have shown promise for optimizing expensive black-box functions. However, their performance is heavily influenced by hyperparameters related to sampling and surrogate fitting, which poses a challenge to their widespread adoption. We investigate the impact of hyperparameters on various SO algorithms and propose a Hyperparameter Adaptive Search for SO (HASSO) approach. HASSO is not a hyperparameter tuning algorithm, but a generic self-adjusting SO algorithm that dynamically tunes its own hyperparameters while concurrently optimizing the primary objective function, without requiring additional evaluations. The aim is to improve the accessibility, effectiveness, and convergence speed of SO algorithms for practitioners. Our approach identifies and modifies the most influential hyperparameters specific to each problem and SO approach, reducing the need for manual tuning without significantly increasing the computational burden. Experimental results demonstrate the effectiveness of HASSO in enhancing the performance of various SO algorithms across different global optimization test problems.", "url": "https://arxiv.org/abs/2310.07970"}, {"metadata": {"arXiv": "2310.07979", "Date": "Thu, 12 Oct 2023 01:57:27 ", "Title": "Graph-SCP: Accelerating Set Cover Problems with Graph Neural Networks", "Authors": ["Zohair Shafi", "Benjamin A. Miller", "Tina Eliassi-Rad", "Rajmonda S. Caceres"], "Categories": "cs.LG cs.DM"}, "abstract": "Machine learning (ML) approaches are increasingly being used to accelerate combinatorial optimization (CO) problems. We look specifically at the Set Cover Problem (SCP) and propose Graph-SCP, a graph neural network method that can augment existing optimization solvers by learning to identify a much smaller sub-problem that contains the solution space. We evaluate the performance of Graph-SCP on synthetic weighted and unweighted SCP instances with diverse problem characteristics and complexities, and on instances from the OR Library, a canonical benchmark for SCP. We show that Graph-SCP reduces the problem size by 30-70% and achieves run time speedups up to~25x when compared to commercial solvers (Gurobi). Given a desired optimality threshold, Graph-SCP will improve upon it or even achieve 100% optimality. This is in contrast to fast greedy solutions that significantly compromise solution quality to achieve guaranteed polynomial run time. Graph-SCP can generalize to larger problem sizes and can be used with other conventional or ML-augmented CO solvers to lead to potential additional run time improvement.", "url": "https://arxiv.org/abs/2310.07979"}, {"metadata": {"arXiv": "2310.07980", "Date": "Thu, 12 Oct 2023 02:03:10 ", "Title": "GRASP: Accelerating Shortest Path Attacks via Graph Attention", "Authors": ["Zohair Shafi. Benjamin A. Miller", "Ayan Chatterjee", "Tina Eliassi-Rad", "Rajmonda S. Caceres"], "Categories": "cs.LG"}, "abstract": "Recent advances in machine learning (ML) have shown promise in aiding and accelerating classical combinatorial optimization algorithms. ML-based speed ups that aim to learn in an end to end manner (i.e., directly output the solution) tend to trade off run time with solution quality. Therefore, solutions that are able to accelerate existing solvers while maintaining their performance guarantees, are of great interest. We consider an APX-hard problem, where an adversary aims to attack shortest paths in a graph by removing the minimum number of edges. We propose the GRASP algorithm: Graph Attention Accelerated Shortest Path Attack, an ML aided optimization algorithm that achieves run times up to 10x faster, while maintaining the quality of solution generated. GRASP uses a graph attention network to identify a smaller subgraph containing the combinatorial solution, thus effectively reducing the input problem size. Additionally, we demonstrate how careful representation of the input graph, including node features that correlate well with the optimization task, can highlight important structure in the optimization solution.", "url": "https://arxiv.org/abs/2310.07980"}, {"metadata": {"arXiv": "2310.07981", "Date": "Thu, 12 Oct 2023 02:10:29 ", "Title": "Reinforcement Learning of Display Transfer Robots in Glass Flow Control Systems: A Physical Simulation-Based Approach", "Authors": ["Hwajong Lee", "Chan Kim", "Seong-Woo Kim"], "Categories": "cs.LG cs.RO cs.SY eess.SY", "Comments": ["10 pages", "17 figures"]}, "abstract": "A flow control system is a critical concept for increasing the production capacity of manufacturing systems. To solve the scheduling optimization problem related to the flow control with the aim of improving productivity, existing methods depend on a heuristic design by domain human experts. Therefore, the methods require correction, monitoring, and verification by using real equipment. As system designs increase in complexity, the monitoring time increases, which decreases the probability of arriving at the optimal design. As an alternative approach to the heuristic design of flow control systems, the use of deep reinforcement learning to solve the scheduling optimization problem has been considered. Although the existing research on reinforcement learning has yielded excellent performance in some areas, the applicability of the results to actual FAB such as display and semiconductor manufacturing processes is not evident so far. To this end, we propose a method to implement a physical simulation environment and devise a feasible flow control system design using a transfer robot in display manufacturing through reinforcement learning. We present a model and parameter setting to build a virtual environment for different display transfer robots, and training methods of reinforcement learning on the environment to obtain an optimal scheduling of glass flow control systems. Its feasibility was verified by using different types of robots used in the actual process.", "url": "https://arxiv.org/abs/2310.07981"}, {"metadata": {"arXiv": "2310.07983", "Date": "Thu, 12 Oct 2023 02:13:48 ", "Title": "RandCom: Random Communication Skipping Method for Decentralized Stochastic Optimization", "Authors": ["Luyao Guo and Sulaiman A. Alghunaim and Kun Yuan and Laurent Condat and Jinde Cao"], "Categories": "cs.LG math.OC stat.ML"}, "abstract": "Distributed optimization methods with random communication skips are gaining increasing attention due to their proven benefits in accelerating communication complexity. Nevertheless, existing research mainly focuses on centralized communication protocols for strongly convex deterministic settings. In this work, we provide a decentralized optimization method called RandCom, which incorporates probabilistic local updates. We analyze the performance of RandCom in stochastic non-convex, convex, and strongly convex settings and demonstrate its ability to asymptotically reduce communication overhead by the probability of communication. Additionally, we prove that RandCom achieves linear speedup as the number of nodes increases. In stochastic strongly convex settings, we further prove that RandCom can achieve linear speedup with network-independent stepsizes. Moreover, we apply RandCom to federated learning and provide positive results concerning the potential for achieving linear speedup and the suitability of the probabilistic local update approach for non-convex settings.", "url": "https://arxiv.org/abs/2310.07983"}, {"metadata": {"arXiv": "2310.07985", "Date": "Thu, 12 Oct 2023 02:18:50 ", "Title": "Neural Combinatorial Optimization with Heavy Decoder: Toward Large Scale Generalization", "Authors": ["Fu Luo", "Xi Lin", "Fei Liu", "Qingfu Zhang", "Zhenkun Wang"], "Categories": "cs.LG cs.NE math.OC", "Comments": ["Accepted at NeurIPS 2023"]}, "abstract": "Neural combinatorial optimization (NCO) is a promising learning-based approach for solving challenging combinatorial optimization problems without specialized algorithm design by experts. However, most constructive NCO methods cannot solve problems with large-scale instance sizes, which significantly diminishes their usefulness for real-world applications. In this work, we propose a novel Light Encoder and Heavy Decoder (LEHD) model with a strong generalization ability to address this critical issue. The LEHD model can learn to dynamically capture the relationships between all available nodes of varying sizes, which is beneficial for model generalization to problems of various scales. Moreover, we develop a data-efficient training scheme and a flexible solution construction mechanism for the proposed LEHD model. By training on small-scale problem instances, the LEHD model can generate nearly optimal solutions for the Travelling Salesman Problem (TSP) and the Capacitated Vehicle Routing Problem (CVRP) with up to 1000 nodes, and also generalizes well to solve real-world TSPLib and CVRPLib problems. These results confirm our proposed LEHD model can significantly improve the state-of-the-art performance for constructive NCO. The code is available at https://github.com/CIAM-Group/NCO_code/tree/main/single_objective/LEHD.", "url": "https://arxiv.org/abs/2310.07985"}, {"metadata": {"arXiv": "2310.07996", "Date": "Thu, 12 Oct 2023 02:52:14 ", "Title": "Reset It and Forget It: Relearning Last-Layer Weights Improves Continual and Transfer Learning", "Authors": ["Lapo Frati", "Neil Traft", "Jeff Clune", "Nick Cheney"], "Categories": "cs.LG cs.CV cs.NE"}, "abstract": "This work identifies a simple pre-training mechanism that leads to representations exhibiting better continual and transfer learning. This mechanism -- the repeated resetting of weights in the last layer, which we nickname \"zapping\" -- was originally designed for a meta-continual-learning procedure, yet we show it is surprisingly applicable in many settings beyond both meta-learning and continual learning. In our experiments, we wish to transfer a pre-trained image classifier to a new set of classes, in a few shots. We show that our zapping procedure results in improved transfer accuracy and/or more rapid adaptation in both standard fine-tuning and continual learning settings, while being simple to implement and computationally efficient. In many cases, we achieve performance on par with state of the art meta-learning without needing the expensive higher-order gradients, by using a combination of zapping and sequential learning. An intuitive explanation for the effectiveness of this zapping procedure is that representations trained with repeated zapping learn features that are capable of rapidly adapting to newly initialized classifiers. Such an approach may be considered a computationally cheaper type of, or alternative to, meta-learning rapidly adaptable features with higher-order gradients. This adds to recent work on the usefulness of resetting neural network parameters during training, and invites further investigation of this mechanism.", "url": "https://arxiv.org/abs/2310.07996"}, {"metadata": {"arXiv": "2310.07999", "Date": "Thu, 12 Oct 2023 03:02:41 ", "Title": "LEMON: Lossless model expansion", "Authors": ["Yite Wang", "Jiahao Su", "Hanlin Lu", "Cong Xie", "Tianyi Liu", "Jianbo Yuan", "Haibin Lin", "Ruoyu Sun", "Hongxia Yang"], "Categories": "cs.LG stat.ML", "Comments": ["Preprint"]}, "abstract": "Scaling of deep neural networks, especially Transformers, is pivotal for their surging performance and has further led to the emergence of sophisticated reasoning capabilities in foundation models. Such scaling generally requires training large models from scratch with random initialization, failing to leverage the knowledge acquired by their smaller counterparts, which are already resource-intensive to obtain. To tackle this inefficiency, we present $\\textbf{L}$ossl$\\textbf{E}$ss $\\textbf{MO}$del Expansio$\\textbf{N}$ (LEMON), a recipe to initialize scaled models using the weights of their smaller but pre-trained counterparts. This is followed by model training with an optimized learning rate scheduler tailored explicitly for the scaled models, substantially reducing the training time compared to training from scratch. Notably, LEMON is versatile, ensuring compatibility with various network structures, including models like Vision Transformers and BERT. Our empirical results demonstrate that LEMON reduces computational costs by 56.7% for Vision Transformers and 33.2% for BERT when compared to training from scratch.", "url": "https://arxiv.org/abs/2310.07999"}, {"metadata": {"arXiv": "2310.08012", "Date": "Thu, 12 Oct 2023 03:28:14 ", "Title": "AutoFHE: Automated Adaption of CNNs for Efficient Evaluation over FHE", "Authors": ["Wei Ao", "Vishnu Naresh Boddeti"], "Categories": "cs.LG cs.CR", "Comments": ["USENIX Security Symposium 2024"]}, "abstract": "Secure inference of deep convolutional neural networks (CNNs) under RNS-CKKS involves polynomial approximation of unsupported non-linear activation functions. However, existing approaches have three main limitations: 1) Inflexibility: The polynomial approximation and associated homomorphic evaluation architecture are customized manually for each CNN architecture and do not generalize to other networks. 2) Suboptimal Approximation: Each activation function is approximated instead of the function represented by the CNN. 3) Restricted Design: Either high-degree or low-degree polynomial approximations are used. The former retains high accuracy but slows down inference due to bootstrapping operations, while the latter accelerates ciphertext inference but compromises accuracy. To address these limitations, we present AutoFHE, which automatically adapts standard CNNs for secure inference under RNS-CKKS. The key idea is to adopt layerwise mixed-degree polynomial activation functions, which are optimized jointly with the homomorphic evaluation architecture in terms of the placement of bootstrapping operations. The problem is modeled within a multi-objective optimization framework to maximize accuracy and minimize the number of bootstrapping operations. AutoFHE can be applied flexibly on any CNN architecture, and it provides diverse solutions that span the trade-off between accuracy and latency. Experimental evaluation over RNS-CKKS encrypted CIFAR datasets shows that AutoFHE accelerates secure inference by $1.32\\times$ to $1.8\\times$ compared to methods employing high-degree polynomials. It also improves accuracy by up to 2.56% compared to methods using low-degree polynomials. Lastly, AutoFHE accelerates inference and improves accuracy by $103\\times$ and 3.46%, respectively, compared to CNNs under TFHE.", "url": "https://arxiv.org/abs/2310.08012"}, {"metadata": {"arXiv": "2310.08015", "Date": "Thu, 12 Oct 2023 03:29:53 ", "Title": "Why Train More? Effective and Efficient Membership Inference via Memorization", "Authors": ["Jihye Choi", "Shruti Tople", "Varun Chandrasekaran", "Somesh Jha"], "Categories": "cs.LG cs.CR"}, "abstract": "Membership Inference Attacks (MIAs) aim to identify specific data samples within the private training dataset of machine learning models, leading to serious privacy violations and other sophisticated threats. Many practical black-box MIAs require query access to the data distribution (the same distribution where the private data is drawn) to train shadow models. By doing so, the adversary obtains models trained \"with\" or \"without\" samples drawn from the distribution, and analyzes the characteristics of the samples under consideration. The adversary is often required to train more than hundreds of shadow models to extract the signals needed for MIAs; this becomes the computational overhead of MIAs. In this paper, we propose that by strategically choosing the samples, MI adversaries can maximize their attack success while minimizing the number of shadow models. First, our motivational experiments suggest memorization as the key property explaining disparate sample vulnerability to MIAs. We formalize this through a theoretical bound that connects MI advantage with memorization. Second, we show sample complexity bounds that connect the number of shadow models needed for MIAs with memorization. Lastly, we confirm our theoretical arguments with comprehensive experiments; by utilizing samples with high memorization scores, the adversary can (a) significantly improve its efficacy regardless of the MIA used, and (b) reduce the number of shadow models by nearly two orders of magnitude compared to state-of-the-art approaches.", "url": "https://arxiv.org/abs/2310.08015"}, {"metadata": {"arXiv": "2310.08031", "Date": "Thu, 12 Oct 2023 04:37:15 ", "Title": "Local Graph Clustering with Noisy Labels", "Authors": ["Artur Back de Luca", "Kimon Fountoulakis", "Shenghao Yang"], "Categories": "cs.LG cs.SI stat.ML", "Comments": ["26 pages", "5 figures", "14 tables"]}, "abstract": "The growing interest in machine learning problems over graphs with additional node information such as texts, images, or labels has popularized methods that require the costly operation of processing the entire graph. Yet, little effort has been made to the development of fast local methods (i.e. without accessing the entire graph) that extract useful information from such data. To that end, we propose a study of local graph clustering using noisy node labels as a proxy for additional node information. In this setting, nodes receive initial binary labels based on cluster affiliation: 1 if they belong to the target cluster and 0 otherwise. Subsequently, a fraction of these labels is flipped. We investigate the benefits of incorporating noisy labels for local graph clustering. By constructing a weighted graph with such labels, we study the performance of graph diffusion-based local clustering method on both the original and the weighted graphs. From a theoretical perspective, we consider recovering an unknown target cluster with a single seed node in a random graph with independent noisy node labels. We provide sufficient conditions on the label noise under which, with high probability, using diffusion in the weighted graph yields a more accurate recovery of the target cluster. This approach proves more effective than using the given labels alone or using diffusion in the label-free original graph. Empirically, we show that reliable node labels can be obtained with just a few samples from an attributed graph. Moreover, utilizing these labels via diffusion in the weighted graph leads to significantly better local clustering performance across several real-world datasets, improving F1 scores by up to 13%.", "url": "https://arxiv.org/abs/2310.08031"}, {"metadata": {"arXiv": "2310.08038", "Date": "Thu, 12 Oct 2023 05:09:27 ", "Title": "Continual Learning via Manifold Expansion Replay", "Authors": ["Zihao Xu", "Xuan Tang", "Yufei Shi", "Jianfeng Zhang", "Jian Yang", "Mingsong Chen", "Xian Wei"], "Categories": "cs.LG cs.CV cs.IR"}, "abstract": "In continual learning, the learner learns multiple tasks in sequence, with data being acquired only once for each task. Catastrophic forgetting is a major challenge to continual learning. To reduce forgetting, some existing rehearsal-based methods use episodic memory to replay samples of previous tasks. However, in the process of knowledge integration when learning a new task, this strategy also suffers from catastrophic forgetting due to an imbalance between old and new knowledge. To address this problem, we propose a novel replay strategy called Manifold Expansion Replay (MaER). We argue that expanding the implicit manifold of the knowledge representation in the episodic memory helps to improve the robustness and expressiveness of the model. To this end, we propose a greedy strategy to keep increasing the diameter of the implicit manifold represented by the knowledge in the buffer during memory management. In addition, we introduce Wasserstein distance instead of cross entropy as distillation loss to preserve previous knowledge. With extensive experimental validation on MNIST, CIFAR10, CIFAR100, and TinyImageNet, we show that the proposed method significantly improves the accuracy in continual learning setup, outperforming the state of the arts.", "url": "https://arxiv.org/abs/2310.08038"}, {"metadata": {"arXiv": "2310.08040", "Date": "Thu, 12 Oct 2023 05:20:18 ", "Title": "SEE-OoD: Supervised Exploration For Enhanced Out-of-Distribution Detection", "Authors": ["Xiaoyang Song", "Wenbo Sun", "Maher Nouiehed", "Raed Al Kontar", "Judy Jin"], "Categories": "cs.LG"}, "abstract": "Current techniques for Out-of-Distribution (OoD) detection predominantly rely on quantifying predictive uncertainty and incorporating model regularization during the training phase, using either real or synthetic OoD samples. However, methods that utilize real OoD samples lack exploration and are prone to overfit the OoD samples at hand. Whereas synthetic samples are often generated based on features extracted from training data, rendering them less effective when the training and OoD data are highly overlapped in the feature space. In this work, we propose a Wasserstein-score-based generative adversarial training scheme to enhance OoD detection accuracy, which, for the first time, performs data augmentation and exploration simultaneously under the supervision of limited OoD samples. Specifically, the generator explores OoD spaces and generates synthetic OoD samples using feedback from the discriminator, while the discriminator exploits both the observed and synthesized samples for OoD detection using a predefined Wasserstein score. We provide theoretical guarantees that the optimal solutions of our generative scheme are statistically achievable through adversarial training in empirical settings. We then demonstrate that the proposed method outperforms state-of-the-art techniques on various computer vision datasets and exhibits superior generalizability to unseen OoD data.", "url": "https://arxiv.org/abs/2310.08040"}, {"metadata": {"arXiv": "2310.08049", "Date": "Thu, 12 Oct 2023 05:43:06 ", "Title": "Exploring the Relationship Between Model Architecture and In-Context Learning Ability", "Authors": ["Ivan Lee", "Nan Jiang", "Taylor Berg-Kirkpatrick"], "Categories": "cs.LG"}, "abstract": "What is the relationship between model architecture and the ability to perform in-context learning? In this empirical study, we take the first steps towards answering this question. In particular, we evaluate fifteen model architectures across a suite of synthetic in-context learning tasks. The selected architectures represent a broad range of paradigms, including recurrent and convolution-based neural networks, transformers, and emerging attention alternatives. We discover that all considered architectures can perform in-context learning under certain conditions. However, contemporary architectures are found to be the best performing, especially as task complexity grows. Additionally, our follow-up experiments delve into various factors that influence in-context learning. We observe varied sensitivities among architectures with respect to hyperparameter settings. Our study of training dynamics reveals that certain architectures exhibit a smooth, progressive learning trajectory, while others demonstrate periods of stagnation followed by abrupt mastery of the task. Finally, and somewhat surprisingly, we find that several emerging attention alternatives are more robust in-context learners than transformers; since such approaches have constant-sized memory footprints at inference time, this result opens the future possibility of scaling up in-context learning to vastly larger numbers of in-context examples.", "url": "https://arxiv.org/abs/2310.08049"}, {"metadata": {"arXiv": "2310.08051", "Date": "Thu, 12 Oct 2023 05:52:54 ", "Title": "LGL-BCI: A Lightweight Geometric Learning Framework for Motor Imagery-Based Brain-Computer Interfaces", "Authors": ["Jianchao Lu", "Yuzhe Tian", "Yang Zhang", "Jiaqi Ge", "Quan Z. Sheng and Xi Zheng"], "Categories": "cs.LG"}, "abstract": "Brain-Computer Interfaces (BCIs) are a groundbreaking technology for interacting with external devices using brain signals. Despite advancements, electroencephalogram (EEG)-based Motor Imagery (MI) tasks face challenges like amplitude and phase variability, and complex spatial correlations, with a need for smaller model size and faster inference. This study introduces the LGL-BCI framework, employing a Geometric Deep Learning Framework for EEG processing in non-Euclidean metric spaces, particularly the Symmetric Positive Definite (SPD) Manifold space. LGL-BCI offers robust EEG data representation and captures spatial correlations. We propose an EEG channel selection solution via a feature decomposition algorithm to reduce SPD matrix dimensionality, with a lossless transformation boosting inference speed. Extensive experiments show LGL-BCI's superior accuracy and efficiency compared to current solutions, highlighting geometric deep learning's potential in MI-BCI applications. The efficiency, assessed on two public EEG datasets and two real-world EEG devices, significantly outperforms the state-of-the-art solution in accuracy ($82.54\\%$ versus $62.22\\%$) with fewer parameters (64.9M compared to 183.7M).", "url": "https://arxiv.org/abs/2310.08051"}, {"metadata": {"arXiv": "2310.08070", "Date": "Thu, 12 Oct 2023 06:36:31 ", "Title": "Tight Time-Space Lower Bounds for Constant-Pass Learning", "Authors": ["Xin Lyu", "Avishay Tal", "Hongxun Wu", "Junzhao Yang"], "Categories": "cs.LG cs.CC", "Comments": ["To appear at FOCS 2023"]}, "abstract": "In his breakthrough paper, Raz showed that any parity learning algorithm requires either quadratic memory or an exponential number of samples [FOCS'16, JACM'19]. A line of work that followed extended this result to a large class of learning problems. Until recently, all these results considered learning in the streaming model, where each sample is drawn independently, and the learner is allowed a single pass over the stream of samples. Garg, Raz, and Tal [CCC'19] considered a stronger model, allowing multiple passes over the stream. In the $2$-pass model, they showed that learning parities of size $n$ requires either a memory of size $n^{1.5}$ or at least $2^{\\sqrt{n}}$ samples. (Their result also generalizes to other learning problems.) In this work, for any constant $q$, we prove tight memory-sample lower bounds for any parity learning algorithm that makes $q$ passes over the stream of samples. We show that such a learner requires either $\\Omega(n^{2})$ memory size or at least $2^{\\Omega(n)}$ samples. Beyond establishing a tight lower bound, this is the first non-trivial lower bound for $q$-pass learning for any $q\\ge 3$. Similar to prior work, our results extend to any learning problem with many nearly-orthogonal concepts. We complement the lower bound with an upper bound, showing that parity learning with $q$ passes can be done efficiently with $O(n^2/\\log q)$ memory.", "url": "https://arxiv.org/abs/2310.08070"}, {"metadata": {"arXiv": "2310.08071", "Date": "Thu, 12 Oct 2023 06:36:41 ", "Title": "Learning Transferable Conceptual Prototypes for Interpretable Unsupervised Domain Adaptation", "Authors": ["Junyu Gao", "Xinhong Ma", "Changsheng Xu"], "Categories": "cs.LG cs.CV", "Comments": ["Submitted to IEEE TIP"]}, "abstract": "Despite the great progress of unsupervised domain adaptation (UDA) with the deep neural networks, current UDA models are opaque and cannot provide promising explanations, limiting their applications in the scenarios that require safe and controllable model decisions. At present, a surge of work focuses on designing deep interpretable methods with adequate data annotations and only a few methods consider the distributional shift problem. Most existing interpretable UDA methods are post-hoc ones, which cannot facilitate the model learning process for performance enhancement. In this paper, we propose an inherently interpretable method, named Transferable Conceptual Prototype Learning (TCPL), which could simultaneously interpret and improve the processes of knowledge transfer and decision-making in UDA. To achieve this goal, we design a hierarchically prototypical module that transfers categorical basic concepts from the source domain to the target domain and learns domain-shared prototypes for explaining the underlying reasoning process. With the learned transferable prototypes, a self-predictive consistent pseudo-label strategy that fuses confidence, predictions, and prototype information, is designed for selecting suitable target samples for pseudo annotations and gradually narrowing down the domain gap. Comprehensive experiments show that the proposed method can not only provide effective and intuitive explanations but also outperform previous state-of-the-arts.", "url": "https://arxiv.org/abs/2310.08071"}, {"metadata": {"arXiv": "2310.08073", "Date": "Thu, 12 Oct 2023 06:50:43 ", "Title": "Samples on Thin Ice: Re-Evaluating Adversarial Pruning of Neural Networks", "Authors": ["Giorgio Piras", "Maura Pintor", "Ambra Demontis", "Battista Biggio"], "Categories": "cs.LG cs.CV"}, "abstract": "Neural network pruning has shown to be an effective technique for reducing the network size, trading desirable properties like generalization and robustness to adversarial attacks for higher sparsity. Recent work has claimed that adversarial pruning methods can produce sparse networks while also preserving robustness to adversarial examples. In this work, we first re-evaluate three state-of-the-art adversarial pruning methods, showing that their robustness was indeed overestimated. We then compare pruned and dense versions of the same models, discovering that samples on thin ice, i.e., closer to the unpruned model's decision boundary, are typically misclassified after pruning. We conclude by discussing how this intuition may lead to designing more effective adversarial pruning methods in future work.", "url": "https://arxiv.org/abs/2310.08073"}, {"metadata": {"arXiv": "2310.08088", "Date": "Thu, 12 Oct 2023 07:26:41 ", "Title": "Dealing with zero-inflated data: achieving SOTA with a two-fold machine learning approach", "Authors": ["Jo\\v{z}e M. Ro\\v{z}anec", "Ga\\v{s}per Petelin", "Jo\\~ao Costa", "Bla\\v{z} Bertalani\\v{c}", "Gregor Cerar", "Marko Gu\\v{c}ek", "Gregor Papa", "Dunja Mladeni\\'c"], "Categories": "cs.LG"}, "abstract": "In many cases, a machine learning model must learn to correctly predict a few data points with particular values of interest in a broader range of data where many target values are zero. Zero-inflated data can be found in diverse scenarios, such as lumpy and intermittent demands, power consumption for home appliances being turned on and off, impurities measurement in distillation processes, and even airport shuttle demand prediction. The presence of zeroes affects the models' learning and may result in poor performance. Furthermore, zeroes also distort the metrics used to compute the model's prediction quality. This paper showcases two real-world use cases (home appliances classification and airport shuttle demand prediction) where a hierarchical model applied in the context of zero-inflated data leads to excellent results. In particular, for home appliances classification, the weighted average of Precision, Recall, F1, and AUC ROC was increased by 27%, 34%, 49%, and 27%, respectively. Furthermore, it is estimated that the proposed approach is also four times more energy efficient than the SOTA approach against which it was compared to. Two-fold models performed best in all cases when predicting airport shuttle demand, and the difference against other models has been proven to be statistically significant.", "url": "https://arxiv.org/abs/2310.08088"}, {"metadata": {"arXiv": "2310.08096", "Date": "Thu, 12 Oct 2023 07:43:27 ", "Title": "ClimateBERT-NetZero: Detecting and Assessing Net Zero and Reduction Targets", "Authors": ["Tobias Schimanski", "Julia Bingler", "Camilla Hyslop", "Mathias Kraus", "Markus Leippold"], "Categories": "cs.LG"}, "abstract": "Public and private actors struggle to assess the vast amounts of information about sustainability commitments made by various institutions. To address this problem, we create a novel tool for automatically detecting corporate, national, and regional net zero and reduction targets in three steps. First, we introduce an expert-annotated data set with 3.5K text samples. Second, we train and release ClimateBERT-NetZero, a natural language classifier to detect whether a text contains a net zero or reduction target. Third, we showcase its analysis potential with two use cases: We first demonstrate how ClimateBERT-NetZero can be combined with conventional question-answering (Q&A) models to analyze the ambitions displayed in net zero and reduction targets. Furthermore, we employ the ClimateBERT-NetZero model on quarterly earning call transcripts and outline how communication patterns evolve over time. Our experiments demonstrate promising pathways for extracting and analyzing net zero and emission reduction targets at scale.", "url": "https://arxiv.org/abs/2310.08096"}, {"metadata": {"arXiv": "2310.08100", "Date": "Thu, 12 Oct 2023 07:50:37 ", "Title": "Generative Intrinsic Optimization: Intrisic Control with Model Learning", "Authors": ["Jianfei Ma"], "Categories": "cs.LG"}, "abstract": "Future sequence represents the outcome after executing the action into the environment. When driven by the information-theoretic concept of mutual information, it seeks maximally informative consequences. Explicit outcomes may vary across state, return, or trajectory serving different purposes such as credit assignment or imitation learning. However, the inherent nature of incorporating intrinsic motivation with reward maximization is often neglected. In this work, we propose a variational approach to jointly learn the necessary quantity for estimating the mutual information and the dynamics model, providing a general framework for incorporating different forms of outcomes of interest. Integrated into a policy iteration scheme, our approach guarantees convergence to the optimal policy. While we mainly focus on theoretical analysis, our approach opens the possibilities of leveraging intrinsic control with model learning to enhance sample efficiency and incorporate uncertainty of the environment into decision-making.", "url": "https://arxiv.org/abs/2310.08100"}, {"metadata": {"arXiv": "2310.08137", "Date": "Thu, 12 Oct 2023 08:51:59 ", "Title": "Counterfactual Explanations for Time Series Forecasting", "Authors": ["Zhendong Wang", "Ioanna Miliou", "Isak Samsten", "Panagiotis Papapetrou"], "Categories": "cs.LG", "Comments": ["10 pages", "6 figures. Accepted by ICDM 2023"]}, "abstract": "Among recent developments in time series forecasting methods, deep forecasting models have gained popularity as they can utilize hidden feature patterns in time series to improve forecasting performance. Nevertheless, the majority of current deep forecasting models are opaque, hence making it challenging to interpret the results. While counterfactual explanations have been extensively employed as a post-hoc approach for explaining classification models, their application to forecasting models still remains underexplored. In this paper, we formulate the novel problem of counterfactual generation for time series forecasting, and propose an algorithm, called ForecastCF, that solves the problem by applying gradient-based perturbations to the original time series. ForecastCF guides the perturbations by applying constraints to the forecasted values to obtain desired prediction outcomes. We experimentally evaluate ForecastCF using four state-of-the-art deep model architectures and compare to two baselines. Our results show that ForecastCF outperforms the baseline in terms of counterfactual validity and data manifold closeness. Overall, our findings suggest that ForecastCF can generate meaningful and relevant counterfactual explanations for various forecasting tasks.", "url": "https://arxiv.org/abs/2310.08137"}, {"metadata": {"arXiv": "2310.08148", "Date": "Thu, 12 Oct 2023 09:12:50 ", "Title": "Open-Set Knowledge-Based Visual Question Answering with Inference Paths", "Authors": ["Jingru Gan", "Xinzhe Han", "Shuhui Wang", "Qingming Huang"], "Categories": "cs.LG"}, "abstract": "Given an image and an associated textual question, the purpose of Knowledge-Based Visual Question Answering (KB-VQA) is to provide a correct answer to the question with the aid of external knowledge bases. Prior KB-VQA models are usually formulated as a retriever-classifier framework, where a pre-trained retriever extracts textual or visual information from knowledge graphs and then makes a prediction among the candidates. Despite promising progress, there are two drawbacks with existing models. Firstly, modeling question-answering as multi-class classification limits the answer space to a preset corpus and lacks the ability of flexible reasoning. Secondly, the classifier merely consider \"what is the answer\" without \"how to get the answer\", which cannot ground the answer to explicit reasoning paths. In this paper, we confront the challenge of \\emph{explainable open-set} KB-VQA, where the system is required to answer questions with entities at wild and retain an explainable reasoning path. To resolve the aforementioned issues, we propose a new retriever-ranker paradigm of KB-VQA, Graph pATH rankER (GATHER for brevity). Specifically, it contains graph constructing, pruning, and path-level ranking, which not only retrieves accurate answers but also provides inference paths that explain the reasoning process. To comprehensively evaluate our model, we reformulate the benchmark dataset OK-VQA with manually corrected entity-level annotations and release it as ConceptVQA. Extensive experiments on real-world questions demonstrate that our framework is not only able to perform open-set question answering across the whole knowledge base but provide explicit reasoning path.", "url": "https://arxiv.org/abs/2310.08148"}, {"metadata": {"arXiv": "2310.08164", "Date": "Thu, 12 Oct 2023 09:36:03 ", "Title": "Interpreting Reward Models in RLHF-Tuned Language Models Using Sparse Autoencoders", "Authors": ["Luke Marks", "Amir Abdullah", "Luna Mendez", "Rauno Arike", "Philip Torr", "Fazl Barez"], "Categories": "cs.LG"}, "abstract": "Large language models (LLMs) aligned to human preferences via reinforcement learning from human feedback (RLHF) underpin many commercial applications. However, how RLHF impacts LLM internals remains opaque. We propose a novel method to interpret learned reward functions in RLHF-tuned LLMs using sparse autoencoders. Our approach trains autoencoder sets on activations from a base LLM and its RLHF-tuned version. By comparing autoencoder hidden spaces, we identify unique features that reflect the accuracy of the learned reward model. To quantify this, we construct a scenario where the tuned LLM learns token-reward mappings to maximize reward. This is the first application of sparse autoencoders for interpreting learned rewards and broadly inspecting reward learning in LLMs. Our method provides an abstract approximation of reward integrity. This presents a promising technique for ensuring alignment between specified objectives and model behaviors.", "url": "https://arxiv.org/abs/2310.08164"}, {"metadata": {"arXiv": "2310.08176", "Date": "Thu, 12 Oct 2023 10:01:39 ", "Title": "Infinite Width Graph Neural Networks for Node Regression/ Classification", "Authors": ["Yunus Cobanoglu"], "Categories": "cs.LG", "Comments": ["50 Pages", "2 Figures (with subfigures)o", "multiple tables"]}, "abstract": "This work analyzes Graph Neural Networks, a generalization of Fully-Connected Deep Neural Nets on Graph structured data, when their width, that is the number of nodes in each fullyconnected layer is increasing to infinity. Infinite Width Neural Networks are connecting Deep Learning to Gaussian Processes and Kernels, both Machine Learning Frameworks with long traditions and extensive theoretical foundations. Gaussian Processes and Kernels have much less hyperparameters then Neural Networks and can be used for uncertainty estimation, making them more user friendly for applications. This works extends the increasing amount of research connecting Gaussian Processes and Kernels to Neural Networks. The Kernel and Gaussian Process closed forms are derived for a variety of architectures, namely the standard Graph Neural Network, the Graph Neural Network with Skip-Concatenate Connections and the Graph Attention Neural Network. All architectures are evaluated on a variety of datasets on the task of transductive Node Regression and Classification. Additionally, a Spectral Sparsification method known as Effective Resistance is used to improve runtime and memory requirements. Extending the setting to inductive graph learning tasks (Graph Regression/ Classification) is straightforward and is briefly discussed in 3.5.", "url": "https://arxiv.org/abs/2310.08176"}, {"metadata": {"arXiv": "2310.08177", "Date": "Thu, 12 Oct 2023 10:03:25 ", "Title": "Improving Fast Minimum-Norm Attacks with Hyperparameter Optimization", "Authors": ["Giuseppe Floris", "Raffaele Mura", "Luca Scionis", "Giorgio Piras", "Maura Pintor", "Ambra Demontis", "Battista Biggio"], "Categories": "cs.LG cs.CV", "Comments": ["Accepted at ESANN23"], "DOI": "10.14428/esann/2023.ES2023-164"}, "abstract": "Evaluating the adversarial robustness of machine learning models using gradient-based attacks is challenging. In this work, we show that hyperparameter optimization can improve fast minimum-norm attacks by automating the selection of the loss function, the optimizer and the step-size scheduler, along with the corresponding hyperparameters. Our extensive evaluation involving several robust models demonstrates the improved efficacy of fast minimum-norm attacks when hyper-up with hyperparameter optimization. We release our open-source code at https://github.com/pralab/HO-FMN.", "url": "https://arxiv.org/abs/2310.08177"}, {"metadata": {"arXiv": "2310.08224", "Date": "Thu, 12 Oct 2023 11:16:57 ", "Title": "Emergence of Latent Binary Encoding in Deep Neural Network Classifiers", "Authors": ["Luigi Sbail\\`o and Luca Ghiringhelli"], "Categories": "cs.LG"}, "abstract": "We observe the emergence of binary encoding within the latent space of deep-neural-network classifiers. Such binary encoding is induced by introducing a linear penultimate layer, which is equipped during training with a loss function that grows as $\\exp(\\vec{x}^2)$, where $\\vec{x}$ are the coordinates in the latent space. The phenomenon we describe represents a specific instance of a well-documented occurrence known as \\textit{neural collapse}, which arises in the terminal phase of training and entails the collapse of latent class means to the vertices of a simplex equiangular tight frame (ETF). We show that binary encoding accelerates convergence toward the simplex ETF and enhances classification accuracy.", "url": "https://arxiv.org/abs/2310.08224"}, {"metadata": {"arXiv": "2310.08282", "Date": "Thu, 12 Oct 2023 12:39:08 ", "Title": "Data driven modeling of self-similar dynamics", "Authors": ["Ruyi Tao", "Ningning Tao", "Yizhuang You", "Jiang Zhang"], "Categories": "cs.LG cond-mat.stat-mech", "Comments": ["10 pages,4 figures,1 table"]}, "abstract": "Multiscale modeling of complex systems is crucial for understanding their intricacies. Data-driven multiscale modeling has emerged as a promising approach to tackle challenges associated with complex systems. On the other hand, self-similarity is prevalent in complex systems, hinting that large-scale complex systems can be modeled at a reduced cost. In this paper, we introduce a multiscale neural network framework that incorporates self-similarity as prior knowledge, facilitating the modeling of self-similar dynamical systems. For deterministic dynamics, our framework can discern whether the dynamics are self-similar. For uncertain dynamics, it can compare and determine which parameter set is closer to self-similarity. The framework allows us to extract scale-invariant kernels from the dynamics for modeling at any scale. Moreover, our method can identify the power law exponents in self-similar systems. Preliminary tests on the Ising model yielded critical exponents consistent with theoretical expectations, providing valuable insights for addressing critical phase transitions in non-equilibrium systems.", "url": "https://arxiv.org/abs/2310.08282"}, {"metadata": {"arXiv": "2310.08320", "Date": "Thu, 12 Oct 2023 13:33:04 ", "Title": "Defending Our Privacy With Backdoors", "Authors": ["Dominik Hintersdorf", "Lukas Struppek", "Daniel Neider", "Kristian Kersting"], "Categories": "cs.LG cs.CL cs.CR cs.CV", "Comments": ["14 pages", "4 figures"]}, "abstract": "The proliferation of large AI models trained on uncurated, often sensitive web-scraped data has raised significant privacy concerns. One of the concerns is that adversaries can extract information about the training data using privacy attacks. Unfortunately, the task of removing specific information from the models without sacrificing performance is not straightforward and has proven to be challenging. We propose a rather easy yet effective defense based on backdoor attacks to remove private information such as names of individuals from models, and focus in this work on text encoders. Specifically, through strategic insertion of backdoors, we align the embeddings of sensitive phrases with those of neutral terms-\"a person\" instead of the person's name. Our empirical results demonstrate the effectiveness of our backdoor-based defense on CLIP by assessing its performance using a specialized privacy attack for zero-shot classifiers. Our approach provides not only a new \"dual-use\" perspective on backdoor attacks, but also presents a promising avenue to enhance the privacy of individuals within models trained on uncurated web-scraped data.", "url": "https://arxiv.org/abs/2310.08320"}, {"metadata": {"arXiv": "2310.08337", "Date": "Thu, 12 Oct 2023 13:54:55 ", "Title": "Neural Diffusion Models", "Authors": ["Grigory Bartosh", "Dmitry Vetrov", "Christian A. Naesseth"], "Categories": "cs.LG"}, "abstract": "Diffusion models have shown remarkable performance on many generative tasks. Despite recent success, most diffusion models are restricted in that they only allow linear transformation of the data distribution. In contrast, broader family of transformations can potentially help train generative distributions more efficiently, simplifying the reverse process and closing the gap between the true negative log-likelihood and the variational approximation. In this paper, we present Neural Diffusion Models (NDMs), a generalization of conventional diffusion models that enables defining and learning time-dependent non-linear transformations of data. We show how to optimise NDMs using a variational bound in a simulation-free setting. Moreover, we derive a time-continuous formulation of NDMs, which allows fast and reliable inference using off-the-shelf numerical ODE and SDE solvers. Finally, we demonstrate the utility of NDMs with learnable transformations through experiments on standard image generation benchmarks, including CIFAR-10, downsampled versions of ImageNet and CelebA-HQ. NDMs outperform conventional diffusion models in terms of likelihood and produce high-quality samples.", "url": "https://arxiv.org/abs/2310.08337"}, {"metadata": {"arXiv": "2310.08348", "Date": "Thu, 12 Oct 2023 14:18:09 ", "Title": "LightZero: A Unified Benchmark for Monte Carlo Tree Search in General Sequential Decision Scenarios", "Authors": ["Yazhe Niu", "Yuan Pu", "Zhenjie Yang", "Xueyan Li", "Tong Zhou", "Jiyuan Ren", "Shuai Hu", "Hongsheng Li", "Yu Liu"], "Categories": "cs.LG", "Comments": ["NeurIPS 2023 Spotlight"]}, "abstract": "Building agents based on tree-search planning capabilities with learned models has achieved remarkable success in classic decision-making problems, such as Go and Atari. However, it has been deemed challenging or even infeasible to extend Monte Carlo Tree Search (MCTS) based algorithms to diverse real-world applications, especially when these environments involve complex action spaces and significant simulation costs, or inherent stochasticity. In this work, we introduce LightZero, the first unified benchmark for deploying MCTS/MuZero in general sequential decision scenarios. Specificially, we summarize the most critical challenges in designing a general MCTS-style decision-making solver, then decompose the tightly-coupled algorithm and system design of tree-search RL methods into distinct sub-modules. By incorporating more appropriate exploration and optimization strategies, we can significantly enhance these sub-modules and construct powerful LightZero agents to tackle tasks across a wide range of domains, such as board games, Atari, MuJoCo, MiniGrid and GoBigger. Detailed benchmark results reveal the significant potential of such methods in building scalable and efficient decision intelligence. The code is available as part of OpenDILab at https://github.com/opendilab/LightZero.", "url": "https://arxiv.org/abs/2310.08348"}, {"metadata": {"arXiv": "2310.08358", "Date": "Thu, 12 Oct 2023 14:29:02 ", "Title": "Towards Demystifying the Generalization Behaviors When Neural Collapse Emerges", "Authors": ["Peifeng Gao", "Qianqian Xu", "Yibo Yang", "Peisong Wen", "Huiyang Shao", "Zhiyong Yang", "Bernard Ghanem", "Qingming Huang"], "Categories": "cs.LG", "Comments": ["20 pages", "6 figures. arXiv admin note: substantial text overlap with arXiv:2304.08914"]}, "abstract": "Neural Collapse (NC) is a well-known phenomenon of deep neural networks in the terminal phase of training (TPT). It is characterized by the collapse of features and classifier into a symmetrical structure, known as simplex equiangular tight frame (ETF). While there have been extensive studies on optimization characteristics showing the global optimality of neural collapse, little research has been done on the generalization behaviors during the occurrence of NC. Particularly, the important phenomenon of generalization improvement during TPT has been remaining in an empirical observation and lacking rigorous theoretical explanation. In this paper, we establish the connection between the minimization of CE and a multi-class SVM during TPT, and then derive a multi-class margin generalization bound, which provides a theoretical explanation for why continuing training can still lead to accuracy improvement on test set, even after the train accuracy has reached 100%. Additionally, our further theoretical results indicate that different alignment between labels and features in a simplex ETF can result in varying degrees of generalization improvement, despite all models reaching NC and demonstrating similar optimization performance on train set. We refer to this newly discovered property as \"non-conservative generalization\". In experiments, we also provide empirical observations to verify the indications suggested by our theoretical results.", "url": "https://arxiv.org/abs/2310.08358"}, {"metadata": {"arXiv": "2310.08425", "Date": "Thu, 12 Oct 2023 15:48:14 ", "Title": "Differentially Private Non-convex Learning for Multi-layer Neural Networks", "Authors": ["Hanpu Shen and Cheng-Long Wang and Zihang Xiang and Yiming Ying and Di Wang"], "Categories": "cs.LG cs.CR stat.ML"}, "abstract": "This paper focuses on the problem of Differentially Private Stochastic Optimization for (multi-layer) fully connected neural networks with a single output node. In the first part, we examine cases with no hidden nodes, specifically focusing on Generalized Linear Models (GLMs). We investigate the well-specific model where the random noise possesses a zero mean, and the link function is both bounded and Lipschitz continuous. We propose several algorithms and our analysis demonstrates the feasibility of achieving an excess population risk that remains invariant to the data dimension. We also delve into the scenario involving the ReLU link function, and our findings mirror those of the bounded link function. We conclude this section by contrasting well-specified and misspecified models, using ReLU regression as a representative example. In the second part of the paper, we extend our ideas to two-layer neural networks with sigmoid or ReLU activation functions in the well-specified model. In the third part, we study the theoretical guarantees of DP-SGD in Abadi et al. (2016) for fully connected multi-layer neural networks. By utilizing recent advances in Neural Tangent Kernel theory, we provide the first excess population risk when both the sample size and the width of the network are sufficiently large. Additionally, we discuss the role of some parameters in DP-SGD regarding their utility, both theoretically and empirically.", "url": "https://arxiv.org/abs/2310.08425"}, {"metadata": {"arXiv": "2310.08470", "Date": "Thu, 12 Oct 2023 16:28:25 ", "Title": "Strategies and impact of learning curve estimation for CNN-based image classification", "Authors": ["Laura Didyk", "Brayden Yarish", "Michael A. Beck", "Christopher P. Bidinosti", "Christopher J. Henry"], "Categories": "cs.LG cs.NE"}, "abstract": "Learning curves are a measure for how the performance of machine learning models improves given a certain volume of training data. Over a wide variety of applications and models it was observed that learning curves follow -- to a large extent -- a power law behavior. This makes the performance of different models for a given task somewhat predictable and opens the opportunity to reduce the training time for practitioners, who are exploring the space of possible models and hyperparameters for the problem at hand. By estimating the learning curve of a model from training on small subsets of data only the best models need to be considered for training on the full dataset. How to choose subset sizes and how often to sample models on these to obtain estimates is however not researched. Given that the goal is to reduce overall training time strategies are needed that sample the performance in a time-efficient way and yet leads to accurate learning curve estimates. In this paper we formulate the framework for these strategies and propose several strategies. Further we evaluate the strategies for simulated learning curves and in experiments with popular datasets and models for image classification tasks.", "url": "https://arxiv.org/abs/2310.08470"}, {"metadata": {"arXiv": "2310.08501", "Date": "Thu, 12 Oct 2023 16:59:50 ", "Title": "Unsupervised Learning of Object-Centric Embeddings for Cell Instance Segmentation in Microscopy Images", "Authors": ["Steffen Wolf", "Manan Lalit", "Henry Westmacott", "Katie McDole", "Jan Funke"], "Categories": "cs.LG cs.CV", "Journal-ref": "Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2023, pages 21263-21272"}, "abstract": "Segmentation of objects in microscopy images is required for many biomedical applications. We introduce object-centric embeddings (OCEs), which embed image patches such that the spatial offsets between patches cropped from the same object are preserved. Those learnt embeddings can be used to delineate individual objects and thus obtain instance segmentations. Here, we show theoretically that, under assumptions commonly found in microscopy images, OCEs can be learnt through a self-supervised task that predicts the spatial offset between image patches. Together, this forms an unsupervised cell instance segmentation method which we evaluate on nine diverse large-scale microscopy datasets. Segmentations obtained with our method lead to substantially improved results, compared to state-of-the-art baselines on six out of nine datasets, and perform on par on the remaining three datasets. If ground-truth annotations are available, our method serves as an excellent starting point for supervised training, reducing the required amount of ground-truth needed by one order of magnitude, thus substantially increasing the practical applicability of our method. Source code is available at https://github.com/funkelab/cellulus.", "url": "https://arxiv.org/abs/2310.08501"}, {"metadata": {"arXiv": "2310.08548", "Date": "Thu, 12 Oct 2023 17:44:59 ", "Title": "Stronger Coreset Bounds for Kernel Density Estimators via Chaining", "Authors": ["Rainie Bozzai and Thomas Rothvoss"], "Categories": "cs.LG cs.CG cs.DS", "Comments": ["23 pages"]}, "abstract": "We apply the discrepancy method and a chaining approach to give improved bounds on the coreset complexity of a wide class of kernel functions. Our results give randomized polynomial time algorithms to produce coresets of size $O\\big(\\frac{\\sqrt{d}}{\\varepsilon}\\sqrt{\\log\\log \\frac{1}{\\varepsilon}}\\big)$ for the Gaussian and Laplacian kernels in the case that the data set is uniformly bounded, an improvement that was not possible with previous techniques. We also obtain coresets of size $O\\big(\\frac{1}{\\varepsilon}\\sqrt{\\log\\log \\frac{1}{\\varepsilon}}\\big)$ for the Laplacian kernel for $d$ constant. Finally, we give the best known bounds of $O\\big(\\frac{\\sqrt{d}}{\\varepsilon}\\sqrt{\\log(2\\max\\{1,\\alpha\\})}\\big)$ on the coreset complexity of the exponential, Hellinger, and JS Kernels, where $1/\\alpha$ is the bandwidth parameter of the kernel.", "url": "https://arxiv.org/abs/2310.08548"}, {"metadata": {"arXiv": "2310.08571", "Date": "Thu, 12 Oct 2023 17:56:53 ", "Title": "Bucks for Buckets (B4B): Active Defenses Against Stealing Encoders", "Authors": ["Jan Dubi\\'nski", "Stanis{\\l}aw Pawlak", "Franziska Boenisch", "Tomasz Trzci\\'nski", "Adam Dziedzic"], "Categories": "cs.LG"}, "abstract": "Machine Learning as a Service (MLaaS) APIs provide ready-to-use and high-utility encoders that generate vector representations for given inputs. Since these encoders are very costly to train, they become lucrative targets for model stealing attacks during which an adversary leverages query access to the API to replicate the encoder locally at a fraction of the original training costs. We propose Bucks for Buckets (B4B), the first active defense that prevents stealing while the attack is happening without degrading representation quality for legitimate API users. Our defense relies on the observation that the representations returned to adversaries who try to steal the encoder's functionality cover a significantly larger fraction of the embedding space than representations of legitimate users who utilize the encoder to solve a particular downstream task.vB4B leverages this to adaptively adjust the utility of the returned representations according to a user's coverage of the embedding space. To prevent adaptive adversaries from eluding our defense by simply creating multiple user accounts (sybils), B4B also individually transforms each user's representations. This prevents the adversary from directly aggregating representations over multiple accounts to create their stolen encoder copy. Our active defense opens a new path towards securely sharing and democratizing encoders over public APIs.", "url": "https://arxiv.org/abs/2310.08571"}, {"metadata": {"arXiv": "2310.07892", "Date": "Wed, 11 Oct 2023 20:55:13 ", "Title": "ASV Station Keeping under Wind Disturbances using Neural Network Simulation Error Minimization Model Predictive Control", "Authors": ["Jalil Chavez-Galaviz", "Jianwen Li", "Ajinkya Chaudhary", "and Nina Mahmoudian"], "Categories": "cs.RO cs.LG"}, "abstract": "Station keeping is an essential maneuver for Autonomous Surface Vehicles (ASVs), mainly when used in confined spaces, to carry out surveys that require the ASV to keep its position or in collaboration with other vehicles where the relative position has an impact over the mission. However, this maneuver can become challenging for classic feedback controllers due to the need for an accurate model of the ASV dynamics and the environmental disturbances. This work proposes a Model Predictive Controller using Neural Network Simulation Error Minimization (NNSEM-MPC) to accurately predict the dynamics of the ASV under wind disturbances. The performance of the proposed scheme under wind disturbances is tested and compared against other controllers in simulation, using the Robotics Operating System (ROS) and the multipurpose simulation environment Gazebo. A set of six tests were conducted by combining two wind speeds (3 m/s and 6 m/s) and three wind directions (0$^\\circ$, 90$^\\circ$, and 180$^\\circ$). The simulation results clearly show the advantage of the NNSEM-MPC over the following methods: backstepping controller, sliding mode controller, simplified dynamics MPC (SD-MPC), neural ordinary differential equation MPC (NODE-MPC), and knowledge-based NODE MPC (KNODE-MPC). The proposed NNSEM-MPC approach performs better than the rest in 4 out of the 6 test conditions, and it is the second best in the 2 remaining test cases, reducing the mean position and heading error by at least 31\\% and 46\\% respectively across all the test cases. In terms of execution speed, the proposed NNSEM-MPC is at least 36\\% faster than the rest of the MPC controllers. The field experiments on two different ASV platforms showed that ASVs can effectively keep the station utilizing the proposed method, with a position error as low as $1.68$ m and a heading error as low as $6.14^{\\circ}$ within time windows of at least $150$s.", "url": "https://arxiv.org/abs/2310.07892"}, {"metadata": {"arXiv": "2310.07896", "Date": "Wed, 11 Oct 2023 21:07:14 ", "Title": "NoMaD: Goal Masked Diffusion Policies for Navigation and Exploration", "Authors": ["Ajay Sridhar", "Dhruv Shah", "Catherine Glossop", "Sergey Levine"], "Categories": "cs.RO cs.CV cs.LG", "Comments": ["Project page https://general-navigation-models.github.io/nomad/"]}, "abstract": "Robotic learning for navigation in unfamiliar environments needs to provide policies for both task-oriented navigation (i.e., reaching a goal that the robot has located), and task-agnostic exploration (i.e., searching for a goal in a novel setting). Typically, these roles are handled by separate models, for example by using subgoal proposals, planning, or separate navigation strategies. In this paper, we describe how we can train a single unified diffusion policy to handle both goal-directed navigation and goal-agnostic exploration, with the latter providing the ability to search novel environments, and the former providing the ability to reach a user-specified goal once it has been located. We show that this unified policy results in better overall performance when navigating to visually indicated goals in novel environments, as compared to approaches that use subgoal proposals from generative models, or prior methods based on latent variable models. We instantiate our method by using a large-scale Transformer-based policy trained on data from multiple ground robots, with a diffusion model decoder to flexibly handle both goal-conditioned and goal-agnostic navigation. Our experiments, conducted on a real-world mobile robot platform, show effective navigation in unseen environments in comparison with five alternative methods, and demonstrate significant improvements in performance and lower collision rates, despite utilizing smaller models than state-of-the-art approaches. For more videos, code, and pre-trained model checkpoints, see https://general-navigation-models.github.io/nomad/", "url": "https://arxiv.org/abs/2310.07896"}, {"metadata": {"arXiv": "2310.07902", "Date": "Wed, 11 Oct 2023 21:16:01 ", "Title": "Unraveling the Single Tangent Space Fallacy: An Analysis and Clarification for Applying Riemannian Geometry in Robot Learning", "Authors": ["No\\'emie Jaquier", "Leonel Rozo", "Tamim Asfour"], "Categories": "cs.RO cs.LG", "Comments": ["8 pages", "5 figures", "3 tables"]}, "abstract": "In the realm of robotics, numerous downstream robotics tasks leverage machine learning methods for processing, modeling, or synthesizing data. Often, this data comprises variables that inherently carry geometric constraints, such as the unit-norm condition of quaternions representing rigid-body orientations or the positive definiteness of stiffness and manipulability ellipsoids. Handling such geometric constraints effectively requires the incorporation of tools from differential geometry into the formulation of machine learning methods. In this context, Riemannian manifolds emerge as a powerful mathematical framework to handle such geometric constraints. Nevertheless, their recent adoption in robot learning has been largely characterized by a mathematically-flawed simplification, hereinafter referred to as the ``single tangent space fallacy\". This approach involves merely projecting the data of interest onto a single tangent (Euclidean) space, over which an off-the-shelf learning algorithm is applied. This paper provides a theoretical elucidation of various misconceptions surrounding this approach and offers experimental evidence of its shortcomings. Finally, it presents valuable insights to promote best practices when employing Riemannian geometry within robot learning applications.", "url": "https://arxiv.org/abs/2310.07902"}, {"metadata": {"arXiv": "2310.08576", "Date": "Thu, 12 Oct 2023 17:59:23 ", "Title": "Learning to Act from Actionless Videos through Dense Correspondences", "Authors": ["Po-Chen Ko", "Jiayuan Mao", "Yilun Du", "Shao-Hua Sun", "Joshua B. Tenenbaum"], "Categories": "cs.RO cs.CV cs.LG stat.ML", "Comments": ["Project page: https://flow-diffusion.github.io/"]}, "abstract": "In this work, we present an approach to construct a video-based robot policy capable of reliably executing diverse tasks across different robots and environments from few video demonstrations without using any action annotations. Our method leverages images as a task-agnostic representation, encoding both the state and action information, and text as a general representation for specifying robot goals. By synthesizing videos that ``hallucinate'' robot executing actions and in combination with dense correspondences between frames, our approach can infer the closed-formed action to execute to an environment without the need of any explicit action labels. This unique capability allows us to train the policy solely based on RGB videos and deploy learned policies to various robotic tasks. We demonstrate the efficacy of our approach in learning policies on table-top manipulation and navigation tasks. Additionally, we contribute an open-source framework for efficient video modeling, enabling the training of high-fidelity policy models with four GPUs within a single day.", "url": "https://arxiv.org/abs/2310.08576"}, {"metadata": {"arXiv": "2310.08392", "Date": "Thu, 12 Oct 2023 15:03:50 ", "Title": "Introducing a Deep Neural Network-based Model Predictive Control Framework for Rapid Controller Implementation", "Authors": ["David C. Gordon", "Alexander Winkler", "Julian Bedei", "Patrick Schaber", "Jakob Andert and Charles R. Koch"], "Categories": "eess.SY cs.LG cs.SY", "Comments": ["Submitted to 2024 American Control Conference (ACC)", "July 8-12", "2024 in Toronto", "Canada. ACC is the annual conference of the American Automatic Control Council (AACC)", "the U.S. national member organization of the International Federation for Automatic Control (IFAC)"]}, "abstract": "Model Predictive Control (MPC) provides an optimal control solution based on a cost function while allowing for the implementation of process constraints. As a model-based optimal control technique, the performance of MPC strongly depends on the model used where a trade-off between model computation time and prediction performance exists. One solution is the integration of MPC with a machine learning (ML) based process model which are quick to evaluate online. This work presents the experimental implementation of a deep neural network (DNN) based nonlinear MPC for Homogeneous Charge Compression Ignition (HCCI) combustion control. The DNN model consists of a Long Short-Term Memory (LSTM) network surrounded by fully connected layers which was trained using experimental engine data and showed acceptable prediction performance with under 5% error for all outputs. Using this model, the MPC is designed to track the Indicated Mean Effective Pressure (IMEP) and combustion phasing trajectories, while minimizing several parameters. Using the acados software package to enable the real-time implementation of the MPC on an ARM Cortex A72, the optimization calculations are completed within 1.4 ms. The external A72 processor is integrated with the prototyping engine controller using a UDP connection allowing for rapid experimental deployment of the NMPC. The IMEP trajectory following of the developed controller was excellent, with a root-mean-square error of 0.133 bar, in addition to observing process constraints.", "url": "https://arxiv.org/abs/2310.08392"}, {"metadata": {"arXiv": "2310.07802", "Date": "Wed, 11 Oct 2023 18:35:26 ", "Title": "An Information Bottleneck Characterization of the Understanding-Workload Tradeoff", "Authors": ["Lindsay Sanneman", "Mycal Tucker", "and Julie Shah"], "Categories": "cs.AI cs.HC"}, "abstract": "Recent advances in artificial intelligence (AI) have underscored the need for explainable AI (XAI) to support human understanding of AI systems. Consideration of human factors that impact explanation efficacy, such as mental workload and human understanding, is central to effective XAI design. Existing work in XAI has demonstrated a tradeoff between understanding and workload induced by different types of explanations. Explaining complex concepts through abstractions (hand-crafted groupings of related problem features) has been shown to effectively address and balance this workload-understanding tradeoff. In this work, we characterize the workload-understanding balance via the Information Bottleneck method: an information-theoretic approach which automatically generates abstractions that maximize informativeness and minimize complexity. In particular, we establish empirical connections between workload and complexity and between understanding and informativeness through human-subject experiments. This empirical link between human factors and information-theoretic concepts provides an important mathematical characterization of the workload-understanding tradeoff which enables user-tailored XAI design.", "url": "https://arxiv.org/abs/2310.07802"}, {"metadata": {"arXiv": "2310.07871", "Date": "Wed, 11 Oct 2023 20:23:33 ", "Title": "Hierarchical Pretraining on Multimodal Electronic Health Records", "Authors": ["Xiaochen Wang", "Junyu Luo", "Jiaqi Wang", "Ziyi Yin", "Suhan Cui", "Yuan Zhong", "Yaqing Wang", "Fenglong Ma"], "Categories": "cs.AI", "Comments": ["Accepted by EMNLP 2023"]}, "abstract": "Pretraining has proven to be a powerful technique in natural language processing (NLP), exhibiting remarkable success in various NLP downstream tasks. However, in the medical domain, existing pretrained models on electronic health records (EHR) fail to capture the hierarchical nature of EHR data, limiting their generalization capability across diverse downstream tasks using a single pretrained model. To tackle this challenge, this paper introduces a novel, general, and unified pretraining framework called MEDHMP, specifically designed for hierarchically multimodal EHR data. The effectiveness of the proposed MEDHMP is demonstrated through experimental results on eight downstream tasks spanning three levels. Comparisons against eighteen baselines further highlight the efficacy of our approach.", "url": "https://arxiv.org/abs/2310.07871"}, {"metadata": {"arXiv": "2310.07899", "Date": "Wed, 11 Oct 2023 21:10:21 ", "Title": "RoboCLIP: One Demonstration is Enough to Learn Robot Policies", "Authors": ["Sumedh A Sontakke", "Jesse Zhang", "S\\'ebastien M. R. Arnold", "Karl Pertsch", "Erdem B{\\i}y{\\i}k", "Dorsa Sadigh", "Chelsea Finn", "Laurent Itti"], "Categories": "cs.AI cs.RO"}, "abstract": "Reward specification is a notoriously difficult problem in reinforcement learning, requiring extensive expert supervision to design robust reward functions. Imitation learning (IL) methods attempt to circumvent these problems by utilizing expert demonstrations but typically require a large number of in-domain expert demonstrations. Inspired by advances in the field of Video-and-Language Models (VLMs), we present RoboCLIP, an online imitation learning method that uses a single demonstration (overcoming the large data requirement) in the form of a video demonstration or a textual description of the task to generate rewards without manual reward function design. Additionally, RoboCLIP can also utilize out-of-domain demonstrations, like videos of humans solving the task for reward generation, circumventing the need to have the same demonstration and deployment domains. RoboCLIP utilizes pretrained VLMs without any finetuning for reward generation. Reinforcement learning agents trained with RoboCLIP rewards demonstrate 2-3 times higher zero-shot performance than competing imitation learning methods on downstream robot manipulation tasks, doing so using only one video/text demonstration.", "url": "https://arxiv.org/abs/2310.07899"}, {"metadata": {"arXiv": "2310.07944", "Date": "Wed, 11 Oct 2023 23:42:00 ", "Title": "AutoRepo: A general framework for multi-modal LLM-based automated construction reporting", "Authors": ["Hongxu Pu", "Xincong Yang", "Jing Li", "Runhao Guo", "Heng Li"], "Categories": "cs.AI"}, "abstract": "Ensuring the safety, quality, and timely completion of construction projects is paramount, with construction inspections serving as a vital instrument towards these goals. Nevertheless, the predominantly manual approach of present-day inspections frequently results in inefficiencies and inadequate information management. Such methods often fall short of providing holistic, exhaustive assessments, consequently engendering regulatory oversights and potential safety hazards. To address this issue, this paper presents a novel framework named AutoRepo for automated generation of construction inspection reports. The unmanned vehicles efficiently perform construction inspections and collect scene information, while the multimodal large language models (LLMs) are leveraged to automatically generate the inspection reports. The framework was applied and tested on a real-world construction site, demonstrating its potential to expedite the inspection process, significantly reduce resource allocation, and produce high-quality, regulatory standard-compliant inspection reports. This research thus underscores the immense potential of multimodal large language models in revolutionizing construction inspection practices, signaling a significant leap forward towards a more efficient and safer construction management paradigm.", "url": "https://arxiv.org/abs/2310.07944"}, {"metadata": {"arXiv": "2310.07984", "Date": "Thu, 12 Oct 2023 02:17:59 ", "Title": "Large Language Models for Scientific Synthesis, Inference and Explanation", "Authors": ["Yizhen Zheng", "Huan Yee Koh", "Jiaxin Ju", "Anh T.N. Nguyen", "Lauren T. May", "Geoffrey I. Webb", "Shirui Pan"], "Categories": "cs.AI cs.CE", "Comments": ["Supplementary Information: https://drive.google.com/file/d/1KrpUpzuFTeMx6a6zl18lqdo8vV-UUa1Z/view?usp=sharing Github Repo: https://github.com/zyzisastudyreallyhardguy/LLM4SD"]}, "abstract": "Large language models are a form of artificial intelligence systems whose primary knowledge consists of the statistical patterns, semantic relationships, and syntactical structures of language1. Despite their limited forms of \"knowledge\", these systems are adept at numerous complex tasks including creative writing, storytelling, translation, question-answering, summarization, and computer code generation. However, they have yet to demonstrate advanced applications in natural science. Here we show how large language models can perform scientific synthesis, inference, and explanation. We present a method for using general-purpose large language models to make inferences from scientific datasets of the form usually associated with special-purpose machine learning algorithms. We show that the large language model can augment this \"knowledge\" by synthesizing from the scientific literature. When a conventional machine learning system is augmented with this synthesized and inferred knowledge it can outperform the current state of the art across a range of benchmark tasks for predicting molecular properties. This approach has the further advantage that the large language model can explain the machine learning system's predictions. We anticipate that our framework will open new avenues for AI to accelerate the pace of scientific discovery.", "url": "https://arxiv.org/abs/2310.07984"}, {"metadata": {"arXiv": "2310.07998", "Date": "Thu, 12 Oct 2023 02:59:49 ", "Title": "A Novel Statistical Measure for Out-of-Distribution Detection in Data Quality Assurance", "Authors": ["Tinghui Ouyang", "Isao Echizen", "Yoshiki Seo"], "Categories": "cs.AI"}, "abstract": "Data outside the problem domain poses significant threats to the security of AI-based intelligent systems. Aiming to investigate the data domain and out-of-distribution (OOD) data in AI quality management (AIQM) study, this paper proposes to use deep learning techniques for feature representation and develop a novel statistical measure for OOD detection. First, to extract low-dimensional representative features distinguishing normal and OOD data, the proposed research combines the deep auto-encoder (AE) architecture and neuron activation status for feature engineering. Then, using local conditional probability (LCP) in data reconstruction, a novel and superior statistical measure is developed to calculate the score of OOD detection. Experiments and evaluations are conducted on image benchmark datasets and an industrial dataset. Through comparative analysis with other common statistical measures in OOD detection, the proposed research is validated as feasible and effective in OOD and AIQM studies.", "url": "https://arxiv.org/abs/2310.07998"}, {"metadata": {"arXiv": "2310.08008", "Date": "Thu, 12 Oct 2023 03:20:43 ", "Title": "Effects of Human Adversarial and Affable Samples on BERT Generalizability", "Authors": ["Aparna Elangovan", "Jiayuan He", "Yuan Li", "Karin Verspoor"], "Categories": "cs.AI", "Comments": ["To appear at EMNLP 2023"]}, "abstract": "BERT-based models have had strong performance on leaderboards, yet have been demonstrably worse in real-world settings requiring generalization. Limited quantities of training data is considered a key impediment to achieving generalizability in machine learning. In this paper, we examine the impact of training \\textit{data quality}, not quantity, on a model's generalizability. We consider two characteristics of training data: the portion of human-adversarial (h-adversarial), i.e., sample pairs with seemingly minor differences but different ground-truth labels, and human-affable (h-affable) training samples, i.e., sample pairs with minor differences but the same ground-truth label. We find that for a fixed size of training samples, as a rule of thumb, having 10-30\\% h-adversarial instances improves the precision, and therefore F1, by up to 20 points in the tasks of text classification and relation extraction. Increasing h-adversarials beyond this range can result in performance plateaus or even degradation.In contrast, h-affables may not contribute to a model's generalizability and may even degrade generalization performance.", "url": "https://arxiv.org/abs/2310.08008"}, {"metadata": {"arXiv": "2310.08032", "Date": "Thu, 12 Oct 2023 04:49:11 ", "Title": "Incorporating Domain Knowledge Graph into Multimodal Movie Genre Classification with Self-Supervised Attention and Contrastive Learning", "Authors": ["Jiaqi Li", "Guilin Qi", "Chuanyi Zhang", "Yongrui Chen", "Yiming Tan", "Chenlong Xia", "Ye Tian"], "Categories": "cs.AI", "Comments": ["Accepted by ACM MM 2023"]}, "abstract": "Multimodal movie genre classification has always been regarded as a demanding multi-label classification task due to the diversity of multimodal data such as posters, plot summaries, trailers and metadata. Although existing works have made great progress in modeling and combining each modality, they still face three issues: 1) unutilized group relations in metadata, 2) unreliable attention allocation, and 3) indiscriminative fused features. Given that the knowledge graph has been proven to contain rich information, we present a novel framework that exploits the knowledge graph from various perspectives to address the above problems. As a preparation, the metadata is processed into a domain knowledge graph. A translate model for knowledge graph embedding is adopted to capture the relations between entities. Firstly we retrieve the relevant embedding from the knowledge graph by utilizing group relations in metadata and then integrate it with other modalities. Next, we introduce an Attention Teacher module for reliable attention allocation based on self-supervised learning. It learns the distribution of the knowledge graph and produces rational attention weights. Finally, a Genre-Centroid Anchored Contrastive Learning module is proposed to strengthen the discriminative ability of fused features. The embedding space of anchors is initialized from the genre entities in the knowledge graph. To verify the effectiveness of our framework, we collect a larger and more challenging dataset named MM-IMDb 2.0 compared with the MM-IMDb dataset. The experimental results on two datasets demonstrate that our model is superior to the state-of-the-art methods. We will release the code in the near future.", "url": "https://arxiv.org/abs/2310.08032"}, {"metadata": {"arXiv": "2310.08043", "Date": "Thu, 12 Oct 2023 05:33:54 ", "Title": "Understanding and Controlling a Maze-Solving Policy Network", "Authors": ["Ulisse Mini", "Peli Grietzer", "Mrinank Sharma", "Austin Meek", "Monte MacDiarmid", "Alexander Matt Turner"], "Categories": "cs.AI", "Comments": ["46 pages"]}, "abstract": "To understand the goals and goal representations of AI systems, we carefully study a pretrained reinforcement learning policy that solves mazes by navigating to a range of target squares. We find this network pursues multiple context-dependent goals, and we further identify circuits within the network that correspond to one of these goals. In particular, we identified eleven channels that track the location of the goal. By modifying these channels, either with hand-designed interventions or by combining forward passes, we can partially control the policy. We show that this network contains redundant, distributed, and retargetable goal representations, shedding light on the nature of goal-direction in trained policy networks.", "url": "https://arxiv.org/abs/2310.08043"}, {"metadata": {"arXiv": "2310.08067", "Date": "Thu, 12 Oct 2023 06:31:43 ", "Title": "GameGPT: Multi-agent Collaborative Framework for Game Development", "Authors": ["Dake Chen", "Hanbin Wang", "Yunhao Huo", "Yuzhao Li", "Haoyang Zhang"], "Categories": "cs.AI"}, "abstract": "The large language model (LLM) based agents have demonstrated their capacity to automate and expedite software development processes. In this paper, we focus on game development and propose a multi-agent collaborative framework, dubbed GameGPT, to automate game development. While many studies have pinpointed hallucination as a primary roadblock for deploying LLMs in production, we identify another concern: redundancy. Our framework presents a series of methods to mitigate both concerns. These methods include dual collaboration and layered approaches with several in-house lexicons, to mitigate the hallucination and redundancy in the planning, task identification, and implementation phases. Furthermore, a decoupling approach is also introduced to achieve code generation with better precision.", "url": "https://arxiv.org/abs/2310.08067"}, {"metadata": {"arXiv": "2310.08118", "Date": "Thu, 12 Oct 2023 08:22:37 ", "Title": "Can Large Language Models Really Improve by Self-critiquing Their Own Plans?", "Authors": ["Karthik Valmeekam", "Matthew Marquez", "Subbarao Kambhampati"], "Categories": "cs.AI"}, "abstract": "There have been widespread claims about Large Language Models (LLMs) being able to successfully verify or self-critique their candidate solutions in reasoning problems in an iterative mode. Intrigued by those claims, in this paper we set out to investigate the verification/self-critiquing abilities of large language models in the context of planning. We evaluate a planning system that employs LLMs for both plan generation and verification. We assess the verifier LLM's performance against ground-truth verification, the impact of self-critiquing on plan generation, and the influence of varying feedback levels on system performance. Using GPT-4, a state-of-the-art LLM, for both generation and verification, our findings reveal that self-critiquing appears to diminish plan generation performance, especially when compared to systems with external, sound verifiers and the LLM verifiers in that system produce a notable number of false positives, compromising the system's reliability. Additionally, the nature of feedback, whether binary or detailed, showed minimal impact on plan generation. Collectively, our results cast doubt on the effectiveness of LLMs in a self-critiquing, iterative framework for planning tasks.", "url": "https://arxiv.org/abs/2310.08118"}, {"metadata": {"arXiv": "2310.08295", "Date": "Thu, 12 Oct 2023 12:56:12 ", "Title": "If our aim is to build morality into an artificial agent, how might we begin to go about doing so?", "Authors": ["Reneira Seeamber and Cosmin Badea"], "Categories": "cs.AI", "Comments": ["12 pages", "1 figure,"], "Journal-ref": "IEEE Intelligent Systems. 2023", "DOI": "10.1109/MIS.2023.3320875"}, "abstract": "As Artificial Intelligence (AI) becomes pervasive in most fields, from healthcare to autonomous driving, it is essential that we find successful ways of building morality into our machines, especially for decision-making. However, the question of what it means to be moral is still debated, particularly in the context of AI. In this paper, we highlight the different aspects that should be considered when building moral agents, including the most relevant moral paradigms and challenges. We also discuss the top-down and bottom-up approaches to design and the role of emotion and sentience in morality. We then propose solutions including a hybrid approach to design and a hierarchical approach to combining moral paradigms. We emphasize how governance and policy are becoming ever more critical in AI Ethics and in ensuring that the tasks we set for moral agents are attainable, that ethical behavior is achieved, and that we obtain good AI.", "url": "https://arxiv.org/abs/2310.08295"}, {"metadata": {"arXiv": "2310.08328", "Date": "Thu, 12 Oct 2023 13:44:35 ", "Title": "Transport-Hub-Aware Spatial-Temporal Adaptive Graph Transformer for Traffic Flow Prediction", "Authors": ["Xiao Xu", "Lei Zhang", "Bailong Liu", "Zhizhen Liang and Xuefei Zhang"], "Categories": "cs.AI", "Comments": ["11 pages", "4 figures. arXiv admin note: text overlap with arXiv:2301.07945 by other authors"]}, "abstract": "As a core technology of Intelligent Transportation System (ITS), traffic flow prediction has a wide range of applications. Traffic flow data are spatial-temporal, which are not only correlated to spatial locations in road networks, but also vary with temporal time indices. Existing methods have solved the challenges in traffic flow prediction partly, focusing on modeling spatial-temporal dependencies effectively, while not all intrinsic properties of traffic flow data are utilized fully. Besides, there are very few attempts at incremental learning of spatial-temporal data mining, and few previous works can be easily transferred to the traffic flow prediction task. Motivated by the challenge of incremental learning methods for traffic flow prediction and the underutilization of intrinsic properties of road networks, we propose a Transport-Hub-aware Spatial-Temporal adaptive graph transFormer (H-STFormer) for traffic flow prediction. Specifically, we first design a novel spatial self-attention module to capture the dynamic spatial dependencies. Three graph masking matrices are integrated into spatial self-attentions to highlight both short- and long-term dependences. Additionally, we employ a temporal self-attention module to detect dynamic temporal patterns in the traffic flow data. Finally, we design an extra spatial-temporal knowledge distillation module for incremental learning of traffic flow prediction tasks. Through extensive experiments, we show the effectiveness of H-STFormer in normal and incremental traffic flow prediction tasks. The code is available at https://github.com/Fantasy-Shaw/H-STFormer.", "url": "https://arxiv.org/abs/2310.08328"}, {"metadata": {"arXiv": "2310.08377", "Date": "Thu, 12 Oct 2023 14:47:51 ", "Title": "Do Not Marginalize Mechanisms, Rather Consolidate!", "Authors": ["Moritz Willig (1)", "Matej Ze\\v{c}evi\\'c (1)", "Devendra Singh Dhami (4)", "Kristian Kersting (1,2,3) (Technical University of Darmstadt", "(2) Hessian Center for AI", "(3) German Research Center for AI (4) Eindhoven University of Technology)"], "Categories": "cs.AI", "Comments": ["19 pages", "8 figures"]}, "abstract": "Structural causal models (SCMs) are a powerful tool for understanding the complex causal relationships that underlie many real-world systems. As these systems grow in size, the number of variables and complexity of interactions between them does, too. Thus, becoming convoluted and difficult to analyze. This is particularly true in the context of machine learning and artificial intelligence, where an ever increasing amount of data demands for new methods to simplify and compress large scale SCM. While methods for marginalizing and abstracting SCM already exist today, they may destroy the causality of the marginalized model. To alleviate this, we introduce the concept of consolidating causal mechanisms to transform large-scale SCM while preserving consistent interventional behaviour. We show consolidation is a powerful method for simplifying SCM, discuss reduction of computational complexity and give a perspective on generalizing abilities of consolidated SCM.", "url": "https://arxiv.org/abs/2310.08377"}, {"metadata": {"arXiv": "2310.08406", "Date": "Thu, 12 Oct 2023 15:19:15 ", "Title": "Tightening Bounds on Probabilities of Causation By Merging Datasets", "Authors": ["Numair Sani", "Atalanti A. Mastakouri"], "Categories": "cs.AI math.ST stat.TH"}, "abstract": "Probabilities of Causation (PoC) play a fundamental role in decision-making in law, health care and public policy. Nevertheless, their point identification is challenging, requiring strong assumptions, in the absence of which only bounds can be derived. Existing work to further tighten these bounds by leveraging extra information either provides numerical bounds, symbolic bounds for fixed dimensionality, or requires access to multiple datasets that contain the same treatment and outcome variables. However, in many clinical, epidemiological and public policy applications, there exist external datasets that examine the effect of different treatments on the same outcome variable, or study the association between covariates and the outcome variable. These external datasets cannot be used in conjunction with the aforementioned bounds, since the former may entail different treatment assignment mechanisms, or even obey different causal structures. Here, we provide symbolic bounds on the PoC for this challenging scenario. We focus on combining either two randomized experiments studying different treatments, or a randomized experiment and an observational study, assuming causal sufficiency. Our symbolic bounds work for arbitrary dimensionality of covariates and treatment, and we discuss the conditions under which these bounds are tighter than existing bounds in literature. Finally, our bounds parameterize the difference in treatment assignment mechanism across datasets, allowing the mechanisms to vary across datasets while still allowing causal information to be transferred from the external dataset to the target dataset.", "url": "https://arxiv.org/abs/2310.08406"}, {"metadata": {"arXiv": "2310.08535", "Date": "Thu, 12 Oct 2023 17:24:15 ", "Title": "Formally Specifying the High-Level Behavior of LLM-Based Agents", "Authors": ["Maxwell Crouse", "Ibrahim Abdelaziz", "Kinjal Basu", "Soham Dan", "Sadhana Kumaravel", "Achille Fokoue", "Pavan Kapanipathi", "Luis Lastras"], "Categories": "cs.AI cs.CL", "Comments": ["Preprint under review"]}, "abstract": "LLM-based agents have recently emerged as promising tools for solving challenging problems without the need for task-specific finetuned models that can be expensive to procure. Currently, the design and implementation of such agents is ad hoc, as the wide variety of tasks that LLM-based agents may be applied to naturally means there can be no one-size-fits-all approach to agent design. In this work we aim to alleviate the difficulty of designing and implementing new agents by proposing a minimalistic, high-level generation framework that simplifies the process of building agents. The framework we introduce allows the user to specify desired agent behaviors in Linear Temporal Logic (LTL). The declarative LTL specification is then used to construct a constrained decoder that guarantees the LLM will produce an output exhibiting the desired behavior. By designing our framework in this way, we obtain several benefits, including the ability to enforce complex agent behavior, the ability to formally validate prompt examples, and the ability to seamlessly incorporate content-focused logical constraints into generation. In particular, our declarative approach, in which the desired behavior is simply described without concern for how it should be implemented or enforced, enables rapid design, implementation and experimentation with different LLM-based agents. We demonstrate how the proposed framework can be used to implement recent LLM-based agents, and show how the guardrails our approach provides can lead to improvements in agent performance. In addition, we release our code for general use.", "url": "https://arxiv.org/abs/2310.08535"}, {"metadata": {"arXiv": "2310.08560", "Date": "Thu, 12 Oct 2023 17:51:32 ", "Title": "MemGPT: Towards LLMs as Operating Systems", "Authors": ["Charles Packer", "Vivian Fang", "Shishir G. Patil", "Kevin Lin", "Sarah Wooders", "Joseph E. Gonzalez"], "Categories": "cs.AI", "Comments": ["Code and data available at https://memgpt.ai"]}, "abstract": "Large language models (LLMs) have revolutionized AI, but are constrained by limited context windows, hindering their utility in tasks like extended conversations and document analysis. To enable using context beyond limited context windows, we propose virtual context management, a technique drawing inspiration from hierarchical memory systems in traditional operating systems that provide the appearance of large memory resources through data movement between fast and slow memory. Using this technique, we introduce MemGPT (Memory-GPT), a system that intelligently manages different memory tiers in order to effectively provide extended context within the LLM's limited context window, and utilizes interrupts to manage control flow between itself and the user. We evaluate our OS-inspired design in two domains where the limited context windows of modern LLMs severely handicaps their performance: document analysis, where MemGPT is able to analyze large documents that far exceed the underlying LLM's context window, and multi-session chat, where MemGPT can create conversational agents that remember, reflect, and evolve dynamically through long-term interactions with their users. We release MemGPT code and data for our experiments at https://memgpt.ai.", "url": "https://arxiv.org/abs/2310.08560"}, {"metadata": {"arXiv": "2310.08569", "Date": "Thu, 12 Oct 2023 17:56:23 ", "Title": "A Lightweight Calibrated Simulation Enabling Efficient Offline Learning for Optimal Control of Real Buildings", "Authors": ["Judah Goldfeder", "John Sipple"], "Categories": "cs.AI cs.CE eess.SP"}, "abstract": "Modern commercial Heating, Ventilation, and Air Conditioning (HVAC) devices form a complex and interconnected thermodynamic system with the building and outside weather conditions, and current setpoint control policies are not fully optimized for minimizing energy use and carbon emission. Given a suitable training environment, a Reinforcement Learning (RL) model is able to improve upon these policies, but training such a model, especially in a way that scales to thousands of buildings, presents many real world challenges. We propose a novel simulation-based approach, where a customized simulator is used to train the agent for each building. Our open-source simulator (available online: https://github.com/google/sbsim) is lightweight and calibrated via telemetry from the building to reach a higher level of fidelity. On a two-story, 68,000 square foot building, with 127 devices, we were able to calibrate our simulator to have just over half a degree of drift from the real world over a six-hour interval. This approach is an important step toward having a real-world RL control system that can be scaled to many buildings, allowing for greater efficiency and resulting in reduced energy consumption and carbon emissions.", "url": "https://arxiv.org/abs/2310.08569"}, {"metadata": {"arXiv": "2310.07726", "Date": "Wed, 27 Sep 2023 06:32:00 ", "Title": "Towards the Vulnerability of Watermarking Artificial Intelligence Generated Content", "Authors": ["Guanlin Li", "Yifei Chen", "Jie Zhang", "Jiwei Li", "Shangwei Guo", "Tianwei Zhang"], "Categories": "cs.CV cs.AI"}, "abstract": "Artificial Intelligence Generated Content (AIGC) is gaining great popularity in social media, with many commercial services available. These services leverage advanced generative models, such as latent diffusion models and large language models, to generate creative content (e.g., realistic images, fluent sentences) for users. The usage of such generated content needs to be highly regulated, as the service providers need to ensure the users do not violate the usage policies (e.g., abuse for commercialization, generating and distributing unsafe content). Numerous watermarking approaches have been proposed recently. However, in this paper, we show that an adversary can easily break these watermarking mechanisms. Specifically, we consider two possible attacks. (1) Watermark removal: the adversary can easily erase the embedded watermark from the generated content and then use it freely without the regulation of the service provider. (2) Watermark forge: the adversary can create illegal content with forged watermarks from another user, causing the service provider to make wrong attributions. We propose WMaGi, a unified framework to achieve both attacks in a holistic way. The key idea is to leverage a pre-trained diffusion model for content processing, and a generative adversarial network for watermark removing or forging. We evaluate WMaGi on different datasets and embedding setups. The results prove that it can achieve high success rates while maintaining the quality of the generated content. Compared with existing diffusion model-based attacks, WMaGi is 5,050$\\sim$11,000$\\times$ faster.", "url": "https://arxiv.org/abs/2310.07726"}, {"metadata": {"arXiv": "2310.07771", "Date": "Wed, 11 Oct 2023 18:00:08 ", "Title": "DrivingDiffusion: Layout-Guided multi-view driving scene video generation with latent diffusion model", "Authors": ["Xiaofan Li", "Yifu Zhang and Xiaoqing Ye"], "Categories": "cs.CV cs.AI", "Comments": ["11 pages"]}, "abstract": "With the increasing popularity of autonomous driving based on the powerful and unified bird's-eye-view (BEV) representation, a demand for high-quality and large-scale multi-view video data with accurate annotation is urgently required. However, such large-scale multi-view data is hard to obtain due to expensive collection and annotation costs. To alleviate the problem, we propose a spatial-temporal consistent diffusion framework DrivingDiffusion, to generate realistic multi-view videos controlled by 3D layout. There are three challenges when synthesizing multi-view videos given a 3D layout: How to keep 1) cross-view consistency and 2) cross-frame consistency? 3) How to guarantee the quality of the generated instances? Our DrivingDiffusion solves the problem by cascading the multi-view single-frame image generation step, the single-view video generation step shared by multiple cameras, and post-processing that can handle long video generation. In the multi-view model, the consistency of multi-view images is ensured by information exchange between adjacent cameras. In the temporal model, we mainly query the information that needs attention in subsequent frame generation from the multi-view images of the first frame. We also introduce the local prompt to effectively improve the quality of generated instances. In post-processing, we further enhance the cross-view consistency of subsequent frames and extend the video length by employing temporal sliding window algorithm. Without any extra cost, our model can generate large-scale realistic multi-camera driving videos in complex urban scenes, fueling the downstream driving tasks. The code will be made publicly available.", "url": "https://arxiv.org/abs/2310.07771"}, {"metadata": {"arXiv": "2310.07801", "Date": "Sun, 30 Jul 2023 07:31:38 ", "Title": "Trajectory-aware Principal Manifold Framework for Data Augmentation and Image Generation", "Authors": ["Elvis Han Cui", "Bingbin Li", "Yanan Li", "Weng Kee Wong", "Donghui Wang"], "Categories": "cs.CV cs.AI stat.ME", "Comments": ["20 figures"]}, "abstract": "Data augmentation for deep learning benefits model training, image transformation, medical imaging analysis and many other fields. Many existing methods generate new samples from a parametric distribution, like the Gaussian, with little attention to generate samples along the data manifold in either the input or feature space. In this paper, we verify that there are theoretical and practical advantages of using the principal manifold hidden in the feature space than the Gaussian distribution. We then propose a novel trajectory-aware principal manifold framework to restore the manifold backbone and generate samples along a specific trajectory. On top of the autoencoder architecture, we further introduce an intrinsic dimension regularization term to make the manifold more compact and enable few-shot image generation. Experimental results show that the novel framework is able to extract more compact manifold representation, improve classification accuracy and generate smooth transformation among few samples.", "url": "https://arxiv.org/abs/2310.07801"}, {"metadata": {"arXiv": "2310.07812", "Date": "Thu, 28 Sep 2023 09:26:39 ", "Title": "Automatic Identification of Stone-Handling Behaviour in Japanese Macaques Using LabGym Artificial Intelligence", "Authors": ["Th\\'eo Ardoin", "C\\'edric Sueur (IPHC", "ANTHROPO LAB", "IUF)"], "Categories": "cs.CV cs.AI"}, "abstract": "The latest advancements in artificial intelligence technology have opened doors to the analysis of intricate behaviours. In light of this, ethologists are actively exploring the potential of these innovations to streamline the time-intensive process of behavioural analysis using video data. In the realm of primatology, several tools have been developed for this purpose. Nonetheless, each of these tools grapples with technical constraints that we aim to surmount. To address these limitations, we have established a comprehensive protocol designed to harness the capabilities of a cutting-edge tool, LabGym. Our primary objective was to evaluate LabGym's suitability for the analysis of primate behaviour, with a focus on Japanese macaques as our model subjects. We have successfully developed a model that demonstrates a high degree of accuracy in detecting Japanese macaques stone-handling behaviour. Our behavioural analysis model was completed as per our initial expectations and LabGym succeed to recognise stone-handling behaviour on videos. However, it is important to note that our study's ability to draw definitive conclusions regarding the quality of the behavioural analysis is hampered by the absence of quantitative data within the specified timeframe. Nevertheless, our model represents the pioneering endeavour, as far as our knowledge extends, in leveraging LabGym for the analysis of primate behaviours. It lays the groundwork for potential future research in this promising field.", "url": "https://arxiv.org/abs/2310.07812"}, {"metadata": {"arXiv": "2310.07889", "Date": "Wed, 11 Oct 2023 20:52:30 ", "Title": "LangNav: Language as a Perceptual Representation for Navigation", "Authors": ["Bowen Pan", "Rameswar Panda", "SouYoung Jin", "Rogerio Feris", "Aude Oliva", "Phillip Isola", "Yoon Kim"], "Categories": "cs.CV cs.AI cs.CL cs.RO"}, "abstract": "We explore the use of language as a perceptual representation for vision-and-language navigation. Our approach uses off-the-shelf vision systems (for image captioning and object detection) to convert an agent's egocentric panoramic view at each time step into natural language descriptions. We then finetune a pretrained language model to select an action, based on the current view and the trajectory history, that would best fulfill the navigation instructions. In contrast to the standard setup which adapts a pretrained language model to work directly with continuous visual features from pretrained vision models, our approach instead uses (discrete) language as the perceptual representation. We explore two use cases of our language-based navigation (LangNav) approach on the R2R vision-and-language navigation benchmark: generating synthetic trajectories from a prompted large language model (GPT-4) with which to finetune a smaller language model; and sim-to-real transfer where we transfer a policy learned on a simulated environment (ALFRED) to a real-world environment (R2R). Our approach is found to improve upon strong baselines that rely on visual features in settings where only a few gold trajectories (10-100) are available, demonstrating the potential of using language as a perceptual representation for navigation tasks.", "url": "https://arxiv.org/abs/2310.07889"}, {"metadata": {"arXiv": "2310.07975", "Date": "Thu, 12 Oct 2023 01:47:55 ", "Title": "Self-supervised visual learning for analyzing firearms trafficking activities on the Web", "Authors": ["Sotirios Konstantakos", "Despina Ioanna Chalkiadaki", "Ioannis Mademlis", "Adamantia Anna Rebolledo Chrysochoou", "Georgios Th. Papadopoulos"], "Categories": "cs.CV cs.AI"}, "abstract": "Automated visual firearms classification from RGB images is an important real-world task with applications in public space security, intelligence gathering and law enforcement investigations. When applied to images massively crawled from the World Wide Web (including social media and dark Web sites), it can serve as an important component of systems that attempt to identify criminal firearms trafficking networks, by analyzing Big Data from open-source intelligence. Deep Neural Networks (DNN) are the state-of-the-art methodology for achieving this, with Convolutional Neural Networks (CNN) being typically employed. The common transfer learning approach consists of pretraining on a large-scale, generic annotated dataset for whole-image classification, such as ImageNet-1k, and then finetuning the DNN on a smaller, annotated, task-specific, downstream dataset for visual firearms classification. Neither Visual Transformer (ViT) neural architectures nor Self-Supervised Learning (SSL) approaches have been so far evaluated on this critical task. SSL essentially consists of replacing the traditional supervised pretraining objective with an unsupervised pretext task that does not require ground-truth labels..", "url": "https://arxiv.org/abs/2310.07975"}, {"metadata": {"arXiv": "2310.07995", "Date": "Thu, 12 Oct 2023 02:49:00 ", "Title": "HeightFormer: A Multilevel Interaction and Image-adaptive Classification-regression Network for Monocular Height Estimation with Aerial Images", "Authors": ["Zhan Chen and Yidan Zhang and Xiyu Qi and Yongqiang Mao and Xin Zhou and Lulu Niu and Hui Wu and Lei Wang and Yunping Ge"], "Categories": "cs.CV cs.AI"}, "abstract": "Height estimation has long been a pivotal topic within measurement and remote sensing disciplines, proving critical for endeavours such as 3D urban modelling, MR and autonomous driving. Traditional methods utilise stereo matching or multisensor fusion, both well-established techniques that typically necessitate multiple images from varying perspectives and adjunct sensors like SAR, leading to substantial deployment costs. Single image height estimation has emerged as an attractive alternative, boasting a larger data source variety and simpler deployment. However, current methods suffer from limitations such as fixed receptive fields, a lack of global information interaction, leading to noticeable instance-level height deviations. The inherent complexity of height prediction can result in a blurry estimation of object edge depth when using mainstream regression methods based on fixed height division. This paper presents a comprehensive solution for monocular height estimation in remote sensing, termed HeightFormer, combining multilevel interactions and image-adaptive classification-regression. It features the Multilevel Interaction Backbone (MIB) and Image-adaptive Classification-regression Height Generator (ICG). MIB supplements the fixed sample grid in CNN of the conventional backbone network with tokens of different interaction ranges. It is complemented by a pixel-, patch-, and feature map-level hierarchical interaction mechanism, designed to relay spatial geometry information across different scales and introducing a global receptive field to enhance the quality of instance-level height estimation. The ICG dynamically generates height partition for each image and reframes the traditional regression task, using a refinement from coarse to fine classification-regression that significantly mitigates the innate ill-posedness issue and drastically improves edge sharpness.", "url": "https://arxiv.org/abs/2310.07995"}, {"metadata": {"arXiv": "2310.07997", "Date": "Thu, 12 Oct 2023 02:52:33 ", "Title": "Point-NeuS: Point-Guided Neural Implicit Surface Reconstruction by Volume Rendering", "Authors": ["Chen Zhang", "Wanjuan Su", "Wenbing Tao"], "Categories": "cs.CV cs.AI"}, "abstract": "Recently, learning neural implicit surface by volume rendering has been a promising way for multi-view reconstruction. However, limited accuracy and excessive time complexity remain bottlenecks that current methods urgently need to overcome. To address these challenges, we propose a new method called Point-NeuS, utilizing point-guided mechanisms to achieve accurate and efficient reconstruction. Point modeling is organically embedded into the volume rendering to enhance and regularize the representation of implicit surface. Specifically, to achieve precise point guidance and noise robustness, aleatoric uncertainty of the point cloud is modeled to capture the distribution of noise and estimate the reliability of points. Additionally, a Neural Projection module connecting points and images is introduced to add geometric constraints to the Signed Distance Function (SDF). To better compensate for geometric bias between volume rendering and point modeling, high-fidelity points are filtered into an Implicit Displacement Network to improve the representation of SDF. Benefiting from our effective point guidance, lightweight networks are employed to achieve an impressive 11x speedup compared to NeuS. Extensive experiments show that our method yields high-quality surfaces, especially for fine-grained details and smooth regions. Moreover, it exhibits strong robustness to both noisy and sparse data.", "url": "https://arxiv.org/abs/2310.07997"}, {"metadata": {"arXiv": "2310.08026", "Date": "Thu, 12 Oct 2023 04:12:43 ", "Title": "Beyond Sharing Weights in Decoupling Feature Learning Network for UAV RGB-Infrared Vehicle Re-Identification", "Authors": ["Xingyue Liu", "Jiahao Qi", "Chen Chen", "Kangcheng Bin and Ping Zhong"], "Categories": "cs.CV cs.AI", "Comments": ["13 pages", "10 figures", "64 citations", "submitted to TMM"]}, "abstract": "Owing to the capacity of performing full-time target search, cross-modality vehicle re-identification (Re-ID) based on unmanned aerial vehicle (UAV) is gaining more attention in both video surveillance and public security. However, this promising and innovative research has not been studied sufficiently due to the data inadequacy issue. Meanwhile, the cross-modality discrepancy and orientation discrepancy challenges further aggravate the difficulty of this task. To this end, we pioneer a cross-modality vehicle Re-ID benchmark named UAV Cross-Modality Vehicle Re-ID (UCM-VeID), containing 753 identities with 16015 RGB and 13913 infrared images. Moreover, to meet cross-modality discrepancy and orientation discrepancy challenges, we present a hybrid weights decoupling network (HWDNet) to learn the shared discriminative orientation-invariant features. For the first challenge, we proposed a hybrid weights siamese network with a well-designed weight restrainer and its corresponding objective function to learn both modality-specific and modality shared information. In terms of the second challenge, three effective decoupling structures with two pretext tasks are investigated to learn orientation-invariant feature. Comprehensive experiments are carried out to validate the effectiveness of the proposed method. The dataset and codes will be released at https://github.com/moonstarL/UAV-CM-VeID.", "url": "https://arxiv.org/abs/2310.08026"}, {"metadata": {"arXiv": "2310.08117", "Date": "Thu, 12 Oct 2023 08:21:17 ", "Title": "DUSA: Decoupled Unsupervised Sim2Real Adaptation for Vehicle-to-Everything Collaborative Perception", "Authors": ["Xianghao Kong", "Wentao Jiang", "Jinrang Jia", "Yifeng Shi", "Runsheng Xu", "Si Liu"], "Categories": "cs.CV cs.AI", "Comments": ["ACM MM 2023"], "DOI": "10.1145/3581783.3611948"}, "abstract": "Vehicle-to-Everything (V2X) collaborative perception is crucial for autonomous driving. However, achieving high-precision V2X perception requires a significant amount of annotated real-world data, which can always be expensive and hard to acquire. Simulated data have raised much attention since they can be massively produced at an extremely low cost. Nevertheless, the significant domain gap between simulated and real-world data, including differences in sensor type, reflectance patterns, and road surroundings, often leads to poor performance of models trained on simulated data when evaluated on real-world data. In addition, there remains a domain gap between real-world collaborative agents, e.g. different types of sensors may be installed on autonomous vehicles and roadside infrastructures with different extrinsics, further increasing the difficulty of sim2real generalization. To take full advantage of simulated data, we present a new unsupervised sim2real domain adaptation method for V2X collaborative detection named Decoupled Unsupervised Sim2Real Adaptation (DUSA). Our new method decouples the V2X collaborative sim2real domain adaptation problem into two sub-problems: sim2real adaptation and inter-agent adaptation. For sim2real adaptation, we design a Location-adaptive Sim2Real Adapter (LSA) module to adaptively aggregate features from critical locations of the feature map and align the features between simulated data and real-world data via a sim/real discriminator on the aggregated global feature. For inter-agent adaptation, we further devise a Confidence-aware Inter-agent Adapter (CIA) module to align the fine-grained features from heterogeneous agents under the guidance of agent-wise confidence maps. Experiments demonstrate the effectiveness of the proposed DUSA approach on unsupervised sim2real adaptation from the simulated V2XSet dataset to the real-world DAIR-V2X-C dataset.", "url": "https://arxiv.org/abs/2310.08117"}, {"metadata": {"arXiv": "2310.08206", "Date": "Thu, 12 Oct 2023 10:51:23 ", "Title": "Long-Tailed Classification Based on Coarse-Grained Leading Forest and Multi-Center Loss", "Authors": ["Jinye Yang", "Ji Xu"], "Categories": "cs.CV cs.AI", "Comments": ["This is another research work to apply leading tree structure along with deep learning architecture"]}, "abstract": "Long-tailed(LT) classification is an unavoidable and challenging problem in the real world. Most of the existing long-tailed classification methods focus only on solving the inter-class imbalance in which there are more samples in the head class than in the tail class, while ignoring the intra-lass imbalance in which the number of samples of the head attribute within the same class is much larger than the number of samples of the tail attribute. The deviation in the model is caused by both of these factors, and due to the fact that attributes are implicit in most datasets and the combination of attributes is very complex, the intra-class imbalance is more difficult to handle. For this purpose, we proposed a long-tailed classification framework, known as \\textbf{\\textsc{Cognisance}}, which is founded on Coarse-Grained Leading Forest (CLF) and Multi-Center Loss (MCL), aiming to build a multi-granularity joint solution model by means of invariant feature learning. In this method, we designed an unsupervised learning method, i.e., CLF, to better characterize the distribution of attributes within a class. Depending on the distribution of attributes, we can flexibly construct sampling strategies suitable for different environments. In addition, we introduce a new metric learning loss (MCL), which aims to gradually eliminate confusing attributes during the feature learning process. More importantly, this approach does not depend on a specific model structure and can be integrated with existing LT methods as an independent component. We have conducted extensive experiments and our approach has state-of-the-art performance in both existing benchmarks ImageNet-GLT and MSCOCO-GLT, and can improve the performance of existing LT methods. Our codes are available on GitHub: \\url{https://github.com/jinyery/cognisance}", "url": "https://arxiv.org/abs/2310.08206"}, {"metadata": {"arXiv": "2310.08276", "Date": "Thu, 12 Oct 2023 12:28:47 ", "Title": "Direction-Oriented Visual-semantic Embedding Model for Remote Sensing Image-text Retrieval", "Authors": ["Qing Ma", "Jiancheng Pan", "Cong Bai"], "Categories": "cs.CV cs.AI", "Comments": ["13 pages", "11 figures"]}, "abstract": "Image-text retrieval has developed rapidly in recent years. However, it is still a challenge in remote sensing due to visual-semantic imbalance, which leads to incorrect matching of non-semantic visual and textual features. To solve this problem, we propose a novel Direction-Oriented Visual-semantic Embedding Model (DOVE) to mine the relationship between vision and language. Concretely, a Regional-Oriented Attention Module (ROAM) adaptively adjusts the distance between the final visual and textual embeddings in the latent semantic space, oriented by regional visual features. Meanwhile, a lightweight Digging Text Genome Assistant (DTGA) is designed to expand the range of tractable textual representation and enhance global word-level semantic connections using less attention operations. Ultimately, we exploit a global visual-semantic constraint to reduce single visual dependency and serve as an external constraint for the final visual and textual representations. The effectiveness and superiority of our method are verified by extensive experiments including parameter evaluation, quantitative comparison, ablation studies and visual analysis, on two benchmark datasets, RSICD and RSITMD.", "url": "https://arxiv.org/abs/2310.08276"}, {"metadata": {"arXiv": "2310.08421", "Date": "Thu, 12 Oct 2023 15:42:17 ", "Title": "\"SegLoc\": Study on Novel Visual Self-supervised Learning Scheme (Segment Localization) Tailored for Dense Prediction Tasks of Security Inspection X-ray Images", "Authors": ["Shervin Halat", "Mohammad Rahmati", "Ehsan Nazerfard"], "Categories": "cs.CV cs.AI"}, "abstract": "Lately, remarkable advancements of artificial intelligence have been attributed to the integration of self-supervised learning scheme. Despite impressive achievements within NLP, yet SSL in computer vision has not been able to stay on track comparatively. Recently, integration of contrastive learning on top of existing SSL models has established considerable progress in computer vision through which visual SSL models have outperformed their supervised counterparts. Nevertheless, most of these improvements were limited to classification tasks, and also, few works have been dedicated to evaluation of SSL models in real-world scenarios of computer vision, while the majority of works are centered around datasets containing class-wise portrait images, most notably, ImageNet. Consequently, in this work, we have considered dense prediction task of semantic segmentation in security inspection x-ray images to evaluate our proposed model Segmentation Localization. Based upon the model Instance Localization, our model SegLoc has managed to address one of the most challenging downsides of contrastive learning, i.e., false negative pairs of query embeddings. In order to do so, in contrast to baseline model InsLoc, our pretraining dataset is synthesized by cropping, transforming, then pasting already labeled segments from an available labeled dataset, foregrounds, onto instances of an unlabeled dataset, backgrounds. In our case, PIDray and SIXray datasets are considered as labeled and unlabeled datasets, respectively. Moreover, we fully harness labels by avoiding false negative pairs through implementing the idea, one queue per class, in MoCo-v2 whereby negative pairs corresponding to each query are extracted from its corresponding queue within the memory bank. Our approach has outperformed random initialization by 3% to 6%, while having underperformed supervised initialization.", "url": "https://arxiv.org/abs/2310.08421"}, {"metadata": {"arXiv": "2310.08442", "Date": "Thu, 12 Oct 2023 16:04:41 ", "Title": "Debias the Training of Diffusion Models", "Authors": ["Hu Yu", "Li Shen", "Jie Huang", "Man Zhou", "Hongsheng Li", "Feng Zhao"], "Categories": "cs.CV cs.AI", "Comments": ["University of Science and Technology of China", "Alibaba Group", "The Chinese University of Hong Kong"]}, "abstract": "Diffusion models have demonstrated compelling generation quality by optimizing the variational lower bound through a simple denoising score matching loss. In this paper, we provide theoretical evidence that the prevailing practice of using a constant loss weight strategy in diffusion models leads to biased estimation during the training phase. Simply optimizing the denoising network to predict Gaussian noise with constant weighting may hinder precise estimations of original images. To address the issue, we propose an elegant and effective weighting strategy grounded in the theoretically unbiased principle. Moreover, we conduct a comprehensive and systematic exploration to dissect the inherent bias problem deriving from constant weighting loss from the perspectives of its existence, impact and reasons. These analyses are expected to advance our understanding and demystify the inner workings of diffusion models. Through empirical evaluation, we demonstrate that our proposed debiased estimation method significantly enhances sample quality without the reliance on complex techniques, and exhibits improved efficiency compared to the baseline method both in training and sampling processes.", "url": "https://arxiv.org/abs/2310.08442"}, {"metadata": {"arXiv": "2310.08097", "Date": "Thu, 12 Oct 2023 07:45:18 ", "Title": "Sentinel: An Aggregation Function to Secure Decentralized Federated Learning", "Authors": ["Chao Feng", "Alberto Huertas Celdran", "Janosch Baltensperger", "Enrique Tomas Mat{\\i}nez Bertran", "Gerome Bovet", "Burkhard Stiller"], "Categories": "cs.DC cs.AI"}, "abstract": "The rapid integration of Federated Learning (FL) into networking encompasses various aspects such as network management, quality of service, and cybersecurity while preserving data privacy. In this context, Decentralized Federated Learning (DFL) emerges as an innovative paradigm to train collaborative models, addressing the single point of failure limitation. However, the security and trustworthiness of FL and DFL are compromised by poisoning attacks, negatively impacting its performance. Existing defense mechanisms have been designed for centralized FL and they do not adequately exploit the particularities of DFL. Thus, this work introduces Sentinel, a defense strategy to counteract poisoning attacks in DFL. Sentinel leverages the accessibility of local data and defines a three-step aggregation protocol consisting of similarity filtering, bootstrap validation, and normalization to safeguard against malicious model updates. Sentinel has been evaluated with diverse datasets and various poisoning attack types and threat levels, improving the state-of-the-art performance against both untargeted and targeted poisoning attacks.", "url": "https://arxiv.org/abs/2310.08097"}, {"metadata": {"arXiv": "2310.08401", "Date": "Thu, 12 Oct 2023 15:10:55 ", "Title": "Performance/power assessment of CNN packages on embedded automotive platforms", "Authors": ["Paolo Burgio and Gianluca Brilli"], "Categories": "cs.DC cs.AI cs.PF", "Comments": ["14 pages; 17 figures", "10 tables"]}, "abstract": "The rise of power-efficient embedded computers based on highly-parallel accelerators opens a number of opportunities and challenges for researchers and engineers, and paved the way to the era of edge computing. At the same time, advances in embedded AI for object detection and categorization such as YOLO, GoogleNet and AlexNet reached an unprecedented level of accuracy (mean-Average Precision - mAP) and performance (Frames-Per-Second - FPS). Today, edge computers based on heterogeneous many-core systems are a predominant choice to deploy such systems in industry 4.0, wearable devices, and - our focus - autonomous driving systems. In these latter systems, engineers struggle to make reduced automotive power and size budgets co-exist with the accuracy and performance targets requested by autonomous driving. We aim at validating the effectiveness and efficiency of most recent networks on state-of-the-art platforms with embedded commercial-off-the-shelf System-on-Chips, such as Xavier AGX, Tegra X2 and Nano for NVIDIA and XCZU9EG and XCZU3EG of the Zynq UltraScale+ family, for the Xilinx counterpart. Our work aims at supporting engineers in choosing the most appropriate CNN package and computing system for their designs, and deriving guidelines for adequately sizing their systems.", "url": "https://arxiv.org/abs/2310.08401"}, {"metadata": {"arXiv": "2310.08066", "Date": "Thu, 12 Oct 2023 06:30:12 ", "Title": "The Search-and-Mix Paradigm in Approximate Nash Equilibrium Algorithms", "Authors": ["Xiaotie Deng", "Dongchen Li", "Hanyu Li"], "Categories": "cs.GT cs.AI cs.DS cs.LO"}, "abstract": "AI in Math deals with mathematics in a constructive manner so that reasoning becomes automated, less laborious, and less error-prone. For algorithms, the question becomes how to automate analyses for specific problems. For the first time, this work provides an automatic method for approximation analysis on a well-studied problem in theoretical computer science: computing approximate Nash equilibria in two-player games. We observe that such algorithms can be reformulated into a search-and-mix paradigm, which involves a search phase followed by a mixing phase. By doing so, we are able to fully automate the procedure of designing and analyzing the mixing phase. For example, we illustrate how to perform our method with a program to analyze the approximation bounds of all the algorithms in the literature. Same approximation bounds are computed without any hand-written proof. Our automatic method heavily relies on the LP-relaxation structure in approximate Nash equilibria. Since many approximation algorithms and online algorithms adopt the LP relaxation, our approach may be extended to automate the analysis of other algorithms.", "url": "https://arxiv.org/abs/2310.08066"}, {"metadata": {"arXiv": "2310.07932", "Date": "Wed, 11 Oct 2023 23:04:07 ", "Title": "What Matters to You? Towards Visual Representation Alignment for Robot Learning", "Authors": ["Ran Tian", "Chenfeng Xu", "Masayoshi Tomizuka", "Jitendra Malik", "Andrea Bajcsy"], "Categories": "cs.RO cs.AI cs.CV"}, "abstract": "When operating in service of people, robots need to optimize rewards aligned with end-user preferences. Since robots will rely on raw perceptual inputs like RGB images, their rewards will inevitably use visual representations. Recently there has been excitement in using representations from pre-trained visual models, but key to making these work in robotics is fine-tuning, which is typically done via proxy tasks like dynamics prediction or enforcing temporal cycle-consistency. However, all these proxy tasks bypass the human's input on what matters to them, exacerbating spurious correlations and ultimately leading to robot behaviors that are misaligned with user preferences. In this work, we propose that robots should leverage human feedback to align their visual representations with the end-user and disentangle what matters for the task. We propose Representation-Aligned Preference-based Learning (RAPL), a method for solving the visual representation alignment problem and visual reward learning problem through the lens of preference-based learning and optimal transport. Across experiments in X-MAGICAL and in robotic manipulation, we find that RAPL's reward consistently generates preferred robot behaviors with high sample efficiency, and shows strong zero-shot generalization when the visual representation is learned from a different embodiment than the robot's.", "url": "https://arxiv.org/abs/2310.07932"}, {"metadata": {"arXiv": "2310.07937", "Date": "Wed, 11 Oct 2023 23:17:43 ", "Title": "Co-NavGPT: Multi-Robot Cooperative Visual Semantic Navigation using Large Language Models", "Authors": ["Bangguo Yu", "Hamidreza Kasaei", "Ming Cao"], "Categories": "cs.RO cs.AI", "Comments": ["7 pages", "4 figures", "conference"]}, "abstract": "In advanced human-robot interaction tasks, visual target navigation is crucial for autonomous robots navigating unknown environments. While numerous approaches have been developed in the past, most are designed for single-robot operations, which often suffer from reduced efficiency and robustness due to environmental complexities. Furthermore, learning policies for multi-robot collaboration are resource-intensive. To address these challenges, we propose Co-NavGPT, an innovative framework that integrates Large Language Models (LLMs) as a global planner for multi-robot cooperative visual target navigation. Co-NavGPT encodes the explored environment data into prompts, enhancing LLMs' scene comprehension. It then assigns exploration frontiers to each robot for efficient target search. Experimental results on Habitat-Matterport 3D (HM3D) demonstrate that Co-NavGPT surpasses existing models in success rates and efficiency without any learning process, demonstrating the vast potential of LLMs in multi-robot collaboration domains. The supplementary video, prompts, and code can be accessed via the following link: \\href{https://sites.google.com/view/co-navgpt}{https://sites.google.com/view/co-navgpt}.", "url": "https://arxiv.org/abs/2310.07937"}, {"metadata": {"arXiv": "2310.08233", "Date": "Thu, 12 Oct 2023 11:27:01 ", "Title": "The Impact of Time Step Frequency on the Realism of Robotic Manipulation Simulation for Objects of Different Scales", "Authors": ["Minh Q. Ta and Holly Dinkel and Hameed Abdul-Rashid and Yangfei Dai and Jessica Myers and Tan Chen and Junyi Geng and Timothy Bretl"], "Categories": "cs.RO cs.AI", "Comments": ["3 pages", "3 figures", "Best Poster Finalist at the 2023 Robotics and AI in Future Factory Workshop at the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). Video presentation [https://www.youtube.com/watch?v=JOXrBpMmI0A]. Robotics and AI in Future Factory workshop [https://sites.google.com/view/robot-ai-future-factory/]"]}, "abstract": "This work evaluates the impact of time step frequency and component scale on robotic manipulation simulation accuracy. Increasing the time step frequency for small-scale objects is shown to improve simulation accuracy. This simulation, demonstrating pre-assembly part picking for two object geometries, serves as a starting point for discussing how to improve Sim2Real transfer in robotic assembly processes.", "url": "https://arxiv.org/abs/2310.08233"}, {"metadata": {"arXiv": "2310.08565", "Date": "Thu, 12 Oct 2023 17:54:20 ", "Title": "Security Considerations in AI-Robotics: A Survey of Current Methods, Challenges, and Opportunities", "Authors": ["Subash Neupane", "Shaswata Mitra", "Ivan A. Fernandez", "Swayamjit Saha", "Sudip Mittal", "Jingdao Chen", "Nisha Pillai", "Shahram Rahimi"], "Categories": "cs.RO cs.AI"}, "abstract": "Robotics and Artificial Intelligence (AI) have been inextricably intertwined since their inception. Today, AI-Robotics systems have become an integral part of our daily lives, from robotic vacuum cleaners to semi-autonomous cars. These systems are built upon three fundamental architectural elements: perception, navigation and planning, and control. However, while the integration of AI-Robotics systems has enhanced the quality our lives, it has also presented a serious problem - these systems are vulnerable to security attacks. The physical components, algorithms, and data that make up AI-Robotics systems can be exploited by malicious actors, potentially leading to dire consequences. Motivated by the need to address the security concerns in AI-Robotics systems, this paper presents a comprehensive survey and taxonomy across three dimensions: attack surfaces, ethical and legal concerns, and Human-Robot Interaction (HRI) security. Our goal is to provide users, developers and other stakeholders with a holistic understanding of these areas to enhance the overall AI-Robotics system security. We begin by surveying potential attack surfaces and provide mitigating defensive strategies. We then delve into ethical issues, such as dependency and psychological impact, as well as the legal concerns regarding accountability for these systems. Besides, emerging trends such as HRI are discussed, considering privacy, integrity, safety, trustworthiness, and explainability concerns. Finally, we present our vision for future research directions in this dynamic and promising field.", "url": "https://arxiv.org/abs/2310.08565"}, {"metadata": {"arXiv": "2310.07800", "Date": "Wed, 11 Oct 2023 18:33:17 ", "Title": "Explainable Attention for Few-shot Learning and Beyond", "Authors": ["Bahareh Nikpour", "Narges Armanfard"], "Categories": "cs.AI cs.LG"}, "abstract": "Attention mechanisms have exhibited promising potential in enhancing learning models by identifying salient portions of input data. This is particularly valuable in scenarios where limited training samples are accessible due to challenges in data collection and labeling. Drawing inspiration from human recognition processes, we posit that an AI baseline's performance could be more accurate and dependable if it is exposed to essential segments of raw data rather than the entire input dataset, akin to human perception. However, the task of selecting these informative data segments, referred to as hard attention finding, presents a formidable challenge. In situations with few training samples, existing studies struggle to locate such informative regions due to the large number of training parameters that cannot be effectively learned from the available limited samples. In this study, we introduce a novel and practical framework for achieving explainable hard attention finding, specifically tailored for few-shot learning scenarios, called FewXAT. Our approach employs deep reinforcement learning to implement the concept of hard attention, directly impacting raw input data and thus rendering the process interpretable for human understanding. Through extensive experimentation across various benchmark datasets, we demonstrate the efficacy of our proposed method.", "url": "https://arxiv.org/abs/2310.07800"}, {"metadata": {"arXiv": "2310.08184", "Date": "Thu, 12 Oct 2023 10:20:36 ", "Title": "Learn From Model Beyond Fine-Tuning: A Survey", "Authors": ["Hongling Zheng", "Li Shen", "Anke Tang", "Yong Luo", "Han Hu", "Bo Du", "Dacheng Tao"], "Categories": "cs.AI cs.LG", "Comments": ["20 pages", "9 figures"]}, "abstract": "Foundation models (FM) have demonstrated remarkable performance across a wide range of tasks (especially in the fields of natural language processing and computer vision), primarily attributed to their ability to comprehend instructions and access extensive, high-quality data. This not only showcases their current effectiveness but also sets a promising trajectory towards the development of artificial general intelligence. Unfortunately, due to multiple constraints, the raw data of the model used for large model training are often inaccessible, so the use of end-to-end models for downstream tasks has become a new research trend, which we call Learn From Model (LFM) in this article. LFM focuses on the research, modification, and design of FM based on the model interface, so as to better understand the model structure and weights (in a black box environment), and to generalize the model to downstream tasks. The study of LFM techniques can be broadly categorized into five major areas: model tuning, model distillation, model reuse, meta learning and model editing. Each category encompasses a repertoire of methods and strategies that aim to enhance the capabilities and performance of FM. This paper gives a comprehensive review of the current methods based on FM from the perspective of LFM, in order to help readers better understand the current research status and ideas. To conclude, we summarize the survey by highlighting several critical areas for future exploration and addressing open issues that require further attention from the research community. The relevant papers we investigated in this article can be accessed at <https://github.com/ruthless-man/Awesome-Learn-from-Model>.", "url": "https://arxiv.org/abs/2310.08184"}, {"metadata": {"arXiv": "2310.08217", "Date": "Thu, 12 Oct 2023 11:05:34 ", "Title": "TriRE: A Multi-Mechanism Learning Paradigm for Continual Knowledge Retention and Promotion", "Authors": ["Preetha Vijayan", "Prashant Bhat", "Elahe Arani", "Bahram Zonooz"], "Categories": "cs.AI cs.CV cs.LG", "Comments": ["Accepted at 37th Conference on Neural Information Processing Systems (NeurIPS 2023)"]}, "abstract": "Continual learning (CL) has remained a persistent challenge for deep neural networks due to catastrophic forgetting (CF) of previously learned tasks. Several techniques such as weight regularization, experience rehearsal, and parameter isolation have been proposed to alleviate CF. Despite their relative success, these research directions have predominantly remained orthogonal and suffer from several shortcomings, while missing out on the advantages of competing strategies. On the contrary, the brain continually learns, accommodates, and transfers knowledge across tasks by simultaneously leveraging several neurophysiological processes, including neurogenesis, active forgetting, neuromodulation, metaplasticity, experience rehearsal, and context-dependent gating, rarely resulting in CF. Inspired by how the brain exploits multiple mechanisms concurrently, we propose TriRE, a novel CL paradigm that encompasses retaining the most prominent neurons for each task, revising and solidifying the extracted knowledge of current and past tasks, and actively promoting less active neurons for subsequent tasks through rewinding and relearning. Across CL settings, TriRE significantly reduces task interference and surpasses different CL approaches considered in isolation.", "url": "https://arxiv.org/abs/2310.08217"}, {"metadata": {"arXiv": "2310.08235", "Date": "Thu, 12 Oct 2023 11:31:01 ", "Title": "GROOT: Learning to Follow Instructions by Watching Gameplay Videos", "Authors": ["Shaofei Cai", "Bowei Zhang", "Zihao Wang", "Xiaojian Ma", "Anji Liu", "Yitao Liang"], "Categories": "cs.AI cs.LG"}, "abstract": "We study the problem of building a controller that can follow open-ended instructions in open-world environments. We propose to follow reference videos as instructions, which offer expressive goal specifications while eliminating the need for expensive text-gameplay annotations. A new learning framework is derived to allow learning such instruction-following controllers from gameplay videos while producing a video instruction encoder that induces a structured goal space. We implement our agent GROOT in a simple yet effective encoder-decoder architecture based on causal transformers. We evaluate GROOT against open-world counterparts and human players on a proposed Minecraft SkillForge benchmark. The Elo ratings clearly show that GROOT is closing the human-machine gap as well as exhibiting a 70% winning rate over the best generalist agent baseline. Qualitative analysis of the induced goal space further demonstrates some interesting emergent properties, including the goal composition and complex gameplay behavior synthesis. Code and video can be found on the website https://craftjarvis-groot.github.io.", "url": "https://arxiv.org/abs/2310.08235"}, {"metadata": {"arXiv": "2310.08367", "Date": "Thu, 12 Oct 2023 14:38:25 ", "Title": "MCU: A Task-centric Framework for Open-ended Agent Evaluation in Minecraft", "Authors": ["Haowei Lin", "Zihao Wang", "Jianzhu Ma", "Yitao Liang"], "Categories": "cs.AI cs.CL cs.CV cs.LG"}, "abstract": "To pursue the goal of creating an open-ended agent in Minecraft, an open-ended game environment with unlimited possibilities, this paper introduces a task-centric framework named MCU for Minecraft agent evaluation. The MCU framework leverages the concept of atom tasks as fundamental building blocks, enabling the generation of diverse or even arbitrary tasks. Within the MCU framework, each task is measured with six distinct difficulty scores (time consumption, operational effort, planning complexity, intricacy, creativity, novelty). These scores offer a multi-dimensional assessment of a task from different angles, and thus can reveal an agent's capability on specific facets. The difficulty scores also serve as the feature of each task, which creates a meaningful task space and unveils the relationship between tasks. For efficient evaluation of Minecraft agents employing the MCU framework, we maintain a unified benchmark, namely SkillForge, which comprises representative tasks with diverse categories and difficulty distribution. We also provide convenient filters for users to select tasks to assess specific capabilities of agents. We show that MCU has the high expressivity to cover all tasks used in recent literature on Minecraft agent, and underscores the need for advancements in areas such as creativity, precise control, and out-of-distribution generalization under the goal of open-ended Minecraft agent development.", "url": "https://arxiv.org/abs/2310.08367"}, {"metadata": {"arXiv": "2310.08431", "Date": "Thu, 12 Oct 2023 15:56:02 ", "Title": "Neural Sampling in Hierarchical Exponential-family Energy-based Models", "Authors": ["Xingsi Dong", "Si Wu"], "Categories": "cs.AI cs.LG q-bio.NC", "Comments": ["NeurIPS 2023"]}, "abstract": "Bayesian brain theory suggests that the brain employs generative models to understand the external world. The sampling-based perspective posits that the brain infers the posterior distribution through samples of stochastic neuronal responses. Additionally, the brain continually updates its generative model to approach the true distribution of the external world. In this study, we introduce the Hierarchical Exponential-family Energy-based (HEE) model, which captures the dynamics of inference and learning. In the HEE model, we decompose the partition function into individual layers and leverage a group of neurons with shorter time constants to sample the gradient of the decomposed normalization term. This allows our model to estimate the partition function and perform inference simultaneously, circumventing the negative phase encountered in conventional energy-based models (EBMs). As a result, the learning process is localized both in time and space, and the model is easy to converge. To match the brain's rapid computation, we demonstrate that neural adaptation can serve as a momentum term, significantly accelerating the inference process. On natural image datasets, our model exhibits representations akin to those observed in the biological visual system. Furthermore, for the machine learning community, our model can generate observations through joint or marginal generation. We show that marginal generation outperforms joint generation and achieves performance on par with other EBMs.", "url": "https://arxiv.org/abs/2310.08431"}, {"metadata": {"arXiv": "2310.08304", "Date": "Thu, 12 Oct 2023 13:11:38 ", "Title": "CHIP: Contrastive Hierarchical Image Pretraining", "Authors": ["Arpit Mittal", "Harshil Jhaveri", "Swapnil Mallick", "Abhishek Ajmera"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Few-shot object classification is the task of classifying objects in an image with limited number of examples as supervision. We propose a one-shot/few-shot classification model that can classify an object of any unseen class into a relatively general category in an hierarchically based classification. Our model uses a three-level hierarchical contrastive loss based ResNet152 classifier for classifying an object based on its features extracted from Image embedding, not used during the training phase. For our experimentation, we have used a subset of the ImageNet (ILSVRC-12) dataset that contains only the animal classes for training our model and created our own dataset of unseen classes for evaluating our trained model. Our model provides satisfactory results in classifying the unknown objects into a generic category which has been later discussed in greater detail.", "url": "https://arxiv.org/abs/2310.08304"}, {"metadata": {"arXiv": "2310.08588", "Date": "Thu, 12 Oct 2023 17:59:58 ", "Title": "Octopus: Embodied Vision-Language Programmer from Environmental Feedback", "Authors": ["Jingkang Yang", "Yuhao Dong", "Shuai Liu", "Bo Li", "Ziyue Wang", "Chencheng Jiang", "Haoran Tan", "Jiamu Kang", "Yuanhan Zhang", "Kaiyang Zhou", "Ziwei Liu"], "Categories": "cs.CV cs.AI cs.LG cs.RO", "Comments": ["Project Page: https://choiszt.github.io/Octopus/", "Codebase: https://github.com/dongyh20/Octopus"]}, "abstract": "Large vision-language models (VLMs) have achieved substantial progress in multimodal perception and reasoning. Furthermore, when seamlessly integrated into an embodied agent, it signifies a crucial stride towards the creation of autonomous and context-aware systems capable of formulating plans and executing commands with precision. In this paper, we introduce Octopus, a novel VLM designed to proficiently decipher an agent's vision and textual task objectives and to formulate intricate action sequences and generate executable code. Our design allows the agent to adeptly handle a wide spectrum of tasks, ranging from mundane daily chores in simulators to sophisticated interactions in complex video games. Octopus is trained by leveraging GPT-4 to control an explorative agent to generate training data, i.e., action blueprints and the corresponding executable code, within our experimental environment called OctoVerse. We also collect the feedback that allows the enhanced training scheme of Reinforcement Learning with Environmental Feedback (RLEF). Through a series of experiments, we illuminate Octopus's functionality and present compelling results, and the proposed RLEF turns out to refine the agent's decision-making. By open-sourcing our model architecture, simulator, and dataset, we aspire to ignite further innovation and foster collaborative applications within the broader embodied AI community.", "url": "https://arxiv.org/abs/2310.08588"}, {"metadata": {"arXiv": "2310.07747", "Date": "Wed, 11 Oct 2023 17:20:32 ", "Title": "Accountability in Offline Reinforcement Learning: Explaining Decisions with a Corpus of Examples", "Authors": ["Hao Sun", "Alihan H\\\"uy\\\"uk", "Daniel Jarrett", "Mihaela van der Schaar"], "Categories": "cs.LG cs.AI cs.RO cs.SY eess.SY"}, "abstract": "Learning transparent, interpretable controllers with offline data in decision-making systems is an essential area of research due to its potential to reduce the risk of applications in real-world systems. However, in responsibility-sensitive settings such as healthcare, decision accountability is of paramount importance, yet has not been adequately addressed by the literature. This paper introduces the Accountable Offline Controller (AOC) that employs the offline dataset as the Decision Corpus and performs accountable control based on a tailored selection of examples, referred to as the Corpus Subset. ABC operates effectively in low-data scenarios, can be extended to the strictly offline imitation setting, and displays qualities of both conservation and adaptability. We assess ABC's performance in both simulated and real-world healthcare scenarios, emphasizing its capability to manage offline control tasks with high levels of performance while maintaining accountability. Keywords: Interpretable Reinforcement Learning, Explainable Reinforcement Learning, Reinforcement Learning Transparency, Offline Reinforcement Learning, Batched Control.", "url": "https://arxiv.org/abs/2310.07747"}, {"metadata": {"arXiv": "2310.07799", "Date": "Wed, 11 Oct 2023 18:32:21 ", "Title": "A Transfer-Learning-Based Prognosis Prediction Paradigm that Bridges Data Distribution Shift across EMR Datasets", "Authors": ["Zhongji Zhang", "Yuhang Wang", "Yinghao Zhu", "Xinyu Ma", "Tianlong Wang", "Chaohe Zhang", "Yasha Wang", "Liantao Ma"], "Categories": "cs.LG cs.AI"}, "abstract": "Due to the limited information about emerging diseases, symptoms are hard to be noticed and recognized, so that the window for clinical intervention could be ignored. An effective prognostic model is expected to assist doctors in making right diagnosis and designing personalized treatment plan, so to promptly prevent unfavorable outcomes. However, in the early stage of a disease, limited data collection and clinical experiences, plus the concern out of privacy and ethics, may result in restricted data availability for reference, to the extent that even data labels are difficult to mark correctly. In addition, Electronic Medical Record (EMR) data of different diseases or of different sources of the same disease can prove to be having serious cross-dataset feature misalignment problems, greatly mutilating the efficiency of deep learning models. This article introduces a transfer learning method to build a transition model from source dataset to target dataset. By way of constraining the distribution shift of features generated in disparate domains, domain-invariant features that are exclusively relative to downstream tasks are captured, so to cultivate a unified domain-invariant encoder across various task domains to achieve better feature representation. Experimental results of several target tasks demonstrate that our proposed model outperforms competing baseline methods and has higher rate of training convergence, especially in dealing with limited data amount. A multitude of experiences have proven the efficacy of our method to provide more accurate predictions concerning newly emergent pandemics and other diseases.", "url": "https://arxiv.org/abs/2310.07799"}, {"metadata": {"arXiv": "2310.07805", "Date": "Wed, 11 Oct 2023 18:38:28 ", "Title": "Generative Modeling with Phase Stochastic Bridges", "Authors": ["Tianrong Chen", "Jiatao Gu", "Laurent Dinh", "Evangelos A. Theodorou", "Josh Susskind", "Shuangfei Zhai"], "Categories": "cs.LG cs.AI"}, "abstract": "Diffusion models (DMs) represent state-of-the-art generative models for continuous inputs. DMs work by constructing a Stochastic Differential Equation (SDE) in the input space (ie, position space), and using a neural network to reverse it. In this work, we introduce a novel generative modeling framework grounded in \\textbf{phase space dynamics}, where a phase space is defined as {an augmented space encompassing both position and velocity.} Leveraging insights from Stochastic Optimal Control, we construct a path measure in the phase space that enables efficient sampling. {In contrast to DMs, our framework demonstrates the capability to generate realistic data points at an early stage of dynamics propagation.} This early prediction sets the stage for efficient data generation by leveraging additional velocity information along the trajectory. On standard image generation benchmarks, our model yields favorable performance over baselines in the regime of small Number of Function Evaluations (NFEs). Furthermore, our approach rivals the performance of diffusion models equipped with efficient sampling techniques, underscoring its potential as a new tool generative modeling.", "url": "https://arxiv.org/abs/2310.07805"}, {"metadata": {"arXiv": "2310.07831", "Date": "Wed, 11 Oct 2023 19:16:35 ", "Title": "When, Why and How Much? Adaptive Learning Rate Scheduling by Refinement", "Authors": ["Aaron Defazio and Ashok Cutkosky and Harsh Mehta and Konstantin Mishchenko"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "Learning rate schedules used in practice bear little resemblance to those recommended by theory. We close much of this theory/practice gap, and as a consequence are able to derive new problem-adaptive learning rate schedules. Our key technical contribution is a refined analysis of learning rate schedules for a wide class of optimization algorithms (including SGD). In contrast to most prior works that study the convergence of the average iterate, we study the last iterate, which is what most people use in practice. When considering only worst-case analysis, our theory predicts that the best choice is the linear decay schedule: a popular choice in practice that sets the stepsize proportionally to $1 - t/T$, where $t$ is the current iteration and $T$ is the total number of steps. To go beyond this worst-case analysis, we use the observed gradient norms to derive schedules refined for any particular task. These refined schedules exhibit learning rate warm-up and rapid learning rate annealing near the end of training. Ours is the first systematic approach to automatically yield both of these properties. We perform the most comprehensive evaluation of learning rate schedules to date, evaluating across 10 diverse deep learning problems, a series of LLMs, and a suite of logistic regression problems. We validate that overall, the linear-decay schedule matches or outperforms all commonly used default schedules including cosine annealing, and that our schedule refinement method gives further improvements.", "url": "https://arxiv.org/abs/2310.07831"}, {"metadata": {"arXiv": "2310.07838", "Date": "Wed, 11 Oct 2023 19:30:08 ", "Title": "Towards the Fundamental Limits of Knowledge Transfer over Finite Domains", "Authors": ["Qingyue Zhao and Banghua Zhu"], "Categories": "cs.LG cs.AI cs.IT math.IT math.ST stat.ML stat.TH", "Comments": ["38 pages", "2 figures; primary version"]}, "abstract": "We characterize the statistical efficiency of knowledge transfer through $n$ samples from a teacher to a probabilistic student classifier with input space $\\mathcal S$ over labels $\\mathcal A$. We show that privileged information at three progressive levels accelerates the transfer. At the first level, only samples with hard labels are known, via which the maximum likelihood estimator attains the minimax rate $\\sqrt{{|{\\mathcal S}||{\\mathcal A}|}/{n}}$. The second level has the teacher probabilities of sampled labels available in addition, which turns out to boost the convergence rate lower bound to ${{|{\\mathcal S}||{\\mathcal A}|}/{n}}$. However, under this second data acquisition protocol, minimizing a naive adaptation of the cross-entropy loss results in an asymptotically biased student. We overcome this limitation and achieve the fundamental limit by using a novel empirical variant of the squared error logit loss. The third level further equips the student with the soft labels (complete logits) on ${\\mathcal A}$ given every sampled input, thereby provably enables the student to enjoy a rate ${|{\\mathcal S}|}/{n}$ free of $|{\\mathcal A}|$. We find any Kullback-Leibler divergence minimizer to be optimal in the last case. Numerical simulations distinguish the four learners and corroborate our theory.", "url": "https://arxiv.org/abs/2310.07838"}, {"metadata": {"arXiv": "2310.07882", "Date": "Wed, 11 Oct 2023 20:45:49 ", "Title": "The Thousand Faces of Explainable AI Along the Machine Learning Life Cycle: Industrial Reality and Current State of Research", "Authors": ["Thomas Decker", "Ralf Gross", "Alexander Koebler", "Michael Lebacher", "Ronald Schnitzer", "and Stefan H. Weber"], "Categories": "cs.LG cs.AI cs.HC", "Comments": ["International Conference on Human-Computer Interaction 2023"], "DOI": "10.1007/978-3-031-35891-3_13"}, "abstract": "In this paper, we investigate the practical relevance of explainable artificial intelligence (XAI) with a special focus on the producing industries and relate them to the current state of academic XAI research. Our findings are based on an extensive series of interviews regarding the role and applicability of XAI along the Machine Learning (ML) lifecycle in current industrial practice and its expected relevance in the future. The interviews were conducted among a great variety of roles and key stakeholders from different industry sectors. On top of that, we outline the state of XAI research by providing a concise review of the relevant literature. This enables us to provide an encompassing overview covering the opinions of the surveyed persons as well as the current state of academic research. By comparing our interview results with the current research approaches we reveal several discrepancies. While a multitude of different XAI approaches exists, most of them are centered around the model evaluation phase and data scientists. Their versatile capabilities for other stages are currently either not sufficiently explored or not popular among practitioners. In line with existing work, our findings also confirm that more efforts are needed to enable also non-expert users' interpretation and understanding of opaque AI models with existing methods and frameworks.", "url": "https://arxiv.org/abs/2310.07882"}, {"metadata": {"arXiv": "2310.07885", "Date": "Wed, 11 Oct 2023 20:47:57 ", "Title": "Leader-Follower Neural Networks with Local Error Signals Inspired by Complex Collectives", "Authors": ["Chenzhong Yin", "Mingxi Cheng", "Xiongye Xiao", "Xinghe Chen", "Shahin Nazarian", "Andrei Irimia and Paul Bogdan"], "Categories": "cs.LG cs.AI"}, "abstract": "The collective behavior of a network with heterogeneous, resource-limited information processing units (e.g., group of fish, flock of birds, or network of neurons) demonstrates high self-organization and complexity. These emergent properties arise from simple interaction rules where certain individuals can exhibit leadership-like behavior and influence the collective activity of the group. Motivated by the intricacy of these collectives, we propose a neural network (NN) architecture inspired by the rules observed in nature's collective ensembles. This NN structure contains workers that encompass one or more information processing units (e.g., neurons, filters, layers, or blocks of layers). Workers are either leaders or followers, and we train a leader-follower neural network (LFNN) by leveraging local error signals and optionally incorporating backpropagation (BP) and global loss. We investigate worker behavior and evaluate LFNNs through extensive experimentation. Our LFNNs trained with local error signals achieve significantly lower error rates than previous BP-free algorithms on MNIST and CIFAR-10 and even surpass BP-enabled baselines. In the case of ImageNet, our LFNN-l demonstrates superior scalability and outperforms previous BP-free algorithms by a significant margin.", "url": "https://arxiv.org/abs/2310.07885"}, {"metadata": {"arXiv": "2310.07894", "Date": "Wed, 11 Oct 2023 21:04:42 ", "Title": "Efficient Integrators for Diffusion Generative Models", "Authors": ["Kushagra Pandey", "Maja Rudolph", "Stephan Mandt"], "Categories": "cs.LG cs.AI cs.CV stat.ML"}, "abstract": "Diffusion models suffer from slow sample generation at inference time. Therefore, developing a principled framework for fast deterministic/stochastic sampling for a broader class of diffusion models is a promising direction. We propose two complementary frameworks for accelerating sample generation in pre-trained models: Conjugate Integrators and Splitting Integrators. Conjugate integrators generalize DDIM, mapping the reverse diffusion dynamics to a more amenable space for sampling. In contrast, splitting-based integrators, commonly used in molecular dynamics, reduce the numerical simulation error by cleverly alternating between numerical updates involving the data and auxiliary variables. After extensively studying these methods empirically and theoretically, we present a hybrid method that leads to the best-reported performance for diffusion models in augmented spaces. Applied to Phase Space Langevin Diffusion [Pandey & Mandt, 2023] on CIFAR-10, our deterministic and stochastic samplers achieve FID scores of 2.11 and 2.36 in only 100 network function evaluations (NFE) as compared to 2.57 and 2.63 for the best-performing baselines, respectively. Our code and model checkpoints will be made publicly available at \\url{https://github.com/mandt-lab/PSLD}.", "url": "https://arxiv.org/abs/2310.07894"}, {"metadata": {"arXiv": "2310.07917", "Date": "Wed, 11 Oct 2023 22:14:17 ", "Title": "A Review of Machine Learning Techniques in Imbalanced Data and Future Trends", "Authors": ["Elaheh Jafarigol", "Theodore Trafalis"], "Categories": "cs.LG cs.AI"}, "abstract": "For over two decades, detecting rare events has been a challenging task among researchers in the data mining and machine learning domain. Real-life problems inspire researchers to navigate and further improve data processing and algorithmic approaches to achieve effective and computationally efficient methods for imbalanced learning. In this paper, we have collected and reviewed 258 peer-reviewed papers from archival journals and conference papers in an attempt to provide an in-depth review of various approaches in imbalanced learning from technical and application perspectives. This work aims to provide a structured review of methods used to address the problem of imbalanced data in various domains and create a general guideline for researchers in academia or industry who want to dive into the broad field of machine learning using large-scale imbalanced data.", "url": "https://arxiv.org/abs/2310.07917"}, {"metadata": {"arXiv": "2310.07918", "Date": "Wed, 11 Oct 2023 22:17:37 ", "Title": "Contextualized Policy Recovery: Modeling and Interpreting Medical Decisions with Adaptive Imitation Learning", "Authors": ["Jannik Deuschel", "Caleb N. Ellington", "Benjamin J. Lengerich", "Yingtao Luo", "Pascal Friederich", "Eric P. Xing"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "Interpretable policy learning seeks to estimate intelligible decision policies from observed actions; however, existing models fall short by forcing a tradeoff between accuracy and interpretability. This tradeoff limits data-driven interpretations of human decision-making process. e.g. to audit medical decisions for biases and suboptimal practices, we require models of decision processes which provide concise descriptions of complex behaviors. Fundamentally, existing approaches are burdened by this tradeoff because they represent the underlying decision process as a universal policy, when in fact human decisions are dynamic and can change drastically with contextual information. Thus, we propose Contextualized Policy Recovery (CPR), which re-frames the problem of modeling complex decision processes as a multi-task learning problem in which complex decision policies are comprised of context-specific policies. CPR models each context-specific policy as a linear observation-to-action mapping, and generates new decision models $\\textit{on-demand}$ as contexts are updated with new observations. CPR is compatible with fully offline and partially observable decision environments, and can be tailored to incorporate any recurrent black-box model or interpretable decision model. We assess CPR through studies on simulated and real data, achieving state-of-the-art performance on the canonical tasks of predicting antibiotic prescription in intensive care units ($+22\\%$ AUROC vs. previous SOTA) and predicting MRI prescription for Alzheimer's patients ($+7.7\\%$ AUROC vs. previous SOTA). With this improvement in predictive performance, CPR closes the accuracy gap between interpretable and black-box methods for policy learning, allowing high-resolution exploration and analysis of context-specific decision models.", "url": "https://arxiv.org/abs/2310.07918"}, {"metadata": {"arXiv": "2310.07931", "Date": "Wed, 11 Oct 2023 23:01:29 ", "Title": "D2 Pruning: Message Passing for Balancing Diversity and Difficulty in Data Pruning", "Authors": ["Adyasha Maharana", "Prateek Yadav", "Mohit Bansal"], "Categories": "cs.LG cs.AI cs.CL cs.CV", "Comments": ["17 pages (Our code is available at https://github.com/adymaharana/d2pruning)"]}, "abstract": "Analytical theories suggest that higher-quality data can lead to lower test errors in models trained on a fixed data budget. Moreover, a model can be trained on a lower compute budget without compromising performance if a dataset can be stripped of its redundancies. Coreset selection (or data pruning) seeks to select a subset of the training data so as to maximize the performance of models trained on this subset, also referred to as coreset. There are two dominant approaches: (1) geometry-based data selection for maximizing data diversity in the coreset, and (2) functions that assign difficulty scores to samples based on training dynamics. Optimizing for data diversity leads to a coreset that is biased towards easier samples, whereas, selection by difficulty ranking omits easy samples that are necessary for the training of deep learning models. This demonstrates that data diversity and importance scores are two complementary factors that need to be jointly considered during coreset selection. We represent a dataset as an undirected graph and propose a novel pruning algorithm, D2 Pruning, that uses forward and reverse message passing over this dataset graph for coreset selection. D2 Pruning updates the difficulty scores of each example by incorporating the difficulty of its neighboring examples in the dataset graph. Then, these updated difficulty scores direct a graph-based sampling method to select a coreset that encapsulates both diverse and difficult regions of the dataset space. We evaluate supervised and self-supervised versions of our method on various vision and language datasets. Results show that D2 Pruning improves coreset selection over previous state-of-the-art methods for up to 70% pruning rates. Additionally, we find that using D2 Pruning for filtering large multimodal datasets leads to increased diversity in the dataset and improved generalization of pretrained models.", "url": "https://arxiv.org/abs/2310.07931"}, {"metadata": {"arXiv": "2310.07972", "Date": "Thu, 12 Oct 2023 01:40:20 ", "Title": "Interpretable Diffusion via Information Decomposition", "Authors": ["Xianghao Kong", "Ollie Liu", "Han Li", "Dani Yogatama", "Greg Ver Steeg"], "Categories": "cs.LG cs.AI cs.IT math.IT", "Comments": ["32 pages", "18 figures"]}, "abstract": "Denoising diffusion models enable conditional generation and density modeling of complex relationships like images and text. However, the nature of the learned relationships is opaque making it difficult to understand precisely what relationships between words and parts of an image are captured, or to predict the effect of an intervention. We illuminate the fine-grained relationships learned by diffusion models by noticing a precise relationship between diffusion and information decomposition. Exact expressions for mutual information and conditional mutual information can be written in terms of the denoising model. Furthermore, pointwise estimates can be easily estimated as well, allowing us to ask questions about the relationships between specific images and captions. Decomposing information even further to understand which variables in a high-dimensional space carry information is a long-standing problem. For diffusion models, we show that a natural non-negative decomposition of mutual information emerges, allowing us to quantify informative relationships between words and pixels in an image. We exploit these new relations to measure the compositional understanding of diffusion models, to do unsupervised localization of objects in images, and to measure effects when selectively editing images through prompt interventions.", "url": "https://arxiv.org/abs/2310.07972"}, {"metadata": {"arXiv": "2310.08056", "Date": "Thu, 12 Oct 2023 06:09:26 ", "Title": "Learning from Label Proportions: Bootstrapping Supervised Learners via Belief Propagation", "Authors": ["Shreyas Havaldar", "Navodita Sharma", "Shubhi Sareen", "Karthikeyan Shanmugam", "Aravindan Raghuveer"], "Categories": "cs.LG cs.AI"}, "abstract": "Learning from Label Proportions (LLP) is a learning problem where only aggregate level labels are available for groups of instances, called bags, during training, and the aim is to get the best performance at the instance-level on the test data. This setting arises in domains like advertising and medicine due to privacy considerations. We propose a novel algorithmic framework for this problem that iteratively performs two main steps. For the first step (Pseudo Labeling) in every iteration, we define a Gibbs distribution over binary instance labels that incorporates a) covariate information through the constraint that instances with similar covariates should have similar labels and b) the bag level aggregated label. We then use Belief Propagation (BP) to marginalize the Gibbs distribution to obtain pseudo labels. In the second step (Embedding Refinement), we use the pseudo labels to provide supervision for a learner that yields a better embedding. Further, we iterate on the two steps again by using the second step's embeddings as new covariates for the next iteration. In the final iteration, a classifier is trained using the pseudo labels. Our algorithm displays strong gains against several SOTA baselines (up to 15%) for the LLP Binary Classification problem on various dataset types - tabular and Image. We achieve these improvements with minimal computational overhead above standard supervised learning due to Belief Propagation, for large bag sizes, even for a million samples.", "url": "https://arxiv.org/abs/2310.08056"}, {"metadata": {"arXiv": "2310.08091", "Date": "Thu, 12 Oct 2023 07:38:10 ", "Title": "Discerning Temporal Difference Learning", "Authors": ["Jianfei Ma"], "Categories": "cs.LG cs.AI"}, "abstract": "Temporal difference learning (TD) is a foundational concept in reinforcement learning (RL), aimed at efficiently assessing a policy's value function. TD($\\lambda$), a potent variant, incorporates a memory trace to distribute the prediction error into the historical context. However, this approach often neglects the significance of historical states and the relative importance of propagating the TD error, influenced by challenges such as visitation imbalance or outcome noise. To address this, we propose a novel TD algorithm named discerning TD learning (DTD), which allows flexible emphasis functions$-$predetermined or adapted during training$-$to allocate efforts effectively across states. We establish the convergence properties of our method within a specific class of emphasis functions and showcase its promising potential for adaptation to deep RL contexts. Empirical results underscore that employing a judicious emphasis function not only improves value estimation but also expedites learning across diverse scenarios.", "url": "https://arxiv.org/abs/2310.08091"}, {"metadata": {"arXiv": "2310.08138", "Date": "Thu, 12 Oct 2023 08:52:36 ", "Title": "Multi-Scale Spatial-Temporal Recurrent Networks for Traffic Flow Prediction", "Authors": ["Haiyang Liu", "Chunjiang Zhu", "Detian Zhang", "Qing Li"], "Categories": "cs.LG cs.AI"}, "abstract": "Traffic flow prediction is one of the most fundamental tasks of intelligent transportation systems. The complex and dynamic spatial-temporal dependencies make the traffic flow prediction quite challenging. Although existing spatial-temporal graph neural networks hold prominent, they often encounter challenges such as (1) ignoring the fixed graph that limits the predictive performance of the model, (2) insufficiently capturing complex spatial-temporal dependencies simultaneously, and (3) lacking attention to spatial-temporal information at different time lengths. In this paper, we propose a Multi-Scale Spatial-Temporal Recurrent Network for traffic flow prediction, namely MSSTRN, which consists of two different recurrent neural networks: the single-step gate recurrent unit and the multi-step gate recurrent unit to fully capture the complex spatial-temporal information in the traffic data under different time windows. Moreover, we propose a spatial-temporal synchronous attention mechanism that integrates adaptive position graph convolutions into the self-attention mechanism to achieve synchronous capture of spatial-temporal dependencies. We conducted extensive experiments on four real traffic datasets and demonstrated that our model achieves the best prediction accuracy with non-trivial margins compared to all the twenty baseline methods.", "url": "https://arxiv.org/abs/2310.08138"}, {"metadata": {"arXiv": "2310.08198", "Date": "Thu, 12 Oct 2023 10:44:47 ", "Title": "Beyond Traditional DoE: Deep Reinforcement Learning for Optimizing Experiments in Model Identification of Battery Dynamics", "Authors": ["Gokhan Budan", "Francesca Damiani", "Can Kurtulus", "N. Kemal Ure"], "Categories": "cs.LG cs.AI"}, "abstract": "Model identification of battery dynamics is a central problem in energy research; many energy management systems and design processes rely on accurate battery models for efficiency optimization. The standard methodology for battery modelling is traditional design of experiments (DoE), where the battery dynamics are excited with many different current profiles and the measured outputs are used to estimate the system dynamics. However, although it is possible to obtain useful models with the traditional approach, the process is time consuming and expensive because of the need to sweep many different current-profile configurations. In the present work, a novel DoE approach is developed based on deep reinforcement learning, which alters the configuration of the experiments on the fly based on the statistics of past experiments. Instead of sticking to a library of predefined current profiles, the proposed approach modifies the current profiles dynamically by updating the output space covered by past measurements, hence only the current profiles that are informative for future experiments are applied. Simulations and real experiments are used to show that the proposed approach gives models that are as accurate as those obtained with traditional DoE but by using 85\\% less resources.", "url": "https://arxiv.org/abs/2310.08198"}, {"metadata": {"arXiv": "2310.08215", "Date": "Thu, 12 Oct 2023 11:04:17 ", "Title": "Trustworthy Machine Learning", "Authors": ["B\\'alint Mucs\\'anyi and Michael Kirchhof and Elisa Nguyen and Alexander Rubinstein and Seong Joon Oh"], "Categories": "cs.LG cs.AI", "Comments": ["373 pages", "textbook at the University of T\\\"ubingen"], "ACM-class": "I.2.0"}, "abstract": "As machine learning technology gets applied to actual products and solutions, new challenges have emerged. Models unexpectedly fail to generalize to small changes in the distribution, tend to be confident on novel data they have never seen, or cannot communicate the rationale behind their decisions effectively with the end users. Collectively, we face a trustworthiness issue with the current machine learning technology. This textbook on Trustworthy Machine Learning (TML) covers a theoretical and technical background of four key topics in TML: Out-of-Distribution Generalization, Explainability, Uncertainty Quantification, and Evaluation of Trustworthiness. We discuss important classical and contemporary research papers of the aforementioned fields and uncover and connect their underlying intuitions. The book evolved from the homonymous course at the University of T\\\"ubingen, first offered in the Winter Semester of 2022/23. It is meant to be a stand-alone product accompanied by code snippets and various pointers to further sources on topics of TML. The dedicated website of the book is https://trustworthyml.io/.", "url": "https://arxiv.org/abs/2310.08215"}, {"metadata": {"arXiv": "2310.08252", "Date": "Thu, 12 Oct 2023 11:55:17 ", "Title": "MetaBox: A Benchmark Platform for Meta-Black-Box Optimization with Reinforcement Learning", "Authors": ["Zeyuan Ma", "Hongshu Guo", "Jiacheng Chen", "Zhenrui Li", "Guojun Peng", "Yue-Jiao Gong", "Yining Ma", "Zhiguang Cao"], "Categories": "cs.LG cs.AI cs.NE", "Comments": ["Accepted at NuerIPS 2023"]}, "abstract": "Recently, Meta-Black-Box Optimization with Reinforcement Learning (MetaBBO-RL) has showcased the power of leveraging RL at the meta-level to mitigate manual fine-tuning of low-level black-box optimizers. However, this field is hindered by the lack of a unified benchmark. To fill this gap, we introduce MetaBox, the first benchmark platform expressly tailored for developing and evaluating MetaBBO-RL methods. MetaBox offers a flexible algorithmic template that allows users to effortlessly implement their unique designs within the platform. Moreover, it provides a broad spectrum of over 300 problem instances, collected from synthetic to realistic scenarios, and an extensive library of 19 baseline methods, including both traditional black-box optimizers and recent MetaBBO-RL methods. Besides, MetaBox introduces three standardized performance metrics, enabling a more thorough assessment of the methods. In a bid to illustrate the utility of MetaBox for facilitating rigorous evaluation and in-depth analysis, we carry out a wide-ranging benchmarking study on existing MetaBBO-RL methods. Our MetaBox is open-source and accessible at: https://github.com/GMC-DRL/MetaBox.", "url": "https://arxiv.org/abs/2310.08252"}, {"metadata": {"arXiv": "2310.08278", "Date": "Thu, 12 Oct 2023 12:29:32 ", "Title": "Lag-Llama: Towards Foundation Models for Time Series Forecasting", "Authors": ["Kashif Rasul", "Arjun Ashok", "Andrew Robert Williams", "Arian Khorasani", "George Adamopoulos", "Rishika Bhagwatkar", "Marin Bilo\\v{s}", "Hena Ghonia", "Nadhir Vincent Hassen", "Anderson Schneider", "Sahil Garg", "Alexandre Drouin", "Nicolas Chapados", "Yuriy Nevmyvaka", "Irina Rish"], "Categories": "cs.LG cs.AI"}, "abstract": "Aiming to build foundation models for time-series forecasting and study their scaling behavior, we present here our work-in-progress on Lag-Llama, a general-purpose univariate probabilistic time-series forecasting model trained on a large collection of time-series data. The model shows good zero-shot prediction capabilities on unseen \"out-of-distribution\" time-series datasets, outperforming supervised baselines. We use smoothly broken power-laws to fit and predict model scaling behavior. The open source code is made available at https://github.com/kashif/pytorch-transformer-ts.", "url": "https://arxiv.org/abs/2310.08278"}, {"metadata": {"arXiv": "2310.08419", "Date": "Thu, 12 Oct 2023 15:38:28 ", "Title": "Jailbreaking Black Box Large Language Models in Twenty Queries", "Authors": ["Patrick Chao", "Alexander Robey", "Edgar Dobriban", "Hamed Hassani", "George J. Pappas", "Eric Wong"], "Categories": "cs.LG cs.AI", "Comments": ["21 pages", "10 figures"]}, "abstract": "There is growing interest in ensuring that large language models (LLMs) align with human values. However, the alignment of such models is vulnerable to adversarial jailbreaks, which coax LLMs into overriding their safety guardrails. The identification of these vulnerabilities is therefore instrumental in understanding inherent weaknesses and preventing future misuse. To this end, we propose Prompt Automatic Iterative Refinement (PAIR), an algorithm that generates semantic jailbreaks with only black-box access to an LLM. PAIR -- which is inspired by social engineering attacks -- uses an attacker LLM to automatically generate jailbreaks for a separate targeted LLM without human intervention. In this way, the attacker LLM iteratively queries the target LLM to update and refine a candidate jailbreak. Empirically, PAIR often requires fewer than twenty queries to produce a jailbreak, which is orders of magnitude more efficient than existing algorithms. PAIR also achieves competitive jailbreaking success rates and transferability on open and closed-source LLMs, including GPT-3.5/4, Vicuna, and PaLM-2.", "url": "https://arxiv.org/abs/2310.08419"}, {"metadata": {"arXiv": "2310.08446", "Date": "Thu, 12 Oct 2023 16:06:18 ", "Title": "Towards Robust Multi-Modal Reasoning via Model Selection", "Authors": ["Xiangyan Liu", "Rongxue Li", "Wei Ji", "Tao Lin"], "Categories": "cs.LG cs.AI", "Comments": ["10 pages", "5 figures"]}, "abstract": "The reasoning capabilities of LLM (Large Language Model) are widely acknowledged in recent research, inspiring studies on tool learning and autonomous agents. LLM serves as the \"brain\" of agent, orchestrating multiple tools for collaborative multi-step task solving. Unlike methods invoking tools like calculators or weather APIs for straightforward tasks, multi-modal agents excel by integrating diverse AI models for complex challenges. However, current multi-modal agents neglect the significance of model selection: they primarily focus on the planning and execution phases, and will only invoke predefined task-specific models for each subtask, making the execution fragile. Meanwhile, other traditional model selection methods are either incompatible with or suboptimal for the multi-modal agent scenarios, due to ignorance of dependencies among subtasks arising by multi-step reasoning. To this end, we identify the key challenges therein and propose the $\\textit{M}^3$ framework as a plug-in with negligible runtime overhead at test-time. This framework improves model selection and bolsters the robustness of multi-modal agents in multi-step reasoning. In the absence of suitable benchmarks, we create MS-GQA, a new dataset specifically designed to investigate the model selection challenge in multi-modal agents. Our experiments reveal that our framework enables dynamic model selection, considering both user inputs and subtask dependencies, thereby robustifying the overall reasoning process. Our code and benchmark: https://github.com/LINs-lab/M3.", "url": "https://arxiv.org/abs/2310.08446"}, {"metadata": {"arXiv": "2310.08459", "Date": "Thu, 12 Oct 2023 16:19:58 ", "Title": "A Survey on Heterogeneous Transfer Learning", "Authors": ["Runxue Bao", "Yiming Sun", "Yuhe Gao", "Jindong Wang", "Qiang Yang", "Haifeng Chen", "Zhi-Hong Mao", "Xing Xie", "Ye Ye"], "Categories": "cs.LG cs.AI"}, "abstract": "The application of transfer learning, an approach utilizing knowledge from a source domain to enhance model performance in a target domain, has seen a tremendous rise in recent years, underpinning many real-world scenarios. The key to its success lies in the shared common knowledge between the domains, a prerequisite in most transfer learning methodologies. These methods typically presuppose identical feature spaces and label spaces in both domains, known as homogeneous transfer learning, which, however, is not always a practical assumption. Oftentimes, the source and target domains vary in feature spaces, data distributions, and label spaces, making it challenging or costly to secure source domain data with identical feature and label spaces as the target domain. Arbitrary elimination of these differences is not always feasible or optimal. Thus, heterogeneous transfer learning, acknowledging and dealing with such disparities, has emerged as a promising approach for a variety of tasks. Despite the existence of a survey in 2017 on this topic, the fast-paced advances post-2017 necessitate an updated, in-depth review. We therefore present a comprehensive survey of recent developments in heterogeneous transfer learning methods, offering a systematic guide for future research. Our paper reviews methodologies for diverse learning scenarios, discusses the limitations of current studies, and covers various application contexts, including Natural Language Processing, Computer Vision, Multimodality, and Biomedicine, to foster a deeper understanding and spur future research.", "url": "https://arxiv.org/abs/2310.08459"}, {"metadata": {"arXiv": "2310.08549", "Date": "Thu, 12 Oct 2023 17:45:05 ", "Title": "Cross-Episodic Curriculum for Transformer Agents", "Authors": ["Lucy Xiaoyang Shi and Yunfan Jiang and Jake Grigsby and Linxi \"Jim\" Fan and Yuke Zhu"], "Categories": "cs.LG cs.AI cs.RO", "Comments": ["To appear in NeurIPS 2023; The first two authors contributed equally"]}, "abstract": "We present a new algorithm, Cross-Episodic Curriculum (CEC), to boost the learning efficiency and generalization of Transformer agents. Central to CEC is the placement of cross-episodic experiences into a Transformer's context, which forms the basis of a curriculum. By sequentially structuring online learning trials and mixed-quality demonstrations, CEC constructs curricula that encapsulate learning progression and proficiency increase across episodes. Such synergy combined with the potent pattern recognition capabilities of Transformer models delivers a powerful cross-episodic attention mechanism. The effectiveness of CEC is demonstrated under two representative scenarios: one involving multi-task reinforcement learning with discrete control, such as in DeepMind Lab, where the curriculum captures the learning progression in both individual and progressively complex settings; and the other involving imitation learning with mixed-quality data for continuous control, as seen in RoboMimic, where the curriculum captures the improvement in demonstrators' expertise. In all instances, policies resulting from CEC exhibit superior performance and strong generalization. Code is open-sourced at https://cec-agent.github.io/ to facilitate research on Transformer agent learning.", "url": "https://arxiv.org/abs/2310.08549"}, {"metadata": {"arXiv": "2310.08558", "Date": "Thu, 12 Oct 2023 17:50:09 ", "Title": "Offline Retraining for Online RL: Decoupled Policy Learning to Mitigate Exploration Bias", "Authors": ["Max Sobol Mark", "Archit Sharma", "Fahim Tajwar", "Rafael Rafailov", "Sergey Levine", "Chelsea Finn"], "Categories": "cs.LG cs.AI cs.RO"}, "abstract": "It is desirable for policies to optimistically explore new states and behaviors during online reinforcement learning (RL) or fine-tuning, especially when prior offline data does not provide enough state coverage. However, exploration bonuses can bias the learned policy, and our experiments find that naive, yet standard use of such bonuses can fail to recover a performant policy. Concurrently, pessimistic training in offline RL has enabled recovery of performant policies from static datasets. Can we leverage offline RL to recover better policies from online interaction? We make a simple observation that a policy can be trained from scratch on all interaction data with pessimistic objectives, thereby decoupling the policies used for data collection and for evaluation. Specifically, we propose offline retraining, a policy extraction step at the end of online fine-tuning in our Offline-to-Online-to-Offline (OOO) framework for reinforcement learning (RL). An optimistic (exploration) policy is used to interact with the environment, and a separate pessimistic (exploitation) policy is trained on all the observed data for evaluation. Such decoupling can reduce any bias from online interaction (intrinsic rewards, primacy bias) in the evaluation policy, and can allow more exploratory behaviors during online interaction which in turn can generate better data for exploitation. OOO is complementary to several offline-to-online RL and online RL methods, and improves their average performance by 14% to 26% in our fine-tuning experiments, achieves state-of-the-art performance on several environments in the D4RL benchmarks, and improves online RL performance by 165% on two OpenAI gym environments. Further, OOO can enable fine-tuning from incomplete offline datasets where prior methods can fail to recover a performant policy. Implementation: https://github.com/MaxSobolMark/OOO", "url": "https://arxiv.org/abs/2310.08558"}, {"metadata": {"arXiv": "2310.08566", "Date": "Thu, 12 Oct 2023 17:55:02 ", "Title": "Transformers as Decision Makers: Provable In-Context Reinforcement Learning via Supervised Pretraining", "Authors": ["Licong Lin", "Yu Bai", "Song Mei"], "Categories": "cs.LG cs.AI cs.CL math.ST stat.ML stat.TH"}, "abstract": "Large transformer models pretrained on offline reinforcement learning datasets have demonstrated remarkable in-context reinforcement learning (ICRL) capabilities, where they can make good decisions when prompted with interaction trajectories from unseen environments. However, when and how transformers can be trained to perform ICRL have not been theoretically well-understood. In particular, it is unclear which reinforcement-learning algorithms transformers can perform in context, and how distribution mismatch in offline training data affects the learned algorithms. This paper provides a theoretical framework that analyzes supervised pretraining for ICRL. This includes two recently proposed training methods -- algorithm distillation and decision-pretrained transformers. First, assuming model realizability, we prove the supervised-pretrained transformer will imitate the conditional expectation of the expert algorithm given the observed trajectory. The generalization error will scale with model capacity and a distribution divergence factor between the expert and offline algorithms. Second, we show transformers with ReLU attention can efficiently approximate near-optimal online reinforcement learning algorithms like LinUCB and Thompson sampling for stochastic linear bandits, and UCB-VI for tabular Markov decision processes. This provides the first quantitative analysis of the ICRL capabilities of transformers pretrained from offline trajectories.", "url": "https://arxiv.org/abs/2310.08566"}, {"metadata": {"arXiv": "2310.07724", "Date": "Sun, 17 Sep 2023 13:32:03 ", "Title": "Visual Forecasting as a Mid-level Representation for Avoidance", "Authors": ["Hsuan-Kung Yang", "Tsung-Chih Chiang", "Ting-Ru Liu", "Chun-Wei Huang", "Jou-Min Liu", "Chun-Yi Lee"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["Tsung-Chih Chiang", "Ting-Ru Liu", "Chun-Wei Huang", "and Jou-Min Liu contributed equally to this work; This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice", "after which this version may no longer be accessible"]}, "abstract": "The challenge of navigation in environments with dynamic objects continues to be a central issue in the study of autonomous agents. While predictive methods hold promise, their reliance on precise state information makes them less practical for real-world implementation. This study presents visual forecasting as an innovative alternative. By introducing intuitive visual cues, this approach projects the future trajectories of dynamic objects to improve agent perception and enable anticipatory actions. Our research explores two distinct strategies for conveying predictive information through visual forecasting: (1) sequences of bounding boxes, and (2) augmented paths. To validate the proposed visual forecasting strategies, we initiate evaluations in simulated environments using the Unity engine and then extend these evaluations to real-world scenarios to assess both practicality and effectiveness. The results confirm the viability of visual forecasting as a promising solution for navigation and obstacle avoidance in dynamic environments.", "url": "https://arxiv.org/abs/2310.07724"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2311.04950", "Date": "Wed, 08 Nov 2023 12:56:59 ", "Title": "Lightweight Diffusion Models with Distillation-Based Block Neural Architecture Search", "Authors": ["Siao Tang", "Xin Wang", "Hong Chen", "Chaoyu Guan", "Yansong Tang", "Wenwu zhu"], "Categories": "cs.CV cs.LG"}, "abstract": "Diffusion models have recently shown remarkable generation ability, achieving state-of-the-art performance in many tasks. However, the high computational cost is still a troubling problem for diffusion models. To tackle this problem, we propose to automatically remove the structural redundancy in diffusion models with our proposed Diffusion Distillation-based Block-wise Neural Architecture Search (DiffNAS). Specifically, given a larger pretrained teacher, we leverage DiffNAS to search for the smallest architecture which achieves on-par or even better performance than the teacher. Considering current diffusion models are based on UNet which naturally has a block-wise structure, we perform neural architecture search independently in each block, which largely reduces the search space. Different from previous block-wise NAS methods, DiffNAS contains a block-wise local search strategy and a retraining strategy with a joint dynamic loss. Concretely, during the search process, we block-wisely select the best subnet to avoid the unfairness brought by the global search strategy used in previous works. When retraining the searched architecture, we adopt a dynamic joint loss to maintain the consistency between supernet training and subnet retraining, which also provides informative objectives for each block and shortens the paths of gradient propagation. We demonstrate this joint loss can effectively improve model performance. We also prove the necessity of the dynamic adjustment of this loss. The experiments show that our method can achieve significant computational reduction, especially on latent diffusion models with about 50% MACs and Parameter reduction.", "url": "https://arxiv.org/abs/2311.04950"}, {"metadata": {"arXiv": "2311.05006", "Date": "Wed, 08 Nov 2023 20:17:35 ", "Title": "Familiarity-Based Open-Set Recognition Under Adversarial Attacks", "Authors": ["Philip Enevoldsen", "Christian Gundersen", "Nico Lang", "Serge Belongie", "Christian Igel"], "Categories": "cs.CV cs.LG", "Comments": ["Published in: The 2nd Workshop and Challenges for Out-of-Distribution Generalization in Computer Vision", "ICCV 2023"]}, "abstract": "Open-set recognition (OSR), the identification of novel categories, can be a critical component when deploying classification models in real-world applications. Recent work has shown that familiarity-based scoring rules such as the Maximum Softmax Probability (MSP) or the Maximum Logit Score (MLS) are strong baselines when the closed-set accuracy is high. However, one of the potential weaknesses of familiarity-based OSR are adversarial attacks. Here, we present gradient-based adversarial attacks on familiarity scores for both types of attacks, False Familiarity and False Novelty attacks, and evaluate their effectiveness in informed and uninformed settings on TinyImageNet.", "url": "https://arxiv.org/abs/2311.05006"}, {"metadata": {"arXiv": "2311.05041", "Date": "Wed, 08 Nov 2023 21:56:29 ", "Title": "Active Transfer Learning for Efficient Video-Specific Human Pose Estimation", "Authors": ["Hiromu Taketsugu and Norimichi Ukita"], "Categories": "cs.CV cs.LG", "Comments": ["17 pages", "12 figures", "Accepted by WACV 2024"], "ACM-class": "I.2.10; I.4.8"}, "abstract": "Human Pose (HP) estimation is actively researched because of its wide range of applications. However, even estimators pre-trained on large datasets may not perform satisfactorily due to a domain gap between the training and test data. To address this issue, we present our approach combining Active Learning (AL) and Transfer Learning (TL) to adapt HP estimators to individual video domains efficiently. For efficient learning, our approach quantifies (i) the estimation uncertainty based on the temporal changes in the estimated heatmaps and (ii) the unnaturalness in the estimated full-body HPs. These quantified criteria are then effectively combined with the state-of-the-art representativeness criterion to select uncertain and diverse samples for efficient HP estimator learning. Furthermore, we reconsider the existing Active Transfer Learning (ATL) method to introduce novel ideas related to the retraining methods and Stopping Criteria (SC). Experimental results demonstrate that our method enhances learning efficiency and outperforms comparative methods. Our code is publicly available at: https://github.com/ImIntheMiddle/VATL4Pose-WACV2024", "url": "https://arxiv.org/abs/2311.05041"}, {"metadata": {"arXiv": "2311.05109", "Date": "Thu, 09 Nov 2023 02:53:21 ", "Title": "Reducing the Side-Effects of Oscillations in Training of Quantized YOLO Networks", "Authors": ["Kartik Gupta", "Akshay Asthana"], "Categories": "cs.CV cs.LG", "Comments": ["WACV 2024"]}, "abstract": "Quantized networks use less computational and memory resources and are suitable for deployment on edge devices. While quantization-aware training QAT is the well-studied approach to quantize the networks at low precision, most research focuses on over-parameterized networks for classification with limited studies on popular and edge device friendly single-shot object detection and semantic segmentation methods like YOLO. Moreover, majority of QAT methods rely on Straight-through Estimator (STE) approximation which suffers from an oscillation phenomenon resulting in sub-optimal network quantization. In this paper, we show that it is difficult to achieve extremely low precision (4-bit and lower) for efficient YOLO models even with SOTA QAT methods due to oscillation issue and existing methods to overcome this problem are not effective on these models. To mitigate the effect of oscillation, we first propose Exponentially Moving Average (EMA) based update to the QAT model. Further, we propose a simple QAT correction method, namely QC, that takes only a single epoch of training after standard QAT procedure to correct the error induced by oscillating weights and activations resulting in a more accurate quantized model. With extensive evaluation on COCO dataset using various YOLO5 and YOLO7 variants, we show that our correction method improves quantized YOLO networks consistently on both object detection and segmentation tasks at low-precision (4-bit and 3-bit).", "url": "https://arxiv.org/abs/2311.05109"}, {"metadata": {"arXiv": "2311.05323", "Date": "Thu, 09 Nov 2023 12:43:01 ", "Title": "Spatial Attention-based Distribution Integration Network for Human Pose Estimation", "Authors": ["Sihan Gao", "Jing Zhu", "Xiaoxuan Zhuang", "Zhaoyue Wang", "and Qijin Li"], "Categories": "cs.CV cs.LG"}, "abstract": "In recent years, human pose estimation has made significant progress through the implementation of deep learning techniques. However, these techniques still face limitations when confronted with challenging scenarios, including occlusion, diverse appearances, variations in illumination, and overlap. To cope with such drawbacks, we present the Spatial Attention-based Distribution Integration Network (SADI-NET) to improve the accuracy of localization in such situations. Our network consists of three efficient models: the receptive fortified module (RFM), spatial fusion module (SFM), and distribution learning module (DLM). Building upon the classic HourglassNet architecture, we replace the basic block with our proposed RFM. The RFM incorporates a dilated residual block and attention mechanism to expand receptive fields while enhancing sensitivity to spatial information. In addition, the SFM incorporates multi-scale characteristics by employing both global and local attention mechanisms. Furthermore, the DLM, inspired by residual log-likelihood estimation (RLE), reconfigures a predicted heatmap using a trainable distribution weight. For the purpose of determining the efficacy of our model, we conducted extensive experiments on the MPII and LSP benchmarks. Particularly, our model obtained a remarkable $92.10\\%$ percent accuracy on the MPII test dataset, demonstrating significant improvements over existing models and establishing state-of-the-art performance.", "url": "https://arxiv.org/abs/2311.05323"}, {"metadata": {"arXiv": "2311.05400", "Date": "Thu, 09 Nov 2023 14:32:57 ", "Title": "SIRE: scale-invariant, rotation-equivariant estimation of artery orientations using graph neural networks", "Authors": ["Dieuwertje Alblas", "Julian Suk", "Christoph Brune", "Kak Khee Yeung", "Jelmer M. Wolterink"], "Categories": "cs.CV cs.LG", "Comments": ["Submitted to Medical Image Analysis"]}, "abstract": "Blood vessel orientation as visualized in 3D medical images is an important descriptor of its geometry that can be used for centerline extraction and subsequent segmentation and visualization. Arteries appear at many scales and levels of tortuosity, and determining their exact orientation is challenging. Recent works have used 3D convolutional neural networks (CNNs) for this purpose, but CNNs are sensitive to varying vessel sizes and orientations. We present SIRE: a scale-invariant, rotation-equivariant estimator for local vessel orientation. SIRE is modular and can generalise due to symmetry preservation. SIRE consists of a gauge equivariant mesh CNN (GEM-CNN) operating on multiple nested spherical meshes with different sizes in parallel. The features on each mesh are a projection of image intensities within the corresponding sphere. These features are intrinsic to the sphere and, in combination with the GEM-CNN, lead to SO(3)-equivariance. Approximate scale invariance is achieved by weight sharing and use of a symmetric maximum function to combine multi-scale predictions. Hence, SIRE can be trained with arbitrarily oriented vessels with varying radii to generalise to vessels with a wide range of calibres and tortuosity. We demonstrate the efficacy of SIRE using three datasets containing vessels of varying scales: the vascular model repository (VMR), the ASOCA coronary artery set, and a set of abdominal aortic aneurysms (AAAs). We embed SIRE in a centerline tracker which accurately tracks AAAs, regardless of the data SIRE is trained with. Moreover, SIRE can be used to track coronary arteries, even when trained only with AAAs. In conclusion, by incorporating SO(3) and scale symmetries, SIRE can determine the orientations of vessels outside of the training domain, forming a robust and data-efficient solution to geometric analysis of blood vessels in 3D medical images.", "url": "https://arxiv.org/abs/2311.05400"}, {"metadata": {"arXiv": "2311.05539", "Date": "Thu, 09 Nov 2023 17:34:57 ", "Title": "A Deep Learning Method for Simultaneous Denoising and Missing Wedge Reconstruction in Cryogenic Electron Tomography", "Authors": ["Simon Wiedemann and Reinhard Heckel"], "Categories": "cs.CV cs.LG"}, "abstract": "Cryogenic electron tomography (cryo-ET) is a technique for imaging biological samples such as viruses, cells, and proteins in 3D. A microscope collects a series of 2D projections of the sample, and the goal is to reconstruct the 3D density of the sample called the tomogram. This is difficult as the 2D projections have a missing wedge of information and are noisy. Tomograms reconstructed with conventional methods, such as filtered back-projection, suffer from the noise, and from artifacts and anisotropic resolution due to the missing wedge of information. To improve the visual quality and resolution of such tomograms, we propose a deep-learning approach for simultaneous denoising and missing wedge reconstruction called DeepDeWedge. DeepDeWedge is based on fitting a neural network to the 2D projections with a self-supervised loss inspired by noise2noise-like methods. The algorithm requires no training or ground truth data. Experiments on synthetic and real cryo-ET data show that DeepDeWedge achieves competitive performance for deep learning-based denoising and missing wedge reconstruction of cryo-ET tomograms.", "url": "https://arxiv.org/abs/2311.05539"}, {"metadata": {"arXiv": "2311.05556", "Date": "Thu, 09 Nov 2023 18:04:15 ", "Title": "LCM-LoRA: A Universal Stable-Diffusion Acceleration Module", "Authors": ["Simian Luo", "Yiqin Tan", "Suraj Patil", "Daniel Gu", "Patrick von Platen", "Apolin\\'ario Passos", "Longbo Huang", "Jian Li", "Hang Zhao"], "Categories": "cs.CV cs.LG", "Comments": ["Technical Report"]}, "abstract": "Latent Consistency Models (LCMs) have achieved impressive performance in accelerating text-to-image generative tasks, producing high-quality images with minimal inference steps. LCMs are distilled from pre-trained latent diffusion models (LDMs), requiring only ~32 A100 GPU training hours. This report further extends LCMs' potential in two aspects: First, by applying LoRA distillation to Stable-Diffusion models including SD-V1.5, SSD-1B, and SDXL, we have expanded LCM's scope to larger models with significantly less memory consumption, achieving superior image generation quality. Second, we identify the LoRA parameters obtained through LCM distillation as a universal Stable-Diffusion acceleration module, named LCM-LoRA. LCM-LoRA can be directly plugged into various Stable-Diffusion fine-tuned models or LoRAs without training, thus representing a universally applicable accelerator for diverse image generation tasks. Compared with previous numerical PF-ODE solvers such as DDIM, DPM-Solver, LCM-LoRA can be viewed as a plug-in neural PF-ODE solver that possesses strong generalization abilities. Project page: https://github.com/luosiallen/latent-consistency-model.", "url": "https://arxiv.org/abs/2311.05556"}, {"metadata": {"arXiv": "2311.05565", "Date": "Thu, 09 Nov 2023 18:20:52 ", "Title": "High-Performance Transformers for Table Structure Recognition Need Early Convolutions", "Authors": ["ShengYun Peng", "Seongmin Lee", "Xiaojing Wang", "Rajarajeswari Balasubramaniyan", "Duen Horng Chau"], "Categories": "cs.CV cs.LG", "Comments": ["Table Representation Learning Workshop at NeurIPS 2023 (Oral)"]}, "abstract": "Table structure recognition (TSR) aims to convert tabular images into a machine-readable format, where a visual encoder extracts image features and a textual decoder generates table-representing tokens. Existing approaches use classic convolutional neural network (CNN) backbones for the visual encoder and transformers for the textual decoder. However, this hybrid CNN-Transformer architecture introduces a complex visual encoder that accounts for nearly half of the total model parameters, markedly reduces both training and inference speed, and hinders the potential for self-supervised learning in TSR. In this work, we design a lightweight visual encoder for TSR without sacrificing expressive power. We discover that a convolutional stem can match classic CNN backbone performance, with a much simpler model. The convolutional stem strikes an optimal balance between two crucial factors for high-performance TSR: a higher receptive field (RF) ratio and a longer sequence length. This allows it to \"see\" an appropriate portion of the table and \"store\" the complex table structure within sufficient context length for the subsequent transformer. We conducted reproducible ablation studies and open-sourced our code at https://github.com/poloclub/tsr-convstem to enhance transparency, inspire innovations, and facilitate fair comparisons in our domain as tables are a promising modality for representation learning.", "url": "https://arxiv.org/abs/2311.05565"}, {"metadata": {"arXiv": "2311.05567", "Date": "Thu, 09 Nov 2023 18:22:32 ", "Title": "Exploring Emotion Expression Recognition in Older Adults Interacting with a Virtual Coach", "Authors": ["Cristina Palmero", "Mikel deVelasco", "Mohamed Amine Hmani", "Aymen Mtibaa", "Leila Ben Letaifa", "Pau Buch-Cardona", "Raquel Justo", "Terry Amorese", "Eduardo Gonz\\'alez-Fraile", "Bego\\~na Fern\\'andez-Ruanova", "Jofre Tenorio-Laranga", "Anna Torp Johansen", "Micaela Rodrigues da Silva", "Liva Jenny Martinussen", "Maria Stylianou Korsnes", "Gennaro Cordasco", "Anna Esposito", "Mounim A. El-Yacoubi", "Dijana Petrovska-Delacr\\'etaz", "M. In\\'es Torres and Sergio Escalera"], "Categories": "cs.CV cs.HC cs.LG", "Comments": ["This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice", "after which this version may no longer be accessible"]}, "abstract": "The EMPATHIC project aimed to design an emotionally expressive virtual coach capable of engaging healthy seniors to improve well-being and promote independent aging. One of the core aspects of the system is its human sensing capabilities, allowing for the perception of emotional states to provide a personalized experience. This paper outlines the development of the emotion expression recognition module of the virtual coach, encompassing data collection, annotation design, and a first methodological approach, all tailored to the project requirements. With the latter, we investigate the role of various modalities, individually and combined, for discrete emotion expression recognition in this context: speech from audio, and facial expressions, gaze, and head dynamics from video. The collected corpus includes users from Spain, France, and Norway, and was annotated separately for the audio and video channels with distinct emotional labels, allowing for a performance comparison across cultures and label types. Results confirm the informative power of the modalities studied for the emotional categories considered, with multimodal methods generally outperforming others (around 68% accuracy with audio labels and 72-74% with video labels). The findings are expected to contribute to the limited literature on emotion recognition applied to older adults in conversational human-machine interaction.", "url": "https://arxiv.org/abs/2311.05567"}, {"metadata": {"arXiv": "2311.05579", "Date": "Thu, 09 Nov 2023 18:38:46 ", "Title": "SigScatNet: A Siamese + Scattering based Deep Learning Approach for Signature Forgery Detection and Similarity Assessment", "Authors": ["Anmol Chokshi", "Vansh Jain", "Rajas Bhope", "Sudhir Dhage"], "Categories": "cs.CV cs.LG eess.SP", "Comments": ["7 pages", "8 figures"]}, "abstract": "The surge in counterfeit signatures has inflicted widespread inconveniences and formidable challenges for both individuals and organizations. This groundbreaking research paper introduces SigScatNet, an innovative solution to combat this issue by harnessing the potential of a Siamese deep learning network, bolstered by Scattering wavelets, to detect signature forgery and assess signature similarity. The Siamese Network empowers us to ascertain the authenticity of signatures through a comprehensive similarity index, enabling precise validation and comparison. Remarkably, the integration of Scattering wavelets endows our model with exceptional efficiency, rendering it light enough to operate seamlessly on cost-effective hardware systems. To validate the efficacy of our approach, extensive experimentation was conducted on two open-sourced datasets: the ICDAR SigComp Dutch dataset and the CEDAR dataset. The experimental results demonstrate the practicality and resounding success of our proposed SigScatNet, yielding an unparalleled Equal Error Rate of 3.689% with the ICDAR SigComp Dutch dataset and an astonishing 0.0578% with the CEDAR dataset. Through the implementation of SigScatNet, our research spearheads a new state-of-the-art in signature analysis in terms of EER scores and computational efficiency, offering an advanced and accessible solution for detecting forgery and quantifying signature similarities. By employing cutting-edge Siamese deep learning and Scattering wavelets, we provide a robust framework that paves the way for secure and efficient signature verification systems.", "url": "https://arxiv.org/abs/2311.05579"}, {"metadata": {"arXiv": "2311.04991", "Date": "Wed, 08 Nov 2023 19:21:48 ", "Title": "Effective Restoration of Source Knowledge in Continual Test Time Adaptation", "Authors": ["Fahim Faisal Niloy", "Sk Miraj Ahmed", "Dripta S. Raychaudhuri", "Samet Oymak and Amit K. Roy-Chowdhury"], "Categories": "cs.LG cs.CV", "Comments": ["WACV 2024"]}, "abstract": "Traditional test-time adaptation (TTA) methods face significant challenges in adapting to dynamic environments characterized by continuously changing long-term target distributions. These challenges primarily stem from two factors: catastrophic forgetting of previously learned valuable source knowledge and gradual error accumulation caused by miscalibrated pseudo labels. To address these issues, this paper introduces an unsupervised domain change detection method that is capable of identifying domain shifts in dynamic environments and subsequently resets the model parameters to the original source pre-trained values. By restoring the knowledge from the source, it effectively corrects the negative consequences arising from the gradual deterioration of model parameters caused by ongoing shifts in the domain. Our method involves progressive estimation of global batch-norm statistics specific to each domain, while keeping track of changes in the statistics triggered by domain shifts. Importantly, our method is agnostic to the specific adaptation technique employed and thus, can be incorporated to existing TTA methods to enhance their performance in dynamic environments. We perform extensive experiments on benchmark datasets to demonstrate the superior performance of our method compared to state-of-the-art adaptation methods.", "url": "https://arxiv.org/abs/2311.04991"}, {"metadata": {"arXiv": "2311.05050", "Date": "Wed, 08 Nov 2023 22:56:37 ", "Title": "Quantum Generative Modeling of Sequential Data with Trainable Token Embedding", "Authors": ["Wanda Hou", "Li Miao", "Yi-Zhuang You"], "Categories": "cs.LG quant-ph", "Comments": ["5 pages", "4 figures"]}, "abstract": "Generative models are a class of machine learning models that aim to learn the underlying probability distribution of data. Unlike discriminative models, generative models focus on capturing the data's inherent structure, allowing them to generate new samples that resemble the original data. To fully exploit the potential of modeling probability distributions using quantum physics, a quantum-inspired generative model known as the Born machines have shown great advancements in learning classical and quantum data over matrix product state(MPS) framework. The Born machines support tractable log-likelihood, autoregressive and mask sampling, and have shown outstanding performance in various unsupervised learning tasks. However, much of the current research has been centered on improving the expressive power of MPS, predominantly embedding each token directly by a corresponding tensor index. In this study, we generalize the embedding method into trainable quantum measurement operators that can be simultaneously honed with MPS. Our study indicated that combined with trainable embedding, Born machines can exhibit better performance and learn deeper correlations from the dataset.", "url": "https://arxiv.org/abs/2311.05050"}, {"metadata": {"arXiv": "2311.05061", "Date": "Wed, 08 Nov 2023 23:57:03 ", "Title": "Efficient Compression of Overparameterized Deep Models through Low-Dimensional Learning Dynamics", "Authors": ["Soo Min Kwon", "Zekai Zhang", "Dogyoon Song", "Laura Balzano", "Qing Qu"], "Categories": "cs.LG stat.ML"}, "abstract": "Overparameterized models have proven to be powerful tools for solving various machine learning tasks. However, overparameterization often leads to a substantial increase in computational and memory costs, which in turn requires extensive resources to train. In this work, we aim to reduce this complexity by studying the learning dynamics of overparameterized deep networks. By extensively studying its learning dynamics, we unveil that the weight matrices of various architectures exhibit a low-dimensional structure. This finding implies that we can compress the networks by reducing the training to a small subspace. We take a step in developing a principled approach for compressing deep networks by studying deep linear models. We demonstrate that the principal components of deep linear models are fitted incrementally but within a small subspace, and use these insights to compress deep linear networks by decreasing the width of its intermediate layers. Remarkably, we observe that with a particular choice of initialization, the compressed network converges faster than the original network, consistently yielding smaller recovery errors throughout all iterations of gradient descent. We substantiate this observation by developing a theory focused on the deep matrix factorization problem, and by conducting empirical evaluations on deep matrix sensing. Finally, we demonstrate how our compressed model can enhance the utility of deep nonlinear models. Overall, we observe that our compression technique accelerates the training process by more than 2x, without compromising model quality.", "url": "https://arxiv.org/abs/2311.05061"}, {"metadata": {"arXiv": "2311.05071", "Date": "Thu, 09 Nov 2023 00:09:18 ", "Title": "On the Behavior of Audio-Visual Fusion Architectures in Identity Verification Tasks", "Authors": ["Daniel Claborne", "Eric Slyman", "Karl Pazdernik"], "Categories": "cs.LG cs.CV cs.SD eess.AS", "ACM-class": "I.4.0; I.2.10; I.5.0"}, "abstract": "We train an identity verification architecture and evaluate modifications to the part of the model that combines audio and visual representations, including in scenarios where one input is missing in either of two examples to be compared. We report results on the Voxceleb1-E test set that suggest averaging the output embeddings improves error rate in the full-modality setting and when a single modality is missing, and makes more complete use of the embedding space than systems which use shared layers and discuss possible reasons for this behavior.", "url": "https://arxiv.org/abs/2311.05071"}, {"metadata": {"arXiv": "2311.05079", "Date": "Thu, 09 Nov 2023 00:35:05 ", "Title": "Social Media Bot Detection using Dropout-GAN", "Authors": ["Anant Shukla and Martin Jurecek and Mark Stamp"], "Categories": "cs.LG cs.SI"}, "abstract": "Bot activity on social media platforms is a pervasive problem, undermining the credibility of online discourse and potentially leading to cybercrime. We propose an approach to bot detection using Generative Adversarial Networks (GAN). We discuss how we overcome the issue of mode collapse by utilizing multiple discriminators to train against one generator, while decoupling the discriminator to perform social media bot detection and utilizing the generator for data augmentation. In terms of classification accuracy, our approach outperforms the state-of-the-art techniques in this field. We also show how the generator in the GAN can be used to evade such a classification technique.", "url": "https://arxiv.org/abs/2311.05079"}, {"metadata": {"arXiv": "2311.05081", "Date": "Thu, 09 Nov 2023 00:46:31 ", "Title": "Generalized test utilities for long-tail performance in extreme multi-label classification", "Authors": ["Erik Schultheis", "Marek Wydmuch", "Wojciech Kot{\\l}owski", "Rohit Babbar", "Krzysztof Dembczy\\'nski"], "Categories": "cs.LG", "Comments": ["This is the authors' version of the work accepted to NeurIPS 2023"]}, "abstract": "Extreme multi-label classification (XMLC) is the task of selecting a small subset of relevant labels from a very large set of possible labels. As such, it is characterized by long-tail labels, i.e., most labels have very few positive instances. With standard performance measures such as precision@k, a classifier can ignore tail labels and still report good performance. However, it is often argued that correct predictions in the tail are more interesting or rewarding, but the community has not yet settled on a metric capturing this intuitive concept. The existing propensity-scored metrics fall short on this goal by confounding the problems of long-tail and missing labels. In this paper, we analyze generalized metrics budgeted \"at k\" as an alternative solution. To tackle the challenging problem of optimizing these metrics, we formulate it in the expected test utility (ETU) framework, which aims at optimizing the expected performance on a fixed test set. We derive optimal prediction rules and construct computationally efficient approximations with provable regret guarantees and robustness against model misspecification. Our algorithm, based on block coordinate ascent, scales effortlessly to XMLC problems and obtains promising results in terms of long-tail performance.", "url": "https://arxiv.org/abs/2311.05081"}, {"metadata": {"arXiv": "2311.05092", "Date": "Thu, 09 Nov 2023 01:50:47 ", "Title": "GeoFormer: Predicting Human Mobility using Generative Pre-trained Transformer (GPT)", "Authors": ["Aivin V. Solatorio"], "Categories": "cs.LG cs.CY", "Comments": ["Accepted in the HuMob-Challenge '23: 1st International Workshop on the Human Mobility Prediction Challenge. Repository is available at https://github.com/avsolatorio/GeoFormer"], "ACM-class": "I.2.7; I.2.4; I.2.0; I.6.3; I.6.4; I.6.5", "DOI": "10.1145/3615894.3628499"}, "abstract": "Predicting human mobility holds significant practical value, with applications ranging from enhancing disaster risk planning to simulating epidemic spread. In this paper, we present the GeoFormer, a decoder-only transformer model adapted from the GPT architecture to forecast human mobility. Our proposed model is rigorously tested in the context of the HuMob Challenge 2023 -- a competition designed to evaluate the performance of prediction models on standardized datasets to predict human mobility. The challenge leverages two datasets encompassing urban-scale data of 25,000 and 100,000 individuals over a longitudinal period of 75 days. GeoFormer stands out as a top performer in the competition, securing a place in the top-3 ranking. Its success is underscored by performing well on both performance metrics chosen for the competition -- the GEO-BLEU and the Dynamic Time Warping (DTW) measures. The performance of the GeoFormer on the HuMob Challenge 2023 underscores its potential to make substantial contributions to the field of human mobility prediction, with far-reaching implications for disaster preparedness, epidemic control, and beyond.", "url": "https://arxiv.org/abs/2311.05092"}, {"metadata": {"arXiv": "2311.05108", "Date": "Thu, 09 Nov 2023 02:51:37 ", "Title": "Personalized Online Federated Learning with Multiple Kernels", "Authors": ["Pouya M. Ghari", "Yanning Shen"], "Categories": "cs.LG", "Comments": ["Published at NeurIPS 2022"], "Journal-ref": "in Advances in Neural Information Processing Systems, volume 35, pages 33316--33329, 2022"}, "abstract": "Multi-kernel learning (MKL) exhibits well-documented performance in online non-linear function approximation. Federated learning enables a group of learners (called clients) to train an MKL model on the data distributed among clients to perform online non-linear function approximation. There are some challenges in online federated MKL that need to be addressed: i) Communication efficiency especially when a large number of kernels are considered ii) Heterogeneous data distribution among clients. The present paper develops an algorithmic framework to enable clients to communicate with the server to send their updates with affordable communication cost while clients employ a large dictionary of kernels. Utilizing random feature (RF) approximation, the present paper proposes scalable online federated MKL algorithm. We prove that using the proposed online federated MKL algorithm, each client enjoys sub-linear regret with respect to the RF approximation of its best kernel in hindsight, which indicates that the proposed algorithm can effectively deal with heterogeneity of the data distributed among clients. Experimental results on real datasets showcase the advantages of the proposed algorithm compared with other online federated kernel learning ones.", "url": "https://arxiv.org/abs/2311.05108"}, {"metadata": {"arXiv": "2311.05128", "Date": "Thu, 09 Nov 2023 03:47:49 ", "Title": "Exploring and Analyzing Wildland Fire Data Via Machine Learning Techniques", "Authors": ["Dipak Dulal", "Joseph J. Charney", "Michael Gallagher", "Carmeliza Navasca", "and Nicholas Skowronski"], "Categories": "cs.LG"}, "abstract": "This research project investigated the correlation between a 10 Hz time series of thermocouple temperatures and turbulent kinetic energy (TKE) computed from wind speeds collected from a small experimental prescribed burn at the Silas Little Experimental Forest in New Jersey, USA. The primary objective of this project was to explore the potential for using thermocouple temperatures as predictors for estimating the TKE produced by a wildland fire. Machine learning models, including Deep Neural Networks, Random Forest Regressor, Gradient Boosting, and Gaussian Process Regressor, are employed to assess the potential for thermocouple temperature perturbations to predict TKE values. Data visualization and correlation analyses reveal patterns and relationships between thermocouple temperatures and TKE, providing insight into the underlying dynamics. The project achieves high accuracy in predicting TKE by employing various machine learning models despite a weak correlation between the predictors and the target variable. The results demonstrate significant success, particularly from regression models, in accurately estimating the TKE. The research findings contribute to fire behavior and smoke modeling science, emphasizing the importance of incorporating machine learning approaches and identifying complex relationships between fine-scale fire behavior and turbulence. Accurate TKE estimation using thermocouple temperatures allows for the refinement of models that can inform decision-making in fire management strategies, facilitate effective risk mitigation, and optimize fire management efforts. This project highlights the valuable role of machine learning techniques in analyzing wildland fire data, showcasing their potential to advance fire research and management practices.", "url": "https://arxiv.org/abs/2311.05128"}, {"metadata": {"arXiv": "2311.05139", "Date": "Thu, 09 Nov 2023 04:40:32 ", "Title": "On neural and dimensional collapse in supervised and unsupervised contrastive learning with hard negative sampling", "Authors": ["Ruijie Jiang", "Thuan Nguyen", "Shuchin Aeron", "Prakash Ishwar"], "Categories": "cs.LG"}, "abstract": "For a widely-studied data model and general loss and sample-hardening functions we prove that the Supervised Contrastive Learning (SCL), Hard-SCL (HSCL), and Unsupervised Contrastive Learning (UCL) risks are minimized by representations that exhibit Neural Collapse (NC), i.e., the class means form an Equianglular Tight Frame (ETF) and data from the same class are mapped to the same representation. We also prove that for any representation mapping, the HSCL and Hard-UCL (HUCL) risks are lower bounded by the corresponding SCL and UCL risks. Although the optimality of ETF is known for SCL, albeit only for InfoNCE loss, its optimality for HSCL and UCL under general loss and hardening functions is novel. Moreover, our proofs are much simpler, compact, and transparent. We empirically demonstrate, for the first time, that ADAM optimization of HSCL and HUCL risks with random initialization and suitable hardness levels can indeed converge to the NC geometry if we incorporate unit-ball or unit-sphere feature normalization. Without incorporating hard negatives or feature normalization, however, the representations learned via ADAM suffer from dimensional collapse (DC) and fail to attain the NC geometry.", "url": "https://arxiv.org/abs/2311.05139"}, {"metadata": {"arXiv": "2311.05144", "Date": "Thu, 09 Nov 2023 04:49:41 ", "Title": "Counter-Empirical Attacking based on Adversarial Reinforcement Learning for Time-Relevant Scoring System", "Authors": ["Xiangguo Sun", "Hong Cheng", "Hang Dong", "Bo Qiao", "Si Qin", "Qingwei Lin"], "Categories": "cs.LG cs.SE", "Comments": ["submitted to TKDE on 08-Jun-2022", "receive the 1st round decision (major revision) on 20-Apr-2023", "submitted to TKDE 2nd time on 30-May-2023", "receive the 2nd round decision (major revision) on 30-Sep-2023", "submitted to TKDE 3rd time on 15-Oct-2023", "now under review for the 3rd round of reviewing"]}, "abstract": "Scoring systems are commonly seen for platforms in the era of big data. From credit scoring systems in financial services to membership scores in E-commerce shopping platforms, platform managers use such systems to guide users towards the encouraged activity pattern, and manage resources more effectively and more efficiently thereby. To establish such scoring systems, several \"empirical criteria\" are firstly determined, followed by dedicated top-down design for each factor of the score, which usually requires enormous effort to adjust and tune the scoring function in the new application scenario. What's worse, many fresh projects usually have no ground-truth or any experience to evaluate a reasonable scoring system, making the designing even harder. To reduce the effort of manual adjustment of the scoring function in every new scoring system, we innovatively study the scoring system from the preset empirical criteria without any ground truth, and propose a novel framework to improve the system from scratch. In this paper, we propose a \"counter-empirical attacking\" mechanism that can generate \"attacking\" behavior traces and try to break the empirical rules of the scoring system. Then an adversarial \"enhancer\" is applied to evaluate the scoring system and find the improvement strategy. By training the adversarial learning problem, a proper scoring function can be learned to be robust to the attacking activity traces that are trying to violate the empirical criteria. Extensive experiments have been conducted on two scoring systems including a shared computing resource platform and a financial credit system. The experimental results have validated the effectiveness of our proposed framework.", "url": "https://arxiv.org/abs/2311.05144"}, {"metadata": {"arXiv": "2311.05241", "Date": "Thu, 09 Nov 2023 09:49:50 ", "Title": "When Meta-Learning Meets Online and Continual Learning: A Survey", "Authors": ["Jaehyeon Son", "Soochan Lee", "Gunhee Kim"], "Categories": "cs.LG stat.ML"}, "abstract": "Over the past decade, deep neural networks have demonstrated significant success using the training scheme that involves mini-batch stochastic gradient descent on extensive datasets. Expanding upon this accomplishment, there has been a surge in research exploring the application of neural networks in other learning scenarios. One notable framework that has garnered significant attention is meta-learning. Often described as \"learning to learn,\" meta-learning is a data-driven approach to optimize the learning algorithm. Other branches of interest are continual learning and online learning, both of which involve incrementally updating a model with streaming data. While these frameworks were initially developed independently, recent works have started investigating their combinations, proposing novel problem settings and learning algorithms. However, due to the elevated complexity and lack of unified terminology, discerning differences between the learning frameworks can be challenging even for experienced researchers. To facilitate a clear understanding, this paper provides a comprehensive survey that organizes various problem settings using consistent terminology and formal descriptions. By offering an overview of these learning paradigms, our work aims to foster further advancements in this promising area of research.", "url": "https://arxiv.org/abs/2311.05241"}, {"metadata": {"arXiv": "2311.05256", "Date": "Thu, 09 Nov 2023 10:30:51 ", "Title": "Latent Task-Specific Graph Network Simulators", "Authors": ["Philipp Dahlinger", "Niklas Freymuth", "Michael Volpp", "Tai Hoang", "Gerhard Neumann"], "Categories": "cs.LG"}, "abstract": "Simulating dynamic physical interactions is a critical challenge across multiple scientific domains, with applications ranging from robotics to material science. For mesh-based simulations, Graph Network Simulators (GNSs) pose an efficient alternative to traditional physics-based simulators. Their inherent differentiability and speed make them particularly well-suited for inverse design problems. Yet, adapting to new tasks from limited available data is an important aspect for real-world applications that current methods struggle with. We frame mesh-based simulation as a meta-learning problem and use a recent Bayesian meta-learning method to improve GNSs adaptability to new scenarios by leveraging context data and handling uncertainties. Our approach, latent task-specific graph network simulator, uses non-amortized task posterior approximations to sample latent descriptions of unknown system properties. Additionally, we leverage movement primitives for efficient full trajectory prediction, effectively addressing the issue of accumulating errors encountered by previous auto-regressive methods. We validate the effectiveness of our approach through various experiments, performing on par with or better than established baseline methods. Movement primitives further allow us to accommodate various types of context data, as demonstrated through the utilization of point clouds during inference. By combining GNSs with meta-learning, we bring them closer to real-world applicability, particularly in scenarios with smaller datasets.", "url": "https://arxiv.org/abs/2311.05256"}, {"metadata": {"arXiv": "2311.05317", "Date": "Thu, 09 Nov 2023 12:25:39 ", "Title": "RepQ: Generalizing Quantization-Aware Training for Re-Parametrized Architectures", "Authors": ["Anastasiia Prutianova", "Alexey Zaytsev", "Chung-Kuei Lee", "Fengyu Sun", "Ivan Koryakovskiy"], "Categories": "cs.LG", "Comments": ["BMVC 2023 (Oral)"]}, "abstract": "Existing neural networks are memory-consuming and computationally intensive, making deploying them challenging in resource-constrained environments. However, there are various methods to improve their efficiency. Two such methods are quantization, a well-known approach for network compression, and re-parametrization, an emerging technique designed to improve model performance. Although both techniques have been studied individually, there has been limited research on their simultaneous application. To address this gap, we propose a novel approach called RepQ, which applies quantization to re-parametrized networks. Our method is based on the insight that the test stage weights of an arbitrary re-parametrized layer can be presented as a differentiable function of trainable parameters. We enable quantization-aware training by applying quantization on top of this function. RepQ generalizes well to various re-parametrized models and outperforms the baseline method LSQ quantization scheme in all experiments.", "url": "https://arxiv.org/abs/2311.05317"}, {"metadata": {"arXiv": "2311.05346", "Date": "Thu, 09 Nov 2023 13:15:36 ", "Title": "Accelerated Shapley Value Approximation for Data Evaluation", "Authors": ["Lauren Watson", "Zeno Kujawa", "Rayna Andreeva", "Hao-Tsung Yang", "Tariq Elahi", "Rik Sarkar"], "Categories": "cs.LG"}, "abstract": "Data valuation has found various applications in machine learning, such as data filtering, efficient learning and incentives for data sharing. The most popular current approach to data valuation is the Shapley value. While popular for its various applications, Shapley value is computationally expensive even to approximate, as it requires repeated iterations of training models on different subsets of data. In this paper we show that the Shapley value of data points can be approximated more efficiently by leveraging the structural properties of machine learning problems. We derive convergence guarantees on the accuracy of the approximate Shapley value for different learning settings including Stochastic Gradient Descent with convex and non-convex loss functions. Our analysis suggests that in fact models trained on small subsets are more important in the context of data valuation. Based on this idea, we describe $\\delta$-Shapley -- a strategy of only using small subsets for the approximation. Experiments show that this approach preserves approximate value and rank of data, while achieving speedup of up to 9.9x. In pre-trained networks the approach is found to bring more efficiency in terms of accurate evaluation using small subsets.", "url": "https://arxiv.org/abs/2311.05346"}, {"metadata": {"arXiv": "2311.05363", "Date": "Thu, 09 Nov 2023 13:44:28 ", "Title": "Beyond the training set: an intuitive method for detecting distribution shift in model-based optimization", "Authors": ["Farhan Damani", "David H Brookes", "Theodore Sternlieb", "Cameron Webster", "Stephen Malina", "Rishi Jajoo", "Kathy Lin", "Sam Sinai"], "Categories": "cs.LG q-bio.QM"}, "abstract": "Model-based optimization (MBO) is increasingly applied to design problems in science and engineering. A common scenario involves using a fixed training set to train models, with the goal of designing new samples that outperform those present in the training data. A major challenge in this setting is distribution shift, where the distributions of training and design samples are different. While some shift is expected, as the goal is to create better designs, this change can negatively affect model accuracy and subsequently, design quality. Despite the widespread nature of this problem, addressing it demands deep domain knowledge and artful application. To tackle this issue, we propose a straightforward method for design practitioners that detects distribution shifts. This method trains a binary classifier using knowledge of the unlabeled design distribution to separate the training data from the design data. The classifier's logit scores are then used as a proxy measure of distribution shift. We validate our method in a real-world application by running offline MBO and evaluate the effect of distribution shift on design quality. We find that the intensity of the shift in the design distribution varies based on the number of steps taken by the optimization algorithm, and our simple approach can identify these shifts. This enables users to constrain their search to regions where the model's predictions are reliable, thereby increasing the quality of designs.", "url": "https://arxiv.org/abs/2311.05363"}, {"metadata": {"arXiv": "2311.05398", "Date": "Thu, 09 Nov 2023 14:29:25 ", "Title": "The Sample Complexity Of ERMs In Stochastic Convex Optimization", "Authors": ["Daniel Carmon", "Roi Livni", "Amir Yehudayoff"], "Categories": "cs.LG stat.ML"}, "abstract": "Stochastic convex optimization is one of the most well-studied models for learning in modern machine learning. Nevertheless, a central fundamental question in this setup remained unresolved: \"How many data points must be observed so that any empirical risk minimizer (ERM) shows good performance on the true population?\" This question was proposed by Feldman (2016), who proved that $\\Omega(\\frac{d}{\\epsilon}+\\frac{1}{\\epsilon^2})$ data points are necessary (where $d$ is the dimension and $\\epsilon>0$ is the accuracy parameter). Proving an $\\omega(\\frac{d}{\\epsilon}+\\frac{1}{\\epsilon^2})$ lower bound was left as an open problem. In this work we show that in fact $\\tilde{O}(\\frac{d}{\\epsilon}+\\frac{1}{\\epsilon^2})$ data points are also sufficient. This settles the question and yields a new separation between ERMs and uniform convergence. This sample complexity holds for the classical setup of learning bounded convex Lipschitz functions over the Euclidean unit ball. We further generalize the result and show that a similar upper bound holds for all symmetric convex bodies. The general bound is composed of two terms: (i) a term of the form $\\tilde{O}(\\frac{d}{\\epsilon})$ with an inverse-linear dependence on the accuracy parameter, and (ii) a term that depends on the statistical complexity of the class of $\\textit{linear}$ functions (captured by the Rademacher complexity). The proof builds a mechanism for controlling the behavior of stochastic convex optimization problems.", "url": "https://arxiv.org/abs/2311.05398"}, {"metadata": {"arXiv": "2311.05417", "Date": "Thu, 09 Nov 2023 14:54:08 ", "Title": "Predicting the Position Uncertainty at the Time of Closest Approach with Diffusion Models", "Authors": ["Marta Guimar\\~aes", "Cl\\'audia Soares", "Chiara Manfletti"], "Categories": "cs.LG cs.RO"}, "abstract": "The risk of collision between resident space objects has significantly increased in recent years. As a result, spacecraft collision avoidance procedures have become an essential part of satellite operations. To ensure safe and effective space activities, satellite owners and operators rely on constantly updated estimates of encounters. These estimates include the uncertainty associated with the position of each object at the expected TCA. These estimates are crucial in planning risk mitigation measures, such as collision avoidance manoeuvres. As the TCA approaches, the accuracy of these estimates improves, as both objects' orbit determination and propagation procedures are made for increasingly shorter time intervals. However, this improvement comes at the cost of taking place close to the critical decision moment. This means that safe avoidance manoeuvres might not be possible or could incur significant costs. Therefore, knowing the evolution of this variable in advance can be crucial for operators. This work proposes a machine learning model based on diffusion models to forecast the position uncertainty of objects involved in a close encounter, particularly for the secondary object (usually debris), which tends to be more unpredictable. We compare the performance of our model with other state-of-the-art solutions and a na\\\"ive baseline approach, showing that the proposed solution has the potential to significantly improve the safety and effectiveness of spacecraft operations.", "url": "https://arxiv.org/abs/2311.05417"}, {"metadata": {"arXiv": "2311.05420", "Date": "Thu, 09 Nov 2023 14:58:53 ", "Title": "Counterfactually Fair Representation", "Authors": ["Zhiqun Zuo and Mohammad Mahdi Khalili and Xueru Zhang"], "Categories": "cs.LG cs.CY"}, "abstract": "The use of machine learning models in high-stake applications (e.g., healthcare, lending, college admission) has raised growing concerns due to potential biases against protected social groups. Various fairness notions and methods have been proposed to mitigate such biases. In this work, we focus on Counterfactual Fairness (CF), a fairness notion that is dependent on an underlying causal graph and first proposed by Kusner \\textit{et al.}~\\cite{kusner2017counterfactual}; it requires that the outcome an individual perceives is the same in the real world as it would be in a \"counterfactual\" world, in which the individual belongs to another social group. Learning fair models satisfying CF can be challenging. It was shown in \\cite{kusner2017counterfactual} that a sufficient condition for satisfying CF is to \\textbf{not} use features that are descendants of sensitive attributes in the causal graph. This implies a simple method that learns CF models only using non-descendants of sensitive attributes while eliminating all descendants. Although several subsequent works proposed methods that use all features for training CF models, there is no theoretical guarantee that they can satisfy CF. In contrast, this work proposes a new algorithm that trains models using all the available features. We theoretically and empirically show that models trained with this method can satisfy CF\\footnote{The code repository for this work can be found in \\url{https://github.com/osu-srml/CF_Representation_Learning}}.", "url": "https://arxiv.org/abs/2311.05420"}, {"metadata": {"arXiv": "2311.05421", "Date": "Thu, 09 Nov 2023 14:59:26 ", "Title": "Diffusion Based Causal Representation Learning", "Authors": ["Amir Mohammad Karimi Mamaghan", "Andrea Dittadi", "Stefan Bauer", "Karl Henrik Johansson", "Francesco Quinzan"], "Categories": "cs.LG stat.ME"}, "abstract": "Causal reasoning can be considered a cornerstone of intelligent systems. Having access to an underlying causal graph comes with the promise of cause-effect estimation and the identification of efficient and safe interventions. However, learning causal representations remains a major challenge, due to the complexity of many real-world systems. Previous works on causal representation learning have mostly focused on Variational Auto-Encoders (VAE). These methods only provide representations from a point estimate, and they are unsuitable to handle high dimensions. To overcome these problems, we proposed a new Diffusion-based Causal Representation Learning (DCRL) algorithm. This algorithm uses diffusion-based representations for causal discovery. DCRL offers access to infinite dimensional latent codes, which encode different levels of information in the latent code. In a first proof of principle, we investigate the use of DCRL for causal representation learning. We further demonstrate experimentally that this approach performs comparably well in identifying the causal structure and causal variables.", "url": "https://arxiv.org/abs/2311.05421"}, {"metadata": {"arXiv": "2311.05426", "Date": "Thu, 09 Nov 2023 15:04:14 ", "Title": "Statistical Learning of Conjunction Data Messages Through a Bayesian Non-Homogeneous Poisson Process", "Authors": ["Marta Guimar\\~aes", "Cl\\'audia Soares", "Chiara Manfletti"], "Categories": "cs.LG"}, "abstract": "Current approaches for collision avoidance and space traffic management face many challenges, mainly due to the continuous increase in the number of objects in orbit and the lack of scalable and automated solutions. To avoid catastrophic incidents, satellite owners/operators must be aware of their assets' collision risk to decide whether a collision avoidance manoeuvre needs to be performed. This process is typically executed through the use of warnings issued in the form of CDMs which contain information about the event, such as the expected TCA and the probability of collision. Our previous work presented a statistical learning model that allowed us to answer two important questions: (1) Will any new conjunctions be issued in the next specified time interval? (2) When and with what uncertainty will the next CDM arrive? However, the model was based on an empirical Bayes homogeneous Poisson process, which assumes that the arrival rates of CDMs are constant over time. In fact, the rate at which the CDMs are issued depends on the behaviour of the objects as well as on the screening process performed by third parties. Thus, in this work, we extend the previous study and propose a Bayesian non-homogeneous Poisson process implemented with high precision using a Probabilistic Programming Language to fully describe the underlying phenomena. We compare the proposed solution with a baseline model to demonstrate the added value of our approach. The results show that this problem can be successfully modelled by our Bayesian non-homogeneous Poisson Process with greater accuracy, contributing to the development of automated collision avoidance systems and helping operators react timely but sparingly with satellite manoeuvres.", "url": "https://arxiv.org/abs/2311.05426"}, {"metadata": {"arXiv": "2311.05430", "Date": "Thu, 09 Nov 2023 15:14:08 ", "Title": "Taxonomy for Resident Space Objects in LEO: A Deep Learning Approach", "Authors": ["Marta Guimar\\~aes", "Cl\\'audia Soares", "Chiara Manfletti"], "Categories": "cs.LG"}, "abstract": "The increasing number of RSOs has raised concerns about the risk of collisions and catastrophic incidents for all direct and indirect users of space. To mitigate this issue, it is essential to have a good understanding of the various RSOs in orbit and their behaviour. A well-established taxonomy defining several classes of RSOs is a critical step in achieving this understanding. This taxonomy helps assign objects to specific categories based on their main characteristics, leading to better tracking services. Furthermore, a well-established taxonomy can facilitate research and analysis processes by providing a common language and framework for better understanding the factors that influence RSO behaviour in space. These factors, in turn, help design more efficient and effective strategies for space traffic management. Our work proposes a new taxonomy for RSOs focusing on the low Earth orbit regime to enhance space traffic management. In addition, we present a deep learning-based model that uses an autoencoder architecture to reduce the features representing the characteristics of the RSOs. The autoencoder generates a lower-dimensional space representation that is then explored using techniques such as Uniform Manifold Approximation and Projection to identify fundamental clusters of RSOs based on their unique characteristics. This approach captures the complex and non-linear relationships between the features and the RSOs' classes identified. Our proposed taxonomy and model offer a significant contribution to the ongoing efforts to mitigate the overall risks posed by the increasing number of RSOs in orbit.", "url": "https://arxiv.org/abs/2311.05430"}, {"metadata": {"arXiv": "2311.05435", "Date": "Thu, 09 Nov 2023 15:21:10 ", "Title": "Parkinson's Disease Detection through Vocal Biomarkers and Advanced Machine Learning Algorithms: A Comprehensive Study", "Authors": ["Md Abu Sayed", "Sabbir Ahamed", "Duc M Cao", "Md Eyasin Ul Islam Pavel", "Malay Sarkar", "Md Tuhin Mia"], "Categories": "cs.LG cs.SD eess.AS"}, "abstract": "Parkinson's disease (PD) is a prevalent neurodegenerative disorder known for its impact on motor neurons, causing symptoms like tremors, stiffness, and gait difficulties. This study explores the potential of vocal feature alterations in PD patients as a means of early disease prediction. This research aims to predict the onset of Parkinson's disease. Utilizing a variety of advanced machine-learning algorithms, including XGBoost, LightGBM, Bagging, AdaBoost, and Support Vector Machine, among others, the study evaluates the predictive performance of these models using metrics such as accuracy, area under the curve (AUC), sensitivity, and specificity. The findings of this comprehensive analysis highlight LightGBM as the most effective model, achieving an impressive accuracy rate of 96%, alongside a matching AUC of 96%. LightGBM exhibited a remarkable sensitivity of 100% and specificity of 94.43%, surpassing other machine learning algorithms in accuracy and AUC scores. Given the complexities of Parkinson's disease and its challenges in early diagnosis, this study underscores the significance of leveraging vocal biomarkers coupled with advanced machine-learning techniques for precise and timely PD detection.", "url": "https://arxiv.org/abs/2311.05435"}, {"metadata": {"arXiv": "2311.05440", "Date": "Thu, 09 Nov 2023 15:24:44 ", "Title": "A Practical Approach to Novel Class Discovery in Tabular Data", "Authors": ["Colin Troisemaine", "Alexandre Reiffers-Masson", "St\\'ephane Gosselin", "Vincent Lemaire", "Sandrine Vaton"], "Categories": "cs.LG", "Comments": ["25 pages", "including 3 pages of annexes"]}, "abstract": "The problem of Novel Class Discovery (NCD) consists in extracting knowledge from a labeled set of known classes to accurately partition an unlabeled set of novel classes. While NCD has recently received a lot of attention from the community, it is often solved on computer vision problems and under unrealistic conditions. In particular, the number of novel classes is usually assumed to be known in advance, and their labels are sometimes used to tune hyperparameters. Methods that rely on these assumptions are not applicable in real-world scenarios. In this work, we focus on solving NCD in tabular data when no prior knowledge of the novel classes is available. To this end, we propose to tune the hyperparameters of NCD methods by adapting the $k$-fold cross-validation process and hiding some of the known classes in each fold. Since we have found that methods with too many hyperparameters are likely to overfit these hidden classes, we define a simple deep NCD model. This method is composed of only the essential elements necessary for the NCD problem and performs impressively well under realistic conditions. Furthermore, we find that the latent space of this method can be used to reliably estimate the number of novel classes. Additionally, we adapt two unsupervised clustering algorithms ($k$-means and Spectral Clustering) to leverage the knowledge of the known classes. Extensive experiments are conducted on 7 tabular datasets and demonstrate the effectiveness of the proposed method and hyperparameter tuning process, and show that the NCD problem can be solved without relying on knowledge from the novel classes.", "url": "https://arxiv.org/abs/2311.05440"}, {"metadata": {"arXiv": "2311.05473", "Date": "Thu, 09 Nov 2023 16:05:38 ", "Title": "Do Ensembling and Meta-Learning Improve Outlier Detection in Randomized Controlled Trials?", "Authors": ["Walter Nelson", "Jonathan Ranisau", "Jeremy Petch"], "Categories": "cs.LG", "Comments": ["Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2023", "December 10th", "2023", "New Orleans", "United States", "8 pages"]}, "abstract": "Modern multi-centre randomized controlled trials (MCRCTs) collect massive amounts of tabular data, and are monitored intensively for irregularities by humans. We began by empirically evaluating 6 modern machine learning-based outlier detection algorithms on the task of identifying irregular data in 838 datasets from 7 real-world MCRCTs with a total of 77,001 patients from over 44 countries. Our results reinforce key findings from prior work in the outlier detection literature on data from other domains. Existing algorithms often succeed at identifying irregularities without any supervision, with at least one algorithm exhibiting positive performance 70.6% of the time. However, performance across datasets varies substantially with no single algorithm performing consistently well, motivating new techniques for unsupervised model selection or other means of aggregating potentially discordant predictions from multiple candidate models. We propose the Meta-learned Probabilistic Ensemble (MePE), a simple algorithm for aggregating the predictions of multiple unsupervised models, and show that it performs favourably compared to recent meta-learning approaches for outlier detection model selection. While meta-learning shows promise, small ensembles outperform all forms of meta-learning on average, a negative result that may guide the application of current outlier detection approaches in healthcare and other real-world domains.", "url": "https://arxiv.org/abs/2311.05473"}, {"metadata": {"arXiv": "2311.05538", "Date": "Thu, 09 Nov 2023 17:34:53 ", "Title": "Embedding Space Interpolation Beyond Mini-Batch, Beyond Pairs and Beyond Examples", "Authors": ["Shashanka Venkataramanan", "Ewa Kijak", "Laurent Amsaleg", "Yannis Avrithis"], "Categories": "cs.LG cs.CV", "Comments": ["Accepted to NeurIPS 2023. arXiv admin note: substantial text overlap with arXiv:2206.14868"]}, "abstract": "Mixup refers to interpolation-based data augmentation, originally motivated as a way to go beyond empirical risk minimization (ERM). Its extensions mostly focus on the definition of interpolation and the space (input or feature) where it takes place, while the augmentation process itself is less studied. In most methods, the number of generated examples is limited to the mini-batch size and the number of examples being interpolated is limited to two (pairs), in the input space. We make progress in this direction by introducing MultiMix, which generates an arbitrarily large number of interpolated examples beyond the mini-batch size and interpolates the entire mini-batch in the embedding space. Effectively, we sample on the entire convex hull of the mini-batch rather than along linear segments between pairs of examples. On sequence data, we further extend to Dense MultiMix. We densely interpolate features and target labels at each spatial location and also apply the loss densely. To mitigate the lack of dense labels, we inherit labels from examples and weight interpolation factors by attention as a measure of confidence. Overall, we increase the number of loss terms per mini-batch by orders of magnitude at little additional cost. This is only possible because of interpolating in the embedding space. We empirically show that our solutions yield significant improvement over state-of-the-art mixup methods on four different benchmarks, despite interpolation being only linear. By analyzing the embedding space, we show that the classes are more tightly clustered and uniformly spread over the embedding space, thereby explaining the improved behavior.", "url": "https://arxiv.org/abs/2311.05538"}, {"metadata": {"arXiv": "2311.05557", "Date": "Thu, 09 Nov 2023 18:05:46 ", "Title": "Exploiting Neural-Network Statistics for Low-Power DNN Inference", "Authors": ["Lennart Bamberg", "Ardalan Najafi", "Alberto Garcia-Ortiz"], "Categories": "cs.LG cs.AR"}, "abstract": "Specialized compute blocks have been developed for efficient DNN execution. However, due to the vast amount of data and parameter movements, the interconnects and on-chip memories form another bottleneck, impairing power and performance. This work addresses this bottleneck by contributing a low-power technique for edge-AI inference engines that combines overhead-free coding with a statistical analysis of the data and parameters of neural networks. Our approach reduces the interconnect and memory power consumption by up to 80% for state-of-the-art benchmarks while providing additional power savings for the compute blocks by up to 39%. These power improvements are achieved with no loss of accuracy and negligible hardware cost.", "url": "https://arxiv.org/abs/2311.05557"}, {"metadata": {"arXiv": "2311.05587", "Date": "Thu, 09 Nov 2023 18:47:33 ", "Title": "Bayesian Methods for Media Mix Modelling with shape and funnel effects", "Authors": ["Javier Marin"], "Categories": "cs.LG"}, "abstract": "In recent years, significant progress in generative AI has highlighted the important role of physics-inspired models that utilize advanced mathematical concepts based on fundamental physics principles to enhance artificial intelligence capabilities. Among these models, those based on diffusion equations have greatly improved image quality. This study aims to explore the potential uses of Maxwell-Boltzmann equation, which forms the basis of the kinetic theory of gases, and the Michaelis-Menten model in Marketing Mix Modelling (MMM) applications. We propose incorporating these equations into Hierarchical Bayesian models to analyse consumer behaviour in the context of advertising. These equation sets excel in accurately describing the random dynamics in complex systems like social interactions and consumer-advertising interactions.", "url": "https://arxiv.org/abs/2311.05587"}, {"metadata": {"arXiv": "2311.05589", "Date": "Thu, 09 Nov 2023 18:47:44 ", "Title": "A Coefficient Makes SVRG Effective", "Authors": ["Yida Yin", "Zhiqiu Xu", "Zhiyuan Li", "Trevor Darrell", "Zhuang Liu"], "Categories": "cs.LG math.OC stat.ML", "Comments": ["Preprint"]}, "abstract": "Stochastic Variance Reduced Gradient (SVRG), introduced by Johnson & Zhang (2013), is a theoretically compelling optimization method. However, as Defazio & Bottou (2019) highlights, its effectiveness in deep learning is yet to be proven. In this work, we demonstrate the potential of SVRG in optimizing real-world neural networks. Our analysis finds that, for deeper networks, the strength of the variance reduction term in SVRG should be smaller and decrease as training progresses. Inspired by this, we introduce a multiplicative coefficient $\\alpha$ to control the strength and adjust it through a linear decay schedule. We name our method $\\alpha$-SVRG. Our results show $\\alpha$-SVRG better optimizes neural networks, consistently reducing training loss compared to both baseline and the standard SVRG across various architectures and image classification datasets. We hope our findings encourage further exploration into variance reduction techniques in deep learning. Code is available at https://github.com/davidyyd/alpha-SVRG.", "url": "https://arxiv.org/abs/2311.05589"}, {"metadata": {"arXiv": "2311.05598", "Date": "Thu, 09 Nov 2023 18:56:43 ", "Title": "Sorting Out Quantum Monte Carlo", "Authors": ["Jack Richter-Powell", "Luca Thiede", "Al\\'an Asparu-Guzik", "David Duvenaud"], "Categories": "cs.LG physics.chem-ph physics.comp-ph"}, "abstract": "Molecular modeling at the quantum level requires choosing a parameterization of the wavefunction that both respects the required particle symmetries, and is scalable to systems of many particles. For the simulation of fermions, valid parameterizations must be antisymmetric with respect to the exchange of particles. Typically, antisymmetry is enforced by leveraging the anti-symmetry of determinants with respect to the exchange of matrix rows, but this involves computing a full determinant each time the wavefunction is evaluated. Instead, we introduce a new antisymmetrization layer derived from sorting, the $\\textit{sortlet}$, which scales as $O(N \\log N)$ with regards to the number of particles -- in contrast to $O(N^3)$ for the determinant. We show numerically that applying this anti-symmeterization layer on top of an attention based neural-network backbone yields a flexible wavefunction parameterization capable of reaching chemical accuracy when approximating the ground state of first-row atoms and small molecules.", "url": "https://arxiv.org/abs/2311.05598"}, {"metadata": {"arXiv": "2311.05606", "Date": "Thu, 09 Nov 2023 18:59:05 ", "Title": "Diffusion-Generative Multi-Fidelity Learning for Physical Simulation", "Authors": ["Zheng Wang", "Shibo Li", "Shikai Fang", "Shandian Zhe"], "Categories": "cs.LG"}, "abstract": "Multi-fidelity surrogate learning is important for physical simulation related applications in that it avoids running numerical solvers from scratch, which is known to be costly, and it uses multi-fidelity examples for training and greatly reduces the cost of data collection. Despite the variety of existing methods, they all build a model to map the input parameters outright to the solution output. Inspired by the recent breakthrough in generative models, we take an alternative view and consider the solution output as generated from random noises. We develop a diffusion-generative multi-fidelity (DGMF) learning method based on stochastic differential equations (SDE), where the generation is a continuous denoising process. We propose a conditional score model to control the solution generation by the input parameters and the fidelity. By conditioning on additional inputs (temporal or spacial variables), our model can efficiently learn and predict multi-dimensional solution arrays. Our method naturally unifies discrete and continuous fidelity modeling. The advantage of our method in several typical applications shows a promising new direction for multi-fidelity learning.", "url": "https://arxiv.org/abs/2311.05606"}, {"metadata": {"arXiv": "2311.05610", "Date": "Thu, 09 Nov 2023 18:59:38 ", "Title": "Efficient Parallelization Layouts for Large-Scale Distributed Model Training", "Authors": ["Johannes Hagemann", "Samuel Weinbach", "Konstantin Dobler", "Maximilian Schall", "Gerard de Melo"], "Categories": "cs.LG cs.DC"}, "abstract": "Efficiently training large language models requires parallelizing across hundreds of hardware accelerators and invoking various compute and memory optimizations. When combined, many of these strategies have complex interactions regarding the final training efficiency. Prior work tackling this problem did not have access to the latest set of optimizations, such as FlashAttention or sequence parallelism. In this work, we conduct a comprehensive ablation study of possible training configurations for large language models. We distill this large study into several key recommendations for the most efficient training. For instance, we find that using a micro-batch size of 1 usually enables the most efficient training layouts. Larger micro-batch sizes necessitate activation checkpointing or higher degrees of model parallelism and also lead to larger pipeline bubbles. Our most efficient configurations enable us to achieve state-of-the-art training efficiency results over a range of model sizes, most notably a Model FLOPs utilization of 70.5% when training a 13B model.", "url": "https://arxiv.org/abs/2311.05610"}, {"metadata": {"arXiv": "2311.05334", "Date": "Thu, 09 Nov 2023 13:01:21 ", "Title": "Real-time Addressee Estimation: Deployment of a Deep-Learning Model on the iCub Robot", "Authors": ["Carlo Mazzola", "Francesco Rea", "Alessandra Sciutti"], "Categories": "cs.RO cs.LG", "Comments": ["4 pages", "3 figures", "paper presented at IRIM-3D 2023 Conference", "Funded by the Horizon-Widera-2021 European Twinning project TERAIS: G.A. n. 101079338"], "ACM-class": "I.2.9; I.2.10; H.1.2"}, "abstract": "Addressee Estimation is the ability to understand to whom a person is talking, a skill essential for social robots to interact smoothly with humans. In this sense, it is one of the problems that must be tackled to develop effective conversational agents in multi-party and unstructured scenarios. As humans, one of the channels that mainly lead us to such estimation is the non-verbal behavior of speakers: first of all, their gaze and body pose. Inspired by human perceptual skills, in the present work, a deep-learning model for Addressee Estimation relying on these two non-verbal features is designed, trained, and deployed on an iCub robot. The study presents the procedure of such implementation and the performance of the model deployed in real-time human-robot interaction compared to previous tests on the dataset used for the training.", "url": "https://arxiv.org/abs/2311.05334"}, {"metadata": {"arXiv": "2311.05360", "Date": "Thu, 09 Nov 2023 13:39:41 ", "Title": "Basis functions nonlinear data-enabled predictive control: Consistent and computationally efficient formulations", "Authors": ["Mircea Lazar"], "Categories": "eess.SY cs.LG cs.SY math.OC"}, "abstract": "This paper considers the extension of data-enabled predictive control (DeePC) to nonlinear systems via general basis functions. Firstly, we formulate a basis functions DeePC behavioral predictor and we identify necessary and sufficient conditions for equivalence with a corresponding basis functions multi-step identified predictor. The derived conditions yield a dynamic regularization cost function that enables a well-posed (i.e., consistent) basis functions formulation of nonlinear DeePC. To optimize computational efficiency of basis functions DeePC we further develop two alternative formulations that use a simpler, sparse regularization cost function and ridge regression, respectively. Consistency implications for Koopman DeePC as well as several methods for constructing the basis functions representation are also indicated. The effectiveness of the developed consistent basis functions DeePC formulations is illustrated on a benchmark nonlinear pendulum state-space model, for both noise free and noisy data.", "url": "https://arxiv.org/abs/2311.05360"}, {"metadata": {"arXiv": "2311.05227", "Date": "Thu, 09 Nov 2023 09:16:02 ", "Title": "Kantian Deontology Meets AI Alignment: Towards Morally Robust Fairness Metrics", "Authors": ["Carlos Mougan", "Joshua Brand"], "Categories": "cs.AI"}, "abstract": "Deontological ethics, specifically understood through Immanuel Kant, provides a moral framework that emphasizes the importance of duties and principles, rather than the consequences of action. Understanding that despite the prominence of deontology, it is currently an overlooked approach in fairness metrics, this paper explores the compatibility of a Kantian deontological framework in fairness metrics, part of the AI alignment field. We revisit Kant's critique of utilitarianism, which is the primary approach in AI fairness metrics and argue that fairness principles should align with the Kantian deontological framework. By integrating Kantian ethics into AI alignment, we not only bring in a widely-accepted prominent moral theory but also strive for a more morally grounded AI landscape that better balances outcomes and procedures in pursuit of fairness and justice.", "url": "https://arxiv.org/abs/2311.05227"}, {"metadata": {"arXiv": "2311.05263", "Date": "Thu, 09 Nov 2023 10:46:09 ", "Title": "Model-Based Minimum Bayes Risk Decoding", "Authors": ["Yuu Jinnai", "Tetsuro Morimura", "Ukyo Honda", "Kaito Ariu", "Kenshi Abe"], "Categories": "cs.AI cs.CL"}, "abstract": "Minimum Bayes Risk (MBR) decoding has been shown to be a powerful alternative to beam search decoding in a variety of text generation tasks. MBR decoding selects a hypothesis from a pool of hypotheses that has the least expected risk under a probability model according to a given utility function. Since it is impractical to compute the expected risk exactly over all possible hypotheses, two approximations are commonly used in MBR. First, it integrates over a sampled set of hypotheses rather than over all possible hypotheses. Second, it estimates the probability of each hypothesis using a Monte Carlo estimator. While the first approximation is necessary to make it computationally feasible, the second is not essential since we typically have access to the model probability at inference time. We propose Model-Based MBR (MBMBR), a variant of MBR that uses the model probability itself as the estimate of the probability distribution instead of the Monte Carlo estimate. We show analytically and empirically that the model-based estimate is more promising than the Monte Carlo estimate in text generation tasks. Our experiments show that MBMBR outperforms MBR in several text generation tasks, both with encoder-decoder models and with large language models.", "url": "https://arxiv.org/abs/2311.05263"}, {"metadata": {"arXiv": "2311.05481", "Date": "Thu, 09 Nov 2023 16:16:31 ", "Title": "meta4: semantically-aligned generation of metaphoric gestures using self-supervised text and speech representation", "Authors": ["Mireille Fares", "Catherine Pelachaud", "Nicolas Obin"], "Categories": "cs.AI"}, "abstract": "Image Schemas are repetitive cognitive patterns that influence the way we conceptualize and reason about various concepts present in speech. These patterns are deeply embedded within our cognitive processes and are reflected in our bodily expressions including gestures. Particularly, metaphoric gestures possess essential characteristics and semantic meanings that align with Image Schemas, to visually represent abstract concepts. The shape and form of gestures can convey abstract concepts, such as extending the forearm and hand or tracing a line with hand movements to visually represent the image schema of PATH. Previous behavior generation models have primarily focused on utilizing speech (acoustic features and text) to drive the generation model of virtual agents. They have not considered key semantic information as those carried by Image Schemas to effectively generate metaphoric gestures. To address this limitation, we introduce META4, a deep learning approach that generates metaphoric gestures from both speech and Image Schemas. Our approach has two primary goals: computing Image Schemas from input text to capture the underlying semantic and metaphorical meaning, and generating metaphoric gestures driven by speech and the computed image schemas. Our approach is the first method for generating speech driven metaphoric gestures while leveraging the potential of Image Schemas. We demonstrate the effectiveness of our approach and highlight the importance of both speech and image schemas in modeling metaphoric gestures.", "url": "https://arxiv.org/abs/2311.05481"}, {"metadata": {"arXiv": "2311.05490", "Date": "Thu, 09 Nov 2023 16:30:22 ", "Title": "General Policies, Subgoal Structure, and Planning Width", "Authors": ["Blai Bonet and Hector Geffner"], "Categories": "cs.AI"}, "abstract": "It has been observed that many classical planning domains with atomic goals can be solved by means of a simple polynomial exploration procedure, called IW, that runs in time exponential in the problem width, which in these cases is bounded and small. Yet, while the notion of width has become part of state-of-the-art planning algorithms such as BFWS, there is no good explanation for why so many benchmark domains have bounded width when atomic goals are considered. In this work, we address this question by relating bounded width with the existence of general optimal policies that in each planning instance are represented by tuples of atoms of bounded size. We also define the notions of (explicit) serializations and serialized width that have a broader scope as many domains have a bounded serialized width but no bounded width. Such problems are solved non-optimally in polynomial time by a suitable variant of the Serialized IW algorithm. Finally, the language of general policies and the semantics of serializations are combined to yield a simple, meaningful, and expressive language for specifying serializations in compact form in the form of sketches, which can be used for encoding domain control knowledge by hand or for learning it from small examples. Sketches express general problem decompositions in terms of subgoals, and sketches of bounded width express problem decompositions that can be solved in polynomial time.", "url": "https://arxiv.org/abs/2311.05490"}, {"metadata": {"arXiv": "2311.04940", "Date": "Wed, 08 Nov 2023 01:54:56 ", "Title": "Interpretable Geoscience Artificial Intelligence (XGeoS-AI): Application to Demystify Image Recognition", "Authors": ["Jin-Jian Xu", "Hao Zhang", "Chao-Sheng Tang", "Lin Li", "Bin Shi"], "Categories": "cs.CV cs.AI eess.IV"}, "abstract": "As Earth science enters the era of big data, artificial intelligence (AI) not only offers great potential for solving geoscience problems, but also plays a critical role in accelerating the understanding of the complex, interactive, and multiscale processes of Earth's behavior. As geoscience AI models are progressively utilized for significant predictions in crucial situations, geoscience researchers are increasingly demanding their interpretability and versatility. This study proposes an interpretable geoscience artificial intelligence (XGeoS-AI) framework to unravel the mystery of image recognition in the Earth sciences, and its effectiveness and versatility is demonstrated by taking computed tomography (CT) image recognition as an example. Inspired by the mechanism of human vision, the proposed XGeoS-AI framework generates a threshold value from a local region within the whole image to complete the recognition. Different kinds of artificial intelligence (AI) methods, such as Support Vector Regression (SVR), Multilayer Perceptron (MLP), Convolutional Neural Network (CNN), can be adopted as the AI engines of the proposed XGeoS-AI framework to efficiently complete geoscience image recognition tasks. Experimental results demonstrate that the effectiveness, versatility, and heuristics of the proposed framework have great potential in solving geoscience image recognition problems. Interpretable AI should receive more and more attention in the field of the Earth sciences, which is the key to promoting more rational and wider applications of AI in the field of Earth sciences. In addition, the proposed interpretable framework may be the forerunner of technological innovation in the Earth sciences.", "url": "https://arxiv.org/abs/2311.04940"}, {"metadata": {"arXiv": "2311.05043", "Date": "Wed, 08 Nov 2023 22:18:53 ", "Title": "Zero-shot Translation of Attention Patterns in VQA Models to Natural Language", "Authors": ["Leonard Salewski", "A. Sophia Koepke", "Hendrik P. A. Lensch", "Zeynep Akata"], "Categories": "cs.CV cs.AI cs.CL", "Comments": ["Published in GCPR 2023"]}, "abstract": "Converting a model's internals to text can yield human-understandable insights about the model. Inspired by the recent success of training-free approaches for image captioning, we propose ZS-A2T, a zero-shot framework that translates the transformer attention of a given model into natural language without requiring any training. We consider this in the context of Visual Question Answering (VQA). ZS-A2T builds on a pre-trained large language model (LLM), which receives a task prompt, question, and predicted answer, as inputs. The LLM is guided to select tokens which describe the regions in the input image that the VQA model attended to. Crucially, we determine this similarity by exploiting the text-image matching capabilities of the underlying VQA model. Our framework does not require any training and allows the drop-in replacement of different guiding sources (e.g. attribution instead of attention maps), or language models. We evaluate this novel task on textual explanation datasets for VQA, giving state-of-the-art performances for the zero-shot setting on GQA-REX and VQA-X. Our code is available at: https://github.com/ExplainableML/ZS-A2T.", "url": "https://arxiv.org/abs/2311.05043"}, {"metadata": {"arXiv": "2311.05168", "Date": "Thu, 09 Nov 2023 06:43:53 ", "Title": "FireMatch: A Semi-Supervised Video Fire Detection Network Based on Consistency and Distribution Alignment", "Authors": ["Qinghua Lin", "Zuoyong Li", "Kun Zeng", "Haoyi Fan", "Wei Li", "Xiaoguang Zhou"], "Categories": "cs.CV cs.AI"}, "abstract": "Deep learning techniques have greatly enhanced the performance of fire detection in videos. However, video-based fire detection models heavily rely on labeled data, and the process of data labeling is particularly costly and time-consuming, especially when dealing with videos. Considering the limited quantity of labeled video data, we propose a semi-supervised fire detection model called FireMatch, which is based on consistency regularization and adversarial distribution alignment. Specifically, we first combine consistency regularization with pseudo-label. For unlabeled data, we design video data augmentation to obtain corresponding weakly augmented and strongly augmented samples. The proposed model predicts weakly augmented samples and retains pseudo-label above a threshold, while training on strongly augmented samples to predict these pseudo-labels for learning more robust feature representations. Secondly, we generate video cross-set augmented samples by adversarial distribution alignment to expand the training data and alleviate the decline in classification performance caused by insufficient labeled data. Finally, we introduce a fairness loss to help the model produce diverse predictions for input samples, thereby addressing the issue of high confidence with the non-fire class in fire classification scenarios. The FireMatch achieved an accuracy of 76.92% and 91.81% on two real-world fire datasets, respectively. The experimental results demonstrate that the proposed method outperforms the current state-of-the-art semi-supervised classification methods.", "url": "https://arxiv.org/abs/2311.05168"}, {"metadata": {"arXiv": "2311.05197", "Date": "Thu, 09 Nov 2023 08:23:44 ", "Title": "Deep Learning in Computed Tomography Pulmonary Angiography Imaging: A Dual-Pronged Approach for Pulmonary Embolism Detection", "Authors": ["Fabiha Bushra", "Muhammad E. H. Chowdhury", "Rusab Sarmun", "Saidul Kabir", "Menatalla Said", "Sohaib Bassam Zoghoul", "Adam Mushtak", "Israa Al-Hashimi", "Abdulrahman Alqahtani", "Anwarul Hasan"], "Categories": "cs.CV cs.AI", "Comments": ["Expert Systems With Applications (Print ISSN: 0957-4174)"]}, "abstract": "Pulmonary Embolism (PE) is a critical medical condition characterized by obstructions in the pulmonary arteries. Despite being a major health concern, it often goes underdiagnosed leading to detrimental clinical outcomes. The increasing reliance on Computed Tomography Pulmonary Angiography for diagnosis presents challenges and a pressing need for enhanced diagnostic solutions. The primary objective of this study is to leverage deep learning techniques to enhance the Computer Assisted Diagnosis of PE. This study presents a comprehensive dual-pronged approach combining classification and detection for PE diagnosis. We introduce an Attention-Guided Convolutional Neural Network (AG-CNN) for classification, addressing both global and local lesion region. For detection, state-of-the-art models are employed to pinpoint potential PE regions. Different ensembling techniques further improve detection accuracy by combining predictions from different models. Finally, a heuristic strategy integrates classifier outputs with detection results, ensuring robust and accurate PE identification. Our attention-guided classification approach, tested on the Ferdowsi University of Mashhad's Pulmonary Embolism (FUMPE) dataset, outperformed the baseline model DenseNet-121 by achieving an 8.1% increase in the Area Under the Receiver Operating Characteristic. By employing ensemble techniques with detection models, the mean average precision (mAP) was considerably enhanced by a 4.7% increase. The classifier-guided framework further refined the mAP and F1 scores over the ensemble models. Our research offers a comprehensive approach to PE diagnostics using deep learning, addressing the prevalent issues of underdiagnosis and misdiagnosis. We aim to improve PE patient care by integrating AI solutions into clinical workflows, highlighting the potential of human-AI collaboration in medical diagnostics.", "url": "https://arxiv.org/abs/2311.05197"}, {"metadata": {"arXiv": "2311.05332", "Date": "Thu, 09 Nov 2023 12:58:37 ", "Title": "On the Road with GPT-4V(ision): Early Explorations of Visual-Language Model on Autonomous Driving", "Authors": ["Licheng Wen", "Xuemeng Yang", "Daocheng Fu", "Xiaofeng Wang", "Pinlong Cai", "Xin Li", "Tao Ma", "Yingxuan Li", "Linran Xu", "Dengke Shang", "Zheng Zhu", "Shaoyan Sun", "Yeqi Bai", "Xinyu Cai", "Min Dou", "Shuanglu Hu", "Botian Shi"], "Categories": "cs.CV cs.AI cs.CL cs.RO"}, "abstract": "The pursuit of autonomous driving technology hinges on the sophisticated integration of perception, decision-making, and control systems. Traditional approaches, both data-driven and rule-based, have been hindered by their inability to grasp the nuance of complex driving environments and the intentions of other road users. This has been a significant bottleneck, particularly in the development of common sense reasoning and nuanced scene understanding necessary for safe and reliable autonomous driving. The advent of Visual Language Models (VLM) represents a novel frontier in realizing fully autonomous vehicle driving. This report provides an exhaustive evaluation of the latest state-of-the-art VLM, \\modelnamefull, and its application in autonomous driving scenarios. We explore the model's abilities to understand and reason about driving scenes, make decisions, and ultimately act in the capacity of a driver. Our comprehensive tests span from basic scene recognition to complex causal reasoning and real-time decision-making under varying conditions. Our findings reveal that \\modelname demonstrates superior performance in scene understanding and causal reasoning compared to existing autonomous systems. It showcases the potential to handle out-of-distribution scenarios, recognize intentions, and make informed decisions in real driving contexts. However, challenges remain, particularly in direction discernment, traffic light recognition, vision grounding, and spatial reasoning tasks. These limitations underscore the need for further research and development. Project is now available on GitHub for interested parties to access and utilize: \\url{https://github.com/PJLab-ADG/GPT4V-AD-Exploration}", "url": "https://arxiv.org/abs/2311.05332"}, {"metadata": {"arXiv": "2311.05371", "Date": "Thu, 09 Nov 2023 13:55:45 ", "Title": "Training Robust Deep Physiological Measurement Models with Synthetic Video-based Data", "Authors": ["Yuxuan Ou", "Yuzhe Zhang", "Yuntang Wang", "Shwetak Patel", "Daniel McDuf", "Xin Liu"], "Categories": "cs.CV cs.AI"}, "abstract": "Recent advances in supervised deep learning techniques have demonstrated the possibility to remotely measure human physiological vital signs (e.g., photoplethysmograph, heart rate) just from facial videos. However, the performance of these methods heavily relies on the availability and diversity of real labeled data. Yet, collecting large-scale real-world data with high-quality labels is typically challenging and resource intensive, which also raises privacy concerns when storing personal bio-metric data. Synthetic video-based datasets (e.g., SCAMPS~\\cite{mcduff2022scamps}) with photo-realistic synthesized avatars are introduced to alleviate the issues while providing high-quality synthetic data. However, there exists a significant gap between synthetic and real-world data, which hinders the generalization of neural models trained on these synthetic datasets. In this paper, we proposed several measures to add real-world noise to synthetic physiological signals and corresponding facial videos. We experimented with individual and combined augmentation methods and evaluated our framework on three public real-world datasets. Our results show that we were able to reduce the average MAE from 6.9 to 2.0.", "url": "https://arxiv.org/abs/2311.05371"}, {"metadata": {"arXiv": "2311.05591", "Date": "Thu, 09 Nov 2023 18:48:02 ", "Title": "Accuracy of a Vision-Language Model on Challenging Medical Cases", "Authors": ["Thomas Buckley", "James A. Diao", "Adam Rodman", "Arjun K. Manrai"], "Categories": "cs.CV cs.AI cs.CL"}, "abstract": "Background: General-purpose large language models that utilize both text and images have not been evaluated on a diverse array of challenging medical cases. Methods: Using 934 cases from the NEJM Image Challenge published between 2005 and 2023, we evaluated the accuracy of the recently released Generative Pre-trained Transformer 4 with Vision model (GPT-4V) compared to human respondents overall and stratified by question difficulty, image type, and skin tone. We further conducted a physician evaluation of GPT-4V on 69 NEJM clinicopathological conferences (CPCs). Analyses were conducted for models utilizing text alone, images alone, and both text and images. Results: GPT-4V achieved an overall accuracy of 61% (95% CI, 58 to 64%) compared to 49% (95% CI, 49 to 50%) for humans. GPT-4V outperformed humans at all levels of difficulty and disagreement, skin tones, and image types; the exception was radiographic images, where performance was equivalent between GPT-4V and human respondents. Longer, more informative captions were associated with improved performance for GPT-4V but similar performance for human respondents. GPT-4V included the correct diagnosis in its differential for 80% (95% CI, 68 to 88%) of CPCs when using text alone, compared to 58% (95% CI, 45 to 70%) of CPCs when using both images and text. Conclusions: GPT-4V outperformed human respondents on challenging medical cases and was able to synthesize information from both images and text, but performance deteriorated when images were added to highly informative text. Overall, our results suggest that multimodal AI models may be useful in medical diagnostic reasoning but that their accuracy may depend heavily on context.", "url": "https://arxiv.org/abs/2311.05591"}, {"metadata": {"arXiv": "2311.05607", "Date": "Thu, 09 Nov 2023 18:59:10 ", "Title": "Real-Time Neural Rasterization for Large Scenes", "Authors": ["Jeffrey Yunfan Liu", "Yun Chen", "Ze Yang", "Jingkang Wang", "Sivabalan Manivasagam", "Raquel Urtasun"], "Categories": "cs.CV cs.AI cs.GR", "Comments": ["Published in ICCV 2023. webpage: https://waabi.ai/NeuRas/"]}, "abstract": "We propose a new method for realistic real-time novel-view synthesis (NVS) of large scenes. Existing neural rendering methods generate realistic results, but primarily work for small scale scenes (<50 square meters) and have difficulty at large scale (>10000 square meters). Traditional graphics-based rasterization rendering is fast for large scenes but lacks realism and requires expensive manually created assets. Our approach combines the best of both worlds by taking a moderate-quality scaffold mesh as input and learning a neural texture field and shader to model view-dependant effects to enhance realism, while still using the standard graphics pipeline for real-time rendering. Our method outperforms existing neural rendering methods, providing at least 30x faster rendering with comparable or better realism for large self-driving and drone scenes. Our work is the first to enable real-time rendering of large real-world scenes.", "url": "https://arxiv.org/abs/2311.05607"}, {"metadata": {"arXiv": "2311.05599", "Date": "Thu, 09 Nov 2023 18:57:02 ", "Title": "SynH2R: Synthesizing Hand-Object Motions for Learning Human-to-Robot Handovers", "Authors": ["Sammy Christen and Lan Feng and Wei Yang and Yu-Wei Chao and Otmar Hilliges and Jie Song"], "Categories": "cs.RO cs.AI"}, "abstract": "Vision-based human-to-robot handover is an important and challenging task in human-robot interaction. Recent work has attempted to train robot policies by interacting with dynamic virtual humans in simulated environments, where the policies can later be transferred to the real world. However, a major bottleneck is the reliance on human motion capture data, which is expensive to acquire and difficult to scale to arbitrary objects and human grasping motions. In this paper, we introduce a framework that can generate plausible human grasping motions suitable for training the robot. To achieve this, we propose a hand-object synthesis method that is designed to generate handover-friendly motions similar to humans. This allows us to generate synthetic training and testing data with 100x more objects than previous work. In our experiments, we show that our method trained purely with synthetic data is competitive with state-of-the-art methods that rely on real human motion data both in simulation and on a real system. In addition, we can perform evaluations on a larger scale compared to prior work. With our newly introduced test set, we show that our model can better scale to a large variety of unseen objects and human motions compared to the baselines. Project page: https://eth-ait.github.io/synthetic-handovers/", "url": "https://arxiv.org/abs/2311.05599"}, {"metadata": {"arXiv": "2311.04938", "Date": "Wed, 08 Nov 2023 00:24:50 ", "Title": "Improved DDIM Sampling with Moment Matching Gaussian Mixtures", "Authors": ["Prasad Gabbur"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["27 pages", "13 figures"], "MSC-class": "I.2, I.4"}, "abstract": "We propose using a Gaussian Mixture Model (GMM) as reverse transition operator (kernel) within the Denoising Diffusion Implicit Models (DDIM) framework, which is one of the most widely used approaches for accelerated sampling from pre-trained Denoising Diffusion Probabilistic Models (DDPM). Specifically we match the first and second order central moments of the DDPM forward marginals by constraining the parameters of the GMM. We see that moment matching is sufficient to obtain samples with equal or better quality than the original DDIM with Gaussian kernels. We provide experimental results with unconditional models trained on CelebAHQ and FFHQ and class-conditional models trained on ImageNet datasets respectively. Our results suggest that using the GMM kernel leads to significant improvements in the quality of the generated samples when the number of sampling steps is small, as measured by FID and IS metrics. For example on ImageNet 256x256, using 10 sampling steps, we achieve a FID of 6.94 and IS of 207.85 with a GMM kernel compared to 10.15 and 196.73 respectively with a Gaussian kernel.", "url": "https://arxiv.org/abs/2311.04938"}, {"metadata": {"arXiv": "2311.05437", "Date": "Thu, 09 Nov 2023 15:22:26 ", "Title": "LLaVA-Plus: Learning to Use Tools for Creating Multimodal Agents", "Authors": ["Shilong Liu", "Hao Cheng", "Haotian Liu", "Hao Zhang", "Feng Li", "Tianhe Ren", "Xueyan Zou", "Jianwei Yang", "Hang Su", "Jun Zhu", "Lei Zhang", "Jianfeng Gao", "Chunyuan Li"], "Categories": "cs.CV cs.AI cs.CL cs.LG cs.MM", "Comments": ["25 pages", "25M file size. Project Page: https://llava-vl.github.io/llava-plus/"]}, "abstract": "LLaVA-Plus is a general-purpose multimodal assistant that expands the capabilities of large multimodal models. It maintains a skill repository of pre-trained vision and vision-language models and can activate relevant tools based on users' inputs to fulfill real-world tasks. LLaVA-Plus is trained on multimodal instruction-following data to acquire the ability to use tools, covering visual understanding, generation, external knowledge retrieval, and compositions. Empirical results show that LLaVA-Plus outperforms LLaVA in existing capabilities and exhibits new ones. It is distinct in that the image query is directly grounded and actively engaged throughout the entire human-AI interaction sessions, significantly improving tool use performance and enabling new scenarios.", "url": "https://arxiv.org/abs/2311.05437"}, {"metadata": {"arXiv": "2311.04937", "Date": "Tue, 07 Nov 2023 20:56:19 ", "Title": "Multimodal Clinical Benchmark for Emergency Care (MC-BEC): A Comprehensive Benchmark for Evaluating Foundation Models in Emergency Medicine", "Authors": ["Emma Chen", "Aman Kansal", "Julie Chen", "Boyang Tom Jin", "Julia Rachel Reisler", "David A Kim", "Pranav Rajpurkar"], "Categories": "cs.LG cs.AI", "Comments": ["Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track"]}, "abstract": "We propose the Multimodal Clinical Benchmark for Emergency Care (MC-BEC), a comprehensive benchmark for evaluating foundation models in Emergency Medicine using a dataset of 100K+ continuously monitored Emergency Department visits from 2020-2022. MC-BEC focuses on clinically relevant prediction tasks at timescales from minutes to days, including predicting patient decompensation, disposition, and emergency department (ED) revisit, and includes a standardized evaluation framework with train-test splits and evaluation metrics. The multimodal dataset includes a wide range of detailed clinical data, including triage information, prior diagnoses and medications, continuously measured vital signs, electrocardiogram and photoplethysmograph waveforms, orders placed and medications administered throughout the visit, free-text reports of imaging studies, and information on ED diagnosis, disposition, and subsequent revisits. We provide performance baselines for each prediction task to enable the evaluation of multimodal, multitask models. We believe that MC-BEC will encourage researchers to develop more effective, generalizable, and accessible foundation models for multimodal clinical data.", "url": "https://arxiv.org/abs/2311.04937"}, {"metadata": {"arXiv": "2311.04943", "Date": "Wed, 08 Nov 2023 04:34:18 ", "Title": "MathNAS: If Blocks Have a Role in Mathematical Architecture Design", "Authors": ["Wang Qinsi and Ke Jinhan and Liang Zhi and Zhang Sihai"], "Categories": "cs.LG cs.AI", "Comments": ["NeurIPS 2023"]}, "abstract": "Neural Architecture Search (NAS) has emerged as a favoured method for unearthing effective neural architectures. Recent development of large models has intensified the demand for faster search speeds and more accurate search results. However, designing large models by NAS is challenging due to the dramatical increase of search space and the associated huge performance evaluation cost. Consider a typical modular search space widely used in NAS, in which a neural architecture consists of $m$ block nodes and a block node has $n$ alternative blocks. Facing the space containing $n^m$ candidate networks, existing NAS methods attempt to find the best one by searching and evaluating candidate networks directly.Different from the general strategy that takes architecture search as a whole problem, we propose a novel divide-and-conquer strategy by making use of the modular nature of the search space.Here, we introduce MathNAS, a general NAS framework based on mathematical programming.In MathNAS, the performances of the $m*n$ possible building blocks in the search space are calculated first, and then the performance of a network is directly predicted based on the performances of its building blocks. Although estimating block performances involves network training, just as what happens for network performance evaluation in existing NAS methods, predicting network performance is completely training-free and thus extremely fast. In contrast to the $n^m$ candidate networks to evaluate in existing NAS methods, which require training and a formidable computational burden, there are only $m*n$ possible blocks to handle in MathNAS. Therefore, our approach effectively reduces the complexity of network performance evaluation.Our code is available at https://github.com/wangqinsi1/MathNAS.", "url": "https://arxiv.org/abs/2311.04943"}, {"metadata": {"arXiv": "2311.04944", "Date": "Wed, 08 Nov 2023 05:14:41 ", "Title": "Edge-assisted U-Shaped Split Federated Learning with Privacy-preserving for Internet of Things", "Authors": ["Hengliang Tang", "Zihang Zhao", "Detian Liu", "Yang Cao", "Shiqiang Zhang", "Siqing You"], "Categories": "cs.LG cs.AI cs.CR"}, "abstract": "In the realm of the Internet of Things (IoT), deploying deep learning models to process data generated or collected by IoT devices is a critical challenge. However, direct data transmission can cause network congestion and inefficient execution, given that IoT devices typically lack computation and communication capabilities. Centralized data processing in data centers is also no longer feasible due to concerns over data privacy and security. To address these challenges, we present an innovative Edge-assisted U-Shaped Split Federated Learning (EUSFL) framework, which harnesses the high-performance capabilities of edge servers to assist IoT devices in model training and optimization process. In this framework, we leverage Federated Learning (FL) to enable data holders to collaboratively train models without sharing their data, thereby enhancing data privacy protection by transmitting only model parameters. Additionally, inspired by Split Learning (SL), we split the neural network into three parts using U-shaped splitting for local training on IoT devices. By exploiting the greater computation capability of edge servers, our framework effectively reduces overall training time and allows IoT devices with varying capabilities to perform training tasks efficiently. Furthermore, we proposed a novel noise mechanism called LabelDP to ensure that data features and labels can securely resist reconstruction attacks, eliminating the risk of privacy leakage. Our theoretical analysis and experimental results demonstrate that EUSFL can be integrated with various aggregation algorithms, maintaining good performance across different computing capabilities of IoT devices, and significantly reducing training time and local computation overhead.", "url": "https://arxiv.org/abs/2311.04944"}, {"metadata": {"arXiv": "2311.04945", "Date": "Wed, 08 Nov 2023 07:22:39 ", "Title": "Auto deep learning for bioacoustic signals", "Authors": ["Giulio Tosato", "Abdelrahman Shehata", "Joshua Janssen", "Kees Kamp", "Pramatya Jati", "Dan Stowell"], "Categories": "cs.LG cs.AI cs.SD eess.AS"}, "abstract": "This study investigates the potential of automated deep learning to enhance the accuracy and efficiency of multi-class classification of bird vocalizations, compared against traditional manually-designed deep learning models. Using the Western Mediterranean Wetland Birds dataset, we investigated the use of AutoKeras, an automated machine learning framework, to automate neural architecture search and hyperparameter tuning. Comparative analysis validates our hypothesis that the AutoKeras-derived model consistently outperforms traditional models like MobileNet, ResNet50 and VGG16. Our approach and findings underscore the transformative potential of automated deep learning for advancing bioacoustics research and models. In fact, the automated techniques eliminate the need for manual feature engineering and model design while improving performance. This study illuminates best practices in sampling, evaluation and reporting to enhance reproducibility in this nascent field. All the code used is available at https: //github.com/giuliotosato/AutoKeras-bioacustic Keywords: AutoKeras; automated deep learning; audio classification; Wetlands Bird dataset; comparative analysis; bioacoustics; validation dataset; multi-class classification; spectrograms.", "url": "https://arxiv.org/abs/2311.04945"}, {"metadata": {"arXiv": "2311.04951", "Date": "Wed, 08 Nov 2023 14:08:00 ", "Title": "Leveraging Speculative Sampling and KV-Cache Optimizations Together for Generative AI using OpenVINO", "Authors": ["Haim Barad", "Ekaterina Aidova", "Yury Gorbachev"], "Categories": "cs.LG cs.AI cs.PF", "Comments": ["To be published on openvino.ai. Code available at https://github.com/openvinotoolkit/openvino_notebooks/tree/main/notebooks/266-speculative-sampling"]}, "abstract": "Inference optimizations are critical for improving user experience and reducing infrastructure costs and power consumption. In this article, we illustrate a form of dynamic execution known as speculative sampling to reduce the overall latency of text generation and compare it with standard autoregressive sampling. This can be used together with model-based optimizations (e.g. quantization) to provide an optimized solution. Both sampling methods make use of KV caching. A Jupyter notebook and some sample executions are provided.", "url": "https://arxiv.org/abs/2311.04951"}, {"metadata": {"arXiv": "2311.05054", "Date": "Wed, 08 Nov 2023 23:33:39 ", "Title": "Geometry-Calibrated DRO: Combating Over-Pessimism with Free Energy Implications", "Authors": ["Jiashuo Liu", "Jiayun Wu", "Tianyu Wang", "Hao Zou", "Bo Li", "Peng Cui"], "Categories": "cs.LG cs.AI", "Comments": ["Short version appears at 37th Conference on Neural Information Processing Systems (NeurIPS 2023)", "Workshop on Distribution Shifts (DistShift)"]}, "abstract": "Machine learning algorithms minimizing average risk are susceptible to distributional shifts. Distributionally Robust Optimization (DRO) addresses this issue by optimizing the worst-case risk within an uncertainty set. However, DRO suffers from over-pessimism, leading to low-confidence predictions, poor parameter estimations as well as poor generalization. In this work, we conduct a theoretical analysis of a probable root cause of over-pessimism: excessive focus on noisy samples. To alleviate the impact of noise, we incorporate data geometry into calibration terms in DRO, resulting in our novel Geometry-Calibrated DRO (GCDRO) for regression. We establish the connection between our risk objective and the Helmholtz free energy in statistical physics, and this free-energy-based risk can extend to standard DRO methods. Leveraging gradient flow in Wasserstein space, we develop an approximate minimax optimization algorithm with a bounded error ratio and elucidate how our approach mitigates noisy sample effects. Comprehensive experiments confirm GCDRO's superiority over conventional DRO methods.", "url": "https://arxiv.org/abs/2311.05054"}, {"metadata": {"arXiv": "2311.05067", "Date": "Thu, 09 Nov 2023 00:05:17 ", "Title": "Accelerating Exploration with Unlabeled Prior Data", "Authors": ["Qiyang Li", "Jason Zhang", "Dibya Ghosh", "Amy Zhang", "Sergey Levine"], "Categories": "cs.LG cs.AI stat.ML", "Comments": ["24 pages", "16 figures", "37th Conference on Neural Information Processing Systems (NeurIPS 2023)"]}, "abstract": "Learning to solve tasks from a sparse reward signal is a major challenge for standard reinforcement learning (RL) algorithms. However, in the real world, agents rarely need to solve sparse reward tasks entirely from scratch. More often, we might possess prior experience to draw on that provides considerable guidance about which actions and outcomes are possible in the world, which we can use to explore more effectively for new tasks. In this work, we study how prior data without reward labels may be used to guide and accelerate exploration for an agent solving a new sparse reward task. We propose a simple approach that learns a reward model from online experience, labels the unlabeled prior data with optimistic rewards, and then uses it concurrently alongside the online data for downstream policy and critic optimization. This general formula leads to rapid exploration in several challenging sparse-reward domains where tabula rasa exploration is insufficient, including the AntMaze domain, Adroit hand manipulation domain, and a visual simulated robotic manipulation domain. Our results highlight the ease of incorporating unlabeled prior data into existing online RL algorithms, and the (perhaps surprising) effectiveness of doing so.", "url": "https://arxiv.org/abs/2311.05067"}, {"metadata": {"arXiv": "2311.05075", "Date": "Thu, 09 Nov 2023 00:15:06 ", "Title": "Mental Health Diagnosis in the Digital Age: Harnessing Sentiment Analysis on Social Media Platforms upon Ultra-Sparse Feature Content", "Authors": ["Haijian Shao", "Ming Zhu", "Shengjie Zhai"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "Amid growing global mental health concerns, particularly among vulnerable groups, natural language processing offers a tremendous potential for early detection and intervention of people's mental disorders via analyzing their postings and discussions on social media platforms. However, ultra-sparse training data, often due to vast vocabularies and low-frequency words, hinders the analysis accuracy. Multi-labeling and Co-occurrences of symptoms may also blur the boundaries in distinguishing similar/co-related disorders. To address these issues, we propose a novel semantic feature preprocessing technique with a three-folded structure: 1) mitigating the feature sparsity with a weak classifier, 2) adaptive feature dimension with modulus loops, and 3) deep-mining and extending features among the contexts. With enhanced semantic features, we train a machine learning model to predict and classify mental disorders. We utilize the Reddit Mental Health Dataset 2022 to examine conditions such as Anxiety, Borderline Personality Disorder (BPD), and Bipolar-Disorder (BD) and present solutions to the data sparsity challenge, highlighted by 99.81% non-zero elements. After applying our preprocessing technique, the feature sparsity decreases to 85.4%. Overall, our methods, when compared to seven benchmark models, demonstrate significant performance improvements: 8.0% in accuracy, 0.069 in precision, 0.093 in recall, 0.102 in F1 score, and 0.059 in AUC. This research provides foundational insights for mental health prediction and monitoring, providing innovative solutions to navigate challenges associated with ultra-sparse data feature and intricate multi-label classification in the domain of mental health analysis.", "url": "https://arxiv.org/abs/2311.05075"}, {"metadata": {"arXiv": "2311.05088", "Date": "Thu, 09 Nov 2023 01:22:58 ", "Title": "Meta-learning of semi-supervised learning from tasks with heterogeneous attribute spaces", "Authors": ["Tomoharu Iwata", "Atsutoshi Kumagai"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "We propose a meta-learning method for semi-supervised learning that learns from multiple tasks with heterogeneous attribute spaces. The existing semi-supervised meta-learning methods assume that all tasks share the same attribute space, which prevents us from learning with a wide variety of tasks. With the proposed method, the expected test performance on tasks with a small amount of labeled data is improved with unlabeled data as well as data in various tasks, where the attribute spaces are different among tasks. The proposed method embeds labeled and unlabeled data simultaneously in a task-specific space using a neural network, and the unlabeled data's labels are estimated by adapting classification or regression models in the embedding space. For the neural network, we develop variable-feature self-attention layers, which enable us to find embeddings of data with different attribute spaces with a single neural network by considering interactions among examples, attributes, and labels. Our experiments on classification and regression datasets with heterogeneous attribute spaces demonstrate that our proposed method outperforms the existing meta-learning and semi-supervised learning methods.", "url": "https://arxiv.org/abs/2311.05088"}, {"metadata": {"arXiv": "2311.05152", "Date": "Thu, 09 Nov 2023 05:24:20 ", "Title": "Cross-modal Prompts: Adapting Large Pre-trained Models for Audio-Visual Downstream Tasks", "Authors": ["Haoyi Duan", "Yan Xia", "Mingze Zhou", "Li Tang", "Jieming Zhu", "Zhou Zhao"], "Categories": "cs.LG cs.AI cs.CV cs.MM", "Comments": ["Accepted to NeurIPS 2023"]}, "abstract": "In recent years, the deployment of large-scale pre-trained models in audio-visual downstream tasks has yielded remarkable outcomes. However, these models, primarily trained on single-modality unconstrained datasets, still encounter challenges in feature extraction for multi-modal tasks, leading to suboptimal performance. This limitation arises due to the introduction of irrelevant modality-specific information during encoding, which adversely affects the performance of downstream tasks. To address this challenge, this paper proposes a novel Dual-Guided Spatial-Channel-Temporal (DG-SCT) attention mechanism. This mechanism leverages audio and visual modalities as soft prompts to dynamically adjust the parameters of pre-trained models based on the current multi-modal input features. Specifically, the DG-SCT module incorporates trainable cross-modal interaction layers into pre-trained audio-visual encoders, allowing adaptive extraction of crucial information from the current modality across spatial, channel, and temporal dimensions, while preserving the frozen parameters of large-scale pre-trained models. Experimental evaluations demonstrate that our proposed model achieves state-of-the-art results across multiple downstream tasks, including AVE, AVVP, AVS, and AVQA. Furthermore, our model exhibits promising performance in challenging few-shot and zero-shot scenarios. The source code and pre-trained models are available at https://github.com/haoyi-duan/DG-SCT.", "url": "https://arxiv.org/abs/2311.05152"}, {"metadata": {"arXiv": "2311.05160", "Date": "Thu, 09 Nov 2023 06:11:44 ", "Title": "RAPID: Training-free Retrieval-based Log Anomaly Detection with PLM considering Token-level information", "Authors": ["Gunho No", "Yukyung Lee", "Hyeongwon Kang", "Pilsung Kang"], "Categories": "cs.LG cs.AI"}, "abstract": "As the IT industry advances, system log data becomes increasingly crucial. Many computer systems rely on log texts for management due to restricted access to source code. The need for log anomaly detection is growing, especially in real-world applications, but identifying anomalies in rapidly accumulating logs remains a challenging task. Traditional deep learning-based anomaly detection models require dataset-specific training, leading to corresponding delays. Notably, most methods only focus on sequence-level log information, which makes the detection of subtle anomalies harder, and often involve inference processes that are difficult to utilize in real-time. We introduce RAPID, a model that capitalizes on the inherent features of log data to enable anomaly detection without training delays, ensuring real-time capability. RAPID treats logs as natural language, extracting representations using pre-trained language models. Given that logs can be categorized based on system context, we implement a retrieval-based technique to contrast test logs with the most similar normal logs. This strategy not only obviates the need for log-specific training but also adeptly incorporates token-level information, ensuring refined and robust detection, particularly for unseen logs. We also propose the core set technique, which can reduce the computational cost needed for comparison. Experimental results show that even without training on log data, RAPID demonstrates competitive performance compared to prior models and achieves the best performance on certain datasets. Through various research questions, we verified its capability for real-time detection without delay.", "url": "https://arxiv.org/abs/2311.05160"}, {"metadata": {"arXiv": "2311.05185", "Date": "Thu, 09 Nov 2023 07:45:05 ", "Title": "Mixture of Weak & Strong Experts on Graphs", "Authors": ["Hanqing Zeng", "Hanjia Lyu", "Diyi Hu", "Yinglong Xia", "Jiebo Luo"], "Categories": "cs.LG cs.AI"}, "abstract": "Realistic graphs contain both rich self-features of nodes and informative structures of neighborhoods, jointly handled by a GNN in the typical setup. We propose to decouple the two modalities by mixture of weak and strong experts (Mowst), where the weak expert is a light-weight Multi-layer Perceptron (MLP), and the strong expert is an off-the-shelf Graph Neural Network (GNN). To adapt the experts' collaboration to different target nodes, we propose a \"confidence\" mechanism based on the dispersion of the weak expert's prediction logits. The strong expert is conditionally activated when either the node's classification relies on neighborhood information, or the weak expert has low model quality. We reveal interesting training dynamics by analyzing the influence of the confidence function on loss: our training algorithm encourages the specialization of each expert by effectively generating soft splitting of the graph. In addition, our \"confidence\" design imposes a desirable bias toward the strong expert to benefit from GNN's better generalization capability. Mowst is easy to optimize and achieves strong expressive power, with a computation cost comparable to a single GNN. Empirically, Mowst shows significant accuracy improvement on 6 standard node classification benchmarks (including both homophilous and heterophilous graphs).", "url": "https://arxiv.org/abs/2311.05185"}, {"metadata": {"arXiv": "2311.05245", "Date": "Thu, 09 Nov 2023 09:58:02 ", "Title": "Uncertainty Wrapper in the medical domain: Establishing transparent uncertainty quantification for opaque machine learning models in practice", "Authors": ["Lisa J\\\"ockel", "Michael Kl\\\"as", "Georg Popp", "Nadja Hilger", "Stephan Fricke"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "When systems use data-based models that are based on machine learning (ML), errors in their results cannot be ruled out. This is particularly critical if it remains unclear to the user how these models arrived at their decisions and if errors can have safety-relevant consequences, as is often the case in the medical field. In such cases, the use of dependable methods to quantify the uncertainty remaining in a result allows the user to make an informed decision about further usage and draw possible conclusions based on a given result. This paper demonstrates the applicability and practical utility of the Uncertainty Wrapper using flow cytometry as an application from the medical field that can benefit from the use of ML models in conjunction with dependable and transparent uncertainty quantification.", "url": "https://arxiv.org/abs/2311.05245"}, {"metadata": {"arXiv": "2311.05304", "Date": "Thu, 09 Nov 2023 12:01:32 ", "Title": "Data Valuation and Detections in Federated Learning", "Authors": ["Wenqian Li", "Shuran Fu", "Fengrui Zhang", "Yan Pang"], "Categories": "cs.LG cs.AI cs.CR"}, "abstract": "Federated Learning (FL) enables collaborative model training without sharing raw data, demanding abundant, high-quality data for optimal model performance. Fair and efficient data evaluation is a fundamental issue for incentivizing clients to provide more high-quality data. Meanwhile, it is likely that only a subset of clients and datasets are relevant for a learning task while the rest of them may have a negative impact on the model training. This paper introduces a novel privacy-preserving method for evaluating client contributions and selecting relevant data samples without a pre-specified training algorithm. Our proposed approach, FedBary, utilizes Wasserstein distance within the federated context, offering a new pioneering solution for data valuation, which provides transparent data evaluation and efficient computation of Wasserstein barycenter to mitigate reliance on validation data. We conduct extensive empirical experiments and theoretical analysis, showing the promising research of this valuation metric.", "url": "https://arxiv.org/abs/2311.05304"}, {"metadata": {"arXiv": "2311.05316", "Date": "Thu, 09 Nov 2023 12:22:44 ", "Title": "ABIGX: A Unified Framework for eXplainable Fault Detection and Classification", "Authors": ["Yue Zhuo", "Jinchuan Qian", "Zhihuan Song", "Zhiqiang Ge"], "Categories": "cs.LG cs.AI"}, "abstract": "For explainable fault detection and classification (FDC), this paper proposes a unified framework, ABIGX (Adversarial fault reconstruction-Based Integrated Gradient eXplanation). ABIGX is derived from the essentials of previous successful fault diagnosis methods, contribution plots (CP) and reconstruction-based contribution (RBC). It is the first explanation framework that provides variable contributions for the general FDC models. The core part of ABIGX is the adversarial fault reconstruction (AFR) method, which rethinks the FR from the perspective of adversarial attack and generalizes to fault classification models with a new fault index. For fault classification, we put forward a new problem of fault class smearing, which intrinsically hinders the correct explanation. We prove that ABIGX effectively mitigates this problem and outperforms the existing gradient-based explanation methods. For fault detection, we theoretically bridge ABIGX with conventional fault diagnosis methods by proving that CP and RBC are the linear specifications of ABIGX. The experiments evaluate the explanations of FDC by quantitative metrics and intuitive illustrations, the results of which show the general superiority of ABIGX to other advanced explanation methods.", "url": "https://arxiv.org/abs/2311.05316"}, {"metadata": {"arXiv": "2311.05418", "Date": "Thu, 09 Nov 2023 14:54:28 ", "Title": "Generalization in medical AI: a perspective on developing scalable models", "Authors": ["Joachim A. Behar", "Jeremy Levy and Leo Anthony Celi"], "Categories": "cs.LG cs.AI"}, "abstract": "Over the past few years, research has witnessed the advancement of deep learning models trained on large datasets, some even encompassing millions of examples. While these impressive performance on their hidden test sets, they often underperform when assessed on external datasets. Recognizing the critical role of generalization in medical AI development, many prestigious journals now require reporting results both on the local hidden test set as well as on external datasets before considering a study for publication. Effectively, the field of medical AI has transitioned from the traditional usage of a single dataset that is split into train and test to a more comprehensive framework using multiple datasets, some of which are used for model development (source domain) and others for testing (target domains). However, this new experimental setting does not necessarily resolve the challenge of generalization. This is because of the variability encountered in intended use and specificities across hospital cultures making the idea of universally generalizable systems a myth. On the other hand, the systematic, and a fortiori recurrent re-calibration, of models at the individual hospital level, although ideal, may be overoptimistic given the legal, regulatory and technical challenges that are involved. Re-calibration using transfer learning may not even be possible in some instances where reference labels of target domains are not available. In this perspective we establish a hierarchical three-level scale system reflecting the generalization level of a medical AI algorithm. This scale better reflects the diversity of real-world medical scenarios per which target domain data for re-calibration of models may or not be available and if it is, may or not have reference labels systematically available.", "url": "https://arxiv.org/abs/2311.05418"}, {"metadata": {"arXiv": "2311.05511", "Date": "Thu, 09 Nov 2023 16:51:26 ", "Title": "Anytime-Constrained Reinforcement Learning", "Authors": ["Jeremy McMahan", "Xiaojin Zhu"], "Categories": "cs.LG cs.AI cs.DS"}, "abstract": "We introduce and study constrained Markov Decision Processes (cMDPs) with anytime constraints. An anytime constraint requires the agent to never violate its budget at any point in time, almost surely. Although Markovian policies are no longer sufficient, we show that there exist optimal deterministic policies augmented with cumulative costs. In fact, we present a fixed-parameter tractable reduction from anytime-constrained cMDPs to unconstrained MDPs. Our reduction yields planning and learning algorithms that are time and sample-efficient for tabular cMDPs so long as the precision of the costs is logarithmic in the size of the cMDP. However, we also show that computing non-trivial approximately optimal policies is NP-hard in general. To circumvent this bottleneck, we design provable approximation algorithms that efficiently compute or learn an approximately feasible policy with optimal value so long as the maximum supported cost is bounded by a polynomial in the cMDP or by the absolute budget. Given our hardness results, our approximation guarantees are the best possible in terms of tractability under worst-case analysis.", "url": "https://arxiv.org/abs/2311.05511"}, {"metadata": {"arXiv": "2311.05584", "Date": "Thu, 09 Nov 2023 18:45:16 ", "Title": "Zero-Shot Goal-Directed Dialogue via RL on Imagined Conversations", "Authors": ["Joey Hong and Sergey Levine and Anca Dragan"], "Categories": "cs.LG cs.AI cs.CL", "Comments": ["25 pages", "6 figures"]}, "abstract": "Large language models (LLMs) have emerged as powerful and general solutions to many natural language tasks. However, many of the most important applications of language generation are interactive, where an agent has to talk to a person to reach a desired outcome. For example, a teacher might try to understand their student's current comprehension level to tailor their instruction accordingly, and a travel agent might ask questions of their customer to understand their preferences in order to recommend activities they might enjoy. LLMs trained with supervised fine-tuning or \"single-step\" RL, as with standard RLHF, might struggle which tasks that require such goal-directed behavior, since they are not trained to optimize for overall conversational outcomes after multiple turns of interaction. In this work, we explore a new method for adapting LLMs with RL for such goal-directed dialogue. Our key insight is that, though LLMs might not effectively solve goal-directed dialogue tasks out of the box, they can provide useful data for solving such tasks by simulating suboptimal but human-like behaviors. Given a textual description of a goal-directed dialogue task, we leverage LLMs to sample diverse synthetic rollouts of hypothetical in-domain human-human interactions. Our algorithm then utilizes this dataset with offline reinforcement learning to train an interactive conversational agent that can optimize goal-directed objectives over multiple turns. In effect, the LLM produces examples of possible interactions, and RL then processes these examples to learn to perform more optimal interactions. Empirically, we show that our proposed approach achieves state-of-the-art performance in various goal-directed dialogue tasks that include teaching and preference elicitation.", "url": "https://arxiv.org/abs/2311.05584"}, {"metadata": {"arXiv": "2311.05596", "Date": "Thu, 09 Nov 2023 18:54:28 ", "Title": "LLM Augmented Hierarchical Agents", "Authors": ["Bharat Prakash", "Tim Oates", "Tinoosh Mohsenin"], "Categories": "cs.LG cs.AI cs.RO"}, "abstract": "Solving long-horizon, temporally-extended tasks using Reinforcement Learning (RL) is challenging, compounded by the common practice of learning without prior knowledge (or tabula rasa learning). Humans can generate and execute plans with temporally-extended actions and quickly learn to perform new tasks because we almost never solve problems from scratch. We want autonomous agents to have this same ability. Recently, LLMs have been shown to encode a tremendous amount of knowledge about the world and to perform impressive in-context learning and reasoning. However, using LLMs to solve real world problems is hard because they are not grounded in the current task. In this paper we exploit the planning capabilities of LLMs while using RL to provide learning from the environment, resulting in a hierarchical agent that uses LLMs to solve long-horizon tasks. Instead of completely relying on LLMs, they guide a high-level policy, making learning significantly more sample efficient. This approach is evaluated in simulation environments such as MiniGrid, SkillHack, and Crafter, and on a real robot arm in block manipulation tasks. We show that agents trained using our approach outperform other baselines methods and, once trained, don't need access to LLMs during deployment.", "url": "https://arxiv.org/abs/2311.05596"}, {"metadata": {"arXiv": "2311.05084", "Date": "Thu, 09 Nov 2023 00:59:28 ", "Title": "Signal Temporal Logic-Guided Apprenticeship Learning", "Authors": ["Aniruddh G. Puranic", "Jyotirmoy V. Deshmukh and Stefanos Nikolaidis"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["23 pages", "8 figures"]}, "abstract": "Apprenticeship learning crucially depends on effectively learning rewards, and hence control policies from user demonstrations. Of particular difficulty is the setting where the desired task consists of a number of sub-goals with temporal dependencies. The quality of inferred rewards and hence policies are typically limited by the quality of demonstrations, and poor inference of these can lead to undesirable outcomes. In this letter, we show how temporal logic specifications that describe high level task objectives, are encoded in a graph to define a temporal-based metric that reasons about behaviors of demonstrators and the learner agent to improve the quality of inferred rewards and policies. Through experiments on a diverse set of robot manipulator simulations, we show how our framework overcomes the drawbacks of prior literature by drastically improving the number of demonstrations required to learn a control policy.", "url": "https://arxiv.org/abs/2311.05084"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>
